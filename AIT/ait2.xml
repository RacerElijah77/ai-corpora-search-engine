<THESIS>
<NUMBER>  2362 </NUMBER>
<ORDER>   AAG9735923 </ORDER>
<TITLE> A LEADING INDICATOR FORECASTING EXPERT SYSTEM </TITLE>
<AUTHOR> SCOTT, THOMAS B.. </AUTHOR>
<YEAR> 1994 </YEAR>
<INSTITUTION> UNIVERSITY OF CINCINNATI; 0045 </INSTITUTION>
<DESCRIPTORS> OPERATIONS RESEARCH; COMPUTER SCIENCE; STATISTICS; ARTIFICIAL INTELLIGENCE; ECONOMICS, FINANCE </DESCRIPTORS>
<ADVISER> ROGER ALAN PICK </ADVISER>
<CLASSIFICATIONS> COMMODITIES </CLASSIFICATIONS>
<ABSTRACT>
The leading indicator forecasting expert system (LIFEX)
developed in this dissertation focuses on medium-range
(three to twelve months) price and demand forecasts for
commodity-type items. LIFEX is two-tiered. Either
statistically unsophisticated users or forecasters and
academics can use it. Forecasters and academics will
select the option which permits them to participate in
the decisions concerning model development. The
statistically unsophisticated user will allow the expert
system to decide all issues such as: (1) real vs.
nominal dollars, (2) interpolation, (3) seasonality, (4)
variable transformations, (5) stationarity (via
detrending), (6) multicollinearity, (7) establishing
variable and model selection criteria, (8) variable
selection, (9) model evaluation, and (10) model
selection. The decision rules were established using a
variety of knowledge acquisition techniques with
multiple experts.
To this author's knowledge, LIFEX represents the first
leading indicator forecasting expert system to evaluate
the select variables and models based primarily on
"predictability" criteria (performance measures of
models developed using out of sample data). This is a
primary strength of the methodology used here and
separates this system from other commercially available
systems.
LIFEX represents a valuable research tool able to
quickly examine the relative importance of the issues
mentioned above in developing reliable forecasts. In
addition to the research contribution, LIFEX is a tool
designed to fill a demonstrated need and is suitable for
planning and strategy, product marketing, and
production/operations planning.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  2363 </NUMBER>
<ORDER>   AAGMM11295 </ORDER>
<TITLE> TRAINING REDUNDANT ARTIFICIAL NEURAL NETWORKS: IMPOSING BIOLOGY ON TECHNOLOGY </TITLE>
<AUTHOR> MEDLER, DAVID ALEXANDER </AUTHOR>
<YEAR> 1994 </YEAR>
<INSTITUTION> UNIVERSITY OF ALBERTA (CANADA); 0351 </INSTITUTION>
<DESCRIPTORS> PSYCHOLOGY, EXPERIMENTAL; COMPUTER SCIENCE; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> M. R. W. DAWSON </ADVISER>
<CLASSIFICATIONS> NIL </CLASSIFICATIONS>
<ABSTRACT>
One biological principle that is often overlooked in the
design of artificial neural networks (ANNs) is
redundancy: Redundancy is the replication of processes
within the brain. This paper examines the effects of
redundancy on learning in ANNs when given either a
pattern classification task or a function approximation
task. Two different pattern classification tasks were
used: parity and encoder. The function approximation
task simulated a robotic arm trained to reach towards an
object in two-dimensional space. Initial results
indicate that there is an optimal level of redundancy in
terms of probability of convergence, convergence speed,
and convergence efficiency. When this level of
redundancy is used, redundant ANNs learned the pattern
classification problem much faster, and converged on a
solution 100% of the time whereas standard ANNs
sometimes failed to learn the problem. Furthermore, when
overall network error is considered, redundant ANNs were
significantly more accurate than standard ANNs at
performing the function approximation task. These
results are discussed in terms of the relevance of
redundancy to the performance of ANNs in general, and
the relevance of redundancy in biological systems in
particular.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  2364 </NUMBER>
<ORDER>   AAIMM97084 </ORDER>
<TITLE> CONTROLEUR NEURO-ADAPTATIF </TITLE>
<AUTHOR> BUGNARIU, NICOLAIE CALIN </AUTHOR>
<YEAR> 1994 </YEAR>
<INSTITUTION> ECOLE POLYTECHNIQUE, MONTREAL (CANADA); 1105 </INSTITUTION>
<DESCRIPTORS> ENGINEERING, ELECTRONICS AND ELECTRICAL; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> JEAN-JULES BRAULT; CHAHE NERGUIZIAN </ADVISER>
<CLASSIFICATIONS> FRENCH TEXT </CLASSIFICATIONS>
<ABSTRACT>
Advanced manipulator applications often require
effective control design to achieve accurate tracking of
fast desired motions. If the parameters of a
manipulator's link and its load are known a priori, the
well-known "computed-torque" control design can he used
for this purpose, and theoretically guarantees exact
tracking. However, for a manipulator handling various
loads, the inertial parameters of the load change from
time to time without being accurately known by the
controller, and the performance of the computed-torque
controller degrades substantially or may even become
unstable. This parameter sensitivity is particularly
severe for direct-drive robots or fast manipulator
motions.
Two of the more recently developed robot controllers are
neural adaptive and indirect adaptive controllers.
The indirect adaptive controller makes an on-line
parameters adaptation, has a stability proof and
implementations facilities. It is important to note that
indirect adaptive controllers requires an on-line
estimation of the system parameters and a well-defined
dynamic model, whereas neural adaptive controllers does
not require any of these conditions.
A neuro-adaptive controller was created by an
hybridization of an indirect adaptive controller and a
special designed neural network called: "Plastic and
Stable, Learning Classification Neural Network"
(P.S.L.C.). This new controller makes a plastic and
stable classification of parameters issued from
multiples "adaptive controllers" working in parallel.
This structure is chosen to reduce drastically the delay
of time needed for parameters estimation, assuring a
better tracking. (Abstract shortened by UMI.)
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  2365 </NUMBER>
<ORDER>   AAIMM97028 </ORDER>
<TITLE> EXPERIENCES DE TRAITEMENT D'IMAGES AVEC L'ARCHITECTURE COGNITIVE SOAR  </TITLE>
<AUTHOR> DODIER, MICHEL </AUTHOR>
<YEAR> 1994 </YEAR>
<INSTITUTION> UNIVERSITE DE MONTREAL (CANADA); 0992 </INSTITUTION>
<DESCRIPTORS> ENGINEERING, ELECTRONICS AND ELECTRICAL; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> DANIEL CREVIER </ADVISER>
<CLASSIFICATIONS> FRENCH TEXT </CLASSIFICATIONS>
<ABSTRACT>
Le projet decrit dans ce rapport s'insere dans une
demarche a plus long terme visant a la creation d'une
interface intelligente a des bibliotheques de programmes
de traitement d'images. Une telle interface doit pouvoir
se referer a des connaissances generales sur le
traitement d'images, qui peuvent s'exprimer sous la
forme de regles SI-ALORS. Cependant, les images
numerisees sont souvent constituees de quelques
centaines de milliers de pixels. Les operations visant a
analyser leur contenu sont complexes et requierent des
capacites de traitement elevees. Il faut, pour effectuer
ces operations sur les images, une couche de logiciel
supplementaire entre l'image elle-meme et la base de
connaissances.
Nous avons utilie a cet effet, la bibliotheque de
programmes de traitement d'images Khoros. L'architecture
cognitive Soar fait office de coquille autour de la base
de connaissances. Le couplage de Soar a Khoros s'est
effectue par l'intermediaire d'un module appele
"processeur de routines visuelles" ou PRV, inspire d'une
theorie de la vision humaine elaboree par Shimon Ullman
du MIT. Ce couplage a ete teste sur une tache
relativement simple, en l'occurrence le decompte de
pieces de monnaie sur un fond uniforme.
Ces essais nous ont permis de demontrer la faisabilite
de l'analyse d'images par couplage d'une bibliotheque de
programmes de traitement conventionnelle avec
l'architecture Soar. Ils ouvrent la voie a l'utilisation
des possibilites d'apprentissage automatise inherentes a
Soar pour augmenter progressivement la complexite des
traitements effectues.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  2366 </NUMBER>
<ORDER>   AAIMM97026 </ORDER>
<TITLE> EXPERIENCES D'APPRENTISSAGE VISUEL A L'AIDE DE L'ARCHITECTURE COGNITIVE SOAR </TITLE>
<AUTHOR> BERNARD, JACQUES </AUTHOR>
<YEAR> 1994 </YEAR>
<INSTITUTION> UNIVERSITE DE MONTREAL (CANADA); 0992 </INSTITUTION>
<DESCRIPTORS> ENGINEERING, ELECTRONICS AND ELECTRICAL; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> DANIEL CREVIER </ADVISER>
<CLASSIFICATIONS> FRENCH TEXT </CLASSIFICATIONS>
<ABSTRACT>
Ce projet constituait la premiere etape d'un effort de
recherche a plus long terme visant a effectuer du
traitement d'image a l'aide de l'architecture cognitive
Soar, initialement developpee a l'universite Carnegie
Mellon comme outil de recherche en intelligence
artificielle. Cette premiere experience consistait a
utiliser Soar pour apprendre a un systeme de vision a
reconnai tre des caracteres imprimes. L'algorithme
utilise pour l'apprentissage est appele "acquisition
incrementale de concepts symboliques" et a ete developpe
par Craig Miller de l'universite du Michigan dans le
cadre de sa these de doctorat.
Le systeme que nous avons developpe permet a l'usager de
specifier, en premier lieu, l'image et la lettre dont il
desire faire l'apprentissage ou l'identification. Notre
programme effectue alors les operations necessaires
pour, soit creer des regles d'identification, soit
prendre une decision quant a la nature de la lettre
concernee.
L'essai le plus complet a ete fait en utilisant trois
images de l'alphabet, soit deux pour l'apprentissage, et
la troisieme pour les tests d'identification. Seize des
vingt-six lettres ont ete identifiees avec succes,
quatre ont ete mal identifiees et six lettres n'ont pu
etre identifiees. Des contraintes de temps nous ont
force a arreter la les experiences, mais nous croyons
qu'avec un ensemble d'apprentissage plus complet, les
performances pourraient etre ameliorees de facon
significative.
Nous avons pu constater que l'algorithme d'apprentissage
comportait une certaine sensibilite au niveau de la
fiabilite des criteres les plus determinants, c'est-a-
dire a pouvoir de discrimination eleve.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  2367 </NUMBER>
<ORDER>   AAIMM96957 </ORDER>
<TITLE> AN INVESTIGATION OF THE EFFECTIVENESS OF MULTIMEDIA IN EXPERT SYSTEMS </TITLE>
<AUTHOR> ALLEN, TRACY LYNN </AUTHOR>
<YEAR> 1994 </YEAR>
<INSTITUTION> THE UNIVERSITY OF NEW BRUNSWICK (CANADA); 0823 </INSTITUTION>
<DESCRIPTORS> COMPUTER SCIENCE; INFORMATION SCIENCE; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> JANE FRITZ </ADVISER>
<CLASSIFICATIONS> NIL </CLASSIFICATIONS>
<ABSTRACT>
Computerized expert systems have emerged as a powerful
means of representing expert knowledge so that it is
more accessible to a greater number of people.
Multimedia technology is mentioned in many contexts as a
means for improving the presentation of information.
This thesis combines these two technologies with the
intent of establishing some guidelines for creating a
more effective expert system through the use of
multimedia techniques. A prototype system has been
developed and evaluated so that the author might gain an
understanding of the complexities involved in this
combination. A discussion of these issues provides some
guidance to those who would implement a multimedia
expert system. The evaluation of the prototype system
showed that, in the right circumstances, multimedia
interfaces can greatly improve the quality information
presentation in expert systems.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  2368 </NUMBER>
<ORDER>   AAIMM96103 </ORDER>
<TITLE> A SCHEMA FOR CONSTRAINT RELAXATION WITH INSTANTIATIONS FOR PARTIAL CONSTRAINT SATISFACTION AND SCHEDULE OPTIMIZATION </TITLE>
<AUTHOR> BECK, JOHN CHRISTOPHER </AUTHOR>
<YEAR> 1994 </YEAR>
<INSTITUTION> UNIVERSITY OF TORONTO (CANADA); 0779 </INSTITUTION>
<DESCRIPTORS> COMPUTER SCIENCE; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> MARK S. FOX </ADVISER>
<CLASSIFICATIONS> NIL </CLASSIFICATIONS>
<ABSTRACT>
We investigate constraint relaxation within a general
constraint model. We claim that a key to relaxation is
recognition that a constraint can be modified in a
variety of ways and that each modification potentially
carries a different impact for both the quality of the
solution and the problem solving process. Our primary
motivation is the application of constraint relaxation
as a technique for coordination of multiple agents in a
shared environment.
We propose a schema for constraint relaxation that is
based on the propagation of information through a
constraint graph. The schema isolates five heuristic
decision points where techniques of varying complexities
can be specified. Three algorithms within the schema are
declared and shown to perform well on Partial Constraint
Satisfaction Problems (PCSPs). Three additional
algorithms are defined and used in the estimation of the
impact of scheduling decisions in a medium size job shop
scheduling problems. Difficulties with the calculation
of actual impact data prevents comparison among the
algorithms. The algorithms represent an advance by
allowing propagation over all types of constraints and
the ability to integrate heuristic decision making.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  2369 </NUMBER>
<ORDER>   AAI9535398 </ORDER>
<TITLE> MULTILAYER NEURAL NETWORK VISION MODEL FOR PATTERN RECOGNITION AND STEREO VISION </TITLE>
<AUTHOR> LEE, YUN-PARN THOMAS </AUTHOR>
<YEAR> 1994 </YEAR>
<INSTITUTION> UNIVERSITY OF CALIFORNIA, SAN DIEGO; 0033 </INSTITUTION>
<DESCRIPTORS> ENGINEERING, ELECTRONICS AND ELECTRICAL; BIOLOGY, NEUROSCIENCE; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> CLARK C. GUEST </ADVISER>
<CLASSIFICATIONS> IMAGE RECOGNITION </CLASSIFICATIONS>
<ABSTRACT>
Vision research has long been an interesting area to
biologists, neural network researchers, and design
engineers. However, even with currently available
technology, it is difficult to find algorithms that are
powerful enough to solve real world problems. This is
true even in a simple unsupervised image recognition
task. The merging of implementation issues and recently
developed neural vision theory provides the foundation
to overcome this problem. This dissertation makes three
contributions toward this goal.
Image classes of grayscale objects have been induced
through unsupervised Hebbian learning using the
Neocognitron neural network model. An analogy is shown
between unsupervised Hebbian learning and principal
component feature extraction when applied to the
Neocognitron modal.
A binocular interaction neural network model which
extends from the Neocognitron neural network model is
presented. This neural network model is different from
the feature based matching algorithm and Markov random
field theory approach on stereo vision.
The design of a novel implementation of the Neocognitron
neural network is presented. Issues involved with
optoelectronic implemented and digital implementation
are discussed. Dramatic increases in real-time
recognition performance on this optoelectronic hybrid
visual hardware can be expected.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  2370 </NUMBER>
<ORDER>   AAI9533112 </ORDER>
<TITLE> IMPROVED CLUSTERING AND CLASSIFICATION ALGORITHMS FOR THE KOHONEN SELF-ORGANIZING NEURAL NETWORK </TITLE>
<AUTHOR> NOUR, MOHAMED ABDALLA </AUTHOR>
<YEAR> 1994 </YEAR>
<INSTITUTION> KENT STATE UNIVERSITY; 0101 </INSTITUTION>
<DESCRIPTORS> COMPUTER SCIENCE; ARTIFICIAL INTELLIGENCE; BUSINESS ADMINISTRATION, MANAGEMENT </DESCRIPTORS>
<ADVISER> GREGORY R. MADEY </ADVISER>
<CLASSIFICATIONS> NIL </CLASSIFICATIONS>
<ABSTRACT>
The Kohonen Self-Organizing Neural Network possesses
remarkable properties such as computational simplicity,
use of unsupervised learning, and applicability to a
broad class of problems. Coupled with these advantages,
however, are some serious limitations that handicap its
learning algorithm from achieving superior performance,
especially with regard to pattern clustering and
classification. Some of these limitations are: (1) slow
convergence, (2) computational inefficiencies, and (3)
suboptimal results.
There have been extensive studies over the last decade
to address these limitations by extending the Kohonen
self-organizing learning algorithm using heuristic and
optimization approaches. Unfortunately, the extent of
improvements resulting from these research efforts have
been relatively insignificant, while most of the
extensions are not applicable to pattern clustering and
classification, an interesting area in many business
applications.
This study develops several extensions to the standard
Kohonen self-organizing algorithm. We first critically
analyze previous extension efforts with a view of
delineating opportunities for performance improvements.
Two improved versions of the standard Kohonen learning
algorithm are then proposed, tested, and compared with
the standard version. Both modified versions are based
on a new network architecture that serves as a point of
departure from the standard Kohonen self-organizing
model. These algorithms are naturally suited to
applications in pattern clustering and classification.
In all the computer simulations using several test data
sets, the modified versions have shown superior
performance to the standard version. We have also tested
the three algorithms on two financial applications,
corporate bond rating and bankruptcy prediction, and
compared their performance results with those from
conventional statistical methods, namely regression
analysis and discriminant analysis. Our computer
simulations have indicated comparable classification
performances from the neural network algorithms and the
two statistical methods.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  2371 </NUMBER>
<ORDER>   AAI9531121 </ORDER>
<TITLE> FUZZY ADAPTIVE RECURRENT COUNTERPROPAGATION NEURAL NETWORKS:  A NEURAL NETWORK ARCHITECTURE FOR QUALITATIVE MODELING AND REAL-TIME SIMULATION OF DYNAMIC PROCESSES </TITLE>
<AUTHOR> PAN, YADUNG </AUTHOR>
<YEAR> 1994 </YEAR>
<INSTITUTION> THE UNIVERSITY OF ARIZONA; 0009 </INSTITUTION>
<DESCRIPTORS> ENGINEERING, ELECTRONICS AND ELECTRICAL; ENGINEERING, INDUSTRIAL; ENGINEERING, SYSTEM SCIENCE; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> FRANCOIS E. CELLIER </ADVISER>
<CLASSIFICATIONS> NIL </CLASSIFICATIONS>
<ABSTRACT>
In this dissertation, a new artificial neural network
(ANN) architecture called fuzzy adaptive recurrent
counterpropagation neural network (FARCNN) is presented.
FARCNNs can be directly synthesized from a set of
training data, making system behavioral learning
extremely fast. FARCNNs can be applied directly and
effectively to model both static and dynamic system
behavior based on observed input/output behavioral
patterns alone without need of knowing anything about
the internal structure of the system under study.
The FARCNN architecture is derived from the methodology
of fuzzy inductive reasoning and a basic form of
counterpropagation neural networks (CNNs) for efficient
implementation of finite state machines. Analog signals
are converted to fuzzy signals by use of a new type of
fuzzy A/D converter, thereby keeping the size of the
Kohonen layer of the CNN manageably small. Fuzzy
inferencing is accomplished by an application-
independent feedforward network trained by means of
backpropagation. Global feedback is used to represent
full system dynamics.
The FARCNN architecture combines the advantages of the
quantitative approach (neural network) with that of the
qualitative approach (fuzzy logic) as an efficient
autonomous system modeling methodology. It also makes
the simulation of mixed quantitative and qualitative
models more feasible.
In simulation experiments, we shall show that FARCNNs
can be applied directly and easily to different types of
systems, including static continuous nonlinear systems,
discrete sequential systems, and as part of large
dynamic continuous nonlinear control systems, embedding
the FARCNN into much larger industry-sized quantitative
models, even permitting a feedback structure to be
placed around the FARCNN.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  2372 </NUMBER>
<ORDER>   AAI9529435 </ORDER>
<TITLE> BELIEF NETWORK INDUCTION </TITLE>
<AUTHOR> MUSICK, CHARLES RONALD, JR. </AUTHOR>
<YEAR> 1994 </YEAR>
<INSTITUTION> UNIVERSITY OF CALIFORNIA, BERKELEY; 0028 </INSTITUTION>
<DESCRIPTORS> COMPUTER SCIENCE; STATISTICS; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> STUART J. RUSSELL </ADVISER>
<CLASSIFICATIONS> DATABASE MINING </CLASSIFICATIONS>
<ABSTRACT>
This dissertation describes BNI (Belief Network
Inductor), a tool that automatically induces a belief
network from a database. The fundamental thrust of this
research program has been to provide a theoretically
sound method of inducing a model from data, and
performing inference over that model. Along with a solid
grounding in probability theory, BNI has proven to be a
quick, practical method of inducing data models that are
highly accurate. The results include a belief network
that stores beta distributions in the conditional
probability tables, coupled with theorems demonstrating
how to maintain these distributions through inference;
techniques for applying neural network and other
learning techniques to the task of conditional
probability table learning; and a decision theoretic
sampling theory which addresses scalability issues by
characterizing the size of the sample needed to produce
high quality inferences.
The setting for this work is in database mining.
Database mining is one of the fastest growing topics in
Artificial Intelligence today, with industry providing
at least as much impetus as research labs and
universities. The general goal is to extract interesting
quantities or relationships that are "hidden" in large
corporate or scientific databases, with the potential
benefits of a successful technology being enormous. For
example, models can be built that characterize what
types of customers will respond to what types of
marketing schemes, retailers will be able to predict
sales to help determine correct inventory levels and
distribution schedules, and insurance companies will be
able to predict expected claim costs and better classify
who will buy what type of coverage.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  2373 </NUMBER>
<ORDER>   AAGNN11433 </ORDER>
<TITLE> A COGNITIVE MAP MODEL FOR GEOGRAPHIC INFORMATION SYSTEMS </TITLE>
<AUTHOR> ZHOU, XIAOYOU </AUTHOR>
<YEAR> 1994 </YEAR>
<INSTITUTION> UNIVERSITY OF ALBERTA (CANADA); 0351 </INSTITUTION>
<DESCRIPTORS> COMPUTER SCIENCE; GEODESY </DESCRIPTORS>
<ADVISER> WAYNE A. DAVIS </ADVISER>
<CLASSIFICATIONS> GIS </CLASSIFICATIONS>
<ABSTRACT>
This thesis is concerned with the problem of storage,
manipulation and retrieval of geographic data. The
objective of this research is to introduce a cognitive
map model for the representation of spatial data in
geographic information systems (GISs). The salient
feature of the proposed model is such that it is a
result of the integration of three areas: database
management systems, artificial intelligence, and
statistics. In this thesis, methods for knowledge
representation, data management, uncertainty handling
that traditionally belong to separate areas are applied
in a complementary manner to enhance the capabilities of
a GIS. This feature provides the proposed model with
significant advancements in GIS technology in three
areas: (1) the model provides a more expressive language
for modeling various geographic concepts, including
shape, location, place, complex objects, object
interrelationships, topological relationships and metric
relationships; (2) the model supports the searching of
complex geographic data according to both attribute-
based and location-based criteria in a flexible and
effective manner; (3) the model also serves as an
integrated approach to spatial data modeling that
effectively handles data errors.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  2374 </NUMBER>
<ORDER>   AAI9529414 </ORDER>
<TITLE> RATIONAL SEARCH </TITLE>
<AUTHOR> MAYER, ANDREW ERIC </AUTHOR>
<YEAR> 1994 </YEAR>
<INSTITUTION> UNIVERSITY OF CALIFORNIA, BERKELEY; 0028 </INSTITUTION>
<DESCRIPTORS> COMPUTER SCIENCE; STATISTICS; OPERATIONS RESEARCH; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> STUART J. RUSSELL </ADVISER>
<CLASSIFICATIONS> BAYESIAN PROBLEM SOLVER </CLASSIFICATIONS>
<ABSTRACT>
In this dissertation, I have described a Bayesian
Problem-Solver (BPS) that emulates the characteristics
of ideal rational agents, and have evaluated a straw-man
BPS implementation for state-space search. I view this
work as an early step toward the development of a
computational decision theory: a practical grounding of
principles of decision theory within existing
computational models.
Specifically, I present a simple framework for rational
search using probability as a knowledge representation
language, and utility as an action selection criterion.
I describe an ideal "Gold Standard" algorithm for
computing expected utility, illustrating that
approximations are necessary for efficiency. I then
design BPS as a family of approximation algorithms,
whose performance I compare to that of control
algorithms. In detailed experiments, BPS is shown to be
accurate in its inferences, and accurate in predictions
of its own performance.
One goal of research in search algorithms is to make
sure that good search components are available for use
by practitioners. BPS satisfies many of the requirements
for an agent-like, rational search component. First, BPS
is instructible, using declarative preferences (utility)
and beliefs (probability). Second, BPS accurately
predicts its own performance, a precondition for the
design of effective selective search mechanisms. And
finally, BPS exhibits promising performance on the Eight
Puzzle, a classic testbed problem, although constant
factors in its time complexity suggest that it will be
most profitably applied to larger, more highly-leveraged
problems.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  2375 </NUMBER>
<ORDER>   AAI9529387 </ORDER>
<TITLE> AN APPLICATION OF UNSUPERVISED NEURAL NETWORKS AND FUZZY CLUSTERING IN THE IDENTIFICATION OF STRUCTURE IN PERSONALITY DATA </TITLE>
<AUTHOR> LAUDEMAN, IRENE VINCIE </AUTHOR>
<YEAR> 1994 </YEAR>
<INSTITUTION> UNIVERSITY OF CALIFORNIA, BERKELEY; 0028 </INSTITUTION>
<DESCRIPTORS> PSYCHOLOGY, PERSONALITY; PSYCHOLOGY, PSYCHOMETRICS; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> OLIVER P. JOHN </ADVISER>
<CLASSIFICATIONS> NIL </CLASSIFICATIONS>
<ABSTRACT>
Questions related to the number and definition of broad
personality types have long been debated in the
personality literature. The present research applied new
methods to these old questions and tested the utility of
these methods in three large samples with a combined
sample size of over 3,000. Thus, replicability and
generalizability were emphasized throughout this study,
so as to move work on personality typologies from the
theoretical realm to a level that admits to stringent
empirical tests.
The method developed in this study addressed typological
issues raised in previous work, especially the reliable
identification of the number of distinct types, the
definition of type membership in nondiscrete, "fuzzy"
terms, and the identification of nonlinear patterns in
the data. The method borrowed heavily from techniques
developed in the discipline of pattern recognition and
used Big Five scale scores as input variables. The input
variables were analyzed with both neural network and
fuzzy clustering implementations of the c-means
clustering algorithm.
The method was used to derive a personality typology
consisting of five broad person types which were
identified in six data sets that were collected from
three populations and used two personality inventories.
The five cluster structure was identified by repeated
neural network analyses of the six data sets. The
cluster centers or mean personality profiles for each of
the five clusters or personality types were found using
fuzzy clustering analyses. Additionally, a fuzzy
membership value was computed for each case in each of
the five clusters. Each case was then assigned to the
cluster in which it had the highest membership value.
Of the five personality types identified in this study,
three were similar to personality types reported in
previous work. The identification of the two previously
undetected personality types was attributed to the
application of a method that used Big Five scales as
input variables, reliably identified an optimal number
of clusters and represented the nonlinear patterns in
the data.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  2376 </NUMBER>
<ORDER>   AAI9529344 </ORDER>
<TITLE> FUZZY LOGIC CONTROL WITH ADAPTIVE METHODS FOR VEHICLE LATERAL GUIDANCE  </TITLE>
<AUTHOR> HESSBURG, THOMAS MICHAEL </AUTHOR>
<YEAR> 1994 </YEAR>
<INSTITUTION> UNIVERSITY OF CALIFORNIA, BERKELEY; 0028 </INSTITUTION>
<DESCRIPTORS> ENGINEERING, MECHANICAL; ENGINEERING, AUTOMOTIVE; ENGINEERING, ELECTRONICS AND ELECTRICAL; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> MASAYOSHI TOMIZUKA </ADVISER>
<CLASSIFICATIONS> MOTION </CLASSIFICATIONS>
<ABSTRACT>
In this dissertation lateral motion control of a vehicle
is investigated in the framework of an automated highway
system (AHS). The objective of lateral motion control
for lane following is to achieve accurate tracking of a
reference lane while maintaining an acceptable level of
passenger comfort in the presence of disturbances and
over a range of operating conditions. The proposed
controllers, based on fuzzy logic control (FLC) theory,
are developed based on implicit models of the vehicle
dynamics as opposed to explicit mathematical models
required by many conventional control design techniques.
The structure of the proposed FLC is modularized into
feedback, preview, and gain scheduling rule bases. In
the initial control design the parameters of the FLC are
tuned manually using information from characteristics of
human driving operation and an existing controller.
Three feedback FLCs with different feedback variables
are designed. A fuzzy preview rule base is developed to
utilize preview information regarding the upcoming radii
of curvature. Also, a gain scheduling rule base is
designed to choose the appropriate controller based on
the velocity of the vehicle and the traction conditions
between the road and the vehicle tires.
In order to achieve an acceptable level of performance,
methods are considered to investigate the automatic
tuning of the FLC parameters. The first method uses
genetic algorithms (GA) and the second approach uses a
novel idea to adjust the FLC parameters on-line to
follow a reference closed-loop model, modeled by a fuzzy
system. In the ladder method, using Lyapunov theory, a
supervisory control term is introduced to ensure that
the closed-loop system under fuzzy logic control will
maintain stability in the sense that the states of the
vehicle are bounded by a specified maximum value.
Experimental test results of the manually tuned FLCs are
shown, and a comparison is made to similar tests
conducted using a frequency shaped linear quadratic
(FSLQ) controller as well as a proportional, integral,
plus derivative (PID) controller.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  2377 </NUMBER>
<ORDER>   AAI9529255 </ORDER>
<TITLE> A QUALITATIVE MODELING FRAMEWORK OF SEMICONDUCTOR MANUFACTURING PROCESSES: SELF-LEARNING FUZZY INFERENCE SYSTEM AND THE STATISTICAL ANALYSIS OF CATEGORICAL DATA </TITLE>
<AUTHOR> CHEN, RAYMOND LEI </AUTHOR>
<YEAR> 1994 </YEAR>
<INSTITUTION> UNIVERSITY OF CALIFORNIA, BERKELEY; 0028 </INSTITUTION>
<DESCRIPTORS> ENGINEERING, ELECTRONICS AND ELECTRICAL; STATISTICS; COMPUTER SCIENCE; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> COSTAS J. SPANOS </ADVISER>
<CLASSIFICATIONS> NIL </CLASSIFICATIONS>
<ABSTRACT>
Many qualitative properties of the product and the
process are of interest during semi-conductor
manufacturing. Typical examples are the sidewall surface
roughness of a poly-silicon etching line and the average
grain size for a polysilicon deposition film. These
properties are important since they affect directly the
quality and performance of the integrated circuit (IC)
devices being built. Traditionally, however, they are
treated informally and subjectively as tacit knowledge
in the processing arena.
A systematic approach to modeling, simulating and
controlling such qualitative properties is presented in
this work. This approach is based on the statistical
analysis of categorical data, and on fuzzy logic theory.
The results show significant promise for incorporating
qualitative and quantitative features of a process in a
computer-integrated manufacturing environment.
Our approach is based on the viewpoint that qualitative
process variables are categorical data and can thus be
better understood with the help of logistic regression
analysis. This analysis reveals important relationships
between the input process settings and the qualitative
process output responses, in a way that is similar to
linear regression analysis for conventional numerical
variables. Similarly, categorical process variables can
be used for process control, which is driven by a
probabilistic model of the categorical variables.
The modeling framework proposed in this work is further
built on a self-learning inference system based on fuzzy
logic theory. According to this methodology, both the
input and output variables (numerical or categorical)
are "fuzzified" into linguistic variables, which take
several discrete values associated with membership
functions. The linguistic values of the input and output
variables are mapped through a fuzzy inference process
which is implemented as a series of fuzzy set
operations. The resulting linguistic values obtained
from such inference operations can be "defuzzified" into
numerical or categorical values.
Such a fuzzy inference system can be designed and
created by training data obtained either from human
expert knowledge, or automatically extracted from hard
data from statistically designed experiments. After the
establishment of the initial inference system, the
membership functions can be tuned adaptively to
accommodate process changes.
In applying such a qualitative modeling framework,
engineers can extract, store, update, and transfer their
qualitative understanding and experience about a process
along with the quantitative knowledge. Hence, in
addition to the conventional statistical, empirical or
physical modeling of the processing technology, the
qualitative inference systems proposed in this work are
also useful in formal process modeling, simulation, and
control.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  2378 </NUMBER>
<ORDER>   AAI9529250 </ORDER>
<TITLE> THE PARAMETERIZATION OF A FUZZY INFERENCE SYSTEM AND ITS APPLICATION TO CONTROL </TITLE>
<AUTHOR> CHANG, PING-WEI </AUTHOR>
<YEAR> 1994 </YEAR>
<INSTITUTION> UNIVERSITY OF CALIFORNIA, BERKELEY; 0028 </INSTITUTION>
<DESCRIPTORS> ENGINEERING, MECHANICAL; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> MASAYOSHI TOMIZUKA </ADVISER>
<CLASSIFICATIONS> POSSIBILITY DISTRIBUTION </CLASSIFICATIONS>
<ABSTRACT>
Fuzzy Logic Control (FLC) may be viewed as a knowledge-
based control strategy that is cast in the form of a
rule base consisting of inference propositions. This
heuristic approach to control design produces a control
law that appears drastically different from the
conventional framework of control design, which takes
the form of analytical formulation. In order to provide
a tool for analyzing the heuristic control design, we
develop a methodology for transforming the fuzzy
inference process, which is the core of a fuzzy logic
control system, into an equivalent mapping between the
antecedent universe and the consequence universe of the
rule base.
Differing from the standard method found in many
applications of fuzzy logic control, our methodology for
processing fuzzy inference is based on examining
optimally synthesized possibility distributions. As a
result, we discover a way of quickly zooming in on the
optimal consequence of the possibility distribution
yielded by collective fuzzy implication. Using this
methodology as a general framework of the fuzzy
inference system, we develop a numerical scheme to help
us design a parameterized mapping that optimally
represents the inference process.
In transforming a fuzzy inference process to a
functional mapping, we obtain a useful tool for modeling
nonlinear control strategies. Based on our empirical
knowledge of the physical system of interest, we can
sometimes lay out effective strategies for every
localized region of the system's operating range. The
framework of the fuzzy rule base offers a natural tool
for us to quantify such knowledge. The improved
analytical property of the equivalent functional mapping
enables us to easily analyze or modify the fuzzy
inference system with the aid of conventional techniques
of control design.
In order to test the control strategy thus derived, we
apply our methodology to control the upswing and
balancing of an inverted pendulum. We demonstrate how we
transform a fuzzy rule base specifically designed for
the control of the pendulum upswing into an equivalent
functional mapping, and how this equivalently
transformed mapping is modified to improve the overall
system response.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  2379 </NUMBER>
<ORDER>   AAI9529026 </ORDER>
<TITLE> MRI SEGMENTATION AND THE QUANTIFICATION OF WHITE MATTER LESIONS  </TITLE>
<AUTHOR> ZIJDENBOS, ALEXANDER PETER </AUTHOR>
<YEAR> 1994 </YEAR>
<INSTITUTION> VANDERBILT UNIVERSITY; 0242 </INSTITUTION>
<DESCRIPTORS> ENGINEERING, ELECTRONICS AND ELECTRICAL; ENGINEERING, BIOMEDICAL; HEALTH SCIENCES, MEDICINE AND SURGERY; HEALTH SCIENCES, RADIOLOGY; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> BENOIT M. DAWANT </ADVISER>
<CLASSIFICATIONS> NEURAL NETWORKS </CLASSIFICATIONS>
<ABSTRACT>
Magnetic Resonance Imaging (MRI) has rapidly become one
of the most important diagnostic tools available to
clinicians. This popularity is mainly due to the facts
that MRI has no known side-effects, that it is non-
invasive, and that it has a very high resolving power
for soft tissues. As such, it is extremely valuable for
in-vivo studies of the human brain. An additional
advantage of MRI is its multispectral character, which
makes it possible to generate images of the same
physical space with different spectral signatures.
The interpretation of MRI data is currently done in a
predominantly visual and qualitative fashion. However,
the increasing amount of data generated by modern MR
scanners and the clinical demand for accurate,
reproducible, and quantitative data analysis promote the
development of computer-aided techniques. An artificial
neural network based image analysis system has been
developed and tested, focused on the quantification of
so-called white matter lesions in the human brain. Early
in the course of this research it became clear that
spatial intensity variations, often present in MRI data,
hamper the use of classical pattern recognition
techniques. Several methods for the correction of this
artifact and studies showing the reliability of the
proposed segmentation technique are presented.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  2380 </NUMBER>
<ORDER>   AAI9527954 </ORDER>
<TITLE> DESIGN AND SIMULATION OF DIGITAL OPTICAL COMPUTING SYSTEMS FOR ARTIFICIAL INTELLIGENCE </TITLE>
<AUTHOR> NA, JONGWHOA </AUTHOR>
<YEAR> 1994 </YEAR>
<INSTITUTION> THE UNIVERSITY OF ARIZONA; 0009 </INSTITUTION>
<DESCRIPTORS> ENGINEERING, ELECTRONICS AND ELECTRICAL; ARTIFICIAL INTELLIGENCE; COMPUTER SCIENCE </DESCRIPTORS>
<ADVISER> AHMED LOURI </ADVISER>
<CLASSIFICATIONS> RULE BASED SYSTEM, EXPERT SYSTEMS </CLASSIFICATIONS>
<ABSTRACT>
Rule-based systems (RBSs) are one of the problem solving
methodologies in artificial intelligence. Although RBSs
have a vast potential in many application areas the slow
execution speed of current RBSs has prohibited them from
the full exploitation of their vast potential.
In this dissertation, to improve the speed of RBSs, we
explore the use of optics for the fast and parallel RBS
architectures. First, we propose an electro-optical rule-
based system (EORBS). Using two-dimensional knowledge
representation and a monotonic reasoning scheme, EORBS
provides highly efficient implementation of the basic
operations needed in rule-based systems, namely,
matching, selection, and rule firing. The execution
speed of the proposed system is theoretically estimated
and is shown to be two orders of magnitude faster than
the current electronic systems. Although EORBS shows the
best performance in execution speed compared to other
RBSs, the monotonic reasoning scheme restricts the
application domains of EORBS.
In order to overcome this limitation on the application
domain in EORBS, a general purpose RBS, called an
Optical Content-Addressable Parallel Processor for
Expert Systems (OCAPP-ES) is proposed. Using a general
knowledge representation scheme and a parallel conflict
resolution scheme, OCAPP-ES executes the three basic RBS
operations on general knowledge (including variables,
symbols, and numbers) in a highly parallel fashion. The
performance of OCAPP-ES is theoretically estimated and
is shown to be an order of magnitude slower than that of
EORBS. However, the performance of OCAPP-ES is still an
order of magnitude faster than any other RBS.
Furthermore, OCAPP-ES is designed to support the general
knowledge representation scheme so that it can be a high
speed general purpose RBS.
To verify the proposed architectures, we developed a
modeling and simulation methodology for digital optical
computing systems. The methodology predicts maximum
performance of a given optical computing architecture
and evaluates its feasibility. As an application
example, we apply this methodology to evaluate the
feasibility and performance of OCAPP which is the
optical match unit of OCAPP-ES. The proposed methodology
is intended to reduce optical computing systems' design
time as well as the design risk associated with building
a prototype system.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  2381 </NUMBER>
<ORDER>   AAI9528135 </ORDER>
<TITLE> A CRITIC BASED SYSTEM FOR NEURAL GUIDANCE AND CONTROL </TITLE>
<AUTHOR> DALTON, JEFFREY STEPHEN </AUTHOR>
<YEAR> 1994 </YEAR>
<INSTITUTION> UNIVERSITY OF MISSOURI - ROLLA; 0135 </INSTITUTION>
<DESCRIPTORS> ENGINEERING, ELECTRONICS AND ELECTRICAL; ENGINEERING, AEROSPACE; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> J. J. BOURQUIN; S. N. BALAKRISHNAN </ADVISER>
<CLASSIFICATIONS> NEURAL NETWORKS, FEEDBACK </CLASSIFICATIONS>
<ABSTRACT>
Intelligent control is a topic which has been
extensively studied for nearly five decades. Recent
efforts include reinforcement learning approaches which
use a controller to provide control actions to the plant
and a critic which observes control actions and plant
states and evaluates performance of the controller. The
evaluation signal is then used to modify controller
actions so that performance of the closed loop system
optimizes a given performance index. Neural networks
have been incorporated into intelligent control systems.
This research proposes a new method for the design of a
feedback control composed of two neural networks. A
controller network provides control actions based on
state feedback, and a critic network observes plant
states and control actions to provide an additive
component to the plant input. The design technique
relies on the use of ideas from neighboring optimal
control. The advantages to this type of design are the
realization of a high speed parallel architecture for
feedback control, robust operation with respect to
additive measurement and actuator noise, ability to
handle variable sampling rates and stable control for
nonlinear and time-varying plants. The design technique
is demonstrated with four applications including
nonlinear and time-varying optimal regulation and
tracking and a two-dimensional linear optimal missile
guidance problem.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  2382 </NUMBER>
<ORDER>   AAI9526654 </ORDER>
<TITLE> USING MACHINE LEARNING TO DERIVE EFFICIENT COST AND PERFORMANCE ESTIMATES IN VLSI CAD DESIGNS </TITLE>
<AUTHOR> GELOSH, DONALD S. </AUTHOR>
<YEAR> 1994 </YEAR>
<INSTITUTION> UNIVERSITY OF PITTSBURGH; 0178 </INSTITUTION>
<DESCRIPTORS> ENGINEERING, ELECTRONICS AND ELECTRICAL; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> DOROTHY E. SETLIFF </ADVISER>
<CLASSIFICATIONS> NIL </CLASSIFICATIONS>
<ABSTRACT>
Area and delay estimates facilitate effective decision-
making ability in high level synthesis. Current
estimation techniques focus on modeling the layout
result and fail to deliver timely or accurate estimates.
This thesis presents a novel approach to deriving these
area and delay estimates by modeling the actions and
activities of the layout tool, rather than the layout
result. This approach uses machine learning techniques
to analyze the input-to-output relationships that result
from applying the target layout tool to an input design
description and producing a layout as an output. This
thesis describes a solution architecture using these
machine learning techniques that captures the
relationships between general design features (e.g.,
topology, connectivity, common input, and common output)
and layout concepts (e.g., relative placement). This
solution architecture has the following characteristics.
First, a set of several training designs captures the
general design features. The target layout tool is run
on the training designs and produces a set of actual
layouts. The general design features and relative
placement concepts from the actual layouts make up a
training set. The formulation of this training set is
important to adequately describe the set of general
design features and the associated layout concepts.
Second, a machine learning system analyzes the training
set looking for relationships between the design
features and layout concepts. This analysis produces a
model of the operation of the layout tool. This model is
in the form of a set of production rules. Third, this
model is applied to real designs to formulate area and
delay estimates. This approach is found to produce
accurate area and delay estimates very quickly, even for
designs with several thousand gates. Experimentation
illustrates the identification of the general design
features, the relative placement concepts, the
formulation of the training set, the derivation of the
tool model, and the application of this model to real
world designs. In addition, two different layout tools
were modeled to show the generality of this approach.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  2383 </NUMBER>
<ORDER>   AAI9526386 </ORDER>
<TITLE> AN INTELLIGENT CONTROL SYSTEM FOR RESISTANCE SPOT WELDING USING FUZZY LOGIC AND NEURAL NETWORK </TITLE>
<AUTHOR> JOU, MIN </AUTHOR>
<YEAR> 1994 </YEAR>
<INSTITUTION> RENSSELAER POLYTECHNIC INSTITUTE; 0185 </INSTITUTION>
<DESCRIPTORS> ENGINEERING, MECHANICAL; ENGINEERING, MATERIALS SCIENCE; ARTIFICIAL INTELLIGENCE; ENGINEERING, INDUSTRIAL </DESCRIPTORS>
<ADVISER> ROBERT W. MESSLER, JR.; WARREN R. DEVRIES </ADVISER>
<CLASSIFICATIONS> TUNING </CLASSIFICATIONS>
<ABSTRACT>
Resistance spot welding is subject to numerous
predictable and unpredictable variables within and
between welding cycles. These can arise from: material
types, composition and thickness tolerances, and surface
finishes and cleanliness, joint geometry, fit-up and
weld spacing and current-shunting; electrode deformation
and wear, and fluctuations in machine cooling water flow
rate and temperature or welding and forging pressure;
and fluctuations in primary (line) voltage and current.
Any or all of these complicate automation, reduce weld
quality, demand overwelding (i.e., production of more
welds than are structurally needed, if each was
perfect), and drive up production costs. For this
reason, ensuring weld quality through on-line, real-time
process control has been and remains a major challenge
and goal.
The objective of this research is to develop an
intelligent control system to ensure weld quality for
the resistance spot welding process. The chosen system
consists of a neural network to generate electrode
displacement and velocity as a function of welding time
and a fuzzy logic controller to execute control commands
based on deviations from ideal behavior caused by
process variations or errors. This approach was taken to
preclude the need for a precise model of the complex
physics involved in the process as well as to circumvent
the need for experimentally generated curves of
electrode displacement for each and every material joint
combination.
In this project, electrode displacement was used as the
signal to indicate weld quality as affected by the
growth of the weld nugget in real time. A series of
experiments were conducted to explore how changes of a
key controllable parameter (i.e., % heat input or power)
affect a measurable signal (i.e., electrode
displacement) for various sheet steels used in the
automotive industry. An artificial neural network has
been developed to generate the relationship between %
heat input and electrode displacement. A fuzzy logic
control system based on this neural network has also
been developed. The output from the fuzzy logic
controller (FLC) is the control action which is then
used to control the power delivered into the weld.
Computer simulation results show that a fuzzy logic
control system can tolerate and compensate for in-
process uncertainties and make an acceptable joint. With
this FLC, the common practice in RSW to overdesign the
total number of welds needed to obtain desired strength
of joints can be eliminated, with attendant cost
savings. Automation of the process in a typical
production environment is also advanced by precluding
the need for a precise model of the physics of the
process, by employing fuzzy logic rules instead. The
need for costly and time-consuming experiments to
generate a curve of electrode displacement versus
welding time is circumvented by using a trained neural
network. Together, a neural network and fuzzy logic
represent a new approach for achieving control of the
complex process of resistance spot welding in automated
assembly environments typified by the automobile
industry that could represent an important new control
strategy for such complex processes.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  2384 </NUMBER>
<ORDER>   AAGNN10343 </ORDER>
<TITLE> THE IMPACT OF ARTIFICIAL INTELLIGENCE TECHNOLOGIES ON INDUSTRIAL RESTRUCTURING IN THE UNITED STATES </TITLE>
<AUTHOR> ZUBRZYCKI, JACK ADAM </AUTHOR>
<YEAR> 1994 </YEAR>
<INSTITUTION> YORK UNIVERSITY (CANADA); 0267 </INSTITUTION>
<DESCRIPTORS> POLITICAL SCIENCE, GENERAL; INFORMATION SCIENCE; ARTIFICIAL INTELLIGENCE; BUSINESS ADMINISTRATION, GENERAL </DESCRIPTORS>
<ADVISER> H. MICHAEL STEVENSON </ADVISER>
<CLASSIFICATIONS> NIL </CLASSIFICATIONS>
<ABSTRACT>
Technological change has always had great appeal as an
important component in resolving problem in accumulation
in capitalist economies. In the current conjuncture,
these problems seem more severe and widespread, and
societies are groping for new terms of resolution. The
current period is comparable to the turn of this
century, when Fordism emerged as a resolution, not least
because of the emergence of a potential technological
basis of restructuring today.
Current problems of accumulation extend beyond questions
of productivity, profitability, or competition. Using
the Regulation School approach, I argue that the fit
between regimes of accumulation and modes of regulation
has collapsed, and this rupture calls into question
patterns of social organization. Artificial Intelligence
(AI) technologies are comparable to Fordist technologies
in their promise to restructure relations at a variety
of levels. AI is conceived of as a transformative
technology, addressing the variety of problems within
regimes of accumulation, and containing nascent
structural forms that suggest new, unusual patterns of
corporatist organization.
The efficacy of AI as the basis of resolution, however,
is complicated by three sets of problems. First, the
internal coherence of AI as a technology is
questionable, as its ambitious quest to automate
thinking is not easily made operational. Second, as a
technological system, AI may be appropriated by social
forces as solutions to problems within regimes of
accumulation, and its transformative capacities may be
undermined by its appeal in resolving specific problems
in accumulation. The disparate coalition of industries
and sectors for whom AI is attractive are unlikely to be
able to overcome their competitive spatialities without
the development of new structural forms or a corporatist
state.
Third, AI contains a shaky political coalition of
proponents, and states have been unwilling or unable to
forge the political support or leadership necessary to
effect changes to modes of regulation. The experience of
Japan shows the most sophisticated social innovation in
conjunction with AI, while the US gropes for an
industrial policy while patterning AI development via
the military. The UK and EC are, for different reasons,
least able to effect a new fit between an AI-based
regime of accumulation and new modes of regulation. To
the extent that new versions of corporatism are evident,
they rely on changes to regimes of accumulation and
modes of regulation that exclude labor, and on the
enchantment of AI as the vehicle to redesign firms,
economies, or social organization.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  2385 </NUMBER>
<ORDER>   AAI9526369 </ORDER>
<TITLE> JOINT SOLUTION OF LOW, INTERMEDIATE AND HIGH-LEVEL VISION TASKS BY GLOBAL OPTIMIZATION: APPLICATION TO COMPUTER VISION AT LOW SIGNAL-TO-NOISE RATIO </TITLE>
<AUTHOR> BHATTACHARJYA, ANOOP KUMAR </AUTHOR>
<YEAR> 1994 </YEAR>
<INSTITUTION> RENSSELAER POLYTECHNIC INSTITUTE; 0185 </INSTITUTION>
<DESCRIPTORS> COMPUTER SCIENCE; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> BADRINATH ROYSAMM </ADVISER>
<CLASSIFICATIONS> EVOLUTIONARY PROGRAMMING </CLASSIFICATIONS>
<ABSTRACT>
In this thesis, methods for conducting model-based
computer vision from low-SNR ($sim$1 dB) image data are
presented. Conventional algorithms break down in this
regime due to a cascading of noise artifacts, and
inconsistencies arising from the lack of optimal
interaction between high and low-level processing. These
problems are addressed by solving low-level problems
such as intensity estimation, segmentation, and boundary
estimation jointly (synergistically) with intermediate-
level problems such as the estimation of position,
magnification, and orientation, and high-level problems
such as object identification and scene interpretation.
This is achieved by formulating a single objective
function that incorporates all the data and object
models, and a hierarchy of stochastic and symbolic
constraints in a Bayesian framework. All image-
processing operations, including those that exploit the
low and high-level variables to satisfy multi-level
pattern constraints, result directly from a parallel
multi-trajectory global optimization algorithm. This
algorithm combines evolutionary search with continuous-
domain optimization via stochastic diffusions. Template-
fitting algorithms derived from high-level object and
scene constraints are also incorporated in the search
algorithm. The overall optimization strategy induces a
class of parallel packet-switched vision architectures
that are scalable and fault-tolerant.
Experiments with 3-D confocal microscopy images, objects
imaged with a CCD camera under poor illumination, and
simulated low-count (7-10 photons/pixel) 2-D Poisson
images demonstrate that compared to non-joint methods, a
joint solution not only results in more reliable scene
interpretation, but also a superior estimation of low-
level image variables. Typically, most object parameters
are estimated to within a 5% accuracy even with overlap
and partial occlusion. These results were computed on a
DAP-510 mesh-connected processor array, a custom Intel
i860-based multiprocessor, and a distributed environment
consisting of loosely-coupled heterogeneous
workstations.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  2386 </NUMBER>
<ORDER>   AAI9526248 </ORDER>
<TITLE> CONVOLUTION NEURAL NETWORK ARCHITECTURE WITH APPLICATION FOR LUNG NODULE DETECTION IN DIGITAL CHEST RADIOGRAPHY </TITLE>
<AUTHOR> LIN, JYH-SHYAN </AUTHOR>
<YEAR> 1994 </YEAR>
<INSTITUTION> UNIVERSITY OF MARYLAND COLLEGE PARK; 0117 </INSTITUTION>
<DESCRIPTORS> ENGINEERING, ELECTRONICS AND ELECTRICAL; ENGINEERING, BIOMEDICAL; COMPUTER SCIENCE; ARTIFICIAL INTELLIGENCE; HEALTH SCIENCES, RADIOLOGY </DESCRIPTORS>
<ADVISER> PANOS A. LIGOMENIDES </ADVISER>
<CLASSIFICATIONS> COMPUTER-AIDED DIAGNOSIS </CLASSIFICATIONS>
<ABSTRACT>
The principal objective of the research reported herein
is the development of a hybrid, neural-digital,
processing system for detection and classification of
objects found in noisy and cluttered 2-D image
environments. We have developed such a neural-digital
computer-aided diagnosis system (N.CADx), based on a
parameterized two-level convolution neural network (CNN)
architecture, and on a special multi-label output
encoding procedure. The developed N.CADx architecture
was trained, tested, and evaluated specifically on the
problem of early diagnosis of lung cancer nodules (3 mm
to 15 mm in diameter) found in digitized chest
radiographs. The system performs automatic "suspect"
localization, feature extraction, and diagnosis of a
particular pattern-class aimed at a high degree of "true-
positive fraction" detection and low "false-positive
fraction" detection. Digital image processing techniques
are used for noise reduction, image enhancement, and
"suspect" search and localization. In the first level
CNN, the neural classification concerns feature
extraction and diagnosis of a particular pattern-class
aimed at a high degree of "true-positive fraction"
detection. The second level CNN is trained specifically
on separating the greatly similar "false" patterns,
which provide a "gray" diagnostic value. Applying fuzzy
linguistic concepts to the nodule diagnosis problem, we
have developed a multi-label output encoding procedure
for neural training and for interpretation of the
activity distributions in the five output neurons. The
activity distributions of the output neurons are
interpreted by the centroid as the "normalized disease
index" (NDI), or as a probability value associated with
a "confidence level" factor. The performance of the
developed N.CADx architecture is proven superior to
other methodologies that have been reported in the
literature up to this date, and to be extensible,
problem-independent, and therefore more applicable to
other medical and industrial problems of difficult
diagnostic tasks in 2-D image environments.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  2387 </NUMBER>
<ORDER>   AAI9526246 </ORDER>
<TITLE> THE ADAPTIVE TIME-DELAY NEURAL NETWORK: CHARACTERIZATION AND APPLICATIONS TO PATTERN RECOGNITION, PREDICTION AND SIGNAL PROCESSING </TITLE>
<AUTHOR> LIN, DAW-TUNG </AUTHOR>
<YEAR> 1994 </YEAR>
<INSTITUTION> UNIVERSITY OF MARYLAND COLLEGE PARK; 0117 </INSTITUTION>
<DESCRIPTORS> ENGINEERING, ELECTRONICS AND ELECTRICAL; COMPUTER SCIENCE; BIOLOGY, NEUROSCIENCE; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> PANOS A. LIGOMENIDES </ADVISER>
<CLASSIFICATIONS> FORECASTING </CLASSIFICATIONS>
<ABSTRACT>
Dynamic analysis of temporally changing signals is a key
issue in real-time signal processing and understanding.
Such changing signals may arise from moving objects in
visual images, spoken words, target trajectories,
medical recording and other kinds of sensor data in a
wide variety of applications. Neural network
architectures with dynamic and temporal capabilities are
promising for signal analysis. In this dissertation, we
describe a solution to temporal problems with a flexible
architecture: the Adaptive Time-Delay Neural Network
(ATNN). A rich repertoire of capabilities of the ATNN
are characterized in this thesis. A series of novel
applications are implemented that for the first time
show the capabilities and promise of the ATNN network
architecture on classes of engineering problems.
Inspired by the time delays that occur in
neurobiological signal transmissions, the dynamic
properties of this network are formulated on-line
through the adaptation of its internal parameters based
on gradient descent rules according to the evolution of
observed inputs and outputs. An arbitrary number of
interconnections with different time delays are placed
between any two processing units, and time delays are
adapted, unconstrained with respect to one another. Thus
the network automatically attempts to optimize its
configuration, which overcomes limitations of previous
works.
We have proposed a network analysis tool, the Network
Unfolding Algorithm (NUA), and with complexity analysis
of the algorithm, demonstrated that the ATNN reduces the
cost of network complexity at least by a factor of O(n)
compared to a standard Backpropagation network. We apply
the theorems of Funahashi, Hornik et al and Stone-
Weierstrass to state the general function approximation
ability of the ATNN. We have evaluated the behavior of
internal hidden units over a series of applications.
The ATNN is capable of spatiotemporal trajectory
learning, trajectory generation, and pattern completion
with different topologies, different training arcs,
various data sampling rates, and any number of
dimensions. Relationships have been discovered between
the complexity of the topology and the number of hidden
units, between pattern generation abilities and
different training arcs and data sampling rates. It is
shown that the ATNN is resilient to perturbations in the
data, and is capable of recovering a spatiotemporal
signal from noisy data. With a special recurrent
configuration, the ATNN has the ability to learn closed
trajectories. These trajectories become trained
attractors of the dynamic network.
The ATNN is applied to chaotic time series prediction,
and we demonstrate that this complicated prediction
problem can be accomplished by a simple ATNN
architecture. Furthermore, the ATNN can detect the
embedded dynamics. A real world problem of
distinguishing multiple type components of exo-
atmospheric targets is demonstrated by applying the
ATNN. The ATNN performs highly complex mapping on a
limited set of training data and achieves better
generalization to overall trends of situations. Its
performance outstrips that of related neural networks.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  2388 </NUMBER>
<ORDER>   AAI9526210 </ORDER>
<TITLE> HEURISTIC SEARCH WITH LIMITED RESOURCES </TITLE>
<AUTHOR> GHOSH, SUBRATA KUMAR </AUTHOR>
<YEAR> 1994 </YEAR>
<INSTITUTION> UNIVERSITY OF MARYLAND COLLEGE PARK; 0117 </INSTITUTION>
<DESCRIPTORS> COMPUTER SCIENCE </DESCRIPTORS>
<ADVISER> DANA S. NAU; AMBUJ MAHANTI </ADVISER>
<CLASSIFICATIONS> ITERATIVE THRESHOLD </CLASSIFICATIONS>
<ABSTRACT>
Heuristic Search is a fundamental problem solving method
with applications in many areas of artificial
intelligence and operations research. A variety of
heuristic search algorithms have been developed with
various computational tradeoffs. For example, the
IDA$sp*$ algorithm overcomes the exponential memory
requirement of A$sp*$, but at the expense of doing more
node generations. This thesis investigates two kinds of
tradeoffs in heuristic search: (1) space versus time for
admissible search algorithms, and (2) space and time
versus solution quality for inadmissible search
algorithms. The main results are summarized below.
In general, no limited-memory best-first admissible
search algorithm can do the same number of node
generations as best-first search algorithm like A$sp*$,
even in the asymptotic sense. However, for a restricted
class of trees, it is possible to guarantee asymptotic
optimality. Analysis of IDA$sp*$ on acyclic graphs shows
that IDA$sp*$ can perform exponentially worse than
A$sp*$ on graphs. This thesis also presents a new
limited-memory admissible tree search algorithm called
Iterative Threshold Search (ITS). ITS improves IDA$sp*$
as follows: (1) unlike IDA$sp*$ it can use any amount of
memory given to it as input, and (2) it dominates
IDA$sp*$, i.e., given the same amount of memory, ITS
never expands more nodes than IDA$sp*$ and there are
trees on which it expands far fewer nodes.
ITS is a space-efficient search algorithm. However, like
IDA$sp*$, it is an admissible algorithm and therefore
does not scale up to large problems. For large problems
and for real time search, this thesis presents two
unidirectional algorithms, namely Breadth-Depth-A$sp*$
(BDA$sp*$) and Controlled-A$sp*$ (CA$sp*$), and a
bidirectional algorithm called Bidirectional Heuristic
Front-to-Front Stage Search (BHFFSS). These algorithms
trade solution quality for exponential time.
Experimental results on the 15-puzzle and 24-puzzle
problems and the 3-machine scheduling problem show that
these algorithms are useful for finding near-optimal
solutions quickly. Finally, the thesis presents a new
search technique called Block Depth-First Search (BDFS).
BDFS can be used both for finding near-optimal solutions
as well as for finding optimal solutions. BDFS starts
with a near-optimal solution in linear time and then
improves its solution until it converges to the optimal
solution.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  2389 </NUMBER>
<ORDER>   AAI9526187 </ORDER>
<TITLE> A VLSI APPROACH TO A NEURAL NET TOMOGRAPHIC IMAGING ALGORITHM </TITLE>
<AUTHOR> CHANG, STEVEN </AUTHOR>
<YEAR> 1994 </YEAR>
<INSTITUTION> UNIVERSITY OF MARYLAND COLLEGE PARK; 0117 </INSTITUTION>
<DESCRIPTORS> ENGINEERING, ELECTRONICS AND ELECTRICAL; COMPUTER SCIENCE; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> MARTIN PECKERAR </ADVISER>
<CLASSIFICATIONS> NIL </CLASSIFICATIONS>
<ABSTRACT>
A technique is presented for solving under determined
systems of linear equations. The unique aspect of this
technique is the incorporation of the algorithm in a
neural net co-processor that will solve "ill-posed"
problems in real time. This co-processor incorporates
informational entropy as a regularizer in the
optimization problem. As such, the network can
accommodate nonlinear constraints. The powerful aspects
of this co-processor is demonstrated using the
tomographic image reconstruction problem.
The tomographic reconstruction problem may be ill-posed
for two reasons: (a) limited data are available, (b)
significant portions of the scene may be obscured from
the probing beam. In absence of all the data necessary,
maximum entropy is used as the regularizer to find the
most noncommittal (i.e., the most random) solution in
light of available system constraints. The existing
numerical approaches using the maximum entropy approach
are computationally intensive, and do not achieve real
time solutions. The neural net circuit architecture was
designed for VLSI-CMOS implementation. The neural net
integrated circuit performs the inverse Radon
transformation using a cost function gradient descent
method.
The neural net algorithm has been modeled in the
programming language "C" to emulate an ideal neural net
circuit. Simulations using 10 pixel x 10 pixel, 25 pixel
x 25 pixel, and 100 pixel x 100 pixel resolution were
performed to test the accuracy of the reconstructed
images using this algorithm. Images such as boxes,
straight lines were reproduced very well. Images with a
higher entropy also reproduced the images well enough to
be recognized.
There are two circuit approaches that are used to
implement this algorithm, an analog approach and a
digital approach. For the digital approach, full
parallel, completely serial and a combination of serial
and parallel are presented. An analog 10 pixel x 10
pixel array was constructed in 2 $mu$m CMOS technology.
Convergence time of the array was less than 5 $mu$s.
Although convergence is very quick, process concerns
make this approach less attractive for large arrays. The
digital design was modeled in "C". The same result is
expected from a full digital integrated circuit
implementation. The parameters that may change with
process are the frequency of operation, power
dissipation and basic circuit layout.
The best approach for implementing this algorithm for
large array sizes is a serial/parallel digital approach.
This technique leads to algorithm convergence within the
microseconds range for a 10 pixel x 10 pixel array.
There are many applications that this co-processor can
be used for other than computed tomography. One such
application is in image data compression. The image (N
pixel x N pixel) is stored as K2N projection data, where
K is the number of angles needed to reconstruct the
image. The amount of data compression is $Nsp2over0K2N$
and with real-time reconstruction, the cost of using
this approach is negligible to the user. (Abstract
shortened by UMI.)
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  2390 </NUMBER>
<ORDER>   AAI9525580 </ORDER>
<TITLE> A COMPUTATIONAL FRAMEWORK FOR ADAPTIVE READING IN DOCUMENT IMAGE UNDERSTANDING </TITLE>
<AUTHOR> LAM, STEPHEN WAI-KEUNG </AUTHOR>
<YEAR> 1994 </YEAR>
<INSTITUTION> STATE UNIVERSITY OF NEW YORK AT BUFFALO; 0656 </INSTITUTION>
<DESCRIPTORS> COMPUTER SCIENCE; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> SARGUR N. SRIHARI </ADVISER>
<CLASSIFICATIONS> DOMAIN KNOWLEDGE </CLASSIFICATIONS>
<ABSTRACT>
The task that a reading machine performs is generally
known as document image understanding (DIU). DIU refers
to extracting relevant information from the digital
image of a printed document and converting it into
editable symbolic form. It locates regions of interest
on the document and derives a logical interpretation for
the document layout and content. At present, most of the
reading machines in use are custom designed to process
some specific types of documents such as bank checks,
tax forms, postal mailpieces, etc., but they are limited
solely to their assigned tasks and cannot be adapted
easily between different documents. However, human
reading is an adaptive process which is capable of
switching to read different documents easily. This is
because human reading is guided by the reader's
knowledge and intention of reading. This dissertation is
inspired by the facts about the processes of human
reading and the current state of the art in DIU. It
proposes a computational framework for adaptive reading
in DIU. The framework is able to (i) process many
different types of document, (ii) classify documents
automatically, and (iii) utilize knowledge about
documents to guide document image processing activities.
The framework consists of three major components: (i) a
knowledge base containing both general and specific
document knowledge, (ii) a set of image processing tools
specialized for document image analysis, and (iii) a
control mechanism utilizing knowledge to direct tools
both in object location and recognition. Based on this
architecture, adaptive DIU becomes a constraint
satisfaction problem, i.e., using image processing tools
to extract data from raster images to satisfy
constraints defined in the knowledge base. The framework
has neither a predefined document-image-processing
strategy nor a specific level of content interpretation.
Both will be determined by the knowledge about the
documents of interest, i.e., the domain knowledge.
In order to validate the framework capability, a system
has been implemented by following the framework
guidelines. A test set containing four different printed
document domains (postal mailpieces, forms, bills, and
journals) is used to demonstrate the adaptability of the
system. Experimental results have shown the adaptability
of the system.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  2391 </NUMBER>
<ORDER>   AAI9525311 </ORDER>
<TITLE> A CONSTRUCTIVE APPROACH TO HYBRID ARCHITECTURES FOR MACHINE LEARNING  </TITLE>
<AUTHOR> FLETCHER, JUSTIN BARROWS SWORE </AUTHOR>
<YEAR> 1994 </YEAR>
<INSTITUTION> WASHINGTON STATE UNIVERSITY; 0251 </INSTITUTION>
<DESCRIPTORS> COMPUTER SCIENCE; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> ZORAN OBRADOVIC </ADVISER>
<CLASSIFICATIONS> NEURAL NETWORKS, EXPERT SYSTEMS, PARALLEL LEARNING </CLASSIFICATIONS>
<ABSTRACT>
Classification systems in artificial intelligence are
primarily based on the concepts of knowledge extraction
from sample data (machine learning) and of representing
existing human knowledge in machine-interpretable form
(expert systems). Current neural network approaches
provide for machine learning, but require significant
human interaction in the design of the neural
architecture. If the architecture is too small, it is
unable to learn the problem. If it is too large, the
architecture may overfit the sample data resulting in
poor generalization. A constructive neural network
algorithm builds a problem-specific architecture as well
as learning the problem at hand. Here, a new
constructive parallel learning algorithm is proposed.
The algorithm consists of three phases: search through
examples for points near the decision boundary;
generation of a pool of candidate hyperplanes for
boundary approximation; and selection of the separating
hyperplanes from the candidate pool. The form of the
final architecture is specified by the cardinality of
the selected set of hyperplanes, where each individual
hyperplane determines connection strengths for one
hidden unit of the constructed network. The pre-existing
knowledge contained in an expert system may be
integrated into a hybrid architecture by directly
embedding the expert system into the neural network.
With a hybrid architecture, a better initial hypothesis
may be formed from which hidden units may be
constructively added by learning from examples to
efficiently extend the initial architecture. A hybrid
system is obtained in which pre-existing knowledge is
complemented by the knowledge obtained from the sample
data.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  2392 </NUMBER>
<ORDER>   AAI9524829 </ORDER>
<TITLE> ARTIFICIAL NEURAL-NETWORK-BASED FEATURE RECOGNITION AND GRAMMAR-BASED FEATURE EXTRACTION TO INTEGRATE DESIGN AND MANUFACTURING </TITLE>
<AUTHOR> CHAN, CHU-CHAI HENRY </AUTHOR>
<YEAR> 1994 </YEAR>
<INSTITUTION> THE UNIVERSITY OF IOWA; 0096 </INSTITUTION>
<DESCRIPTORS> ENGINEERING, INDUSTRIAL; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> GARY W. FISHCER </ADVISER>
<CLASSIFICATIONS> NIL </CLASSIFICATIONS>
<ABSTRACT>
For a concurrent engineering environment to be
effective, two critical steps are needed. The first step
is to share information among the various engineering
activities. The second step is to understand the meaning
of the shared information. This research focuses on the
interpretation and extraction of feature information
contained in the CAD representation of a part. Automatic
feature recognition can help understand the meaning of
features, one type of concurrent engineering
information, and is an essential linkage between CAD and
CAM.
A big problem for automatic feature recognition is that
the increasing number of recognized features causes the
process of recognition to be very complicated. The
neural network technology is proposed to avoid these
problems. Neural networks can recognize features very
quickly and the trained features can be interpreted
directly from the geometric information instead of
relying on expert-defined rules.
To avoid the learning training problems associated with
many neural networks, this research presents a fast
learning algorithm called CMAC. The research also
demonstrates other advantages of using neural networks,
such as the recognition of partial features or compound
features.
The major advantage of a neural network is that it can
classify features quickly and robustly. On the other
hand, a grammar-based system is capable of extracting
information accurately. This research proposes an
approach that combines the advantages of both methods,
namely, rapid classification of features and creation of
a useful feature-based data format for downstream
applications. The output of the proposed approach is an
implicit form for a classified feature. The compact form
of the output makes it easy to use in an application
context.
The feature recognizer described in the research also
has learning capability. The feature recognizer allows
changes to a geometric model to classify and extract new
features. In order to provide learning capability, a
framework is developed to memorize the geometry
information of a new feature, then classify the feature
and define rules for its extraction.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  2393 </NUMBER>
<ORDER>   AAI9524534 </ORDER>
<TITLE> ARTIFICIAL NEURAL NETWORK-BASED CONTINGENCY RANKING AND SECURITY-CONSTRAINED OPTIMAL DISPATCH </TITLE>
<AUTHOR> GHOSH, SOUMEN </AUTHOR>
<YEAR> 1994 </YEAR>
<INSTITUTION> UNIVERSITY OF WYOMING; 0264 </INSTITUTION>
<DESCRIPTORS> ENGINEERING, ELECTRONICS AND ELECTRICAL; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> NIL </ADVISER>
<CLASSIFICATIONS> POWER, BACKPROPAGATION TRAINING </CLASSIFICATIONS>
<ABSTRACT>
In this dissertation work, Artificial Neural Networks
have been applied to the problem of Static Security
Enhancement of Power System. Static Security Enhancement
essentially addresses the problem of ranking the
potential contingent elements and providing preventive
strategies based on security-constrained dispatch.
Two three-layered perceptron networks have been used in
the ranking of Line Flow contingency and Bus Voltage
contingency. The training parameters for the two
networks are chosen by the methods based on a regression-
based correlation technique. Four new indices, two
Severity Indices and two Margin Indices have been
defined for ranking purposes. The Severity Indices
perform better than the classical Performance Indices
(PI) in the training of the networks.
This new approach has been tested on the IEEE 118-bus
test system. The contingency ranking obtained in the
proposed method is comparable with the ranking provided
by the Performance Index method. The proposed method is
faster than the method based on the PI method. Once the
proper training of the networks has been achieved, the
new rankings are almost instantaneous while testing the
trained networks.
A new method based on Hopfield Neural Network is also
proposed for solving Security-Constrained Optimal
Dispatch. The Hopfield network is used for the solution
of the constrained optimization problem. The main idea
behind solving the optimization problem is to formulate
an appropriate computational energy function E(X) so
that the lowest energy state would correspond to the
required solution of X. The proposed method is based on
transformation of the energy function minimization
problem into a set of differential equations. The method
is used in the active and reactive security-constrained
dispatch problems with illustrations on four test
systems a 6-bus system, the IEEE 14-bus test system, the
IEEE 24-bus reliability test system and the IEEE 118-bus
test system. Results obtained in the proposed method are
comparable with the results obtained in the method based
on dual-linear programming formulation.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  2394 </NUMBER>
<ORDER>   AAGC516397 </ORDER>
<TITLE> CONTROLE CATASTROPHIQUE D'UN SYSTEME A BASE DE CONNAISANCES: CONCEPTION, MODELISATION ET APPLICATION AU DIAGNOSTIC DES DEFAULTS DES FROMAGES; CONTROL OF KNOWLEDGE BASE WITH CATASTROPHE THEORY: CONCEPTION, MODELLING AND APPLICATION TO DIAGNOSIS OF FLAWS IN CHEESE </TITLE>
<AUTHOR> SABATIER, PHILIPPE </AUTHOR>
<YEAR> 1994 </YEAR>
<INSTITUTION> INSTITUT NATIONAL DES SCIENCES APPLIQUEES DE LYON (FRANCE); 5285 </INSTITUTION>
<DESCRIPTORS> ENGINEERING, INDUSTRIAL; AGRICULTURE, FOOD SCIENCE AND TECHNOLOGY; ARTIFICIAL INTELLIGENCE AVENUE ALBERT EINSTEIN, F-69621  VILLEURBANNE CEDEX, FRANCE </DESCRIPTORS>
<ADVISER> NIL </ADVISER>
<CLASSIFICATIONS> NIL </CLASSIFICATIONS>
<ABSTRACT>
L'Intelligence Artificielle s'interesse a la mise en
oeuvre de systemes symboliques formels, dont les
representations doivent se comporter comme des
connaissances humaines. Le developpement de l'I.A. dans
le domaine du diagnostic de troubles sanitaires pose le
probleme du controle--i.e. de la coherence--des bases de
connaissances. L'objet de ce travail est de degager les
elements d'une methodologie du controle fonde sur
l'apport de la Theorie des Catastrophes (TC). Nous
partons de l'etude des delicats problemes conceptuels,
et mathematiques que pose la modelisation des phenomenes
biologiques. Nous montrons ensuite que la TC, est
susceptible de fournir un modele adequat pour la
comprehension des defauts des fromages. Plus que la
modelisation d'un domaine, nous cherchons a etablir la
pertinence d'une methode et l'interet de la constitution
d'un niveau intermediaire (ici microbiologique) entre la
perception des formes (ici organoleptique) et
l'organisation de la matiere (ici biochimique). Ce
niveau correspond a une representation interne de la
realite physique, et permet d'interpreter le divers
phenomenologique. Nous montrons que la TC ouvre la
possibilite d'une veritable schematisation des
descriptions, compris langageres, des objets naturels.
Elle s'appuie sur la mise en evidence de facteurs
d'invariance phenomenologique. Cet apport est decisif
pour ameliorer le controle des systemes a base de
connaissances, et particulierement des outils dlaide au
diagnostic, pour lesquels se pose un probleme
d'interpretation.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  2395 </NUMBER>
<ORDER>   AAI9520783 </ORDER>
<TITLE> DESIGN OF AUTOMOTIVE JOINTS: USING OPTIMIZATION TO TRANSLATE PERFORMANCE CRITERIA TO PHYSICAL DESIGN PARAMETERS  </TITLE>
<AUTHOR> ZHU, MIN </AUTHOR>
<YEAR> 1994 </YEAR>
<INSTITUTION> VIRGINIA POLYTECHNIC INSTITUTE AND STATE UNIVERSITY; 0247 </INSTITUTION>
<DESCRIPTORS> APPLIED MECHANICS; ARTIFICIAL INTELLIGENCE; ENGINEERING, AUTOMOTIVE </DESCRIPTORS>
<ADVISER> E. NIKOLAIDIS </ADVISER>
<CLASSIFICATIONS> FINITE ELEMENT, NEURAL NETWORK </CLASSIFICATIONS>
<ABSTRACT>
In the preliminary design stage of a car body, targets
are first set on the performance characteristics of the
overall body and its components using optimization and
engineering judgment. Then designers try to design the
components to meet the determined performance targets
and keep the weight low using empirical, trial-and-error
procedures. This process usually yields poor results
because it is difficult to find a good design that
satisfies the targets using trial-and-error and there
might even be no feasible design that meets the targets.
To improve the current design process, we need tools to
link the performance targets and the physical design
parameters.
A methodology is presented for developing two such tools
for design guidance of joints in car bodies. The first
tool predicts the performance characteristics of a given
joint fast (at a fraction of a second). The second finds
a joint design that meets given performance targets and
satisfies packaging and manufacturing constraints. These
tools can be viewed as translators that translate the
design parameters defining the geometry of a joint into
performance characteristics of that joint and vice-
versa.
The methodology for developing the first translator
involves parameterization of a joint, identification of
packaging, manufacturing and styling constraints, and
establishment of a neural network and a response surface
polynomial to predict the performance of a given joint
fast (at a fraction of a second). The neural network is
trained using results from finite element analysis of
several joint designs. The second translator is an
optimizer that finds the joint with the smallest mass
that meets given performance targets and satisfies
packaging, manufacturing and styling constraints.
The methodology is demonstrated on a joint of an actual
car.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  2396 </NUMBER>
<ORDER>   AAI9517027 </ORDER>
<TITLE> GROUNDING EXPLANATIONS IN EVOLVING, DIAGNOSTIC SITUATIONS  </TITLE>
<AUTHOR> JOHANNESEN, LEILA JULIA </AUTHOR>
<YEAR> 1994 </YEAR>
<INSTITUTION> THE OHIO STATE UNIVERSITY; 0168 </INSTITUTION>
<DESCRIPTORS> ENGINEERING, INDUSTRIAL; COMPUTER SCIENCE; PSYCHOLOGY, GENERAL; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> DAVID D. WOODS </ADVISER>
<CLASSIFICATIONS> FAULT MANAGEMENT </CLASSIFICATIONS>
<ABSTRACT>
This research was motivated by the desire to further
understanding on how artificial intelligence (AI)
systems may effectively support practitioners engaged in
fault management in dynamic situations. Standard
approaches to diagnostic assistance in which
retrospective explanations are provided are not well
suited to the demands of dynamic fault management. Such
explanations occur as interruptions in the flow of work
and result in data overload. A field study of human
practitioners in one dynamic fault management
application (anesthesiologists during neurosurgical
operations) was undertaken in order to gain insight into
effective diagnostic support among team members. The
conceptual framework that guided the field study drew
from research on cooperation in communication, and
particularly on work from conversation analysis on the
"common ground" maintained during coordinative activity.
The findings indicate that team members assist one
another in maintaining accurate interpretations of the
process by helping one another keep track of influences
on the process. Two ways they do this are by providing
unprompted reports of their relevant activities on the
process and by providing informative responses that go
beyond answering explicitly posed questions. Episodes of
management and diagnosis show that causal explanations
among team members are better described as joint
interpretations (in which both team members are involved
in the process of attaining a mutual interpretation),
rather than as retrospective explanations given from one
team member to another. Explanations of assessments and
activities that are found are typically brief and in the
flow of activity.
The general implications for the design of intelligent
systems intended to support practitioners in dynamic
fault management are that such systems should not be
"dark boards" concerning their activities and
assessments. But, because they lack many of the
sophisticated capabilities displayed in human
communication, intelligent system design must avoid
distracting in an effort to maintain the common ground.
Instead, the focus should be on providing intelligent
system assessments and information about activities in
the context of (i.e., relative) to events in the dynamic
process.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  2397 </NUMBER>
<ORDER>   AAI0576002 </ORDER>
<TITLE> DUAL-MODE DYNAMICS NEURAL NETWORKS FOR COMBINATORIAL OPTIMIZATION </TITLE>
<AUTHOR> PARK, JUN </AUTHOR>
<YEAR> 1994 </YEAR>
<INSTITUTION> UNIVERSITY OF SOUTHERN CALIFORNIA; 0208 </INSTITUTION>
<DESCRIPTORS> ENGINEERING, ELECTRONICS AND ELECTRICAL; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> SUKHAN LEE </ADVISER>
<CLASSIFICATIONS> NIL </CLASSIFICATIONS>
<ABSTRACT>
This thesis presents a new approach to solving
combinatorial optimization problems based on a novel
dynamic neural network featuring a dual-mode of network
dynamics, the state dynamics and the weight dynamics.
The network is referred to here as the dual-mode
dynamics neural network (D2NN).
The combinatorial optimization problem usually has a
huge number of elements in its configuration space, so
that we cannot explore them exhaustively. Recently, the
neural network approaches have been studied for the
solution of the combinatorial optimization problem. The
computational characteristic of neural network--the
distributed and collective computation over a massively
parallel architecture, emulating nonlinear dynamics--has
invoked high expectation to overcome the curse of
combinatorial search complexity in optimization. Several
effective approaches have been applied to various
combinatorial optimization problems, and have shown that
the preliminary results are promising.
There are two major difficulties, however, in the neural
network approaches to optimization problems. First, the
objective function for a given problem must have the
form that can be mapped onto the network, and secondly,
due to the local minima problem, the quality of the
solution is quite sensitive to various factors, such as
the initial state and the parameters in the objective
function. The proposed scheme overcomes these
difficulties (1) by maintaining the objective function
separately from the network energy function, rather than
mapping it onto the network, and (2) by introducing a
weight dynamics utilizing the objective function to
avoid the local minima problem. The state dynamics
defines state trajectories in a direction to minimize
the network energy specified by the current weights and
states, whereas the weight dynamics generates weight
trajectories in a direction to minimize a preassigned
external objective function at a current state. D2NN is
operated in such a way that the two modes of network
dynamics alternately govern the network until an
equilibrium is reached.
The D2NN has been applied to N-Queen problem, the
knapsack problem, and the traveling salesman problem and
indicates the superior performance. (Copies available
exclusively from Micrographics Department, Doheny
Library, USC, Los Angeles, CA 90089-0182.)
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  2398 </NUMBER>
<ORDER>   AAI0575977 </ORDER>
<TITLE> MARKER PROPAGATION NETWORKS: A PRACTICAL PARALLEL PROCESSING APPROACH </TITLE>
<AUTHOR> LIN, CHANGHWA </AUTHOR>
<YEAR> 1994 </YEAR>
<INSTITUTION> UNIVERSITY OF SOUTHERN CALIFORNIA; 0208 </INSTITUTION>
<DESCRIPTORS> ENGINEERING, ELECTRONICS AND ELECTRICAL </DESCRIPTORS>
<ADVISER> DAN MOLDOVAN </ADVISER>
<CLASSIFICATIONS> NIL </CLASSIFICATIONS>
<ABSTRACT>
The marker propagation is developed for an artificial
intelligence application with a semantic networks
knowledge base. It is a promising parallel approach for
many artificial intelligence applications. However,
marker propagation models have not yet been widely
accepted due to their ill-defined parallel processing
model and sequential machine implementations.
The goal of this research is to develop a parallel
marker propagation model from a practical parallel
processing perspective. The approach begins with an
analysis of parallelism in operations required for a
marker propagation program. Based on the analysis,
develop a parallel marker propagation model, namely
marker propagation networks. We study the major factors
that affect the performance of the marker propagation
networks, and propose the practical solutions. A
parallel processor prototype is implemented based on the
requirements for the marker propagation networks. The
proposed solutions are built into the prototype to prove
their correctness. We also implemented a set of
programming tools, including performance data gathering
tools and a parallel program debugger, to make the
prototype a complete marker propagation networks
application development system.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  2399 </NUMBER>
<ORDER>   AAINN95806 </ORDER>
<TITLE> THE PROPERTY SET MODEL FOR KNOWLEDGE REPRESENTATION IN INDUCTIVE LEARNING </TITLE>
<AUTHOR> HADJIMICHAEL, MICHAEL </AUTHOR>
<YEAR> 1994 </YEAR>
<INSTITUTION> THE UNIVERSITY OF REGINA (CANADA); 0148 </INSTITUTION>
<DESCRIPTORS> COMPUTER SCIENCE </DESCRIPTORS>
<ADVISER> S. K. M. WONG </ADVISER>
<CLASSIFICATIONS> NIL </CLASSIFICATIONS>
<ABSTRACT>
Knowledge representation is an issue crucial to the
study of artificial intelligence, particularly in the
area of machine learning. Inductive learning systems
which create decision rules or decision trees typically
represent their input information using an attribute-
value table model. The nature of such traditional
representational models is such that observed events
must be drawn from a common domain, and represented by a
uniform set of attribute values, with no expression of
uncertainty. These requirements severely limit the
domain of representable events available for inductive
learning. This dissertation will present a knowledge
representation model, the Property Set (PS) model,
different in two important ways from the attribute-value
table; first, by allowing many arbitrary properties to
be associated with each event, and second, by
generalizing represented events to be elementary
concepts, which are the smallest describable units
available, either simple objects, or concept
descriptions. An added benefit of this representation is
a technique for quantifying the generalization performed
by an inductive learning system. A generalization, the
Fuzzy Property Set (FPS) model, further improves on
traditional models by allowing for the expression of
"degree" in the representation, providing for a natural
means of dealing with uncertainty, including unknown
values. Inductive learning algorithms, based on the PS
model, and the FPS model, are presented. These
algorithms learn concepts from input events by building
concept descriptions in a bottom-up fashion from the
smallest descriptive units available. The learned
descriptions are useful for crisply classifying unknown
objects, or for ranking unknown objects on a continuous
scale.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  2400 </NUMBER>
<ORDER>   AAI9528436 </ORDER>
<TITLE> HEURISTICS TO SUPPORT CONSTRAINT-BASED MODEL FORMULATION AND ANALYSIS </TITLE>
<AUTHOR> RANGANATHAN, PADMANABHAN </AUTHOR>
<YEAR> 1994 </YEAR>
<INSTITUTION> NEW YORK UNIVERSITY, GRADUATE SCHOOL OF BUSINESS ADMINISTRATION; 0868 </INSTITUTION>
<DESCRIPTORS> BUSINESS ADMINISTRATION, GENERAL; COMPUTER SCIENCE; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> VASANT DHAR </ADVISER>
<CLASSIFICATIONS> NIL </CLASSIFICATIONS>
<ABSTRACT>
Considerable work in Artificial Intelligence has been
directed at making explicit, useful information that
might be implicit in a problem description, and on
control regimes that exploit the description. An object-
oriented representation, for example, enables us to make
inferences, by making use of relationships among classes
of objects, that might not have been explicitly
envisioned during design.
Engineers and other professionals also routinely use a
number of strategies for solving, simplifying or
reasoning about constraint-based problems problems by
deriving useful information that might be implicit in a
problem description. These strategies include (1)
identification of the "more important" variables,
constraints and preferences, (2) identification of
overconstrained or underconstrained problems and
redundant variables, (3) incremental establishment (or
removal) of bounds on the values of variables as a
problem specification is established (or removed), (4)
hierarchical problem-solving, where values are
established, first, for the more important variables,
(5) simplifying the problem description by simplifying
complicated constraints, (6) when "stuck", using a
generate and test strategy to determine values for
variables, and (7) resorting to the use of relaxation
and numerical analysis methods when analytical methods
cannot be applied.
There are, however, no theories or guidelines specifying
when such strategies should be applied in order to
derive information that a model builder or user might
find useful, or that would answer specific queries.
Rather, designers and analysts continue to write
customized programs for analyzing their designs or
models in a trial and error fashion.
The contribution of this work is two-fold. First, based
on detailed observations of the incremental formulation
and analysis of an engineering design problem, we
provide a set of heuristic rules that enable us to cover
the entire range of analyses that are involved in
domains involving linear and non-linear algebraic
constraints, logical relationships among variables, and
empirically based relationships among variables,
expressed in the form of tables. Our solution surpasses
other existing characterizations described in the
literature, which are limited in their range of
representational features, solution strategies and
control structure. We enunciate a set of rules that
identify when to apply a particular strategy to a
problem specification in order to derive useful
information or to answer specific queries. We evaluate
the effectiveness of these rules on a sample set of
problems.
The examples we use to illustrate our work come from
engineering design. However, our broader interests lie
in models and their analysis in general.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  2401 </NUMBER>
<ORDER>   AAI1361560 </ORDER>
<TITLE> USING GEOGRAPHICAL INFORMATION SYSTEMS AND NEURAL NETWORKS TO PREDICT FUEL MOISTURE IN HOMOGENEOUS FUELS </TITLE>
<AUTHOR> BALL, BARBARA JEAN </AUTHOR>
<YEAR> 1994 </YEAR>
<INSTITUTION> THE UNIVERSITY OF ARIZONA; 0009 </INSTITUTION>
<DESCRIPTORS> AGRICULTURE, FORESTRY AND WILDLIFE; BIOLOGY, ECOLOGY; COMPUTER SCIENCE; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> PHILLIP GUERTIN </ADVISER>
<CLASSIFICATIONS> NIL </CLASSIFICATIONS>
<ABSTRACT>
Computer models used to predict the pattern and rate of
spread of fire in grasslands as well as other vegetation
types rely on various inputs for their calculations.
Because of the direct effect they have on the quantity
of fuel available to carry a fire and the effects of
moisture on the potential for fuel available to carry a
fire and the effects of moisture on the potential for
fuel to begin burning and to sustain a fire, fuel
loading measurements, which are similar to production
measurements in grasslands, and estimates of fuel
moisture are two important variables to be considered
when modeling fire behavior. The objective of this
project is to determine if there is a relationship
between measured environmental variables and the fuel
moisture values at the same sample points which can be
modeled with GIS data and neural networks. This study
was carried out using a combination of field sampled
data and common GIS data layers. The results demonstrate
the potential for neural network analysis in this type
of environmental problem.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  2402 </NUMBER>
<ORDER>   AAI1361410 </ORDER>
<TITLE> ADAPTIVE FILTER CONTROL USING NEURAL NETWORKS </TITLE>
<AUTHOR> MANSFIELD, KIM </AUTHOR>
<YEAR> 1994 </YEAR>
<INSTITUTION> UTAH STATE UNIVERSITY; 0241 </INSTITUTION>
<DESCRIPTORS> COMPUTER SCIENCE; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> DONALD H. COOLEY </ADVISER>
<CLASSIFICATIONS> NIL </CLASSIFICATIONS>
<ABSTRACT>
This thesis explores the applicability of using neural
networks to control the adaption of finite impulse
response filters as applied to speakerphones. It
presents a discussion of the problems associated with
speakerphones and their solutions. This thesis proposes
to use a neural network to control the adaption of FIR
(finite impulse response) filters in the speakerphone
and examines the results of the neural network control.
In this thesis, a neural network is used to detect
receive audio more accurately than current methods. This
thesis presents the results of using the neural network
control versus the conventional method of control. By
using a neural network, adaption times of the FIR filter
decreased by 50%.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  2403 </NUMBER>
<ORDER>   AAI1361248 </ORDER>
<TITLE> NCUBRONN: A NEW FAST FEEDFORWARD NEURAL NETWORK ALGORITHM </TITLE>
<AUTHOR> WANG, GUANGRAN </AUTHOR>
<YEAR> 1994 </YEAR>
<INSTITUTION> UNIVERSITY OF NEVADA, RENO; 0139 </INSTITUTION>
<DESCRIPTORS> COMPUTER SCIENCE; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> CARL G. LOONEY </ADVISER>
<CLASSIFICATIONS> NIL </CLASSIFICATIONS>
<ABSTRACT>
Feedforward Neural Networks have proven to be useful in
the fields of classification, and have also been used as
small-scale expert systems, but they have some trade-
offs. There are two steps in the process of neural
networks: learning and operation. This thesis only
concerns the learning process. We consider two major
methods in this thesis: (1) Gradient Descent and (2)
Random Optimization.
Gradient descent has very good speed, but is not
guaranteed to find the global minimum for large-scaled
neural networks where the solutions could converge to a
local minimum, the iterated approximate values could
oscillate between two different minimum, or cycle
through a set of values. Random optimization may be used
for large-scaled neural networks. It can find the global
minimum with probability 1. However, the convergence is
much slower than the gradient descent method.
In this paper, we introduce a novel neural network
algorithm, which modifies a type of network developed by
Dr. Looney, by using mathematical inversion formulas to
get rid of the activation function at the output layer
of neurodes. The new neural network is called NCUBRONN,
which applies a type of random optimization method, but
it is much faster than other random optimization
networks.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  2404 </NUMBER>
<ORDER>   AAI1361246 </ORDER>
<TITLE> OPTICAL CHARACTER RECOGNITION USING NEURAL NETWORKS </TITLE>
<AUTHOR> YANG, CHIH-CHIN </AUTHOR>
<YEAR> 1994 </YEAR>
<INSTITUTION> UNIVERSITY OF NEVADA, RENO; 0139 </INSTITUTION>
<DESCRIPTORS> ENGINEERING, ELECTRONICS AND ELECTRICAL; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> CARL LOONEY </ADVISER>
<CLASSIFICATIONS> NIL </CLASSIFICATIONS>
<ABSTRACT>
This thesis derives from image interpretation, which is
a process of discovering, identifying, and understanding
patterns. The principal goal of this research is to
endow a machine with the capability to alphanumeric
characters, and further to achieve character recognition
accuracy that is as close as possible to the superb
capability exhibited by human beings for performing such
tasks.
This research applies a classification model called the
distance threshold clustering algorithm by modifying it
to group identified pixels on the scanning screen. Those
pixels extracted from a hand writing character will be
sharpened by adopting decision rules for further
recognition. For character recognition, the Hopfield
neural network is integrated into our system. Its
remarkable binary feature yields the advantage of bit-
mapping communication.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  2405 </NUMBER>
<ORDER>   AAGC513011 </ORDER>
<TITLE> CLUSTER-BASED SPECIFICATION TECHNIQUES IN DEMPSTER- SHAFER THEORY FOR AN EVIDENTIAL INTELLIGENCE ANALYSIS OF MULTIPLE TARGET TRACKS  </TITLE>
<AUTHOR> SCHUBERT, JOHAN </AUTHOR>
<YEAR> 1994 </YEAR>
<INSTITUTION> KUNGLIGA TEKNISKA HOGSKOLAN (SWEDEN); 1022 </INSTITUTION>
<DESCRIPTORS> COMPUTER SCIENCE; ARTIFICIAL INTELLIGENCE MICROFICHE VERSION  TRITA-DISS-2205, S-100 44 STOCKHOLM 70, SWEDEN SWEDEN </DESCRIPTORS>
<ADVISER> NIL </ADVISER>
<CLASSIFICATIONS> ARTIFICIAL INTELLIGENCE </CLASSIFICATIONS>
<ABSTRACT>
In Intelligence Analysis it is of vital importance to
manage uncertainty. Intelligence data is almost always
uncertain and incomplete, making it necessary to reason
and make decisions under uncertainty. One way to manage
the uncertainty in Intelligence Analysis is Dempster-
Shafer Theory. We may call this application of Dempster-
Shafer Theory Evidential Intelligence Analysis. This
thesis contains five results regarding multiple target
tracks and intelligence specification in Evidential
Intelligence Analysis.
When simultaneously reasoning with evidence about
several different events it is necessary to separate the
evidence according to event. These events should then be
handled independently. However, when propositions of
evidences are weakly specified in the sense that it may
not be certain to which event they are referring, this
may not be directly possible. In the first article of
this thesis a criterion for partitioning evidences into
subsets representing events is established.
In the second article we will specify each piece of
nonspecific evidence by observing changes in cluster and
domain conflicts if we move a piece of evidence from one
subset to another. A decrease in cluster conflict is
interpreted as an evidence indicating that this piece of
evidence does not actually belong to the subset where it
was placed by the partition. We will find this kind of
evidence regarding the relation between each piece of
evidence and every subset. When this has been done we
can make a partial specification of each piece of
evidence.
In the third article we set out to find a posterior
probability distribution regarding the number of
subsets. We use the idea that each single piece of
evidence in a subset supports the existence of that
subset. With this we can create a new bpa that is
concerned with the question of how many subsets we have.
In order to obtain the sought-after posterior domain
probability distribution we combine this new bpa with
our prior domain probability distribution.
For the case of evidence ordered in a complete directed
acyclic graph the fourth article presents a new
algorithm with lower computational complexity for
Dempster's rule than that of step by step application of
Dempster's rule. We are interested in finding the most
probable completely specified path through the graph,
where transitions are possible only from lower to higher
ranked vertices. The path is here a representation for a
sequence of states, for instance a sequence of snapshots
of a physical object's track.
The fifth article concerns an earlier method for
decision making where expected utility intervals are
constructed for different choices. When the expected
utility interval of one alternative is included in that
of another, it is necessary to make some assumptions. If
there are several different decision makers we might
sometimes be interested in having the highest expected
utility among the decision makers. We must then also
take into account the rational choices we can assume to
be made by later decision makers.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  2406 </NUMBER>
<ORDER>   AAI1361114 </ORDER>
<TITLE> AN OVERVIEW OF THE ROLE OF CONTEXT IN COMPUTER VISION </TITLE>
<AUTHOR> BRUCK, JEFFREY A. </AUTHOR>
<YEAR> 1994 </YEAR>
<INSTITUTION> THE AMERICAN UNIVERSITY; 0008 </INSTITUTION>
<DESCRIPTORS> COMPUTER SCIENCE; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> MICHAEL A. GRAY </ADVISER>
<CLASSIFICATIONS> NIL </CLASSIFICATIONS>
<ABSTRACT>
This survey investigates the use of context as a method
for limiting the search space and improving the output
of computer vision systems. It presents current thoughts
on the value of using context in intelligent systems and
examines the representations and strategies of computer
vision systems that make use of it. We define three
types of context--immediate, modeled, and operational--
and describe its two main roles in computer vision:
selection of algorithms and verification of hypotheses.
We present common themes of current context-based
computer vision systems, highlight some special ideas,
and examine the design, processing, and implementation
status of five systems in detail. Thoughts on promising
ideas and areas that require further investigation are
also presented.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  2407 </NUMBER>
<ORDER>   AAI1360908 </ORDER>
<TITLE> SCENARIO-BASED VIEW ABSTRACTION AGENTS IN KNOWLEDGE- BASED SYSTEMS </TITLE>
<AUTHOR> THAKKER, KAUSHAL ARVIND </AUTHOR>
<YEAR> 1994 </YEAR>
<INSTITUTION> THE UNIVERSITY OF TEXAS AT ARLINGTON; 2502 </INSTITUTION>
<DESCRIPTORS> COMPUTER SCIENCE; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> KARAN A. HARBISON </ADVISER>
<CLASSIFICATIONS> NIL </CLASSIFICATIONS>
<ABSTRACT>
The Scenario-Based Engineering Process (SEP) is based on
four major concepts from artificial intelligence and
systems engineering--high user involvement, rapid
prototyping, iteration and architecture-based
composition. SEP uses scenarios for environment, domain
and technology layer definitions. Automating these user
views is an important aspect of using the process and is
lacking in conventional CASE environments.
SEP information is acquired from various sources and
represented in semantic network and frame structures of
Knowledge-Based Systems (KBS's). However current KBS's
seldom define explicit semantics for logical
partitioning of knowledge or the creation of user views.
To address this problem, an approach for viewing a
domain model was developed. The approach was based on
obtaining multiple-view abstraction using agents that
manipulate the knowledge base. A prototype of a small
Patient Record System with views for a receptionist,
nurse and doctor was implemented in LOOM. User views
were implemented as internal agents using methods and
actions.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  2408 </NUMBER>
<ORDER>   AAI1360887 </ORDER>
<TITLE> ARTIFICIAL NEURAL NETWORKS FOR AUTOMATIC CONTROL </TITLE>
<AUTHOR> LORENTZ, TIMOTHY ALAN </AUTHOR>
<YEAR> 1994 </YEAR>
<INSTITUTION> THE UNIVERSITY OF TEXAS AT ARLINGTON; 2502 </INSTITUTION>
<DESCRIPTORS> ENGINEERING, MECHANICAL; ENGINEERING, AEROSPACE; ENGINEERING, ELECTRONICS AND ELECTRICAL; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> STEPHEN KUGLE </ADVISER>
<CLASSIFICATIONS> NIL </CLASSIFICATIONS>
<ABSTRACT>
Artificial neural networks are massively parallel
networks of simple computational elements which
collectively have the ability to learn and to
generalize. This paper presents an application of
artificial neural networks to aircraft flight control. A
full authority neural network is trained using
supervised learning via the back-propagation algorithm
to provide stabilization of the airframe and to shape
the desired dynamic behavior (handling qualities) of a
linear aircraft model. The final system performance is
demonstrated through simulations and linear analysis of
the resulting aircraft and neural controller. These
results demonstrate the neural controller's excellent
closed-loop performance.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  2409 </NUMBER>
<ORDER>   AAI1360860 </ORDER>
<TITLE> DESIGN AND ANALYSIS OF MULTIAGENT COORDINATION MODELS </TITLE>
<AUTHOR> BHARATIA, VIRALKUMAR A. </AUTHOR>
<YEAR> 1994 </YEAR>
<INSTITUTION> THE UNIVERSITY OF TEXAS AT ARLINGTON; 2502 </INSTITUTION>
<DESCRIPTORS> COMPUTER SCIENCE; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> DIANE J. COOK </ADVISER>
<CLASSIFICATIONS> NIL </CLASSIFICATIONS>
<ABSTRACT>
Research in artificial intelligence on planning is
generally concerned with finding a sequence of actions
that achieves the desired goals. Coordination allows
multiple agents to synchronize their activities. Based
on distribution of control, two paradigms for multiagent
coordination viz. central and distributed are prevalent.
A hybrid group coordination approach is proposed in this
research. Coordination models for these three approaches
are developed. The performance of these coordination
models is analyzed under different planning conditions
characterized by parameters like the number of
resources, nature of initial uncoordinated plans and
number of agents. A group formation strategy has been
developed to enhance the performance of the group model.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  2410 </NUMBER>
<ORDER>   AAI1360792 </ORDER>
<TITLE> NEURAL NETWORKS AS METHODOLOGICAL TOOLS: A COMPLEMENT TO COMMON LINEAR STATISTICAL METHODS </TITLE>
<AUTHOR> MCMILLEN, ROBERT CAMERON </AUTHOR>
<YEAR> 1994 </YEAR>
<INSTITUTION> MISSISSIPPI STATE UNIVERSITY; 0132 </INSTITUTION>
<DESCRIPTORS> PSYCHOLOGY, EXPERIMENTAL; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> TRACY HENLEY </ADVISER>
<CLASSIFICATIONS> NIL </CLASSIFICATIONS>
<ABSTRACT>
Neural networks are presented as a complementary
methodological tool to common statistical methods for
certain types of classification problems. Prior research
has suggested that neural networks can classify cases
more accurately than many commonly used statistical
techniques in situations in which a data set does not
fully meet the required assumptions, there are missing
data, or there is a large amount of variance in several
of the variables. There is also evidence to suggest that
neural networks are a useful interpretive tool in these
situations. Several neural networks were applied to a
classification problem involving a problematic data set.
The analyses were compared to a series of logistic
regressions. Initially the logistic regression models
provided greater predictive accuracy than the neural
network models. However, as the data sets became more
problematic, the accuracy of the neural network models
surpassed that of the logistic regression models. It was
concluded that neural networks are most useful as
classification tools when insight and explanation are of
less interest than predictive accuracy in problematic
data sets.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  2411 </NUMBER>
<ORDER>   AAI1360693 </ORDER>
<TITLE> MACHINE LEARNING THROUGH DISCOURSE IN NATURAL LANGUAGE </TITLE>
<AUTHOR> KARACHIWALA, IRFAN SHABBIR </AUTHOR>
<YEAR> 1994 </YEAR>
<INSTITUTION> UNIVERSITY OF LOUISVILLE; 0110 </INSTITUTION>
<DESCRIPTORS> COMPUTER SCIENCE; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> NIL </ADVISER>
<CLASSIFICATIONS> NIL </CLASSIFICATIONS>
<ABSTRACT>
The ability to learn is considered one of the most
fundamental attributes of intelligent behavior. Ever
since the dawn of AI, researchers have sought to create
machines that could learn. The thesis that follows is
concerned with investigating the process of making
computers learn by being told. Two learning systems
named "Socrates" and "Darwin" were created for this
purpose. "Socrates" was the first venture into this kind
of learning, and was designed as a starter project to
primarily get an insight into the kind and range of
learning that could be achieved on a machine. "Darwin"
is a follow up to "Socrates" and was written to overcome
many of the limitations of its predecessor.
Darwin and Socrates both are incremental learning
systems that learn and acquire knowledge through
interactive dialogues with a user (teacher) in a limited
natural language. The specific problem handled is how to
enable a computer system to acquire information about a
domain unfamiliar to itself, from humans who are experts
in those domains, but have limited computer knowledge.
Learning, knowledge representation, natural language
processing and natural language generation are major
research areas of artificial intelligence, and both
systems are ventures into parts of these areas.
Darwin tries to emulate the process of human learning,
and starts out with as little knowledge as possible.
This minimal set of information includes (a) certain
concepts such as thing, part, measure, etc., (b) syntax,
and semantics for a small subset of English, (c)
language recognition and generation rules, and (d)
certain logic rules. Almost all knowledge is learned
incrementally, and is stored in the knowledge base in
the form of first-order logic and hierarchical trees.
Darwin learns concepts about nouns, measures, parts, and
relations among other things. Some of the major
accomplishments in Darwin include its ability to learn
verbs and relations, and to distinguish between what it
does not know from what it knows to be false. Darwin
also contains a critic and question answering unit, thus
the user can not only enter in new information, but also
query it about the information that the system has
learned or deduced.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  2412 </NUMBER>
<ORDER>   AAIMM95552 </ORDER>
<TITLE> BUFFER MANAGEMENT FOR FRAME-BASED KNOWLEDGE BASES </TITLE>
<AUTHOR> PEREYRA, HEBERT W. </AUTHOR>
<YEAR> 1994 </YEAR>
<INSTITUTION> QUEEN'S UNIVERSITY AT KINGSTON (CANADA); 0283 </INSTITUTION>
<DESCRIPTORS> COMPUTER SCIENCE; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> PATRICK MARTIN; MICHAEL JENKINS </ADVISER>
<CLASSIFICATIONS> NIL </CLASSIFICATIONS>
<ABSTRACT>
As knowledge base technology matures larger and more
complex knowledge based systems are being developed.
These systems require efficient data management both in
transient as well as persistent storage. In this thesis
we study the applicability of DBMS memory and buffer
management principles to large frame-based knowledge
bases. We develop a prototype frame management system
that effectively incorporates persistency into a frame
data manipulation language, provides buffer management
support to the system, and integrates the main memory
run-time environment with secondary storage provided by
an object-oriented database.
We also study the effect of incorporating semantic
information about the knowledge representation scheme
into the memory management process. Traditional data
base systems, and the more recent object-oriented
systems, do not model structural relationships as first
class data objects, consequently, these systems have no
structural information to exploit in the data management
process. Two structurally-sensitive frame management
algorithms are proposed and tested against traditional
buffer management schemes.
Our performance analysis shows that frame management is
effective and results in buffer hit-ratios of at least
75%. No conclusive evidence was found as to the benefits
of using context-sensitive frame management schemes
relative to traditional buffer management algorithms
tough. The results suggest that structurally-sensitive
knowledge management is highly sensitive to the frame
buffer size and to the workload. It is also an expensive
approach due to the computational time required to
prioritize frames according to the structural
relationships of frame taxonomies.
Further investigation of the smart frame management
approach is required. More testing is needed as to
analyze how much semantic information the system should
use in order to maximize potential gains. The empirical
evidence suggests that smart frame management should be
a dynamic process that allows tailoring of the knowledge
management system to specific applications and intended
access patterns.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  2413 </NUMBER>
<ORDER>   AAIMM95125 </ORDER>
<TITLE> INTELLIGENT MAINTENANCE SUPPORT SYSTEM FOR MINING TRUCKS </TITLE>
<AUTHOR> URSENBACH, ANDREW WAYNE </AUTHOR>
<YEAR> 1994 </YEAR>
<INSTITUTION> UNIVERSITY OF ALBERTA (CANADA); 0351 </INSTITUTION>
<DESCRIPTORS> ENGINEERING, AUTOMOTIVE; COMPUTER SCIENCE; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> MING RAO </ADVISER>
<CLASSIFICATIONS> NIL </CLASSIFICATIONS>
<ABSTRACT>
Maintenance of heavy mining trucks at Syncrude Canada
Ltd. amounts to several million dollars per year. The
trucks are large with complex componentry and it is
difficult for any one person to become an expert in all
the maintenance procedures. Built into the trucks is a
hardware monitoring system that monitors and records the
performance of the vehicles. To facilitate better
maintenance and reduce downtime, a project was initiated
with the University of Alberta to develop an Intelligent
Maintenance Support System (IMSS).
The system has three functions. The first function is
condition monitoring. The condition monitoring is
divided into normal condition monitoring, which displays
a graphical trend of vehicle component performance, and
abnormal condition monitoring, which detects faults that
occur within the truck. The second function is component
fault diagnosis, which narrows the conclusion of the
abnormal condition monitoring to a specific component.
The third function is maintenance assistance, which
provides maintenance information to the user. It is an
integrated system whereby the three modules work in
conjunction with one another, each module using the
results of the previous one. The abnormal condition
monitoring and component fault diagnosis make use of
expert systems, while the maintenance assistance employs
a hypermedia package.
This thesis is a discussion of the development and the
methodology of integration of the IMSS modules. Also
discussed is the development of the supporting
subsystems in the IMSS.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  2414 </NUMBER>
<ORDER>   AAIMM95036 </ORDER>
<TITLE> IDENTIFICATION OF POWER SYSTEM TRANSFER FUNCTIONS USING NEURAL NETWORKS </TITLE>
<AUTHOR> GILLARD, DEBORAH MAY </AUTHOR>
<YEAR> 1994 </YEAR>
<INSTITUTION> UNIVERSITY OF ALBERTA (CANADA); 0351 </INSTITUTION>
<DESCRIPTORS> ENGINEERING, ELECTRONICS AND ELECTRICAL; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> KEN BOLLINGER </ADVISER>
<CLASSIFICATIONS> NIL </CLASSIFICATIONS>
<ABSTRACT>
This thesis describes an investigation into the use of a
multilayered neural network for measuring the transfer
function of a power system. The objectives are to
quickly and accurately measure the transfer function of
a system with the plant operating under normal
conditions. In addition, the excitation signal used in
the identification procedure will not affect the quality
of the power output or the frequency of the system under
test.
This research emphasized the development of a neural
network that is easily trained and robust to changing
system conditions. Performance studies of the trained
neural network are described. In addition, variations in
the neural network architecture are also investigated
for the purpose of increasing the speed of
identification without compromising the accuracy of the
results.
Simulation studies suggest the practical feasibility of
the algorithm as a stand-alone identification package,
even though the algorithm can form part of a feedback
control strategy. Finally, the same technique applied to
a forward modelling scheme could be used to test the
effect of control strategies.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  2415 </NUMBER>
<ORDER>   AAGC511133 </ORDER>
<TITLE> MODELISATION DE L'EXPERTISE EN RECHERCHE CLINIQUE. APPLICATION A LA CANCEROLOGIE; MODELLING EXPERTISE IN CLINICAL RESEARCH: APPLICATION TO ONCOLOGY  </TITLE>
<AUTHOR> BLANCHARD, JEAN-MARC </AUTHOR>
<YEAR> 1994 </YEAR>
<INSTITUTION> INSTITUT NATIONAL DES SCIENCES APPLIQUEES DE LYON (FRANCE); 5285 </INSTITUTION>
<DESCRIPTORS> COMPUTER SCIENCE; ARTIFICIAL INTELLIGENCE; HEALTH SCIENCES, CHEMOTHERAPY </DESCRIPTORS>
<ADVISER> NIL </ADVISER>
<CLASSIFICATIONS> MEDICAL INFORMATICS </CLASSIFICATIONS>
<ABSTRACT>
L'intelligence Artificielle a d'emblee montre un grand
interet pour le domaine medical et les Systemes Experts
ont largement aborde les problemes inherents a la
pratique courante en Medecine. L'application presentee
dans le cadre de ce travail aborde la Recherche Clinique
en Cancerologie. Une presentation detaillee de cet
univers permet d'apprecier l'importance des difficultes
rencontrees par les Cliniciens dans le cadre de leur
activite. Deux types complementaires de systeme experts
sont developpes: pour l'aide a la Decision Therapeutique
et pour l'aide a l'Inclusion de Patients dans les Etudes
Cliniques en Cancerologie. La validation de la qualite
des avis proposes par le module d'Aide a la Decision
Therapeutique a abouti a un resultat global de plus de
85% de reponses conformes avec celles proposees par les
Experts, apres une evaluation initiale de l'ordre de
80%. Nous avons par ailleurs montre qu'il etait possible
d'enrichir simplement l'expertise prise en compte, en
etendant celle-ci a des pathologies non abordees dans le
modele initial. Enfin, en nous basant sur l'organisation
des Bases de Connaissances mises en oeuvre et a partir
de l'identification de la structuration de la demarche
therapeutique des Experts, nous proposons un modele
conceptuel de representation de cette demarche. Ce
modele, decompose en trois etapes de resolution, traduit
l'expertise exprimee par les Medecins lorsqu'ils mettent
en pratique leurs competences.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  2416 </NUMBER>
<ORDER>   AAI9524488 </ORDER>
<TITLE> AN INCREMENTAL NAVIGATION LOCALIZATION METHODOLOGY FOR APPLICATION TO SEMI-AUTONOMOUS MOBILE ROBOTIC PLATFORMS TO ASSIST INDIVIDUALS HAVING SEVERE MOTOR DISABILITIES </TITLE>
<AUTHOR> THOMAS, DARYL DEVON </AUTHOR>
<YEAR> 1994 </YEAR>
<INSTITUTION> THE LOUISIANA STATE UNIVERSITY AND AGRICULTURAL AND MECHANICAL COL.; 0107 </INSTITUTION>
<DESCRIPTORS> COMPUTER SCIENCE; ENGINEERING, BIOMEDICAL; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> S. S. IYENGAR </ADVISER>
<CLASSIFICATIONS> NIL </CLASSIFICATIONS>
<ABSTRACT>
In the present work, the author explores the issues
surrounding the design and development of an intelligent
wheelchair platform incorporating the "semi-autonomous"
system paradigm, to meet the needs of individuals with
severe motor disabilities.
The author presents a discussion of the problems of
navigation that must be solved before any system of this
type can be instantiated, and enumerates the general
design issues that must be addressed by the designers of
systems of this type. This discussion includes reviews
of various methodologies that have been proposed as
solutions to the problems considered. Next, the author
introduces a new navigation method, called Incremental
Signature Recognition (ISR), for use by semi-autonomous
systems in structured environments. This method is based
on the recognition, recording, and tracking of
environmental discontinuities: sensor reported anomalies
in measured environmental parameters. The author then
proposes a robust, redundant, dynamic, self-diagnosing
sensing methodology for detecting and compensating for
hidden failures of single sensors and sensor
idiosyncrasies. This technique is optimized for the
detection of spatial discontinuity anomalies. Finally,
the author gives details of an effort to realize a
prototype ISR based system, along with insights into the
various implementation choices made.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  2417 </NUMBER>
<ORDER>   AAI9524478 </ORDER>
<TITLE> A DIRECTED HYPERGRAPH APPROACH FOR THE VERIFICATION OF RULE-BASED EXPERT SYSTEMS </TITLE>
<AUTHOR> RAMASWAMY, MYSORE </AUTHOR>
<YEAR> 1994 </YEAR>
<INSTITUTION> THE LOUISIANA STATE UNIVERSITY AND AGRICULTURAL AND MECHANICAL COL.; 0107 </INSTITUTION>
<DESCRIPTORS> COMPUTER SCIENCE; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> YE-SHO CHEN </ADVISER>
<CLASSIFICATIONS> NIL </CLASSIFICATIONS>
<ABSTRACT>
Rule-based representation techniques have become popular
for storing and manipulation of domain knowledge in
expert systems. It is important that systems using such
a representation are verified for accuracy before
implementation. In recent years, graphical techniques
have been found to provide a good framework for the
detection of errors that may appear in a rule base. In
this dissertation, we develop a technique that uses a
directed hypergraph to accurately detect all the
different types of errors that appear in a rule base.
This technique overcomes limitations of existing
graphical techniques that are unable to accurately
detect all the errors that appear in a rule base,
without misdiagnosing error-free instances. The directed
hypergraph technique allows rules to be represented in a
manner that clearly identifies complex dependencies
across compound clauses in the rule base. Since
connectivity across compound clauses are accurately
represented, the verification procedure can detect
errors in an accurate fashion. We have developed a
verification procedure that uses the adjacency matrix of
the directed hypergraph. The procedure detects different
types of errors by using simple operations on the
adjacency matrix.
In practice, expert systems are often used to make
inferences based on multiple observed facts. Most
existing techniques have ignored this aspect, since the
selection of valid combinations of rule antecedents from
a large number of rule antecedents to be considered is
difficult. To address this issue, the directed
hypergraph technique has been extended to perform
verification checks when sets of feasible multiple
assertions are made available to the system. As the size
of the rule base increases, execution of the algorithm
can be hard due to storage and computational
considerations. It has been empirically found that sets
of rules in large rule bases are sufficiently separated
to allow decomposition into smaller sets. The directed
hypergraph technique has been enhanced to accurately
detect all errors in large rule bases by performing
verification checks over the smaller groups of rules
separately, and propagating the results from one group
to other linked groups.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  2418 </NUMBER>
<ORDER>   AAI9524352 </ORDER>
<TITLE> ANALYSES OF BIOLOGICAL NERVOUS SYSTEMS USING NEURAL NETWORKS AND FUZZY LOGIC TECHNIQUES </TITLE>
<AUTHOR> SHAH, SAFWAN </AUTHOR>
<YEAR> 1994 </YEAR>
<INSTITUTION> UNIVERSITY OF COLORADO AT BOULDER; 0051 </INSTITUTION>
<DESCRIPTORS> ENGINEERING, AEROSPACE; ENGINEERING, BIOMEDICAL; COMPUTER SCIENCE; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> MARK BALAS </ADVISER>
<CLASSIFICATIONS> NIL </CLASSIFICATIONS>
<ABSTRACT>
Advances in neurophysiological recording techniques have
dramatically increased both the quantity and quality of
information available for studying the
structure/function of biological nervous systems.
However, advances in computational and analytical
techniques for studying these structure/function
relationships have not kept pace with experiments. As
such, there is a need to develop computational
techniques which can take advantage of the available
neurophysiological data. This dissertation explores one
such technique with an emphasis on simulating the
functional dynamics of simultaneous single-unit
recordings.
To study the collective computational abilities of a
nervous tissue, simultaneous single-unit recordings were
obtained from the cricket mesothoracic ganglion. Methods
to process the spike train data for simulation and
modeling experiments were then devised. Fuzzy logic
techniques were used to model the stochastic nature of
neural spike trains. Artificial neural networks (ANNs)
were used as the crucible for concurrent analyses. As
shown, herein, the nexus of fuzzy logic with ANNs
yielded an inherently parallel framework well suited for
the analyses of simultaneous single-unit data.
Results from a systematic study of these models were as
follows. First, the ANN models were shown to "learn" the
cellular spiking histories of many cells. And, the
models were shown to generalize, thus, model performance
was not degraded when confronted with novel spike train
data. Second, the models were examined for fault
tolerance capabilities typically associated with
biological nervous systems. As such, several types of
lesioning tests were carried out and consequent ANN
performance was measured. The results clearly showed
that the models possessed properties, hitherto solely
associated with biological neural networks:
equipotentiality and mass action. Third, on trained ANN
models, a technique was developed for determining
cellular interactions and the resulting effective
connectivity was computed. Finally, methods to extend
the models by taking into account cell size related
biases on information processing were investigated.
Overall, techniques developed provide a critical step
towards bridging the existing disparity between
experimental methods (data) and the available
analytical/computational techniques.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  2419 </NUMBER>
<ORDER>   AAI9523646 </ORDER>
<TITLE> GENERAL METHODS FOR ANALYZING MACHINE LEARNING SAMPLE COMPLEXITY  </TITLE>
<AUTHOR> MICHAEL, CHRISTOPH </AUTHOR>
<YEAR> 1994 </YEAR>
<INSTITUTION> THE COLLEGE OF WILLIAM AND MARY; 0261 </INSTITUTION>
<DESCRIPTORS> COMPUTER SCIENCE; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> W. ROBERT COLLINS </ADVISER>
<CLASSIFICATIONS> PAC MODEL </CLASSIFICATIONS>
<ABSTRACT>
During the past decade, there has been a resurgence of
interest in applying mathematical methods to problems in
artificial intelligence. Much work has been done in the
field of machine learning, but it is not always clear
how the results of this research should be applied to
practical problems. Our aim is to help bridge the gap
between theory and practice by addressing the question:
"If we are given a machine learning algorithm, how
should we go about formally analyzing it?" as opposed to
the usual question: "how do we write a learning
algorithm we can analyze?"
We will consider algorithms that accept randomly drawn
training data as input, and produce classification rules
as their outputs. For the most part our analyses will be
based on the syntactic structure of these classification
rules; for example, if we know that the algorithm we
want to analyze will only output logical expressions
that are conjunctions of variables, we can use this fact
to facilitate our analysis.
We use a probabilistic framework for machine learning,
often called the pac model. In this framework, one asks
whether or not a machine learning algorithm has a high
probability of generating classification rules that
"usually" make the right classification (pac means
probably approximately correct). Research in the pac
framework can be divided into two subfields. The first
field is concerned with the amount of training data that
is needed for successful learning to take place (success
being defined in terms of generalization ability); the
second field is concerned with the computational
complexity of learning once the training data have been
selected. Since most existing algorithms use heuristics
to deal with the problem of complexity, we are primarily
concerned with the amount of training data that
algorithms require.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  2420 </NUMBER>
<ORDER>   AAI9523232 </ORDER>
<TITLE> COMPUTER-ASSISTED MECHANISTIC EVALUATION OF ORGANIC OXIDATION-REDUCTION REACTIONS </TITLE>
<AUTHOR> SINCLAIR, SHENNA </AUTHOR>
<YEAR> 1994 </YEAR>
<INSTITUTION> YALE UNIVERSITY; 0265 </INSTITUTION>
<DESCRIPTORS> CHEMISTRY, ORGANIC; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> WILLIAM L. JORGENSEN </ADVISER>
<CLASSIFICATIONS> NIL </CLASSIFICATIONS>
<ABSTRACT>
CAMEO, an interactive computer program designed to
predict the products of organic reactions given the
starting materials and conditions, has been refined and
expanded. The analysis of various classes of redox
reactions, the formulation of empirically and
mechanistically derived reactivity rules, and their
subsequent implementation in the CAMEO program are
addressed in this thesis. The mechanistic evaluation and
implementation of the Sharpless epoxidation, Li-ammonia
reductions (including the Birch reduction), and
heterogeneous catalytic hydrogenations using palladium,
platinum, nickel, and rhodium metals are described.
Emphasis is placed on the theoretical and empirical
organizing principles used to determine the reactivity
of organic compounds toward the reagents. For the
Sharpless epoxidation and the hydrogenation reactions, a
special emphasis is placed on the stereochemical
relationship between the substrate structure and reagent
and the subsequent effect on reactivity. For Li-ammonia
reductions, mechanistic intermediates are explicitly
shown and are automatically submitted for further
reaction evaluation by the established
Basic/Nucleophilic module.
In the course of studying large numbers of reported
literature transformations for the CAMEO project,
reactivity rules based on current mechanistic,
theoretical, and empirical knowledge were developed.
Within the context of CAMEO, the reactivity rules serve
to condense the program and make it operate more
efficiently. In the larger sense, these rules, which
encompass a knowledge of structure, functionality,
fundamental physical data and just how all these factors
work together to influence "electron-pushing", are of
general value to chemistry.
A key feature for the successful prediction of reaction
products was the development of expansive reactivity
tables containing functional group interconversions
amassed from literature precedents. The reactivity
information in these tables is integrated with an
empirical knowledge of electronic and steric
interactions and then used to predict selectivity in a
multifun
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  2421 </NUMBER>
<ORDER>   AAI9522949 </ORDER>
<TITLE> NERVOTRON: A FUNCTIONAL SILICON ANALOG TO THE NEURON </TITLE>
<AUTHOR> BITETTO, MARCO ANTONIO V. </AUTHOR>
<YEAR> 1994 </YEAR>
<INSTITUTION> THE UNION INSTITUTE; 1033 </INSTITUTION>
<DESCRIPTORS> ENGINEERING, ELECTRONICS AND ELECTRICAL; COMPUTER SCIENCE; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> HULAN JACK, JR.; VITO PRUSCIA </ADVISER>
<CLASSIFICATIONS> MACHINE LEARNING </CLASSIFICATIONS>
<ABSTRACT>
NERVOTRONS are silicon based analogs of biological
neurons that are in effect capable of reacting in many
of the same analogous modes of operations as the
currently understood models of neurons. The theory
behind such analogous processing units is discussed
along with a discussion of how hardware analogs can be
made to form auto-programming networks via the use of
closed loop feedback methods of the PID (Proportional
Integral Derivative) variety and/or use of Markovian
Renormalization error minimization techniques. A
collection of idealized interconnection networks of
NERVOTRONS are described and techniques are discussed
for the actualization of these idealized networks in
silicon. Computerized simulation models are included for
the basic processing models of the NERVOTRON and a
method of determining how long it would take a
NERVOTRONIC control system to eliminate a perturbation
from the actual signal input. This dissertation
concludes with a discussion of the future potential of
NERVOTRONIC technology to mankind, current limitations
and future development. Included are discussions on the
topics of: Thinking, Learning and Creativity; Cognitron
Theory; Reading Machine; Talking; Exploder;
Specifications of Recommended Components;
Renormalization Theory and Concepts and Markovian
Renormalization; Simulation Programs; and Analysis of
the Functional Anatomy of the Human Brain.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  2422 </NUMBER>
<ORDER>   AAI9522563 </ORDER>
<TITLE> A NEW APPROACH TO RADAR DETECTION BASED ON THE PARTITIONING AND STATISTICAL CHARACTERIZATION OF THE SURVEILLANCE VOLUME </TITLE>
<AUTHOR> SLAMANI, MOHAMED ADEL </AUTHOR>
<YEAR> 1994 </YEAR>
<INSTITUTION> SYRACUSE UNIVERSITY; 0659 </INSTITUTION>
<DESCRIPTORS> ENGINEERING, ELECTRONICS AND ELECTRICAL; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> NIL </ADVISER>
<CLASSIFICATIONS> NIL </CLASSIFICATIONS>
<ABSTRACT>
In signal processing applications it is common to assume
Gaussian statistics in the design of optimal signal
processors. However, non-Gaussian processes do arise in
many situations. For example, measurements reveal that
radar clutter may be approximated by either Weibull, K-
distributed, Lognormal, or Gaussian distributions
depending upon the scenario. When the possibility of a
non-Gaussian problem is encountered, the question as to
which probability distributions should be utilized in a
specific situation for modeling the data needs to be
answered.
In practice, the underlying probability distributions
are not known a priori. Consequently, an assessment must
be made by monitoring the environment. Another
consideration is that radar detection problems can
usually be divided into strong, intermediate, and weak
signal cases. Hence, the system that monitors a radar
environment must be able to subdivide the surveillance
volume into weak background noise and clutter patches in
addition to approximating the underlying probability
distributions for each patch. This is in contrast to
current practice where a single robust detector, usually
based on the Gaussian assumption, is employed.
The objective of this work is to develop techniques that
monitor the environment and select the appropriate
detector for processing the data.
The main contributions are: (1) an image processing
technique is devised which enables partitioning of the
surveillance volume into background noise and clutter
patches, (2) the Ozturk algorithm is used to identify
suitable approximations to the probability density
function for each clutter patch, and (3) rules to be
used with an expert system shell under development at
the University of Massachusetts and Boston University
are formulated for monitoring the environment and
selecting the appropriate detector for processing the
data.
Computer simulated examples demonstrate the
effectiveness by which the approach proposed in this
work is able to partition the surveillance volume and
approximate the probability distributions within
homogeneous regions.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  2423 </NUMBER>
<ORDER>   AAI9522431 </ORDER>
<TITLE> EXTENDING CONVENTIONAL LOOP DESIGN TECHNIQUES TO FUZZY LOGIC CONTROL </TITLE>
<AUTHOR> KIRBY, RAYMOND L. </AUTHOR>
<YEAR> 1994 </YEAR>
<INSTITUTION> THE UNIVERSITY OF ALABAMA; 0004 </INSTITUTION>
<DESCRIPTORS> ENGINEERING, ELECTRONICS AND ELECTRICAL; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> ROBERT LELAND; M. G. REKOFF, JR. </ADVISER>
<CLASSIFICATIONS> NIL </CLASSIFICATIONS>
<ABSTRACT>
Fuzzy Logic Control may be described as a knowledge-
based linguistic control strategy. The knowledge base is
represented by a set of control rules. These rules allow
human intuition and experience to become the control
strategy. In a conventional control system the control
law is an analytic function of the process state. In
fuzzy logic control systems the control law is composed
of if condition-then action type linguistic statements
in which the action, or consequent, is a function of the
condition, or antecedent.
Since its inception in 1965, fuzzy logic control has
found application in the process industries. In spite of
any number of successful applications, it has not been
widely accepted by the control engineering community.
This may be attributed to the lack of a sound foundation
for analysis and design in traditional engineering
terms. The objective of this dissertation is to offer
such a foundation.
This objective is accomplished in three distinct ways.
First, a mathematical analysis of the current techniques
used in the realization of a fuzzy logic controller is
performed. This analysis defines how the various fuzzy
logic controller parameters influence its dynamic
properties. This is the first step in the process of
establishing fuzzy logic control in traditional
engineering terms. This analysis defines the
relationship between the fuzzy logic controller
parameters and common engineering performance measure.
Secondly, alternatives to current techniques are
proposed. These alternatives transform the nonlinear
controller into a linear model. This model is expressed
in traditional engineering terms and can be used with
any of the conventional analysis and design strategies.
Finally, a design strategy is proposed for both known
and unknown processes. This strategy, based on the
proposed alternatives, utilizes the linear model to
achieve expected performance standards. The concept of
trajectory tuning is introduced as a means of improving
performance by nonlinearizing the response trajectory. A
case study is included to illustrate how superior
performance can be achieved.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  2424 </NUMBER>
<ORDER>   AAI9522318 </ORDER>
<TITLE> PARALLEL DIAGNOSTIC REASONING </TITLE>
<AUTHOR> GROVE, RALPH FREDERICK </AUTHOR>
<YEAR> 1994 </YEAR>
<INSTITUTION> UNIVERSITY OF LOUISVILLE; 0110 </INSTITUTION>
<DESCRIPTORS> COMPUTER SCIENCE; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> JAMES H. GRAHAM </ADVISER>
<CLASSIFICATIONS> NIL </CLASSIFICATIONS>
<ABSTRACT>
Model-based diagnosis has been successfully applied to a
variety of complex systems, including power generation
systems, chemical processes, electrical circuits, etc.,
in small and medium scale applications. As system sizes
grow and as the level of detail contained in the models
grows, the worst-case cost for model-based diagnosis
increases dramatically, placing limits on the
scalability of model-based techniques for traditional
single processor computer architectures. In this
dissertation, several methods of applying parallel
processing to model-based diagnosis are explored with
the objective of developing a scalable solution to
general diagnostic problems.
This work includes an overview of diagnosis and related
developments in parallel processing, a formal
description of model-based diagnosis, and an
investigation of three methods for applying parallel
processing to diagnosis. The three methods are based
upon different computational models, including a message-
passing multicomputer (MPMC), a shared-memory
multiprocessor (SMMP), and a modified processor array
with reconfigurable bus system (PARBS). Complexity
analysis which describes worst-case performance is
included for all three of the methods and simulation
results indicating average performance are presented for
the methods based upon MPMC and SMMP architectures.
Worst-case computational complexity for single-fault
diagnosis ranges from O(1) under the PARBS model to O(n
+ f$sp2$) (where f is the number of observed faults)
under the MPMC model. For multiple-fault diagnosis
problems, computational complexity ranges from O(n) for
a restricted group of problems under the MPMC
architecture to O(nf + f$sp3$) for general problems
under MPMC and O(n$sp2$ + f) under the SMMP
architecture. Simulation results indicate that the
methods based upon MPMC and SMMP architectures can solve
single-fault problems with a response time in linear
proportion to problem size while the time required for
multiple-fault problems is proportional to the square of
problem size.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  2425 </NUMBER>
<ORDER>   AAGC511106 </ORDER>
<TITLE> MODELISATION ET PLACEMENT AUTOMATIQUE DE CAPTEURS- VISION. INTEGRATION D'UN MODULE-VISION DANS UN SYSTEME DE CAO-ROBOTIQUE; MODELING AND AUTOMATIC PLACEMENT OF VISION SENSORS. INTEGRATION OF A VISION MODULE IN A CAD/CAM-ROBOTIC SYSTEM </TITLE>
<AUTHOR> BEN AMAR, CHOKRI </AUTHOR>
<YEAR> 1994 </YEAR>
<INSTITUTION> INSTITUT NATIONAL DES SCIENCES APPLIQUEES DE LYON (FRANCE); 5285 </INSTITUTION>
<DESCRIPTORS> ENGINEERING, INDUSTRIAL; ARTIFICIAL INTELLIGENCE AVENUE ALBERT EINSTEIN, F-69621  VILLEURBANNE CEDEX, FRANCE </DESCRIPTORS>
<ADVISER> NIL </ADVISER>
<CLASSIFICATIONS> COMPUTER VISION </CLASSIFICATIONS>
<ABSTRACT>
Simuler les procedes de production, des leur conception,
presente des avantages qui apparaissent chaque jour plus
interessants, du fait des economies engendrees: gain de
temps, non immobilisation de l'outil de production,
optimisation de l'investissement, etc$...$ Les logiciels
disponibles, tout performants qu'ils soient, pechent
cependant par un manque notable concernant la simulation
realiste de capteurs evolues. Cette lacune est encore
plus manifeste vis-a-vis des systemes de vision
industriels, pourtant de plus en plus utilises sur les
chai nes de production pour le controle-qualite et/ou
pour l'identification des pieces en cours
d'approvisionnement ou de fabrication. C'est pour
pallier cette insuffisance que nous proposons un
simulateur de capteurs complexes, tels que les cameras
CCD, qui permet d'obtenir des images d'objets ou de
scenes virtuels. Ces images, tres proches de la realite,
peuvent etre alors utilisees pour simuler, par exemple,
une tache de recponnaissance de formes ou une tache de
controle dimensionnel; la fonction de ce nouvel outil
est absolument necessaire pour la simulation d'un poste
de controle-Vision et autorise la programmation hors-
ligne de celui-ci. Ce resultat acquis, on constate que
pour parfaire cet outil il convient de se preoccuper
egalement du choix de la position de la camera dans le
poste de travail; choix qui n'est pas evident, car
devant tenir compte des problemes de champ de vision, de
resolution, de mise au point, d'eclairage, de collision,
etc$...$ C'est pour sette raison que notre proposition
associe a la simulation une methode de placement
automatique de camera. L'ensemble de modelisation et de
placement automatique de capteurs-Vision constitue un
poste virtuel de Vision, qui peut valablement etre
integre a un systeme de CAO-Robotique, afin de disposer
d'un outil complet de simulation de taches faisant appel
a des robots et a des systemes de vision. Ce module-
Vision est valide par la description de deux
applications, l'une dans l'optique controle, l'autre
dans un processus d'assemblage robotise.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  2426 </NUMBER>
<ORDER>   AAI9522125 </ORDER>
<TITLE> NEURAL NETWORKS AND FUZZY LOGIC FOR STRUCTURAL CONTROL </TITLE>
<AUTHOR> JOGHATAIE, ABDOLREZA </AUTHOR>
<YEAR> 1994 </YEAR>
<INSTITUTION> UNIVERSITY OF ILLINOIS AT URBANA-CHAMPAIGN; 0090 </INSTITUTION>
<DESCRIPTORS> ENGINEERING, CIVIL; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> J. GHABOUSSI </ADVISER>
<CLASSIFICATIONS> NIL </CLASSIFICATIONS>
<ABSTRACT>
A new method for the active control of structures is
proposed in this study. This method is based on the use
of learning capability and adaptivity of neural networks
and the high degree of flexibility and adjustability
acquired through utilization of fuzzy logic. This method
is classified as a "learning control method" with
emphasis on the important role of the learning
capabilities of the controller. However it can be
classified as a smart or an intelligent control method
too. This method has been called the "neuro-fuzzy
control method" and its corresponding controller, the
"neuro-fuzzy controller". Neuro-fuzzy controllers can
theoretically cope with any nonlinearity, delay and
imperfection in the controlled structure. Hence they can
be considered as general controllers for structural
purposes.
In this method, a neural network called the "emulator
neural network" is trained to learn to predict the
response of the structure from the history of response
and control signals. It learns about all the sources of
nonlinearity and time delay, actuators capacity and any
imperfections in the whole control system, implicitly.
Then it is used in a preliminary control of the
structure and the training of another neural network
called the "neuro-controller". Neuro-controller has all
the required knowledge of controlling the structure. At
last a supplementary fuzzy controller is constructed to
improve on the performance of the "neuro-controller".
These two controllers which work in series, constitute
the "neuro-fuzzy controller".
In this study, the neuro-fuzzy control method is
explained and its capabilities are numerically assessed
through its application to the digital control of a
three storey steel frame structure, subjected to
different simulated earthquake excitations. Also for the
sake of comparison, the predictive optimal control
method is used in the control of the same structure,
subjected to the same excitations. Then the results of
the neuro-fuzzy control and the predictive optimal
control methods are compared to each other. It is shown
that the neuro-fuzzy controller is able to provide
better results than the predictive optimal controller.
Also, it is proposed to use as the criteria for the
evaluation of capabilities of any control method, the
three characteristics of adaptivity, prediction
capability and simplicity of that method. It is
discussed and demonstrated that the neuro-fuzzy control
method satisfies these criteria better than the other
proposed methods.
Neural network related issues have played important
roles in the progress of this study. These issues such
as improvements on the learning speed of the muiti-layer
feed-forward neural networks are discussed in this
article too.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  2427 </NUMBER>
<ORDER>   AAI9521932 </ORDER>
<TITLE> NONLINEAR SYSTEMS CONTROL USING NEURAL NETWORKS </TITLE>
<AUTHOR> YESILDIREK, AYDIN </AUTHOR>
<YEAR> 1994 </YEAR>
<INSTITUTION> THE UNIVERSITY OF TEXAS AT ARLINGTON; 2502 </INSTITUTION>
<DESCRIPTORS> ENGINEERING, ELECTRONICS AND ELECTRICAL; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> FRANK L. LEWIS </ADVISER>
<CLASSIFICATIONS> NIL </CLASSIFICATIONS>
<ABSTRACT>
For several classes of nonlinear systems, neural network
(NN) controller structures and weight update rules are
studied for closed-loop control applications. Design
techniques guaranteeing stability and tracking are
derived using the Lyapunov theorems and extensions.
Throughout this work, we have focused on designing a
controller working on-line under less knowledge,
reasonable conditions, and mild assumptions.
The relation between adaptive control and NN control is
studied. It is argued that the NN controller performs
very well when compared with adaptive control, which
needs to know a complete regression matrix of the
system. However, in the presence of any unmodeled
dynamics the NN controller outperforms adaptive control.
For a serial-link rigid arm, functional-link and
multilayer NN controllers with guaranteed tracking are
developed. Standard robot control notions, such as
filtered tracking error and robot properties, together
with passivity are used to derive the structure of the
NN. Novel tuning rules which guarantee boundedness of
closed-loop signals without a persistency of excitation
condition are derived using Lyapunov theory. These rules
suggest necessary changes to the backpropagation
algorithm to guarantee stability of the overall system.
Then, these results are extended easily to other
robotics systems, such as flexible-link manipulators and
force/motion control problems.
This design technique is next applied to a general class
of nonlinear systems. Using the same multilayer NN
structure with an additional robustifying control input
we have shown boundedness of all signals. For a larger
class of systems, a feedback linearization technique is
chosen for control; two three-layer NN controller are
implemented to estimate the feedback linearizing control
without using knowledge of the nonlinear system
dynamics. As the NN learns its actual weights on-line,
the proposed controller based on the NN weight estimates
avoids zero division and remains bounded.
Finally, simplified tuning algorithms which yield
similar stability results with much less computation are
developed. Tuning algorithms are modified-Hebbian rules
which perform on-line tracking for the classes of
systems studied above. A great deal of computational
advantage is gained without sacrificing stability
results.
In all of the work, initialization of the NN weights is
straightforward (we simply set them to zero) and no
stringent condition like persistency of excitation or
off-line training is required. Thus, these NN
controllers are applicable to a wide range of realtime
applications.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  2428 </NUMBER>
<ORDER>   AAI9521927 </ORDER>
<TITLE> INTELLIGENT CONTROL OF NONLINEAR DYNAMICAL SYSTEMS USING MULTILAYER NEURAL NETWORKS </TITLE>
<AUTHOR> SARANGAPANI, JAGANNATHAN </AUTHOR>
<YEAR> 1994 </YEAR>
<INSTITUTION> THE UNIVERSITY OF TEXAS AT ARLINGTON; 2502 </INSTITUTION>
<DESCRIPTORS> ENGINEERING, ELECTRONICS AND ELECTRICAL; COMPUTER SCIENCE; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> F. L. LEWIS </ADVISER>
<CLASSIFICATIONS> NIL </CLASSIFICATIONS>
<ABSTRACT>
This dissertation focuses on two major topics: control
of a class of nonlinear systems with known dynamics and
the control of systems with unknown dynamics.
Specifically in the first part of this work, a
systematic approach for modeling and base motion control
of a mobile base with an onboard robot arm is presented.
Feedback linearization is used to take into account the
complete dynamics with nonholonomic constraints, yet
methods from potential field theory are incorporated to
provide resolution among possibly conflicting
performance goals (e.g. path following and obstacle
avoidance). The feedback linearization provides an inner
loop that accounts for possible motion of the onboard
arm. A rigorous yet simple approach to motion planning
through optimization techniques is then presented for
these mobile vehicles. The resulting Cartesian
trajectory generated from the motion planning algorithm
is employed as the reference trajectory in the outer
loop, which is designed based on a Lyapunov function
candidate. The net result is a base motion controller
that enables these mobile vehicles to track a Cartesian
trajectory with a desired final orientation (docking
angle) and provides the necessary intelligence to avoid
any static obstacles by using a simple correction term
generated from a potential function.
In the second part of this work a family of novel
learning algorithms is proposed for the control of multi-
input and multi-output (MIMO) unknown nonlinear
dynamical systems by employing neural networks (NN). The
structure of the NN controller is derived using a
filtered error/passivity approach. For guaranteed
stability, it is shown that the learning rate parameter
in the case of the delta rule should decrease with the
number of hidden-layer neurons. The notion of
persistency of excitation (PE) for a multilayer NN is
defined and explored. New on-line weight tuning
algorithms are developed that do not need the
persistency of excitation condition. The notions of
discrete-time "passive NN" and "robust NN" are
introduced. These multilayer NN weight tuning algorithms
are extended for the Model Reference Adaptive Control
(MRAC) of a class of nonlinear systems. Finally, the
identification using NN of a class of nonlinear
dynamical systems is discussed.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  2429 </NUMBER>
<ORDER>   AAI9521843 </ORDER>
<TITLE> LEARNING SITUATIONAL KNOWLEDGE THROUGH OBSERVATION OF EXPERT PERFORMANCE IN A SIMULATION-BASED ENVIRONMENT </TITLE>
<AUTHOR> SIDANI, TAHA ABDULLAH </AUTHOR>
<YEAR> 1994 </YEAR>
<INSTITUTION> UNIVERSITY OF CENTRAL FLORIDA; 0705 </INSTITUTION>
<DESCRIPTORS> ENGINEERING, ELECTRONICS AND ELECTRICAL; COMPUTER SCIENCE; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> AVELINO J. GONZALEZ </ADVISER>
<CLASSIFICATIONS> NEURAL NETWORKS </CLASSIFICATIONS>
<ABSTRACT>
Incorporating intelligence in the computer has been the
aim of many research projects in Artificial
Intelligence. The degree of intelligence implemented
into the computer is highly dependent upon the amount of
knowledge possessed by experts in the field and the
efficiency and effectiveness of transferring this
expertise from man to machine. Research in knowledge
acquisition has reduced the effort involved in acquiring
knowledge from the expert. However, most knowledge
acquisition approaches focus on capturing the expert
explicit knowledge and ignore the implicit expertise
altogether. The focus of this research was to capture
and model the implicit knowledge that is commonly
applied by experts while dealing with a dynamic real-
life situation. This effort resulted in the design of a
methodology based on learning by observation. The
approach modularizes the implicit primitive expert
knowledge as a finite group of skills that can be
observed and learned using neural network. Furthermore,
a global symbolic reasoner which applied high level
symbolic knowledge was designed for assessing the
overall situation.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  2430 </NUMBER>
<ORDER>   AAI9521841 </ORDER>
<TITLE> AN AUTOMATED KNOWLEDGE ELICITATION ARCHETYPE FOR AN INTELLIGENT INDIVIDUALIZED INSTRUCTION SYSTEM </TITLE>
<AUTHOR> JUNG, NAMHO </AUTHOR>
<YEAR> 1994 </YEAR>
<INSTITUTION> UNIVERSITY OF CENTRAL FLORIDA; 0705 </INSTITUTION>
<DESCRIPTORS> ENGINEERING, INDUSTRIAL; COMPUTER SCIENCE; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> JOHN E. BIEGEL </ADVISER>
<CLASSIFICATIONS> MACHINE LEARNING, NATURAL LANGUAGE </CLASSIFICATIONS>
<ABSTRACT>
The Automated Knowledge Elicitation Archetype (AKEA) is
a knowledge acquisition methodology that automatically
builds a flexible knowledge base for an Intelligent
Individualized Instruction (I$sp3$) system. The I$sp3$
system is a Dynamic Intelligent Teaching System (DITS)
that provides a student with individualized instruction
to attain competency in a particular subject area. The
I$sp3$ system is a generic knowledge based system that
separates domain independent knowledge from domain
dependent knowledge that can be applied to several
domains by providing the domain dependent knowledge.
AKEA builds this necessary knowledge for problem solving
from existing cases such as a set of problem statements
and their numeric answers.
AKEA builds a problem-solving knowledge base that is
capable of interpreting and solving problems in the
domain. The knowledge base generated by AKEA is flexible
enough to be used when it is either open (for adding new
knowledge) or closed (for use). The premise of the open
system is an ability to add knowledge incrementally--
expanding the problem-solving capabilities without
recompiling the existing knowledge. As an open knowledge
base under the AKEA environment, it is able to receive
new knowledge at any time. Similarly, AKEA provides a
closed environment so that the currently available
knowledge base can be used even if it is not complete.
AKEA enables a knowledge base system to be used before
or during the knowledge acquisition process; a user does
not have to wait until all knowledge is extracted before
using the system.
AKEA acquires the domain knowledge automatically. The
inputs are the existing cases. AKEA reads the problem
statements from a file, builds the domain knowledge, and
saves it in its knowledge base. AKEA acquires domain
knowledge efficiently: it uses computer time, not a
domain expert's. The knowledge generated is available
immediately so that the AKEA application system could
use it for solving follow-on problems.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  2431 </NUMBER>
<ORDER>   AAI9521783 </ORDER>
<TITLE> NEURAL NETWORKS FOR NDE SIGNAL CLASSIFICATION </TITLE>
<AUTHOR> OKURE, MACKAY A. E. </AUTHOR>
<YEAR> 1994 </YEAR>
<INSTITUTION> NORTHWESTERN UNIVERSITY; 0163 </INSTITUTION>
<DESCRIPTORS> ENGINEERING, MECHANICAL; COMPUTER SCIENCE; ENGINEERING, ELECTRONICS AND ELECTRICAL; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> NIL </ADVISER>
<CLASSIFICATIONS> NIL </CLASSIFICATIONS>
<ABSTRACT>
Nondestructive evaluation (NDE) applications may be
characterized by noisy data, less-than-perfect detection
and a serious problem of false alarm indications. This
thesis addresses some of the fundamental problems
encountered in the development of neural networks for
NDE applications. Such neural networks would possess the
capacity to associate waveforms generated in NDE
equipment with the presence of flaws in components being
inspected. Their adoption would help alleviate operator
fatigue, one of the most vexing problems of human
inspection.
I collected real-world NDE data from a semi-automatic
eddy current machine used for inspecting aircraft
wheels. The wheels, having been removed for maintenance,
serve as an almost ideal example of the high potential
benefit from an intelligent automation system. I adopt
the multilayer feedforward neural network architecture
and a variation of the well-known backpropagation
algorithm to develop and train neural networks to
distinguish between flaw and normal signatures. I
develop the relative operating characteristic (ROC)
curve for objectively assessing and comparing the
efficacy of the resulting neural network with a
threshold-based method similar to the one in current
use. I show that preprocessing the transient data using
the wavelet transform and then analyzing it by a neural
network can significantly improve performance.
The phenomenon of over-training arising from monitoring
of performance of a neural network during training is
also studied. Both its incidence and origin are shown
using two-dimensional computer-generated data to enable
appropriate visualization. It is shown that over-
training occurs when a classification boundary takes a
severely distorted shape, from an otherwise optimal one,
to accommodate sometimes few and isolated large errors
in classification. Its dependence on the number of
patterns in the training data set and the number of
units in the network is demonstrated. It is shown that
fewer training patterns and increased number of units
increase the severity of classification boundary
distortion.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  2432 </NUMBER>
<ORDER>   AAI9521750 </ORDER>
<TITLE> THREE-DIMENSIONAL OBJECT IDENTIFICATION SYSTEM USING ARTIFICIAL NEURAL NETWORKS </TITLE>
<AUTHOR> LEE, JAEYOUNG </AUTHOR>
<YEAR> 1994 </YEAR>
<INSTITUTION> NORTHWESTERN UNIVERSITY; 0163 </INSTITUTION>
<DESCRIPTORS> COMPUTER SCIENCE; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> CHI-HAUR WU </ADVISER>
<CLASSIFICATIONS> NIL </CLASSIFICATIONS>
<ABSTRACT>
A new model-based three-dimensional object
identification system using artificial neural networks
is proposed in this dissertation. The proposed system
consists of three parts: the geometric modeler, the
aspect matcher and the aspect categorizer. The geometric
modeler will build automatically three-dimensional
identification model and two-dimensional input aspect
description from a given CAD model and lower level image
features. Topological information is also extracted and
added to this model and description. Then, the aspect
matcher will create and use the local compatibility
table in guiding the process to find the matching faces
in an input aspect and a three-dimensional object model.
The matching is done on the modified Hopfield neural
network. The aspect matcher also generates the invariant
area patterns from matched faces. At the final stage,
the aspect categorizer will accept the invariant area
pattern and categorize the aspect viewing positions to
store the aspect information of the identified object.
To classify and store the aspect category, a modified
ART-style neural network is applied. The important
properties of the proposed identification system are
automatic creation of identification model, invariant
mapping of visible face area pattern and real time
identification, learning and estimation of aspect
categories.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  2433 </NUMBER>
<ORDER>   AAI9521749 </ORDER>
<TITLE> ON DISTRIBUTED DETECTION WITH APPLICATIONS TO SPEAKER VERIFICATION </TITLE>
<AUTHOR> LEE, CHUNG-TSHUY </AUTHOR>
<YEAR> 1994 </YEAR>
<INSTITUTION> NORTHWESTERN UNIVERSITY; 0163 </INSTITUTION>
<DESCRIPTORS> ENGINEERING, ELECTRONICS AND ELECTRICAL; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> CHUNG-CHIEH LEE </ADVISER>
<CLASSIFICATIONS> NIL </CLASSIFICATIONS>
<ABSTRACT>
This work deals with a decision-theoretic approach to
speaker verification which involves using spoken
utterance(s) to verify the speaker's identity. The
objective is a robust speaker verification system whose
performance degradation due to temporal variations in
each speaker's speech characteristics is minimal. In the
training phase, essential features of speech signal
including cepstral and $Delta$-cepstral parameters are
extracted from the speech utterances spoken by a
speaker. A multimode statistical model is used to
characterize these parameters and to represent this
speaker's identity and is referred to as the speaker
model. The proposed speaker model enables us to use a
distributed decision network approach to decision rule
design. By using a telephone-line based speech database,
we show that the combination of the novel speaker model
and distributed decision rules yields superior speaker
verification performance and superior robustness with
respect to model variations.
We also study a distributed multiple hypothesis
detection problem where uncertainties exist in the local
decision makers. We assume that the local decision rules
are fixed and therefore characterize each local decision-
maker by its performance characteristics. We then
address the robustness problem at the decision fusion
level and study several decision fusion rules. We
conclude that the decision fusion rule derived based on
Dempster-Shafer's belief function discounting
outperforms all the others when uncertainties do exist
in local decisions.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  2434 </NUMBER>
<ORDER>   AAI9521657 </ORDER>
<TITLE> EXPLANATION-MEDIATED VISION:  MAKING SENSE OF THE WORLD THROUGH CAUSAL ANALYSIS </TITLE>
<AUTHOR> BRAND, MATTHEW ELY </AUTHOR>
<YEAR> 1994 </YEAR>
<INSTITUTION> NORTHWESTERN UNIVERSITY; 0163 </INSTITUTION>
<DESCRIPTORS> COMPUTER SCIENCE; PSYCHOLOGY, GENERAL; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> ERIC ROSKAMP </ADVISER>
<CLASSIFICATIONS> NIL </CLASSIFICATIONS>
<ABSTRACT>
A long-standing and widely acknowledged problem in
artificial intelligence is the dissociation of
perception and cognition. This dissociation has led, on
one hand, to cognitive models that bear uncertain
relation to the problems of purposefully interacting
with the world, and on the other hand to perceptual
algorithms that produce data whose meaning and relevance
is usually unknown, if considered at all.
In this thesis I argue that the key to integrating
perception and cognition is the development of good
domain models of the perceptual world, describing the
causality of the physical world, how that causality is
manifest in the activity of the senses, and how special
aspects of that causality are privileged as
"functional," or goal-related.
To support this argument I describe a number of
artificial vision systems in which "perceptual" and
"cognitive" computations interact and constrain each
other via causal-perceptual models. These systems
produce meaningful explanations of the internal dynamics
of scenes. These explanations support a variety of high-
level intelligent behaviors, including planning, robotic
manipulation, and design evaluation. In the course of
scene analysis, these systems use functional and causal
anomalies in ongoing explanations to generate visual
queries, thus providing control of focus of attention in
low-level visual processing. The causal models employed
by these systems are relatively small, but sufficiently
powerful to generate explanations of highly complex
structures. Much of these models can be recycled between
visually disparate domains, suggesting wide generality.
Given the success of these models, I consider the
prospects for a cognitive psychology of vision, in which
the knowledge that drives human visual understanding can
be captured, formalized, and deployed in machines.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  2435 </NUMBER>
<ORDER>   AAI9521606 </ORDER>
<TITLE> EFFICIENT EVALUATION OF NORMAL LOGIC PROGRAMS </TITLE>
<AUTHOR> SWIFT, TERRANCE LEE </AUTHOR>
<YEAR> 1994 </YEAR>
<INSTITUTION> STATE UNIVERSITY OF NEW YORK AT STONY BROOK; 0771 </INSTITUTION>
<DESCRIPTORS> COMPUTER SCIENCE </DESCRIPTORS>
<ADVISER> DAVID S. WARREN </ADVISER>
<CLASSIFICATIONS> DEDUCTIVE DATABASE </CLASSIFICATIONS>
<ABSTRACT>
An accident of implementation may be responsible for the
fact that Logic Programming, Deductive Databases and Non-
Monotonic Reasoning are different subfields. Logic
Programming views logic as a programming language--
usually through Prolog or an extension of Prolog. The
Deductive Database community regards logic as a database
language, often using a variant of magic sets as a basis
for implementation. Finally the field of Non-Monotonic
Reasoning studies non-classical logics of interest to
Artificial Intelligence or other applications. However,
there are currently few engines powerful enough to
execute practical programs in Non-Monotonic Reasoning.
Tabling methods have been formulated recently that have
the potential to unify these subfields. This thesis
explores how to efficiently implement one such method:
SLG.
Previous formulations of SLG do not make explicit the
search strategy for an evaluation, or consider trade-
offs between alternate search strategies. To bring out
these features, an operational semantics for SLG,
SLG$sb0O$, is defined which makes explicit algorithms
for completion and other operations. This formalism
allows proofs of correctness of algorithms upon which
the SLG-WAM is based, as well as proofs of termination
for programs of bounded-term size. The modelling of
search strategy is powerful enough to derive preliminary
results for the cut/O operator as extended to SLG, and
for combining SLG and SLDNF using Existential Negation.
Based on the SLG$sb0O$ search strategy, Part 2 describes
the SLG-WAM, an engine which evaluates SLG for
stationary stratified programs, and integrates SLG with
full Prolog functionality, including the cut, findall,
and meta-predicates. Data structures and instructions of
the SLG-WAM are described in detail. The SLG-WAM is in
fact the engine for the XSB system, and has been
installed in hundreds of sites around the world.
Part three analyzes the SLG-WAM and compares its
performance with the WAM and with other deductive
databases. When executing queries using SLD, the
overhead of SLG to the WAM is about 10-15% on some
standard benchmarks. At the same time, the SLG-WAM is an
order of magnitude faster than current deductive
databases for in-memory queries. These results are
analyzed in detail, and areas for further optimization
are identified.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  2436 </NUMBER>
<ORDER>   AAGC507967 </ORDER>
<TITLE> LA DETECTION CENTRALISEE DES FUITES SUR LES RESEAUX D'EAU POTABLE PAR RESEAUX DE NEURONES; CENTRALIZED LEAKAGE DETECTION ON WATER DISTRIBUTION SYSTEMS WITH NEURAL NETWORKS </TITLE>
<AUTHOR> BISSERY, CHRISTOPHE </AUTHOR>
<YEAR> 1994 </YEAR>
<INSTITUTION> INSTITUT NATIONAL DES SCIENCES APPLIQUEES DE LYON (FRANCE); 5285 </INSTITUTION>
<DESCRIPTORS> ENGINEERING, CIVIL; ENGINEERING, SYSTEM SCIENCE; ARTIFICIAL INTELLIGENCE AVENUE ALBERT EINSTEIN, F-69621  VILLEURBANNE CEDEX, FRANCE </DESCRIPTORS>
<ADVISER> NIL </ADVISER>
<CLASSIFICATIONS> NIL </CLASSIFICATIONS>
<ABSTRACT>
On assiste depuis quelques annees, sous la pression de
l'environnement, a un changement de perception du risque
de dysfonctionnement des systemes techniques et en
particulier des reseaux d'eau potable. Le risque nul
n'existe pas et il faut donc apprendre a le gerer. C'est
dans ce cadre qu'emerge le besoin de detection
centralisee des fuites sur les reseaux d'eau potable,
les fuites qui representent une part importante du
risque de dysfonctionnement de la distribution d'eau.
Ce travail de recherche propose un systeme de detection
centralisee des fuites sur les reseaux d'eau potable a
base de reseaux de neurones. On y etudie en particulier
des methodologies de construction des bases
d'apprentissage et de localisation des capteurs qui
permettent un passage simple de l'experimentation a la
detection en site reel.
Ce travail a permis de constater que sur modele
hydraulique de reseau reel, le systeme de detection a
base de reseaux de neurones permettait d'obtenir des
resultats en detection qui justifiaient d'une mise en
place reelle. L'etude s'acheve sur une definition des
priorites d'etude pour permettre cette mise en place sur
site reel (en particulier, les besoins de prevision de
consommation horaire).
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  2437 </NUMBER>
<ORDER>   AAI9521540 </ORDER>
<TITLE> FUNCTION APPROXIMATION AND LEARNING BY NEURAL NETWORKS </TITLE>
<AUTHOR> DASGUPTA, BHASKAR </AUTHOR>
<YEAR> 1994 </YEAR>
<INSTITUTION> UNIVERSITY OF MINNESOTA; 0130 </INSTITUTION>
<DESCRIPTORS> COMPUTER SCIENCE; MATHEMATICS; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> NIL </ADVISER>
<CLASSIFICATIONS> NIL </CLASSIFICATIONS>
<ABSTRACT>
In this thesis we consider efficiency of neural networks
in terms of approximation and learning of arbitrary
functions. Neural networks are a class of parallel
computation models which have been widely used in
solving combinatorial optimization and various other
problems. Our purpose is to investigate how efficient
some of these computation models are in terms of
approximation and learning of various functions.
In the first part of the thesis we compare different
gate functions in terms of the approximation power of
their neural networks. Evaluation criteria are circuit
size s, circuit depth d and the approximation error
$e(s,d).$ We consider two different error models, namely
"extremely tight" approximations (i.e. $e(s,d) = 2sp0-
s)$ and the "more relaxed" approximations (i.e. $e(s,d)
= ssp0-d).$ Our goal is to determine those gate
functions that are equivalent to the standard sigmoid
$sigma(x) = 01over1 + exp(-x)$ under these two error
models. For error $e(s,d) = 2sp0-s,$ the class of
equivalent gate functions contains, among others, (non-
polynomial) rational functions, (non-polynomial) roots
and most radial basis functions. Newman's approximation
of $vert xvert$ by rational functions is obtained as a
corollary of this equivalence result. Probably not
equivalent are polynomials, the sine-function and linear
splines. For error $e(s,d) = ssp0-d$ the class of
equivalent activation functions grows considerably,
containing for instance linear splines, polynomials and
the sine-function.
In the second part of the thesis we deal with
computational issues of loading a fixed-architecture
neural network with a set of positive and negative
examples. This is the first result on the hardness of
loading a simple 3-node architecture which do not
consist of the binary-threshold neurons, but rather
utilize a particular continuous activation function,
commonly used in the neural network literature. Our
theoretical results lend further suggestion to the use
of incremental (architecture-changing) techniques for
training networks rather than fixed architectures.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  2438 </NUMBER>
<ORDER>   AAI9521473 </ORDER>
<TITLE> DISCRETE COMPUTATION IN THE CONTINUUM </TITLE>
<AUTHOR> BARTLETT, RONALD EVERETT </AUTHOR>
<YEAR> 1994 </YEAR>
<INSTITUTION> THE UNIVERSITY OF MEMPHIS; 1194 </INSTITUTION>
<DESCRIPTORS> COMPUTER SCIENCE; MATHEMATICS; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> NIL </ADVISER>
<CLASSIFICATIONS> NEURAL NETWORK, CELLULAR AUTOMATA, CANTOR SET </CLASSIFICATIONS>
<ABSTRACT>
This thesis is a two-part study of the computational
properties of dynamical systems. Part I studies the
computability properties of piecewise linear and
piecewise monotone maps of the real interval. Part II is
concerned with the computability properties of cellular
automata mappings.
The major new contributions of Part I are: (1) A
construction of a piecewise linear map semi-conjugate to
a nontrivial pushdown automaton. (2) The construction of
a recursive homomorphism between the attractor-basin
portrait of a given halting Turing machine and that of
an appropriately chosen tent map. (3) A construction of
a computation universal monotone map that is also
capable of simulating the fixed-point behavior of any
cellular automaton, discrete neural network, general
automata network, and moreover, any continuous self-map
of the Cantor set.
The major new results of Part II are: (1) One-
dimensional bilinear cellular automata over Z$sbsp0p0p$
are $pi$-universal, i.e. capable of simulating any one
dimensional cellular automaton. (2) A phenomenological
classification of quadric cellular automata over
Z$sb0m.$ (3) Constructions of a 4$sp0th$ degree
polynomial over Z$sb6$ for Bank's Computer, a
computation universal cellular automaton, and a 5$sp0th$
degree polynomial over Z$sb032$ for the Billiard Ball
Model, a computation universal reversible cellular
automaton.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  2439 </NUMBER>
<ORDER>   AAI9521138 </ORDER>
<TITLE> A THEORY OF GENERALIZATION IN LEARNING MACHINES WITH NEURAL NETWORK APPLICATIONS </TITLE>
<AUTHOR> WANG, CHANGFENG </AUTHOR>
<YEAR> 1994 </YEAR>
<INSTITUTION> UNIVERSITY OF PENNSYLVANIA; 0175 </INSTITUTION>
<DESCRIPTORS> COMPUTER SCIENCE; ENGINEERING, ELECTRONICS AND ELECTRICAL; STATISTICS; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> SATOSH S. VENKATESH </ADVISER>
<CLASSIFICATIONS> NIL </CLASSIFICATIONS>
<ABSTRACT>
This thesis presents a new theory of generalization in
neural network types of learning machines. The new
theory can be viewed as a refinement of the decision
theoretical framework of learning based on the uniform
weak law in probability theory (i.e., the VC-method),
and leads to a finer degree of approximation hitherto
available. The role played by the VC-theory in studying
learning problems becomes evident in the new framework.
Indeed, the intrinsic limitation of the VC-theory in
assessment of generalization error is demonstrated. The
focus is on assessment and improvement of generalization
performance when there is only a finite number of
examples. In a unified framework, the theory provides
systematic answers to the problems of learnability,
assessment of generalization error, temporal dynamics of
generalization, and design of machine complexity. Under
conditions weaker than those required for distribution-
free (or Probably Approximately Correct learning), it
proves a kind of learnability for both fixed and varying
machine structures, and gives rates of growth of machine
size for attaining learnability in the latter case. The
theory introduces a new method for assessing the
generalization performance, and obtains estimates of the
generalization error in both post-training and during
the training process for general linear and nonlinear
machines. These results contribute to the problem of how
generalization error is related to the number of
examples and machine complexity, and provide answers to
the open problems of when learning should be stopped and
how the complexity of the machine affects the
generalization error during the training process; thus
providing a precise language for describing the over-
training phenomenon. The results on generalization error
estimation lead to criteria for choosing correct size of
machines and optimal stopping time simultaneously so
that near optimal generalization performance is
attained. These criteria find connections with the
Akaike's Information Criterion and Minimal Description
Length Principle for machine size selection, and shed
light on the properties of the latter. The effects of
regularization on the generalization error as well as
the relation between regularization and early stopping
are analyzed. These results in turn provide guidelines
for choosing the regularization function. The results of
this thesis are relevant to problems of regression,
pattern recognition, statistical function estimation,
and stochastic approximation.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  2440 </NUMBER>
<ORDER>   AAI9521067 </ORDER>
<TITLE> SYNCHRONICITY AND COHERENCE IN ARTIFICIAL NEURAL NETWORKS </TITLE>
<AUTHOR> LIN, SHENG-YUAN </AUTHOR>
<YEAR> 1994 </YEAR>
<INSTITUTION> UNIVERSITY OF PENNSYLVANIA; 0175 </INSTITUTION>
<DESCRIPTORS> ENGINEERING, ELECTRONICS AND ELECTRICAL; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> NABIL H. FARHAT </ADVISER>
<CLASSIFICATIONS> NIL </CLASSIFICATIONS>
<ABSTRACT>
This dissertation describes a new model and a new
approach to study the dynamics of artificial neural
networks. In traditional artificial neural network
research, the formal neuron model is adopted, which
takes the average frequency of the action potential
pulses as the only relevant information. There is
evidence that the time information does play an
important role in neural computation, and that
biological neural networks exhibit very complex
dynamics. The complexity of neural dynamics include
phase-locking, quasi-periodic firing, chaotic firing,
and bifurcations due to change in the parameters of the
neurons.
A new neuron model called the Programmable Unijunction
Oscillator Neuron (PUTON) capable of providing the
complexities mentioned above is developed. The PUTON is
structurally simple, has low power consumption, and can
be described by simple mathematics. The complexity of
the PUTON when driven by a periodic (sinusoidal) signal
is demonstrated via bifurcation diagrams and several
metrics of the dynamics. Analog electronic circuits
implementation of the PUTON are developed, and opto-
electronical realization are demonstrated.
A novel method to characterize the dynamics of the PUTON
is developed. The method focuses on the phase
information of the pulses fired by the neurons. The
phase is measured relative to the periodic driving
signal. The continuous time dynamics of the PUTON when
driven by a periodic signal is transformed to a discrete
one-dimensional map. Mathematical analyses are used to
prove that the system can exhibit chaotic dynamics under
certain conditions. The characteristics of the model
neurons studied are obtained in great detail. The
results of experiments and simulations are presented and
shown to be in excellent agreement.
A network of 32 PUTONs coupling through a Synapse Chip
provided by the JPL is built to demonstrate phase-
locking in a pulsed neural network. Methods of
characterizing the performance of such a network are
explored. The phase-locking capability of the network
suggests potential for solving optimization problems
like the TSP rapidly. The research work presented in
this dissertation provides the foundation for a new
generation of neural network hardware, in which
complexity, bifurcation and chaos on the neuron level
may be exploited to achieve higher-level functions.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  2441 </NUMBER>
<ORDER>   AAI9521020 </ORDER>
<TITLE> TEMPORAL CONSIDERATIONS AND COHERENCE IN NEURAL NETWORKS </TITLE>
<AUTHOR> ELDEFRAWY, MOSTAFA HASSIB </AUTHOR>
<YEAR> 1994 </YEAR>
<INSTITUTION> UNIVERSITY OF PENNSYLVANIA; 0175 </INSTITUTION>
<DESCRIPTORS> ENGINEERING, ELECTRONICS AND ELECTRICAL; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> NIL </ADVISER>
<CLASSIFICATIONS> CIRCLE MAPS </CLASSIFICATIONS>
<ABSTRACT>
We investigated novel artificial model neurons with
similar capabilities to the biological neuron's various
firing modalities. Such neurons can encode their
stimulus particularly when it is periodic in the form of
phase-locked firing, bursting, and chaotic firing, which
could underlie certain forms of neural computations.
Model neurons were investigated, and the integrate-and-
fire model neuron was then adopted for investigation and
implementation because of its structural simplicity, and
complex rich firing modalities, under periodic stimulus.
Periodic stimulus is thought to emerge via coherent
neural activities or the firing of synchronized coupled
neuron populations (networks), which are then received
and processed by the neuron via its synapto-dendritic
processes. The periodically driven integrate-and-fire
model neuron was implemented as a simple relaxation
oscillator circuit utilizing the S-shaped nonlinearity
of a glow-lamp that represented the biological neuron's
excitable membrane characteristics. This model neuron's
firing modalities under sinusoidal stimulus was then
characterized using: first, instantaneous frequency
measurements and numerical simulations, where for the
first time such measurements were performed using a
sophisticated "Frequency and Interval Time Analyzer",
which showed the neuron to exhibit phase-locking,
bursting, and erratic firing behavior and enabled
representing its behavior in the form of bifurcation
diagrams. Second, concepts and tools from the theory of
nonlinear dynamics were used to predict the neuron's
behavior via phase transition maps (PTMs) that were
analytically derived and numerically computed because of
the transcendental nature of the PTM equations. A new
modified integrate-and-fire neuron was then developed
which resulted in an analytical closed form expression
for the PTM that turned out to be the well studied
"circle map" which is known to exhibit chaos for certain
ranges of its parameter space. This is significant
because, first, since the circle map expression provides
instant description of the neuron's behavior for any
chosen set of the neuron's and driving signal's
parameters, a big saving in computing resources compared
to the numerically produced phase transition maps is
achieved. Second, now it is possible to implement the
circle map in Silicon using a simple circuit that is
also able to generate chaos, which could be useful for
annealing applications. The collective computing
capabilities of the brain are thought to be due to
coherent firing or synchronization of distant neurons,
suggesting that synchronization underlies feature
linking abilities in the visual cortex. Thus, we studied
synchronization in arrays of coupled integrate-and-fire
neurons, using hardware experimentation as well as
computer modeling and numerical simulation.
Synchronization in coupled integrate-and-fire neurons
was then explored in solving the travelling salesman
problem, a well known NP-complete optimization problem,
resulting in the development of a heuristic "random
deletions" algorithm that outperformed other known
heuristic optimization techniques, as applied to the
traveling salesman problem. The algorithm seems to use
chaos to randomly search the solution space in order to
achieve annealing and find an optimum solution. We found
three auditory perception tasks to be suitable for
possible implementation using this model neuron. This
work suggests that artificial neural networks employing
functionally complex processing elements like the
integrate-and-fire bifurcating neuron studied here,
could provide functional capabilities in neural networks
that are beyond the capabilities of present day neural
networks, especially in the performance of higher level
functions like feature binding, cognition, and efficient
solution of optimization problems. (Abstract shortened
by UMI.)
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  2442 </NUMBER>
<ORDER>   AAI9520203 </ORDER>
<TITLE> THE MULTI-LINK NEURAL NETWORK MODEL </TITLE>
<AUTHOR> LANG, ZHENGPING </AUTHOR>
<YEAR> 1994 </YEAR>
<INSTITUTION> MEDICAL UNIVERSITY OF SOUTH CAROLINA; 0122 </INSTITUTION>
<DESCRIPTORS> ENGINEERING, SYSTEM SCIENCE; ENGINEERING, BIOMEDICAL; COMPUTER SCIENCE; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> ZHEN ZHANG </ADVISER>
<CLASSIFICATIONS> FEEDFORWARD, PATTERN RECOGNITION </CLASSIFICATIONS>
<ABSTRACT>
Neural networks have been increasingly applied to both
basic biomedical research and clinical studies.
Nonlinear optimization problems like the identification
of auditory threshold response are very difficult to
solve due to the lack of theoretical support for any
arbitrarily nonlinear analysis. Experimental analysis
based on some analytical models and their associated
computational algorithms normally provides a local
solution to these optimization problems. With its more
flexible architecture and more powerful learning
capability, neural network could provide a better
solution to these problems.
We present a new neural network architecture based on
the Multi-Link Neural Network (MLNN) model. An MLNN has
a structure similar to that of a feedforward network
except that each connection between a pair of nodes in
the hidden layer and the output layer is made of
multiple links with possibly different weight values.
This results in an aggregation of a combinatorial number
of subnets that themselves can be viewed as ordinary
feedforward networks. The overall connection status of
an MLNN with M hidden nodes, N output nodes, and K links
for each connection, is represented as an M $times$ N
dimensional region with K$sp0Mtimes N$ sampling points
in the weight space. The multi-link structure defines a
sampling grid over this region.
A region-based search algorithm has been developed that,
for problems of a complex nature, offers a better chance
in locating a global minimum than the traditional
backpropagation algorithm. This is directly due to the
flexible and coordinated use of global information
provided by the multi-link structure during the training
process. In order to reduce the computational complexity
introduced by the added links, an adaptive training
control scheme based on a global temperature parameter
has been built into the search algorithm. This results
in a fast convergence speed.
Correspondence between the training process and the
motion dynamics of the sampling grid has been
established through a geometrically based network
analysis. It has been shown geometrically that (1) the
training for one iteration has the equivalent effect of
Window-Sizing the sampling grid; (2) the local
optimization has the effect of adapting the sampling
grid in order to best reflect the local geometry of the
error surface; (3) the sampling grid moves along the
direction of the vector summed by all the gradients of
the points on the sampling grid. The last result can be
further extended to the continuous case where
convergence is guaranteed for a class of the so-called
$lambda$-difference functions.
Results from nonlinear pattern recognition problems,
such as parity-checking and numerical-digit
classification as well as a practical application to the
identification of animal auditory threshold response
recorded as evoked potential signals, have demonstrated
the effectiveness of the MLNN model and its associated
region-based search algorithm.
The MLNN model can be applied to areas similar to that
of the traditional feedforward neural networks. However,
it is more suitable for problems with complex solution
spaces. One obvious application of the multi-link
principle is in the field of solving some general
parametric estimation problems which can be easily
transformed into a multi-link framework.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  2443 </NUMBER>
<ORDER>   AAI9518794 </ORDER>
<TITLE> MULTI-SENSOR INTEGRATION FOR INTELLIGENT CONTROL OF MACHINING THROUGH ARTIFICIAL NEURAL NETWORKS AND FUZZY MODELLING </TITLE>
<AUTHOR> KUO, REN-JIEH </AUTHOR>
<YEAR> 1994 </YEAR>
<INSTITUTION> THE PENNSYLVANIA STATE UNIVERSITY; 0176 </INSTITUTION>
<DESCRIPTORS> ENGINEERING, INDUSTRIAL; COMPUTER SCIENCE; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> PAUL H. COHEN </ADVISER>
<CLASSIFICATIONS> NIL </CLASSIFICATIONS>
<ABSTRACT>
Wear of the cutting tool is an inevitable result of the
metal cutting process. Since undesirable effects of tool
wear include: (1) a loss in dimensional accuracy of the
finished product and (2) a possible damage to the
workpiece, it is very important to develop a system
which is able to on-line monitor the amount of tool wear
for precision flexible manufacturing systems.
Unfortunately, most of the methods developed only
concern two or three wear states instead of the
continuous amount of tool flank wear. Thus, this thesis
develops an on-line estimation system, which consists of
four parts in series: data acquisition, feature
extraction, pattern recognition, and multi-sensor
integration, to predict the continuous amount of tool
wear.
The first part of the system employs a dynamometer to
measure forces in the feed, radial, and main cutting
directions, accelerometers for vibrations in feed and
main cutting directions, and an acoustic emission
sensor. The second part extracts the features from the
sensor data obtained through time series and frequency
analyzers. Thereafter, these features are learned by
artificial neural networks (ANNs) with error
backpropagation (EBP) learning algorithm. The EBP
learning algorithm is improved by using three fuzzy
models to dynamically update the training parameters,
training rate, momentum, and steepness of activation
function. Finally, the decision of each sensor is
integrated via a multi-sensor integration method called
self-organization and self-adjusting fuzzy modeling
(SOSAFM). SOSAFM consists of two stages, self-organizing
stage (SOS) and self-adjusting stage (SAS). In SOS,
Kohonen's feature mapping divides the training samples
into several groups, and membership functions and
regression model are found for each group. Then the
parameters of membership functions and regression models
are fine-tuned by EBP-type learning algorithm in SAS.
The results in the machining of SAE 6150 alloy steel
with K68 grade tungsten-carbide inserts show that SOSAFM
can provide significantly better prediction compared
with ANN and multiple regression. Also, the training
speed of standard EBP is accelerated by dynamically
updating the training parameters. In addition, the
profile of workpiece is improved after being adjusted by
amount of flank wear.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  2444 </NUMBER>
<ORDER>   AAI9513328 </ORDER>
<TITLE> CONSOLIDATION AND LEARNING: A CONNECTIONIST MODEL OF HUMAN CREDIT ASSIGNMENT </TITLE>
<AUTHOR> CHOWN, ERIC LANCE </AUTHOR>
<YEAR> 1994 </YEAR>
<INSTITUTION> THE UNIVERSITY OF MICHIGAN; 0127 </INSTITUTION>
<DESCRIPTORS> COMPUTER SCIENCE; ARTIFICIAL INTELLIGENCE; PSYCHOLOGY, GENERAL </DESCRIPTORS>
<ADVISER> STEPHEN KAPLAN </ADVISER>
<CLASSIFICATIONS> NIL </CLASSIFICATIONS>
<ABSTRACT>
This dissertation concerns the issue of human credit
assignment, particularly why some things are so easily
remembered while others are forgotten. The point of view
taken is an adaptive one: differences in the strength of
learning from situation to situation are seen as
reflections of the differences in the probable
importance of each situation. One difficulty with such
an approach is that it appears to imply that humans have
the ability to effectively evaluate importance--a
scenario which is often unlikely, especially in novel
domains. The alternative offered is that the human
cognitive architecture is sensitive to a variety of
generic situations, and that these sensitivities are
automatically reflected in learning.
Insight into these sensitivities is provided by an
examination of the consolidation process, a brief period
of transition during which memory is fixed or made
permanent. There is a large set of evidence linking
consolidation with the ultimate strength of learning.
Consolidation is modelled in this dissertation with
TRACE, a connectionist simulation based upon Hebb's cell
assembly construct. Learning in TRACE comes as the
result of correlated neural activity; factors which
influence such activity, therefore, will necessarily
impact learning. This provides the human cognitive
architecture with the sensitivity required by the
learning system.
One of the key factors which impacts consolidation is
arousal. The arousal level of an organism, in turn, is
sensitive to "important" events such as pleasure, pain
and confusion. The relationship between arousal and the
strength of learning is well known: When arousal is
high, learning is strong; when arousal is low, learning
is weak. Less well known is the impact of arousal on
short term performance. High levels of arousal have been
shown to result in "reminiscence," a situation where
performance improves over time without intervening
practice. In this case high levels of arousal actually
impair short term recall. This result is counter-
intuitive and until now has never been successfully
modelled. Reminiscence can be modelled in TRACE, and
within the context of a consolidation-based learning
system, the effects can also be shown to be adaptive.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  2445 </NUMBER>
<ORDER>   AAI9522554 </ORDER>
<TITLE> THE IMPACT OF A NATURAL LANGUAGE INTERFACE ON BARRIERS TO INFORMATION ACCESS </TITLE>
<AUTHOR> ROBERGE, LINDA </AUTHOR>
<YEAR> 1994 </YEAR>
<INSTITUTION> SYRACUSE UNIVERSITY; 0659 </INSTITUTION>
<DESCRIPTORS> BUSINESS ADMINISTRATION, MANAGEMENT; INFORMATION SCIENCE; JOURNALISM; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> NIL </ADVISER>
<CLASSIFICATIONS> MANAGEMENT INFORMATION SYSTEMS </CLASSIFICATIONS>
<ABSTRACT>
The electronic storage and retrieval of data has
revolutionized the availability of information. However,
availability and accessibility are not necessarily
synonymous. While the data might be there, many types of
barriers may prevent information retrieval. This study
investigates whether or not a Natural Language Interface
can reduce three types of information access barriers
for non-expert computer users.
The evaluation process used professional journalists who
were interested in computer assisted reporting, but who
had neither experience nor skills in that area. The
group using the Natural Language Interface (NLI) to
complete the evaluation task was able to ask
significantly more questions than the group using
Structured Query Language (SQL). Both groups spent
approximately the same amount of time analyzing the
data, and considered the same number of data fields in
the analysis. A larger percentage of the NLI group was
able to shift their attention away from how to ask the
questions and onto the information they were obtaining.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  2446 </NUMBER>
<ORDER>   AAGC507928 </ORDER>
<TITLE> CONCEPTION ET EVALUATION D'UN SYSTEME A BASE DE CONNAISSANCES D'AIDE A L'ELIMINATION DE DECHETS; DESIGN AND EVALUATION OF A KNOWLEDGE-BASED SYSTEM TO AID IN WASTE TREATMENT </TITLE>
<AUTHOR> SOARES, SEBASTIAO ROBERTO </AUTHOR>
<YEAR> 1994 </YEAR>
<INSTITUTION> INSTITUT NATIONAL DES SCIENCES APPLIQUEES DE LYON (FRANCE); 5285 </INSTITUTION>
<DESCRIPTORS> ENVIRONMENTAL SCIENCES; ENGINEERING, INDUSTRIAL; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> NIL </ADVISER>
<CLASSIFICATIONS> EXPERT SYSTEMS, INDUSTRIAL WASTE </CLASSIFICATIONS>
<ABSTRACT>
Le travail realise est relatif au developpement et a
l'utilisation de modeles elementaires de raisonnement
sur l'elimination de dechets industriels, en vue de
disposer d'un outil d'aide a la decision. La demarche
suivie est decomposee en trois etapes:
1. La premiere etape consiste a identifier, interpreter
et enchai ner les principales informations concernant
les filieres d'elimination de dechets (filieres
thermique, biologique, physico-chimique et enfouissement
technique), ainsi que leurs interactions. Elle consiste
en l'acquisition des connaissances necessaires sur les
differents traitements pour constituer des modeles de
raisonnement.
2. La deuxieme etape est consacree a la formalisation
des connaissances sous la forme de regles de production
et a leur automatisation.
Cette procedure est a l'origine de DECHAIDE, Systeme a
Base de Connaissances (scSBC) qui permet, a partir d'une
nombre restreint de parametres d'un dechet, d'orienter
celui-ci vers les filieres d'elimination techniquement
les plus adaptees.
3. Enfin, dans la derniere etape, DECHAIDE est evalue a
la fois sur le plan technique, pragmatique et subjectif.
Cette evaluation a permis de degager la coherence,
l'influence sur la performance de l'utilisateur et
certaines faiblesses de ce systeme. L'analyse du
comportement de DECHAIDE face a des situations reelles
d'elimination de dechets a permis de valider et
demontrer l'utilite pedagogique et technique des scSBC
dans un domaine multidisciplinaire comme celui de la
gestion de dechets.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  2447 </NUMBER>
<ORDER>   AAI9522467 </ORDER>
<TITLE> MODELING CONSUMER CHOICE: AN EXPERIMENTAL COMPARISON OF CONCEPT LEARNING SYSTEM, LOGIT, AND ARTIFICIAL NEURAL NETWORK MODELS </TITLE>
<AUTHOR> BLANKENSHIP, RAY JOSEPH </AUTHOR>
<YEAR> 1994 </YEAR>
<INSTITUTION> THE UNIVERSITY OF MISSISSIPPI; 0131 </INSTITUTION>
<DESCRIPTORS> BUSINESS ADMINISTRATION, MARKETING; STATISTICS; BIOLOGY, NEUROSCIENCE; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> JAMES H. BARNES, JR.; JOHN D. JOHNSON </ADVISER>
<CLASSIFICATIONS> NIL </CLASSIFICATIONS>
<ABSTRACT>
As the amount of information produced grows at an
astronomical rate, pressures on the Management
Information systems (MIS) function has also grown to not
only be able to store and retrieve volumes of data but
also to be able to apply methodologies to these data
that will capture the essence of information contained
therein. Thus, MIS has a responsibility to evaluate
different methodologies or information technologies as
they are developed and become available for use to
insure that the MIS function is meeting its
responsibility. It is this function of methodology
evaluation that serves as the primary goal of the
present research.
This research empirically compares the performance of
multi-layered feed-forward artificial neural networks
(MLFFNN) that use a genetic adaptive neural network
training (GANNT) algorithm against the backpropagation
training algorithm for MLFFNN, the Inductive
Dichotomizer 3 (ID3) algorithm, and a multinomial logit
model. These algorithms represent several prevalent
methods of machine learning in the literature. The
problem domain is in the area of modeling consumer
choice. This problem was chosen because ANNs seem to be
a natural solution for this problem.
A repeated measures or one-way within-subjects design
was used to empirically compare the performance of the
different machine learning algorithms in this research.
Results indicate that the GANNT algorithm is able to
significantly predict better than the backpropagation
algorithm and the "predicted" multinomial logit model.
The GANNT algorithm was also able to predict as well as
some other models reported in the literature. The
implications are that no a priori assumptions about the
data had to be made when using the GANNT algorithm. Only
the ID3 algorithm had significantly better hit ratios
than the other models compared in this research.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  2448 </NUMBER>
<ORDER>   AAIC421290 </ORDER>
<TITLE> ONTOLOGICAL AND GNOSEOLOGICAL PRESUPPOSITIONS OF SCIENCE IN THE WORKS OF STANLEY L. JAKI:  AN APPLICATION TO THE AI CONTROVERSY </TITLE>
<AUTHOR> VILLAJIN, NOEL MA. NIEGA </AUTHOR>
<YEAR> 1994 </YEAR>
<INSTITUTION> UNIVERSIDAD DE NAVARRA (SPAIN); 5864 </INSTITUTION>
<DESCRIPTORS> PHILOSOPHY; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> NIL </ADVISER>
<CLASSIFICATIONS> NIL </CLASSIFICATIONS>
<ABSTRACT>
The thesis dissertation deals with the presuppositions
of science: the creation ex nihilo of the universe by
God, its Ultimate Cause and Ultimate Intelligibility
(the ontological presupposition) and the capacity of
human beings to know its intelligibility (the
gnoseological presupposition). Science in itself cannot
know these truths. It is the knowledge of the material
realm and yet, it presupposes in its venture other
truths that fall beyond its scope. Another third
presupposition of science, a derivative of the
ontological and gnoseological presuppositions and which
may be called the axiological presupposition, has also
been studied. This third presupposition refers to the
human inclination to tend towards the universe as a
good. These presuppositions are philosophical and
theological in character that according to Jaki
influenced the viable birth of science in the Middle
Ages and its progressive growth. Stanley Jaki in
defending the nature of science argues its limited
nature to know reality and points out these
presuppositions. Science cannot be absolute. It is
committed to accept and affirm what is given to it by
philosophy and by faith. The dissertation paper concerns
also the intimate relationship between science, faith
and philosophy, between faith and reason. The topic of
artificial intelligence, or AI, is specially considered
in this work of investigation. A description of it is
given and the arguments of Jaki are presented against a
reductionist AI, or strong AI, that prove false its
claims. The dissertation paper is divided therefore into
two parts: a discussion on the presuppositions of
science (chapters 2 and 3) and on AI (chapters 4 and 5).
An introductory chapter, chapter 1, offers a brief
presentation of Stanley Jaki and his thoughts.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  2449 </NUMBER>
<ORDER>   AAIC412458 </ORDER>
<TITLE> THE APPLICATION OF ARTIFICIAL INTELLIGENCE TO MINERAL PROCESSING CONTROL </TITLE>
<AUTHOR> TRELOAR-BRADFORD, STEPHEN HALL </AUTHOR>
<YEAR> 1994 </YEAR>
<INSTITUTION> UNIVERSITY OF NOTTINGHAM (UNITED KINGDOM); 0616 </INSTITUTION>
<DESCRIPTORS> ENGINEERING, MINING UNIVERSITY PARK, NOTTINGHAM,  GREAT BRITAIN </DESCRIPTORS>
<ADVISER> NIL </ADVISER>
<CLASSIFICATIONS> NIL </CLASSIFICATIONS>
<ABSTRACT>
Increasing economic pressure and complexity of
processing has brought greater emphasis on the need for
improved mineral processing plant performance. Improved
plant performance depends on good plant control.
Developments in electronics have reduced the cost of
hardware and have allowed the systematic installation of
control and monitoring systems in modern plants. These
developments have not shown the improvements that were
originally anticipated. This is due to the limitations
of the process models developed using current modelling
techniques in modelling the highly non-linear and
complex mineral processes.
Artificial intelligence has been the study of how the
human brain is able to model the complex world around
us. Investigation into this field has resulted in the
development of two practical techniques. These are
expert systems and artificial neural networks (ANN). The
approaches of the two techniques to this problem are
quite different. Expert systems take the logical
approach, where any problem can be broken down into a
number of rules and facts. ANNs learn the model defining
the correlation between process variables from given
examples of the process. Application of these techniques
to mineral processing control and operation showed
potential, but also some significant limitations. Expert
systems are best suited for relatively simple, well-
defined and unchanging problems, while ANNs can deal
with more ill-defined and complex problems. Since
mineral processes are mainly highly non-linear and
complex, ANN's were selected as a possible solution to
developing an alternative modelling technique.
Investigations analysed the major ANN performance
factors and the development of a model development
procedure. The results showed that ANN's were able to
model complex functions, generate the underlying model
from the training data and gave improved performance
over current empirical models. The ANN model developed
was for a 125 mm hydrocyclone operating under high feed
solids concentration. Test work also included ANN model
development using data collected from a modern
processing plant. The results showed problems with the
data, but indicated these were due to the under
utilisation of the data available from the control
system.
The research showed that artificial intelligence
techniques are powerful modelling and problem solving
tools. As with any other technique, they should be used
only for appropriate problems. ANNs have shown a
particular ability in being able to model the complex
mineral processes. This ability can be used in the
development of more robust control models and in an
intelligent model development environment, with
visualisation tools, that could provide a practical
mineral processing modelling tool for plant operations.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  2450 </NUMBER>
<ORDER>   AAI9523455 </ORDER>
<TITLE> PARALLEL PROBABILISTIC SELF-ORGANIZING HIERARCHICAL NEURAL NETWORKS </TITLE>
<AUTHOR> VALAFAR, FARAMARZ </AUTHOR>
<YEAR> 1994 </YEAR>
<INSTITUTION> PURDUE UNIVERSITY; 0183 </INSTITUTION>
<DESCRIPTORS> ENGINEERING, ELECTRONICS AND ELECTRICAL; ENGINEERING, BIOMEDICAL; BIOLOGY, NEUROSCIENCE; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> OKAN K. ERSOY </ADVISER>
<CLASSIFICATIONS> NIL </CLASSIFICATIONS>
<ABSTRACT>
A new neural network architecture called the Parallel
Probabilistic Self-Organizing Hierarchical Neural
Network (PPSHNN) is introduced. The PPSHNN is designed
to solve complex classification problems, by dividing
the input vector space into regions, and by performing
classification on those regions. It consists of several
modules which operate in a hierarchically during
learning and in parallel during testing. Each module has
the task of classification for a region of the input
information space as well as the task of participating
in the formation of these regions through post- and pre-
rejection schemes. The decomposition into regions is
performed in a manner that makes classification easier
on each of the regions. The post-rejector submodule
performs a bitwise statistical analysis and detection of
hard to classify vectors. The pre-rejector module
accepts only those classes for which the module is
trained and rejects others.
The PNS module is developed as a variation of the PPSHNN
module. If delta rule networks are used to build the
submodules of PNS, then it uses piecewise linear
boundaries to divide the problem space into regions. The
PNS module has a high classification accuracy while it
remains relatively inexpensive. The submodules of PNS
are fractile in nature, meaning that each such unit may
itself consist of a number of PNS modules. The PNS
module is discussed as the building block for the
synthesis of PPSHNN.
The SIMD version of PPSHNN is implemented on MASPAR with
16k processors. On all the experiments performed, this
network has outperformed the previously used networks in
terms of accuracy of classification and speed.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  2451 </NUMBER>
<ORDER>   AAI9523375 </ORDER>
<TITLE> APPROACHES TO THE MODELING OF TABLET PROCESSING AND STABILITY OF SOLID DOSAGE FORMS </TITLE>
<AUTHOR> KESAVAN, JOTHI GANESH </AUTHOR>
<YEAR> 1994 </YEAR>
<INSTITUTION> PURDUE UNIVERSITY; 0183 </INSTITUTION>
<DESCRIPTORS> HEALTH SCIENCES, PHARMACY; ENGINEERING, INDUSTRIAL; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> GARNET E. PECK </ADVISER>
<CLASSIFICATIONS> PHARMACEUTICAL FORMULATION, NEURAL NETWORKS, SOLID STATE </CLASSIFICATIONS>
<ABSTRACT>
Tablet formulation presents a challenge. This is because
of the competing and counteracting requirements of a
tablet system. Three objectives relevant to the
development of a tablet dosage form were investigated.
A model granulation and tablet system was designed. In
this model system, four variables were chosen and they
were the granulation equipment, the diluent, the binder
concentration, and the binder addition method.
Granulations and tablets were prepared according to a
fixed experimental design and were evaluated. The
results of the model system were used for developing
neural network models and for studying the tablet
compaction event.
Neural networks were utilized for modeling and
predicting the characteristics of the granulation and
tablet system. The neural networks satisfactorily
predicted all the granulation and tablet properties in
the training step. The neural networks also
satisfactorily predicted all the granulation and tablet
properties in the testing step except for hardness and
friability.
The second objective was to study the effect of the
tablet compaction on the tablet properties. Both the
time and force compression parameters were significant
in predicting the tablet properties. The third objective
addressed the stability of theophylline anhydrous
present in a theophylline anhydrous-polyvinylpyrrolidone
physical mixture. The effect of relative humidity on the
stability was investigated. The glassy and rubbery
states of polyvinylpyrrolidone affected the hydration of
theophylline anhydrous in the physical mixture by
different mechanisms.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  2452 </NUMBER>
<ORDER>   AAI9523366 </ORDER>
<TITLE> THE APPLICATION OF FUZZY LOGIC AND NEURAL NETWORKS TO FREEWAY INCIDENT DETECTION </TITLE>
<AUTHOR> HSIAO, CHIEN-HUA </AUTHOR>
<YEAR> 1994 </YEAR>
<INSTITUTION> PURDUE UNIVERSITY; 0183 </INSTITUTION>
<DESCRIPTORS> ENGINEERING, CIVIL; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> MICHAEL J. CASSIDY </ADVISER>
<CLASSIFICATIONS> NIL </CLASSIFICATIONS>
<ABSTRACT>
The purpose of this research is to improve the
reliability of automatic freeway incident detection by
applying the fuzzy logic system and neural networks. A
Fuzzy Logic Incident Patrol System (FLIPS) is proposed
to combine a fuzzy logic system and the learning
capabilities of neural networks to form a connectionist
model. The proposed system can be constructed
automatically from training examples to find the optimum
input/output term sets, input/output membership
functions, and fuzzy logic rules.
The output of FLIPS is an incident detection index which
represents the possibility of an incident. These
continuous indices can be sent to a freeway traffic
operations center for further analysis. One example of
such further analysis is the conversion of the
continuous incident index value into a binary value
predicting the absence or presence of an incident. The
Fuzzy Logic Adaptive Threshold System (FLATS) is
developed for this purpose. The FLATS produces an
adaptive threshold for the conversion task based on the
current incident detection index provided by FLIPS.
FLATS itself is also a fuzzy logic system with a
recurrent neural network structure. Therefore, the
threshold serves both as input and output parameters for
FLATS. Like FLIPS, the FLATS can also be generated
automatically from training examples.
In total, four artificial intelligence incident
detection models have been developed to evaluate the
benefits of the proposed integrated learning process and
adaptive threshold technique. The evaluation results
show that the integrated learning process and adaptive
threshold technique can significantly improve incident
detection performance. The FLATS-I, which incorporates
proposed integrated learning process and adaptive
threshold technique, exhibits superior incident
detection performance.
Finally, the research conducted comparisons of the FLATS-
I with conventional incident detection algorithms (i.e.,
the McMaster algorithm, the California algorithm, and
the filtering technique) using the same incident
database collected in Toronto, Canada. The evaluation
results indicate that the FLATS-I provides promising
improvements in the incident detection and the
persistence check technique used in the McMaster
algorithm may not be an effective method to improve
incident detection.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  2453 </NUMBER>
<ORDER>   AAI9523309 </ORDER>
<TITLE> MODELING AND CONTROL OF NONLINEAR PROCESSES USING NEURAL NETWORKS AND FUZZY LOGIC </TITLE>
<AUTHOR> AOYAMA, ATSUSHI </AUTHOR>
<YEAR> 1994 </YEAR>
<INSTITUTION> PURDUE UNIVERSITY; 0183 </INSTITUTION>
<DESCRIPTORS> ENGINEERING, CHEMICAL; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> VENKAT VENKATASUBRAMANIAN </ADVISER>
<CLASSIFICATIONS> NIL </CLASSIFICATIONS>
<ABSTRACT>
Nonlinearity is the rule rather than the exception in
chemical processes. Neural networks are considered to be
attractive for modeling nonlinear processes because of
their ability to approximate arbitrary functions.
However, previous attempts to use neural networks in the
internal model control framework were not very
successful as the inverse model generated by the neural
network was not very accurate and lead to performance
degradation. To overcome this problem, the use of steady
state data in addition to the transient data for the
network training is proposed. In general, neural network
models are empirical nonlinear input-output models, with
all the input-output mapping details hidden in the
structure and the weights of the network. However, in
the present research, a specific model structure
consisting of the bias/drift term and the steady state
gain is imposed, leading to the possibility for greater
model insight and facilitating an analytical model
inversion. First, a method to integrate mathematical
models with neural networks, where a mathematical model
models the bias/drift term and a neural network models
the steady state gain, is proposed. This approach is
applied to a SISO control-affine process control and
showed comparable performances to the exact mathematical
based IMC. Second, a modeling scheme where both the
bias/drift term and the steady state gain are modeled by
neural networks is proposed. The proposed approach is
applied to the tasks of modeling and control of SISO
nonlinear processes which are not inherently control-
affine and showed a significant performance improvement
over a conventional PID controller. In addition, this
control-affine model based approach was combined with
the generalized Smith predictor approach for the control
of nonminimum-phase nonlinear processes. When the
process is poorly described by a control-affine model,
two approaches are proposed. First, a third neural
network is introduced to model the discrepancy between
control-affine model and actual process and incorporated
in an auxiliary loop. Second, a modeling scheme using a
fuzzy neural network structure is introduced. Both
approaches lead to improved closed-loop performance.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  2454 </NUMBER>
<ORDER>   AAI9520583 </ORDER>
<TITLE> AN EXPERT SYSTEM FOR EMPLOYEE FLEXIBLE BENEFIT SELECTION </TITLE>
<AUTHOR> CHIEDO, THEODORA ONYEKURU </AUTHOR>
<YEAR> 1994 </YEAR>
<INSTITUTION> WALDEN UNIVERSITY; 0543 </INSTITUTION>
<DESCRIPTORS> COMPUTER SCIENCE; BUSINESS ADMINISTRATION, MANAGEMENT; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> THOMAS SAWYER </ADVISER>
<CLASSIFICATIONS> NIL </CLASSIFICATIONS>
<ABSTRACT>
This study focused on the difficult and cumbersome
selection process faced by employees at medium to large
organizations that offer flexible benefits plans.
Because of the complexity inherent in flexible benefits,
especially medical benefits programs, employees need
adequate knowledge of benefit options and a systematic
process to choose properly from among available benefit
options. The purpose of the study, therefore, was to
provide employees with an alternative method of benefit
selection and to evaluate the impact on both employees
and the organization.
The alternative method studied was the use of expert
system technology to aid employees in the benefit
selection process. A prototype expert system was
developed. A survey was conducted in a large
organization to determine the following: (1) whether
employees will spend less time choosing benefits using
the expert system, (2) whether the expert system
software will recommend different benefits, (3) whether
employees will be more satisfied using the expert system
software in selecting benefits, and (4) whether the use
of expert system technology will reduce organizations'
cost of educating employees on benefits.
Research findings in the study indicate that the use of
expert system technology to choose from among flexible
benefits will lead to greater employee satisfaction,
reduce the time used in choosing benefits, and reduce
employer cost of educating employees on benefits more
effectively than any other method.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  2455 </NUMBER>
<ORDER>   AAI9520494 </ORDER>
<TITLE> A HETEROGENEOUS FRAMEWORK FOR REASONING ABOUT IMMUNOLOGICAL SCENARIOS  </TITLE>
<AUTHOR> WILLIAMS, CLAY EDWIN </AUTHOR>
<YEAR> 1994 </YEAR>
<INSTITUTION> TEXAS A&M UNIVERSITY; 0803 </INSTITUTION>
<DESCRIPTORS> COMPUTER SCIENCE; HEALTH SCIENCES, IMMUNOLOGY; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> WILLIAM M. LIVELY; DONALD K. FRIESEN </ADVISER>
<CLASSIFICATIONS> DEEP REASONING, IMMUNE SYSTEM </CLASSIFICATIONS>
<ABSTRACT>
The field of artificial intelligence has been applied to
medicine for many years. However, limited success has
prompted the development of systems capable of deep
reasoning. The immune system is quite complex, yet
current research has provided detailed knowledge
concerning the immune response. However, limitations
imposed on laboratory study by the distributed nature of
the immune system make it an excellent candidate for
study via deep models. This research presents a model
for understanding cell/cytokine interactions in the
immune system, stating expected behavior and comparing
the expectations to actual data.
An overview of basic immunological knowledge used in the
construction of the system (IMMSIM) is presented. A
multi-layered heterogeneous knowledge representation
framework called the immunological knowledge
representation structure (IKRS) is introduced, modeling
information at the molecular, cellular and systemic
levels. The concepts of events and activities are
introduced in order to use the IKRS to generate expected
scenarios concerning what will occur given some set of
events that befall the immune system. The heterogeneity
of the system is further enhanced by developing its
capability to numerically model the scenarios. Finally,
methods for comparing expected scenarios with actual
data and explaining differences found therein are
presented.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  2456 </NUMBER>
<ORDER>   AAGC507919 </ORDER>
<TITLE> ESTIMATION, MODELISATION ET LANGAGE DE DECLARATION ET DE MANIPULATION DE CHAMPS SPATIAUX CONTINUS; ESTIMATION, MODELISATION AND LANGUAGE FOR DECLARATION AND MANIPULATION OF SPATIAL CONTINUOUS FIELDS </TITLE>
<AUTHOR> PARIENTE, DILLON </AUTHOR>
<YEAR> 1994 </YEAR>
<INSTITUTION> INSTITUT NATIONAL DES SCIENCES APPLIQUEES DE LYON (FRANCE); 5285 </INSTITUTION>
<DESCRIPTORS> COMPUTER SCIENCE; ARTIFICIAL INTELLIGENCE EINSTEIN, F-69621  VILLEURBANNE CEDEX, FRANCE </DESCRIPTORS>
<ADVISER> NIL </ADVISER>
<CLASSIFICATIONS> NEURAL NETWORKS </CLASSIFICATIONS>
<ABSTRACT>
Les champs geographiques continus sont generalement
representes par des ensembles de points-echantillons ou
d'attributs sur des zones privilegiees, ce qui conduit a
des discontinuites dans les valeurs d'attribut ou a des
homogeneisations de ces valeurs qui ne correspondent pas
a la realite. La solution reside dans l'interpolation et
l'extrapolation a partir des valeurs connues des champs
continus, et de contraintes sur le realisme de
l'estimation.
Une nouvelle methode d'estimation est alors proposee,
reposant sur les resultats de la methode des differences
finies, et le modele de reseau neuronal de Hopfield. Une
modelisation orientee objet des champs continus permet
de prendre en compte des contraintes specifiees sur
l'estimation. Un nouveau type abstrait de donnees est
defini pour le typage d'attributs derivant d'un champ
continu. Enfin, un nouveau langage est specifie,
permettant la declaration et la manipulation des champs
continus et des informations necessaires a l'estimation
de ces champs.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  2457 </NUMBER>
<ORDER>   AAI9520331 </ORDER>
<TITLE> ON ADAPTIVE RADIAL BASIS FUNCTION NEURAL NETWORKS FOR THE FORECASTING OF TIME SERIES PROCESSES </TITLE>
<AUTHOR> CHIU, CHIH-CHOU </AUTHOR>
<YEAR> 1994 </YEAR>
<INSTITUTION> TEXAS A&M UNIVERSITY; 0803 </INSTITUTION>
<DESCRIPTORS> ENGINEERING, INDUSTRIAL; ARTIFICIAL INTELLIGENCE; STATISTICS </DESCRIPTORS>
<ADVISER> JOSEPH J. PIGNATIELLO, JR.; DEBORAH F. COOK </ADVISER>
<CLASSIFICATIONS> NIL </CLASSIFICATIONS>
<ABSTRACT>
A feedforward neural model, the radial basis functions
(RBF) network, was utilized to forecast process
parameter values from a time series process. To
demonstrate the forecasting capability, a predictive
modeling system for the kappa number associated with a
paper pulping manufacturing process was constructed by
using RBF network (Chapter II). In the construction of
the RBF network, two problems were found. First, the
determination of the width of the kernel function during
the training in the output layer has not been addressed
completely yet. Also, the optimal design parameters,
such as the number of neurons in the hidden layer and
the initial values of the learning rate for connection
weights, were not known. Because of these existing
problems, the maximum prediction accuracy for the RBF
network is hardly achieved. To overcome this difficulty,
two simple approaches, the radius-modification (RM) and
response surface methodology (RSM), are introduced
(Chapter III and IV).
Furthermore, the decreased forecasting precision problem
caused by the unknown optimal design parameters also
exists in the other widely used feedforward neural
model, the multi-layer perceptron (MLP) network. To
solve this problem, RSM approach is applied in Chapter V
to determine the optimal neural network setup. The
results indicate that the adaptive neural network model
using the proposed RM or RSM technique was able to
identify patterns from the manufacturing process data
sets and to make precise predictions of future values of
time series processes.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  2458 </NUMBER>
<ORDER>   AAI9520013 </ORDER>
<TITLE> A HYBRID APPROACH FOR CLASSIFICATION LEARNING FROM DATABASES  </TITLE>
<AUTHOR> LEE, CHANGHWAN </AUTHOR>
<YEAR> 1994 </YEAR>
<INSTITUTION> THE UNIVERSITY OF CONNECTICUT; 0056 </INSTITUTION>
<DESCRIPTORS> COMPUTER SCIENCE; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> NIL </ADVISER>
<CLASSIFICATIONS> MACHINE LEARNING </CLASSIFICATIONS>
<ABSTRACT>
By examining the content of a database, interesting
relationships among data can be discovered
automatically. The extracted knowledge can facilitate
classification and/or reasoning in databases. The
purpose of my research is to set forth a basic theory
for a classification learning system from databases, and
information theory serves as the theoretical background
of the entire system.
The approach employed in this research is composed of
three phases: pre-processing phase, rule-based learning
phase, and similarity-based learning phase. In the
preprocessing phase, numeric attributes are discretized
with varying intervals based on the amount of
information they contain. A new discretization method,
called context-sensitive discretization, which minimizes
the information loss during discretization is proposed.
While most machine learning research has been primarily
concerned with the development of systems that implement
one type of learning strategy, in this research, we use
a multistrategy approach which combines rule-based
learning with similarity-based learning, and show how
this marriage allows for overall better performance.
In the rule-based learning phase, for each rule, we
derive an entropy function, based on Hellinger
divergence, which can measure the amount of information
each inductive rule contains. We show how well the
Hellinger divergence measures the importance of each
rule, and also propose some heuristics to reduce the
computational complexity by analyzing the
characteristics of the Hellinger measure. In the
similarity-based learning phase, we improve the current
similarity-based learning method in a number of ways. An
unified form of similarity measure, applicable to every
type of database attribute, is proposed, and the weight
of each attribute is calculated automatically.
The system has been implemented and tested intensively
on a number of well-known machine learning data sets.
The performance of the system has been compared with
that of other well-known classification learning
techniques. The results presented in this dissertation
support the thesis that hybrid algorithms combining rule-
based classification and similarity-based classification
can be tractable, that resulting rules can capture
complex interrelationships among attributes in a variety
of databases, and that these combined methods can thus
classify new cases with high accuracy.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  2459 </NUMBER>
<ORDER>   AAI9519738 </ORDER>
<TITLE> TRANSFORM ADAPTIVE IMAGE COMPRESSION WITH GENERALIZED NEURAL NETWORKS </TITLE>
<AUTHOR> RIOS, ANDRES </AUTHOR>
<YEAR> 1994 </YEAR>
<INSTITUTION> UNIVERSITY OF MIAMI; 0125 </INSTITUTION>
<DESCRIPTORS> ENGINEERING, ELECTRONICS AND ELECTRICAL; COMPUTER SCIENCE; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> MANSUR R. KABUKA </ADVISER>
<CLASSIFICATIONS> NIL </CLASSIFICATIONS>
<ABSTRACT>
This research illustrates the use of a novel model of
neural networks, the generalized neural network model,
to build connectionist architectures and their processes
tailored to the definition of globally and locally
adaptive compression systems. This model extends the
traditional connectionist ideas to include the behave-
act, evolve-learn and behave-control functions of the
network, which allow overcoming the drawbacks of
previous direct connectionist approaches to the
transform image compression problem. Thereafter, the
architecture and its processes are used for the
definition of a globally and locally adaptive
compression system that surpasses known compression
algorithms in three main aspects: very high compression
rate with a low introduced distortion, ability to tackle
a broad set of data and feasibility for on-line real-
time compression. The algorithms are backed up by
quantitative, empirical and comparative studies to
different neural network approaches and known standard
compression methods.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  2460 </NUMBER>
<ORDER>   AAI9519482 </ORDER>
<TITLE> STATISTICAL SEMANTICS OF PHRASES IN HIERARCHICAL CONTEXTS  </TITLE>
<AUTHOR> STEIER, AMY MARIE </AUTHOR>
<YEAR> 1994 </YEAR>
<INSTITUTION> UNIVERSITY OF CALIFORNIA, SAN DIEGO; 0033 </INSTITUTION>
<DESCRIPTORS> COMPUTER SCIENCE; ARTIFICIAL INTELLIGENCE; LANGUAGE, LINGUISTICS </DESCRIPTORS>
<ADVISER> RICHARD K. BELEW </ADVISER>
<CLASSIFICATIONS> NATURAL LANGUAGE, CORPUS LINGUISTICS </CLASSIFICATIONS>
<ABSTRACT>
The research in this dissertation is centered around the
study of phrasal semantics in varying corpora contexts.
We embrace a statistical approach to semantics in which
corpora statistics are used to characterize meaning. The
linguistic issues we concentrate on are the phenomena of
semantic compositionality and collocational constraints.
The semantic compositionality of a phrase is the extent
to which the meaning of the phrase is inferred from the
typical meanings associated with its constituents. For
example, the meaning of the phrase DATABASE SOFTWARE is
highly compositional, whereas the meaning of the phrase
BULL'S EYE or POLITICALLY CORRECT is highly
noncompositional. Collocational constraints are
restrictions in language that determine which words can
co-occur with which other words. Not all collocational
constraints exist between words that are syntactically
modifying each other.
We study the interaction between collocational
constraints and phrasal indexing by performing an in-
depth comparison of syntactic and statistical approaches
to phrasal indexing in Information Retrieval. We study
the issue of compositionality in statistical semantics
by first determining how effective various statistical
measures are at measuring semantic compositionality in
phrases. We then use these same measures to study
whether the semantic compositionality of a phrase can be
used to determine the effectiveness of the phrase and
its constituents as index terms.
Another theme of our research is the effect of varying
corpora contexts on statistical approaches to semantics.
Text collections are often heterogeneous; the larger a
collection is, the more likely it has been generated by
many different authors using very different vocabularies
and covering many different topics. Therefore, global
statistics can become problematic if local variations in
word usage patterns are lost. One particular research
issue we focus on is how the semantic compositionality
of a phrase can vary across the subcontexts of a larger,
more heterogeneous collection. We also study the effect
of global versus local statistics on performance in
Information Retrieval. By global, we mean statistics
computed using the entire collection; by local, we mean
statistics computed using a smaller, more topically
cohesive subset of the collection. All together, this
research has furthered our understanding of the
statistical semantics of phrases in hierarchical
contexts.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  2461 </NUMBER>
<ORDER>   AAI9519094 </ORDER>
<TITLE> A COOPERATIVE TRAINING MODEL FOR SUPERVISED LEARNING IN ARTIFICIAL NEURAL NETWORKS </TITLE>
<AUTHOR> CHOW, CHI-KEI RICK </AUTHOR>
<YEAR> 1994 </YEAR>
<INSTITUTION> UNIVERSITY OF SOUTHWESTERN LOUISIANA; 0233 </INSTITUTION>
<DESCRIPTORS> COMPUTER SCIENCE; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> CHEE-HUNG HENRY CHU </ADVISER>
<CLASSIFICATIONS> NIL </CLASSIFICATIONS>
<ABSTRACT>
A new model for supervised neural network learning using
genetic algorithms (GAs) is introduced. Artificial
neural networks are computational models inspired by the
neuro-anatomy of organisms. Our brains can perform
certain computations such as speech recognition, pattern
recognition, and motion control much faster and more
robust than any existing supercomputer in the world.
Therefore, neurocomputing is adopted as an alternative
computing paradigm to conventional symbolic based
computing for such computationally intensive problems.
Genetic algorithms are optimization methods that apply
the strategy of evolution in nature. GAs mimic the
processes of natural selection and sexual reproduction
to evolve solutions to a problem. The selection process
allows more good genes or subsolutions to be passed on
to the next generation. Furthermore, the reproduction
step ensures mixing and recombination of good genes.
Traditionally, supervised neural network learning is
conducted using gradient descent algorithms which can be
trapped into local minima of the search space. More
recently, GAs were employed for supervised neural
network learning because of their ability to explore a
multimodal search space by manipulating building blocks,
or schemata, instead of raw data points. Networks are
usually encoded in binary strings, a population of
chromosomes, on which GAs perform evolution operations
such as genetic recombination and selection. Large
networks are encoded as long chromosomes which expose
many schemata to destructions inflicted by genetic
crossover.
The new model, referred to as the cotrain (cooperative
training) model, reduces such destructions by using a
distributed chromosome representation of a network and a
cooperative mechanism to coordinate the evolutions in
separate subpopulations. The new model is discussed and
experimental results are presented.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  2462 </NUMBER>
<ORDER>   AAI9518675 </ORDER>
<TITLE> A COMPARATIVE STUDY OF SOAR AND THE CONSTRUCTION- INTEGRATION MODEL  </TITLE>
<AUTHOR> WHARTON, CATHLEEN SUSAN </AUTHOR>
<YEAR> 1994 </YEAR>
<INSTITUTION> UNIVERSITY OF COLORADO AT BOULDER; 0051 </INSTITUTION>
<DESCRIPTORS> COMPUTER SCIENCE; PSYCHOLOGY, GENERAL; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> CLAYTON H. LEWIS </ADVISER>
<CLASSIFICATIONS> COGNITIVE ARCHITECTURES </CLASSIFICATIONS>
<ABSTRACT>
Researchers in AI and HCI are weighing the merits of
contrasting classes of cognitive architectures: those
that feature highly structured information processed by
rules ("symbolic" architectures), and those that feature
less structured information processed by propagation of
activation ("associational" architectures). To better
understand the trade-offs one architecture was selected
from each class: Soar representing symbolic
architectures and the Construction-Integration Model for
associational architectures. Within the framework
provided by these architectures an HCI task was
modelled. The particular task modelled was one of using
an Automatic Teller Machine to get the balance of a
checking account. This task is said to be situated: A
user must rely on both knowledge from the environment
and internally to perform this task. This dissertation
reports what was learned from the comparison of these
two architectures and the resulting ATM task models.
The findings of this study are that both of these
architectures appear to be more similar than not. Many
similarities were noted in the twenty-one dimensions
compared at the architectural level in addition to the
similarities identified for the six psychological and
modelling dimensions used to compare the resulting task
models.
From an architectural perspective, the two architectures
are extremely similar. Some points of similarity include
taskability and rationality. Some differences can also
be seen, as in the two architectures' approach to
learning (particularly for declarative knowledge), and
their underlying computational methods. These
differences, however, appear to go away when the
resulting task models are considered.
From a modelling perspective, two key results from this
study were identified. The first is than the task drove
the modelling more that the architecture. This finding
appears to reflect the immense power and flexibility of
these architectures, presumably mirroring the
flexibility of humans. It further indicates that the
choice of architecture, for modelling purposes, may be
irrelevant: the choice of architecture may be dependent
upon the task to be modelled. For example, for a
learning intensive task, one might choose Soar. For
modelling errors and attention issues, one might choose
CI. The second finding was that the resulting models
were highly similar. Thus, comparing the models at a
structural level appears not to be sufficient. Instead,
to tease apart the subtle distinctions of the models, it
appears that we need a strong test based on performance
distinctions such as timing, learning, and errorful
behavior.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  2463 </NUMBER>
<ORDER>   AAI9518516 </ORDER>
<TITLE> TOWARDS PLANNING: INCREMENTAL INVESTIGATIONS INTO ADAPTIVE ROBOT CONTROL  </TITLE>
<AUTHOR> MEEDEN, LISA ANNE </AUTHOR>
<YEAR> 1994 </YEAR>
<INSTITUTION> INDIANA UNIVERSITY; 0093 </INSTITUTION>
<DESCRIPTORS> COMPUTER SCIENCE; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> MICHAEL GASSER </ADVISER>
<CLASSIFICATIONS> NEURAL NETWORKS </CLASSIFICATIONS>
<ABSTRACT>
Traditional models of planning have adopted a top-down
perspective by focusing on the deliberative, conscious
qualities of planning at the expense of having a system
that is connected to the world through its perceptions.
My thesis takes the opposing, bottom-up perspective that
being firmly situated in the world is the crucial
starting point to understanding planning. The central
hypothesis of this thesis is that the ability to plan
developed from the more primitive capacity of reactive
control.
Neural networks offer the most promising mechanism for
investigating robot control and planning because
connectionist methodology allows the task demands rather
than the designer's biases to be the primary force in
shaping a system's development. Input can come directly
from the sensors and output can feed directly into the
actuators creating a close coupling of perception and
action. This interplay between sensing and acting
fosters a dynamic interaction between the controller and
its environment that is crucial to producing reactive
behavior. Because adaptation is fundamental to the
connectionist paradigm, the designer need not posit what
form the internal knowledge will take or what specific
function it will serve. Instead, based on the training
task, the system will construct its own internal
representations built directly from the sensor readings
to achieve the desired control behavior. Once the system
has reached an adequate level of performance at the
task, its method can be dissected and a high-level
understanding of its control principles can be
determined.
This thesis takes an incremental approach towards
understanding planning. In the initial phase, several
ways of representing goals are explored using a
simulated robot in a one-dimensional environment. Next
the model is extended to accommodate an actual physical
robot and two reinforcement learning methods for
adapting the network controllers are compared: a
gradient descent algorithm and a genetic algorithm.
Finally, the model's behavior and representations are
analyzed to reveal that it contains the potential
building blocks necessary for planning. By actively
restricting the extent of our presuppositions about
planning, we may be able to develop truly autonomous
robots with radically different forms of control and
planning.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  2464 </NUMBER>
<ORDER>   AAI9518398 </ORDER>
<TITLE> MEDICAL IMAGE TOMOGRAPHY: A STATISTICALLY TAILORED NEURAL NETWORK APPROACH </TITLE>
<AUTHOR> KERR, JOHN PATRICK </AUTHOR>
<YEAR> 1994 </YEAR>
<INSTITUTION> IOWA STATE UNIVERSITY; 0097 </INSTITUTION>
<DESCRIPTORS> ENGINEERING, BIOMEDICAL; HEALTH SCIENCES, RADIOLOGY; ENGINEERING, ELECTRONICS AND ELECTRICAL; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> ERIC B. BARTLETT </ADVISER>
<CLASSIFICATIONS> COMPUTED TOMOGRAPHY, ARTIFICIAL NEURAL NETWORKS </CLASSIFICATIONS>
<ABSTRACT>
In medical computed tomography (CT) the tomographic
images are reconstructed from planar information
collected 180$spcirc$ to 360$spcirc$ around the patient.
In clinical applications, the reconstructions are
typically produced using a filtered backprojection
algorithm. Filtered backprojection methods have
limitations that create a high percentage of statistical
uncertainty in the reconstructed images. Many techniques
have been developed which produce better
reconstructions, but they tend to be computationally
expensive, and thus, impractical for clinical use.
Artificial neural networks (ANN) have been shown to be
adept at learning and then simulating complex functional
relationships. For medical tomography, a neural network
can be trained to produce a reconstructed medical image
given the planar data as input. Once trained an ANN can
produce an accurate reconstruction very quickly.
A backpropagation ANN with statistically derived
activation functions has been developed to improve the
trainability and generalization ability of a network to
produce accurate reconstructions. The tailored
activation functions are derived from the estimated
probability density functions (p.d.f.s) of the ANN
training data set. A set of sigmoid derivative functions
are fitted to the p.d.f.s and then integrated to produce
the ANN activation functions, which are also estimates
of the cumulative distribution functions (c.d.f.s) of
the training data. The statistically tailored activation
functions and their derivatives are substituted for the
logistic function and its derivative that are typically
used in backpropagation ANNs.
A set of geometric images was derived for training an
ANN for cardiac SPECT image reconstruction. The planar
projections for the geometric images were simulated
using the Monte Carlo method to produce sixty-four 64-
quadrant planar views taken 180 about each image. A 4096
x 629 x 4096 architecture ANN was simulated on the
MasPar MP-2, a massively parallel single-instruction
multiple-data (SIMD) computer. The ANN was trained on
the set of geometric tomographic images. Trained on the
geometric images, the ANN was able to generalize the
input-to-output function of the planar data-to-tomogram
and accurately reconstruct actual cardiac SPECT images.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  2465 </NUMBER>
<ORDER>   AAI9518364 </ORDER>
<TITLE> SPLINE NETWORK MODELING AND FAULT CLASSIFICATION OF A HEATING VENTILATION AND AIR-CONDITIONING SYSTEM </TITLE>
<AUTHOR> CHACKALACKAL, MATTHEW SCARIA </AUTHOR>
<YEAR> 1994 </YEAR>
<INSTITUTION> IOWA STATE UNIVERSITY; 0097 </INSTITUTION>
<DESCRIPTORS> ENGINEERING, ELECTRONICS AND ELECTRICAL; ENGINEERING, HEAT AND THERMODYNAMICS; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> HSIEN-SEN HUNG </ADVISER>
<CLASSIFICATIONS> NIL </CLASSIFICATIONS>
<ABSTRACT>
A spline network, that is an alternative to artificial
neural networks, is introduced in this dissertation.
This network has an input layer, a single hidden layer,
and an output layer. Spline basis functions, with small
support, are used as the activation functions. The
network is used to model the steady state operation of a
complex Heating Ventilation and Air-conditioning (HVAC)
system. Real data was used to train the spline network.
A neural network was also trained on the same set of
data. Based on the training process, it is possible to
conclude that when compared to artificial neural
networks, the spline network is much faster to train,
needed fewer input-output pairs, and had no convergence
problems. The weights of the spline network are obtained
by solving a set of linear equations.
The spline network model of the HVAC system is used to
detect faulty operation of the actual system. Once
abnormal operation of the system is monitored, a fuzzy
neural network is used to locate the faulty component.
The fuzzy neural network is trained on data obtained by
simulating fault scenarios. This network minimizes
ambiguities at decision boundaries. The results of fault
classification are presented in the dissertation.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  2466 </NUMBER>
<ORDER>   AAGMM17574 </ORDER>
<TITLE> THE PROBLEM OF DETECTING SMALL TARGETS USING MICROWAVE RADAR: A NEURAL NETWORK SOLUTION </TITLE>
<AUTHOR> BRYANT, DONALD S. </AUTHOR>
<YEAR> 1994 </YEAR>
<INSTITUTION> MEMORIAL UNIVERSITY OF NEWFOUNDLAND (CANADA); 0306 </INSTITUTION>
<DESCRIPTORS> ENGINEERING, ELECTRONICS AND ELECTRICAL; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> GARY SABIN </ADVISER>
<CLASSIFICATIONS> NIL </CLASSIFICATIONS>
<ABSTRACT>
A neural network technique has been applied to the
marine radar small target detection problem. It has been
compared to the conventional processing method of scan
to scan integration. The results of the analysis
indicate that a neural network is capable of providing
performance that is at least as good as, and if the
scanning window is optimized for the pulse length being
used, much better than the conventional processing
technique for small targets embedded in sea clutter.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  2467 </NUMBER>
<ORDER>   AAGC505562 </ORDER>
<TITLE> A MULTIPLE ADAPTIVE RESONANCE THEORY ARCHITECTURE APPLIED TO MOTION RECOGNITION TASKS </TITLE>
<AUTHOR> BULPITT, ANDREW JOHN </AUTHOR>
<YEAR> 1994 </YEAR>
<INSTITUTION> UNIVERSITY OF YORK (UNITED KINGDOM); 0769 </INSTITUTION>
<DESCRIPTORS> COMPUTER SCIENCE; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> NIL </ADVISER>
<CLASSIFICATIONS> PATTERN RECOGNITION </CLASSIFICATIONS>
<ABSTRACT>
Existing techniques for temporal pattern recognition
provide systems that may be applied to specific tasks,
but are not easily adapted to different problems. Many
techniques suffer from limitations such as the lengths
of sequences with which they may be used, the
recognition of events which occur at varying speeds or
the need for prior knowledge about the expected result
in order to set up the model. This thesis describes a
neural network model developed to carry out temporal
pattern recognition tasks and overcome some of the
limitations of other approaches. The use of self
organising neural networks allow the model to be trained
to different environments in which it is applied without
prior knowledge of the expected result.
The model is applied to the problem of recognising human
actions using information supplied from only the joints
of the actor. Research has shown how humans are able to
recognise complex actions from such information and even
identify the sex and identity of an actor. A small
amount of information such as this makes the application
well suited to the neural network models.
In order to acquire the required data a video interface
has been developed which provides a fast and efficient
system for locating actors joints using coloured bands
attached to the actor. A knowledge based system is then
applied to the data in order to find the positions of
any occluded joints.
The results produced show the model is able to identify
the motion of actors from the data and illustrates its
ability to learn and recognise temporal sequences which
may occur at various speeds and over different lengths
of time. The test data also illustrates how the model
can deal with repetitions within sequences and provides
the desirable property of time invariance.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  2468 </NUMBER>
<ORDER>   AAI9518174 </ORDER>
<TITLE> AN INTEGRATED NEURAL NETWORK MODEL OF THE PRODUCTION OF MESOPHASE PITCH-BASED CARBON FIBERS </TITLE>
<AUTHOR> BRANDES, BRIAN TODD </AUTHOR>
<YEAR> 1994 </YEAR>
<INSTITUTION> CLEMSON UNIVERSITY; 0050 </INSTITUTION>
<DESCRIPTORS> ENGINEERING, CHEMICAL; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> J. N. BEARD </ADVISER>
<CLASSIFICATIONS> NIL </CLASSIFICATIONS>
<ABSTRACT>
The physical properties of carbon fibers depend upon the
many operating conditions under which they are produced,
but much of this dependence is functionally unknown.
Also, there is a large time lag (on the order of several
weeks in Clemson's pilot-scale process) between spinning
and final product quality measurement. Therefore, an
advanced control strategy, such as feedforward control,
would be required to satisfactorily optimize and control
the production process. The objective of this research
was to determine the feasibility of developing a
computer-implemented process model for the production of
mesophase pitch-based carbon fibers which could be used
as the basis of an advanced control system.
A successful integrated neural network process model was
developed. The model is a combination of fundamental
equations, empirical equations, and feedforward neural
networks (FNNs). The equations were applied to sparse
process data that were compiled from previous
researchers in order to transform and simplify the data.
Then, the transformed data were used as inputs to the
FNNs. Various input configurations and numbers of
neurons in the hidden layer were investigated, and the
best FNNs were chosen using several criteria. The model
was then used in several applications to demonstrate its
utility and potential.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  2469 </NUMBER>
<ORDER>   AAI9518061 </ORDER>
<TITLE> SMALL AREA, LOW POWER, MIXED-MODE CIRCUITS FOR HYBRID NEURAL NETWORK APPLICATIONS </TITLE>
<AUTHOR> FANG, XUEFENG </AUTHOR>
<YEAR> 1994 </YEAR>
<INSTITUTION> OHIO UNIVERSITY; 0167 </INSTITUTION>
<DESCRIPTORS> ENGINEERING, ELECTRONICS AND ELECTRICAL; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> JANUSZ A. STARZYK </ADVISER>
<CLASSIFICATIONS> ARTIFICIAL NEURAL NETWORKS </CLASSIFICATIONS>
<ABSTRACT>
This dissertation is devoted to the development of small
area, low power, mixed-mode circuits for hybrid
implementation of neural networks. Current-mode and
voltage-mode techniques were investigated to design
these building blocks: mixed-mode multipliers, D/A
converters, multiplying D/A converters, winner-take-all
circuits. Small area and low power design issues were
addressed. Designed circuit structure were modified to
cut down area and power dissipation. New switchable
current source, voltage buffer, and analog switch were
proposed to improve the circuits' performance. An image
processor was designed to show the application potential
of the developed building blocks. Extensive simulations
were made to verify the design. It has been shown that
low power designs can be obtained by making transistors
operate in the weak inversion region for current-mode
circuits, and using the capacitor arrays for voltage-
mode circuits. With the designed circuits, it is easy to
integrate a large number of neurons in a single chip.
The proposed methods and circuits make a significant
contribution to fully exploiting the great computation
power of artificial neural networks.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  2470 </NUMBER>
<ORDER>   AAI9518052 </ORDER>
<TITLE> BODY-BASED COGNITION: REASONING GUIDED BY FEELINGS, EMOTIONS AND METAPHOR  </TITLE>
<AUTHOR> KOZAK, MARGARET MANELLA </AUTHOR>
<YEAR> 1994 </YEAR>
<INSTITUTION> ILLINOIS INSTITUTE OF TECHNOLOGY; 0091 </INSTITUTION>
<DESCRIPTORS> COMPUTER SCIENCE; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> PETER H. GREENE </ADVISER>
<CLASSIFICATIONS> FESINA </CLASSIFICATIONS>
<ABSTRACT>
A computer reasoning agent, equipped with a few feelings
and seven stories of feeling clusters, is able to
perform a number of tasks required for functioning in
the everyday world. The computer reasoning agent is
called FESINA (FEeling-based Semi-INtelligent Agent).
FESINA's feelings select the stories which guide her
reasoning. FESINA moves around a room and senses
containment from her encounters with the walls of the
room. Then, when in a situation that can be perceived
metaphorically as containment, she remembers how she
sensed containment previously, and she uses a version of
this story to look around a room to inventory its
contents, or to determine what she was doing when she
forgets or is sidetracked from an activity. She fills
herself with food to satisfy a hunger, and recalls this
story to use a version of it when she wishes to exit a
room, look at an object, obtain an object, or to achieve
any goal that is expressible as a want or a need. FESINA
also handles obstacles. With feelings of enablement,
blockage and frustration, she pushes objects out of her
way and walks around immovable objects. In
metaphorically related situations, she uses versions of
these stories to handle visual objects and difficult
actions. She also utilizes specific world knowledge to
identify methods with which to handle other obstacles.
She remembers retreating from an obstacle which blocked
her path, and she uses a version of this story to
retreat from any object she considers harmful. She also
uses a version of this same story to quit a task with
which she has become totally frustrated.
Her plans are stories of feelings and activity
sequences. Execution of a plan is traversal of a path in
a mental space. If the prerequisites of an activity are
not satisfied, a feeling results that recruits stories
to guide the next activity, and causes the activity
needed to satisfy the prerequisites to be mapped into a
newly spawned mental space. When the new activity is
finished its task space is erased, and the suspended
activity resumed.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  2471 </NUMBER>
<ORDER>   AAI9517395 </ORDER>
<TITLE> ADAPTIVE SENSORY/MOTOR INTEGRATION FOR AN AUTONOMOUS MOBILE ROBOT </TITLE>
<AUTHOR> SHEAFFER, CHARLES MARTIN </AUTHOR>
<YEAR> 1994 </YEAR>
<INSTITUTION> UNIVERSITY OF MINNESOTA; 0130 </INSTITUTION>
<DESCRIPTORS> COMPUTER SCIENCE; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> MARIA GINI </ADVISER>
<CLASSIFICATIONS> NIL </CLASSIFICATIONS>
<ABSTRACT>
This dissertation describes the design and
implementation of a learning system for control of an
autonomous mobile robot. Reactive behaviors are learned
that allow a real robot to retreat from potential
collisions and to explore its environment by seeking out
nearby objects. This is accomplished through a set of
neural networks. The robot is able to derive teaching
inputs from kinesthetic feedback; no external teaching
input is required. A set of value networks supports the
proper interpretation of the feedback, resulting in
robust acquisition of the intended behaviors. Higher
level processes are learned via supervised techniques
which abstract elements of the sensory/motor
configurations and integrate them with a simple lexical
network to allow the robot to be directed using a
rudimentary command grammar. These are the first steps
in providing an autonomous mobile robot with the ability
to achieve flexible, intelligent behavior in a dynamic
environment. They allow the robot to make use of all its
sensory, motor, and cognitive abilities in an
integrated, coherent manner. Results from experiments
with simulations and a real robot are presented. A
theoretical decomposition of the process of identifying
instances of learning opportunities is used to drive the
design of our system.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  2472 </NUMBER>
<ORDER>   AAINN94786 </ORDER>
<TITLE> ARTIFICIAL NEURAL SIGNAL COMPRESSION WITH APPLICATIONS TO IMAGE AND SPEECH </TITLE>
<AUTHOR> WANG, ZHICHENG </AUTHOR>
<YEAR> 1994 </YEAR>
<INSTITUTION> UNIVERSITY OF WATERLOO (CANADA); 1141 </INSTITUTION>
<DESCRIPTORS> ENGINEERING, ELECTRONICS AND ELECTRICAL; COMPUTER SCIENCE; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> JOHN V. HANSON </ADVISER>
<CLASSIFICATIONS> NEURAL NETWORKS </CLASSIFICATIONS>
<ABSTRACT>
This thesis is devoted to the theory and practice of
sign compression with artificial neural structures and
learning methods. The studies in signal compression are
pursued with novel ideas and techniques in the aspects
of vector coding, parallel architecture, self-
adaptation, nonlinearity and global optimization. Hence,
the field of signal compression is broadened with new
areas and directions. In addition to common goals of
communications, storage, and signal processing, signal
compression is intimately connected to a variety of
other fields such as image classification, speech
recognition, pattern recognition, neural networks,
stochastic analysis, cluster analysis, regression, and
decision tree design. Thus the techniques presented here
can often be applied to other fields.
Beginning with adaptive and nonlinear prediction, the
generalized prediction with different structures and
designs has been investigated to overcome the
limitations of linear prediction. A code-excited
generalized predictive coding system is proposed to
enrich and improve predictive coding techniques with
nonlinear and parallel pitch and formant predictions. In
addition to prediction, we also investigated feature
extraction for signal modeling and compression. Linear
and nonlinear principal component analyses and
multilayer neural networks are used to achieve feature
extraction and dimensional reduction for a variety of
information sources. The proposed feature coding based
on the self-learning compression network and generalized
Hebbian learning is a signal compression technique of
promise, which is considered as the extension of
transform coding. Vector quantization needs
computationally efficient algorithms which enable one to
find an optimal vector quantizer for quantizing a given
random vector. Hence, we established a quasi-parallel
architecture for vector quantization to overcome the
exponential increase of computational complexity with
coding rate and vector dimension in traditional vector
quantization techniques. The globally optimal design of
a vector quantizer is another important topic of the
thesis. To obtain the globally optimal vector quantizer
for a given source, we approach the problem in aspects
of stochastic escaping from local minima, maximum
information preservation, and uniform distortion
distribution and present several algorithms for global
optimization. Hybrid systems of compression with or
without memory are also investigated. Neural hidden
state and trellis coders, neural trees, and neural
vector nonlinear predictive coding schemes are proposed.
This thesis presents new techniques with advanced
features in signal compression for speech and images,
some of which have achieved outstanding performance
while others have the same or better performance with
some advantages over conventional compression
techniques. The new approach to signal compression is
promising in both theory and practical application.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  2473 </NUMBER>
<ORDER>   AAINN94752 </ORDER>
<TITLE> A NEURAL PREDICTIVE HMM ARCHITECTURE FOR SPEECH AND SPEAKER RECOGNITION  </TITLE>
<AUTHOR> HASSANEIN, KHALED SAAD </AUTHOR>
<YEAR> 1994 </YEAR>
<INSTITUTION> UNIVERSITY OF WATERLOO (CANADA); 1141 </INSTITUTION>
<DESCRIPTORS> ENGINEERING, ELECTRONICS AND ELECTRICAL; ARTIFICIAL INTELLIGENCE; COMPUTER SCIENCE </DESCRIPTORS>
<ADVISER> M. I. ELMASRY; S. L. DENG </ADVISER>
<CLASSIFICATIONS> NEURAL NETWORKS </CLASSIFICATIONS>
<ABSTRACT>
A speech recognition system is developed utilizing a
neural predictive hidden Markov model architecture. In
this framework multi-layered feed-forward neural
networks are employed to implement accurate nonlinear
speech frame prediction. A Markov chain is used to
control changes in the weight parameters of these
predictive networks. We show that speech recognition
accuracy is closely linked to the capability of the
predictive model in representing long-term temporal
correlations in the speech signal.
Analytical expressions are derived for the correlation
functions of various types of predictive models (linear,
nonlinear, and jointly linear/nonlinear) in order to
determine the faithfulness of these models to the actual
speech data. This analysis, computer simulation and
speech recognition experiments suggest that when both
nonlinear and linear prediction are jointly performed
within the hidden layer of the neural network predictor,
the model is better at capturing long-term speech data
correlations, and consequently, improving speech
recognition accuracy. A convergence analysis was carried
out indicating the advantages, in terms of better
conditioning, of including explicit linear nodes within
the hidden layer of neural predictive models.
Performance estimates are also obtained for the neural
predictive HMM algorithm when mapped to a parallel
systolic-based architecture, indicating its real time
speech recognition performance capabilities.
A corrective training technique based on the Maximum
Mutual Information criterion is then developed for
training this class of models. Speech recognition
systems trained using this approach were shown to
significantly outperform their noncorrective Maximum
Likelihood trained counterparts in several speech
recognition tasks.
Finally, the Neural Predictive Hidden Markov Model (NP-
HMM) is successfully used to implement an accurate and
robust fixed-text speaker identification system.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  2474 </NUMBER>
<ORDER>   AAINN94748 </ORDER>
<TITLE> MODELING ARTICULATORY DYNAMICS USING HMM TECHNIQUES FOR AUTOMATIC SPEECH RECOGNITION </TITLE>
<AUTHOR> ERLER, KEVIN J. </AUTHOR>
<YEAR> 1994 </YEAR>
<INSTITUTION> UNIVERSITY OF WATERLOO (CANADA); 1141 </INSTITUTION>
<DESCRIPTORS> ENGINEERING, ELECTRONICS AND ELECTRICAL; COMPUTER SCIENCE; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> GEORGE FREEMAN </ADVISER>
<CLASSIFICATIONS> HIDDEN MARKOV MODELS, PHONEMES </CLASSIFICATIONS>
<ABSTRACT>
State-of-the-art speech recognition is accomplished by
using stochastic models (Hidden Markov Models or HMMs)
to represent small, non-overlapping segments of speech,
often referred to as "phonemes". In these conventional
HMM speech recognizers, the control strategy does not
draw on the underlying structure of speech, but rather
models the acoustics as a set of disjoint "segmental"
units. Such a strategy does not accommodate the acoustic
influence that phonemes have on neighboring phonemes,
nor does it attach any meaning to the interval states of
the model.
In this work, an alternative HMM control strategy is
presented which draws on the idea that the production of
speech is a process governed by the mechanical motion of
a finite set of relatively slow moving articulators. The
Articulatory Feature Model is defined as an HMM in which
each internal state of the model represents one point in
the (quantized) articulatory space (that is: one
possible configuration of the articulatory system).
Rather than modeling disjoint acoustic segments, this
model represents the acoustic patterns associated with
the various articulatory configurations of the speech
production system. Instead of a set of small disjoint
models, this scheme represents the entire vocabulary
with a single, large HMM. Individual vocabulary items
are specified as a sequence of target articulatory
configurations. The context dependency of phonemes is
now explicitly accommodated by those states representing
articulatory configurations visited between articulatory
targets. The internal model states now have potential
real-world interpretation due to their correlation with
the physical state of the production system. This allows
the incorporation of linguistic and physiological
knowledge to restrict the model evolution and improve
performance. The development of the quantized
articulatory space, target articulatory feature
sequences, and feature evolution constraints for a large-
vocabulary speech recognition system are presented.
Recognition results are presented for both small and
large vocabulary tasks, showing that the articulatory
feature scheme is competitive with the traditional
phoneme model (offering roughly 10% decrease in error
rate over the phoneme model). Analysis of the model's
behaviour indicates how model designers are able to
capitalize on the physical interpretation of internal
model states.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  2475 </NUMBER>
<ORDER>   AAINN94661 </ORDER>
<TITLE> COMPUTER SOFTWARE FOR THE CONTROL OF POTATO STORAGE ENVIRONMENT </TITLE>
<AUTHOR> LANDRY, JACQUES-ANDRE </AUTHOR>
<YEAR> 1994 </YEAR>
<INSTITUTION> MCGILL UNIVERSITY (CANADA); 0781 </INSTITUTION>
<DESCRIPTORS> ENGINEERING, AGRICULTURAL; COMPUTER SCIENCE </DESCRIPTORS>
<ADVISER> E. NORRIS </ADVISER>
<CLASSIFICATIONS> NIL </CLASSIFICATIONS>
<ABSTRACT>
Much research has proven that computer controlled
vegetable storage can achieve better storage conditions
than traditional control systems. During the last 10
years, the use of microcomputer-based environmental
control systems has become commonplace. However, to take
full advantage of this computerization of the control
process, it is not enough only to program the control
functions that are performed by normal analog equipment.
New and better control strategies must be developed.
Recent advances in computer technology have made
possible the development of expert systems; a branch of
artificial intelligence. One of the advantages of
developing such a system is that it provides a reasoning
tool which approaches the level of proficiency human
experts exhibit in that field. The application of new
control methods using expert systems has been
extensively demonstrated for greenhouse environments.
However, the application of expert systems for the
control of vegetable storage is still to be
investigated. In the first phase of this project, the
development and implementation of a sophisticated
control software, using a conventional algorithm-based
programming language, were achieved. Throughout the
three years of experimentation in an industrial potato
storage, the software proved to be appropriate for the
control of storage environmental parameters (temperature
and relative humidity). During the second phase, the
application of an expert system for the on-line control
of potato storage was explored. The development of a
rule-based expert system, that could replace the
conventional algorithm-based control routines was
achieved. The integration of the expert system into the
control software will result in a highly efficient
control software, which can easily be maintained and
improved as new knowledge emerges. The use of an expert
system will also render possible the representation of
heuristic knowledge in the form of rules, which was not
possible with the use of conventional, algorithm-based
programming language.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  2476 </NUMBER>
<ORDER>   AAINN94599 </ORDER>
<TITLE> IMPROVED LEARNING STRATEGIES FOR SMALL VOCABULARY AUTOMATIC SPEECH RECOGNITION </TITLE>
<AUTHOR> CARDIN, REGIS </AUTHOR>
<YEAR> 1994 </YEAR>
<INSTITUTION> MCGILL UNIVERSITY (CANADA); 0781 </INSTITUTION>
<DESCRIPTORS> COMPUTER SCIENCE; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> RENATO DE MORI </ADVISER>
<CLASSIFICATIONS> NIL </CLASSIFICATIONS>
<ABSTRACT>
There are basically three areas which can be explored to
improve an HMM based recognizer, namely, parameter
extraction, training methods and vocabulary
representation.
The goal of parameter extraction is not only to find a
compact and robust parametric representation of the
speech signal, but also to find one which allows the
HMMs to obtain the best possible recognition
performance. Historically, improvements at this level
have usually been obtained on a trial and error basis,
using as much knowledge as possible about both the
speech production and speech perception mechanisms. That
is, the acoustic parameter extraction module has always
been viewed as a separate module from the HMMs. This
thesis will explore the concept of performing parameter
extraction with a connectionist model, whose parameters
can be learned from training data.
Two HMM training techniques are used in this thesis,
namely MLE and MMIE. Parameter initialization, of
critical importance for both, will be investigated for
discrete, semi-continuous and continuous HMMs. Training
processes involving a combination of MLE and MMIE
training are studied. Other issues such as codebook
exponents and the use of pause and silence models will
also be explored.
Even if the vocabulary contains only 11 words, its
representation is a very important issue. The effects of
vocabulary representation with phoneme based, word based
(with no sharing) and inter-word models will be
experimentally evaluated. It will be shown how a word
error rate of 0.23% and a string error rate of 0.68% can
be achieved on the TIDIGITS corpus--a performance
rivalling the best results ever reported by any group of
researchers.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  2477 </NUMBER>
<ORDER>   AAI9520785 </ORDER>
<TITLE> A NEURAL NETWORK APPROACH TO THE ANALYSIS OF SCANNER DATA  </TITLE>
<AUTHOR> AINSCOUGH, THOMAS LEE </AUTHOR>
<YEAR> 1994 </YEAR>
<INSTITUTION> UNIVERSITY OF GEORGIA; 0077 </INSTITUTION>
<DESCRIPTORS> BUSINESS ADMINISTRATION, MARKETING; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> JAY E. ARONSON; FREDERICK STEPHENSON </ADVISER>
<CLASSIFICATIONS> PURCHASE BEHAVIOR </CLASSIFICATIONS>
<ABSTRACT>
The primary purpose of collecting scanner data is to
model and predict the dynamics of purchase behavior as
influenced by marketing mix variables. The objective of
this dissertation is to examine neural networks as an
alternative to traditional statistical methods for the
analysis of this "knowledge rich" data source. Neural
networks are computer based learning models that mimic
the way in which the human brain works, albeit on a much
lower level. The data under examination in this study
were supplied by the A.C. Nielsen Company and were
collected at the store level over a three-year period.
The results of the study showed that three and four
layer neural networks can be a suitable alternative to
multiple linear regression for modeling and predicting
the effects of retailer activity on brand sales. The
neural network models performed better in terms of mean
squared error and $Rsp 2$ than the regression model. The
study also demonstrated that neural network models used
in conjunction with sensitivity analysis can be useful
in testing hypotheses with scanner data.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  2478 </NUMBER>
<ORDER>   AAGC490611 </ORDER>
<TITLE> ATTENTIVE VISUAL TRACKING AND TRAJECTORY ESTIMATION FOR DYNAMIC SCENE SEGMENTATION </TITLE>
<AUTHOR> ROBERTS, JONATHAN MICHAEL </AUTHOR>
<YEAR> 1994 </YEAR>
<INSTITUTION> UNIVERSITY OF SOUTHAMPTON (UNITED KINGDOM); 5036 </INSTITUTION>
<DESCRIPTORS> ENGINEERING, ELECTRONICS AND ELECTRICAL; COMPUTER SCIENCE; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> NIL </ADVISER>
<CLASSIFICATIONS> INTELLIGENT COPILOT SYSTEMS, HIGHWAY AUTOMATION </CLASSIFICATIONS>
<ABSTRACT>
Intelligent Co-Pilot Systems (ICPS) offer the next
challenge to vehicle-highway automation. The key to
ICPSs is the detection of moving objects (other
vehicles) from the moving observer using a visual
sensor. The aim of the work presented in this thesis was
to design and implement a feature detection and tracking
strategy that is capable of tracking image features
independently, in parallel, and in real-time and to
cluster/segment features utilising the inherent temporal
information contained within feature trajectories.
Most images contain areas that are of little or no
interest to vision tasks. An attentive, data-driven,
approach to feature detection and tracking is proposed
which aims to increase the efficiency of feature
detection and tracking by focusing attention onto
relevant regions of the image likely to contain scene
structure. This attentive algorithm lends itself
naturally to parallelisation and results from a parallel
implementation are presented.
A scene may be segmented into independently moving
objects based on the assumption that features belonging
to the same object will move in an identical way in
three dimensions (this assumes objects are rigid). A
model for scene segmentation is proposed that uses
information contained within feature trajectories to
cluster, or group, features into independently moving
objects. This information includes: image-plane
position, time-to-collision of a feature with the image-
plane, and the type of motion observed. The Multiple
Model Adaptive Estimator (MMAE) algorithm is extended to
cope with constituent filters with different states
(MMAE$sp2$) in an attempt to accurately estimate the
time-to-collision of a feature and provide a reliable
idea of the type of motion observed (in the form of a
model belief measure).
Finally, poor state initialisation is identified as a
likely prime cause for poor Extended Kalman Filter (EKF)
performance (and hence poor MMAE$sp2$ performance) when
using high order models. The idea of the neurofuzzy
initialised EKF (NF-EKF) is introduced which attempts to
reduce the time for an EKF to converge by improving the
accuracy of the EKF's initial state estimates.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  2479 </NUMBER>
<ORDER>   AAI9520422 </ORDER>
<TITLE> DESIGN AND IMPLEMENTATION OF A CASEBASE MANAGEMENT SYSTEM  </TITLE>
<AUTHOR> MAHAPATRA, RADHAKANTA </AUTHOR>
<YEAR> 1994 </YEAR>
<INSTITUTION> TEXAS A&M UNIVERSITY; 0803 </INSTITUTION>
<DESCRIPTORS> BUSINESS ADMINISTRATION, GENERAL; COMPUTER SCIENCE; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> ARUN SEN </ADVISER>
<CLASSIFICATIONS> DATABASE, EXPERT SYSTEMS, FILE SYSTEM </CLASSIFICATIONS>
<ABSTRACT>
Case-based reasoning offers a new approach for
developing knowledge-based systems. Current case-based
systems lack adequate data management capability, which
restricts the use of these systems to applications that
only use small casebases. An important issue in case-
based reasoning research is how to scale-up these
systems to create large case-based systems. Such large
systems will facilitate the use of case-based reasoning
to solve complex business problems.
This research investigates the data management
requirement of large casebases. It proposes a new
architecture for case-based systems. The casebase, in
the proposed architecture, is stored in secondary
storage and is managed by a Casebase Management System
(CBMS). It facilitates sharing of a casebase by multiple
reasoners and creation of large case-based systems.
Research issues in designing a CBMS are specifically
addressed. A software engineering methodology was used.
An analysis of the case-based reasoning literature and
the database literature revealed the differences between
case management and data management. Similar cases are
retrieved during a case retrieval operation. Cases are
required to be clustered using inter-case similarity to
improve case retrieval performance. The index management
function in a CBMS facilitates retrieval of partially
matched cases. A similarity-based clustering algorithm
was developed and its performance was evaluated using a
simulation experiment. A feature tree was used to store
information to identify partially matched cases. A
prototype system called alpha was developed. It uses the
similarity-based case clustering algorithm to cluster
cases. An index management function has been implemented
for alpha using the feature tree. The performance of the
system was evaluated and was found to be satisfactory.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  2480 </NUMBER>
<ORDER>   AAI1361140 </ORDER>
<TITLE> A DISTRIBUTED TRUTH MAINTENANCE SYSTEM </TITLE>
<AUTHOR> DOULAMIS, JOHN NIKOLAOS </AUTHOR>
<YEAR> 1994 </YEAR>
<INSTITUTION> THE AMERICAN UNIVERSITY; 0008 </INSTITUTION>
<DESCRIPTORS> COMPUTER SCIENCE; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> MICHAEL A. GRAY </ADVISER>
<CLASSIFICATIONS> NIL </CLASSIFICATIONS>
<ABSTRACT>
Computer Reasoning programs must be able to accept
changes in current situations as well as to adopt new
information without losing consistency. Hence, a
mechanism for keeping knowledge in a consistent state
must be included to a problem solving component; this
role can be played by a Truth Maintenance System (TMS).
Furthermore, the trend for knowledge-based systems to be
larger and more diverse, as well as to cooperate among
them, is lately apparent. This argues for them to be
developed in a distributed fashion where the individual
modules have the characteristics of intelligent agents.
We present here the implementation of a Distributed
Truth Maintenance System that can be used by a
collection of nonmonotonically reasoning agents. The
system is based on a variation of the algorithm
presented by Bridgeland and Huhns and is implemented in
Common Lisp under a Unix environment. Furthermore, a
method for using domain knowledge to improve the
system's performance is described, based on the
principle of locality.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  2481 </NUMBER>
<ORDER>   AAI1360567 </ORDER>
<TITLE> AUTOMATED INTERPRETATION OF NUCLEAR MEDICINE SCANS FOR THE DIAGNOSIS OF PULMONARY EMBOLISM </TITLE>
<AUTHOR> BANISH, MICHELE RUGGIERO </AUTHOR>
<YEAR> 1994 </YEAR>
<INSTITUTION> UNIVERSITY OF ALABAMA IN HUNTSVILLE; 0278 </INSTITUTION>
<DESCRIPTORS> ENGINEERING, ELECTRONICS AND ELECTRICAL; HEALTH SCIENCES, RADIOLOGY; ENGINEERING, BIOMEDICAL; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> NIL </ADVISER>
<CLASSIFICATIONS> NIL </CLASSIFICATIONS>
<ABSTRACT>
This thesis applies pattern recognition technology to
aid the diagnosis of pulmonary embolism. Nuclear
medicine radiographs are processed by matched and
synthetic discriminant function filtering, with no human
interaction, and a diagnosis is reported. Matched
filtering the perfusion scan achieves a diagnosis rate
of 80%. The synthetic discriminant function consistently
missed more diagnoses than the matched filter. Expert
interpretation, confirmed by pulmonary angiography, is
used as the indicator of the accurate patient diagnosis.
A set of thirty-seven patients are diagnosed in this
study. The diagnostic performance of these algorithms
can be improved by incorporating additional ventilation
and perfusion scans into the interpretation method.
Diagnosis of pulmonary embolism is most often made by
visually interpreting the digital display of radiographs
on a graphics terminal. The visual interpretations are
based on a series of subjective comparisons. Reliance on
the subjective interpretation leads to inconsistency
that adversely affect diagnosis and leads to expensive
and invasive procedures, drug therapy, morbidity, and in
some cases mortality. Pattern recognition algorithms can
make consistent measurable comparisons among medical
image sets. Normal pulmonary patterns are recognized and
the degree of difference from the pattern indicates a
diagnosis of either low- or high-probability of
pulmonary embolism.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  2482 </NUMBER>
<ORDER>   AAI1360401 </ORDER>
<TITLE> DEVELOPMENT OF AN EXPERT SYSTEM FOR EVALUATING THE ENVIRONMENTAL QUALITY OF OFFICE BUILDINGS </TITLE>
<AUTHOR> AHMED, RABEE MOHAMED REFFAT </AUTHOR>
<YEAR> 1994 </YEAR>
<INSTITUTION> KING FAHD UNIVERSITY OF PETROLEUM AND MINERALS (SAUDI ARABIA); 1088 </INSTITUTION>
<DESCRIPTORS> ENGINEERING, CIVIL; ARTIFICIAL INTELLIGENCE; HEALTH SCIENCES, OCCUPATIONAL HEALTH AND THERAPY </DESCRIPTORS>
<ADVISER> NIL </ADVISER>
<CLASSIFICATIONS> NIL </CLASSIFICATIONS>
<ABSTRACT>
An office building is designed and built to host a group
of people performing distinct office work. The
performance of the users of such a building is
substantially influenced by its environmental quality.
Environmental Quality Factors (EQF) are lighting,
acoustic, thermal and indoor air quality. The evaluation
of environmental quality of such a building is an
indication of how well this building achieves the
environmental comfort for its users.
This study addressed the evaluation of environmental
quality of office buildings as an integrated approach
(lighting, acoustic, thermal and indoor air quality). In
this research, the performance criteria (variables) of
EQF and the scales used for evaluating these performance
criteria (attributes) were extracted from two main
sources: The first by carrying out an extensive
literature review through published papers, reports,
books, etc. related to EQF. The second by conducting the
interviews with 21 academicians and 29 practitioners who
are considered experts in these areas in the Eastern
Province of the Kingdom of Saudi Arabia.
Sixty-five performance criteria (variables) and their
attributes were extracted to investigate and comprehend
the EQF and used to build the knowledge base of
environmental quality evaluation of office buildings.
Also, the evaluation methods that the domain experts are
using for assessing the environment of office buildings
were analyzed.
A computerized unified program using Expert System for
Environmental Quality Evaluation (ESEQE) of office
buildings was developed simulating the methods that the
domain experts used in office environment assessment.
This computerized program correlated 100% with a hand
worked solution.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  2483 </NUMBER>
<ORDER>   AAI1360389 </ORDER>
<TITLE> APPLICATION OF ARTIFICIAL NEURAL NETWORKS TO OPTICAL CHARACTER RECOGNITION </TITLE>
<AUTHOR> AHMED, OSAMA ABDEL-WAHHAB </AUTHOR>
<YEAR> 1994 </YEAR>
<INSTITUTION> KING FAHD UNIVERSITY OF PETROLEUM AND MINERALS (SAUDI ARABIA); 1088 </INSTITUTION>
<DESCRIPTORS> ENGINEERING, ELECTRONICS AND ELECTRICAL; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> NIL </ADVISER>
<CLASSIFICATIONS> NIL </CLASSIFICATIONS>
<ABSTRACT>
In this work we examine shape descriptors and neural
network classifiers for the recognition of Arabic
characters. There are a total of 29 characters in the
Arabic alphabet. However, since the shape of character
changes depending on its position in the word
(beginning, middle, end, and stand-alone) we end up with
more than 29 shapes.
Shape descriptors are studied in this work. In
particular the moment invariant approach due to Hu.(3),
is studied and examined, with some modifications, on the
Arabic alphabet.
A new algorithm for training the feed forward neural
network is developed in this thesis. This algorithm is
shown to be faster and more stable than other schemes
presented in the literature.
The thesis presents the classification of shapes through
shape descriptors and feed forward neural network
classifiers. Testing on Arabic characters of different
sizes and orientation is carried out. Four separate
neural networks were trained for each character position
with the seven moment invariants of Hu.(3) as an input.
The output is trained to give five bits representing the
ASCII code of Arabic letters plus one bit to serve as a
parity check. Results of using the new training
algorithm for the feed-forward neural network are
presented. Very high recognition rate of Arabic fonts is
achieved.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  2484 </NUMBER>
<ORDER>   AAI1360388 </ORDER>
<TITLE> AN EXPERT SYSTEM FOR LOAD FLOW PLANNING </TITLE>
<AUTHOR> AL-HARARI, FARID YOUSEF ABDUL-RAHMAN </AUTHOR>
<YEAR> 1994 </YEAR>
<INSTITUTION> KING FAHD UNIVERSITY OF PETROLEUM AND MINERALS (SAUDI ARABIA); 1088 </INSTITUTION>
<DESCRIPTORS> ENGINEERING, ELECTRONICS AND ELECTRICAL; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> NIL </ADVISER>
<CLASSIFICATIONS> NIL </CLASSIFICATIONS>
<ABSTRACT>
A sensitivity based Intelligent Load Flow Planning
Engine is developed. The main objective of the engine is
to provide both an expert and novice user with a
friendly working environment, aiming at enhancing a
user's creativity in making operational plans in power
system.
The developed engine can review the initial load flow
results, detect abnormals and suggest necessary control
measures to alleviate line overloads and adjust the load
bus voltage, var generation and voltage angle of
generator bus to desired operating limits.
The expert system is developed using Expert System tool
called CLIPS based on rule-based method and forward
chaining reasoning process. Simulation studies with the
developed expert system applied to various power systems
show satisfactory results.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  2485 </NUMBER>
<ORDER>   AAI1360186 </ORDER>
<TITLE> AN INTELLIGENT TREADMILL CONTROLLER </TITLE>
<AUTHOR> ROBINSON, WALLACE JAY </AUTHOR>
<YEAR> 1994 </YEAR>
<INSTITUTION> UTAH STATE UNIVERSITY; 0241 </INSTITUTION>
<DESCRIPTORS> ENGINEERING, ELECTRONICS AND ELECTRICAL; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> ROBERT W. GUNDERSON </ADVISER>
<CLASSIFICATIONS> NIL </CLASSIFICATIONS>
<ABSTRACT>
The Intelligent Treadmill Controller addressed a local
company's hope to replace a treadmill motor's hardware
control approach with a rule-based design, implemented
in software to make more use of an already existing
microcontroller. In the process, a seemingly small
dollar value per unit may be saved; however, over a
year's time and based on current production, this
savings translates to hundreds of thousands of dollars.
In addition to financial aspects, a more constant motor
response, regardless of user load, was desired.
The system is considered to be a single-input-single-
output design, although inputs which were accounted for
in software include desired speed, as selected by the
user, time delay, to account for needed motor response
time and hardware delays, and external load, i.e., the
load of the user on the device. Actual speed was the
single output generated according to the control theory
approach. The time delay and external load approximation
inputs were rule-based parameters addressed in software.
The project was separated into two phases, the first of
which was a linear digital method that addressed the
load estimation problem, since a technique to measure
the torque effects of the user did not exist on the
treadmill. The second design used fuzzy logic to control
the motor response in a much more general sense,
producing a result depending on the difference of
desired and actual speeds, and not directly considering
the external load input, but adequately causing the
error in speeds to be minimized.
Complete implementation transpired in the first approach
and, as compared to the original hardware design,
superior control resulted at slow speeds and at least
equivalent performance at higher speeds. (Abstract
shortened by UMI.)
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  2486 </NUMBER>
<ORDER>   AAI1360169 </ORDER>
<TITLE> DESIGN AND SIMULATION OF AN IRRIGATION CONTROLLER USING LOCALIZED INTELLIGENT NODE CONTROL </TITLE>
<AUTHOR> DYE, TROY J. </AUTHOR>
<YEAR> 1994 </YEAR>
<INSTITUTION> UTAH STATE UNIVERSITY; 0241 </INSTITUTION>
<DESCRIPTORS> ENGINEERING, ELECTRONICS AND ELECTRICAL; ENGINEERING, AGRICULTURAL; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> ROBERT W. GUNDERSON </ADVISER>
<CLASSIFICATIONS> NIL </CLASSIFICATIONS>
<ABSTRACT>
Because of limited amounts of water and increasing costs
of electricity, many farmers are finding it difficult to
produce crops that are consistently profitable. This
thesis presents a solution to this problem by providing
intelligent node control using networking techniques to
schedule irrigation.
System design requirements include local control of
irrigation applications based on field needs, while
allowing pipeline pressure as the only global input
variable. The controller logic prevents system
oscillation due to pressure changes as valves open and
main line laterals fill. Other system design
requirements include provisions for water sharing,
system initialization, various pump characteristics and
manual override to allow human interaction.
A simulation program was written and is used to test the
controller algorithms. The program, written in C++,
provides pressure and flow data analyses, as well as, a
model of the evaporation losses.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  2487 </NUMBER>
<ORDER>   AAI1360088 </ORDER>
<TITLE> A STUDY OF NEURAL NETWORKS IN THERMAL SYSTEMS </TITLE>
<AUTHOR> PENARANDA, GUILLERMO </AUTHOR>
<YEAR> 1994 </YEAR>
<INSTITUTION> RICE UNIVERSITY; 0187 </INSTITUTION>
<DESCRIPTORS> ENGINEERING, MECHANICAL; ENGINEERING, HEAT AND THERMODYNAMICS; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> ANDREW J. MEADE, JR. </ADVISER>
<CLASSIFICATIONS> NIL </CLASSIFICATIONS>
<ABSTRACT>
Neural networks have been found to be useful as a
technique for the modeling of non-linear functions or
processes that involve several variables. The primary
goal of this thesis is to explore the feasibility of
applying feedforward backpropagation neural networks in
the optimization of multistage thermal systems.
Basically, the idea consists of using neural networks as
a function approximation technique for each stage of a
multistage process. After the successful approximation,
existing optimization methods are used to obtain the
parameters that optimize the system. In addition, it is
shown how feedforward backpropagation neural networks
can be used in solving calculus of variation problems,
by separating the process into discrete stages, thus
forming a multistage process problem. Finally, parallel
work was done in developing a faster deterministic
training algorithm, as an alternative to the time
consuming backpropagation training algorithm.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  2488 </NUMBER>
<ORDER>   AAI1360041 </ORDER>
<TITLE> THE APPLICATION OF FEEDFORWARD ARTIFICIAL NEURAL NETWORKS TO FUNCTION APPROXIMATION AND THE SOLUTION OF DIFFERENTIAL EQUATIONS </TITLE>
<AUTHOR> FERNANDEZ, ALVARO AGUSTIN </AUTHOR>
<YEAR> 1994 </YEAR>
<INSTITUTION> RICE UNIVERSITY; 0187 </INSTITUTION>
<DESCRIPTORS> APPLIED MECHANICS; ENGINEERING, AEROSPACE; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> ANDREW J. MEADE, JR. </ADVISER>
<CLASSIFICATIONS> NIL </CLASSIFICATIONS>
<ABSTRACT>
The increasing use of artificial neural networks and
other connectionist systems in engineering, and the
advantages obtained from that use, motivated the
development of an approach wherein a single or multiple
input feedforward artificial neural network with
piecewise linear hard limit transfer functions could be
directly "constructed." By viewing the network as a
function approximator, algebraic constraint equations
for the input and bias weights were derived which
transformed the mathematical character of the net into
one amenable to rigorous analysis without changing the
architecture. Further application of the method of
weighted residuals allowed direct solution for the
output weights without any training. Ordinary and
partial differential equations were solved using this
method and the resulting accuracy and reliability
verified. Further extension of this research will
hopefully lead to the creation of adaptive engineering
systems able to incorporate both governing equations and
experimental data.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  2489 </NUMBER>
<ORDER>   AAGC489486 </ORDER>
<TITLE> ARCHITECTURES CONNEXIONNISTES EVOLUTIVES: ALGORITHMES D'APPRENTISSAGE ET HEURISTIQUES; EVOLUTIVE CONNECTIONIST ARCHITECTURES: TRAINING ALGORITHMS AND HEURISTICS </TITLE>
<AUTHOR> FOMBELLIDA LOPEZ, MICHEL </AUTHOR>
<YEAR> 1994 </YEAR>
<INSTITUTION> UNIVERSITE DE L'ETAT A LIEGE (BELGIUM); 0422 </INSTITUTION>
<DESCRIPTORS> COMPUTER SCIENCE; ARTIFICIAL INTELLIGENCE PLACE COCKERILL, 1, B-4000  LIEGE, BELGIUM </DESCRIPTORS>
<ADVISER> NIL </ADVISER>
<CLASSIFICATIONS> NEURAL NETWORKS, FEEDFORWARD NETWORKS </CLASSIFICATIONS>
<ABSTRACT>
Introduced at the end of the nineteen fifties,
artificial neural networks represent a field of research
and applications that is highly regarded today, after a
long period of oblivion. Inspired more or less freely by
the way our brain functions, these systems are made of
numerous interconnected processing elements operating in
a parallel way (the term is connectionist
architectures). Their function is determined by the
architecture of the network, the strength of the
interconnections and the calculations of each processing
element. The networks, which are generic structures, are
able to adapt to a specific problem by a training
process controlled by a sole algorithm instead of by
detailed programming. Particularly suited to
classification and non-Parametric regression problems,
their implementation is often made difficult by the
empiricism of the choice of a set of parameters, that
influence the performance of the system (speed and
quality of the training). During this study, we make
every effort to correct this by putting forward, for
feedforward multi-layer networks, a rapid variant of the
error backpropagation training algorithm and an
automatic optimization of the network architecture.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  2490 </NUMBER>
<ORDER>   AAIMM94802 </ORDER>
<TITLE> MCALLESTER'S LANGUAGES IN A KNOWLEDGE REPRESENTATION CONTEXT  </TITLE>
<AUTHOR> FOGEL, JULIAN </AUTHOR>
<YEAR> 1994 </YEAR>
<INSTITUTION> UNIVERSITY OF WATERLOO (CANADA); 1141 </INSTITUTION>
<DESCRIPTORS> MATHEMATICS; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> FAHIEM BACCHUS </ADVISER>
<CLASSIFICATIONS> D. A. MCALLESTER </CLASSIFICATIONS>
<ABSTRACT>
A knowledge base written in a term subsumption language
(TSL) describes the world in terms of concepts, such as
the concept book or dog, and the relations (roles)
between them, such as loves or is-parent-of. TSLs are a
family of languages, each of which is completely
specified by a formal syntax and semantics, which
provide logical operators for building new concepts from
old ones. A TSL system is a program that automatically
builds an IS-A hierarchy from the concepts defined in a
knowledge base, and can draw inferences from this
knowledge. A different family of languages, defined by
McAllester in the context of automated reasoning,
provides complete polynomial-time inference algorithms
for subsets of first order logic. Two of McAllester's
languages, one with a taxonomic syntax and the other
with a Montagovian syntax, are examined in the context
of TSLs, with which they are shown to have some overlap.
In addition, the $forall C : R$ operator introduced by
the Montagovian language is formally shown to be
incomparable to the standard $forall R : C$ operator
provided by TSLs.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  2491 </NUMBER>
<ORDER>   AAIMM94224 </ORDER>
<TITLE> AUTOMATED COGNITIVE MODELLING FOR INTELLIGENT COMPUTER ASSISTED INSTRUCTION SYSTEMS CONTAINING QUALITATIVE KNOWLEDGE </TITLE>
<AUTHOR> POLIQUIN, JOEPH ALAIN MICHEL </AUTHOR>
<YEAR> 1994 </YEAR>
<INSTITUTION> ROYAL MILITARY COLLEGE OF CANADA (CANADA); 1103 </INSTITUTION>
<DESCRIPTORS> COMPUTER SCIENCE; ARTIFICIAL INTELLIGENCE; EDUCATION, TECHNOLOGY </DESCRIPTORS>
<ADVISER> B. J. FUGERE </ADVISER>
<CLASSIFICATIONS> NIL </CLASSIFICATIONS>
<ABSTRACT>
As the automated systems supporting education have
become more complex and adaptable to the users' need,
one of the fundamental requirements associated with the
design and construction of these systems has been to
obtain a more accurate picture of the students'
understanding at a given point in time. In more
traditional educational settings, teachers rely on
intuition and experience as much as empirical results to
derive such a picture. Automated teachers, on the other
hand, do not have the benefit of intuition and
experience and therefore, the picture must be created
using available student data.
The field of User Modelling has provided much of the
background for research in cognitive modelling of
students. In this thesis, the problem of cognitive
modelling for Intelligent Computer Assisted Instruction
systems is reviewed, and various techniques of modelling
are surveyed. One approach is considered as a suitable
candidate for domains containing Qualitative knowledge,
and augments an existing framework which is designed to
dynamically model students.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  2492 </NUMBER>
<ORDER>   AAIMM94219 </ORDER>
<TITLE> CONJUGATE GRADIENT BACKPROPAGATION NEURAL NETWORKS WITH A NOVEL NEURON INPUT FUNCTION </TITLE>
<AUTHOR> JONES, GLENN SCOTT </AUTHOR>
<YEAR> 1994 </YEAR>
<INSTITUTION> ROYAL MILITARY COLLEGE OF CANADA (CANADA); 1103 </INSTITUTION>
<DESCRIPTORS> COMPUTER SCIENCE; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER>  P. E. ALLARD </ADVISER>
<CLASSIFICATIONS> NIL </CLASSIFICATIONS>
<ABSTRACT>
The multi-layer feedforward neural network trained with
the backpropagation learning algorithm is considered
along with two potential modifications:
First is an alternative calculation of the input signal,
or activation, which is fed into each neuron for
subsequent application of the neuron transfer function.
Through a simple squaring of the normal input signal,
additional nonlinearity is injected into the neuron
mechanism. This adds to the number of target states (or
error minima) available to be found by the learning
algorithm. Having a larger number of viable target
states appears to increase the likelihood of successful
training and the speed of the training process.
Second, we look at changing the backpropagation learning
algorithm by adopting an existing technique from the
field of optimization known as conjugate gradient
descent. Conjugate gradient techniques have become
increasingly popular in recent neural network
development and offer the prospect of conducting
artificial neural network (ANN) learning in a more
efficient fashion.
Finally we evaluate our proposed modifications to
backpropagation with a real world industrial modeling
problem. We consider a large data set consisting of
almost 1800 observations of more than 80 variables which
describes a highly complex chemical process. We evaluate
our modifications to backpropagation by developing ANN
models of this industrial process using the different
variants of backpropagation.
Squared neuron activation and conjugate gradient descent
are found to improve training performance for the
problems considered, but typical difficulties with
backpropagation (e.g. local minima) remain.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  2493 </NUMBER>
<ORDER>   AAIMM94077 </ORDER>
<TITLE> A FUZZY-PID HYBRID CONTROLLER FOR A PILOT SCALE PEANUT ROASTER </TITLE>
<AUTHOR> KESSLER, MICHAEL ERWIN </AUTHOR>
<YEAR> 1994 </YEAR>
<INSTITUTION> UNIVERSITY OF GUELPH (CANADA); 0081 </INSTITUTION>
<DESCRIPTORS> ENGINEERING, CHEMICAL; AGRICULTURE, FOOD SCIENCE AND TECHNOLOGY; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> VALERIE J. DAVIDSON </ADVISER>
<CLASSIFICATIONS> NIL </CLASSIFICATIONS>
<ABSTRACT>
A dual mode fuzzy-PID hybrid controller was developed
and tested for a continuous, forced convection hot air
pilot scale peanut roaster. The aim of this thesis was
to design a generic controller which could outperform
the conventional PID controller. The control algorithm
uses both conventional PID control and fuzzy logic
control.
The second goal was to develop a new method of obtaining
the Ziegler-Nichol's PID tuning parameters using a PRBS
system identification.
It was found that the hybrid controller does in fact
outperform the conventional PID controller for the
peanut roaster. The advantages of the hybrid controller
over the PID controller were most apparent during set
point changes. The Hybrid controller produced a set
point response with little or no overshoot as well as
having a quicker rise time than the PID controller.
The PRBS identification proved to be an effective tool
for the estimation of the Ziegler-Nichol's PID tuning
parameters.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  2494 </NUMBER>
<ORDER>   AAIMM94040 </ORDER>
<TITLE> SELECTION OF FEATURES FOR CLASSIFICATION TASKS USING NEURAL NETWORKS AND GENETIC ALGORITHMS </TITLE>
<AUTHOR> CUI, CHEN </AUTHOR>
<YEAR> 1994 </YEAR>
<INSTITUTION> UNIVERSITY OF GUELPH (CANADA); 0081 </INSTITUTION>
<DESCRIPTORS> COMPUTER SCIENCE; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> D. STACEY; M. MCLEISH </ADVISER>
<CLASSIFICATIONS> NIL </CLASSIFICATIONS>
<ABSTRACT>
The field of automated classification has recently seen
a number of advances. Highly related to this subject is
the problem of feature selection which is to select that
subset of features from a large initial set which
provides the best classification performance. The major
benefit of feature selection is not only that it may
reduce cost but also that it could eliminate noisy
features. There are many approaches to this problem,
which include genetic algorithms, backward search,
forward search, and artificial neural networks.
In this thesis, two new approaches for feature selection
and automated classification are proposed. The first one
uses a combination of ART2 with backpropagation--two
models of artificial neural networks. A second approach
has also been examined which combines genetic algorithms
with backpropagation and fuzzy logic. Two real world
problems--coating material selection and cellular
feature selection--have been tested using these
approaches and have got promising results.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  2495 </NUMBER>
<ORDER>   AAIMM93789 </ORDER>
<TITLE> THE APPLICATION OF GENETIC ALGORITHMS TO NEURAL NETWORKS </TITLE>
<AUTHOR> MACLENNAN, GEORGE ALEXANDER </AUTHOR>
<YEAR> 1994 </YEAR>
<INSTITUTION> DALHOUSIE UNIVERSITY (CANADA); 0328 </INSTITUTION>
<DESCRIPTORS> COMPUTER SCIENCE; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> KEVIN MORIARTY </ADVISER>
<CLASSIFICATIONS> NIL </CLASSIFICATIONS>
<ABSTRACT>
Neural network design and training has been plagued by
the difficulty to fully understand exactly how they
perform the transformations. The ability to find an
appropriate solution is hampered by a search space which
is vast and contains many local optima. Genetic
algorithms provide a structure under which to
efficiently search this solution space and arrive at a
near-optimal network. This thesis explores the progress
made in this field in the areas of representation,
genetic operators, and fitness functions for the
application of genetic algorithms to neural network
design and training. The search by genetic algorithm for
a design of a neural network to map the XOR function is
studied and the appropriate training parameters for
efficient design are investigated.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  2496 </NUMBER>
<ORDER>   AAIMM93324 </ORDER>
<TITLE> SYNTHESIS OF MULTILAYER FEEDFORWARD NEURAL NETWORKS WITH HARD-LIMITING NEURONS </TITLE>
<AUTHOR> YU, STEPHEN XIANGUI </AUTHOR>
<YEAR> 1994 </YEAR>
<INSTITUTION> UNIVERSITY OF WINDSOR (CANADA); 0115 </INSTITUTION>
<DESCRIPTORS> ENGINEERING, ELECTRONICS AND ELECTRICAL; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> ROBERT NAN K. LOH; W. C. MILLER </ADVISER>
<CLASSIFICATIONS> NIL </CLASSIFICATIONS>
<ABSTRACT>
The training and synthesis of multilayer and multi-
output feedforward artificial neural networks with hard-
limiting neurons is considered in this thesis. Networks
with hard-limiting neurons are considered as they are
easier to implement using VLSI technology. New results
are presented that deal with varying the neuron
activation function, accelerating the convergence of
training, and the synthesis of neural networks.
A steepness factor that allows one to vary the neuron
activation function between sigmoidal and hard-limiting
properties is used. A function has been developed
whereby this factor is changed during the training
process according to an exponential function with a
negative exponent given by the sum-squared-error. The
resultant varying neuron activation function is used in
conjunction with the standard backpropagation algorithm
to allow the training of neural networks with hard-
limiting neurons instead of only ones with sigmoidal
properties.
A method to accelerate the convergence of the
backpropagation algorithm has been derived using the
concept of orthogonal vectors during successive
iterations. A new expression for updating the weighting
coefficients has been derived that contains a momentum
function instead of simply a momentum constant.
A new synthesis technique is presented for multi-layer,
multi-output neural networks that utilizes a generalized
Tiling algorithm that has been developed in the thesis.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  2497 </NUMBER>
<ORDER>   AAI9517301 </ORDER>
<TITLE> A FUZZY COGNITIVE MAP KNOWLEDGE REPRESENTATION FOR PERFORMING FAILURE MODES AND EFFECTS ANALYSIS </TITLE>
<AUTHOR> PELAEZ, COLON ENRIQUE </AUTHOR>
<YEAR> 1994 </YEAR>
<INSTITUTION> UNIVERSITY OF SOUTH CAROLINA; 0202 </INSTITUTION>
<DESCRIPTORS> ENGINEERING, GENERAL; COMPUTER SCIENCE; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> JOHN B. BOWLES </ADVISER>
<CLASSIFICATIONS> NIL </CLASSIFICATIONS>
<ABSTRACT>
Automating Failure Modes and Effects Analysis (FMEA) to
do more than simple clerical functions, data collection,
data-base manipulation, and automatic report generation,
has been a long sought goal of reliability analysts.
This dissertation investigates the application of fuzzy
knowledge representations and inferencing techniques
using fuzzy cognitive maps, and fuzzy knowledge
combination to a system for failure modes and effects
analysis.
Its main contribution is the specification of a
graphical-causal representation of failures, their
manipulation using fuzzy logic, and a strategy for
combining these graphical representations to resolve
conflicting expert opinions during a system's design
evaluation.
The strategy proposed focuses on the knowledge-use level
perspective to provide a complete understanding of the
problem. Fuzzy set theory and fuzzy cognitive maps are
utilized to represent causality when performing the
FMEA. Failure modes, effects, causes, etc., are
represented through a set of concept nodes, and weighted
linguistic relationships between concepts to express
causality.
This research seeks to establish the theoretical
background that is required for acquiring- and
representing causality graphically and linguistically,
its manipulation using fuzzy logic techniques, and later
the combination of the expert's graphical representation
to handle consensus FMEA.
Graphic-causal FMEA is emphasized with motivation to
include linguistic descriptions of causal relationships
and possible semantic constraints. Furthermore, this
research argues that the fuzzy cognitive map model
provides a more suitable and more natural representation
of the kind of knowledge used in FMEA.
Some experiments are conducted to illustrate the utility
of the developed strategy. Although some extensions to
the proposed method are necessary to build a meaningful
prototype system; the knowledge representation,
inferencing strategy and knowledge combination
approaches developed in this research provide a solid
ground for building an intelligent knowledge-based FMEA
system.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  2498 </NUMBER>
<ORDER>   AAI9517296 </ORDER>
<TITLE> DYNAMIC NEURAL NETWORK CONTROL </TITLE>
<AUTHOR> NIKRAVESH, MASOUD </AUTHOR>
<YEAR> 1994 </YEAR>
<INSTITUTION> UNIVERSITY OF SOUTH CAROLINA; 0202 </INSTITUTION>
<DESCRIPTORS> ENGINEERING, CHEMICAL; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> ANDREW E. FARELL </ADVISER>
<CLASSIFICATIONS> DNNC) (NEURAL NETWORK, PROCESS CONTROL </CLASSIFICATIONS>
<ABSTRACT>
Dynamic Neural Network Control (DNNC) is a model
predictive control strategy potentially applicable to a
large class of nonlinear systems. It uses a neural
network to model the process and its mathematical
inverse to control the process. The DNNC strategy
differs from previous neural network controllers because
the network structure is very simple and offers
potential for fewer weights and better initialization of
network weights. DNNC's ability to model nonlinear
process behavior does not appear to suffer as a result
of its simplicity.
In this research, the performance of the DNNC strategy
for controlling highly non-linear CSTR with time varying
parameters including activation energy (i.e.,
deactivation of catalyst) and heat transfer coefficient
(i.e. fouling) is demonstrated. First, the DNNC
controller performance was compared with PID control and
a recently proposed neural network controller (NIMC)
under conditions of constant parameters. In comparison
to PID and NIMC, DNNC showed excellent controller
performance in spite of its simplicity (total number of
weights and bias terms = 15) compared to NIMC (total
number of weights and bias terms = 70). The DNNC
strategy is also able to reject the unmodeled
disturbance more effectively than either the PID or the
NIMC strategy.
For the nonlinear, time varying case the performance of
DNNC was compared to the PID control strategy. DNNC
(without on-line adaptation) showed excellent
performance in controlling the exothermic CSTR in the
region where the PID controller failed. It has been
shown that the DNNC controller strategy is robust enough
to perform well over a wide range of operating
conditions. A first order filter was introduced into the
DNNC structure in order to ensure stability and
robustness.
The DNNC design technique for nonlinear dynamic systems
is closely related to its stability properties. The
local and global stability analysis in the DNNC
framework is much easier than conventional neural
networks. The results from the DNNC stability analysis
will be used to define the Neural Network Stability
Index (NNSI). NNSI can be used to determine the optimal
network structure, to analyze the controller
performance, and to design an optimal controller.
For time varying processes, updating conventional neural
network models which are complex and consist of several
nodes and weights, is difficult and time consuming.
Since the DNNC model is very simple, the updating
routine is, in fact, much faster than that of any other
neural network hybrid model that has been proposed
previously. DNNC has the ability to rapidly and
recursively learn from plant data.
The design of multivariable controllers in the DNNC
control strategy is also straightforward. The DNNC
weights represent the process model and interaction
between input/output and it is possible to determine the
severity of the interaction by interpreting the network
weights.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  2499 </NUMBER>
<ORDER>   AAI1378440 </ORDER>
<TITLE> A FUZZY CONTROLLED NONUNIFORM DIFFUSION MODEL FOR COMPETING PRODUCTS </TITLE>
<AUTHOR> BEIFUSS, STEPHAN W. </AUTHOR>
<YEAR> 1994 </YEAR>
<INSTITUTION> UNIVERSITY OF SOUTHERN CALIFORNIA; 0208 </INSTITUTION>
<DESCRIPTORS> BUSINESS ADMINISTRATION, MARKETING; MATHEMATICS; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> WLODEK PROSKUROWSKI </ADVISER>
<CLASSIFICATIONS> NIL </CLASSIFICATIONS>
<ABSTRACT>
The Bass Diffusion Model was developed in 1969. Since
then, many extensions have been suggested to overcome
several limitations of the model. In this paper, we
further extend some of the proposed improvements to
derive a new diffusion model for competing products.
Independently, fuzzy logic systems have been developed
and have proved to be a powerful tool for engineering
control systems, because they allow to include both
numerical and linguistic information.
We introduced a fuzzy logic controller in the proposed
diffusion model in order to get a forecast of the
behavior of the diffusion process. The performed
simulations show reasonable results, but they also point
out limitations of the current version of our fuzzy
controller. We expect that future improvements leading
to an adaptive version of the controller will result in
a practical forecast tool.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  2500 </NUMBER>
<ORDER>   AAI9517003 </ORDER>
<TITLE> APPLICATION OF REPETITIVE CONTROL AND ITERATIVE LEARNING CONTROL TO COLD ROLLING PROCESSES </TITLE>
<AUTHOR> GARIMELLA, SRINIVAS S. </AUTHOR>
<YEAR> 1994 </YEAR>
<INSTITUTION> THE OHIO STATE UNIVERSITY; 0168 </INSTITUTION>
<DESCRIPTORS> ENGINEERING, MECHANICAL; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> KRISHNASWAMY SRINIVASAN </ADVISER>
<CLASSIFICATIONS> NIL </CLASSIFICATIONS>
<ABSTRACT>
Control of the thickness of the strip in cold rolling of
flat rolled products, which impacts the quality of the
product, and of the tension in the strip which impacts
productivity of the operation, are considered.
Recognizing that the process is repetitive and is
subject to periodic disturbances within each cycle (i.e.
during the rolling of a coil) and from cycle-to-cycle
(i.e. from coil-to-coil during the rolling of a batch of
similar products), two control techniques--repetitive
control for within coil control and iterative learning
control for coil-to-coil control, are applied to the
process in the dissertation.
Application of repetitive control to rolling offers new
opportunities for advancing the design and analysis of
repetitive control systems, the most significant one
being the need for a repetitive controller structure for
tracking/regulation applications subject to
reference/disturbance inputs composed of multiple
periodic components whose periods are not rationally
related. This need stems from the recognition that the
roll eccentricity disturbance, in general, may be due to
multiple rolls whose diameters may not be rationally
related. Noting that a parallel addition of multiple
repetitive controllers, suggested by intuition, does not
work, a simple modification of this arrangement for SISO
systems that stabilizes the system while providing
significant reduction of the gauge error due to roll
eccentricity, is proposed in the thesis. Analysis and
design procedures to achieve effective trade-offs
between the accuracy, stability and transient response
of the system established are provided.
Noting that the eccentricity disturbances produce
periodic disturbances in gauge and tension due to the
multivariable nature of the process, a MIMO repetitive
controller is proposed for controlling these
disturbances. Since these disturbances may have multiple
periodic components whose periods are not rationally
related, the multiple repetitive controller structure
proposed for SISO systems is extended to MIMO systems
along with procedures for analysis and design.
Coil-to-coil control of gauge and tension by means of
iterative learning control is considered to compensate
for repetitive disturbances such as errors in the
feedforward, static setup model, and variations in roll
bite friction due to roll speed changes during thread-up
and thread-down transitions. A MIMO learning controller
structure that utilizes the same parametrization as that
of the repetitive controller is proposed. A sufficient
condition for the convergence of the system, which
closely resembles the condition for the stability of
MIMO repetitive control systems, and guidelines for
selecting learning controller parameters to ensure rapid
error convergence and acceptable accuracy are presented.
Threading phase simulations compare performance of these
learning controllers to that of coil-to-coil adaption
schemes, which involve adaption of either the yield
stress model parameter or the friction coefficient in
setup models, selected a priori. The adaption scheme is
driven by error in the steady state roll force predicted
by the setup model. Simulations show that the scheme
works well only if the adaption parameter is chosen
correctly. Learning controllers, on the other hand, do
not suffer from this limitation. The extent to which
gauge and tension errors during thread could be reduced
with learning control depends on how accurately the
dynamics of the system are known. Finally, mill
acceleration simulations confirm that gauge and tension
disturbances caused by friction variations can be
substantially reduced by applying learning control.
Similar performance improvements with learning control
can be expected for mill deceleration as well.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  2501 </NUMBER>
<ORDER>   AAI9516702 </ORDER>
<TITLE> TRAFFIC DATA INTEGRATION IN ADVANCED TRAVELER INFORMATION SYSTEMS USING FUZZY OPERATOR LOGIC </TITLE>
<AUTHOR> TARKO, ANDRZEJ PIOTR </AUTHOR>
<YEAR> 1994 </YEAR>
<INSTITUTION> UNIVERSITY OF ILLINOIS AT CHICAGO; 0799 </INSTITUTION>
<DESCRIPTORS> ENGINEERING, CIVIL; COMPUTER SCIENCE; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> NIL </ADVISER>
<CLASSIFICATIONS> CONGESTION DETECTION </CLASSIFICATIONS>
<ABSTRACT>
The continuously deteriorating performance of
transportation systems has created a need for new
solutions. Advanced Traveler Information Systems (ATIS),
a component of Intelligent Vehicle Highway Systems, is
thought to assist travelers in reducing travel times and
increasing comfort of traveling. This can be
accomplished by using updated, complete traffic
information. General data sparsity and variety create a
need for efficient data processing from all available
sources.
The primary goal of this research is to investigate the
feasibility of using fuzzy logic as a framework for
traffic data processing based on an example algorithm of
congestion detection in signalized networks. An
artificial intelligence approach to data integration, is
designed to achieve the maximum benefit by using several
data sources and expert rules to interpret and integrate
the available data. The additional computational effort
required is addressed in the algorithm design.
The data integration process is viewed as a tree
consisting of two data operations: conversion and
fusion. The formalism of fuzzy operator logic and the
Dempster-Shafer rule of combination are used as a
framework for data integration. The knowledge base has
been structured to expose and utilize data redundancy in
order to enhance the traffic information quality. The
original Dempster-Shafer formalism has been modified to
improve fusion of contradictory information. The
congestion information desired is retrieved from the
knowledge base through a sequence of arithmetic and
minimax operations which makes the process of data
integration time efficient.
A prototype algorithm for congestion detection has been
calibrated from data produced by the INTRAS simulation
program. The measure of algorithm performance and the
calibration process have been designed for application
to real world conditions. The calibration and evaluation
results indicate that the algorithm is capable of
producing confident answers about congestion conditions
for a large number of links when sparse data prevail.
The analysis also shows that intelligent data processing
may remarkably decrease the need for on-line data by 60-
80%.
An implementation of the developed congestion detection
algorithm is considered to support incident detection in
the networks operating under ATIS. Also the use fuzzy
operator logic and the Dempster-Shafer rule of
combination for on-line estimation of travel times is
discussed.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  2502 </NUMBER>
<ORDER>   AAI9516520 </ORDER>
<TITLE> ARTIFICIAL NEURAL NETWORK METAMODELS OF STOCHASTIC COMPUTER SIMULATIONS </TITLE>
<AUTHOR> KILMER, ROBERT ALLEN </AUTHOR>
<YEAR> 1994 </YEAR>
<INSTITUTION> UNIVERSITY OF PITTSBURGH; 0178 </INSTITUTION>
<DESCRIPTORS> ENGINEERING, INDUSTRIAL; OPERATIONS RESEARCH; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> NIL </ADVISER>
<CLASSIFICATIONS> NIL </CLASSIFICATIONS>
<ABSTRACT>
A computer simulation model can be thought of as a
relation which connects input parameters to output
measures. Since these models can become computationally
expensive in terms of processing time and/or memory
requirements, there are many reasons why it would be
beneficial to be able to approximate these models in a
computationally expedient manner. This research examines
the use of artificial neural networks (ANN), to develop
a metamodel of computer simulations. The development and
use of the Baseline ANN Metamodel Approach is provided
and is shown to outperform traditional regression
approaches. The results provide a solid foundation and
methodological direction for developing ANN metamodels
to perform complex tasks such as simulation
'optimization', sensitivity analysis, and simulation
aggregation/reduction.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  2503 </NUMBER>
<ORDER>   AAI9516121 </ORDER>
<TITLE> A SYSTEM FOR INTELLIGENT DOCUMENT IMAGE ANALYSIS, RECOGNITION AND COMPRESSION </TITLE>
<AUTHOR> JIANG, WEY-WEN CINDY </AUTHOR>
<YEAR> 1994 </YEAR>
<INSTITUTION> COLUMBIA UNIVERSITY; 0054 </INSTITUTION>
<DESCRIPTORS> ENGINEERING, ELECTRONICS AND ELECTRICAL; COMPUTER SCIENCE; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> HENRY E. MEADOWS </ADVISER>
<CLASSIFICATIONS> IMAGE PROCESSING </CLASSIFICATIONS>
<ABSTRACT>
This dissertation presents a framework for solving tasks
in intelligent document analysis systems. These systems
aim at converting a document's pixel representation of
text blocks into an equivalent symbolic representation
and at removing redundancy in neighboring pixels of
pictorial blocks.
Document images are composed of blocks of different
types, i.e. text, graphics, halftone images, and
graytone images. We propose a document analysis system
which performs segmentation, labeling, classification,
and compression of blocks in document images. A flexible
segmentation scheme employing three passes of run-length
linking is designed. A block labeling scheme is used to
label blocks of any shape. Our classifier can identify
block types accurately by examining the texture of
labeled blocks. Based on characteristics of each block
type, an appropriate compression scheme is applied.
Black and white graphics, which usually have long white
runs or black runs, can be compressed with run-length
coding. We propose a novel two-layer coding/decoding
system to compress halftone blocks losslessly and
efficiently. The multi-layer perceptron, a feed-forward
neural network, is employed to exploit the non-linear
correlation of neighboring pixels and to compress
graytone images losslessly.
Text images are recognized by optical character
recognition (OCR) systems and stored in ASCII form. Most
current OCR systems perform binarization on inputs
before attempting recognition. However, a significant
amount of information is lost during binarization of
acquired graytone images. We propose a restoration
scheme to convert graytone text images into bi-level
images, while retaining information in graytones.
Another good application of our restoration scheme is
the recognition of texts in scene images.
Our proposed framework provides several advantages over
previous work: (1) Documents can have more complex
layout styles. (2) Images segmented using our proposed
scheme are better for classification. (3) Measures used
for classification can more accurately discriminate
among block types. (4) Our compression schemes for
halftone blocks and graytone blocks outperform standard
algorithms in compression ratio. (5) Text images, when
restored into bi-level images using our proposed scheme,
are closer to ideal ones and better adapted for
character recognition. Applications of this work exist
in any place where processing of printed information is
needed.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  2504 </NUMBER>
<ORDER>   AAI9516095 </ORDER>
<TITLE> RUNTIME REORGANIZATION OF PARALLEL AND DISTRIBUTED EXPERT DATABASE SYSTEMS </TITLE>
<AUTHOR> DEWAN, HASANAT M. </AUTHOR>
<YEAR> 1994 </YEAR>
<INSTITUTION> COLUMBIA UNIVERSITY; 0054 </INSTITUTION>
<DESCRIPTORS> COMPUTER SCIENCE; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> SALVATORE J. STOLFO </ADVISER>
<CLASSIFICATIONS> PARALLEL SYSTEMS, DISTRIBUTED SYSTEMS, DATABASE </CLASSIFICATIONS>
<ABSTRACT>
In the last decade and half, scientific and commercial
databases have grown at a fast pace as increasingly many
enterprises have begun offering and using database-
centered services. Concomitantly, new application
requirements have placed unusual processing demands on
existing databases. Many researchers believe that next
generation database systems will be required to provide
efficient and scalable facilities for high level
inference and complex query processing.
In this thesis, we address the efficiency and
scalability problem in the context of Database Rule
Processing Systems (DRPS). We propose a scalable
strategy for the efficient parallel processing of rule
programs applied to massive databases. We introduce
predictive load balancing techniques in a synchronous
model of rule execution, where the variance in runtime
of the distributed sites is minimized per cycle of rule
processing, thus increasing utilization and speedup. We
demonstrate that static load balancing techniques are
insufficient, and thus low overhead dynamic load
balancing is the key to successful scaling. We present a
form of dynamic load balancing that is based upon
predicting future system loads, rather than conventional
demand-driven or adaptive approaches that monitor
current system state. We utilize a combination of meta-
data on the database and observed system performance to
predictively formulate load balancing decisions over a
parallel ensemble. We analyze a number of possible
predictive dynamic load balancing protocols by
isoefficiency analysis to guide the design of a
distributed rule processing system. Our results are
outlined as follows. We develop a set-oriented rule
language with parallel execution semantics to overcome
the constraints imposed by tuple-oriented rule
languages. We initially assume a replicated database
configuration for simplicity, and we explore automatic
work partitioning techniques, including heuristic
determination of partitioning attributes, predictive
dynamic load balancing protocols to apply them, a "self-
monitoring" principle for system modelling that predicts
system performance in the near term based upon recent
performance history, and extensive use of statistics on
the underlying database (meta data) to achieve load
balancing and hence scaling. We then extend our basic
results and develop comprehensive algorithms for
predictively balanced inference support and complex
query processing over distributed database
configurations. Our approach enables large-scale expert
databases. It is expected that the resulting
quantitative improvements will lead to qualitative
improvements in the applications built within this
framework.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  2505 </NUMBER>
<ORDER>   AAI9514916 </ORDER>
<TITLE> A DIAGNOSTIC EXPERT SYSTEM, ILIAD, AS A QUALITY REVIEW SCREEN  </TITLE>
<AUTHOR> LAU, LEE MIN </AUTHOR>
<YEAR> 1994 </YEAR>
<INSTITUTION> THE UNIVERSITY OF UTAH; 0240 </INSTITUTION>
<DESCRIPTORS> HEALTH SCIENCES, GENERAL; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> NIL </ADVISER>
<CLASSIFICATIONS> EXPERT SYSTEM </CLASSIFICATIONS>
<ABSTRACT>
A diagnostic expert system, Iliad, was evaluated as a
quality review tool in the Medicare inpatient review
performed by Peer Review Organizations (PROs).
The current PRO review appeared to underdetect
diagnostic errors. The PRO review started with a nurse
review using generic quality screens. Only cases flagged
by the nurse review as containing a potential quality
problem were then referred for a physician review. The
quality screens focused only on treatment, discharge and
documentation. Physician review, directed by the
concerns raised in the nurse review, might also have
failed to detect diagnostic errors. Thus, the expert
diagnostic capability of Iliad could be useful as a
nurse review screen for diagnostic errors. A discrepancy
between Iliad's diagnosis and that made by the attending
physician for a case would flag a potential diagnostic
error. The case could then be referred to a physician
for confirmation.
Two experiments were performed. The first compared Iliad
review with the current PRO review. On 100 Medicare
inpatient cases flagged by the Utah Peer Review
Organization (UPRO) nurse review as containing potential
problems, and which contained diagnoses recognized by
Iliad, Iliad review found 17% of the cases to have
contained a diagnostic error, significantly higher than
the 0% Diagnostic Error Rate (DER) found by UPRO. The
Iliad nurse review True Positive Rate (TPR) was also
significantly higher than that of the UPRO nurse review.
The second experiment compared Iliad review to the
computerized UCDS (Unified Clinical Data Set) review
undergoing testing at UPRO. In a random sample of 326
Utah Medicare inpatient cases containing diagnoses
recognized by Iliad, Iliad review found a significantly
higher DER of 6%, compared to that found by the UCDS
review (0.8%). The Iliad nurse review TPR was also
significantly higher than that of the UCDS nurse review.
The effects of varying the "strictness" of Iliad review,
different diagnosis matching strategies, different nurse
reviewers, and different physician reviewers were
explored. A cost-benefit estimation was also performed.
It was concluded that Iliad review was effective and
efficient in detecting diagnostic errors causing quality
of care problems in Medicare hospitalizations.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  2506 </NUMBER>
<ORDER>   AAI9514914 </ORDER>
<TITLE> SMART PARTS: TOWARD THE AUTOMATED SYNTHESIS OF NEURAL CIRCUITS </TITLE>
<AUTHOR> HURDLE, JOHN FRANKLIN </AUTHOR>
<YEAR> 1994 </YEAR>
<INSTITUTION> THE UNIVERSITY OF UTAH; 0240 </INSTITUTION>
<DESCRIPTORS> COMPUTER SCIENCE; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> NIL </ADVISER>
<CLASSIFICATIONS> NIL </CLASSIFICATIONS>
<ABSTRACT>
This work introduces a new niche of neural hardware
called SMART PARTS and describes how to synthesize them
using a new tool named TROUT. SMART PARTS are "smart" in
the sense that they can learn an input$rightarrow$output
mapping implicit in a data set. Like any good supervised
learning technique, those embedded in SMART PARTS can
generalize based on what they have learned. SMART PARTS
are "parts" in the sense that they are small, high-
speed, environmentally-robust, application-specific
neural processors meant to provide the neural hardware
designer what off-the-shelf MSI and LSI parts provide
the conventional digital designer: customized
functionality in a small package. Unlike such parts
SMART PARTS have to be synthesized to meet the needs of
an application. The key is to match an application set
with a neural model. To provide a rational basis linking
hardware issues and neural theory, a novel definition
for "neural model" is provided, one that relies on the
functional abstraction of neurons and synapses, and one
that promotes architecture to a first-class status.
Starting with only an application's data set, TROUT can
produce SMART PARTS virtually automatically. It uses
several novel techniques in the process: reliance on a
provably minimal neural model specification;
exploitation of user-supplied hints and elimination of
"cool" attributes (attributes that contribute little, in
an information theoretic sense, to the
input$rightarrow$output mapping) to minimize model
complexity; multimodel model selection and subsequent
parameter optimization driven by circuit and data set
constraints; exclusive use of structurally-adaptive
neural models; and use of asynchronous circuit design
techniques that provide an excellent fit to neural model
implementation. This dissertation documents how each of
these techniques can be used in a very practical way to
achieve a nearly optimal neural part, one tailored to a
specific application. Several examples are included to
illustrate the TROUT synthesis process.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  2507 </NUMBER>
<ORDER>   AAI9514610 </ORDER>
<TITLE> ANALYSIS AND SYNTHESIS OF DISTRIBUTED SYSTEMS  </TITLE>
<AUTHOR> ZHUANG, YAN </AUTHOR>
<YEAR> 1994 </YEAR>
<INSTITUTION> UNIVERSITY OF MARYLAND COLLEGE PARK; 0117 </INSTITUTION>
<DESCRIPTORS> ENGINEERING, ELECTRONICS AND ELECTRICAL; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> JOHN S. BARAS </ADVISER>
<CLASSIFICATIONS> ADAPTIVE WAVELET NEURAL NETWORKS </CLASSIFICATIONS>
<ABSTRACT>
We first model and analyze distributed systems including
distributed sensors and actuators. We then consider
identification of distributed systems via adaptive
wavelet neural networks (AWNNs) by taking advantage of
the multiresolution property of wavelet transforms and
the parallel computational structure of neural networks.
A new systematic approach is developed in this
dissertation to construct an optimal discrete
orthonormal wavelet basis with compact support for
spanning the subspaces employed for system
identification and signal representation. We then apply
a backpropagation algorithm to train the network to
approximate the system. Filter banks for parameterizing
wavelet systems are studied. An analog VLSI
implementation architecture of the AWNN is also given in
this dissertation. This work is applicable to signal
representation and compression under optimal orthonormal
wavelet bases in addition to progressive system
identification and modeling. We anticipate that this
work will find future applications in signal processing
and intelligent systems.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  2508 </NUMBER>
<ORDER>   AAI9514499 </ORDER>
<TITLE> SPATIO-TEMPORAL IMAGE PROCESSING FOR VEHICULAR NAVIGATION </TITLE>
<AUTHOR> BURLINA, PHILIPPE MARTIN </AUTHOR>
<YEAR> 1994 </YEAR>
<INSTITUTION> UNIVERSITY OF MARYLAND COLLEGE PARK; 0117 </INSTITUTION>
<DESCRIPTORS> ENGINEERING, ELECTRONICS AND ELECTRICAL; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> RAMA CHELLAPPA </ADVISER>
<CLASSIFICATIONS> NIL </CLASSIFICATIONS>
<ABSTRACT>
Several aspects of the problem of dynamic image analysis
are investigated with the intended purpose of addressing
certain issues commonly encountered in Intelligent
Vehicle and Highway Systems and autonomous vehicular
navigation. First, the class of motions with arbitrary
smooth maneuvers (i.e., with polynomial translational
components) are considered. For these dynamic
situations, we study a family of temporal parametric
descriptors, shown to be visually recoverable, which are
relevant for vehicle guidance, enable a qualitative
description of the trajectory, and follow
straightforward dynamics if the detected model order is
correct. For these parameters, methods based on
brightness derivatives and methods based on feature
trajectories are both proposed. Next we address inherent
limitations in estimating these parameters. An
integrated model-based estimation and decision theoretic
approach enabling model order validation, collision
detection and estimation is described. Experiments on
both synthetic data and real imagery are presented to
substantiate and test the modules. Other issues such as
the use of log-polar retinas are considered as well.
Finally, we investigate the use of special transforms
for the analysis of image motion that includes a
divergent motion component. Polynomial parallel
translations are known to yield three dimensional power
spectral densities that can be factored into two terms:
the two dimensional spectrum of the stationary image and
a spectral motion support. This useful result is
extended to the case of arbitrary 3D translations by use
of spatio-temporal Mellin Transforms. The relationship
of time to collision to the resulting motion support is
investigated, and integral methods for the computation
of time to collision are derived.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  2509 </NUMBER>
<ORDER>   AAI9513265 </ORDER>
<TITLE> QUALITATIVE DISTANCE AND DIRECTION REASONING IN GEOGRAPHIC SPACE  </TITLE>
<AUTHOR> HONG, JUNG-HONG </AUTHOR>
<YEAR> 1994 </YEAR>
<INSTITUTION> UNIVERSITY OF MAINE; 0113 </INSTITUTION>
<DESCRIPTORS> ENGINEERING, CIVIL; COMPUTER SCIENCE; GEOGRAPHY; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> MAX J. EGENHOFER </ADVISER>
<CLASSIFICATIONS> DISTANCE REASONING </CLASSIFICATIONS>
<ABSTRACT>
This thesis is inspired by the need to build a reasoning
mechanism that deals with qualitative distances and
directions, such as the approximate distances and the
cardinal directions (e.g., near, North). Spatial
reasoning has been recognized as an important capability
for the knowledge-based Geographic Information Systems
(GISs). While humans do it constantly in our lives, the
formalization of such reasoning behavior in computers is
still incomplete. Although a number of researchers have
built computational models that deal with the reasoning
about spatial relations in geographic space, only few
have investigated the combination of distances and
directions.
The major obstacle for the qualitative distance and
direction reasoning is that qualitative distances are
context-dependent, therefore, the composition operator
of such locational relations may depend on the geometric
definitions of qualitative distances. This thesis builds
models for qualitative distances and directions with two
criteria: complete coverage and mutual exclusiveness.
These models serve as the basis for the design of
reasoning model, whose basic methods are (1) the
transformation between qualitative and quantitative
locational relations and (2) the well-developed
quantitative reasoning methods. Qualitative composition
can then be defined via the simulation of quantitative
locational relations. Three reasoning models--the all-
answer model, the likely-answer model, and the single-
answer model--are introduced to assess the qualitative
compositions.
To evaluate the reasoning models, data based on (1) the
number of qualitative distances, (2) the number of
qualitative directions, and (3) the geometric patterns
of distance intervals are simulated and tested. The
results indicate that the compositions of qualitative
distances and directions are primarily robust and only
few compositions are affected by the interval patterns
of qualitative distances. It is hence possible to build
a reasoning mechanism based on inference rules instead
of analytical calculations. The assessments of
compositions show that careful selections of answers for
each composition can increase the efficiency of
reasoning while maintaining a satisfactory
approximation. It is also found that the proposed
reasoning models can provide reasonable guesses for the
requested relations.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  2510 </NUMBER>
<ORDER>   AAI9619112 </ORDER>
<TITLE> AN INTEGRATED MACHINE FAULT DIAGNOSIS SYSTEM USING FUZZY MULTI-ATTRIBUTE DECISION-MAKING APPROACH </TITLE>
<AUTHOR> LIU, SHIH-YAUG </AUTHOR>
<YEAR> 1994 </YEAR>
<INSTITUTION> UNIVERSITY OF HOUSTON; 0087 </INSTITUTION>
<DESCRIPTORS> ENGINEERING, SYSTEM SCIENCE; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> NIL </ADVISER>
<CLASSIFICATIONS> FUZZY LOGIC </CLASSIFICATIONS>
<ABSTRACT>
Most current machine fault diagnosis systems emphasize
the correctness of the hypothesized result; however, in
time constrained situations, the efficiency of the
diagnostic process becomes more important and should not
be overlooked. This dissertation presents an Integrated
Machine Fault Diagnosis System (IMFDS) that enhances the
efficiency of the diagnostic process, improves the
completeness and consistency of the knowledge base, and
assists users in developing and maintaining their
diagnostic systems.
IMFDS consists of five modules: (1) a diagnostic tree
module establishes the hierarchical structure regarding
the function or connectivity of the diagnosis system,
(2) a fuzzy multi-attribute decision-making module
determines the most efficient diagnostic process and
creates a "meta knowledge base" to control the diagnosis
process, (3) a knowledge-base module captures human
expertise and deep knowledge to diagnose the possible
machine fault, (4) an inference-engine module controls
the diagnosis process and deals with uncertainty from
the user input and knowledge base itself, and (5) a
learning module uses the failure-driven learning method
to train the knowledge base from past actual cases.
This system has been successfully implemented in the MS-
Windows environment and it is written in MS Visual
BASIC. To validate the system performance, IMFDS is
compared to EXACT, an expert system for automobile air-
compressor troubleshooting, using fifty sample cases of
actual repair records. The result shows that IMFDS can
reduce the diagnosis time by 24.9%.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  2511 </NUMBER>
<ORDER>   AAI9512706 </ORDER>
<TITLE> A NEURAL NETWORK MODEL OF THE VESTIBULO-OCULAR REFLEX </TITLE>
<AUTHOR> LEE, CHAO YOUNG </AUTHOR>
<YEAR> 1994 </YEAR>
<INSTITUTION> UNIVERSITY OF MINNESOTA; 0130 </INSTITUTION>
<DESCRIPTORS> BIOLOGY, NEUROSCIENCE; COMPUTER SCIENCE; ENGINEERING, BIOMEDICAL; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> JOHN H. ANDERSON; JAMES E. HOLTE </ADVISER>
<CLASSIFICATIONS> NIL </CLASSIFICATIONS>
<ABSTRACT>
The neural integration mechanism in the horizontal
vestibulo-ocular reflex (VOR) is modeled by a
distributed artificial neural network. Six groups of
processing elements are included in the model. Each
group simulates a specific neuronal population involved
in the vestibulo-ocular reflex. The interconnection
pattern between these groups is based on the neural-
physiological experiments and the current understanding
of the vestibular system. The processing elements
composing the artificial neural network model has some
of the physiological features of real nerve cells. We
have successfully modeled a neural network that performs
the desired VOR neural integration function through the
supervised learning. The results are considerably better
than the previous models' by means of the frequency
response, the system robustness and the biological
plausibility. Based on the features of the model, we are
able to make some predictions about the performance of
the physiological VOR pathway with respect to the
pathological effects induced by local lesions of various
neuronal populations and the neural plasticity of the
VOR pathways.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  2512 </NUMBER>
<ORDER>   AAINN94018 </ORDER>
<TITLE> ARTIFICIAL NEURAL NETWORK BASED POWER SYSTEM STABILIZERS </TITLE>
<AUTHOR> ZHANG, YIMIN </AUTHOR>
<YEAR> 1994 </YEAR>
<INSTITUTION> UNIVERSITY OF CALGARY (CANADA); 0026 </INSTITUTION>
<DESCRIPTORS> ENGINEERING, ELECTRONICS AND ELECTRICAL; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> O. P. MALIK </ADVISER>
<CLASSIFICATIONS> NIL </CLASSIFICATIONS>
<ABSTRACT>
Techniques for using artificial neural networks (ANNs)
to implement various control strategies to design power
system stabilizers (PSSs) are proposed in this
dissertation. The multi-layer neural network with error
backpropagation training algorithm is used to design the
ANN based PSS. The ANN structure and training techniques
are discussed.
An ANN is first trained to simulate the control
functions of an adaptive PSS (APSS). This combines the
quick response of an ANN and good control performance of
an APSS. An inverse mapped ANN control technique is
developed. This ANN controller identifies the inverse
dynamics of an unknown plant and acts as a controller.
An ANN PSS based on this control technique is tested on
a single machine infinite bus system. A multi-input ANN
PSS algorithm is also developed to overcome the inherent
limitations of single input PSSs.
A multi-machine power system is used to test the inverse
mapped ANN PSS in damping power system multi-mode
oscillations. The inverse mapped ANN PSS is implemented
on a conventional sequential type PC, and is applied on
a physical power system model to test its on-line
control performance. The simulation and lab test results
show that the proposed ANN PSSs exhibit very good
performance in damping power system low frequency
oscillations, improve power system stability, have good
effect in different environments, and can work in
cooperation with other PSSs.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  2513 </NUMBER>
<ORDER>   AAINN93505 </ORDER>
<TITLE> NEURAL NETWORKS AND NEURAL FIELDS: DISCRETE AND CONTINUOUS SPACE NEURAL MODELS </TITLE>
<AUTHOR> EDWARDS, RODERICK </AUTHOR>
<YEAR> 1994 </YEAR>
<INSTITUTION> UNIVERSITY OF VICTORIA (CANADA); 0244 </INSTITUTION>
<DESCRIPTORS> MATHEMATICS; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> REINHARD ILLNER </ADVISER>
<CLASSIFICATIONS> DISCRETE SPACE NEURAL MODELS </CLASSIFICATIONS>
<ABSTRACT>
'Attractor' neural network models have useful
properties, but biology suggests that more varied
dynamics may be significant. Even the equations of the
Hopfield network, without the constraint of symmetry,
can have complex behaviours which have been little
studied. Several new ideas or approaches to neural
network theory are examined here, focussing on the
distinction between discrete and continuous space neural
models. First, simple chaotic dynamical systems are
examined, as candidates for more natural neural network
models, including coupled systems of Lorenz equations
and a Hopfield equation model with a balance of
inhibitory and excitatory neurons. Also, continuous
space models with a structure like that of the Hopfield
network are briefly explored, with interesting training
possibilities.
The main results deal with the approximation of Hopfield
network equations with a particular class of connection
structures (allowing asymmetry), by a reaction-diffusion
equation, using techniques borrowed from particle
methods used in the numerical solution of fluid-
dynamical equations. It is shown that the approximation
holds rigorously only in certain spatial regions but the
small regions where it fails, namely within transition
layers between regions of high and low activity, are not
likely to be critical. The result serves to classify
connectivities in Hopfield-type models and sheds light
on the limiting behaviour of networks as the number of
neurons goes to infinity. Standard discretizations of
the reaction-diffusion equations are analyzed to clarify
the effects which can arise in the limiting process. The
discrete space systems can have stable patterned
equilibria which must be close to metastable patterns of
the continuous systems.
Our results also suggest that the fine structure of
neural connections is important, and to obtain complex
behaviour in the Hopfield network equations, a
predominance of inhibition or wildly oscillating
connection matrix entries are indicated.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  2514 </NUMBER>
<ORDER>   AAINN93430 </ORDER>
<TITLE> REPETITIVE LEARNING CONTROL OF ROBOTIC MANIPULATORS </TITLE>
<AUTHOR> FU, JIANGUO (JAMES) </AUTHOR>
<YEAR> 1994 </YEAR>
<INSTITUTION> MCMASTER UNIVERSITY (CANADA); 0197 </INSTITUTION>
<DESCRIPTORS> ENGINEERING, ELECTRONICS AND ELECTRICAL; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> N. K. SINHA </ADVISER>
<CLASSIFICATIONS> NIL </CLASSIFICATIONS>
<ABSTRACT>
This thesis deals with the repetitive learning control
of robotic manipulators. The research topic is motivated
by the fact that industrial robots usually perform
repetitive tasks. Unlike other conventional controllers,
the repetitive learning controller can improve the
performance of a robot as it repeats the same task. The
proposed control strategy has advantages of easy
implementation, low cost and better performance. A
critical survey of the state of the art in repetitive
learning control of robots is presented. This thesis is
divided into two major parts: a two operational modes
based approach and a neural network based scheme.
In the first part of the thesis, a theoretical framework
has been developed for designing controllers based on
the proposed two operational modes. The repetitive
operations of a robot can be divided into two
operational modes: a single operational mode and a
repetitive operational mode. Based on this, the author
proposes repetitive learning schemes for motion control
of both rigid and flexible joints robots, as well as for
control of constrained robots with rigid joints. The
designed controllers converge in both operational modes.
In the single operational mode, the controllers behave
like adaptive controllers, while similar to a betterment
process in the repetitive operational mode. These
conclusions are firmly supported by simulation studies.
In the second part of this thesis, special attention is
paid to schemes based on neural networks. The author's
own modification of back-propagation neural networks is
first established in the thesis. It is then applied to
motion control of both rigid and flexible joints robots,
as well as force control of rigid robots. The neural
networks play the role of an approximate inverse dynamic
model of a robot and are then parallelled with a
conventional PD controller to achieve control goals.
Very promising results have been reported in this
thesis.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  2515 </NUMBER>
<ORDER>   AAINN93409 </ORDER>
<TITLE> A KNOWLEDGE-BASED APPROACH TO THE DESIGN, SIMULATION, AND EVALUATION OF FLEXIBLE MANUFACTURING SYSTEMS </TITLE>
<AUTHOR> RAVI, THIRUVENGADAM </AUTHOR>
<YEAR> 1994 </YEAR>
<INSTITUTION> MCMASTER UNIVERSITY (CANADA); 0197 </INSTITUTION>
<DESCRIPTORS> ENGINEERING, INDUSTRIAL; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> H. A. ELMARAGHY </ADVISER>
<CLASSIFICATIONS> NIL </CLASSIFICATIONS>
<ABSTRACT>
Launching new manufacturing systems for production is a
difficult task which involves several people and
resources, and is time-consuming and capital intensive.
Flexible manufacturing systems (FMS), which are a new
generation of manufacturing systems, further complicate
this launching process because they consist of several
interacting components such as workstations, pallets,
automated material handling systems, and buffers. The
lack of knowledge about the interaction between these
components has often resulted in the poor performance of
many FMS designs. Major corporations today are adopting
a proactive philosophy rather than a reactive one, and
for a complex and capital intensive manufacturing system
such as an FMS, the design process is extremely critical
for its successful performance.
The design process, which precedes the launching of an
FMS, is iterative and consists of planning, model
development, and output analysis. While several computer-
based tools are available for modeling and evaluating
FMS designs, there is a dearth of such tools for
synthesizing new designs and analyzing output from
simulation models to improve these designs. System
designers have traditionally performed these two
activities using their knowledge and experience. These
are cumbersome and time-consuming activities and
consequently increase the design cycle time.
The objective of this thesis is to reduce the FMS design
cycle time by automating the design process. A knowledge-
based system called FMX, Flexible Manufacturing Expert,
was developed in this thesis to generate and evaluate
designs of manufacturing systems with a high degree of
automation. The object-oriented FMX is an intelligent
system which combines expert systems and simulation
modeling to design and evaluate flexible manufacturing
systems. It consists of several modules, the major ones
including an expert design synthesizer to generate
initial system designs, a simulation model developer to
automatically convert designs into graphical simulation
models, and an expert analyzer to analyze simulation
output, identify design deficiencies, and recommend
changes. The current implementation of FMX was developed
using the Knowledge Engineering Environment (KEE) expert
system shell and the SimKit simulation package, and it
runs on a Sun workstation under a UNIX operating system.
FMX has been applied for designing flexible
manufacturing systems in the machining domain. Two case
studies have been included in this thesis to demonstrate
its capabilities--one of which includes industrial
system used by a major automotive manufacturer in
Ontario. The first case study took two iterations while
the second one took three iterations to find tune a
synthesized design that satisfies various performance
measures such as production volumes, equipment
utilizations, equipment blocking, and queue length of
automatic pallet changers. For both case studies, the
investment cost per part index decreased for each
iteration thus proving that the design changes suggested
by the expert analyzer improved the performance of the
initial system design while reducing its cost. The final
output from FMX is a list of components that comprise
the system, its graphical layout, and its performance
measures.
FMX is a comprehensive decision support system which
integrates all phases of a flexible manufacturing system
design into a single software framework. Its modules
such as the expert design synthesizer, simulation model
developer, and expert analyzer each address a specific
phase of the system design process. FMX generates
consistent designs with minimum intervention from the
user and hence reduces the design cycle time
significantly.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  2516 </NUMBER>
<ORDER>   AAINN93395 </ORDER>
<TITLE> DECISION SUPPORT FOR MUNICIPAL SOLID WASTE MANAGEMENT AND PLANNING  </TITLE>
<AUTHOR> BARLISHEN, KIMBERLY DAWN </AUTHOR>
<YEAR> 1994 </YEAR>
<INSTITUTION> MCMASTER UNIVERSITY (CANADA); 0197 </INSTITUTION>
<DESCRIPTORS> ENGINEERING, SANITARY AND MUNICIPAL; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> F. L. HALL </ADVISER>
<CLASSIFICATIONS> WASTE MANAGEMENT </CLASSIFICATIONS>
<ABSTRACT>
A thorough review of mathematical models, based on the
application of systems analysis techniques, that have
been developed for municipal solid waste (MSW)
management and planning problems is presented as
evidence of the growing number and complexity of the
available models. A survey of practising waste
management professionals indicated a general interest in
systems analysis techniques to assist with decision-
making. However, a lack of practical applications of
these techniques was also indicated, particularly by
local and regional waste management agencies. The lack
of practical model applications may result from the past
reliance on landfills to manage MSW and the many non-
economic implications (social, environmental, political,
etc.) of MSW management and planning decisions.
Research, to date, has not directly addressed the
perceived deficiencies with the current problem solving
techniques, nor has the application of knowledge-based
system techniques been adequately explored within the
field of MSW management and planning.
Three general approaches are proposed for the
integration of knowledge found in the technical
literature and possessed by experienced waste management
engineers and planners, and existing mathematical
models. These approaches are based on the creation of
knowledge-based systems to interface with individual
models, or assist with model selection and integration.
A range of suitable application problem areas within the
domain of MSW management and planning are described. As
a means of demonstrating the validity, and potential
benefits and limitations of the suggested decision
support approaches, a prototype decision support system
was developed to assist with the preliminary planning of
MSW management systems. This prototype system combines
knowledge-based system components with spreadsheet,
optimization and simulation models to assist with the
major planning activities: waste forecasting; technology
evaluation; composting and recycling program design;
facility sizing, location and investment timing, and
waste allocation; and MSW management system analysis
using simulation. The user is guided through the complex
process of long-range program and facility planning, and
is assisted with applying and integrating the various
modelling components. Potential users of the prototype
decision support system are local and regional waste
management engineers and planners, consulting firms, and
municipal decision-makers. Based on the opinions
expressed by several practising waste management
professionals, and two case study applications, the
prototype decision support system is considered to
represent a reasonable, useful, and practical (with
respect to data requirements and cost) planning tool.
This research has also produced knowledge bases for the
prototype decision support system that represent a
collection and organization of a significant amount of
waste management expertise and mathematical modelling
expertise contained in the MSW management and planning
literature.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  2517 </NUMBER>
<ORDER>   AAINN93387 </ORDER>
<TITLE> APPRENTISSAGE AUTOMATIQUE DE REGLES DE RECHERCHE DE BUS POUR LES CIRCUITS IMPRIMES </TITLE>
<AUTHOR> LANGHEIT, CHRISTIAN </AUTHOR>
<YEAR> 1994 </YEAR>
<INSTITUTION> ECOLE POLYTECHNIQUE, MONTREAL (CANADA); 1105 </INSTITUTION>
<DESCRIPTORS> ENGINEERING, ELECTRONICS AND ELECTRICAL; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> JEAN CHARLES BERNARD </ADVISER>
<CLASSIFICATIONS> FRENCH TEXT </CLASSIFICATIONS>
<ABSTRACT>
This research is part of a tool development framework
for printed circuit board design. It promotes the bus
concept for the placement and routing stages thus
permitting the use of the inner regularities of an
electronic circuit design.
A new model of bus, based on certain electronic
component characteristics and on circuit connectivity is
presented. It is the first routing bus model breaking
the classical definition stipulating that a bus is a set
of parallel traces between two components. It can be
used for modeling buses between two or more components
with parallel or crossing traces. The model considers
the organization of the component pins to which the
buses are connected. We define some criteria allowing to
characterize bus aggregation in order to obtain a better
control of their routing.
In addition to the bus model, we present the basic
software modules needed to develop an integrated tool
for placement and routing based on the bus model.
In order to validate the bus model, a tool for searching
bus on printed circuit boards is developed. This tool,
built as an expert system, applies some searching rules
in order to identity buses between two components of a
printed circuit. Machine learning techniques from
artificial intelligence are used for the rule
acquisition step.
We also present a new type of certainty factor
associated to the search rules. It permits the control
of rules firing by the expert system. This factor relies
on both the notion of services factor, which represents
the experience of a rule with expert acceptance of the
resulting bus, and the notion of instability factor
reflecting the discontinuity of the rule's acceptance by
an expert.
The learning mechanism is based on rule induction by
making generalization of rules found from the examples
of the expert. The learning is incremental and comes
from the results of the bus searching expert system.
Two modes of training are tested. In the first mode,
interactions with the expert permit a faster certainty
factor adjustment of the rules while the second one does
not use interaction with the expert.
These two modes of training are achieved using 694 bus
examples extracted from 10 printed circuit boards. These
examples allowed the establishment of two different rule
bases used in searching for buses.
These two rule bases are validated by using the expert
system to search for buses on the 10 printed circuits
used for the training. In the two cases, the expert
system obtained a 99.4% recognition rate. This allows us
to conclude that the introduced bus model is realistic
and so are the search rules extracted from a printed
circuit design expert. We can also conclude that the
machine learning techniques give good results in the
acquisition of bus searching rules based on our model.
We further tested the expert system with new printed
circuits. This second set of examples, coming from 6
circuits, was not used for the training. The expert
system succeeded in finding 95% of the 183 buses which
were laid out on those circuits. We can therefore
conclude that the rule generalization mechanism is
efficient. Since buses which were not used for the
training are identified correctly.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  2518 </NUMBER>
<ORDER>   AAINN93251 </ORDER>
<TITLE> ON-LINE FAST LEARNING WITH VARIABLE THRESHOLDS PROTOTYPE NEURAL CLASSIFIER </TITLE>
<AUTHOR> ABU-NASR, MAHMOUD A. </AUTHOR>
<YEAR> 1994 </YEAR>
<INSTITUTION> UNIVERSITY OF WINDSOR (CANADA); 0115 </INSTITUTION>
<DESCRIPTORS> ENGINEERING, ELECTRONICS AND ELECTRICAL; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> MAHER SID-AHMED </ADVISER>
<CLASSIFICATIONS> PATTERN CLASSIFICATION </CLASSIFICATIONS>
<ABSTRACT>
Pattern classification is one of the most successful
applications of neural networks. Most of the previous
research focused around training the multi-layer
perceptrons (MLP's) with the back propagation algorithm.
Although the MLP's are capable of resolving pattern
classes separated by non-linear class boundaries, they
have some drawbacks that limit their acceptance for
classifying problems of the real-world. Namely they
require very lengthy training times, they cannot learn
incrementally, and their convergence is not guaranteed.
In this thesis, we develop two prototype based
classifiers that require training times that are orders
of magnitude less than the MLP's, and can be trained in
increments. One of the classifiers uses prototypes of
fixed thresholds to represent all classes. The other
classifier forms prototypes of different firing
thresholds, which it chooses and adjusts according to an
algorithm.
The classifiers were tested on standard and real world
problems like hand-written numeral recognition, in which
they demonstrated superior performance in terms of speed
of learning and memory efficiency.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  2519 </NUMBER>
<ORDER>   AAI9517556 </ORDER>
<TITLE> THE INTELLIGENT FACILITATOR'S ASSISTANT </TITLE>
<AUTHOR> CURTIS, ARTHUR CLAYTON, JR. </AUTHOR>
<YEAR> 1994 </YEAR>
<INSTITUTION> THE UNIVERSITY OF ARIZONA; 0009 </INSTITUTION>
<DESCRIPTORS> BUSINESS ADMINISTRATION, MANAGEMENT; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> DOUGLAS R. VOGEL </ADVISER>
<CLASSIFICATIONS> IFA): COUPLING MODELS OF PRODUCT-ORIENTED GROUPS AND EXPERT FACILITATOR BEHAVIOR (EXPERT SYSTEMS, DECISION SUPPORT </CLASSIFICATIONS>
<ABSTRACT>
This dissertation describes the development of a
knowledge-based system, dubbed the "Intelligent
Facilitator's Assistant" (IFA), which is capable of
assisting a facilitator with selected aspects of
meetings employing tool-oriented electronic meeting
support (EMS) systems. Issues in the separation of site-
specific and domain-specific knowledge are discussed, as
are alternatives for modeling facilitator behavior.
Software activities carried out as part of the research,
which included the construction of a general-purpose
microcomputer-based expert system development
environment, are also covered. The final products of the
research are conceptual models of product-oriented work
groups and expert facilitator behavior in pre-session
planning; these are realized in a taxonomy of products
for EMS sessions and in a prototype knowledge base for
agenda construction. Significant conclusions of the
research are: (1) an intelligent assistant must be based
on deep knowledge of the tool environment; (2) such an
assistant must accommodate multiple models of both
facilitator and user behavior; (3) the advent of
intelligent assistants has major implications for the
design of software for this environment, specifically in
providing for control and visibility of tool activity by
a process rather than a human operator.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  2520 </NUMBER>
<ORDER>   AAIC407105 </ORDER>
<TITLE> ARTIFICIAL INTELLIGENCE METHODS IN PROCESS PLANT LAYOUT </TITLE>
<AUTHOR> MCBRIEN, ANDREW </AUTHOR>
<YEAR> 1994 </YEAR>
<INSTITUTION> UNIVERSITY OF NOTTINGHAM (UNITED KINGDOM); 0616 </INSTITUTION>
<DESCRIPTORS> ENGINEERING, CHEMICAL UNIVERSITY PARK, NOTTINGHAM,  ENGLAND </DESCRIPTORS>
<ADVISER> NIL </ADVISER>
<CLASSIFICATIONS> NIL </CLASSIFICATIONS>
<ABSTRACT>
The thesis describes "plant layout system" or PLS, an
expert system which automates all aspects of conceptual
layout of chemical process plant, from sizing equipment
using process data to deriving the equipment items'
elevation and plan positions. PLS has been applied to a
test process of typical size and complexity and which
encompasses a wide range of layout issues and problems.
The thesis presents the results of the tests to show
that PLS generates layouts that are entirely
satisfactory and conventional from an engineering
viewpoint.
The major advance made during this work is the approach
to layout by expert system of any kind of process plant.
The thesis describes the approach in full, together with
the engineering principles which it acknowledges.
Plant layout problems are computationally complex. PLS
decomposes layout into a sequence of formalised steps
and uses a powerful and sophisticated technique to
reduce plant complexity. PLS uses constraint propagation
for spatial synthesis and includes propagation
algorithms developed specifically for this domain. PLS
includes a novel qualitative technique to select
constraints to be relaxed. A conventional frame based
representation was found to be appropriate, but with
procedural knowledge recorded in complex forward
chaining rules with novel features. Numerous examples of
the layout engineer's knowledge are included to
elucidate the epistemology of the domain.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  2521 </NUMBER>
<ORDER>   AAI9514210 </ORDER>
<TITLE> PREDICTION OF MAGNETOSPHERIC PARAMETERS USING ARTIFICIAL NEURAL NETWORKS </TITLE>
<AUTHOR> NAGAI, AKIRA </AUTHOR>
<YEAR> 1994 </YEAR>
<INSTITUTION> RICE UNIVERSITY; 0187 </INSTITUTION>
<DESCRIPTORS> PHYSICS, GENERAL; STATISTICS; COMPUTER SCIENCE; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> NIL </ADVISER>
<CLASSIFICATIONS> NIL </CLASSIFICATIONS>
<ABSTRACT>
Artificial neural network models have been developed
that provide the magnetospheric parameters Dst, polar
cap potential and the midnight equatorward boundary of
diffuse aurora. Layered feedforward neural networks have
successfully learned the relationship between the solar
wind and the magnetospheric parameters using supervised
back-propagation training. All models have achieved a
higher prediction accuracy than the existing empirical
or statistical models. These models are applied to the
prediction of the parameters, which will then be used by
the Rice Magnetospheric Specification and Forecast Model
(MSFM). The neural network models are able to forecast
the magnetospheric parameters 30 to 60 minutes ahead
using the information from a solar wind monitor
spacecraft. With the forecast values, the MSFM will be
able to forecast particle fluxes in the inner
magnetosphere. The MSFM is applied to the April 1988
magnetic storm for the forecast capability test. The
neural network modeling, the comparison of the
prediction accuracy with other methods and the result of
the MSFM forecast capability test are presented.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  2522 </NUMBER>
<ORDER>   AAI9514205 </ORDER>
<TITLE> A VISION-BASED FUZZY LOGIC AND NEURAL NETWORK APPROACH TO THE CONTROL OF HYPER-REDUNDANT ROBOT MANIPULATORS </TITLE>
<AUTHOR> MAGEE, KEVIN NOWELL </AUTHOR>
<YEAR> 1994 </YEAR>
<INSTITUTION> RICE UNIVERSITY; 0187 </INSTITUTION>
<DESCRIPTORS> ENGINEERING, MECHANICAL; COMPUTER SCIENCE; ENGINEERING, ELECTRONICS AND ELECTRICAL; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> JOHN B. CHEATHAM, JR. </ADVISER>
<CLASSIFICATIONS> NIL </CLASSIFICATIONS>
<ABSTRACT>
Hyper-redundant robot manipulators possess a very large
degree of kinematic redundancy and are capable of motion
similar to that of snakes and elephant trunks. Because
of the computational burden required to calculate the
pseudo-inverse of the manipulator Jacobian matrix for
high degree of freedom robots, hyper-redundant
manipulators have proven challenging to control by
traditional methods. Additionally, control can be
further complicated because the large number of joints
and links in a hyper-redundant arm can be a source of
measurement error in real-world systems.
A fuzzy logic and neural network based control system
for hyper-redundant arms is presented which operates on
data from real-time vision. The neural network maps goal
position and orientation to desired arm configuration. A
modified region fill algorithm is used to provide an
estimate of the current configuration as seen in two
camera views. A fuzzy logic rule base constructed from
human intuition specifies motor signals which servo the
arm from the current position to the goal position
according to velocity profiles modeled after human goal-
directed movement strategies.
As a test case, the control system is applied to a
thirty-two degree of freedom robot arm designed and
built at Rice University. The controller is demonstrated
to provide accuracy similar to that of humans on certain
tasks. Although application is made specifically to a
hyper-redundant arm, the control system developed in
this research also could be applied to many lower degree
of freedom manipulators, provided that their motion is
heuristically easy to describe.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  2523 </NUMBER>
<ORDER>   AAI9513739 </ORDER>
<TITLE> SCHEDULING WITH TIME WINDOW </TITLE>
<AUTHOR> THONGMEE, SANSERN </AUTHOR>
<YEAR> 1994 </YEAR>
<INSTITUTION> TEXAS TECH UNIVERSITY; 0230 </INSTITUTION>
<DESCRIPTORS> ENGINEERING, INDUSTRIAL; OPERATIONS RESEARCH; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> SURYA D. LIMAN </ADVISER>
<CLASSIFICATIONS> NIL </CLASSIFICATIONS>
<ABSTRACT>
In this research, we consider scheduling problems with
time window. For single machine scheduling problems with
time window, we investigate three different cases: (1)
common due window size determination problem, (2) common
due window location assignment problem, and (3) common
due window location and size determination problem. We
distinguish the first problem into two cases, the
unrestricted and the restricted case. For the
unrestricted case, we propose a polynomial time
algorithm to optimally solve the problem. The problem
becomes NP-complete for the restricted due window case,
hence we propose a dynamic programming algorithm. We
show that the second and third problems can be optimally
solved by the proposed polynomial time algorithms. The
common due window size determination problem is also
extended to the parallel machine system. We show that
the problem is NP-complete even when the number of
machines is equal to two. We provide an optimal
algorithm based on a dynamic programming algorithm to
solve the two machine case. For the general m-machine
case, we propose an approximate algorithm with the
relative worst case error bound of 2. In addition, a
heuristic algorithm based on neural networks is proposed
to solve the common due window size determination on a
single machine problem. We show that the performance of
the neural network-based algorithm is very promising
when compared with the optimal solution obtained by the
dynamic programming algorithm.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  2524 </NUMBER>
<ORDER>   AAI9513655 </ORDER>
<TITLE> ANALYSIS OF HUMAN SKIN CHARACTERISTICS USING ELECTRICAL IMPEDANCE TECHNIQUES BASED ON COMPUTATIONAL INTELLIGENCE </TITLE>
<AUTHOR> CHANG, BAO RONG </AUTHOR>
<YEAR> 1994 </YEAR>
<INSTITUTION> UNIVERSITY OF MISSOURI - COLUMBIA; 0133 </INSTITUTION>
<DESCRIPTORS> ENGINEERING, ELECTRONICS AND ELECTRICAL; ENGINEERING, BIOMEDICAL; BIOPHYSICS, MEDICAL; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> EARL J. CHARLSON </ADVISER>
<CLASSIFICATIONS> NIL </CLASSIFICATIONS>
<ABSTRACT>
The primary objective of this study is to develop the
fast algorithms for estimating the electrotonic
parameters of skin impedance. Conventional methods for
determining AC skin impedance resulting from off-line
estimation operating on a wide frequency range from DC
to 1 MHz are accurate but lack real time convenience. In
this research, three proposed direct methods--an
analytical method, a fuzzy inference approach, and an
artificial neural network, which make use of the
instantaneous input voltage and current data to estimate
the electrotonic parameters of skin impedance are
introduced. These techniques are faster than
conventional methods because they operate on a real-time
and on-line computation, and require only a single high
frequency input signal. Two typical examples of
measurement of AC skin impedance--(1) palm-to-palm
measurement, and (2) H meridian measurement were used as
test targets in this study. After electrotonic
parameters estimation, a comparison of three proposed
computational methods was made and results indicated
that three estimations yield accurate results.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  2525 </NUMBER>
<ORDER>   AAI9513145 </ORDER>
<TITLE> KNOWLEDGE-/RULE-BASED SEMANTICS FOR LARGE DATABASE SYSTEMS </TITLE>
<AUTHOR> YURCHAK, KIRK ELLIOTT </AUTHOR>
<YEAR> 1994 </YEAR>
<INSTITUTION> LEHIGH UNIVERSITY; 0105 </INSTITUTION>
<DESCRIPTORS> COMPUTER SCIENCE; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> DONALD J. HILLMAN </ADVISER>
<CLASSIFICATIONS> NIL </CLASSIFICATIONS>
<ABSTRACT>
Since their dawn, database management systems have
saturated virtually every area of academic and
commercial domains. They have proven to be as
indispensable as the paper and pencil. Yet while
relational database management systems (RDBMSs) have
been made so readily available, most are still quite
primitive with regard to semantic abstraction. It may be
argued that these RDBMSs are not much more than mere
vessels of information having little knowledge of the
semantics--the underlying, meaningful aspects--which
apply to the data they represent. Few systems allow
tables to "know" about other tables around them, and
almost no systems allow knowledge of tables governed by
different types of RDBMSs. The notion of data semantics
spans a single record's relation to itself (cross-field
semantics), a record's relation to other records in the
same table (cross-record semantics), a record's relation
to records of other tables (cross-table semantics), and
even a record's relation to records of other tables
governed by other RDBMSs (cross-platform semantics). It
suggests the concept of inferring certain data-
manipulative actions based on other committal actions
performed on a given database.
This dissertation proposes a knowledge-/rule-based
approach to inject high-level semantics into today's
various RDBMSs. The system has been dubbed the Semantic
Database Management System (SDBMS) and uses rule-bases
associated with each database under its control to
represent semantic repercussions relative to data-
manipulations (inserts, updates, deletes, and the like).
The databases governed by the SDBMS may be of
potentially differing RDBMSs. A semantic engine (SE) is
used to control inferences within the rule-bases and
translate manipulative consequents to respective RDBMS
engines. Users, developers, and programs alike access
data governed by the SDBMS through a semantic interface
(SI).
The goal of this work is to provide centralized access
of many forms of data through a universal medium, making
primitive database engines more powerful and powerful
database engines more flexible. It provides a means for
communication between RDBMSs and promotes more
"intelligent" systems. Most importantly it lessens the
burden previously posed on producing a myriad of ad hoc
customized programs subsequently requiring linkage to
RDBMSs to inject the otherwise lacking semantic
knowledge.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  2526 </NUMBER>
<ORDER>   AAI9513071 </ORDER>
<TITLE> MULTISTAGE NEURAL NETWORKS AND MULTIRESOLUTION APPROACHES TO SIGNAL AND IMAGE PROCESSING </TITLE>
<AUTHOR> SUNDARAM, RAMAKRISHNAN </AUTHOR>
<YEAR> 1994 </YEAR>
<INSTITUTION> PURDUE UNIVERSITY; 0183 </INSTITUTION>
<DESCRIPTORS> ENGINEERING, ELECTRONICS AND ELECTRICAL; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> K. OKAN ERSOY </ADVISER>
<CLASSIFICATIONS> SIGNAL PROCESSING </CLASSIFICATIONS>
<ABSTRACT>
The Hopfield neural configuration has been employed in a
partitioned mode to achieve signal restoration. This
approach is computationally efficient and capable of
progressing to deeper local minima on the reconstruction
error surface. Other features include increased
parallelism and ease of hardware implementation. We
propose two distinct multistage algorithms to perform
error minimization. The partial data approach treats all
the neurons of subsets of the data while the partial
neuron strategy divides the data set into regions based
on the neurons of the entire data. We analyze the
performance of these two methods in the context of image
restoration.
In an effort to understand low level biological vision
processes, we have investigated the edge localization
features of bandpass masks in the transform domain. The
spatial frequency localized Laplacian of Gaussian filter
in conjunction with the Discrete Cosine Transform yields
superior edge positional accuracy when compared with
traditional techniques. This has significant
ramifications in several areas including motion
compensated image coding and contour tracking in medical
images. In the latter case, we have used 2-D and 3-D
extensions of the filter to perform object boundary
detection in Magnetic Resonance image scans. A
systematic selection and variation of the filter
parameter controls the accuracy of the contour map and
reduces edge misclassification. Further, a parallel
implementation of this approach makes it a powerful tool
in image data analysis.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  2527 </NUMBER>
<ORDER>   AAI9513008 </ORDER>
<TITLE> CONTROL OF DYNAMIC SYSTEMS USING FEEDFORWARD NEURAL NETWORKS  </TITLE>
<AUTHOR> KUSCHEWSKI, JOHN GUSTAV </AUTHOR>
<YEAR> 1994 </YEAR>
<INSTITUTION> PURDUE UNIVERSITY; 0183 </INSTITUTION>
<DESCRIPTORS> ENGINEERING, ELECTRONICS AND ELECTRICAL; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> STANISLAW H. ZAK </ADVISER>
<CLASSIFICATIONS> NEURAL NETWORKS </CLASSIFICATIONS>
<ABSTRACT>
We investigate dynamic system control using feedforward
neural networks (FNNs) that use generalized weight
adaptation algorithms.
We first analyze a method for control of linear, time-
invariant, single-input single-output dynamic systems
using an adaptive linear element (Adaline). The main
feature of the control structure is a single feedback
loop. We then present an algorithm, based on root locus
concepts, for determining the proper range of the
Adaline's learning rate. A case study, that includes
computer simulations and laboratory experiments, is
carried out to evaluate the performance of this method
when applied to the position control of a permanent
magnet armature-controlled dc servomechanism, the main
element of which is a permanent magnet armature-
controlled dc servomotor.
We then present methods for identification and control
of dynamic systems using Adaline, two-layer, and three-
layer FNNs equipped with generalized weight adaptation
algorithms. The main feature of the control structure is
the coordination of feedforward and feedback loops. The
FNNs considered contain odd nonlinear operators in their
neurons and in their weight adaptation algorithms. We
carry out two case studies to evaluate the performance
of the proposed methods.
The first case study involves a nonlinear, time-
invariant, dynamic system consisting of an inverted
pendulum controlled by an armature-controlled dc motor
through a gear train. We use computer simulations to
evaluate the proposed methods of on-line FNN based
identification of the system's forward and inverse
dynamics. Specifically, our interest is in the effect
the type of nonlinear functions in the neurons and in
the weight adaptation algorithms have on identification
performance. We then evaluate the proposed methods of
FNN based control via on-line identification of the
system's inverse dynamics combined with the coordination
of feedforward control method. The second case study
involves FNN based position control of a dc
servomechanism. In this case study, we evaluate the
performance of the FNN based control method.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  2528 </NUMBER>
<ORDER>   AAI9512988 </ORDER>
<TITLE> COMPUTER AIDED ACCEPTANCE PLANNING: GENERATING QUALITY ACCEPTANCE PARAMETERS AND STRATIFIED SAMPLING PLANS THROUGH NEURAL NETWORK LEARNING ABILITY AND CAD MODELING </TITLE>
<AUTHOR> HSIE, MACHINE </AUTHOR>
<YEAR> 1994 </YEAR>
<INSTITUTION> PURDUE UNIVERSITY; 0183 </INSTITUTION>
<DESCRIPTORS> ENGINEERING, CIVIL; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> LUH-MAAN CHANG </ADVISER>
<CLASSIFICATIONS> NIL </CLASSIFICATIONS>
<ABSTRACT>
A quality acceptance sampling plan (QASP) is the key in
designing Quality Assurance specifications. The QASP
guides the decision between accepting or rejecting the
quality of products by specifying the requirements of:
(1) how many measurements are needed, (2) where to take
these measurements, and (3) how to make an acceptance or
rejection decision based on measured data. This research
tackles the problems encountered in the development of a
QASP.
This research is the first work exploring the learning
ability of an Artificial Neural Network (ANN) to solve
the problem of designing an acceptance sampling plan.
The ANN features the capability of "learning-from-
example." A special approach has been designed to create
a training database that generates "good examples" and
filters out "bad examples." Therefore, the obtained
training examples have the advantage of providing more
efficient sampling plans. Namely, the trained ANN can
produce an acceptance plan that has a smaller sample
size, but still obtain the desired quality levels. The
obtained ANN in this research can also be directly
applied to other types of acceptance planning. Namely,
without re-training, the ANN can be broadly used in
other construction areas, such as highway pavement and
concrete tests.
Meanwhile, CAD modeling is studied to help generate a
stratified sampling scheme and random inspection spots.
The CAD system defines a basic surface element that is
suitable for representing the surface of steel
structures. This surface element with four vertexes is
both simple and easy to operate. The defined surface
element can be efficiently processed, stratified, and
grouped to simulate sampling lots. A random sampling
algorithm has also been defined to pick inspection
spots. As a result, contractors could pay more attention
to maintaining the equal quality over the entire
construction projects. This should lead to more
efficient use of taxpayers' money. The proposed CAD
modeling provides the capability to manage the costs
associated with the inspection risks.
This work has resulted in the development of two
packages. The software called Q-Design (abbreviation of
Quality acceptance plan Designer) has been developed to
fulfill the Artificial Neural Network Module, and the I-
CAD (abbreviation of Inspection plan generator in CAD
system) has been developed to support the CAD modeling
module.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  2529 </NUMBER>
<ORDER>   AAI9512839 </ORDER>
<TITLE> WEIGHT INITIALIZATION IN FEEDFORWARD NEURAL NETWORK CLASSIFIERS  </TITLE>
<AUTHOR> KAYLANI, TAREK </AUTHOR>
<YEAR> 1994 </YEAR>
<INSTITUTION> TEMPLE UNIVERSITY; 0225 </INSTITUTION>
<DESCRIPTORS> ENGINEERING, ELECTRONICS AND ELECTRICAL; COMPUTER SCIENCE; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> SUSHIL DASGUPTA </ADVISER>
<CLASSIFICATIONS> NEURAL NETWORKS </CLASSIFICATIONS>
<ABSTRACT>
In this dissertation, a new weight initialization method
for multi layer perceptron (MLP) classifiers is
developed. This method employs a set of boundary-
preserving patterns to describe initial positions and
orientations of decision boundary segments of hidden
nodes. These segments are then used to determine the
number of hidden nodes and initialize input-to-hidden
weights. Hidden-to-output weights are determined in
closed form by solving a set of linear equations using
the method of pseudoinverses.
A modified condensed nearest neighbor (CNN) algorithm is
also developed to retain a condensed set of boundary-
preserving patterns and avoid the retention of interior
patterns or patterns that may lie in the overlap region
between class distributions. It also attempts to
minimize the effect of the ordering of patterns, in the
training set, on the final contents of the condensed
set. This is achieved by defining a probabilistic
rejection criteria and ordering training patterns based
on k-nearest neighbor estimates of the a posteriori
probabilities.
Four experiments, including three synthesized
distributions and a speaker-independent phoneme
recognition problem, are used to test the validity of
the proposed method. The performance of MLP classifiers
initialized using the proposed approach is compared with
those initialized using the conventional method and the
method of cluster centers. Sensitivity analysis is also
performed to test the effect of a number of
initialization parameters, introduced by the proposed
approach, on the classification performance of the
resulting MLP classifiers.
Simulation results indicate that our method compares
favorably, in terms of classification accuracy, with the
other initialization methods and results in a smaller
number of hidden nodes. This is essential for designing
MLP classifiers with good generalization and that are
less prone to overfitting. Furthermore, it was found
that the classification accuracy of MLPs designed using
boundary-preserving patterns are very sensitive to
variations in the size of the probabilistic reject
region, and thus has to be optimized for in the design
cycle. Also, networks initialized using boundary-
preserving patterns train approximately five times
faster than those initialized randomly.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  2530 </NUMBER>
<ORDER>   AAI9617803 </ORDER>
<TITLE> THE DISABILITY INDEX ANALYSIS SYSTEM VIA ERGONOMICS, EXPERT SYSTEMS, AND MULTIPLE ATTRIBUTE DECISION-MAKING APPROACHES </TITLE>
<AUTHOR> KO, MIN-DER </AUTHOR>
<YEAR> 1994 </YEAR>
<INSTITUTION> UNIVERSITY OF HOUSTON; 0087 </INSTITUTION>
<DESCRIPTORS> ENGINEERING, INDUSTRIAL; HEALTH SCIENCES, PHYSICAL THERAPY; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> NIL </ADVISER>
<CLASSIFICATIONS> NIL </CLASSIFICATIONS>
<ABSTRACT>
Through rehabilitation and training visually impaired
people can be placed in appropriate types of jobs
compatible with their abilities.
The Americans with Disabilities Act (ADA), which went
into effect in July 1992, is designed to assist and
accelerate the return to work of disabled people. The
ADA has redefined the employability and disability of
disabled persons. Employers are requested to look at the
abilities of disabled workers and to make reasonable
accommodations in their jobs and working environments.
Traditional rehabilitation and training simply cannot
fulfill the requirements of the ADA. Thus,
multidisciplinary approaches should be employed to make
proper assessments and to provide reasonable
accommodations for compliance with the ADA.
A functional assessment approach should be established
to measure the physical ability of handicapped people in
response to specific tasks and environmental demands.
The objective of this study is to develop an integrated
computerized system, Vision Impaired Task and Assignment
Lexicon or VITAL, to measure the vision impaired
worker's residual capabilities and to provide the
necessary recommendations for job accommodations. The
VITAL includes two major modules: the Disability Index
(DI) analysis module, and the ergonomic consultation
module.
A single measure, the Disability Index representing
vocational potentials of visually impaired individuals,
through a range of worker characteristics and skill
tests, is developed via Multiple Attribute Decision
Making (MADM) procedures.
The resulting DI can be used to identify the functional
deficits and limitations of the visually impaired
worker, and to match the visually impaired persons to
appropriate employment. This information is also used in
the ergonomic consultation module to provide
recommendations regarding job and workplace design for
the visually impaired worker.
In conclusion, the integration of developing the DI via
MADM, ergonomics, and expert systems approaches may
match the worker skills to job requisites effectively
and could ultimately provide real assistance to those
agencies who seek to obtain productive employment for
visually impaired workers.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  2531 </NUMBER>
<ORDER>   AAI9512798 </ORDER>
<TITLE> SIMULATION SAMPLING FOR A NEURAL-BASED IC PARAMETRIC FAULT DIAGNOSIS SYSTEM </TITLE>
<AUTHOR> WU, KWOKMING ANGUS </AUTHOR>
<YEAR> 1994 </YEAR>
<INSTITUTION> WASHINGTON STATE UNIVERSITY; 0251 </INSTITUTION>
<DESCRIPTORS> ENGINEERING, ELECTRONICS AND ELECTRICAL; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> JACK L. MEADOR </ADVISER>
<CLASSIFICATIONS> NIL </CLASSIFICATIONS>
<ABSTRACT>
A general concept of using feedforward neural networks
for IC parametric fault testing is introduced in Chapter
1. It points out that the IC failure diagnosis problem
can be formulated as a statistical pattern recognition
problem. When trained on circuit measurements, a
feedforward neural network can automatically detect
parametric circuit faults. The absence of any need for
data preprocessing and rapid evaluation makes neural
network a suitable candidate for real-time automatic
production testing. However, the quality of the
classification performance and training efficiency of
neural network strongly depends on the information
presented in the training samples. The success of
applying neural networks in IC parametric fault
diagnosis depends on the ability to efficiently train a
network. This thesis discusses the topics of how to
efficiently train a neural network for IC parametric
fault diagnosis and to develop an effective way to
collect training data which have essential information
to the network training to establish the discriminant
functions for parametric fault diagnosis.
"Boundary band" measurement selection is proposed to
reduce the computation overhead of the feedforward
neural network training. It makes use of the border data
at the circuit specification transition boundaries for
network training. Experimental results positively show
that the proposed training method reduced the training
effort and improved the prediction accuracy in the
single parametric fault cases. To apply the training
method on multiple parametric faults cases, a simulation
sampling algorithm is proposed for boundary data
generation.
The simulation sampling algorithm can capture the
circuit response surfaces that specify the acceptance
region effectively, and facilitate the search for
boundary data used in classifier training for IC
parametric faults testing. The proposed method is based
on the use of design of experiments and regression
models which directly relate each IC performance to the
process disturbances, i.e., those random variables which
characterize the fluctuations that occur during IC
fabrication. Results show that the proposed simulation
sampling algorithm utilizes an effective extreme
vertices sample strategy to best make use of the result
of circuit simulation runs. It estimates the acceptance
region effectively with response functions that are
accurate at the boundaries of the region without relying
on the probability density functions of process
variables. It makes use of the response surface
estimates effectively to generate boundary sample points
for network training. The efficiencies of the proposed
algorithm have been positively demonstrated with testing
examples. Network trained with the proposed algorithm
did out perform the trained with Monte Carlo method.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  2532 </NUMBER>
<ORDER>   AAI9512635 </ORDER>
<TITLE> A KNOWLEDGE-BASED CONSTRUCTION CLAIMS ADVISOR FOR THE A.I.A. A201 GENERAL CONDITIONS DOCUMENT </TITLE>
<AUTHOR> COOPER, THOMAS EUGENE </AUTHOR>
<YEAR> 1994 </YEAR>
<INSTITUTION> AUBURN UNIVERSITY; 0012 </INSTITUTION>
<DESCRIPTORS> ENGINEERING, CIVIL; LAW; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> JAMES D. LUTZ </ADVISER>
<CLASSIFICATIONS> AMERICAN INSTITUTE OF ARCHITECTS </CLASSIFICATIONS>
<ABSTRACT>
In the contemporary construction environment, the
evaluation and processing of construction claims is of
utmost importance. Unfortunately, the claims procedure
established in the Contract Documents is often
needlessly complicated and the Contractor's right to the
Claim can be inadvertently waived by failing to comply
with notice requirements.
In the United States, a large percentage of the
contracts for the construction of buildings utilize the
documents developed by and distributed through the
American Institute of Architects (A.I.A.). In most of
these cases, the A.I.A. A201 General Conditions document
applies.
The claims-related provisions of this document were
incorporated into a knowledge-based system that provides
specific advice to a Contractor for the evaluation and
processing of a construction claim. This interactive
system, named "Claims Advisor", was developed by use of
the Windows version of the expert system shell EXSYS
Professional.
The system evaluates the relative strength of the
Contractor's claim and reminds the user of the
applicable claims procedures, notice requirements, and
time limitations. Since the system is totally
interactive with the user, only that specific date
relevant to the claim in question must be provided.
The consultation initially identifies the applicable
Contract Documents, then proceeds to the circumstances
that lead to the claim, and finally guides the user
through the claims processing procedure itself.
Throughout the consultation, on-screen help is available
to assist the user in providing the proper response(s)
and to interpret the system's conclusions. A total of
21,702 discreet paths through the system's internal
logic diagram is available to the user and in each case
a specific course of action is recommended.
During the investigation, seven typical construction
cases were selected for evaluation by the Claims
Advisor. In six of the seven cases, the system produced
the same conclusion that was arrived at by litigation.
In the remaining case, the system's result was opposite
to that reached by the District Court, but identical to
that reached by the Appeals Court.
Potential users of the system include project managers
and other construction personnel as well as construction
educators and their students.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  2533 </NUMBER>
<ORDER>   AAI9512633 </ORDER>
<TITLE> POKAYOKE SYSTEMS IN UNMANNED MANUFACTURING CELLS </TITLE>
<AUTHOR> CHEN, CHING-SHIHN JOSEPH </AUTHOR>
<YEAR> 1994 </YEAR>
<INSTITUTION> AUBURN UNIVERSITY; 0012 </INSTITUTION>
<DESCRIPTORS> ENGINEERING, INDUSTRIAL; ENGINEERING, MECHANICAL; ENGINEERING, AUTOMOTIVE; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> J. TEMPLE BLACK </ADVISER>
<CLASSIFICATIONS> NIL </CLASSIFICATIONS>
<ABSTRACT>
The Pokayoke Stoplight Control (PSC) and Fuzzy-Net In-
process Pokayoke (FNIP) systems have been developed in
unmanned manufacturing cells (UMCs) to approach a zero
defect rate based on fuzzy systems and neural networks
approaches.
The PSC system provides an UMC with "make one, check
one, and pass one on" capability. A stoplight control
device in the PSC system can respond to the measurement
of the previously finished part by either shutting down
the cell when a defect occurs or warning the cell
manager when an incident happens. A digital simulation
analysis verified that the PSC system could prevent the
defect before it occurs.
The FNIP system is a real-time approach for detecting a
tooling defect in an UMC. By coupling fuzzy logic
control systems and neural networks into the FNIP
system, a self-learning capability (ability to generate
rule bases and to fine tune the membership functions of
each linguist variable to the appropriate level of
granularity) was developed. The FNIP system consists of
two components: (1) the fuzzy search classifier (FSC),
which maps a state vector into a recommended action
using fuzzy pattern recognition, and (2) the fuzzy
adaptive controller (FAC), which maps a state vector and
a failure signal into a scalar grade that indicates
state integrity. The FAC also produces the output active
value, p, to upgrade FSC mapping according to the
variation of the input state.
An automatic learning algorithm was developed for the
FAC and the FSC. It consisted of five steps: (1) divide
the input space into fuzzy regions, (2) generate fuzzy
rules from given data pairs through experiment, (3)
avoid conflicting rules, (4) develop a combined fuzzy
rule base, and (5) determine a mapping based on the
fuzzy rule base. With this on-line learning capability,
learning was accomplished by fine-tuning the parameters
in the fuzzy-nets systems. Consequently, the parameters
describing the fuzzy membership function in the FSC are
changed. In the FAC, the weights (the fuzzy active
values) are adjusted. By using this adaptive function,
the FNIP system can detect the changes of the machining
conditions and upgrade the classifier in order to adapt
to the current machine characteristics.
The performance of FNIP system was examined for an end
milling operation. Various tests prove that the FNIP
system can detect tool breakage at a success rate of
approximately 90%. Additionally, the results prove that
the FNIP system has the capability to upgrade the rule
base while the machining process takes place. From this
study, the FNIP system is shown to be able to detect
tool breakage in the end milling operation "on-line,"
approaching a real-time basis.
We have shown that fuzzy system and neural networks can
corporate to enhance capability of the intelligent
pattern recognition applications and the design of a
robust controller.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  2534 </NUMBER>
<ORDER>   AAI9512626 </ORDER>
<TITLE> A DATABASE DESIGN AND A CONTROLLED AND ADAPTABLE ATTRIBUTE SEARCH MECHANISM FOR THE KL-SNOWY TERMINOLOGICAL KNOWLEDGE REPRESENTATION LANGUAGE </TITLE>
<AUTHOR> SALIMI, ABOALFAZL </AUTHOR>
<YEAR> 1994 </YEAR>
<INSTITUTION> UNIVERSITY OF CENTRAL FLORIDA; 0705 </INSTITUTION>
<DESCRIPTORS> COMPUTER SCIENCE; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> FERNANDO GOMEZ; ALI OROOJI </ADVISER>
<CLASSIFICATIONS> KNOWLEDGE REPRESENTATION </CLASSIFICATIONS>
<ABSTRACT>
The next generation information systems require access
to a large number of simple and complex objects, and
inferencing capability is required to utilize such
systems in various applications. Current AI and database
systems, alone, do not have the capability to handle the
demanding requirements of the new and next generation
applications. AI systems are strong in reasoning and
problem solving but weak in efficiently accessing a
large knowledge-base. Database systems are very
effective in storage and retrieval of large amount of
data, but weak in reasoning. The capabilities of these
two areas must be integrated in order to satisfy all
information requirements.
Snowy-KBMS, a knowledge-base management system, has been
designed as (a) a system to support the new application
needs which are expected to grow in their required
capabilities and the size of knowledge-base, and (b) a
platform for investigating various issues that arise as
a result of AI and database integration. Snowy-KBMS
provides various capabilities such as modification of a
dynamically changing knowledge-base and secondary
storage representation of a large knowledge-base
structure.
We have also designed a new strategy, called controlled
and adaptable attribute search (CAAS), for efficient
knowledge-base access. In this strategy, an inheritable
attribute, defined in a concept, is replicated in the
concept's subclasses which are HTD (Hierarchy Traversal
Distance) concepts away from the concept. This strategy
will allow a search for an attribute in superclasses of
a concept to terminate after visiting a maximum of HTD
concepts in each superclass path of the concept. This is
in contrast to the two strategies, no replication and
full replication, used by object-oriented and knowledge-
representation systems. The degree of replication in
CAAS determines space/time efficiency. CAAS allows a
knowledge-base manager to make the appropriate
adjustments. The CAAS mechanism is not system dependent
and can, therefore, be used in other object-oriented and
terminological-based systems.
We will present the Snowy-KBMS architecture, the CAAS
mechanism used to implement inheritance, and the
simulation results of the Snowy's infer and insert
operations using CAAS.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  2535 </NUMBER>
<ORDER>   AAI9512605 </ORDER>
<TITLE> MANAGEMENT OF STANDARD GRAPHIC SYMBOLS IN A COMPUTER- AIDED DESIGN AND DRAFTING ENVIRONMENT USING NEURAL NETWORK APPROACHES </TITLE>
<AUTHOR> YANG, DER-SHUNG </AUTHOR>
<YEAR> 1994 </YEAR>
<INSTITUTION> UNIVERSITY OF ILLINOIS AT URBANA-CHAMPAIGN; 0090 </INSTITUTION>
<DESCRIPTORS> COMPUTER SCIENCE; ENGINEERING, CIVIL; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> LARRY A. RENDELL </ADVISER>
<CLASSIFICATIONS> NIL </CLASSIFICATIONS>
<ABSTRACT>
Computer-Aided Design and Drafting (CADD) systems have
become prevalent for producing building design drawings.
An ultimate goal of CADD systems is to automate analyses
and communication of high-level design information
extracted from CADD drawings, a difficult task because
of the lack of CADD standards. Using standard graphic
symbols attached with symbolic information can help, but
locating symbols in large libraries is difficult. AUGURS
is a new interactive tool designed to assist CADD users
in utilizing standard symbols.
The task of recognizing symbols sketched by CADD users
differs from traditional pattern recognition problems in
several ways. Standard libraries have over 1000 symbols,
grouped into seven disciplines. The large symbol set
makes training data difficult to obtain. Since AUGURS is
embedded in the CADD system, it must be efficient and
compact. Also, it needs to handle irregular distortion
in symbols sketched by users. These difficulties are
lessened by the special output format that requires
AUGURS to perform only "admissible" recognition,
classifying the input to a small set of plausible
symbols.
The symbol recognition program in AUGURS is a neural
network similar to the Neocognitron, but is more compact
and efficient and having better recognition performance.
The main thrust of the AUGURS approach is a novel
network structure encoded with general knowledge
balancing the discriminant power and the noise tolerance
of the network. To handle large symbol sets, another
thrust of the AUGURS approach is to construct a network
by first building an integrated network from the
internal structures of smaller networks trained on sub-
tasks, and then pruning unnecessary components from this
integrated network.
This research contains an extensive empirical study of
numerous related work varying conditions and parameters.
The results demonstrate the superiority of the AUGURS
approach over many alternatives, including Zipcode Nets,
an unconstrained network, networks using such invariant
features as Zernike moments, pseudo-Zernike moments,
normalized moments, and Fourier-Mellin descriptors, the
Integrated Neural Network, and the connectionist gluing
approach. A practicality analysis shows that AUGURS can
handle around 100 symbols, about the size of a
discipline library. To enable AUGURS to handle even more
symbols, future work is planned to augment it with
domain-specific knowledge and other improvements.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  2536 </NUMBER>
<ORDER>   AAI9512536 </ORDER>
<TITLE> MODELLING FUNCTIONS FROM SAMPLE DATA WITH CLASSIFICATION APPLICATIONS  </TITLE>
<AUTHOR> SAARINEN, SIRPA HELENA </AUTHOR>
<YEAR> 1994 </YEAR>
<INSTITUTION> UNIVERSITY OF ILLINOIS AT URBANA-CHAMPAIGN; 0090 </INSTITUTION>
<DESCRIPTORS> COMPUTER SCIENCE; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> GEORGE CYBENKO </ADVISER>
<CLASSIFICATIONS> PATTERN RECOGNITION, FEEDFORWARD NEURAL NETWORKS, FUNCTION APPROXIMATION, NEAREST NEIGHBOR </CLASSIFICATIONS>
<ABSTRACT>
In this thesis we investigate various aspects of the
pattern recognition problem solving process. Pattern
recognition can be viewed as a decision making process
where the underlying density functions or discriminant
functions of the application have to be estimated often
in a high dimensional space. We consider two main types
of estimators: the feed-forward neural network and the
nearest neighbor method.
In the first part of the thesis we investigate the
optimization problem that is solved when using feed-
forward neural networks for function approximation. We
find that the feed-forward neural network optimization
problem is very ill-conditioned and can influence the
solution process severely. We also show how the feed-
forward neural network function and its gradient can be
implemented using automatic differentiation techniques.
The second part of the thesis is concerned with the
nearest neighbor method. We present two new continuous,
supervised learning methods: a novel memory-based
learning technique and an approximate nearest neighbor
method, both approximating the convergence properties of
the nearest neighbor method. These methods can be used
in continuous learning areas such as speech, hand-
writing and financial applications. We also present a
fast approximate search method for high dimensional
spaces that is based on the k-d-tree. A lower bound on
the performance of the method is derived and some
results are shown for a uniform distribution. An
application of this method to a speech data set shows
very promising results.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  2537 </NUMBER>
<ORDER>   AAI9512523 </ORDER>
<TITLE> HIERARCHICAL AND INTERACTIVE PARAMETER REFINEMENT FOR EARLY-STAGE SYSTEM DESIGN </TITLE>
<AUTHOR> REDDY, SUDHAKAR Y. </AUTHOR>
<YEAR> 1994 </YEAR>
<INSTITUTION> UNIVERSITY OF ILLINOIS AT URBANA-CHAMPAIGN; 0090 </INSTITUTION>
<DESCRIPTORS> ENGINEERING, MECHANICAL; ENGINEERING, SYSTEM SCIENCE </DESCRIPTORS>
<ADVISER> STEPHEN C.-Y. LU </ADVISER>
<CLASSIFICATIONS> CAD </CLASSIFICATIONS>
<ABSTRACT>
Though simulation models are extensively used for
detailed design analysis, their potential benefits for
supporting early-stage design have not yet been
harvested. This thesis presents a new design
methodology, called Hierarchical and Interactive
Decision Refinement (HIDER), which enables detailed
simulation models to be utilized for early-stage design
of engineering systems. HIDER uses a machine-learning
approach for forming fast empirical models at different
levels of abstraction from the detailed simulation
models. Models for different subsystems and from
different perspectives are formed in a uniform
representation and are used together in a single design
environment to provide decision support for system
design.
HIDER uses an interactive refinement approach, based on
explicit use of multiple competing objectives, to enable
the designer to quickly and effectively explore the
overall design space. Multiple objective optimization
produces sets of Pareto-optimal designs, and the
tradeoffs between the different design and performance
attributes in these sets are used to interactively
refine a large initial design space guided by domain-
independent heuristics as well as domain-dependent
knowledge.
A prototype implementation of HIDER, which integrates
the adaptive modeling and the interactive refinement
approaches with an artificial intelligence based design
environment, has been developed to demonstrate and
evaluate the methodology. Results from the evaluation of
HIDER for the parametric design of a diesel engine are
presented. The thesis also demonstrates the methodology
for the system-level design of a wheel loader
simultaneously from competing perspectives, using
detailed and disparate simulation models for cycle time
and stability analyses.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  2538 </NUMBER>
<ORDER>   AAI9512411 </ORDER>
<TITLE> DYNAMIC ANALYSES OF VEHICLES </TITLE>
<AUTHOR> INGRAM, RICHARD GEORGE </AUTHOR>
<YEAR> 1994 </YEAR>
<INSTITUTION> UNIVERSITY OF ILLINOIS AT URBANA-CHAMPAIGN; 0090 </INSTITUTION>
<DESCRIPTORS> ENGINEERING, MECHANICAL; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> CARL LARSON </ADVISER>
<CLASSIFICATIONS> EARTHMOVING EQUIPMENT </CLASSIFICATIONS>
<ABSTRACT>
The overall objective of this thesis is to improve the
method engineers use to predict the performance of
earthmoving vehicle systems. The motivation for this
work is shown by illustrating how these predictions are
used in the design process to impact the financial well-
being of the corporations that use them. The vehicle,
the operator who controls the vehicle, and the soil
which the vehicle digs, carries, and dumps are the three
parts of earthmoving systems whose behavior must be
predicted. Practicing engineers have well known
techniques for predicting the vehicle's behavior. They
do need advances that will allow them to make the
predictions more quickly. In this thesis, a method for
predicting vehicle behavior known as Kane's method is
evaluated to determine if it can address this problem.
These engineers currently have difficulty modeling the
soil. In this thesis, a new method for modeling soil
using neural networks is evaluated and predicted results
are compared to test results.
Since the improvements to vehicle simulation developed
in this thesis must ultimately improve the ability of
corporations that produce earthmoving equipment to
compete, it is necessary to show how this work benefits
the business process. This thesis includes a description
of one type of marketing model that utilizes vehicle
performance predictions and shows how that model can be
applied to an earthmoving vehicle.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  2539 </NUMBER>
<ORDER>   AAI9512398 </ORDER>
<TITLE> ESTIMATION OF SHAPE, LIGHTING, AND REFLECTIVITY FROM STEREO AND SHADING INFORMATION </TITLE>
<AUTHOR> HOUGEN, DARRELL ROY </AUTHOR>
<YEAR> 1994 </YEAR>
<INSTITUTION> UNIVERSITY OF ILLINOIS AT URBANA-CHAMPAIGN; 0090 </INSTITUTION>
<DESCRIPTORS> COMPUTER SCIENCE; ENGINEERING, ELECTRONICS AND ELECTRICAL; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> NARENDRA AHUJA </ADVISER>
<CLASSIFICATIONS> NIL </CLASSIFICATIONS>
<ABSTRACT>
This thesis is concerned with the combined use of stereo
and shading information for the purpose of three-
dimensional surface shape estimation. The applicability,
resolution, and accuracy of each individual method is
examined and compared with that attainable in a combined
approach. Integration is examined from standard and
stochastic perspectives. The standard approach involves
use of stereo information as an initial estimate of the
surface shape from which parameters of the shading
method such as the light source direction can be
estimated. Issues of lighting and reflectivity
estimation are addressed and solutions are advanced. In
particular, general methods for estimation of the light
source distribution and reflectance map are proposed and
tested. Colored lighting and color variant reflectance
functions are examined as possible sources of additional
shape information. A statistical approach to surface
shape estimation called 'shape from appearance' is also
advanced. In this approach, stereo information is used
indirectly as a source of statistical information. It is
shown that through a scale change the resulting
statistical model can be used to achieve higher
resolution than is achievable through the direct use of
stereo information.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  2540 </NUMBER>
<ORDER>   AAI9512392 </ORDER>
<TITLE> NEURAL NETWORKS FOR SIGNAL PROCESSING AND CONTROL </TITLE>
<AUTHOR> HESSELROTH, TED DANIEL </AUTHOR>
<YEAR> 1994 </YEAR>
<INSTITUTION> UNIVERSITY OF ILLINOIS AT URBANA-CHAMPAIGN; 0090 </INSTITUTION>
<DESCRIPTORS> BIOLOGY, NEUROSCIENCE; PHYSICS, GENERAL; COMPUTER SCIENCE; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> KLAUS J. SCHULTEN </ADVISER>
<CLASSIFICATIONS> ROBOTICS </CLASSIFICATIONS>
<ABSTRACT>
Neural networks are developed for controlling a robot-
arm and camera system and for processing images. The
networks are based upon computational schemes that may
be found in the brain.
In the first network, a neural map algorithm is employed
to control a five-joint pneumatic robot arm and gripper
through feedback from two video cameras. The
pneumatically driven robot arm employed shares essential
mechanical characteristics with skeletal muscle systems.
To control the position of the arm, 200 neurons formed a
network representing the three-dimensional workspace
embedded in a four-dimensional system of coordinates
from the two cameras, and learned a set of pressures
corresponding to the end effector positions, as well as
a set of Jacobian matrices for interpolating between
these positions. Because of the properties of the rubber-
tube actuators of the arm, the position as a function of
supplied pressure is nonlinear, nonseparable, and
exhibits hysteresis. Nevertheless, through the neural
network learning algorithm the position could be
controlled to an accuracy of about one pixel ($sim$3 mm)
after two hundred learning steps. Applications of
repeated corrections in each step via the Jacobian
matrices leads to a very robust control algorithm since
the Jacobians learned by the network have to satisfy the
weak requirement that they yield a reduction of the
distance between gripper and target.
The second network is proposed as a model for the
mammalian vision system in which backward connections
from the primary visual cortex (V1) to the lateral
geniculate nucleus play a key role. The application of
hebbian learning to the forward and backward connections
causes the formation of receptive fields which are
sensitive to edges, bars, and spatial frequencies of
preferred orientations. The receptive fields are learned
in such a way as to maximize the rate of transfer of
information from the LGN to V1. Orientational
preferences are organized into a feature map in the
primary visual cortex by the application of lateral
interactions during the learning phase. The organization
of the mature network is compared to that found in the
macaque monkey by several analytical tests.
The capacity of the network to process images is
investigated. By a method of reconstructing the input
images in terms of V1 activities, the simulations show
that images can be faithfully represented in V1 by the
proposed network. The signal-to-noise ratio of the image
is improved by the representation, and compression
ratios of well over two-hundred are possible. Lateral
interactions between V1 neurons sharpen their
orientational tuning. We further study the dynamics of
the processing, showing that the rate of decrease of the
error of the reconstruction is maximized for the
receptive fields used.
Lastly, we employ a Fokker-Planck equation for a more
detailed prediction of the error value vs. time. The
Fokker-Planck equation for an underdamped system with a
driving force is derived, yielding an energy-dependent
diffusion coefficient which is the integral of the
spectral densities of the force and the velocity of the
system. The theory is applied to correlated noise
activation and resonant activation. Simulation results
for the error of the network vs time are compared to the
solution of the Fokker-Planck equation.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  2541 </NUMBER>
<ORDER>   AAI9617802 </ORDER>
<TITLE> DEVELOPMENT OF A COMPUTER INTEGRATED HYBRID EXPERT SYSTEM FOR CONDUCTING THE SEQUENTIAL MULTIPLEX ALGORITHM AND POSTOPTIMALITY ANALYSIS </TITLE>
<AUTHOR> KIM, JAIHYUN </AUTHOR>
<YEAR> 1994 </YEAR>
<INSTITUTION> UNIVERSITY OF HOUSTON; 0087 </INSTITUTION>
<DESCRIPTORS> ENGINEERING, INDUSTRIAL; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> NIL </ADVISER>
<CLASSIFICATIONS> NIL </CLASSIFICATIONS>
<ABSTRACT>
Goal programming has been proposed as an effective tool
for multiple objective optimization problems, and the
MULTIPLEX model and algorithm generalize the GP
approach. A computer integrated system named MASSE is
developed to conduct the sequential MULTIPLEX algorithm
and postoptimality analysis. MASSE consists of three
different parts: model input, implementation of the
MULTIPLEX algorithm, and postoptimality analysis.
The MULTIPLEX model encompasses five classes of linear
programming and goal programming models, and a module to
assort the decision maker's mathematical model is
performed before model input. A rule-based expert system
is applied to classify the input model. Considering the
preference and familiarity of the user and the size of
the problem, three input modes are devised to enhance
user friendliness. After completing model input, MASSE
transforms the decision maker's model to the MULTIPLEX
model.
The sequential MULTIPLEX algorithm solves the single
linear programming problem for each achievement vector
sequentially. Since the stand-alone system may
deteriorate solution quality, LINDO is interfaced with
the algorithm to produce an exact solution.
When applying the sequential algorithm, the problem is
reduced, and it is essential to reconstruct the
multiphase tableau before performing the sensitivity
analysis. In addition to the routines for the general
cases of postoptimality analysis, routines for
unimplementable solutions, unbounded solutions, and
alternative optimal solutions are also developed in
order to obtain implementable, bounded, and other
optimal solutions, respectively. The decision maker's
subjective decisions are reflected in changes to the
solution procedure throughout the procedure.
Computer integrated system, MASSE, was successfully
implemented to problems with single- and multiple-
objective function. The system is easy to access and
descriptive output is understandable and readable.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  2542 </NUMBER>
<ORDER>   AAI9512334 </ORDER>
<TITLE> ALGORITHMS FOR COMBINATORIAL OPTIMIZATION IN REAL-TIME AND THEIR AUTOMATED REFINEMENTS BY GENETICS-BASED LEARNING </TITLE>
<AUTHOR> CHU, LON-CHAN </AUTHOR>
<YEAR> 1994 </YEAR>
<INSTITUTION> UNIVERSITY OF ILLINOIS AT URBANA-CHAMPAIGN; 0090 </INSTITUTION>
<DESCRIPTORS> COMPUTER SCIENCE; ENGINEERING, ELECTRONICS AND ELECTRICAL; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> BENJAMIN W. WAH </ADVISER>
<CLASSIFICATIONS> NIL </CLASSIFICATIONS>
<ABSTRACT>
The goal of this research is to develop a systematic,
integrated method of designing efficient search
algorithms that solve optimization problems in real
time. Search algorithms studied in this thesis comprise
meta-control and primitive search. The class of
optimization problems addressed are called combinatorial
optimization problems, examples of which include many NP-
hard scheduling and planning problems, and problems in
operations research and artificial-intelligence
applications. The problems we have addressed have a well-
defined problem objective and a finite set of well-
defined problem constraints. In this research, we use
state-space trees as problem representations. The
approach we have undertaken in designing efficient
search algorithms is an engineering approach and
consists of two phases: (a) designing generic search
algorithms, and (b) improving by genetics-based machine
learning methods parametric heuristics used in the
search algorithms designed. Our approach is a systematic
method that integrates domain knowledge, search
techniques, and automated learning techniques for
designing better search algorithms. Knowledge captured
in designing one search algorithm can be carried over
for designing new ones.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  2543 </NUMBER>
<ORDER>   AAI9512317 </ORDER>
<TITLE> THE DISCOURSE MODEL FOR COLLABORATIVE DESIGN: A DISTRIBUTED AND ASYNCHRONOUS APPROACH </TITLE>
<AUTHOR> CASE, MICHAEL PATRICK </AUTHOR>
<YEAR> 1994 </YEAR>
<INSTITUTION> UNIVERSITY OF ILLINOIS AT URBANA-CHAMPAIGN; 0090 </INSTITUTION>
<DESCRIPTORS> ENGINEERING, MECHANICAL; COMPUTER SCIENCE; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> STEPHEN C-Y. LU </ADVISER>
<CLASSIFICATIONS> NIL </CLASSIFICATIONS>
<ABSTRACT>
A model is developed for use in software environments
that provide automation support for collaborative
engineering design. This model, called the Discourse
Model, includes a structure specification and a process
specification. Components of the structure include
specifications for a blackboard-based workspace that
incorporates frames, constraints, semantic networks,
libraries of sharable design objects, software agent
modules, an electronic messaging system, and a Virtual
Workspace Language based in part on Knowledge Query
Manipulation Language (KQML). Components of the process
include procedures for identifying agent interest sets,
applying state transformations to the design model,
switching design contexts, identifying conflicts between
designers, exchanging rationale, and tracking resolved
conflicts. The model is implementation-independent and
applicable to many research and commercial design
environments currently available. The Discourse Model is
implemented in the Designer Software blackboard
environment. An example scenario is provided in the
Architecture/Engineering/Construction domain that
illustrates collaboration during the conceptual design
of a fire station.
The Discourse Model has several implications for
managing the complexity of large design projects that
require the collaborative efforts of more than a few
individuals. First, it fills a research gap between
client/server based closely-coupled systems that use a
single shared database and peer-to-peer loosely-coupled
federations of software that incur high data translation
and semantic losses. Second, it yields a new capability
for automatic identification and dissemination of agent
interest sets, leading to detection of unsuspected
conflict areas between designers. Finally, the conflict
detection, rationalization, and resolution protocol
ensures that all interested designers have an
opportunity to participate in the resolution of
conflicts. Appendices include the Virtual Workspace
Language and frame libraries used in the example
scenario.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  2544 </NUMBER>
<ORDER>   AAI9512138 </ORDER>
<TITLE> ULTRASONIC MATERIAL CHARACTERIZATION AND IMAGING BY UNSUPERVISED LEARNING </TITLE>
<AUTHOR> SHEU, JENG-TZONG </AUTHOR>
<YEAR> 1994 </YEAR>
<INSTITUTION> MICHIGAN STATE UNIVERSITY; 0128 </INSTITUTION>
<DESCRIPTORS> ENGINEERING, BIOMEDICAL; ENGINEERING, ELECTRONICS AND ELECTRICAL; HEALTH SCIENCES, RADIOLOGY; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> BONG HO </ADVISER>
<CLASSIFICATIONS> NIL </CLASSIFICATIONS>
<ABSTRACT>
Attenuation coefficient has been considered as a very
important feature in biological tissues
characterization. It is also a well-known fact that
attenuation coefficient is strongly frequency dependent.
However, estimation of attenuation coefficient of
dispersive material is a very difficult task. Unlike
traditional estimation methods, the proposed approach
extracted material dependent features from echoes for
qualitative analysis by unsupervised learning technique.
Two unsupervised learning (clustering) algorithms and
two cluster validity indices were evaluated by Monte
Carlo study to obtain the statistical information.
Finally, an algorithm and an index, according to the
result of Monte Carlo study, were chosen to employ in
the application of ultrasonic material characterization.
The algorithm was implemented by the competitive
learning model of artificial neural networks. The
clustering results are represented in the form of images
in which different color shades represents different
clusters. Different data sets including data extracted
from a phantom and a slice of brain sample were used in
the experiments. The proposed method achieved some
results which are very difficult to fulfill by
traditional methods.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  2545 </NUMBER>
<ORDER>   AAI9512101 </ORDER>
<TITLE> DESIGN AND ANALYSIS OF NEURAL NETWORKS FOR PATTERN RECOGNITION  </TITLE>
<AUTHOR> MAO, JIANCHANG </AUTHOR>
<YEAR> 1994 </YEAR>
<INSTITUTION> MICHIGAN STATE UNIVERSITY; 0128 </INSTITUTION>
<DESCRIPTORS> COMPUTER SCIENCE; ENGINEERING, ELECTRONICS AND ELECTRICAL; MATHEMATICS; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> NIL </ADVISER>
<CLASSIFICATIONS> FEEDFORWARD NETWORKS </CLASSIFICATIONS>
<ABSTRACT>
There are many common links between neural networks and
classical statistical pattern recognition approaches for
designing a recognition system. For example, many
statistical pattern recognition approaches can be mapped
onto a neural network architecture. On the other hand,
some well-known neural network models are related to
classical statistical methods. In spite of numerous
successful applications of feedforward networks reported
in the literature, their generalization behavior has not
been well-understood. This dissertation further expands
the common links between the two disciplines through
design of neural networks for pattern recognition
problems and analysis of the generalization ability of
feedforward networks.
A number of neural networks and learning algorithms for
feature extraction, data projection, classification and
clustering are proposed. These networks include: linear
discriminant analysis network, network for Sammon's
projection, nonlinear projection based on Kohonen's self-
organizing maps, nonlinear discriminant analysis
network, network-based k-nearest neighbor classifier,
and network for detecting hyperellipsoidal clusters. A
comparative study of five networks for feature
extraction and data projection is also conducted.
The generalization ability of a feedforward network
refers to its performance on independent test data
relative to the performance on the training data. Two
different approaches, Vapnik's theory and Moody's
approach, for studying the generalization ability of
feedforward networks are compared. Moody's approach is
extended to a more general setting which allows the
sampling points of test data to be different from those
in training data according to an additive noise model.
Monte Carlo experiments are conducted to verify Moody's
result and our extension of his model, and to
demonstrate the role of the weight-decay regularization
in reducing the effective number of parameters. We also
present a taxonomy of regularization techniques in
neural networks, and demonstrate that a variety of
networks and learning algorithms can fit into this
framework. One significant impact of the theoretical
analysis of the generalization ability of feedforward
networks is that it reveals how different factors
involved in designing feedforward networks interact with
each other. A practical node pruning method is proposed
for designing parsimonious networks which generalize
well, and for reducing the dimensionality of the feature
vector.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  2546 </NUMBER>
<ORDER>   AAI9512073 </ORDER>
<TITLE> HIERARCHICAL TOKEN GROUPING IN KNOWLEDGE-BASED TUBULAR OBJECT EXTRACTION </TITLE>
<AUTHOR> HUANG, QIAN </AUTHOR>
<YEAR> 1994 </YEAR>
<INSTITUTION> MICHIGAN STATE UNIVERSITY; 0128 </INSTITUTION>
<DESCRIPTORS> COMPUTER SCIENCE; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> NIL </ADVISER>
<CLASSIFICATIONS> NIL </CLASSIFICATIONS>
<ABSTRACT>
This dissertation addresses the issues in extracting
tubular objects using an integrated model-based approach
under a problem solving architecture called hierarchical
token grouping.
Tubular objects exist in various application domains.
For example, blood vessels, plant roots, bacteria, and
roads are all tube-shaped. Recognizing this class of
objects from images, quantifying them, and understanding
their networks will be of great benefit to many domains.
Unfortunately, a robust recovery of tubular objects from
noisy images can not be achieved using simple
segmentation methods. An integrated, hierarchical, and
descriptive approach to the problem is needed.
Both modularity and integration are indispensable
aspects of vision problem solving. A bag of tools for a
bag of problems has to be effectively integrated to
achieve an overall solution. We propose a formalism
called hierarchical token grouping (HTG) for such an
integration purpose. Using the central theme of
grouping, we exploit the homogeneity in vision problem
solving. Heterogeneous modules can be treated as
homogeneous operational units that systematically
aggregate perceptual tokens across all levels of
abstraction. The syntax of the formalism is developed
that establishes a consistent and systematic framework
for integrating modules, cues, and knowledge, all in a
globally coherent mechanism. The formalism is used in,
but not limited to, developing a model-based recognition
system for tubular objects.
An integrated model-based recognition strategy is
adopted to extract tubular objects. The geometric shape
information is combined with the imaging information in
a generalized stochastic tube model, a parameterized
form of a class of Generalized Cylinders. This model
renders the recognition problem as a parameter
estimation problem which is subsequently solved in a
hierarchical fashion using optimal filters. Due to the
descriptive nature of the model, a new scheme is used to
visualize a sweeping along a 3D object trajectory.
The model-based tubular object recognition system
developed under the framework of HTG is tested and
evaluated using three evaluation schemes. A total of 53
2D images and 59 3D volumes are used in testing,
including synthetic and real data of blood vessels,
plant roots, bacteria, and wires. Experimental results
demonstrate the effectiveness of the integrated model-
based recognition strategy and the usefulness of the
framework of hierarchical token grouping.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  2547 </NUMBER>
<ORDER>   AAI9511588 </ORDER>
<TITLE> NONLINEAR FLIGHT CONTROL USING NEURAL NETWORKS </TITLE>
<AUTHOR> KIM, BYOUNG SOO </AUTHOR>
<YEAR> 1994 </YEAR>
<INSTITUTION> GEORGIA INSTITUTE OF TECHNOLOGY; 0078 </INSTITUTION>
<DESCRIPTORS> ENGINEERING, AEROSPACE; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> ANTHONY J. CALISE </ADVISER>
<CLASSIFICATIONS> NIL </CLASSIFICATIONS>
<ABSTRACT>
This thesis presents the theoretical development and
numerical investigation of a direct adaptive tracking
control architecture using neural networks. Emphasis is
placed on utilization of neural networks in a flight
control architecture based on feedback linearization of
the aircraft dynamics. Neural networks are used to
represent the nonlinear inverse transformation needed
for feedback linearization. Neural networks may be first
trained off-line using a nominal mathematical model,
which provides an approximate inversion that can
accommodate the total flight envelope. Neural networks
capable of on-line learning are required to compensate
for inversion error which may arise from imperfect
modeling, approximate inversion or sudden changes in
aircraft dynamics. A stable weights adjustment rule for
the on-line neural network is derived. Under mild
assumptions on the nonlinearities representing the
inversion error, the adaptation algorithm assures that
all the signals in the loop are uniformly bounded and
that the weights of the on-line neural network tend to
constant values. Simulation results for an F/A-18
aircraft and an AH-64 helicopter models are presented to
illustrate the performance of the on-line neural network
based adaptation algorithm.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  2548 </NUMBER>
<ORDER>   AAI9509481 </ORDER>
<TITLE> CIRCUIT DESIGN AND SIMULATION OF AN AUGMENTED ADAPTIVE RESONANCE THEORY </TITLE>
<AUTHOR> HO, CHING-SUNG </AUTHOR>
<YEAR> 1994 </YEAR>
<INSTITUTION> UNIVERSITY OF CENTRAL FLORIDA; 0705 </INSTITUTION>
<DESCRIPTORS> ENGINEERING, ELECTRONICS AND ELECTRICAL; PHYSICS, SOLID STATE; BIOLOGY, NEUROSCIENCE; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> JUIN J. LIOU </ADVISER>
<CLASSIFICATIONS> AART </CLASSIFICATIONS>
<ABSTRACT>
This dissertation presents circuit implementations for
an binary-input adaptive resonance theory neural network
architecture, called the augmented ART-1 neural network
(AART1-NN). The AART1-NN is a modification of the
popular ART1-NN, developed by Carpenter and Grossberg,
and it exhibits the same behavior as the ART1-NN. The
AART1-NN is a real-time model, and has the ability to
classify an arbitrary set of binary input patterns into
different clusters. The design of the AART1-NN circuit
is based on a set of coupled nonlinear differential
equations that constitute the AART1-NN model. Various
ways are examined to implement an efficient and
practical AART1-NN in electronic hardware. They include
designing circuits of AART1-NN by means of discrete
electronic components, such as operational amplifiers,
capacitors, and resistors, digital VLSI circuit, and
mixed analog/digital VLSI circuit. The implemented
circuit prototypes are verified using the PSpice circuit
simulator, running on Sun workstations. Results obtained
from PSpice circuit simulations are also compared with
results obtained by solving the coupled differential
equations numerically. The prototype systems developed
in this work can be used as building blocks for larger
AART1-NN architectures, as well as for other types of
ART architectures that involve the AART1-NN model.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  2549 </NUMBER>
<ORDER>   AAI9509238 </ORDER>
<TITLE> A NEURAL NETWORK APPROACH FOR JOB SHOP SCHEDULING PROBLEMS </TITLE>
<AUTHOR> DU, HONGWEI </AUTHOR>
<YEAR> 1994 </YEAR>
<INSTITUTION> FLORIDA INSTITUTE OF TECHNOLOGY; 0473 </INSTITUTION>
<DESCRIPTORS> OPERATIONS RESEARCH; MATHEMATICS; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> DONALD W. FAUSETT </ADVISER>
<CLASSIFICATIONS> NIL </CLASSIFICATIONS>
<ABSTRACT>
This dissertation presents an application of artificial
neural networks to the solution of job shop scheduling
problems. It begins with a new branch and bound
algorithm based on a disjunctive graph model of Balas.
The algorithm has been developed to find reasonable
initial solutions for input to our neural network
models. Besides the new ideas to generate the lower
bound and to direct the branch by critical path of the
graph, it uses the essential relationships between
operations using the same machine to reduce the numbers
of disjunctive pairs first time. Then we present two
artificial neural network models for solving job shop
scheduling problems. First, a continuous Hopfield-type
artificial neural network has been utilized to obtain
solutions to job shop scheduling problems with the help
of simulated annealing to escape from local minima. This
allows a better solution to be found more readily. In
this approach, each neuron represents one operation of a
particular job. Therefore, the total number of neurons
equals the total number of operations. Next, the problem
has been mapped onto a Boltzmann machine neural network
architecture. No one has presented this to date in the
literature (to our knowledge). In this approach, each
operation is represented by a group of neurons, equal in
number to the number of jobs in the problem. In contrast
to a similar approach, developed by Foo and Takefuji,
for a six jobs and six machines problem, our Hopfield-
type model uses 36 neurons and our Boltzmann machine
model needs 216 neurons, while their model requires 1332
neurons. Larger number of neurons require longer
computer execution times for convergence. These
approaches have been programmed and tested on several
standard test problems. The results obtained compare
favorably with other methods.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  2550 </NUMBER>
<ORDER>   AAI9508898 </ORDER>
<TITLE> HIGH-SPEED MODEL-BASED IDENTIFICATION OF DYNAMIC SYSTEMS </TITLE>
<AUTHOR> HUANG, MING-SHYAN </AUTHOR>
<YEAR> 1994 </YEAR>
<INSTITUTION> THE UNIVERSITY OF WISCONSIN - MADISON; 0262 </INSTITUTION>
<DESCRIPTORS> ENGINEERING, MECHANICAL; ENGINEERING, ELECTRONICS AND ELECTRICAL; COMPUTER SCIENCE; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> SLAWOMIR A. SPIEWAK </ADVISER>
<CLASSIFICATIONS> NIL </CLASSIFICATIONS>
<ABSTRACT>
System identification is of great importance to
understand a system's characteristics and behaviors.
Although it has been a subject of extensive research for
many years, the reliability and accuracy of results can
be very problematic for systems whose input signals are
non-measurable, and/or the model structures are vaguely
defined. The estimation of model parameters may require
long computational time, especially for systems with
high order models. Furthermore, system identification
relies heavily on experts' experience and knowledge,
which have not been integrated into available numerical
algorithms as yet.
Self-tuning sensors are a good representative of dynamic
systems with unavailable input signals, which require
system identification. To recover these signals,
suitable filters are used. To tune these filters on-
line, parameters of the sensor and the machining
process, in which this sensor is used, have to be
estimated. Accurate estimation of these parameters
requires, in turn, a priori information about the
sensor, machine, and process.
The primary objective of this research is to develop an
algorithm that allows accurate, reliable, and fast
system identification. This algorithm has to be
applicable to systems with sharp resonances which are
spread over wide-frequency bandwidths. If necessary, the
required algorithm can use large signal samples, which
are readily available. On-line tuning requires the
knowledge of which identified resonances of the entire
system are associated with the sensor and cause
significant distortions of measured signals. Recognition
of these resonances requires a priori knowledge about
the system and application of human experts' experience
with identification.
A high speed, robust, and accurate identification
algorithm was developed and tested in this research. The
algorithm integrates artificial intelligence techniques,
high speed parallel processing, and ARMA modeling
methodology.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  2551 </NUMBER>
<ORDER>   AAI0575727 </ORDER>
<TITLE> DISCRETE-TIME NEURAL NETWORKS AS DYNAMICAL SYSTEMS </TITLE>
<AUTHOR> WANG, XIN </AUTHOR>
<YEAR> 1994 </YEAR>
<INSTITUTION> UNIVERSITY OF SOUTHERN CALIFORNIA; 0208 </INSTITUTION>
<DESCRIPTORS> MATHEMATICS; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> EDWARD K. BLUM </ADVISER>
<CLASSIFICATIONS> NIL </CLASSIFICATIONS>
<ABSTRACT>
This dissertation, viewing neural networks as dynamical
systems, intends to give a coherent treatment on various
dynamics of neural networks covering periodicity,
bifurcation, chaos, and coupled oscillations, as well as
relationships between discrete-time and continuous-time
models. A discrete-time model of neural networks is
mostly used to motivate and illustrate the general
principles. (Copies available exclusively from
Micrographics Department, Doheny Library, USC, Los
Angeles, CA 90089-0182.)
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  2552 </NUMBER>
<ORDER>   AAIMM03536 </ORDER>
<TITLE> THE LEARNABILITY AND TEACHABILITY OF VERTEX SETS </TITLE>
<AUTHOR> EVANS, PATRICIA ANNE </AUTHOR>
<YEAR> 1994 </YEAR>
<INSTITUTION> UNIVERSITY OF VICTORIA (CANADA); 0244 </INSTITUTION>
<DESCRIPTORS> COMPUTER SCIENCE; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> MICHAEL R. FELLOWS </ADVISER>
<CLASSIFICATIONS> CRYPTOGRAPHY </CLASSIFICATIONS>
<ABSTRACT>
A concept's learnability is one perspective from which
to analyze its complexity. Graphs and graph properties
form a rich combinatorial area for complexity analysis.
This thesis explores the learnability of various
properties of sets and vertices in graphs, using models
for exact learning with queries. Lower bounds are found
for the number of queries required, thus proving that
many of the learning algorithms are optimal. The
complexity of teaching, where the Teacher has the active
role in the learning process, is also explored for sets
of vertices. Learning complexity has a link to
cryptographical complexity; I look at the relationship
between learnability and a cryptosystem based on vertex
sets.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  2553 </NUMBER>
<ORDER>   AAI0575717 </ORDER>
<TITLE> RECOMBINATION, SELECTION, AND THE GENETIC CONSTRUCTION OF COMPUTER PROGRAMS </TITLE>
<AUTHOR> TACKETT, WALTER ALDEN </AUTHOR>
<YEAR> 1994 </YEAR>
<INSTITUTION> UNIVERSITY OF SOUTHERN CALIFORNIA; 0208 </INSTITUTION>
<DESCRIPTORS> COMPUTER SCIENCE </DESCRIPTORS>
<ADVISER> JEAN-LUC GAUDIOT </ADVISER>
<CLASSIFICATIONS> NIL </CLASSIFICATIONS>
<ABSTRACT>
Computational intelligence seeks, as a basic goal, to
create artificial systems which mimic aspects of
biological adaptation, behavior, perception, and
reasoning. Toward that goal, genetic program induction--
"Genetic Programming"--has succeeded in automating an
activity traditionally considered to be the realm of
creative human endeavor. It has been applied
successfully to the creation of computer programs which
solve a diverse set of model problems. This naturally
leads to questions such as: (1) Why does it work? (2)
How does it fundamentally differ from existing methods?
(3) What can it do that existing methods cannot?
The research described here seeks to answer those
questions. This is done on several fronts. Analysis is
performed which shows that Genetic Programming has a
great deal in common with heuristic search, long studied
in the field of Artificial Intelligence. It introduces a
novel aspect to that method in the form of the
recombination operator which generates successors by
combining parts of favorable strategies. On another
track, we show that Genetic Programming is a powerful
tool which is suitable for real-world problems. This is
done first by applying it to an extremely difficult
induction problem and measuring performance against
other state-of-the-art methods. We continue by
formulating a model induction problem which not only
captures the pathologies of the real world, but also
parameterizes them so that variation in performance can
be measured as a function of confounding factors. At the
same time, we study how the effects of search can be
varied through the effects of the selection operator.
Combining the lessons of the search analysis with known
properties of biological systems leads to the
formulation of a new recombination operator which is
shown to improve induction performance. In support of
the analysis of selection and recombination, we define
problems in which structure is precisely controlled.
These allow fine discrimination of search performance
which help to validate analytic predictions. Finally, we
address a truly unique aspect of Genetic Programming,
namely the exploitation of symbolic procedural knowledge
in order to provide "explanations" from genetic
programs.
(Copies available exclusively from Micrographics Dept.,
Doheny Library, USC, L.A., CA 90089-0182).
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  2554 </NUMBER>
<ORDER>   AAINN92942 </ORDER>
<TITLE> UNSUPERVISED LEARNING FROM A GOAL-DRIVEN AGENT </TITLE>
<AUTHOR> PELLETIER, BERTRAND </AUTHOR>
<YEAR> 1994 </YEAR>
<INSTITUTION> CARLETON UNIVERSITY (CANADA); 0040 </INSTITUTION>
<DESCRIPTORS> COMPUTER SCIENCE; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> BERNARD PAGUREK; STAN MATWIN </ADVISER>
<CLASSIFICATIONS> NIL </CLASSIFICATIONS>
<ABSTRACT>
Knowledge acquisition, the process of incorporating
expertise into computer systems, is one of the most
difficult and challenging problems in machine learning.
One way to address the problem is to extract the desired
information by analyzing the behaviour of human experts
while they are at their best, that is to say, while they
solve problems in their domains of expertise--in
contrast with situations where they try to explain how
to solve these problems.
One approach to the knowledge acquisition problem
consists in recording--without any perturbations--expert
behaviours in order to extract pertinent information
from them.
This thesis describes an approach and an implemented
system to realize this form of unsupervised and non-
obtrusive learning. The approach exploits techniques and
representations from machine learning and planning to
address the problem.
Starting from an incomplete theory of goals and plans
used by the experts to solve problems, and using several
instances of expert behaviours not fully explained by
this theory, missing knowledge is inferred to augment
the theory, making it adequate to explain a larger part
of the behaviours.
The learning methods proposed in the thesis do the
following: determine the goal structure used by the
expert, that is to say, the decomposition of goals into
subgoals, down to the level of primitive actions, infer
candidate pertinent goals achieved by the expert that
are left unexplained by the current theory, identify and
generalize the plans used by the expert to achieve the
goals, and determine the precondition and the
postcondition and the generalized plans.
This type of learning is appropriate to acquire
knowledge from designers using software tools (in
databases and integrated circuits, for instance), and
from planners achieving goals under given constraints
such as in robotics or experimentation.
The learning methods were applied to two domains--entity-
relationship model design and office tasks--where
favorable empirical results have been obtained and are
described.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  2555 </NUMBER>
<ORDER>   AAINN92807 </ORDER>
<TITLE> A MINIMUM DESCRIPTION LENGTH FRAMEWORK FOR UNSUPERVISED LEARNING </TITLE>
<AUTHOR> ZEMEL, RICHARD STANLEY </AUTHOR>
<YEAR> 1994 </YEAR>
<INSTITUTION> UNIVERSITY OF TORONTO (CANADA); 0779 </INSTITUTION>
<DESCRIPTORS> COMPUTER SCIENCE; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> NIL </ADVISER>
<CLASSIFICATIONS> NIL </CLASSIFICATIONS>
<ABSTRACT>
A fundamental problem in learning and reasoning about a
set of information is finding the right representation.
The primary goal of an unsupervised learning procedure
is to optimize the quality of a system's internal
representation. In this thesis, we present a general
framework for describing unsupervised learning
procedures based on the Minimum Description Length (MDL)
principle. The MDL principle states that the best model
is one that minimizes the summed description length of
the model and the data with respect to the model.
Applying this approach to the unsupervised learning
problem makes explicit a key trade off between the
accuracy of a representation (i.e., how concise a
description of the input may be generated from it) and
its succinctness (i.e., how compactly the representation
itself can be described).
Viewing existing unsupervised learning procedures in
terms of the framework exposes their implicit
assumptions about the type of structure assumed to
underlie the data. While these existing algorithms
typically minimize the data description using a fixed
length representation, we use the framework to derive a
class of objective functions for training self-
supervised neural networks, where the goal is to
minimize the description length of the representation
simultaneously with that of the data. Formulating a
description of the representation forces assumptions
about the structure of the data to be made explicit,
which in turn leads to a particular network
configuration as well as an objective function that can
be used to optimize the network parameters. We describe
three new learning algorithms derived in this manner
from the MDL framework. Each algorithm embodies a
different scheme for describing the internal
representation, and is therefore suited to a range of
datasets based on the structure underlying the data.
Simulations demonstrate the applicability of these
algorithms on some simple computational vision tasks.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  2556 </NUMBER>
<ORDER>   AAINN92720 </ORDER>
<TITLE> MERGING RULE-BASED EXPERTISE: A FINANCIAL MANAGEMENT COST ACCOUNTING SYSTEM APPLICATION </TITLE>
<AUTHOR> KRUSHELNYCKY, EUGENE </AUTHOR>
<YEAR> 1994 </YEAR>
<INSTITUTION> UNIVERSITY OF TORONTO (CANADA); 0779 </INSTITUTION>
<DESCRIPTORS> ENGINEERING, INDUSTRIAL; ARTIFICIAL INTELLIGENCE; BUSINESS ADMINISTRATION, ACCOUNTING </DESCRIPTORS>
<ADVISER> I. B. TURKSEN </ADVISER>
<CLASSIFICATIONS> NIL </CLASSIFICATIONS>
<ABSTRACT>
A model of merging rule-based expertise from two experts
was developed from the perspective of looking at two-
expert expert systems and considering both crisp and
fuzzy models. An application in financial cost
management systems was chosen. Validation of the theory
was sought through the construction of two-expert expert
systems. Eight systems were constructed to compare a
priori crisp and fuzzy systems of the a posteriori
system and empirical results. Initial results utilizing
a simple union scheme for merging rules were no better
than 68% in predictive accuracy. A classification scheme
consisting of adjacent pair-wise comparisons of
membership values to a predefined delta is developed for
the identification of variables critical to inter-expert
solution resolution. Three types of interactions are
observed: dominance, agreed dissonance and agreed
settlement. The model incorporating the latter types of
interaction far outperforms the crisp and fuzzy models
which lack the latter information. The model which
incorporates the classification scheme of interaction
using critical variables has a predictive accuracy of
100%. It is found that two-expert expert systems are
more flexible and offer a wider selection of both inputs
and possible solution sets to users. Two-expert based
systems are found to be superior to one-expert based
systems. Two-expert based systems incorporating
interaction information are concluded to be superior to
those not including this information. Suggestions are
made with respect to other techniques of representing
expert interaction, both from inferencing and variable
representation viewpoints.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  2557 </NUMBER>
<ORDER>   AAINN92616 </ORDER>
<TITLE> TEMPORAL REASONING IN THE SITUATION CALCULUS </TITLE>
<AUTHOR> PINTO, JAVIER ANDRES </AUTHOR>
<YEAR> 1994 </YEAR>
<INSTITUTION> UNIVERSITY OF TORONTO (CANADA); 0779 </INSTITUTION>
<DESCRIPTORS> COMPUTER SCIENCE; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> RAYMOND REITER </ADVISER>
<CLASSIFICATIONS> NIL </CLASSIFICATIONS>
<ABSTRACT>
A fundamental problem in Knowledge Representation is the
design of a logical language to express theories about
actions and change. One of the most prominent proposals
for such a language is John McCarthy's situation
calculus, a formalism which views situations as
branching towards the future. The situation calculus has
been criticized for imposing severe representational
limitations. For example, actions cannot be concurrent,
properties change discreetly, etc. In this thesis we
show that many of these limitations can be overcome. Our
work builds upon the discrete situation calculus and on
Reiter's montonic solution to the frame problem. A
limitation of Reiter's approach is that it does not
allow for state constraints. However, Lin and Reiter
have made progress by providing a correctness criterion
by which one can determine if an axiomatization can be
said to solve the frame problem for theories that
include state constraints.
In this thesis we extend Lin and Reiter's work on the
ramification problem by providing mechanisms to deal
with theories of action that include binary state
constraints and/or stratified definitions. Furthermore,
we show how to extend the situation calculus to deal
with a wider range of representational issues. In
particular, we provide an approach to represent
determinate knowledge about the future. Also, we extend
the situation calculus to deal with concurrent actions.
This problem is addressed by separating the problem into
a precondition interaction problem and an effect
interaction problem. Moreover, we present an enriched
ontology of the situation calculus that allows the
representation of knowledge about continuous properties
of the world. We introduce the notion of a natural
event, which is the result of a process governed by the
laws of nature. Finally, we show that the situation
calculus provides a better logical foundation for
reasoning about actions and time than some other popular
temporal logics.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  2558 </NUMBER>
<ORDER>   AAI1359959 </ORDER>
<TITLE> KNOWLEDGE BASED EXPERT SYSTEM FOR "AMERICANS WITH DISABILITIES ACT </TITLE>
<AUTHOR> SOMASEKHARARADHYA, MANJUNATH </AUTHOR>
<YEAR> 1994 </YEAR>
<INSTITUTION> TEXAS A&M UNIVERSITY-KINGSVILLE; 1187 </INSTITUTION>
<DESCRIPTORS> ENGINEERING, INDUSTRIAL; ENGINEERING, CIVIL; ARCHITECTURE; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> KAMBIZ FARAHMAND </ADVISER>
<CLASSIFICATIONS> ADA </CLASSIFICATIONS>
<ABSTRACT>
According to the 1990 census, an estimated 43 million
persons in the United States have a disability and this
number is increasing as the population as a whole is
growing. In general, facilities that can provide
reasonable accommodation to the disabled individuals are
clearly more valuable than non-accessible facilities.
The objective of this research is to develop and build a
knowledge based system that would provide design and
layout guidelines and recommendations for such
facilities.
The result of this research is a Knowledge Based Expert
System for "Americans With Disabilities Act (ADA) of
1990" Facilities Layout and Accessibility Design
Guidelines. This system is a useful tool that provides
facilities layout and accessibility design guidelines
for quick access and use in the design and development
environment. By incorporating the facilities layout and
accessibility design guidelines into a knowledge based
expert system, the Facility Designer will have quick
access to the ADA regulations in a given area and the
design recommendations and specifications required to be
in compliance with the law.
Recommendations for future research and development in
this and other areas related to ADA and design
improvements for disabled workers are provided.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  2559 </NUMBER>
<ORDER>   AAI1359958 </ORDER>
<TITLE> THE DEVELOPMENT OF FUZZY COGNITIVE MAP FOR MANUFACTURABILITY ANALYSIS BASED ON PART FEATURES </TITLE>
<AUTHOR> RAO, SUBRAMANYA KRISHNAMURTHY </AUTHOR>
<YEAR> 1994 </YEAR>
<INSTITUTION> TEXAS A&M UNIVERSITY-KINGSVILLE; 1187 </INSTITUTION>
<DESCRIPTORS> ENGINEERING, INDUSTRIAL; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> PRASAD S. GAVANKAR </ADVISER>
<CLASSIFICATIONS> NIL </CLASSIFICATIONS>
<ABSTRACT>
Knowledge representation is very important to define and
express any social or technical problem. Manufacturing
is a vast area in which various complex problems exist.
The fuzzy cognitive map is one novel way of expressing
such complex situations.
This thesis considers the approach of construction and
use of fuzzy cognitive maps to assess and analyze the
degree of difficulty in manufacturing a machined part.
The study is based on feature geometry of a part and
interaction of one feature with another. It is also
important to consider factors such as precision of the
part, capability of an available machine tool, etc.
Fuzzy cognitive map is drawn and transformed into a
mathematical model. The cognitive map matrix is
subjected to iterative multiply-accumulate operation,
until equilibrium is reached. The output vector is
logical inference.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  2560 </NUMBER>
<ORDER>   AAI1359947 </ORDER>
<TITLE> EXPERT SYSTEM FOR THE DESIGN OF EXPERIMENTS </TITLE>
<AUTHOR> KAYATHI, RAJENDER REDDY </AUTHOR>
<YEAR> 1994 </YEAR>
<INSTITUTION> TEXAS A&M UNIVERSITY-KINGSVILLE; 1187 </INSTITUTION>
<DESCRIPTORS> ENGINEERING, INDUSTRIAL; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> JAVAD GOLKAR </ADVISER>
<CLASSIFICATIONS> NIL </CLASSIFICATIONS>
<ABSTRACT>
This paper deals with the development of an expert
system for the design of experiments. The expert system
suggests appropriate experiments depending on the
conditions supplied by the user. This expert system is
developed in a user friendly windows environment. The
programming code is written in C language.
The research develops basic work for building an expert
system for the design of experiments. The expert system
knowledge base consists of the most commonly used
experiments in a day-to-day industrial environment. The
knowledge base needs to be upgraded from time-to-time in
order to keep up with the requirements of new
experiments to take full advantage of the expert system
capabilities.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  2561 </NUMBER>
<ORDER>   AAI1359947 </ORDER>
<TITLE> EXPERT SYSTEM FOR THE DESIGN OF EXPERIMENTS </TITLE>
<AUTHOR> KAYATHI, RAJENDER REDDY </AUTHOR>
<YEAR> 1994 </YEAR>
<INSTITUTION> TEXAS A&M UNIVERSITY-KINGSVILLE; 1187 </INSTITUTION>
<DESCRIPTORS> ENGINEERING, INDUSTRIAL; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> JAVAD GOLKAR </ADVISER>
<CLASSIFICATIONS> NIL </CLASSIFICATIONS>
<ABSTRACT>
This paper deals with the development of an expert
system for the design of experiments. The expert system
suggests appropriate experiments depending on the
conditions supplied by the user. This expert system is
developed in a user friendly windows environment. The
programming code is written in C language.
The research develops basic work for building an expert
system for the design of experiments. The expert system
knowledge base consists of the most commonly used
experiments in a day-to-day industrial environment. The
knowledge base needs to be upgraded from time-to-time in
order to keep up with the requirements of new
experiments to take full advantage of the expert system
capabilities.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  2562 </NUMBER>
<ORDER>   AAI1359696 </ORDER>
<TITLE> A RULE-BASED APPROACH TO CLASS SCHEDULING </TITLE>
<AUTHOR> MCSPADDEN, JANET MARIE </AUTHOR>
<YEAR> 1994 </YEAR>
<INSTITUTION> CALIFORNIA STATE UNIVERSITY, LONG BEACH; 6080 </INSTITUTION>
<DESCRIPTORS> COMPUTER SCIENCE; ARTIFICIAL INTELLIGENCE; EDUCATION, ADMINISTRATION; EDUCATION, TECHNOLOGY </DESCRIPTORS>
<ADVISER> SHUI F. LAM </ADVISER>
<CLASSIFICATIONS> NIL </CLASSIFICATIONS>
<ABSTRACT>
A complete software package was developed for a typical
academic department in a university setting to
facilitate scheduling of faculty and classes. The method
used was that of a rule-based approach which produced
not necessarily an optimal solution (i.e. not all
classes may be scheduled to full time faculty) but one
which conformed to a set of established rules. The input
was easily tunable to allow the user to generate within
seconds multiple schedules to choose from. The solution
was implemented in the C++ programming language. The
software was tested using actual data for the fall
semester of 1993 and spring semester of 1994. The
computerized process required nominal time to construct,
however, the possible savings in scheduling time and the
ability to meet the needs of other departments with
moderate changes make it a valuable contribution.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  2563 </NUMBER>
<ORDER>   AAIMM03153 </ORDER>
<TITLE> ELECTRONIC CULTURE: COMPUTER MEDIATED COMMUNICATION AND COGNITIVE ENHANCEMENT </TITLE>
<AUTHOR> MULHOLLAND, LIZA SHEEHAN </AUTHOR>
<YEAR> 1994 </YEAR>
<INSTITUTION> UNIVERSITY OF CALGARY (CANADA); 0026 </INSTITUTION>
<DESCRIPTORS> MASS COMMUNICATIONS; PSYCHOLOGY, GENERAL; ARTIFICIAL INTELLIGENCE; PSYCHOLOGY, SOCIAL </DESCRIPTORS>
<ADVISER> DAVID MITCHELL </ADVISER>
<CLASSIFICATIONS> NIL </CLASSIFICATIONS>
<ABSTRACT>
Will computer mediated technology 'enhance' or 'extend'
consciousness? The question is situated in
'Communications History,' and reviews the problematic
established by the Toronto School--in that various media
affect significant shifts in cultural environments
(Innis), and individual consciousness (McLuhan).
Informed by the shift from orality to literacy (Ong),
and the current shift from literate to electronic
cultures (Heim and Landow)--each remains an inadequate
model for the effects of media on cognition. The focus
of the thesis is recontextualized to review early models
of mind, Artificial Intelligence, and the emergence of a
science of cognition.
A possible model for the structure and function of human
cognition is presented in Howard Gardner's Theory of
Multiple Intelligences; then operationalized in a
process whereby raw intellectual capacities are encoded
by symbols for subsequent representation by symbolic and
cultural products (media). This paper contends computer
mediated communication may have a significant impact on
cognition (Salomon)--amplifying and extending the
sensorium; upgrading and activating metacognitive
constructs and by initiating higher-order thinking.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  2564 </NUMBER>
<ORDER>   AAI1359696 </ORDER>
<TITLE> A RULE-BASED APPROACH TO CLASS SCHEDULING </TITLE>
<AUTHOR> MCSPADDEN, JANET MARIE </AUTHOR>
<YEAR> 1994 </YEAR>
<INSTITUTION> CALIFORNIA STATE UNIVERSITY, LONG BEACH; 6080 </INSTITUTION>
<DESCRIPTORS> COMPUTER SCIENCE; ARTIFICIAL INTELLIGENCE; EDUCATION, ADMINISTRATION; EDUCATION, TECHNOLOGY </DESCRIPTORS>
<ADVISER> SHUI F. LAM </ADVISER>
<CLASSIFICATIONS> NIL </CLASSIFICATIONS>
<ABSTRACT>
A complete software package was developed for a typical
academic department in a university setting to
facilitate scheduling of faculty and classes. The method
used was that of a rule-based approach which produced
not necessarily an optimal solution (i.e. not all
classes may be scheduled to full time faculty) but one
which conformed to a set of established rules. The input
was easily tunable to allow the user to generate within
seconds multiple schedules to choose from. The solution
was implemented in the C++ programming language. The
software was tested using actual data for the fall
semester of 1993 and spring semester of 1994. The
computerized process required nominal time to construct,
however, the possible savings in scheduling time and the
ability to meet the needs of other departments with
moderate changes make it a valuable contribution.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  2565 </NUMBER>
<ORDER>   AAI1359570 </ORDER>
<TITLE> ANALYSIS OF VIBRATION DATA USING NEURAL NETWORK SOFTWARE </TITLE>
<AUTHOR> KARAM, MARC </AUTHOR>
<YEAR> 1994 </YEAR>
<INSTITUTION> UNIVERSITY OF NEVADA, RENO; 0139 </INSTITUTION>
<DESCRIPTORS> ENGINEERING, ELECTRONICS AND ELECTRICAL; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> ANDRZEJ TRZYNADLOWSKI </ADVISER>
<CLASSIFICATIONS> NIL </CLASSIFICATIONS>
<ABSTRACT>
Analysis of vibration data in rotating electromachine
systems is an important means of preventive maintenance
diagnostics. The data, obtained from proximity probes,
are often distorted. Visual inspection of the raw data
must be done prior to further analysis in order to
eliminate invalid records.
This thesis describes a research study on the
application of neural network software to the
classification of vibration waveforms. Three validation
networks were developed to distinguish between
undistorted, positive-clip, negative-clip, and glitched
waveforms. The successful results confirm the
feasibility of validation of vibration data using neural
networks. In addition, recovery of clipped peaks using
neural networks was attempted. Satisfactory results were
obtained with waveforms limited to 5 bytes clip.
Detailed description of the developed networks, training
and testing procedures, and obtained results are
presented. The successful outcome of the study opens the
way for application of neural network software in expert
systems for machinery diagnostics.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  2566 </NUMBER>
<ORDER>   AAI1359421 </ORDER>
<TITLE> CLASSIFICATION OF SAR IMAGES AND RETRIEVAL OF REMOTELY SENSED PARAMETERS USING NEURAL NETWORKS </TITLE>
<AUTHOR> RAWAT, VIKRAM KUMAR </AUTHOR>
<YEAR> 1994 </YEAR>
<INSTITUTION> THE UNIVERSITY OF TEXAS AT ARLINGTON; 2502 </INSTITUTION>
<DESCRIPTORS> ENGINEERING, ELECTRONICS AND ELECTRICAL; REMOTE SENSING; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> ADRIAN K. FUNG </ADVISER>
<CLASSIFICATIONS> NIL </CLASSIFICATIONS>
<ABSTRACT>
Neural networks are applied for retrieval and
classification of remotely sensed data. Study of various
characteristics of the parameters to be retrieved is
essential prior to the retrieval process. Fast learning
neural networks have been found to successfully retrieve
relevant parameters if the input to network is properly
selected. Forest scattering parameters from simulated
data have been successfully retrieved with excellent
results. The use of neural network is extended for
supervised classification of AIRSAR images. Two types of
networks are used for the classification problem, the
multi-layer perceptron which uses the output weight
optimization technique and the functional link network
which is a polynomial classifier. Both of these networks
perform excellently with low training error percentage
if the input to the network is properly chosen. The
resulting classified images are compared to conventional
Bayes-Gaussian Classifier outputs.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  2567 </NUMBER>
<ORDER>   AAI1359247 </ORDER>
<TITLE> AN APPLICATION OF GAUSSIAN RADIAL BASED FUNCTION NEURAL NETWORKS FOR THE CONTROL OF A NONLINEAR MULTI LINK ROBOTIC MANIPULATOR </TITLE>
<AUTHOR> MIZEREK, ROBERT T. </AUTHOR>
<YEAR> 1994 </YEAR>
<INSTITUTION> UNIVERSITY OF NEVADA, LAS VEGAS; 0506 </INSTITUTION>
<DESCRIPTORS> ENGINEERING, ELECTRONICS AND ELECTRICAL; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> NIL </ADVISER>
<CLASSIFICATIONS> NIL </CLASSIFICATIONS>
<ABSTRACT>
The theory of Gaussian radial based function neural
networks is developed along with a stable adaptive
weight training law founded upon Lyapunov stability
theory. This is applied to the control of a nonlinear
multi-linked robotic manipulator for the general case of
N links. Simulations of a two link system are performed
and demonstrate the derived principles.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  2568 </NUMBER>
<ORDER>   AAI0665576 </ORDER>
<TITLE> THE USE OF CONNECTIONIST NETWORK MODELS FOR PROCESSING NATURAL LANGUAGE TEXT </TITLE>
<AUTHOR> ROS, NICOLETTA CHRISTINA JOHANNA </AUTHOR>
<YEAR> 1994 </YEAR>
<INSTITUTION> UNIVERSITY OF PRETORIA (SOUTH AFRICA); 6004 </INSTITUTION>
<DESCRIPTORS> COMPUTER SCIENCE </DESCRIPTORS>
<ADVISER> G. D. OOSTHUIZEN </ADVISER>
<CLASSIFICATIONS> NIL </CLASSIFICATIONS>
<ABSTRACT>
Connectionist natural language processing (CNLP) is a
new approach to the processing of language. Traditional
artificial intelligence (AI) methods, also referred to
as symbolic methods, are representation-oriented (using
symbols and rules), while connectionist (or subsymbolic)
methods are process-oriented (dependent on adjustments
to weights in a neural network).
Natural language processing (NLP) is a general term used
to describe the processes that formalise language
structure and relationships in order to express meaning
and resolve ambiguities. Various connectionist models
for processing syntax and semantics of language text, as
well as for representing world knowledge, are reviewed.
A simulation of a neural network in C$sp0++$ illustrates
that hidden regularities in language can be captured in
a connectionist way.
Neither symbolic (traditional) AI techniques, nor
subsymbolic (neural network) techniques can claim to
solve all kinds of problems. Hybrid systems, combining
these techniques, will most likely become the NLP
systems of the future.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  2569 </NUMBER>
<ORDER>   AAI0665552 </ORDER>
<TITLE> THE APPLICATION OF NEURAL NETWORKS TO SALES FORECASTING: A MARKETING PERSPECTIVE </TITLE>
<AUTHOR> BREEDT, MARIUS FREDERICK </AUTHOR>
<YEAR> 1994 </YEAR>
<INSTITUTION> UNIVERSITY OF PRETORIA (SOUTH AFRICA); 6004 </INSTITUTION>
<DESCRIPTORS> BUSINESS ADMINISTRATION, MARKETING; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> G. PUTH; R. J. VAN EYDEN </ADVISER>
<CLASSIFICATIONS> NIL </CLASSIFICATIONS>
<ABSTRACT>
The purpose of this study is to illustrate the
application of neural networks to sales forecasting. As
sales forecasting lies at the heart of most company
planning and strategic decision making, it is often
crucial for sales managers to make accurate predictions.
In the light of this discipline, this study endeavoured
to compare the forecast results obtained from neural
networks with those recorded by multiple regression
analysis.
Two data sets were applied to the forecasting models in
which thirteen economically based inputs or independent
variables were included. The results secured from a
historical comparison between the two techniques
illustrated that neural networks was the superior
technique through recording substantially higher $Rsp2$
values over both data sets than did multiple regression
analysis. Therefore the empirical investigations of this
study regarding the technology of neural networks,
attested that this technology can be applied as a
forecasting method.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  2570 </NUMBER>
<ORDER>   AAIMM92930 </ORDER>
<TITLE> INDUCTIVE LEARNING IN NETWORK FAULT DIAGNOSIS </TITLE>
<AUTHOR> SHI, GUANG </AUTHOR>
<YEAR> 1994 </YEAR>
<INSTITUTION> CARLETON UNIVERSITY (CANADA); 0040 </INSTITUTION>
<DESCRIPTORS> ENGINEERING, ELECTRONICS AND ELECTRICAL; COMPUTER SCIENCE; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> BERNIE PAGUREK; NICK DAWES </ADVISER>
<CLASSIFICATIONS> NIL </CLASSIFICATIONS>
<ABSTRACT>
Machine learning is a study of computational methods for
acquiring knowledge and improving problem solving
ability. Among multiple machine learning techniques,
Inductive learning techniques have been widely studied
and applied into real world applications including the
network management domain. However, most inductive
learning algorithms have the general problem of
overfitting training examples, which makes the rules
generated from inductive learning algorithms less
reliable and accurate.
This thesis addresses the general overfitting problem
and applications of inductive learning techniques in
network fault diagnosis. Specifically, this thesis
presents the development of a new pruning algorithm
which can reduce the overfitting problem. As part of the
Pegasus fault diagnosis project, this thesis also
investigates the application of the CN2 rule induction
algorithm in the development of router normal traffic
patterns for the BNR wide area network.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  2571 </NUMBER>
<ORDER>   AAIMM92420 </ORDER>
<TITLE> AUTOMATED LEARNING OF MUSCLE BASED LOCOMOTION THROUGH CONTROL ABSTRACTION </TITLE>
<AUTHOR> GRZESZCZUK, RADEK </AUTHOR>
<YEAR> 1994 </YEAR>
<INSTITUTION> UNIVERSITY OF TORONTO (CANADA); 0779 </INSTITUTION>
<DESCRIPTORS> COMPUTER SCIENCE; ARTIFICIAL INTELLIGENCE; APPLIED MECHANICS </DESCRIPTORS>
<ADVISER> DEMETRI TERZOPOULOS </ADVISER>
<CLASSIFICATIONS> NIL </CLASSIFICATIONS>
<ABSTRACT>
We present a new technique that automatically
synthesizes realistic locomotion for the animation of
physically-based models of living creatures. The method
is suitable for highly deformable creatures such as
snakes and fish with many degrees of freedom and a
considerable number of internal muscle actuators. The
technique is a multilevel learning procedure which first
performs a global search for time-sampled actuator
activation functions that produce efficient locomotion.
The process then abstracts these low-level activation
functions into a highly compact representation. The
representation emphasizes the natural periodicities of
the derived muscle actions and makes explicit the
coordination among multiple muscles that has led to
effective locomotion. Finally, the synthetic creatures
can put into practice the compact, efficient controllers
that they have learned. The learning technique enables
them to accomplish higher-level tasks specified by the
animator and guided by simple sensory perception--for
example, locomote and execute turning maneuvers to reach
a visible target.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  2572 </NUMBER>
<ORDER>   AAIMM92248 </ORDER>
<TITLE> NEURAL NETWORKS FOR FORECASTING FOREIGN EXCHANGE RATES </TITLE>
<AUTHOR> DE MATOS, GIOVANI </AUTHOR>
<YEAR> 1994 </YEAR>
<INSTITUTION> THE UNIVERSITY OF MANITOBA (CANADA); 0303 </INSTITUTION>
<DESCRIPTORS> ECONOMICS, FINANCE </DESCRIPTORS>
<ADVISER> MILTON S. BOYD </ADVISER>
<CLASSIFICATIONS> NIL </CLASSIFICATIONS>
<ABSTRACT>
Recent research has shown that financial markets are
nonlinear, have memory, and can be modeled more
accurately with techniques other than the traditional
linear statistical methods. Neural networks are a
relatively new computer artificial intelligence method
that can be used for predicting nonlinear economic time
series. Neural networks are used to look for patterns in
training sets of data, learn these patterns, and then
classify new patterns and make forecasts.
Many different neural network models can be used for
predictive purposes. First, this study compared the
predictive power of the feedforward and the recurrent
backpropagation neural networks using monthly Japanese
yen futures prices. Results showed that feedforward
networks produced lower forecast errors. Both models
were able to out perform the simple naive model which
used only last month's price. Second, a feedforward
network daily trading was set up to forecast a technical
indicator for trading the Japanese yen futures market.
Results showed a $10.24 profit per day and 21.56 percent
profit per year over 14 years. This profitability
suggests some form of dependency in the data, which is
not recognized by traditional linear models. These
results are consistent with Levich and Thomas (1993),
who also found profits using a technical trading model
in currency markets.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  2573 </NUMBER>
<ORDER>   AAIMM92208 </ORDER>
<TITLE> FORECASTING FUTURES TRADING VOLUME USING NEURAL NETWORKS </TITLE>
<AUTHOR> KAASTRA, IEBELING </AUTHOR>
<YEAR> 1994 </YEAR>
<INSTITUTION> THE UNIVERSITY OF MANITOBA (CANADA); 0303 </INSTITUTION>
<DESCRIPTORS> ECONOMICS, AGRICULTURAL; ECONOMICS, FINANCE; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> MILTON S. BOYD </ADVISER>
<CLASSIFICATIONS> NIL </CLASSIFICATIONS>
<ABSTRACT>
Artificial neural networks are universal and highly
flexible function approximators first used in the fields
of cognitive science and engineering. In recent years,
neural network applications in finance for such tasks as
pattern recognition, classification, and time series
forecasting have dramatically increased. However, the
large number of parameters that must be selected to
develop a neural network forecasting model have meant
that the design process still involves much trial and
error.
Therefore, the objective of this study is to provide a
practical introductory guide in the design of a neural
network for forecasting economic time series data. An
eight-step procedure to design a neural network
forecasting model is explained. The design procedure is
then illustrated by developing backpropagation neural
network models to forecast monthly futures trading
volume for barley, canola, flax, oats, rye, and wheat
traded on the Winnipeg Commodity Exchange (WCE).
Comparisons of forecasting accuracy are made by
commodity and by forecast horizon.
The results indicate that the neural networks are able
to forecast up to nine months ahead and outperform the
naive model for all commodities except barley and rye.
The neural network forecasts relative to the naive model
currently in place to forecast futures trading volume do
not deteriorate as the forecast horizon increases. The
results suggest that improvements to the neural networks
could be made by matching the moving average length of
the inputs to the number of months forecasted ahead.
Twenty three out of the 54 networks used three hidden
neurons indicating that a small network can approximate
the function quite well.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  2574 </NUMBER>
<ORDER>   AAGC564688 </ORDER>
<TITLE> ARQUITECTURA NEURONAL NO SUPERVISADA PARA EL CONTROL DE UN ROBOT MOVIL EN ENTORNOS NO ESTACIONARIOS; UNSUPERVISED NEURAL ARCHITECTURE FOR THE CONTROL OF A MOBILE ROBOT IN NONSTATIONARY ENVIRONMENTS </TITLE>
<AUTHOR> ZALAMA CASANOVA, EDUARDO </AUTHOR>
<YEAR> 1994 </YEAR>
<INSTITUTION> UNIVERSIDAD DE VALLADOLID (SPAIN); 0713 </INSTITUTION>
<DESCRIPTORS> ENGINEERING, ELECTRONICS AND ELECTRICAL; ARTIFICIAL INTELLIGENCE UNIVERSIDAD DE  VALLADOLID, C/JUAN MAMBRILLA, 14 (CASA DE LOS ZUNIGA), E-47003  VALLADOLID, SPAIN </DESCRIPTORS>
<ADVISER> NIL </ADVISER>
<CLASSIFICATIONS> MACHINE LEARNING, VECTOR ASSOCIATIVE MAP </CLASSIFICATIONS>
<ABSTRACT>
This memory presents a real-time, unsupervised neural
network that learns to control a two-degree-of freedom
mobile robot in a non-stationary environment. The
proposed neural controller, combines associative
learning and Vector Associative Map (VAM) learning to
generate transformations between spatial and velocity
coordinates. As a result, the controller learns the
wheel velocities required to reach a target at an
arbitrary distance and angle. The transformations are
learned in an unsupervised training phase during which
the robot moves as a result of randomly selected wheel
velocities. The controller structure permits to
compensate noise and other forms of disturbance, such as
wheel slippage or changes in the robot's plant. The
controller is also able to adapt in response to long-
term changes in the robot's plant, such as change in the
radius of the wheels. The controller includes a module
that learns an internal odometric transformatiom,
allowing the robot to reach targets when visual input is
sporadic or unreliable. The architecture is extended to
include a module for reactive obstacle avoidance.
Obstacle avoidance is performed in a reactive manner by
representing the objects and targets in the robot's
environment as Gaussian functions. Performance of the
controller is presented in different situations: target
reaching, path following, adaptation to miss-
calibrations, wheel slippage, navigation without
exteroceptive information and obstacle avoidance.
Finally, it is shown preliminary results on the hardware
implementation of the neural controller with the mobile
robot ROBUTER.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  2575 </NUMBER>
<ORDER>   AAIC482374 </ORDER>
<TITLE> ON THE ANALYSIS OF PATTERN SEQUENCES BY SELF-ORGANIZING MAPS  </TITLE>
<AUTHOR> KANGAS, JARI ANTERO </AUTHOR>
<YEAR> 1994 </YEAR>
<INSTITUTION> TEKNILLINEN KORKEAKOULU (HELSINKI) (FINLAND); 5766 </INSTITUTION>
<DESCRIPTORS> COMPUTER SCIENCE; ARTIFICIAL INTELLIGENCE; SPEECH COMMUNICATION 1, FIN-02150 ESPOO, FINLAND </DESCRIPTORS>
<ADVISER> NIL </ADVISER>
<CLASSIFICATIONS> VOICE ANALYSIS, SPEECH RECOGNITION </CLASSIFICATIONS>
<ABSTRACT>
This thesis is organized in three parts. In the first
part, the Self-Organizing Map algorithm is introduced.
The discussion focuses on the analysis of the Self-
Organizing Map algorithm. It is shown that the nonlinear
nature of the algorithm makes it difficult to analyze
the algorithm except in some trivial cases.
In the second part the Self-Organizing Map algorithm is
applied to several pattern sequence analysis tasks. The
first application is a voice quality analysis system. It
is shown that the Self-Organizing Map algorithm can be
applied to voice analysis by providing a visualization
of certain deviations. The key point in the
applicability of Self-Organizing Map algorithm is
topological nature of the mapping; similar voice samples
are mapped to nearby locations in the map.
The second application is a speech recognition system.
Through several experiments it is demonstrated that by
collecting some time dependent features and using them
in conjunction with the basic Self-Organizing Map
algorithm one can improve speech recognition accuracy
considerably.
The applications explained in the second part of the
thesis were rather straightforward works where the
sequential signal itself was transformed for the
analysis. In the third part of the thesis it is
demonstrated that the Self-Organizing Map algorithm
itself could be extended by identifying each Map unit
with an arbitrary operator with capabilities for pattern
sequence processing. It is shown that the operator maps
are applicable for example to speech signal (waveform)
categorization.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  2576 </NUMBER>
<ORDER>   AAIMM91991 </ORDER>
<TITLE> PLANIFICATION DE TRAJECTOIRE D'UN MANIPULATEUR A L'AIDE DES RESEAUX NEURONIQUES ET DE LA LOGIQUE FLOUE: UNE APPLICATION A LA SAISIE D'UN OBJET MOBILE </TITLE>
<AUTHOR> PAYEUR, PIERRE </AUTHOR>
<YEAR> 1994 </YEAR>
<INSTITUTION> UNIVERSITE LAVAL (CANADA); 0726 </INSTITUTION>
<DESCRIPTORS> ENGINEERING, ELECTRONICS AND ELECTRICAL; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> HOANG LE-HUY; CLEMENT GOSSELIN </ADVISER>
<CLASSIFICATIONS> FRENCH TEXT </CLASSIFICATIONS>
<ABSTRACT>
Ce memoire presente une etude du potentiel des reseaux
de neurones et de la logique floue en tant que methodes
alternatives pour la planification de trajectoire d'un
manipulateur seriel plan a trois degres de liberte. Une
structure de reseaux neuroniques est proposee pour
l'anticipation de la position, de l'orientation, de la
vitesse et de l'acceleration d'un objet en mouvement. Un
algorithme de planification de trajectoire a base de
logique floue traitant aussi l'evitement de collisions
entre l'objet et les membres du robot est decrit en
details. Les concepts generaux servant a la
determination d'un point de saisie, a l'optimisation des
modules, ainsi qu'a la gestion de l'approche de l'objet
par l'organe terminal sont presentes. Enfin, les
resultats obtenus en simulation sont illustres et
analyses afin de conclure sur la robustesse et le
potentiel important des reseaux neuroniques et de la
logique floue dans le developpement d'algorithmes de
commande de haut niveau appliques a la robotique.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  2577 </NUMBER>
<ORDER>   AAIMM91979 </ORDER>
<TITLE> UNE APPROCHE DE SATISFACTION DE CONTRAINTES POUR LA MODELISATION DE PLANIFICATEURS INTELLIGENTS </TITLE>
<AUTHOR> PELLETIER, BRUNO </AUTHOR>
<YEAR> 1994 </YEAR>
<INSTITUTION> UNIVERSITE LAVAL (CANADA); 0726 </INSTITUTION>
<DESCRIPTORS> COMPUTER SCIENCE; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> BERNARD MOULIN </ADVISER>
<CLASSIFICATIONS> FRENCH TEXT </CLASSIFICATIONS>
<ABSTRACT>
L'objectif premier du projet etait d'explorer
differentes techniques pour realiser un systeme de
planification intelligent avec une approche multi-agents
capable de resoudre des problemes de gestion de temps et
de ressources physiques. Apres avoir etudie les
fondements de la programmation par contraintes, nous
avons propose un modele de representation de
connaissances temporelles en vue du developpement d'un
prototype de systeme de gestion de contraintes
temporelles. Nous avons aussi repertorie des methodes de
gestion des ressources physiques pour completer la liste
de nos instruments d'aide a la gestion. Ces outils sont
venus se greffer a un ensemble d'agents autonomes concu
pour le systeme de type planificateur. Trois points ont
ete explores durant la conception de l'architecture du
planificateur. Ce sont la mise en place d'une structure
de donnees pour definir une strategie d'utilisation des
agents, le developpement d'un mecanisme de coordination
entre agents et un protocole de communication entre ceux-
ci.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  2578 </NUMBER>
<ORDER>   AAIMM91973 </ORDER>
<TITLE> CONCEPTION D'UN SYSTEME EXPERT D'ANALYSE ECONOMIQUE ET FINANCIERE DE L'ENTREPRISE AGRICOLE </TITLE>
<AUTHOR> LECOURS, JEAN </AUTHOR>
<YEAR> 1994 </YEAR>
<INSTITUTION> UNIVERSITE LAVAL (CANADA); 0726 </INSTITUTION>
<DESCRIPTORS> ECONOMICS, AGRICULTURAL; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> RAYMOND LEVALLOIS </ADVISER>
<CLASSIFICATIONS> FRENCH TEXT </CLASSIFICATIONS>
<ABSTRACT>
Les programmes informatiques existant presentement
contribuent a un accroissement significatif du volume de
donnees enregistrees sur les fermes quebecoises sans
toutefois contribuer a l'aspect interpretatif de celle-
ci. Nous croyons que la venue des systemes experts
pourrait attenuer cette lacune des programmes
informatiques proceduraux sans toutefois les remplacer.
La connaissance des points forts et des faiblesses de
son entreprise, un jugement sur sa situation financiere
ainsi qu'une evaluation du degre de risque pourraient
aider les producteurs$sp*$ gestionnaires ainsi que ceux
qui les assistent dans leurs decisions. Le but de cette
etude est d'elaborer un systeme expert pour
l'interpretation des donnees au point de vue economique,
financier et du risque de l'entreprise agricole. Lors de
la validation, l'utilisation du systeme expert pour
l'analyse de 10 fermes a permis de relever 89% des
conclusions des experts pour ces memes fermes. ftn*Dans
ce document, le generique masculin est utilise sans
aucune discrimination et uniquement dans le but
d'alleger le texte.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  2579 </NUMBER>
<ORDER>   AAIMM91970 </ORDER>
<TITLE> ETUDE DE DIVERSES STRATEGIES DE COMMANDE MULTIVARIABLE BASEES SUR LES RESEAUX NEURONAUX </TITLE>
<AUTHOR> LAVOIE, GAETAN </AUTHOR>
<YEAR> 1994 </YEAR>
<INSTITUTION> UNIVERSITE LAVAL (CANADA); 0726 </INSTITUTION>
<DESCRIPTORS> ENGINEERING, CHEMICAL; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> JULES THIBAULT </ADVISER>
<CLASSIFICATIONS> FRENCH TEXT </CLASSIFICATIONS>
<ABSTRACT>
La commande automatique joue un role important dans la
production de biens utiles a la societe. Afin de
produire des biens de meilleure qualite et de repondre
aux nouvelles normes environnementales de plus en plus
severes, il est donc essentiel de developper de
nouvelles techniques de commande. Dans ce travail, on
propose des utilisations des reseaux de neurones a
retropropagation dans des strategies de commande
multivariable. Les reseaux de neurones serviront a
innover des strategies de regulation basees sur des
modeles lineaires classiques. Les strategies de controle
basees sur les reseaux de neurones sont le Regulateur
Neuronal Recursif avec (RNR-A) et sans adaptation (RNR),
le Regulateur Neuronal Inverse (RNI) et le Regulateur a
Modele Interne (RNMI). Ces techniques de regulation
seront comparees a des strategies largement utilisees en
industrie: les regulateurs PID et DMC.
La plupart des applications des reseaux de neurones
porte sur des procedes monovariables. Dans cet ouvrage,
ils modeliseront les comportements dynamiques direct et
inverse d'un procede multivariable a deux entrees et a
deux sorties. Nous etudierons les performances de ces
regulateurs sur des procedes lineaire et non lineaire a
l'aide de fonctions objectives.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  2580 </NUMBER>
<ORDER>   AAIMM91964 </ORDER>
<TITLE> IDENTIFICATION DES ENJEUX ENVIRONNEMENTAUX D'UN PROJET ROUTIER A L'AIDE D'UN SYSTEME A BASE DE CONNAISSANCES </TITLE>
<AUTHOR> LELIEVRE, MARTIN </AUTHOR>
<YEAR> 1994 </YEAR>
<INSTITUTION> UNIVERSITE LAVAL (CANADA); 0726 </INSTITUTION>
<DESCRIPTORS> ENGINEERING, CIVIL; ARTIFICIAL INTELLIGENCE; ENVIRONMENTAL SCIENCES </DESCRIPTORS>
<ADVISER> NIL </ADVISER>
<CLASSIFICATIONS> FRENCH TEXT </CLASSIFICATIONS>
<ABSTRACT>
La notion d'enjeux environnementaux des projets prend de
plus en plus d'importance de nos jours. A cet effet,
nous avons developpe un systeme a base de connaissances,
alliant la methode des reseaux cause-effet et l'analyse
multicritere. Applique a un projet routier, il permet
autant a des specialistes qu'au public profane d'etablir
les grands enjeux d'un projet.
L'evaluation des enjeux resulte de l'agregation de deux
notes finales, l'une exprimant l'evaluation experte et
l'autre, l'evaluation publique, en une seule note
globale pour chaque element du milieu.
D'un cote, l'evaluation experte simule le raisonnement
expert en evaluant les changements sur les elements du
milieu a partir d'actions portees sur l'environnement.
Cette evaluation est basee sur les deux principales
etapes de l'evaluation environnementale, soit
l'identification et l'evaluation. Dans un premier temps,
la premiere etape a pour but d'actualiser, pour une
etude de cas, un reseau cause-effet universel valide par
des experts. Pour les phases construction et
exploitation du projet, nous avons cree deux reseaux qui
permettent de distinguer les enjeux de repercussion
temporelle differente. Le reseau actualise permet de
relier les actions entreprises avec les composantes
biophysiques et socio-economiques du milieu concerne.
Tous les objets de ces reseux sont repartis en trois
classes et sont relies par un seul type de lien du genre
"l'objet pere affecte l'objet fils". L'intensite des
liens entre les elements varie dependamment du milieu
dans lequel le projet se situe; on distingue trois types
de milieu.
Ensuite, la deuxieme etape propage l'ampleur des actions
entreprises sur les elements du milieu pour exprimer, en
une note, le changement subi par chaque element. Cette
propagation s'effectue a partir de trois operations
d'agregation. (Abstract shortened by UMI.)
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  2581 </NUMBER>
<ORDER>   AAI9511157 </ORDER>
<TITLE> INTELLIGENT MACHINES AS HIERARCHICAL STOCHASTIC AUTOMATA </TITLE>
<AUTHOR> LIMA, PEDRO M. URBANO A. </AUTHOR>
<YEAR> 1994 </YEAR>
<INSTITUTION> RENSSELAER POLYTECHNIC INSTITUTE; 0185 </INSTITUTION>
<DESCRIPTORS> ENGINEERING, ELECTRONICS AND ELECTRICAL; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> GEORGE N. SARIDIS </ADVISER>
<CLASSIFICATIONS> NIL </CLASSIFICATIONS>
<ABSTRACT>
Most of the work done in the last few years by several
researchers towards building Autonomous Intelligent
Controllers quite often mentions the need for a
methodology of design and a measure of how successful
the final result is.
A new design methodology is introduced in this thesis
for improvement of performance of Intelligent
Controllers developed by the Analytic Theory of
Intelligent Machines proposed by Saridis. The
translation interfaces of a 3-level Hierarchical Goal-
Directed Intelligent Machine (HGDIM) are modeled by a 2-
stage Hierarchical Learning Stochastic Automaton (HLSA).
The HLSA is an original extension of the Generalized
Learning Stochastic Automaton (LSA) proposed by K. S. Fu
and his associates. The decision probabilities at the
two stages are recursively updated from the success and
failure signals received by the bottom stage whenever a
primitive algorithm of the HGDIM is applied to the
environment where the machine operates. Under this
learning scheme, the probability of selecting the
optimal tasks and primitive algorithms is proven to
converge to 1 with probability 1. An optimal action
(task or primitive algorithm) is defined as the action
which minimizes a cost function recursively updated
through feedback. This cost function of an action has
two terms: one is the cost of applying the action, and
the other is the complement of the reliability of the
action.
Other novel contributions of this work include a
coherent analytical measure of algorithm cost and
reliability, a new measure of performance for HGDIMs,
and an original Hierarchical Reinforcement Learning
Scheme for HLSAs, based on the bottom-up propagation of
the cost function.
Results of simulations show the application of the
methodologies to the Operations Management of a Glass
Furnace, and Intelligent Robotic Systems.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  2582 </NUMBER>
<ORDER>   AAI9510829 </ORDER>
<TITLE> PULMONARY NODULE DETECTION IN DIGITAL CHEST RADIOGRAPHY USING ARTIFICIAL NEURAL NETWORKS </TITLE>
<AUTHOR> GARG, SEEMA </AUTHOR>
<YEAR> 1994 </YEAR>
<INSTITUTION> DUKE UNIVERSITY; 0066 </INSTITUTION>
<DESCRIPTORS> ENGINEERING, BIOMEDICAL; HEALTH SCIENCES, RADIOLOGY; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> NIL </ADVISER>
<CLASSIFICATIONS> RADIOGRAPHY </CLASSIFICATIONS>
<ABSTRACT>
The detection of solitary pulmonary nodules on the chest
radiographic examination is an extremely important
diagnostic task. The detected nodule, if determined to
be malignant, is a primary indicator of asymptomatic
lung cancer. Because of the extremely complex background
of the radiograph and the similarity of nodules to other
anatomical features, pulmonary nodule detection is one
of the most difficult tasks that confront radiologists.
The development of a computational artificial neural
network-based diagnostic aid for radiologists for the
detection of pulmonary nodules was the focus of this
research.
The computational tool of artificial neural networks,
which loosely emulates the basic structure of biological
neural systems, has been successful in a variety of
pattern-recognition applications. In this research, two
neural network architectures, the single layer
perceptron and the multi-layer perceptron, were
investigated for the detection of pulmonary nodules in
digital chest radiographs. A systematic evaluation was
conducted of the networks' sensitivity to several
parameters including image resolution, nodule contrast,
size, and shape, and inter-patient variability. The
networks' detection performance was evaluated using
Receiver Operating Characteristic (ROC) analysis.
Network detection performance of a nodule in a Gaussian
noise background was compared to that of the ideal
observer from classical signal detection theory. Then,
the networks were evaluated on nodules superimposed on
patient radiographs. As a benchmark against which
network performance was measured, experienced human
observers (radiologists) were presented the same
detection task. Finally, localization of nodules, both
simulated and real, was implemented by "scanning" the
networks over the entire pulmonary region in patient
chest radiographs on a pixel-by-pixel basis.
Both the single layer and multi-layer networks performed
very well compared to the statistical ideal observer and
expert human observers. Network detection and
localization performance yielded high sensitivity (92%)
and specificity (5 false positives per image) in the
full lung region. The final product was developed as a
nodule-screening device. The input to the system was a
patient radiograph with suspected pulmonary nodules and
the network output indicated potential nodule sites.
Provided with candidate nodule locations, the
radiologist can make the final diagnostic decision.
Artificial neural networks show great promise as a
component of a computer-based pulmonary nodule detection
system for the aid of the radiologist.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  2583 </NUMBER>
<ORDER>   AAI9510791 </ORDER>
<TITLE> ADAPTIVE TRAFFIC CONTROL USING NEURAL NETWORKS </TITLE>
<AUTHOR> SARAF, RAJEEV KUMAR </AUTHOR>
<YEAR> 1994 </YEAR>
<INSTITUTION> VANDERBILT UNIVERSITY; 0242 </INSTITUTION>
<DESCRIPTORS> ENGINEERING, CIVIL; COMPUTER SCIENCE; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> MARK ABKOWITZ; DOUGLAS FISHER </ADVISER>
<CLASSIFICATIONS> TRAFFIC CONTROL </CLASSIFICATIONS>
<ABSTRACT>
Traffic flow is complex and dynamic. Even though
historical data indicates recurring patterns, cycle to
cycle variations are large enough to undermine the
efficacy of a pre-timed control. Therefore, systems that
recognize and adapt in real-time to traffic variations
are desirable. Neural networks have shown potential in
the area of adaptive control and pattern recognition by
learning the relationship between the environmental
inputs and output variables. These techniques can be
applied to traffic control. Once trained, neural
networks can automatically generate plans to meet
varying demand. This dissertation research explored the
feasibility of using neural networks for centralized
control and distributed control.
For the centralized traffic control system, neural
networks were trained to map traffic flow variables to
ideal control variable settings, i.e., cycle length,
phase lengths and offsets. TRANSYT-7F was used to
"train" networks by determining ideal control parameters
values for traffic conditions. Once trained, neural
networks predicted signal plans for unseen traffic
conditions.
For the distributed traffic control system, experiments
were carried out to evaluate the feasibility of neural
networks for making phase switching decisions for an
isolated intersection under the control of an actuated
controller. The neural network was trained to map the
relationship between the current intersection state and
the next signal state (i.e., terminate or continue with
the current phases) using Optimized Policies for
Adaptive Control (OPAC) as the trainer.
The performance of the trained neural network was
assessed by the values of the measures of effectiveness
(MOEs) that measured the impact of the control strategy
on the traffic operations. Experiments with various
neural network configurations suggest that the approach
is robust.
Extensive and systematic experiments with actual traffic
data demonstrated the feasibility of adaptive, on-line
traffic control with neural networks. In addition, this
dissertation research provides a framework and
methodology for evaluating alternative learning-based
traffic control systems.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  2584 </NUMBER>
<ORDER>   AAI9510683 </ORDER>
<TITLE> THE ROAD UTILIZATION LEARNING EXPERT SYSTEM </TITLE>
<AUTHOR> LISTOWSKY, PHILIP </AUTHOR>
<YEAR> 1994 </YEAR>
<INSTITUTION> CITY UNIVERSITY OF NEW YORK; 0046 </INSTITUTION>
<DESCRIPTORS> COMPUTER SCIENCE; ARTIFICIAL INTELLIGENCE; TRANSPORTATION </DESCRIPTORS>
<ADVISER> JERRY WAXMAN </ADVISER>
<CLASSIFICATIONS> RULES </CLASSIFICATIONS>
<ABSTRACT>
The major objective of this research is the description
of a process for the design and production of a computer
expert system which emulates the vehicle routing
decision making and expert knowledge processes of human
expert emergency service professionals. A project goal
is the production of a system which places this expert
knowledge at the disposal of non-expert emergency
services personnel. It is expected that this will
facilitate optimal emergency services personnel and
resource utilization by effectively allowing all
personnel to function as effectively as the expert
personnel. The knowledge-based, Road Utilization
Learning Expert System (RULES) determines the best route
to get from a starting location to a given destination
at different times and under varying conditions. Several
techniques are employed, including the production of
inference rules, the coding of a knowledge-base, and
applying heuristic solutions to a special routing
problem not soluble by ordinary algorithmic methods.
A rule-based system was formulated from knowledge of
significant factors that may influence path choices, and
expert considerations of how these factors interact with
each other. One source for this information was a survey
of professionals in the emergency services dispatching
field, conducted to determine critical factors
influencing route decisions. In addition to providing
raw data used in weighting factors which affect the
routing decision making process, the participants were
queried about their need for a system like RULES. These
survey results indicated that about 70% of emergency
services chiefs nationwide would trust a computer with
the task of dispatching their units. These respondents
also chose a computer system containing the knowledge of
all human experts in the department, as a method that
elicits the greatest confidence and trust. We have
designed a strategy for the gathering of knowledge and
the production of a rule-of-inference model from this
information. A description of techniques which have been
developed for the testing, operation, and maintenance of
this model are also presented. The long term
significance of the original methods created and
described here is in their providing a method for
producing expert systems which emulate the expert
decision making processes of human emergency services
experts.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  2585 </NUMBER>
<ORDER>   AAINN02230 </ORDER>
<TITLE> RESEAUX NEURONAUX OPTIQUES </TITLE>
<AUTHOR> BERGERON, ALAIN </AUTHOR>
<YEAR> 1994 </YEAR>
<INSTITUTION> UNIVERSITE LAVAL (CANADA); 0726 </INSTITUTION>
<DESCRIPTORS> PHYSICS, OPTICS; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> HENRI H. ARSEHAUT </ADVISER>
<CLASSIFICATIONS> FRENCH TEXT, ROBOTICS, NEURAL NETWORKS, ASSOCIATIVE MEMORY </CLASSIFICATIONS>
<ABSTRACT>
Cette recherche vise a la mise en oeuvre optique de
reseaux neuronaux. Deux architectures differentes sont
proposees. La premiere est la memoire associative
permettant d'associer a un objet quelconque une sortie
arbitraire tout en preservant l'information sur sa
position. La seconde architecture, le classificateur
neuronal pour le controle robotique, permet
l'identification d'une entree et son classement selon
differentes categories. La sortie est compatible avec
les systemes numeriques standard. Pour realiser ces
architectures, une approche modulaire est privilegiee.
Le correlateur constitue le module de base des
realisations. Differents modules sont de plus introduits
pour realiser convenablement les operations neuronales.
Le premier de ces modules est le seuil optoelectronique
permettant de realiser une fonction non lineaire,
element essentiel des reseaux neuronaux. Le second
module a etre introduit est l'encodeur optonumerique,
utile au classement des objets. Le probleme de
l'enregistrement de la memoire est aborde a l'aide du
codage iteratif global.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  2586 </NUMBER>
<ORDER>   AAI9510591 </ORDER>
<TITLE> DISCOURSE INTERPRETATION AND THE SCOPE OF OPERATORS </TITLE>
<AUTHOR> POESIO, MASSIMO </AUTHOR>
<YEAR> 1994 </YEAR>
<INSTITUTION> THE UNIVERSITY OF ROCHESTER; 0188 </INSTITUTION>
<DESCRIPTORS> COMPUTER SCIENCE; LANGUAGE, LINGUISTICS; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> LENHART K. SCHUBERT </ADVISER>
<CLASSIFICATIONS> CONTEXTUAL DEPENDENCY, AMBIGUITY </CLASSIFICATIONS>
<ABSTRACT>
The problem of ambiguity is central to any theory of
language interpretation, whether we are interested in
language processing in humans or in developing a usable
natural language processing system. Psycholinguistic
evidence suggests that human subjects are able to choose
an interpretation when necessary, and that competing
factors are involved in this choice; however, no theory
of language interpretation deals satisfactorily with the
combinatorial explosion paradox--the fact that no matter
how ambiguous natural language sentences are, they are
usually interpreted without significant effort.
The main idea presented in this dissertation is that the
scope preferences observed in the literature are not the
result of an independent 'scope disambiguation' module,
but of independent interpretation processes such as
definite description interpretation or the
interpretation of modals. None of these interpretive
procedures is especially concerned with 'scope
disambiguation,' but the result of these inferences is
that relations of contextual dependency such as
anaphoric reference or presuppositionality become part
of the common ground; the scope preferences observed in
the literature reflect these relations of dependency.
The dissertation includes a formal proposal concerning
the representation of contextual dependency, and its
impact on the semantics of sentence constituents.
My theory of ambiguity is based on a distinction between
semantic ambiguity, that can be captured implicitly, by
means of underspecified representations, and perceived
ambiguity, that results from the process of discourse
interpretation. My model of the common ground can be
used to characterize both situations characterized by
the presence of semantic ambiguity, and situations
characterized by the existence of perceived ambiguity.
The reasoning that leads to the establishment of scoping
preferences makes use, I argue, of information that is
pragmatic in nature; this calls for a model of discourse
interpretation in which the 'common ground' contains
such information. In the case of spoken language
conversations, the common ground must be a model of the
discourse situation of the conversational participants.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  2587 </NUMBER>
<ORDER>   AAI9510568 </ORDER>
<TITLE> UNSUPERVISED CLASSIFICATION LEARNING FROM CROSS-MODAL ENVIRONMENTAL STRUCTURE </TITLE>
<AUTHOR> DE SA, VIRGINIA RUTH </AUTHOR>
<YEAR> 1994 </YEAR>
<INSTITUTION> THE UNIVERSITY OF ROCHESTER; 0188 </INSTITUTION>
<DESCRIPTORS> COMPUTER SCIENCE; PSYCHOLOGY, DEVELOPMENTAL; PSYCHOLOGY, GENERAL; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> DANA H. BALLARD </ADVISER>
<CLASSIFICATIONS> NIL </CLASSIFICATIONS>
<ABSTRACT>
This dissertation addresses the problem of unsupervised
learning for pattern classification or category
learning. A model that is based on gross cortical
anatomy and implements biologically plausible
computations is developed and shown to have
classification power approaching that of a supervised
discriminant algorithm.
The advantage of supervised learning is that the final
error metric is available during training.
Unfortunately, when modeling human category learning, or
in constructing classifiers for autonomous robots, one
must deal with not having an omniscient entity labeling
all incoming sensory patterns. We show that we can
substitute for the labels by making use of structure
between the pattern distributions to different sensory
modalities. For example the co-occurrence of a visual
image of a cow with a "moo" sound can be used to
simultaneously develop appropriate visual features for
distinguishing the cow image and appropriate auditory
features for recognizing the moo.
We model human category learning as a process of
minimizing the disagreement between outputs of sensory
modalities processing temporally coincident patterns. We
relate this mathematically to the optimal goal of
minimizing the number of misclassifications in each
modality and apply the idea to derive an algorithm for
piecewise linear classifiers in which each network uses
the output of the other networks as a supervisory
signal.
Using the Peterson-Barney vowel dataset we show that the
algorithm finds appropriate placement for the
classification boundaries. The algorithm is then
demonstrated on the task of learning to recognize
acoustic and visual speech from images of lips and their
emanating sounds. Performance on these tasks is within 1-
7% of the related supervised algorithm (LVQ2.1).
Finally we compare the algorithm to Becker's IMAX
algorithm and give suggestions as to how the algorithm
may be implemented in the brain using physiological
results concerning the relationship between two types of
neural plasticity, LTP and LTD, observed in visual
cortical cells. We also show how the algorithm can be
used as an efficient method for dealing with learning
from data with missing values.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  2588 </NUMBER>
<ORDER>   AAI9510533 </ORDER>
<TITLE> INFORMATION EXTRACTION AS A BASIS FOR PORTABLE TEXT CLASSIFICATION SYSTEMS </TITLE>
<AUTHOR> RILOFF, ELLEN MICHELE </AUTHOR>
<YEAR> 1994 </YEAR>
<INSTITUTION> UNIVERSITY OF MASSACHUSETTS; 0118 </INSTITUTION>
<DESCRIPTORS> COMPUTER SCIENCE; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> WENDY G. LEHNERT </ADVISER>
<CLASSIFICATIONS> NIL </CLASSIFICATIONS>
<ABSTRACT>
Knowledge-based natural language processing systems have
achieved good success with many tasks, but they often
require many person-months of effort to build an
appropriate knowledge base. As a result, they are not
portable across domains. This knowledge-engineering
bottleneck must be addressed before knowledge-based
systems will be practical for real-world applications.
This dissertation addresses the knowledge-engineering
bottleneck for a natural language processing task called
"information extraction". A system called AutoSlog is
presented which automatically constructs dictionaries
for information extraction, given an appropriate
training corpus. In the domain of terrorism, AutoSlog
created a dictionary using a training corpus and five
person-hours of effort that achieved 98% of the
performance of a hand-crafted dictionary that took
approximately 1500 person-hours to build.
This dissertation also describes three algorithms that
use information extraction to support high-precision
text classification. As more information becomes
available on-line, intelligent information retrieval
will be crucial in order to navigate the information
highway efficiently and effectively. The approach
presented here represents a compromise between keyword-
based techniques and in-depth natural language
processing. The text classification algorithms classify
texts with high accuracy by using an underlying
information extraction system to represent linguistic
phrases and contexts. Experiments in the terrorism
domain suggest that increasing the amount of linguistic
context can improve performance. Both AutoSlog and the
text classification algorithms are evaluated in three
domains: terrorism, joint ventures, and
microelectronics. An important aspect of this
dissertation is that AutoSlog and the text
classification systems can be easily ported across
domains.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  2589 </NUMBER>
<ORDER>   AAI9510483 </ORDER>
<TITLE> FLEXIBILITY IN A KNOWLEDGE-BASED SYSTEM FOR SOLVING DYNAMIC RESOURCE-CONSTRAINED SCHEDULING PROBLEMS </TITLE>
<AUTHOR> HILDUM, DAVID WALDAU </AUTHOR>
<YEAR> 1994 </YEAR>
<INSTITUTION> UNIVERSITY OF MASSACHUSETTS; 0118 </INSTITUTION>
<DESCRIPTORS> COMPUTER SCIENCE; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> DANIEL D. CORKILL </ADVISER>
<CLASSIFICATIONS> NIL </CLASSIFICATIONS>
<ABSTRACT>
The resource-constrained scheduling problem (RCSP)
involves the assignment of a limited set of resources to
a collection of tasks, with the intent of satisfying
some particular qualitative objective, under a variety
of technological and temporal constraints. Real-world
environments, however, introduce a variety of
complications to the standard RCSP. The dynamic resource-
constrained scheduling problem describes a class of real-
world RCSPs that exist within the context of dynamic and
unpredictable environments, where the details of the
problem are often incomplete, and subject to change over
time, without notice.
Previous approaches to solving resource-constrained
scheduling problems failed to focus on the dynamic
nature of real-world environments. The scheduling
process occurs away from the environment in which the
resulting schedule is executed. Complete prior knowledge
of the order set is assumed, and reaction to changes in
the environment, if at all, is limited.
We have developed a generic, multi-faceted, knowledge-
based approach to solving dynamic resource-constrained
scheduling problems, which focuses on issues of
flexibility during the solution process to enable
effective reaction to dynamic environments. Our approach
is characterized by a highly opportunistic control
scheme that provides the ability to adapt quickly to
changes in the environment, a least-commitment
scheduling procedure that preserves maneuverability by
explicitly incorporating slack time into the developing
schedule, and the systematic consultation of a range of
relevant scheduling perspectives at key decision-making
points that provides an informed view of the current
state of problem-solving at all times.
The Dynamic Scheduling System (DSS) is a working
implementation of our scheduling approach, capable of
representing a wide range of dynamic RCSPs, and
producing quality schedules under a variety of real-
world conditions. It handles a number of additional
domain complexities, such as inter-order tasks and
mobile resources with significant travel requirements.
We discuss our scheduling approach and its application
to two different RCSP domains, and evaluate its
effectiveness in each, using special application systems
built with DSS.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  2590 </NUMBER>
<ORDER>   AAI9510452 </ORDER>
<TITLE> DOMAIN-SPECIFIC KNOWLEDGE ACQUISITION FOR CONCEPTUAL SENTENCE ANALYSIS  </TITLE>
<AUTHOR> CARDIE, CLAIRE </AUTHOR>
<YEAR> 1994 </YEAR>
<INSTITUTION> UNIVERSITY OF MASSACHUSETTS; 0118 </INSTITUTION>
<DESCRIPTORS> COMPUTER SCIENCE; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> WENDY G. LEHNERT </ADVISER>
<CLASSIFICATIONS> NATURAL LANGUAGE </CLASSIFICATIONS>
<ABSTRACT>
The availability of on-line corpora is rapidly changing
the field of natural language processing (NLP) from one
dominated by theoretical models of often very specific
linguistic phenomena to one guided by computational
models that simultaneously account for a wide variety of
phenomena that occur in real-world text. Thus far, among
the best-performing and most robust systems for reading
and summarizing large amounts of real-world text are
knowledge-based natural language systems. These systems
rely heavily on domain-specific, handcrafted knowledge
to handle the myriad syntactic, semantic, and pragmatic
ambiguities that pervade virtually all aspects of
sentence analysis. Not surprisingly, however, generating
this knowledge for new domains is time-consuming,
difficult, and error-prone, and requires the expertise
of computational linguists familiar with the underlying
NLP system. This thesis presents Kenmore, a general
framework for domain-specific knowledge acquisition for
conceptual sentence analysis. To ease the acquisition of
knowledge in new domains, Kenmore exploits an on-line
corpus using symbolic machine learning techniques and
robust sentence analysis while requiring only minimal
human intervention. Unlike most approaches to knowledge
acquisition for natural language systems, the framework
uniformly addresses a range of subproblems in sentence
analysis, each of which traditionally had required a
separate computational mechanism. The thesis presents
the results of using Kenmore with corpora from two real-
world domains (1) to perform part-of-speech tagging,
semantic feature tagging, and concept tagging of all
open-class words in the corpus; (2) to acquire
heuristics for part-of-speech disambiguation, semantic
feature disambiguation, and concept activation; and (3)
to find the antecedents of relative pronouns.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  2591 </NUMBER>
<ORDER>   AAI9510447 </ORDER>
<TITLE> RECURSIVE AUTOMATIC ALGORITHM SELECTION FOR INDUCTIVE LEARNING </TITLE>
<AUTHOR> BRODLEY, CARLA ELIZABETH </AUTHOR>
<YEAR> 1994 </YEAR>
<INSTITUTION> UNIVERSITY OF MASSACHUSETTS; 0118 </INSTITUTION>
<DESCRIPTORS> COMPUTER SCIENCE; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> PAUL E. UTGOFF </ADVISER>
<CLASSIFICATIONS> NIL </CLASSIFICATIONS>
<ABSTRACT>
The results of empirical comparisons of existing
learning algorithms illustrate that each algorithm has a
selective superiority; each is best for some but not all
tasks. Selective superiority arises because each
learning algorithm searches within a restricted
generalization space, defined by its representation
language, and employs a search bias for selecting a
generalization in that space. Given a data set, it is
often not clear beforehand which algorithm will yield
the best performance. The problem is complicated further
because for some learning tasks, different subtasks are
learned best using different algorithms. In such cases,
the ability to form a hybrid classifier that combines
different representation languages will produce a more
accurate classifier than employing a single
representation language and search bias.
This dissertation presents an approach to overcoming
this problem by applying knowledge about the biases of a
set of learning algorithms to conduct a recursive
automatic algorithm search. The approach permits
classifiers learned by the available algorithms to be
mixed in a recursive tree-structured hybrid, thereby
allowing different subproblems of the learning task to
be learned by different algorithms. The Model Class
Selection System (MCS), an implementation of the
approach, combines decision trees, linear discriminant
functions and instance-based classifiers in a tree-
structured hybrid classifier. Heuristic knowledge about
the characteristics that indicate one bias is better
than another is encoded in the rule base that guides
MCS's search for the best classifier. An empirical
evaluation illustrates that MCS achieves classification
accuracies equal to or higher than the best of its
primitive learning components for a variety of data
sets, demonstrating that domain-independent knowledge
about the biases of machine learning algorithms can
guide an automatic algorithm selection search.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  2592 </NUMBER>
<ORDER>   AAI9509711 </ORDER>
<TITLE> NEURAL NETWORK MODELING OF THE ROLE OF THE FRONTAL LOBES IN SEQUENCE CLASSIFICATION </TITLE>
<AUTHOR> BAPI, RAJU SURAMPUDI </AUTHOR>
<YEAR> 1994 </YEAR>
<INSTITUTION> THE UNIVERSITY OF TEXAS AT ARLINGTON; 2502 </INSTITUTION>
<DESCRIPTORS> COMPUTER SCIENCE; MATHEMATICS; PSYCHOLOGY, GENERAL; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> DANIEL S. LEVINE </ADVISER>
<CLASSIFICATIONS> NIL </CLASSIFICATIONS>
<ABSTRACT>
A neural network model of sequence learning and
classification is presented. The model is designed based
on an avalanche network and an ARTMAP module. The aim of
this model is to reproduce data showing that monkeys
with frontal lobe damage can learn an invariant sequence
of movements if it is rewarded, but cannot learn to
perform any one of several variations of a sequence if
all are rewarded. The network is built in three stages.
In the first two stages the avalanche module and a
sequence detector layer learn sequences, and in the
third stage the ARTMAP module classifies the sequences
based on reward. The network's behavior also reproduces
data showing that frontally damaged monkeys can perform
a flexible sequence task if they limit their performance
to some of the possible variations on the sequence.
Analogies are drawn between the classifier layer and the
frontal lobes, and between the avalanche module and part
of the basal ganglia.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  2593 </NUMBER>
<ORDER>   AAI9509620 </ORDER>
<TITLE> EXPLORATION-BASED DESIGN SYNTHESIS OF BEHAVIOR-BASED AUTONOMOUS ROBOTS  </TITLE>
<AUTHOR> ALI, MUHAMMAD MUAZZAM </AUTHOR>
<YEAR> 1994 </YEAR>
<INSTITUTION> COLORADO STATE UNIVERSITY; 0053 </INSTITUTION>
<DESCRIPTORS> ENGINEERING, MECHANICAL; BIOLOGY, ECOLOGY; ENGINEERING, SYSTEM SCIENCE; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> NIL </ADVISER>
<CLASSIFICATIONS> ROBOTICS </CLASSIFICATIONS>
<ABSTRACT>
Behavior-based robot control is a relatively new, but
accepted, concept for building autonomous robots.
Several different kinds of proof-of-concept robots using
the so-called subsumption architecture have been
demonstrated. These robots have been shown to solve some
fairly difficult tasks in unstructured and uncertain
domains. The initial results are very promising, but
much remains as to an underlying understanding for
designing and implementing behavior-based robot control.
Subsumption architecture utilizes a biological metaphor
to build autonomous robots and relies upon an
evolutionary-styled bottom up and incremental design
approach to incorporate biological-like robustness into
the robotic systems. This dissertation argues that
evolution is not an engineering design practice. As
such, a rational mapping between concept to
implementation is necessary to effectively design and
construct robust robots for real world applications.
Contrasted with subsumption architecture, an exploration-
based design synthesis approach is utilized in this
dissertation. This approach is principled, well-
practiced, and provides an inherently continuous process
of understanding how to transform the Behavior-Based
Robot Control concept into a systematic design
methodology. Practicality of this approach is being
verified by developing a control architecture for the
Mars Micro-Rover with the attributes of a Behavior-Based
robot.
Exploration-based design synthesis has far-reaching
implications when applied to the Behavior-Based Robot
Control domain working knowledge. An immediate benefit
is the ability to express this working knowledge
formally, which provides a means to better understand
and to address yet unknown areas of Behavior-Based Robot
Control such as the complexity of mediation mechanisms
or properties of emergent behaviors.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  2594 </NUMBER>
<ORDER>   AAINN01202 </ORDER>
<TITLE> LA GENERATION AUTOMATIQUE DE DESCRIPTIONS DE SYSTEMES DYNAMIQUES  </TITLE>
<AUTHOR> TOURIGNY, NICOLE </AUTHOR>
<YEAR> 1994 </YEAR>
<INSTITUTION> UNIVERSITE DE MONTREAL (CANADA); 0992 </INSTITUTION>
<DESCRIPTORS> COMPUTER SCIENCE; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> GUY LAPALME </ADVISER>
<CLASSIFICATIONS> FRENCH TEXT, ARTIFICIAL INTELLIGENCE </CLASSIFICATIONS>
<ABSTRACT>
Le travail presente dans cette these porte sur la
generation automatique de descriptions de systemes
dynamiques. Bien que plusieurs travaux aient deja ete
realises pour generer automatiquement des descriptions
de systemes, aucun ne traite de l'integration des
aspects statiques et dynamiques du systeme a resumer, ce
qui constitue justement notre principale contribution a
ce domaine de recherche.
Nous proposons une methode qui permet de produire
automatiquement des resumes de systemes dynamiques
modelises sous la forme de programmes. Lorsque les
seules sources d'information disponibles sont
constituees d'une trace et d'un programme, ce dernier
constitue le meilleur point de depart pour decrire un
systeme dynamique puisqu'il contient deja les modeles
des objets du systeme. Mais comme le programme ne
contient pas d'information sur l'execution des modeles,
nous proposons d'utiliser aussi la trace d'execution du
programme. Le programme fournit alors l'information
concernant les aspects statiques du comportement du
systeme tandis que la trace fournit celle concernant ses
aspects dynamiques. Le processus de generation est
realise en utilisant les schemas ainsi que la methode
que nous avons definis. Les resumes produits decrivent
les plans d'action des objets.
Notre approche est basee sur l'etude des systemes
dynamiques consideres comme des ensembles d'objets en
interaction et sur l'analyse de descriptions textuelles
de tels systemes. Apres avoir etudie les differents
modeles a la base du processus de description de
systemes dynamiques, nous avons defini un schema qui
permette de prendre en compte les aspects dynamiques du
systeme lors du processus de generation de descriptions.
Nous avons egalement examine comment les differentes
parties du schema peuvent etre linguistiquement
articulees. Apres avoir examine la production de
descriptions de systemes dynamiques, nous avons propose
une methode permettant de generer automatiquement ces
descriptions. Nous avons ensuite concu un generateur
base sur ces modeles el sur cette methode.
Afin de valider notre approche, nous avons implante un
generateur de descriptions de systemes dynamiques ecrit
en C-Prolog sur Macintosh. Il utilise en entree des
programmes rediges en DEMOS, une extension de Simula, et
il produit des descriptions en francais de l'evolution
du systeme dynamique.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  2595 </NUMBER>
<ORDER>   AAI9509618 </ORDER>
<TITLE> A GIS MULTI-CRITERIA EXPERT DECISION SUPPORT SYSTEM FOR WATER RESOURCES MANAGEMENT </TITLE>
<AUTHOR> ABU-ZEID, KHALED MAHMOUD </AUTHOR>
<YEAR> 1994 </YEAR>
<INSTITUTION> COLORADO STATE UNIVERSITY; 0053 </INSTITUTION>
<DESCRIPTORS> ENGINEERING, CIVIL; HYDROLOGY; ENGINEERING, SYSTEM SCIENCE; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> NIL </ADVISER>
<CLASSIFICATIONS> NIL </CLASSIFICATIONS>
<ABSTRACT>
This research documents how the engineering community
can effectively transfer their knowledge to enhance the
quality of water resources decision-making through the
use of computers. It shows that it is effective for
modern engineering technologists to actively participate
in the social and political processes. It also
demonstrates the use of new engineering technologies and
tools such as GIS, Expert Systems, and Decision Support
Systems, and their applicability to solving water
resources problems.
This dissertation presents a Decision Support System
developed to evaluate different cropping pattern
strategies used in the Eastern Nile Delta of Egypt. The
computer-based Decision Support System uses a
Geographical Information System to support the decision
making through visualization and multi-criteria
evaluation. A detailed logic for an Expert System was
developed to perform the decision making process based
upon information obtained from numerous experts involved
in the decision making process for water resources
management issues in the study area. An unbiased
procedure was implemented to give environmental,
ecological, economical, political, and social weights to
the experts and to their multi-criteria procedures for
evaluating water management strategies. A powerful user
friendly interface was developed to provide the
communication tool linking the decision maker's
interaction with the database, the Geographical
Information System, and the Expert System. The Decision
Support System enables the user to view the impacts on
different parameters, such as soil salinities and evapo-
transpiration, due to implementing a certain water use
strategy. The parameters are obtained from a simulation
model for irrigation and drainage in Egypt and are
stored in a database used by the Decision Support
System. A graphical user interface is provided for the
user to select between strategies and compare impacts of
different strategies on water usages and crop
production. The user can select to simultaneously view
more than one strategy on the computer screen for
comparison purposes. He can also view the short and long
term effects of a particular strategy on a parameter by
showing its distribution at successive time steps. The
Decision Support System is developed using PDC PROLOG as
a programming language, and it is coupled with IDRISI as
a Geographic Information System tool. Every effort has
been made to make it a user friendly tool for decision
makers.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  2596 </NUMBER>
<ORDER>   AAI9509534 </ORDER>
<TITLE> RELIABILITY MODELING AND ASSESSMENT OF REAL-TIME ARTIFICIAL INTELLIGENCE SYSTEMS </TITLE>
<AUTHOR> TSAO, DAVID TA-WEI </AUTHOR>
<YEAR> 1994 </YEAR>
<INSTITUTION> THE UNIVERSITY OF MISSISSIPPI; 0131 </INSTITUTION>
<DESCRIPTORS> COMPUTER SCIENCE; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> ING-RAY CHEN </ADVISER>
<CLASSIFICATIONS> NIL </CLASSIFICATIONS>
<ABSTRACT>
The research goal of this work is to develop and
demonstrate the applicability of a reliability theory
for assessing the reliability of real-time AI systems,
such as those embedded in process-control environments
where an AI program is used for formulating control
decisions in response to external sensor stimuli. Two
complementary approaches are investigated for achieving
this research goal, namely, macroscopic modeling based
on testing; and microscopic modeling based on
mathematical and simulation techniques, with the former
requiring a working or prototype system to be
implemented first, while the latter not requiring a
working system a priori but requiring knowledge of the
system design details.
Under macroscopic modeling, we develop a reliability
theory to assess the reliability of systems which are
susceptible to fuzzy (not completely acceptable) but not
necessarily catastrophic control decisions such as AI
systems. Five possible fuzzy-failure criteria under
which a system is considered as having failed are
discussed and a closed-form solution for the system
reliability is derived for each case. This generalized
reliability theory is then extended to consider real-
time AI systems for which not only fuzzy-failures but
also deadline-violation failures are possible. Two macro
models, namely, a time-based model and a mission-based
model, are derived, with the former giving the system
reliability as a function of execution time, and the
latter giving the system reliability as a function of
the number of missions encountered by the system during
its lifetime. The success of these two macro models are
tested with a simulated robot system and a simulated
multicriteria aircraft routing system with which the
methodologies for collecting failure data from testing
for assessing system reliability are illustrated. Under
microscopic modeling, this work presents a methodology
based on hierarchical modeling with simulation and Petri
net techniques to predict the reliability of real-time
expert systems.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  2597 </NUMBER>
<ORDER>   AAI9509498 </ORDER>
<TITLE> DYNAMIC ACROSS TIME AUTONOMOUS - SENSING, INTERPRETATION, MODEL LEARNING AND MAINTENANCE THEORY </TITLE>
<AUTHOR> MAHAJAN, AJAY MOHAN </AUTHOR>
<YEAR> 1994 </YEAR>
<INSTITUTION> TULANE UNIVERSITY; 0235 </INSTITUTION>
<DESCRIPTORS> ENGINEERING, MECHANICAL; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> J. F. FIGUEROA </ADVISER>
<CLASSIFICATIONS> AUTONOMOUS SENSOR, ROBOTICS </CLASSIFICATIONS>
<ABSTRACT>
A formal theory for the development of a generic model
of an autonomous sensor is proposed and implemented. An
autonomous sensor not only interprets the acquired data
in accordance with an embedded expert system knowledge
base but also uses it to modify and enhance the
knowledge base. The main objective of the model is to
combine the capabilities of the physical sensor and an
expert operator monitoring the sensor in real-time. This
gives the sensor the capabilities of not only sensing
the measurand, but also interpreting the sensed data at
a higher human-like level, maintaining its databases
over time to account for bad or incomplete data, and
learning about the measurand and sensor behaviors. The
sensor's data base is defined as the quantitative data
it senses as well as the qualitative data it interprets.
Its knowledge base is defined as the rules that allow
maintenance of the truth and integrity of the system and
methodologies for model learning. Relevant aspects of
the system are described by properties and their
qualitative measure called states. A set of properties
and their state values define a concept, and a set of
consecutively occurring concepts, over time, describe
behaviors that essentially provide a qualitative view of
the different possible states of the system. These
behaviors and associated concepts, called envisionments,
are used to identify the measurand and sensor behaviors
in real-time so as to take appropriate countermeasures
for those behaviors that cause problems. The
identification process is called interpretation and is
similar to the pattern recognition problem. Dynamic
Across Time Autonomous - Sensing, Interpretation, Model
Learning And Maintenance Theory (DATA-SIMLAMT) is a
novel theory in the field of robotics and artificial
intelligence that attempts to model computer reasoning
on human-like reasoning about system behaviors. It finds
applications in any field that incorporates the human in
the control system. Autonomous sensing is just one
application of this theory.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  2598 </NUMBER>
<ORDER>   AAI9509357 </ORDER>
<TITLE> INTELLIGENT COMPUTATIONS APPLIED TO POWER SYSTEM SECURITY </TITLE>
<AUTHOR> HUANG, SHYH-JIER </AUTHOR>
<YEAR> 1994 </YEAR>
<INSTITUTION> UNIVERSITY OF WASHINGTON; 0250 </INSTITUTION>
<DESCRIPTORS> ENGINEERING, ELECTRONICS AND ELECTRICAL; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> MOHAMED A. EL-SHARKAWI </ADVISER>
<CLASSIFICATIONS> NIL </CLASSIFICATIONS>
<ABSTRACT>
Three intelligent approaches for solving power system
security problems are proposed in this dissertation. The
first of these approaches is based on multi-layered
perceptrons and genetic algorithms. It helps prevent
learning stagnation, avoid trapping in a local minimum,
and reduce the training time. The second approach is to
integrate Kohonen self-organizing feature maps with
genetic algorithms. The genetic algorithm is applied in
order to decide the initial weights in the Kohonen
classifiers. The competitive learning is then performed
to fine tune the privileged weight vector of the
selected neuron. This method is beneficial in avoiding
the problem of getting trapped in isolated regions which
denies the formulation of adequate clusters. Therefore,
learning performance can be highly improved. The third
proposed approach is the application of query-based
learning to enhance the neural network classification
performance. The inversion of neural networks is applied
to find the boundary points. The contour gradients are
then computed along the boundary surface. The conjugated
points are generated along the contour. These points are
screened by the oracle, and then combined with the
existing training patterns to refine the classification
boundary. This method is very beneficial when the
training data is insufficient or the data acquisition
process is difficult to perform.
The proposed approaches are applied to the power system
security problems. For each proposed method, both static
and dynamic security are explored. These intelligent
approaches investigate the nonlinear relationships
between power system operating environments and their
security status. The computation procedures of the
proposed methodologies are described in detail. The
proposed approaches are validated through simulations of
utility data and standard test systems.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  2599 </NUMBER>
<ORDER>   AAI9509315 </ORDER>
<TITLE> FUZZY ADAPTIVE INFERENCE IN NEURAL NETWORKS AND SEARCH </TITLE>
<AUTHOR> ARABSHAHI, PAYMAN </AUTHOR>
<YEAR> 1994 </YEAR>
<INSTITUTION> UNIVERSITY OF WASHINGTON; 0250 </INSTITUTION>
<DESCRIPTORS> ENGINEERING, ELECTRONICS AND ELECTRICAL; COMPUTER SCIENCE; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> ROBERT J. MARKS, II </ADVISER>
<CLASSIFICATIONS> NIL </CLASSIFICATIONS>
<ABSTRACT>
With the aim of improving performance, we use fuzzy
control to quantify the heuristics used in different
nonlinear optimization algorithms and classification
procedures commonly used to train neural networks. Under
the assumption that the underlying error surface is in
some sense smooth, for the case of the backpropagation
and random search algorithms, this results in remarkably
accelerated convergence. In the hierarchical ART 1
network, we are able to adaptively classify the data
space into a predetermined number of classes.
We also consider here the problem of improving the
performance of the fuzzy controller itself. A new
technique for adaptation of fuzzy membership functions
and aggregation operators in a fuzzy inference system is
proposed. The technique relies upon the isolation of the
specific membership function that contributed to the
final decision, followed by the updating of this
function's parameters using steepest descent. The error
measure used is thus back propagated from output to
input, through the min and max operators used during the
inference stage. This is feasible because the operations
of min and max are continuous differentiable functions
and therefore can be placed in a chain of partial
derivatives for steepest descent adaptation.
The process of adaptation itself can reveal
overdetermination of the fuzzy system in two ways.
First, if two membership functions come sufficiently
close to each other, they can be fused into a single
membership function. Second, if a membership function
becomes too narrow, it can be deleted. In both cases,
the number of If-Then rules is reduced. In certain
cases, the overall performance of the fuzzy system can
be improved by this adaptive pruning.
In Part 2 of this dissertation we show that the Fourier
transform of the linear output of a single hidden layer
perceptron consists of a multitude of line masses
passing through the origin. Each line corresponds to one
of the hidden neurons and its slope is determined by
that neuron's weight vector. We also show that
convolving the output of the network with a function can
be achieved simply by modifying the shape of the
sigmoidal nonlinearities in the hidden layer. Examples
of such filtering operations are presented and
discussed.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  2600 </NUMBER>
<ORDER>   AAI9509138 </ORDER>
<TITLE> A KNOWLEDGE-BASED APPROACH TO DERIVING LOGICAL STRUCTURE FROM DOCUMENT IMAGES </TITLE>
<AUTHOR> NIYOGI, DEBASHISH </AUTHOR>
<YEAR> 1994 </YEAR>
<INSTITUTION> STATE UNIVERSITY OF NEW YORK AT BUFFALO; 0656 </INSTITUTION>
<DESCRIPTORS> COMPUTER SCIENCE; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> SARGUR N. SRIHARI </ADVISER>
<CLASSIFICATIONS> NIL </CLASSIFICATIONS>
<ABSTRACT>
An important application of artificial intelligence is
document image understanding, specifically the analysis
of document images to derive a symbolic description of
the document structure and contents. This requires the
segmentation of the different blocks of printed matter
using standard image processing techniques, and the use
of spatial domain knowledge to first classify these
blocks (e.g., text paragraphs, photographs, etc.), then
group these blocks into logical units (e.g., newspaper
stories, magazine articles, etc.), and finally determine
the reading order of the text blocks within each logical
unit. The above steps describe the problem of converting
the physical structure of the document into its logical
structure with the use of domain knowledge about
document layout. The objective of this work is to
develop a computational model for the derivation of the
logical structure of documents using certain formalisms
designed for this task. In this model, a simple yet
powerful rule-based control strategy utilizes the data
obtained from the invocation of different types of
operations on a digitized document image, and makes
inferences about the document using a knowledge base of
document layout rules. The domain knowledge about
document structure is represented in a unified multi-
level hierarchical form, and is used by reasoning
processes to make inferences. The main issues
investigated in this research are: the kinds of domain
and control knowledge that are required, how to
represent this knowledge in a globally integrated form,
and how to devise a control strategy that efficiently
utilizes this knowledge. A knowledge-based document
logical structure derivation system (DeLoS) has been
developed based on this model. The system consists of a
hierarchical rule-based control system that guides the
block classification, block grouping and read-ordering
operations; a global data structure that stores the
document image data and incremental inferences; and a
domain knowledge base that encodes the rules governing
document layout. Applications of this approach include
use in digital libraries for the retrieval of relevant
logical document information, as well as in
comprehensive document understanding systems that can
read document text and allow interactive querying of the
syntactic and semantic information in a document.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  2601 </NUMBER>
<ORDER>   AAI9509126 </ORDER>
<TITLE> A COMPUTATIONAL MODEL OF COLOR PERCEPTION AND COLOR NAMING </TITLE>
<AUTHOR> LAMMENS, JOHAN MAURICE GISELE </AUTHOR>
<YEAR> 1994 </YEAR>
<INSTITUTION> STATE UNIVERSITY OF NEW YORK AT BUFFALO; 0656 </INSTITUTION>
<DESCRIPTORS> COMPUTER SCIENCE; ENGINEERING, ELECTRONICS AND ELECTRICAL; PSYCHOLOGY, PHYSIOLOGICAL; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> STUART C. SHAPIRO </ADVISER>
<CLASSIFICATIONS> NIL </CLASSIFICATIONS>
<ABSTRACT>
I define a computational model of color perception and
color naming which is based in part on
neurophysiological data and which can explain results in
psychological, anthropological, and linguistic studies
on color naming and categorization. In particular, the
model explains the graded nature and foci of color
categories. This model constitutes a semantic model of
basic color terms, grounded in perception. It allows an
artificial cognitive agent to name color samples, point
out examples of named colors in its environment, and
select objects from its environment by color, consistent
with human performance on the same tasks. An algorithm
and implementation for the computational model is
presented, and evaluated theoretically and
experimentally.
The contributions of this work are in autonomous agent
architecture on the one hand, particularly in the area
of symbol grounding and embodiment, and in perceptual
modeling, particularly color vision, on the other hand.
The application presented is a vertically integrated
one, ranging from real visual input to symbolic
description, and back.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  2602 </NUMBER>
<ORDER>   AAI9509117 </ORDER>
<TITLE> SEMANTICS OF SUBSET-LOGIC LANGUAGES </TITLE>
<AUTHOR> JANA, DEVASHIS </AUTHOR>
<YEAR> 1994 </YEAR>
<INSTITUTION> STATE UNIVERSITY OF NEW YORK AT BUFFALO; 0656 </INSTITUTION>
<DESCRIPTORS> COMPUTER SCIENCE; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> BHARAT JAYARAMAN </ADVISER>
<CLASSIFICATIONS> LOGIC PROGRAMMING </CLASSIFICATIONS>
<ABSTRACT>
This dissertation examines the semantics of a new
paradigm of logic programming called subset-logic
programming. The most novel construct of a subset-logic
program is the subset assertion, which in conjuction
with the more conventional relational and equational
assertions provide a declarative alternative to many
common uses of Prolog's extra-logical features: cut,
assert, retract, setof, and mode declarations. These
three forms effectively allow to specify function and
relation definitions involving (finite) sets as first-
class data objects.
Our study of the semantics of subset-logic languages
begins by laying the logical foundations for these
languages. Because of the need for new set constructors
in representing finite sets, we first axiomatize their
meaning through suitable axioms, and then use these
axioms in a variety of ways: (i) to show that the set
constructors indeed behave like finite sets; (ii) to
provide a framework for establishing the correctness of
set-unification: (iii) to define a Herbrand structure;
and (iv) to provide a basis for discussing logical-
consequence semantics for the subset-logic languages.
The semantics of subset-logic languages are then studied
in two stages: The first stage has only equality and
subset program clauses. Here we show that their
declarative semantics can be expressed in terms of
logical consequence, and their operational semantics in
terms of set-matching and a modification of SLD
resolution. We then establish the soundness and
completeness of the declarative and operational
semantics through fixpoint semantics. We further give an
enhancement of this semantics that additionally handles
database programs with incomplete information in a sound
but incomplete manner. In the second stage, we also
include relations, and examine logical-consequence
semantics. On the operational side, we use set-
unification with resolution.
The contribution of this dissertation is that we have
provided rigorous foundations for incorporating finite
sets into logic programming. Using this foundation, we
have shown that semantics for the initial levels of the
subset-logic languages can be given through the
logically impeccable means of logical-consequence
semantics.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  2603 </NUMBER>
<ORDER>   AAI9508886 </ORDER>
<TITLE> OPTIMIZED CODE GENERATION FOR PROGRAMMABLE DIGITAL SIGNAL PROCESSORS </TITLE>
<AUTHOR> YU, JIM KIN HUNG </AUTHOR>
<YEAR> 1994 </YEAR>
<INSTITUTION> THE UNIVERSITY OF WISCONSIN - MADISON; 0262 </INSTITUTION>
<DESCRIPTORS> ENGINEERING, ELECTRONICS AND ELECTRICAL; COMPUTER SCIENCE </DESCRIPTORS>
<ADVISER> YU-HEN HU </ADVISER>
<CLASSIFICATIONS> NIL </CLASSIFICATIONS>
<ABSTRACT>
In this dissertation, we present a novel approach for
optimized code generation for Programmable Digital
Signal Processors (PDSP) using artificial intelligence
techniques. Our code generator, named OASIS, combines
Template Pattern Matching with Means-Ends Analysis,
Hierarchical Planning, expert system and heuristic
search, to mimic the reasoning and planning processes
used by human assembly programmers.
An important advantage of this framework is that it can
easily support context-dependent algorithm
transformations (CDAT). Unlike static optimizations,
CDAT can guarantee to improve the quality of the
generated code, at the expense of longer computational
time.
Optimal code generation is known to be an NP-Complete
problem. However, we do not limit OASIS' potential. We
parameterize the algorithm on two variables, the search
depth K and the search breadth B. We demonstrate that
the proposed algorithm can execute in polynomial time to
the size of the input program and exponential only to K.
This approach allows great flexibility to the algorithm.
By varying K and B, the user can match the quality of
the generated code with the available computational
resources. We also present a procedure for automatically
obtaining the best code that the computational system
can generate.
We present several case studies using a simplified
architecture and instruction set based on the
TMS3202x/C5x. Empirical results show that very good
results can be accomplished with depths as small as 3.
For many embedded DSP applications, hand coding in
assembly is still the only effective approach. We show
that OASIS can yield code of quality comparable to that
of hand-written codes by DSP experts and many times
superior to that generated by a conventional optimizing
compiler.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  2604 </NUMBER>
<ORDER>   AAI9508632 </ORDER>
<TITLE> DESIGN OF A CONTROL ARCHITECTURE FOR RE-ENTRANT FLOW SHOPS </TITLE>
<AUTHOR> GHARPURE, JAGANNATH T. </AUTHOR>
<YEAR> 1994 </YEAR>
<INSTITUTION> OKLAHOMA STATE UNIVERSITY; 0664 </INSTITUTION>
<DESCRIPTORS> ENGINEERING, INDUSTRIAL; OPERATIONS RESEARCH; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> JOE H. MIZE </ADVISER>
<CLASSIFICATIONS> NIL </CLASSIFICATIONS>
<ABSTRACT>
Scope and method of study. This research effort was
directed at conceptualizing and designing a
comprehensive architecture for control of re-entrant
flow shops. In a re-entrant flow shop the parts revisit
work centers several times. The production targets for
different part types are to be achieved as closely as
possible while maintaining good performance with respect
to other measures of merit. The developed architecture
is hybrid as it combines ideas from the fields of
operations research and Artificial Intelligence. The re-
entrant flow shop to be controlled was modeled using the
Object Oriented paradigm. The controllers exerted
control on the simulated re-entrant flow shop. Different
features of the control architecture were studied for
their role in control in the context of different types
of complexity factors. The developed architecture was
used to control an example re-entrant flow shop cited in
the literature.
Findings and conclusions. Different structural
complexity factors and complexity due to randomness were
identified. These complexity factors complicate the task
of control. Two critical control factors were
identified, viz. the time period of periodic action
(TPOFPA) and the communication strategy (COMSTGY). After
every TPOFPA certain periodic actions are carried out.
The COMSTGY can be two way or one way. In two way
strategy the plant controller and the work center
controller communicate with each other. In one way
strategy only the plant controller sends commands to the
work center controller. Several experiments were carried
out in 5 x 2 x 3 factorial arrangement in a Completely
Randomized Design. It was found that the control factors
play an important role in control in the context of
increasing complexity levels. Specifically it was found
that the two way communication strategy functions better
than one way at all levels and types of complexity and
at all levels of TPOFPA. Further, for a given COMSTGY as
the TPOFPA increases the performance deteriorates.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  2605 </NUMBER>
<ORDER>   AAI9607131 </ORDER>
<TITLE> MODELING AND PREDICTION OF THERMALLY INDUCED ERRORS IN MACHINE TOOLS USING A LASER BALL BAR AND A NEURAL NETWORK </TITLE>
<AUTHOR> SRINIVASA, NARAYAN </AUTHOR>
<YEAR> 1994 </YEAR>
<INSTITUTION> UNIVERSITY OF FLORIDA; 0070 </INSTITUTION>
<DESCRIPTORS> ENGINEERING, MECHANICAL; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> JOHN C. ZIEGERT </ADVISER>
<CLASSIFICATIONS> NIL </CLASSIFICATIONS>
<ABSTRACT>
Thermally induced errors are major contributors to the
overall accuracy of machine tools. While this area is
well researched, a major drawback of currently proposed
methods is the amount of time consumed in building this
model. Due to this drawback, there has been a reluctance
in the industrial community to adopt these techniques.
In this study, a direct method of machine tool
calibration is adopted. Rather than individually
measuring the parametric errors of the machine tool over
a thermal duty cycle to build the error model of the
machine, the total positional errors at the cutting tool
are rapidly measured using the laser ball bar. The
measured errors are correlated with temperature
gradients of the various heat sources in an on-line
fashion by a neural network using pattern recognition
principles. The methodology is implemented on a two axis
computerized numerical control turning center. The
neural network builds the error model of the machine
tool using training data collected over a thermal duty
cycle.
The predicting ability of the network was further tested
using random thermal duty cycles. A PC based system was
used to compensate for the errors predicted by the
neural network. The performance of the system was also
evaluated through cutting tests under various thermal
conditions. A substantial improvement in the overall
accuracy of the turning center was obtained.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  2606 </NUMBER>
<ORDER>   AAI9507854 </ORDER>
<TITLE> ON INTEGRATING INDUCTIVE LEARNING WITH PRIOR KNOWLEDGE AND REASONING </TITLE>
<AUTHOR> GIRAUD-CARRIER, CHRISTOPHE G. </AUTHOR>
<YEAR> 1994 </YEAR>
<INSTITUTION> BRIGHAM YOUNG UNIVERSITY; 0022 </INSTITUTION>
<DESCRIPTORS> COMPUTER SCIENCE; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> TONY R. MARTINEZ </ADVISER>
<CLASSIFICATIONS> NIL </CLASSIFICATIONS>
<ABSTRACT>
Learning and reasoning are both aspects of what is
considered to be intelligence. Their studies within AI
have been separated historically, learning being the
topic of neural networks and machine learning, and
reasoning falling under classical (or symbolic) AI.
However, learning and reasoning share many
interdependencies, and the integration of the two may
lead to more powerful models. This dissertation examines
some of these interdependencies and describes several
models, culminating with a system called FLARE
(Framework for Learning And REasoning). The proposed
models integrate inductive learning with prior knowledge
and reasoning. Learning is incremental, prior knowledge
is given by a teacher or deductively obtained by
instantiating commonsense knowledge, and reasoning is
non-monotonic. Simulation results on several datasets
and classical commonsense protocols demonstrate promise.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  2607 </NUMBER>
<ORDER>   AAI9505497 </ORDER>
<TITLE> IMPLEMENTATION OF NEURAL NETWORKS WITH INTEGER ARITHMETIC </TITLE>
<AUTHOR> FISHER, MARK RICHARD </AUTHOR>
<YEAR> 1994 </YEAR>
<INSTITUTION> THE UNIVERSITY OF TEXAS AT ARLINGTON; 2502 </INSTITUTION>
<DESCRIPTORS> ENGINEERING, MECHANICAL; COMPUTER SCIENCE; ENGINEERING, ELECTRONICS AND ELECTRICAL; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> ROBERT L. WOODS </ADVISER>
<CLASSIFICATIONS> NIL </CLASSIFICATIONS>
<ABSTRACT>
The subject of this dissertation is the increase of
computational speed of trained neural networks that are
programmed on a microcomputer or microprocessor. This
increased speed allows complex neural networks to run in
real time and to use inexpensive computers for control.
The method uses only integer addition and
multiplication. All other mathematical operations are
eliminated by using table lookup, which gives less
programming steps, faster execution, and less processor
capability requirements. As a result, trained neural
networks can be installed on an inexpensive eight-bit
chip, and give acceptable accuracy.
A brief review of the concepts of conventional neural
networks is presented. A discussion of the learning rate
constants for successful training is given. The increase
in computational speed gained by this method is shown.
Even with eight-bit integer math, the degradation in
control accuracy from 32 bit floating point math is
shown to be less than one percent. Two examples of
integer neural networks are presented for real time
control of gear shifting and hill angle computation on a
hybrid electric vehicle. Software of these examples are
given. The examples performed successfully in a real
time dynamic simulation of the vehicle.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  2608 </NUMBER>
<ORDER>   AAINN92164 </ORDER>
<TITLE> MODELLING LOCOMOTOR PATTERN GENERATION USING ARTIFICIAL NEURAL NETWORKS </TITLE>
<AUTHOR> BROWN, CALVIN JAMES </AUTHOR>
<YEAR> 1994 </YEAR>
<INSTITUTION> THE UNIVERSITY OF MANITOBA (CANADA); 0303 </INSTITUTION>
<DESCRIPTORS> COMPUTER SCIENCE; ARTIFICIAL INTELLIGENCE; BIOLOGY, NEUROSCIENCE </DESCRIPTORS>
<ADVISER> DAVID SCUSE </ADVISER>
<CLASSIFICATIONS> NIL </CLASSIFICATIONS>
<ABSTRACT>
The detailed formation of the motor output patterns used
to produce locomotion in mammals has been found to be
generated primarily by neural circuitry housed in the
spinal cord. The problem of determining the organization
of the system of spinal neurons responsible for this,
the locomotor pattern generator (LPG), is a difficult
one. To provide some additional insight into how the LPG
could be functionally organized, a new conceptual LPG
model was designed. Given that computational modelling
is recognized as a useful tool in the exploration of
complex systems and that artificial and biological
neural networks have numerous characteristics in common,
a computational version of the LPG model was designed
and developed using artificial neural network (ANN)
techniques. To enhance the exploration of the LPG's
behaviour, a software model of a muscle pair was also
developed and incorporated into the ANN LPG model.
The LPG and the muscle-pair models were then run under a
variety of circumstances to demonstrate the behaviour of
the conceptual model. The results show how the LPG model
is able to qualitatively imitate features of its
biological counterpart in situations analogous to
"normal" locomotion in which it is both influencing and
reacting to the muscle pair, to "fictive" locomotion
during which the influence of the muscle pair is
disabled, and to "entrained" locomotion in which
externally forced oscillation of the muscles affects the
LPG. The results also suggest new organizational and
behavioral characteristics that LPG's might possess and
serve to demonstrate how useful ANN technology can be in
modelling actual biological systems.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  2609 </NUMBER>
<ORDER>   AAINN92158 </ORDER>
<TITLE> COMPUTER SIMULATION AND OPTIMIZATION FOR ECONOMIC RAW MATERIAL SELECTION </TITLE>
<AUTHOR> CHEN, RUILIN </AUTHOR>
<YEAR> 1994 </YEAR>
<INSTITUTION> THE UNIVERSITY OF MANITOBA (CANADA); 0303 </INSTITUTION>
<DESCRIPTORS> ENGINEERING, INDUSTRIAL; BUSINESS ADMINISTRATION, MANAGEMENT; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> D. STRONG; O. HAWALESHKA </ADVISER>
<CLASSIFICATIONS> NIL </CLASSIFICATIONS>
<ABSTRACT>
This dissertation concentrates on a sole subject--
economic raw material selection techniques for
engineering manufacturers. To approach the problem of
economic raw material selection, a generalized economic
model for raw material selection is proposed. A
realistic example is presented and some significant
variables and relationships are investigated.
Afterwards, an analytical method is followed to give a
series of mathematical equations for determining the
optimal material quality level. Certain serious
limitations are pointed out regarding practical
application of this approach. To overcome the
difficulty, a computer simulation model integrated with
two optimization techniques is provided to identify the
optimum raw material properties for the particular case.
Two system modeling approaches are developed to simulate
costs incurred during material purchasing, impact of
manufacturing processes and impact of product quality in
order to select the most suitable raw material and
supplier available for the particular application.
Finally, an Abductive Network Method--an "expert system"
type of approach--is used for the raw material selection
problem with "fuzzy" inputs. This research is based on a
realistic example in order to indicate its practical
usefulness.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  2610 </NUMBER>
<ORDER>   AAINN91963 </ORDER>
<TITLE> RECONNAISSANCE INVARIANTE DES FORMES AVEC LE FILTRE DE FOURIER-MELLIN ET UN RESEAU NEURONIQUE </TITLE>
<AUTHOR> LEJEUNE, CLAUDE </AUTHOR>
<YEAR> 1994 </YEAR>
<INSTITUTION> UNIVERSITE LAVAL (CANADA); 0726 </INSTITUTION>
<DESCRIPTORS> PHYSICS, OPTICS; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> YUNLONG SHENG; HENRI H. ARSENAULT </ADVISER>
<CLASSIFICATIONS> FRENCH TEXT </CLASSIFICATIONS>
<ABSTRACT>
Le filtre de Fourier-Mellin est applique a un ensemble
d'objets pour generer des vecteurs invariants sous
translation, rotation et changement d'echelle. C'est la
premiere methode permettant d'obtenir ces trois
invariants simultanement. Le calcul des vecteurs
invariants est fait numeriquement et optiquement. Les
vecteurs ainsi obtenus sont utilises comme entrees dans
un reseau neuronique backpropagation pour faire la
classification des prototypes qui lui sont presentes.
Les dimensions des vecteurs invariants sont tres petites
par rapport aux objets d'entree et permettent d'utiliser
un reseau possedant un nombre restreint de connexions.
Il devient possible d'entrai ner le reseau dans des
temps relativement courts sur un ordinateur du type PC.
Une fois le reseau entrai ne, nous lui presentons des
vecteurs invariants provenant d'objets se retrouvant
dans l'ensemble d'entrai nement mais ayant subi des
rotations et des changements d'echelle. Ce nouveau
groupe represente l'ensemble de rappel. La performance
de la methode est tres bonne avec des taux de succes
superieurs a 85%.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  2611 </NUMBER>
<ORDER>   AAI9510968 </ORDER>
<TITLE> AN EMPIRICAL INVESTIGATION OF THE EFFECT OF VARIATIONS IN EXPERT SYSTEM EXPLANATION PRESENTATION ON USERS' ACQUISITION OF EXPERTISE AND PERCEPTIONS OF THE SYSTEM </TITLE>
<AUTHOR> EVERETT, ANDRE MICHAEL </AUTHOR>
<YEAR> 1994 </YEAR>
<INSTITUTION> THE UNIVERSITY OF NEBRASKA - LINCOLN; 0138 </INSTITUTION>
<DESCRIPTORS> INFORMATION SCIENCE; COMPUTER SCIENCE; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> SANG M. LEE </ADVISER>
<CLASSIFICATIONS> NIL </CLASSIFICATIONS>
<ABSTRACT>
Expertise constitutes the foundation of an
organization's ability to benefit from competitive and
comparative advantage. Expert systems are the principal
form of technology promising enhanced propagation of
expertise, yet have been accused of fostering its
extinction. The critical feature distinguishing expert
systems from other computer-based information systems is
their potential to furnish explanations.
Prior studies demonstrated that explanations enhance
user confidence in expert system recommendations,
discovering that explanation presentation affects user
acquisition of several forms of domain knowledge. This
study extends prior findings by integrating earlier
results within a proposed framework for expert system
explanations, the core of which was empirically tested
and confirmed. The framework establishes a link among
explanation content and intended function.
Relationships among explanation content, presentation
format, acquisition of expertise, invocation mode, and
various user perceptions regarding the system and
explanations were hypothesized. A simulated expert
system interface, with variations in explanation
features, was written to conduct a controlled experiment
employing 260 student subjects. The problem task was
product/process matching, within the domain of
manufacturing strategy.
The principal content/function associations stipulated
in the framework were confirmed: Facts content promotes
clarification, trace content promotes duplication, and
justification content promotes ratification.
The critical importance of justification explanations
was highlighted through numerous significant findings.
The impact of the presence or absence of justification
explanations was pervasive, spreading to measures that
were not affected by this feature, such as ease of use.
Most subject perceptual measures were strongly linked to
this one characteristic, indicating that user acceptance
of an expert system may hinge on the presence of
justification explanations. Differences were also found
between optional and automatic invocation of
explanations, indicating that even a single keystroke
for invocation may affect a user's decision to view an
explanation, and thereby indirectly affect their
perceptions of the system's adequacy.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  2612 </NUMBER>
<ORDER>   AAI9508602 </ORDER>
<TITLE> COGNITION AND LEARNING: THE IMPLICATIONS OF A SITUATED CONNECTIONIST PERSPECTIVE FOR THEORY AND PRACTICE IN EDUCATION </TITLE>
<AUTHOR> ST. JULIEN, JOHN A. </AUTHOR>
<YEAR> 1994 </YEAR>
<INSTITUTION> THE LOUISIANA STATE UNIVERSITY AND AGRICULTURAL AND MECHANICAL COL.; 0107 </INSTITUTION>
<DESCRIPTORS> EDUCATION, CURRICULUM AND INSTRUCTION; EDUCATION, PSYCHOLOGY; EDUCATION, SOCIOLOGY OF </DESCRIPTORS>
<ADVISER> JAMES ANTHONY WHITSON; WILLIAM DOLL </ADVISER>
<CLASSIFICATIONS> NIL </CLASSIFICATIONS>
<ABSTRACT>
In this dissertation I attempt to construct a framework
for an alternate theory of instruction, starting from
the position that education has no theory of learning;
instead, what passes for theories of learning are
actually descriptions of the conditions under which
knowledge is acquired. Descriptive theorizing does not
serve education well because it is not likely, being a
description of what is known told in terms of assumed
categories, to be generative or adaptive.
I question the naturalness of current assumptions about
thought and learning by tracing the consolidation of the
present discursive formation around a presumed unity of
logic, language, and causality based on the forms of
geometry. A crucial move in that consolidation was
Descartes' formulation of thought as essentially
logical. As our culture deals with the contradictions
inherent in this formulation, new disciplines of
knowledge arise. Most interestingly for education, the
new disciplines of cognitive science and artificial
intelligence have pushed the idea that humans are
"computers," that we reason by calculation, to the
breaking point. It has become increasingly obvious that
humans cannot think according to the forms of logic and
connectionist theories which propose alternate images of
mind are gaining ascendance.
The implications for education are large. I extensively
explore the implications of connectionist modeling for a
distinctively educational model of learning. These
connectionist theories substitute a shifting and
uncertain web of associations for the solid storage
metaphor common to most educational theorizing and
methods. The stability which can no longer be located in
the sovereign self must instead be found in the world
and in the socially-based practices that constitute both
the world and the individual. Situated cognition,
pragmatists, and poststructural sociologists are
explored to understand the new constellation surrounding
learning. A short exploratory study, based on the
principles that emerged from the study, of an alternate
way to teach categories is experimentally explored and
found successful. This work was extended to a computer-
based implementation which allowed theoretical ideas
concerning time and activity to be explored. Includes a
Macintosh disk.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  2613 </NUMBER>
<ORDER>   AAINN92298 </ORDER>
<TITLE> NEURAL NETWORKS VERSUS TIME SERIES MODELS FOR FORECASTING COMMODITY PRICES </TITLE>
<AUTHOR> KOHZADI, NOWROUZ </AUTHOR>
<YEAR> 1994 </YEAR>
<INSTITUTION> THE UNIVERSITY OF MANITOBA (CANADA); 0303 </INSTITUTION>
<DESCRIPTORS> ECONOMICS, AGRICULTURAL; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> MILTON S. BOYD </ADVISER>
<CLASSIFICATIONS> NIL </CLASSIFICATIONS>
<ABSTRACT>
Neutral networks were originally developed in cognitive
science to study the function of the brain. They have
been shown to be universal and highly flexible
approximators which do not necessarily require
restrictive error term assumptions needed for parametric
approaches such as the Box-Jenkins ARIMA models. Neural
networks have been widely used in engineering and
computer science for classification and pattern
recognition and began to become more popular around 1985
when the method of backpropagation was introduced by the
PDP group.
The objective of this study was to compare traditional
ARIMA time series models with neural networks to see
which can produce the superior forecast. The properties
and behavior of the data are first examined and it is
tested for nonlinear and chaotic behavior, using monthly
US cattle prices from 1973-1990. Grassberger and
Procaccia, BDS, and Hurst exponent tests are used to
test for nonlinear and chaotic behavior. The results
showed no such behavior. Therefore, linear models such
as ARIMA models appear to be suitable for modelling
cattle prices. But neural networks may have an advantage
over linear ARIMA models because they do not require
differencing and they also are less sensitive to
violations of error term assumptions.
Forecasts were examined for errors and for the correct
turning point prediction, in order to evaluate buying
and selling signals. Results of neural network models
showed that they were able to successfully forecast
prices out of sample with considerably more accuracy
than ARIMA models.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  2614 </NUMBER>
<ORDER>   AAG9508721 </ORDER>
<TITLE> DESIGN AND SYNTHESIS OF METAL FORMING PROCESSES </TITLE>
<AUTHOR> ALI, AMER FAISAL </AUTHOR>
<YEAR> 1994 </YEAR>
<INSTITUTION> OHIO UNIVERSITY; 0167 </INSTITUTION>
<DESCRIPTORS> ENGINEERING, MECHANICAL </DESCRIPTORS>
<ADVISER> JAY S. GUNASEKERA </ADVISER>
<CLASSIFICATIONS> ROLLING, EXTRUSION </CLASSIFICATIONS>
<ABSTRACT>
In this globally competitive environment it is
imperative to devise new manufacturing methods that are
cost effective and continually seek to improve the
existing manufacturing techniques. Computer-aided-design
(CAD), computer-aided-manufacturing (CAM), and computer-
aided-engineering tools have been harnessed in the
previous decade to analyze manufacturing processes. The
availability of computing power has also increased
dramatically which allows more computer intensive
operations. However, most of the CAD/CAM/CAE tools are
built around iterative "input-analysis-input"
techniques. This methodology is cumbersome and time
consuming, especially if the analysis problem is quite
large.
The primary focus of this dissertation is on the
development of design methodologies in metal forming and
manufacturing. The methodologies presented are generic
and may be applied to a number of processes. The
implementation of numerous tools gives these
methodologies their versatility and effectiveness. The
selection of a methodology for a particular operation
depends on the task at hand. The design methodologies
presented include: (1) Hierarchial Design Methodology;
(2) Intelligent Hybrid System; (3) Taguchi and Axiomatic
Design Process; (4) Property Based Design.
This hierarchial design methodology is time and cost
effective because it provides a systematic means of
achieving an optimum process design by limiting the
design space in successive, orderly steps. Conceptual
design using the axiomatic design principle is used to
identify important parameters. Preliminary designs
consisting of simplified tools are employed to develop
an initial design. As the design space is narrowed more
accurate finite element methods are used to analyze the
process.
The second approach further improves the hierarchial
design concepts and is performed by artificial
intelligence tools. The artificial intelligence approach
to metal forming processes demonstrates the use of an
intelligent hybrid tool to design and control the pack
rolling process which is presented as an example. This
intelligent harnesses the power of two AI tools--the
expert system and the neural network approach.
A new experimental design methodology is presented which
is particularly effective if the analytical solution is
not available or the process is too complex to model. In
this situation, carefully controlled experiments are
employed to provide the understanding of the process and
to establish a design criteria for control of the
process. This methodology employs the axiomatic design
approach combined with the Taguchi design method to
generate a conceptual design. This methodology works
very effectively with any experimental technique and has
extremely high merits if used for design of a relatively
new process.
A novel property based design approach is presented
which will have tremendous impact on the metal forming
community. The objective of this methodology is to
design the process based on the desired properties of
the final product. This methodology brings a higher
level of scientific approach into the design process.
The property based methodology is developed and
demonstrated for the extrusion process. A new extrusion
die design is presented based on controlling the Zener-
Holloman parameter which yields a uniform microstructure
along any section of the extrusion. Moreover, this
approach reduces the scatter of the grain size along the
cross-section and also achieves the desired crystallized
grains at each section of the extrudate.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  2615 </NUMBER>
<ORDER>   AAI9607077 </ORDER>
<TITLE> NEURAL NETWORKS FOR SIGNAL AND INFORMATION PROCESSING </TITLE>
<AUTHOR> HSU, HUI-HUANG </AUTHOR>
<YEAR> 1994 </YEAR>
<INSTITUTION> UNIVERSITY OF FLORIDA; 0070 </INSTITUTION>
<DESCRIPTORS> ENGINEERING, ELECTRONICS AND ELECTRICAL; COMPUTER SCIENCE; ENGINEERING, BIOMEDICAL; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> LIMIN FU </ADVISER>
<CLASSIFICATIONS> EXPERT SYSTEMS </CLASSIFICATIONS>
<ABSTRACT>
One way to improve the capability of the neural network
is to incorporate human knowledge. Knowledge-based
neural networks can utilize both the knowledge from
human experts and the knowledge inherent in the data.
Neural networks mapped from a set of production rules
are referred to as rule-based neural networks. Fuzziness
and context are two distinct aspects of the knowledge of
human experts. However, previous research on rule-based
neural networks did not consider these two important
aspects. Thus, a fuzzification layer is proposed to be
added to the rule-based neural network for encoding the
fuzziness of continuous input variables. The
fuzzification layer can be superimposed onto any back-
propagation networks. Moreover, a neural model with an
adaptive memory structure follows the rule-based neural
network in order to perform context processing. The
adaptive memory is an extension of the gamma model (a
neural model for temporal processing) for learning both
the right and left contexts. A hybrid information
processing system is constructed based on the above-
mentioned neural models, and is evaluated on the
electroencephalogram (EEG) sleep staging problem.
Different experiments are designed to test the system.
Compared with the previous results on the same sleep
records, the present results demonstrate the following
advantages. First, knowledge-based neural networks out-
perform both symbolic knowledge-based systems and
traditional neural networks. Secondly, fuzzy encoding of
continuous data gives better performance than crispy
data representation. Thirdly, context processing
effectively enhances the results of information
processing. The developed system is promising for sleep
staging, but the design principles are generally
applicable.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  2616 </NUMBER>
<ORDER>   AAG9507711 </ORDER>
<TITLE> A STUDY OF DISTANCE-BASED MACHINE LEARNING ALGORITHMS </TITLE>
<AUTHOR> WETTSCHERECK, DIETRICH </AUTHOR>
<YEAR> 1994 </YEAR>
<INSTITUTION> OREGON STATE UNIVERSITY; 0172 </INSTITUTION>
<DESCRIPTORS> COMPUTER SCIENCE; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> THOMAS G. DIETTERICH </ADVISER>
<CLASSIFICATIONS> NIL </CLASSIFICATIONS>
<ABSTRACT>
Distance-based algorithms are machine learning
algorithms that classify queries by computing distances
between these queries and a number of internally stored
exemplars. Exemplars that are closest to the query have
the largest influence on the classification assigned to
the query. Two specific distance-based algorithms, the
nearest neighbor algorithm and the nearest-
hyperrectangle algorithm, are studied in detail.
It is shown that the k-nearest neighbor algorithm (kNN)
outperforms the first nearest neighbor algorithm only
under certain conditions. Data sets must contain
moderate amounts of noise. Training examples from the
different classes must belong to clusters that allow an
increase in the value of k without reaching into
clusters of other classes. Methods for choosing the
value of k for kNN are investigated. It shown that one-
fold cross-validation on a restricted number of values
for k suffices for best performance. It is also shown
that for best performance the votes of the k-nearest
neighbors of a query should be weighted in inverse
proportion to their distances from the query.
Principal component analysis is shown to reduce the
number of relevant dimensions substantially in several
domains. Two methods for learning feature weights for a
weighted Euclidean distance metric are proposed. These
methods improve the performance of kNN and NN in a
variety of domains.
The nearest-hyperrectangle algorithm (NGE) is found to
give predictions that are substantially inferior to
those given by kNN in a variety of domains. Experiments
performed to understand this inferior performance led to
the discovery of several improvements to NGE. Foremost
of these is BNGE, a batch algorithm that avoids
construction of overlapping hyperrectangles from
different classes. Although it is generally superior to
NGE, BNGE is still significantly inferior to kNN in a
variety of domains. Hence, a hybrid algorithm (KBNGE),
that uses BNGE in parts of the input space that can be
represented by a single hyperrectangle and kNN
otherwise, is introduced.
The primary contributions of this dissertation are (a)
several improvements to existing distance-based
algorithms, (b) several new distance-based algorithms,
and (c) an experimentally supported understanding of the
conditions under which various distance-based algorithms
are likely to give good performance.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  2617 </NUMBER>
<ORDER>   AAG9507450 </ORDER>
<TITLE> A NON-CONTACT INTELLIGENT SYSTEM FOR MEASURING THE DIMENSIONS OF HOT-FORGED PARTS </TITLE>
<AUTHOR> TANG, TING-WEN </AUTHOR>
<YEAR> 1994 </YEAR>
<INSTITUTION> UNIVERSITY OF MISSOURI - ROLLA; 0135 </INSTITUTION>
<DESCRIPTORS> ENGINEERING, ELECTRONICS AND ELECTRICAL; ENGINEERING, INDUSTRIAL; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> KOTI NYAMEKYE </ADVISER>
<CLASSIFICATIONS> NIL </CLASSIFICATIONS>
<ABSTRACT>
Historically the hot-forging industry has suffered from
high production costs due to a high defect rate. Current
inspection methods are not capable of measuring hot
parts which have just emerged from a forging process.
Therefore inspection can only proceed after a 30-minute
cooling period. As a result, hundreds of parts produced
during that period have to be scrapped once a defect is
found. As higher accuracy is demanded, the number of
scrapped parts increases. A project is conducted here to
implement a real-time inspection system by using vision
devices and computer assistance. Research efforts are
divided into two phases. In the first phase, the
hardware layout of the system is designed, inspection
and measurement methodologies are studied, accuracy of
the vision system is optimized and fundamental software
is developed. In this phase, inspection is driven
manually by operators. A new measurement methodology is
developed, and various edge-locating methods such as
edge detection, thinning and approximation are studied
and applied to help operators locate correct dimensions.
Intelligent feedback is implemented to correct possible
locating errors. The impact of camera-object alignment
is also discussed thoroughly. The first phase of
research is reported in this dissertation. The second
phase, not included in this dissertation, will follow
after completion of phase one research. In the second
phase, thermal contraction will be studied and the
system will be designed to conduct inspection
automatically.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  2618 </NUMBER>
<ORDER>   AAG9507449 </ORDER>
<TITLE> GENETIC NEURO-NESTER </TITLE>
<AUTHOR> POSHYANONDA, PIPATPONG </AUTHOR>
<YEAR> 1994 </YEAR>
<INSTITUTION> UNIVERSITY OF MISSOURI - ROLLA; 0135 </INSTITUTION>
<DESCRIPTORS> ENGINEERING, INDUSTRIAL; OPERATIONS RESEARCH; COMPUTER SCIENCE; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> C. H. DAGLI </ADVISER>
<CLASSIFICATIONS> STOCK CUTTING </CLASSIFICATIONS>
<ABSTRACT>
In this study, the integration of artificial neural
networks and genetic algorithms is explored as a
solution approach for the problem of uncured composite
stock cutting, which is NP-complete. Patterns used can
be either rectangular or irregular and the approach
proposed can accommodate any orientation and size
restrictions to be imposed. A genetic algorithm is used
to generate sequences of the input patterns to be
allocated. Each gene represents the sequence of the
pattern allocation used by the allocation algorithm
developed. The scrap percentage of each allocation is
used as an evaluation criterion for each gene in
determining the best allocation while considering
successive generations. The allocation algorithm uses
the sliding method integrated with an artificial neural
network, based on the Adaptive Resonance Theory (ART1)
paradigm, to allocate the patterns according to the
sequence generated by the genetic algorithm. The results
obtained by the approach gives packing densities in the
order of 75 to 95 percent.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  2619 </NUMBER>
<ORDER>   AAG9507446 </ORDER>
<TITLE> AN INTELLIGENT GROUP DECISION SUPPORT SYSTEM FOR LOCATING MANUFACTURING FACILITIES </TITLE>
<AUTHOR> CHI, SHENG-CHAI </AUTHOR>
<YEAR> 1994 </YEAR>
<INSTITUTION> UNIVERSITY OF MISSOURI - ROLLA; 0135 </INSTITUTION>
<DESCRIPTORS> OPERATIONS RESEARCH; BUSINESS ADMINISTRATION, MANAGEMENT; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> C. O. BENJAMIN; C. A. RIORDAN </ADVISER>
<CLASSIFICATIONS> DECISION SUPPORT SYSTEM </CLASSIFICATIONS>
<ABSTRACT>
The research efforts in this dissertation addresses the
need of a sophisticated group decision-making approach
for location selection. To meet this need, an
intelligent group decision support system (GDSS)
prototype was created and its performance in assisting
small groups of decision makers in selecting the best
state for locating a new manufacturing facility was
evaluated.
The GDSS prototype system combines artificial
intelligence (AI) techniques, operations research (OR)
methods, and database management systems into a
synergistic decision-making framework to solve the
facility location problem. An artificial neural network
technique is applied to identify a small subset of best
locations from location database. An expert system (ES)
model coupled with fuzzy scalar measures is utilized to
check the degree of group consensus. An interactive
computer communication feature using the C programming
language supports group discussion to arrive at a final
decision.
Evaluation of the GDSS prototype used technical
evaluation, subjective evaluation by individual users,
and an empirical study comparing decision-making
performance of groups using and not using an intelligent
GDSS groups. The results showed that the GDSS prototype
performed well in both the quality and outcome of the
group decision-making process. Further work is
recommended to do field test of the system with decision-
makers in industry.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  2620 </NUMBER>
<ORDER>   AAG9507444 </ORDER>
<TITLE> THE APPLICATION OF MARKOV STATE PROBABILITIES IN DEVELOPING ARTIFICIALLY INTELLIGENT MANAGERIAL STRATEGIES: A CASE STUDY BASED ON MAJOR LEAGUE BASEBALL </TITLE>
<AUTHOR> ARCONATI, ARNOLD VINCENT </AUTHOR>
<YEAR> 1994 </YEAR>
<INSTITUTION> UNIVERSITY OF MISSOURI - ROLLA; 0135 </INSTITUTION>
<DESCRIPTORS> OPERATIONS RESEARCH; COMPUTER SCIENCE; BUSINESS ADMINISTRATION, MANAGEMENT; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> YILDIRIM OMURTAG; JERRY R. BAYLESS </ADVISER>
<CLASSIFICATIONS> BASEBALL </CLASSIFICATIONS>
<ABSTRACT>
Baseball is a very large industry that influences the
lives and financial assets of millions of people.
Many baseball analysts estimate that even the best Major
League player can increase his team's expected number of
yearly wins by only 3 or 4 games. In 1993 Bobby Bonilla,
a New York Mets National League outfielder, earned
$5,200,000 more than the average Major League player
earned. The Mets apparently believed that expenditure of
this money was worth his expected additional victories.
If the strategy of an Artificially Intelligent baseball
manager could produce 4 more team victories than the
corresponding human baseball manager, would this
artificial expert also be worth $5,200,000 per year?
Baseball, like many other processes, transitions from
state to state until it terminates in either a win or a
loss state. Each intermediate state has an associated
probability of win, PW. For instance, the home team's PW
might be 0.350 for the state--losing by two runs during
the bottom of the 3rd inning, with one out and a runner
on 1st base.
Human managers frequently have no concept of a given
state's proper PW. But this paper develops a computer
simulation model that estimates the PW for each of the
9072 states that comprise this Major League baseball
process. Consequently, it devises representative
strategies to artificially steer the process into a
winning terminal state. Since the specific path to any
given state is irrelevant, the sport of baseball is
defined as a Markov process.
This paper is more than a treatise about baseball. It
employs the relatively concise and clear baseball
process as a guide to help any industry develop
successful processes by artificially selecting the next
discretionary Markov State.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  2621 </NUMBER>
<ORDER>   AAG9507015 </ORDER>
<TITLE> APPLICATIONS OF NEURAL NETWORKS TO PARTIAL DIFFERENTIAL EQUATIONS </TITLE>
<AUTHOR> MCGEE, DANIEL LEE, JR. </AUTHOR>
<YEAR> 1994 </YEAR>
<INSTITUTION> THE UNIVERSITY OF ARIZONA; 0009 </INSTITUTION>
<DESCRIPTORS> MATHEMATICS; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> HAL S. THARP </ADVISER>
<CLASSIFICATIONS> NIL </CLASSIFICATIONS>
<ABSTRACT>
Efforts to improve hyperthermia treatments of cancer
have motivated this research. Three fundamental goals
that have have been defined are the identification of
tissue parameter values, the prediction of tissue
temperature behavior, and the control of tissue
temperature behavior during hyperthermia treatments.
This dissertation consists of three independent studies
plying neural networks to hyperthermia. These studies
examine neural network based systems and how these
systems apply to the identification, prediction, and
control of tissue temperature behavior during a
hyperthermia treatment.
The first study examines the ability of neural networks
to estimate the tissue perfusion values and the minimum
temperature associated with numerically calculated
steady state hyperthermia temperature fields. This study
utilizes a limited number of measured temperatures
within this field. We show that a hierarchical system of
neural networks consisting of a first layer of pattern
recognizing neural networks and a second layer of
hypersurface reconstructing neural networks is capable
of estimating these variables within a selected error
tolerance. Additional results indicate that if the
locations of the measured temperatures within the
temperature field are selected effectively, the
hierarchical system of neural networks can tolerate a
moderate level of model mismatch.
The second study examines the feasibility of using a
system of neural networks to estimate the Laplacian
values at the sensor locations in a tissue sample by
using the measured temperature data. By combining these
neural network Laplacian estimates with the measured
data, numerical values for three different components
(conduction, advection, and external power) can be
obtained at the sensor locations. These thermal terms
can then be used in a model of the tissue to predict
future temperatures. Using only measured data collected
early in the treatment, we show that recursive
application of this estimation process can provide
accurate predictions of the temperature behavior at the
sensor locations of a tissue sample for the duration of
a treatment. This system was also found to be robust
with respect to the addition of white noise to both the
sensor measurements and the amount of power delivered to
the sensor locations.
The final study explores the ability of a neural network
based predictive system to formulate a predictive
control strategy. We show that with certain restrictions
on the power deposition patterns, desired temperature
trajectories within the tissue model can be achieved
with a neural network based predictive control system.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  2622 </NUMBER>
<ORDER>   AAG9506212 </ORDER>
<TITLE> PROUD: AN INTEGRATED REVERSE ENGINEERING SYSTEM FOR SOFTWARE MAINTENANCE </TITLE>
<AUTHOR> HUANG, HAI </AUTHOR>
<YEAR> 1994 </YEAR>
<INSTITUTION> UNIVERSITY OF HAWAII; 0085 </INSTITUTION>
<DESCRIPTORS> COMPUTER SCIENCE </DESCRIPTORS>
<ADVISER> ISAO MIYAMOTO </ADVISER>
<CLASSIFICATIONS> NIL </CLASSIFICATIONS>
<ABSTRACT>
Programmers who maintain software systems face one big
problem--it is difficult to get accurate and relevant
information about the target system. Reverse engineering
can be a solution to the problem since it obtains the
information about the target system from the most
reliable source--the source code of the target system.
This dissertation presents an integrated, intelligent
reverse engineering system--Proud (Program Understanding
System). Proud is a component for reverse engineering
and program analysis in the SMA (Software Maintenance
Assistant) project. Its objective is to provide accurate
and relevant information of the target system for other
components in SMA by extraction from and analysis of the
source codes of the target system. Proud has the
following unique features: (1) It uses a graphical
knowledge representation language that incorporates many
advanced artificial intelligence features for
representing different aspects and properties of
software. (2) It provides a graphical, non-procedural
query language to access and manipulate information
extracted and abstracted from the source codes of the
target system. (3) It adopts a flexible, adaptable
approach and hence it is easily customized to fit the
requirements of a particular software maintenance
project. (4) It uses a rule-based approach in the design
and implementation of most of its extraction tools so
that tools become language independent and can easily
provide extra information if demanded.
The system has been tested with some source code files
from Fujitsu Limited. It is also used as the front-end
processor for other projects. Proud shows its
capabilities in these tests and has been proven as a
useful tool for software maintenance.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  2623 </NUMBER>
<ORDER>   AAG9506032 </ORDER>
<TITLE> VISOR: LEARNING VISUAL SCHEMAS IN NEURAL NETWORKS FOR OBJECT RECOGNITION AND SCENE ANALYSIS </TITLE>
<AUTHOR> LEOW, WEE KHENG </AUTHOR>
<YEAR> 1994 </YEAR>
<INSTITUTION> THE UNIVERSITY OF TEXAS AT AUSTIN; 0227 </INSTITUTION>
<DESCRIPTORS> COMPUTER SCIENCE; ENGINEERING, ELECTRONICS AND ELECTRICAL; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> RISTO P. MIIKKULAINEN </ADVISER>
<CLASSIFICATIONS> NIL </CLASSIFICATIONS>
<ABSTRACT>
This dissertation describes a neural network system
called VISOR for object recognition and scene analysis.
The research with VISOR aims at three general goals: (1)
to contribute to building robust, general vision systems
that can be adapted to different applications, (2) to
contribute to a better understanding of the human visual
system by modeling high-level perceptual phenomena, and
(3) to address several fundamental problems in neural
network implementation of intelligent systems, including
resource-limited representation, and representing and
learning structured knowledge. These goals lead to a
schema-based approach to visual processing, and focus
the research on the representation and learning of
visual schemas in neural networks.
Given an input scene, VISOR focuses attention at one
component of an object at a time, and extracts the shape
and position of the component. The schemas, represented
in a hierarchy of maps and connections between them,
cooperate and compete to determine which one best
matches the input. VISOR keeps shifting attention to
other parts of the scene, reusing the same schema
representations to identify the objects one at a time,
eventually recognizing what the scene depicts. The
recognition result consists of labels for the objects
and the entire scene. VISOR also learns to encode the
schemas' spatial structures through unsupervised
modification of connection weights, and reinforcement
feedback from the environment is used to determine
whether to adapt existing schemas or create new schemas
to represent novel inputs.
VISOR's operation is based on cooperative, competitive,
and parallel bottom-up and top-down processes that seem
to underlie many human perceptual phenomena. Therefore,
VISOR can provide a computational account of many such
phenomena, including shifting of attention, priming
effect, perceptual reversal, and circular reaction, and
may lead to a better understanding of how these
processes are carried out in the human visual system.
Compared to traditional rule-based systems, VISOR shows
remarkable robustness of recognition, and is able to
indicate the confidence of its analysis as the inputs
differ increasingly from the schemas. With such
properties, VISOR is a promising first step towards a
general vision system that can be used in different
applications after learning the application-specific
schemas.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  2624 </NUMBER>
<ORDER>   AAG9505922 </ORDER>
<TITLE> HIDDEN MARKOV MODEL FOR HUMAN PERFORMANCE MODELING </TITLE>
<AUTHOR> YANG, JIE </AUTHOR>
<YEAR> 1994 </YEAR>
<INSTITUTION> THE UNIVERSITY OF AKRON; 0003 </INSTITUTION>
<DESCRIPTORS> ENGINEERING, ELECTRONICS AND ELECTRICAL; COMPUTER SCIENCE; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> NIL </ADVISER>
<CLASSIFICATIONS> NIL </CLASSIFICATIONS>
<ABSTRACT>
Human performance is the actions and/or reactions of
humans under specified circumstances. Actions reflect
human skill in performing a task, and reactions reflect
control strategy in response to the environment. Many
human-computer interactions require modeling human
performance. Human performance modeling, however, is
challenging because of its stochastic nature and
relative measure.
In this dissertation, I propose a systematic methodology
for modeling human performance based on the hidden
Markov model (HMM) approach. To illustrate the concepts,
procedures, and implementational issues, three case
studies are carried out in great detail on gesture
recognition, action learning, and control strategy
learning. First, the problem of gesture recognition is
investigated. A prototype of an HMM-based gesture
recognition system has been developed to demonstrate the
feasibility of the proposed method, to illustrate the
procedures, and to address implementational issues. The
system has achieved 99.78% accuracy for an isolated
recognition task with nine gestures, and shows great
potential for connected gesture recognition. The problem
of action learning from observation is then studied. An
HMM has been used to represent all the observed action
data based on the most likely performance criterion and
to acquire skill from these data. The HMM-based action
learning approach has been successfully applied to the
Self-Mobile Space Manipulator ($SMsp2$) for learning the
skill of exchanging an Orbit Replaceable Unit (ORU).
Finally, the problem of control strategy learning is
discussed. For a given system, the control strategy is
partitioned into a set of decision patterns which are
described by corresponding HMMs. Simulation results on a
linear system and an inverted pendulum system are given.
HMM provides a framework for modeling human actions and
control strategy, to cope with stochastic nature of
human performance. The concepts and systems developed in
this dissertation are significant for various problems
in man-machine interactions such as teleoperation,
learning control, and skill learning. The approach is
also a practical solution in developing a knowledge-
based intelligent system to provide high quality
performance. The technology presented here is extendible
to a variety of other problems in man-machine
interactions.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  2625 </NUMBER>
<ORDER>   AAI9607059 </ORDER>
<TITLE> A KNOWLEDGE-BASED EXPERT SYSTEM APPROACH TO ANALYZE AND EVALUATE HIGHWAY CONSTRUCTION SCHEDULES </TITLE>
<AUTHOR> FAHMIE, MARWAN MOHAMMAD </AUTHOR>
<YEAR> 1994 </YEAR>
<INSTITUTION> UNIVERSITY OF FLORIDA; 0070 </INSTITUTION>
<DESCRIPTORS> ENGINEERING, CIVIL; OPERATIONS RESEARCH; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> RALPH D. ELLIS, JR. </ADVISER>
<CLASSIFICATIONS> NIL </CLASSIFICATIONS>
<ABSTRACT>
Project scheduling is the practice of regulating and
controlling the execution and performance of a
construction project. The practice involves the
establishing of a plan for the project execution based
on engineering and administrative requirements, and
available resources. Available computerized scheduling
software had been criticized for its inflexibility,
impartiality and inability to evaluate the schedule
reliability.
In the field of highway construction in the state of
Florida, the utilization of computerized scheduling
techniques in preparing and monitoring construction
projects has been observed to be very limited. In
addition to software inflexibility, the absence of an
activity-oriented coding system for highway construction
projects is among the reasons that pertain to the
limited use of scheduling software. The vast anticipated
growth in highway construction and maintenance projects
necessitates the utilization of a specialized domain-
oriented computerized scheduling technique which will
provide highway construction parties with schedule
evaluation and activities execution regulations.
This study is focused toward the development of a
knowledge-based diagnostic model that will examine the
data produced by a computerized scheduling technique
about an initial or in-progress highway construction
schedule. The model evaluation will be done in
compliance with facts and regulations pertaining to
scheduling highway construction projects. The facts
employed in this model include scheduling techniques
knowledge, general construction scheduling knowledge and
highway construction regulations.
The model knowledge base was developed using an expert
system shell featuring the ability to interface
dynamically with external data base files. Using an IF-
THEN-ELSE production rules and a Standard Query Language
program, the model prototype is designed to counsel the
user with instructions and observed malfunctions
regarding the schedule under evaluation. The results of
the model prototype evaluation may be presented in a
form of on-screen or printed reports.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  2626 </NUMBER>
<ORDER>   AAG9505299 </ORDER>
<TITLE> DIAGNOSTIC KNOWLEDGE-BASED SYSTEMS FOR BATCH CHEMICAL PROCESSES: HYPOTHESIS QUEUING AND EVALUATION </TITLE>
<AUTHOR> SRAVANA, KUMAR KARNATI </AUTHOR>
<YEAR> 1994 </YEAR>
<INSTITUTION> THE OHIO STATE UNIVERSITY; 0168 </INSTITUTION>
<DESCRIPTORS> ENGINEERING, CHEMICAL; COMPUTER SCIENCE; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> J. F. DAVIS </ADVISER>
<CLASSIFICATIONS> NIL </CLASSIFICATIONS>
<ABSTRACT>
Knowledge-based system (KBS) approaches to diagnosis
have seen widespread application in the process plant
domain. Much of the research focus, however, has been
toward continuous processes. In this research,
recognizing that effectiveness of a diagnostic system
can be maximized by taking into account the
characteristics of the process, batch and continuous
chemical process characteristics are analyzed from a
diagnostic viewpoint.
Based upon when diagnosis is initiated with respect to
the cycle time of batch processes, two categories of
diagnosis, namely after-cycle diagnosis and during-cycle
diagnosis, have been identified. The computational
demands in each category are characterized.
It has been shown that the Generic Task (GT) approach
has the ability to capture knowledge from a variety of
sources, and in a form that is directly useful in batch
process diagnosis. It has been shown that after-cycle
diagnosis involves a number of tasks, each of which
perform a unique function. A framework for after-cycle
diagnosis is developed consisting of three primary
tasks: Qualitative Interpretation (QI), Hierarchical
Classification (HC) and Hypothesis Queuing (HQ). HC is
the core task incorporating all the process knowledge
and the primary generic organizational and reasoning
strategies.
A conceptual basis for knowledge organization in the
form of hierarchy is evolved, in which the top-level
hypotheses represent the batch procedures (steps),
intermediate-level hypotheses represent specific fault
categories of the top-level hypotheses and the tip-level
hypotheses represent equipment faults or operator
errors. Establish-refine strategy is shown to be the
primary reasoning strategy. A new search strategy called
hypothesis-invocation-by-elimination, where a hypothesis
is evaluated due to the rejection of certain other
hypotheses, is developed.
A new generic task, Hypothesis Queuing (HQ), is
developed which uses the knowledge available in HC in a
transformed manner. It queues the various hypotheses in
the hierarchy based upon their "suggested" explanatory
powers, which are evaluated by the use of initially
available symptom data. This task is shown to be
extremely useful in situations where diagnosis involves
a number of field tests.
The conceptual developments have been applied to the
after-cycle diagnosis of an industrial batch polymer
process, in which diagnosis relies heavily on product
quality data.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  2627 </NUMBER>
<ORDER>   AAG9505173 </ORDER>
<TITLE> CHARACTERIZATION AND REPRESENTATION OF FUNCTIONAL REQUIREMENTS AND FUNCTIONAL TOLERANCING FOR CONCURRENT DESIGN AND MANUFACTURING </TITLE>
<AUTHOR> CHEN, BAOSHENG </AUTHOR>
<YEAR> 1994 </YEAR>
<INSTITUTION> THE OHIO STATE UNIVERSITY; 0168 </INSTITUTION>
<DESCRIPTORS> ENGINEERING, MECHANICAL; ENGINEERING, INDUSTRIAL; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> CHIA-HSIANG MENQ </ADVISER>
<CLASSIFICATIONS> NIL </CLASSIFICATIONS>
<ABSTRACT>
The proposed dissertation research is designed to
investigate two issues that are directly related to the
concurrent design and manufacturing of mechanical
products and systems. The focus is on understanding the
functional structure of modern mechanical products and
on modeling their required functions so as to support
the various activities in their design and
manufacturing.
The characterization of the functional requirements of
both mechanical components and systems has been studied
in this dissertation research. The hierarchy analysis,
the decomposition, and the dependence check of the
functional requirements are used as three major issues
in the characterization process. To represent a group of
functional requirements, a functional structure and a
descriptive model which includes functional intent,
characteristics, and target value or ideal state are
proposed. The representation scheme can be implemented
along with the design model of a product to provide
sufficient information for downstream product
activities.
To support the subsequent production activities, based
on the understanding of the various functional
requirements, an approach of tolerancing for function is
presented. The tolerancing for function approach
attempts to determine the possible tolerance
specifications for a product directly according to its
functional requirements and their allowable variations.
Based on the proposed tolerancing for function approach,
a framework for functional tolerancing is proposed which
can be implemented in a computer-integrated design and
manufacturing environment. The framework includes four
inter-related modules: identification, transformation,
tolerancing, and specification modules.
The proposed functional framework provides a basis for
the characterization and representation of the
functional requirements in mechanical design. It will
also provide a basis for integrating design intent into
the product cycle so that higher level of decision
making and complex reasoning for the determination of
optimum product design and process planning become
possible. The proposed tolerancing for function approach
can be used to support the subsequent production
activities, and establish a foundation for continuing
research on automatic tolerancing. By using the proposed
functional tolerancing approach, the current practice of
tolerance representation and specification can be
extended and applied to the products that are
sophisticated in function and/or complicated in
geometry.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  2628 </NUMBER>
<ORDER>   AAG9506220 </ORDER>
<TITLE> AN EXPERIMENTAL STUDY OF INCORPORATING THEMATIC ROLE ANALYSIS INTO VSM-BASED TEXT INFORMATION REPRESENTATION AND RETRIEVAL: DESIGN AND EVALUATION OF THE SEMANTIC VECTOR SPACE MODEL </TITLE>
<AUTHOR> LIU, GEOFFREY ZHENGFU </AUTHOR>
<YEAR> 1994 </YEAR>
<INSTITUTION> UNIVERSITY OF HAWAII; 0085 </INSTITUTION>
<DESCRIPTORS> INFORMATION SCIENCE; COMPUTER SCIENCE; LANGUAGE, LINGUISTICS; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> LARRY N. OSBORNE </ADVISER>
<CLASSIFICATIONS> NIL </CLASSIFICATIONS>
<ABSTRACT>
One of the current trends in the field of information
retrieval is to apply artificial intelligence
techniques, especially natural language processing and
knowledge representation techniques, to the problem of
information retrieval. Although this approach is
appealing, it is unlikely that the problem can be solved
once and for all by completely relying on the semantic
processing and knowledge representation techniques and
attempting direct retrieval of information from a
knowledge base constructed out of a collection of
natural language texts.
A feasible approach is to use the well-developed IR
techniques as the backbone and incorporate some of the
NLP techniques to increase the power of content
representation without involving sophisticated processes
of semantic interpretation and knowledge representation.
In this dissertation research, a text representation and
searching technique, called "the Semantic Vector Space
Model" (SVSM), was developed by combining Salton's
Vector Space Model (VSM) with heuristic syntax parsing
and distributed representation of semantic case
structures. In this model, both documents and queries
are represented as semantic matrices. A search mechanism
was designed to compute the similarity between two
semantic matrices and the similarity value was
interpreted as the predictor of relevancy.
A prototype system was built to implement this model by
modifying the SMART system and using the Xerox P-O-S
tagger as the pre-processor of the indexing process. The
prototype system, called "SMART++", was used in a series
of experiments designed to evaluate the proposed text
representation and searching technique in terms of
precision, recall, and effectiveness of relevance
ranking. The original SMART system was used as the
benchmark. Three experimental collections acquired from
Cornell University were used in the experiments.
The results of these experiments showed that if
documents and queries were too short (typically less
than 2 lines in length) our technique was less effective
than the Vector Space Model. But with longer documents
and queries, especially when original documents were
used as queries, we found that the system based on our
technique had significantly better performance than the
SMART system. This suggests that a significant
improvement of system performance can be achieved by
combining semantic case structure information with the
weighted term representation of texts in a situation
where longer queries are available.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  2629 </NUMBER>
<ORDER>   AAG1358818 </ORDER>
<TITLE> GENETIC ALGORITHMS IN BATTLEFIELD COMMUNICATIONS NETWORK CONFIGURATION </TITLE>
<AUTHOR> CHANG, TONY F. </AUTHOR>
<YEAR> 1994 </YEAR>
<INSTITUTION> UNIVERSITY OF GEORGIA; 0077 </INSTITUTION>
<DESCRIPTORS> COMPUTER SCIENCE; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> WALTER D. POTTER </ADVISER>
<CLASSIFICATIONS> NIL </CLASSIFICATIONS>
<ABSTRACT>
The problem of finding a low-cost set of communication
network components is a very difficult and time-
consuming task. This is because of the large number of
possible configurations derivable from the numerous
types and quantities of components. In this thesis, we
describe a genetic algorithm approach to solving the
battlefield communications network configuration
problem. A prototype expert module (named IDA-NET) has
been developed to perform this task. To further prove
that our genetic algorithm approach is an appropriate
method towards solving this problem, the result of IDA-
NET is compared with the results generated by a general
heuristic algorithm (i.e., the hill-climbing search
algorithm). The comparison shows that the genetic
algorithm approach performed better than the other
heuristic algorithm.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  2630 </NUMBER>
<ORDER>   AAG1358814 </ORDER>
<TITLE> APPLYING EXPERT SYSTEMS TECHNOLOGY TO THE IMPLEMENTATION OF A FORECASTING MODEL IN FOODSERVICE </TITLE>
<AUTHOR> SANCHEZ, NORMA F. </AUTHOR>
<YEAR> 1994 </YEAR>
<INSTITUTION> KANSAS STATE UNIVERSITY; 0100 </INSTITUTION>
<DESCRIPTORS> BUSINESS ADMINISTRATION, MANAGEMENT; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> NIL </ADVISER>
<CLASSIFICATIONS> NIL </CLASSIFICATIONS>
<ABSTRACT>
The objective of the study was to develop an expert
system model to replicate the intuitive forecast process
of the forecast knowledge expert in foodservice. Series
of interviews with the knowledge expert were made during
Fall semester of 1993. Collection site was a university
dining center which utilized food court concept. Entree
items for three of the four service lines were forecast.
More than 240,000 potential combinations of menu items
exist based on variety of offerings available. An expert
system software shell and spreadsheet software were used
to develop the system. The expert system for forecasting
menu items was tested to evaluate user friendliness and
accuracy. Evaluation was made by comparing the forecast
generated by the model to the knowledge expert forecast.
Error was reduced, using Mean Absolute Deviation (MAD)
and Mean Squared Error (MSE) from MAD of 21.60 and MSE
of 717.86 to MAD of 0.27 and MSE of 1.07. Percentage of
acceptability was 81.11%.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  2631 </NUMBER>
<ORDER>   AAG1358692 </ORDER>
<TITLE> AN OBJECT-ORIENTED SOFTWARE TEST-BED FOR INTELLIGENT ROBOT CONTROL </TITLE>
<AUTHOR> KALYANAKUMAR, K. C. </AUTHOR>
<YEAR> 1994 </YEAR>
<INSTITUTION> LAMAR UNIVERSITY - BEAUMONT; 0424 </INSTITUTION>
<DESCRIPTORS> COMPUTER SCIENCE; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> NIL </ADVISER>
<CLASSIFICATIONS> NIL </CLASSIFICATIONS>
<ABSTRACT>
Designing a controller for a monoped robot using
techniques presented in fuzzy systems is the main idea
of this thesis. A simulation of the robot was used for
the experiments. The description of the 3-link robot is
given. A method developed by Wang and Mendel (1992) for
generating fuzzy rules by learning from examples was
used and the same is presented. Experiments were
conducted for a single jump of the robot without
considering continuity. Trials were conducted to
determine the values of control variables for different
desired inputs of the robot. A large number of such
input-control data pairs with their corresponding
fitness value were used to generate fuzzy rules. After
creating a Fuzzy Associative Memory with this set of
examples, values of control variables were determined
for a set of desired values of input variables. These
desired values were compared with those generated by the
simulator. Whenever the two sets of values differed they
were made to converge by using meta-rules to adjust the
values of control variables. After convergence was
achieved a set of input-output data pair was generated
and the Fuzzy Associative Memory or the rule base was
updated from this set of input-output values.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  2632 </NUMBER>
<ORDER>   AAGMM91357 </ORDER>
<TITLE> INTEGRATION DE VOCABULAIRE: UNE ETAPE VERS LE PARTAGE DES STRUCTURES DE CONNAISSANCE ENTRE SYSTEMES </TITLE>
<AUTHOR> ALLOUCHE, MOURAD </AUTHOR>
<YEAR> 1994 </YEAR>
<INSTITUTION> UNIVERSITE LAVAL (CANADA); 0726 </INSTITUTION>
<DESCRIPTORS> COMPUTER SCIENCE; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> GUY MINEAU </ADVISER>
<CLASSIFICATIONS> FRENCH TEXT </CLASSIFICATIONS>
<ABSTRACT>
La variete des techniques d'acquisition des
connaissances et l'heterogeneite des formalismes de
representation de la connaissance constituent un goulot
d'etranglement qui nuit au partage de structures de
connaissance entre systemes. Ce partage est souhaite
afin que des systemes autonomes puissent cooperer.
Actuellement, nous assistons a des courants de pensee
qui visent a augmenter l'accessibilite aux sources de
connaissances de la facon la plus transparente possible.
Parmi ces courants, se distinguent la definition de
standards pour la representation de la connaissance,
l'etablissement d'ontologies generiques, et la
definition, l'extraction et l'integration d'ontologies
existantes. Dans ce memoire, nous proposons dans une
premiere etape d'utiliser une technique de
classification symbolique afin d'etablir des primitives
ontologiques qui caracterisent un domaine a modeliser.
L'analyse de la structure de classification produite
engendre un processus de revision et d'enrichissement de
la modelisation theorique du domaine, et facilite son
integration a d'autres domaines. Dans la deuxieme etape,
nous presentons une etude comparative de quatre
techniques de codification de hierarchies de types
desquelles nous avons selectionne la plus performante
pour le mecanisme de classification que nous avons
utilise.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  2633 </NUMBER>
<ORDER>   AAGC387385 </ORDER>
<TITLE> SUBSYMBOLIC REPRESENTATIONS, SELF-ORGANIZING MAPS, AND OBJECT MOTION LEARNING </TITLE>
<AUTHOR> HEIKKONEN, JUKKA VEIKKO </AUTHOR>
<YEAR> 1994 </YEAR>
<INSTITUTION> LAPPEENRANNAN TEKNILLINEN KORKEAKOULU (FINLAND); 5755 </INSTITUTION>
<DESCRIPTORS> COMPUTER SCIENCE </DESCRIPTORS>
<ADVISER> NIL </ADVISER>
<CLASSIFICATIONS> NIL </CLASSIFICATIONS>
<ABSTRACT>
This thesis addresses two sensory-based problems where
the task is to learn object motions from low-level
sensory information. In addition, this thesis reviews of
fundamental issues in artificial intelligence, including
different approaches to problem solving in sensory-based
tasks, the knowledge representation, and artificial
neural networks, and especially emphasizes the role of
the Self-Organizing Map (SOM) in sensory information
processing.
The first problem addressed in this thesis is the task
of learning and representing object motions directly
from spatiotemporal features extracted from image
sequences. In this task the SOM is utilized for building
representations of the movements of objects within the
given environment. It is shown how object motions in
real-world traffic scenes can be learned, and how our
methods apply to the quantitative motion analysis of air
flows that are visualized by tracer gas. In addition, we
show how to associate environment features to the
learned motion representations for building generalized
motion models to confront with novel situations that
differ slightly from given example motions.
The second problem is related with autonomous mobile
robots that have to construct a representation from
sensory situations to appropriate actions in order to
navigate in their environments without colliding with
obstacles. The viability of the proposed control
strategy for an action-oriented mobile robot is
demonstrated with a simulated robot in four case
studies. First, we show how the simulated mobile robot
can learn motion behaviors needed in navigating through
corridor intersections. Second, the robot learns an
efficient obstacle avoidance behavior in its environment
from several example paths and the robot can improve its
performance while operating. Third, the robot learns to
navigate between two points without any outside
assistance during navigation, and fourth, the mobile
robot utilizes visual information while enrouting in its
environment. The provided experiments demonstrate that
the proposed control strategy learns quickly to select
suitable actions for sensory situations, adapts easily
to new environments, and can utilize both the outputs of
range sensors and visual information.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  2634 </NUMBER>
<ORDER>   AAGC384874 </ORDER>
<TITLE> SUPERVISORY CONTROL SYSTEMS </TITLE>
<AUTHOR> VAN DE REE, ROGIER VINCENT </AUTHOR>
<YEAR> 1994 </YEAR>
<INSTITUTION> TECHNISCHE UNIVERSITEIT TE DELFT (THE NETHERLANDS); 0951 </INSTITUTION>
<DESCRIPTORS> COMPUTER SCIENCE NETHERLANDS NETHERLANDS </DESCRIPTORS>
<ADVISER> NIL </ADVISER>
<CLASSIFICATIONS> PROPAGATION CONTROL </CLASSIFICATIONS>
<ABSTRACT>
Supervisory control tasks comprise planning, scheduling,
fault detection and fault diagnosis. When operating in
real-time, these supervisory tasks must be performed
within a limited time. On-line supervisory control for
operator support at the plantwide level requires a high
degree of automation of these tasks. To manage the
complexity of these control tasks in large and complex
dynamic domains, such as chemical batch processing,
artificial intelligence techniques turn out to be
valuable.
This dissertation describes a hierarchical architecture
for general supervisory control systems for plantwide
applications. An overview is given of methods used to
implement supervisory tasks. Data and knowledge
representation and manipulation techniques are developed
that manage the complexity of large process models.
Hierarchical process models are created in an object-
oriented process model design environment and used in a
supervisory control environment for model reference
control purposes.
A process model consists of four layers that represent
the aggregate levels recognisable in a corporation. To
keep these layers consistent with each other,
abstraction is used to propagate low-level changes to
higher level layers. Data transformation takes care of
exchanging results between knowledge representation
paradigms. These paradigms allow representation of
knowledge from different sources, like engineers and
operators. Propagation control handles network
complexity to evaluate the model within a limited time.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  2635 </NUMBER>
<ORDER>   AAG9506787 </ORDER>
<TITLE> A HUMAN LEARNING APPROACH FOR DESIGNING ADAPTIVE KNOWLEDGE-BASED SYSTEMS </TITLE>
<AUTHOR> ROHATGI, MUKESH </AUTHOR>
<YEAR> 1994 </YEAR>
<INSTITUTION> TEXAS TECH UNIVERSITY; 0230 </INSTITUTION>
<DESCRIPTORS> COMPUTER SCIENCE; INFORMATION SCIENCE; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> SURYA B. YADAV </ADVISER>
<CLASSIFICATIONS> NIL </CLASSIFICATIONS>
<ABSTRACT>
Most information systems are static in nature and follow
a predetermined behavior. Unfortunately, static systems
have proved to be very brittle when faced with
adaptation to the changing demands of their environment.
Researchers have stated that systems can exhibit
adaptive behavior through learning.
The purpose of this research was to show that it is
feasible to use human learning processes (instead of ad
hoc techniques) to manifest learning in a computer-based
system. Therefore, the primary objective of this
research was to conceptually develop and validate the
"human learning approach" perspective for designing
machine learning systems.
To demonstrate the feasibility of the "human learning
approach," this research has developed a conceptual
model for machine learning systems by adopting a
cognitive modeling approach. Learning mechanisms
incorporated in the conceptual model were designed on
the basis of human learning theory. The model was then
implemented in the form of a knowledge-based prototype
system. Finally, the prototype system was shown to
exhibit learning behavior through acquisition,
modification and discovery of knowledge structures. The
exhibition of learning behavior by the prototype system
serves as a "proof of concept" for the "human learning
approach."
This research contributes to the work being done in
machine learning because it suggests an alternate method
for designing machine learning systems. It is also
relevant to information systems design because this
research offers a possible solution for designing
"adaptive" information systems.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  2636 </NUMBER>
<ORDER>   AAI9606759 </ORDER>
<TITLE> DEVELOPING A KNOWLEDGE-BASED EXPERT SYSTEM TO DETERMINE CONTRACT DURATION FOR HIGHWAY CONSTRUCTION </TITLE>
<AUTHOR> CHEN, WEI-TONG </AUTHOR>
<YEAR> 1994 </YEAR>
<INSTITUTION> UNIVERSITY OF FLORIDA; 0070 </INSTITUTION>
<DESCRIPTORS> ENGINEERING, CIVIL; BUSINESS ADMINISTRATION, MANAGEMENT; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> ZOHAR HERBSMAN </ADVISER>
<CLASSIFICATIONS> NIL </CLASSIFICATIONS>
<ABSTRACT>
In today's highway construction industry, the focus of
the work has shifted from the building of new highway
systems to the resurfacing, rehabilitating and restoring
(3Rs) of those already in existence. As a result, the
flow of traffic must be maintained with the required
lane and shoulder restrictions throughout the
construction of the project.
Appropriate contract durations allow the contractor
sufficient time to complete the work, while at the same
time minimizing the disruption to the flow of traffic
and other construction-related inconveniences that may
be experienced by the traveling public. An appropriate
contract duration should be agreeable to both the state
highway agencies (SHAs) and the contractor, thereby
reducing the incidence and severity of potential
contractual disputes. Most importantly, however, proper
contract durations must be established so that the
financial interests of both the SHAs and the general
public remain paramount.
This research was devoted to developing EXCONDD, a
knowledge-based expert system (KBES) for contract
duration determination for highway construction. Various
contract duration influence factors and the overview of
KBES were addressed in detail.
Three commercial software packages are used in EXCONDD.
Among these software, EXSYS Professional plays the most
important role because it controls the execution of the
entire system. Lotus 123 is utilized to establish
various templates. Suretrak Project Scheduler takes
charge of project scheduling.
EXCONDD includes three modules: the parametric
estimating time (PTE) module, the production rates
module, and the "A + B" module. The production rates
module can only be utilized to estimate contract
duration for highway widening and resurfacing projects,
while the other modules are applicable to any type of
project with no restriction. Knowledge and expertise of
EXCONDD was extracted mainly from SHAs guidelines and
experienced schedulers in the field of highway
construction. By integrating these three modules,
contract duration of highway projects can be easily
determined.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  2637 </NUMBER>
<ORDER>   AAG9505073 </ORDER>
<TITLE> A COMPLETE, HYPERMEDIA, COMPUTER-BASED DECISION ANALYSIS SUPPORT SYSTEM FOR MEDICAL EXPERT SYSTEMS </TITLE>
<AUTHOR> CHIU, DENG-YIV </AUTHOR>
<YEAR> 1994 </YEAR>
<INSTITUTION> ILLINOIS INSTITUTE OF TECHNOLOGY; 0091 </INSTITUTION>
<DESCRIPTORS> COMPUTER SCIENCE; HEALTH SCIENCES, MEDICINE AND SURGERY; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> MARTHA W. EVENS </ADVISER>
<CLASSIFICATIONS> NIL </CLASSIFICATIONS>
<ABSTRACT>
Many difficulties may be encountered when trying to
carry out important decisions in the real world without
complete data needed to make the decisions. In these
cases, decision analysis may exhibit its greatest
advantage. The decision analysis support system can be
helpful in those situations.
The decision analysis support system uses theory,
concepts of decision making, statistics, and computer
techniques, such as the value of information, Bayes'
theorem, decision tree, sensitivity analysis, object-
oriented programming, and hypermedia.
It provides an easy, efficient, and attractive way to
perform decision analysis. The Control Center controls
the entire operation. The Problem Creator makes it easy
to add a new problem to the support system. The Problem
Editor can be used to edit the problems stored in the
Problem Database. The Knowledge Base Editor can be used
to edit the rules in the Knowledge Base. The User$sb-
$Input$sb-$All$sb-$Data Utility lets users input data
for analysis. The Data Adjustment Utility adjusts prior
data for a specific patient. The Decision Analysis
Utility performs the decision analysis. The Training
Utility is used to teach users how to use the support
system and to introduce decision theory and concepts.
The Training Utility is very easy to use and its
interface is very attractive.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  2638 </NUMBER>
<ORDER>   AAG9504769 </ORDER>
<TITLE> FAULT TOLERANCE IN FEED-FORWARD ARTIFICIAL NEURAL NETWORKS  </TITLE>
<AUTHOR> CLAY, REED DAVID </AUTHOR>
<YEAR> 1994 </YEAR>
<INSTITUTION> UNIVERSITY OF CALIFORNIA, BERKELEY; 0028 </INSTITUTION>
<DESCRIPTORS> COMPUTER SCIENCE; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> CARLO H. SEQUIN </ADVISER>
<CLASSIFICATIONS> NEURAL NETWORKS </CLASSIFICATIONS>
<ABSTRACT>
Traditional computers architectures are extremely
sensitive to even the most trivial and isolated hardware
failures. Inspired by the impressive information
processing capabilities of human brains, many
researchers study artificial neural networks (ANN's) as
an alternative to traditional symbolic processing
algorithms. While the style of computation of ANN's is
functionally more similar to the brains than are
traditional computers, they are not as fault tolerant as
is popularly assumed. In this thesis we discuss how
ANN's can become fault tolerant and we investigate
methods for automatically improving the fault tolerance
of ANN's.
In the context of classification tasks, we explore an
algorithm that, during training, randomly and
temporarily introduces the types of faults that one
might expect to occur. We have found this to be a simple
yet powerful technique for reliably achieving fault
tolerance in ANN's for a variety of tasks, including the
recognition of handwritten characters. One benefit of
the new method is that it can readily handle a variety
of different faults such as stuck-at-max faults as well
as double and triple faults. Furthermore, our technique
can actually improve an ANN's ability to generalize and
properly respond to new data.
For analog function approximation tasks, a more exact
output is required and complete fault tolerance is
harder to achieve. We present a technique that is able
to improve fault tolerance by limiting the maximal
contribution of each unit in the network to a small
fraction of the total output signal. To achieve a large
localized output signal, several Gaussian units are
moved into the same location in the input domain and
summed together. Since the contribution of each unit is
small and equal in magnitude, there is only a modest
error under any possible failure mode. We also
investigate a technique that utilizes multiple networks
each calculating the same function and then uses the
combination of their outputs to determine the overall
network output. This technique is quite fault tolerant
even on difficult tasks such as sunspot prediction.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  2639 </NUMBER>
<ORDER>   AAG9504762 </ORDER>
<TITLE> MAINTAINING THE CONSISTENCY OF LARGE EVOLUTIONARY SOFTWARE BASED ON LOOSE HIERARCHICAL TRUTH MAINTENANCE SYSTEM </TITLE>
<AUTHOR> CHANDRA, CLAUDIA </AUTHOR>
<YEAR> 1994 </YEAR>
<INSTITUTION> UNIVERSITY OF CALIFORNIA, BERKELEY; 0028 </INSTITUTION>
<DESCRIPTORS> COMPUTER SCIENCE; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> C. V. RAMAMOORTHY </ADVISER>
<CLASSIFICATIONS> DOMINO, SOFTWARE DEVELOPMENT </CLASSIFICATIONS>
<ABSTRACT>
A software system continues to evolve during its
lifetime, from development to maintenance. When a
modification is made at the maintenance stage, the
problem of trying to determine the extent of a
modification can be compounded by the problem of trying
to understand the detailed functionalities of the system
and to determine where a modification should be made.
The main supports that software developers need to
maintain software systems are in rederiving the
specifications of an implemented system and in
determining the effects that a modification to the
software would cause. The two tasks of understanding and
modifying a software system is called reverse
engineering and reengineering. We can view both tasks as
the problem of analyzing dependency relationships
between the various components that compose the software
system from the requirements specification, design, and
implementation layers. To determine the ripple effects
of a modification the dependencies are traced in the
forward direction, whereas to deduce the specification
of an implementation component, the dependencies between
components in successive abstraction layers are traced
in the backward direction.
The DOMINO software maintenance system is intended to
assist software engineers to perform the two main tasks
of understanding and instituting modifications to a
software system during development and maintenance. The
conceptual idea behind DOMINO is the maintenance of
dependencies between software objects at each stage of
software development and between software objects from
the different stages of development. We identified and
defined the characteristics of various software objects
that can be created during each stage of software
development from the requirements, design, to the
implementation stage. We developed a model of these
software objects, the means by which they interact, and
the various types of dependency relationships that can
exist between them. We also characterized the various
types of assumptions that can be made during the
development process.
DOMINO provides facilities for modeling and tracing
dependency relations between software objects and for
maintaining the consistency of software objects as
modifications are made. The facilities provided by
DOMINO rely on truth maintenance techniques for
maintaining the software objects specifications as a
belief network. For this purpose, we developed the loose
hierarchical assumption-based truth maintenance system
(LHATMS), which is an improvement of the De Kleer's
ATMS. The LHATMS allows the organization of datum into
ATMS modules which are organized in a loose hierarchy.
This provides a means for organizing a large dependency
network into groups of closely related datum and also
improves the efficiency of the propagation algorithms in
the traditional ATMS. (Abstract shortened by UMI.)
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  2640 </NUMBER>
<ORDER>   AAG9504614 </ORDER>
<TITLE> NEURAL NETWORKS MODELING CORTICAL CELLS FOR MACHINE VISION  </TITLE>
<AUTHOR> FOLSOM, TYLER C. </AUTHOR>
<YEAR> 1994 </YEAR>
<INSTITUTION> UNIVERSITY OF WASHINGTON; 0250 </INSTITUTION>
<DESCRIPTORS> ENGINEERING, ELECTRONICS AND ELECTRICAL; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> ROBERT B. PINTER </ADVISER>
<CLASSIFICATIONS> SIGNAL PROCESSING, VISUAL RECOGNITION </CLASSIFICATIONS>
<ABSTRACT>
This research examines the signal processing performed
by the simple cells of the mammalian primary visual
cortex with the objective of developing useful
techniques for machine vision. We summarize the known
signal transformations that occur in the retina, lateral
geniculate nucleus, and visual cortex. A two dimensional
Gabor wavelet transformation is considered as a model of
primary cortical processing. Computational complexity
ofthe Gabor transform is analyzed for both sequential
and parallel computers. We consider the Gabor transform
in the context of a Cohen class kernel and examine its
relationship to the Wigner distribution. We show that
"energy based" models of visual processing discard
significant information contained in the phase. The
similarity among Gabor elementary fUnctions, Gaussian
derivatives, Canny edge detectors and facet models is
noted. We consider a system for generalized object
recognition using a metric based on the similarity
between the Gabor coefficients of a received image and a
template. Such a metric could be used to construct an
image classification hierarchy similar to that used by
Adaptive Resonance Theory. Computer simulations using
this approach show promise, but rely on pre-processing
to align the two images.
When used for visual recognition, the Gabor wavelet
transform faces a dilemma. If the basis functions are
orthogonal, then the transformation is unstable with
respect to image shifts. This can be at least partially
remedied by using a non-orthogonal basis set, but then
the representation is not unique. Thus we discard the
requirement that the original retinal image be directly
reconstructible from the coefficients ofthe cortical
filters. We find that a set of 10 or 14 filters can be
constructed such that it is possible to disambiguate the
2-D responses of the individual filters. Under the
assumption that the stimulus is a step edge or a bar,
algorithms are derived that can determine which stimulus
was present, find its orientation, position, intensity
and scale. We call this method "quadrature
disambiguation". These ideas are validated by
programming automated analyses of test images. The
technique is well suited for implementation in active
vision sensors using an opto-electronic semiconductor
retina.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  2641 </NUMBER>
<ORDER>   AAG9503945 </ORDER>
<TITLE> A MULTI-TIME SCALE LEARNING MECHANISM FOR NEUROMIMIC PROCESSING </TITLE>
<AUTHOR> MOBUS, GEORGE EDWARD </AUTHOR>
<YEAR> 1994 </YEAR>
<INSTITUTION> UNIVERSITY OF NORTH TEXAS; 0158 </INSTITUTION>
<DESCRIPTORS> COMPUTER SCIENCE; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> PAUL FISHER </ADVISER>
<CLASSIFICATIONS> NIL </CLASSIFICATIONS>
<ABSTRACT>
Learning and representing and reasoning about temporal
relations, particularly causal relations, is a deep
problem in artificial intelligence (AI). Learning such
representations in the real world is complicated by the
fact that phenomena are subject to multiple time scale
influences and may operate with a strange attractor
dynamic. This dissertation proposes a new computational
learning mechanism, the adaptrode, which, used in a
neuromimic processing architecture may help to solve
some of these problems. The adaptrode is shown to
emulate the dynamics of real biological synapses and
represents a significant departure from the classical
weighted input scheme of conventional artificial neural
networks. Indeed the adaptrode is shown, by analysis of
the deep structure of real synapses, to have a strong
structural correspondence with the latter in terms of
multi-time scale biophysical processes.
Simulations of an adaptrode-based neuron and a small
network of neurons are shown to have the same learning
capabilities as invertebrate animals in classical
conditioning. Classical conditioning is considered a
fundamental learning task in animals. Furthermore, it is
subject to temporal ordering constraints that fulfill
the criteria of causal relations in natural systems. It
may offer clues to the learning of causal relations and
mechanisms for causal reasoning.
The adaptrode is shown to solve an advanced problem in
classical conditioning that addresses the problem of
real world dynamics. A network is able to learn
multiple, contrary associations that separate in time
domains, that is a long-term memory can co-exist with a
short-term contrary memory without destroying the
former. This solves the problem of how to deal with
meaningful transients while maintaining long-term
memories.
Possible applications of adaptrode-based neural networks
are explored and suggestions for future research are
made.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  2642 </NUMBER>
<ORDER>   AAG9503791 </ORDER>
<TITLE> ASPECTS OF PARTIAL INFORMATION IN DATABASES </TITLE>
<AUTHOR> LIBKIN, LEONID </AUTHOR>
<YEAR> 1994 </YEAR>
<INSTITUTION> UNIVERSITY OF PENNSYLVANIA; 0175 </INSTITUTION>
<DESCRIPTORS> COMPUTER SCIENCE </DESCRIPTORS>
<ADVISER> PETER BUNEMAN </ADVISER>
<CLASSIFICATIONS> SEMANTICS </CLASSIFICATIONS>
<ABSTRACT>
Information stored in databases is usually incomplete.
Typical sources of partiality are missing information,
conflicts that occur when databases are merged, and
asking queries against several databases simultaneously.
The field of partial information in databases has not
received the attention that it deserves. Most work on
partial information in databases asks which operations
of standard languages, like relational algebra, can
still be performed correctly in the presence of simple
forms of partial information. We believe that the
problem should be looked at from another point of view:
the semantics of partiality must be clearly understood
and it should give us new design principles for
languages for databases with partial information.
The main goals of this thesis are to develop new
analytical tools for studying partial information and
its semantics, and to use the semantics of partiality as
the basis for design of query languages. Unlike typical
research in artificial intelligence, we concentrate on
general purpose solutions that are effectively
implementable in the context of database query languages
and provide a flexible basis for future modeling
challenges.
We present a common semantic framework for various kinds
of partial information which can be applied in a context
more general than the flat relational model. This
semantics is based on the idea of ordering objects in
terms of being more informative. Such ordered semantics
cleanly integrates all kinds of partial information and
serves as a tool to establish connections between them.
By analyzing mathematical properties of partial data, it
is possible to find operations naturally associated with
it. Such operations, arising from characterization of
semantic domains of types as free algebras, can be
turned into programming language constructs.
We discuss languages for databases with partial
information that are given rise to by the semantics. A
language for sets and or-sets is introduced and
normalization theorem is proved. It allows to
incorporate semantics into the language and to
distinguish two levels of querying: structural and
conceptual. This language has been implemented on top of
Standard ML, and shown to be useful in problems of
querying independent and incomplete databases.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  2643 </NUMBER>
<ORDER>   AAG9503581 </ORDER>
<TITLE> GENERALIZED KNOWLEDGE-BASED SEMANTICS FOR MULTI-VALUED LOGIC PROGRAMS </TITLE>
<AUTHOR> MOBASHER, BAMSHAD </AUTHOR>
<YEAR> 1994 </YEAR>
<INSTITUTION> IOWA STATE UNIVERSITY; 0097 </INSTITUTION>
<DESCRIPTORS> COMPUTER SCIENCE; MATHEMATICS; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> GIORA SLUTZKI; DON L. PIGOZZI </ADVISER>
<CLASSIFICATIONS> NIL </CLASSIFICATIONS>
<ABSTRACT>
A generalized logic programming system is presented
which uses bilattices as the underlying framework for
the semantics of programs. The two orderings of the
bilattice reflect the concepts of truth and knowledge.
Programs are interpreted according to their knowledge
content, resulting in a monotonic semantic operator even
in the presence of negation. A special case, namely,
logic programming based on the four-valued bilattice is
carefully studied on its own right. In the four-valued
case, a version of the Closed World Assumption is
incorporated into the semantics. Soundness and
Completeness results are given with and without the
presence of the Closed World Assumption. The concepts
studied in the four-valued case are then generalized to
arbitrary bilattices. The resulting logic programming
systems are well suited for representing incomplete or
conflicting information. Depending on the choice of the
underlying bilattice, the knowledge-based logic
programming language can provide a general framework for
other languages based on probabilistic logics,
intuitionistic logics, modal logics based on the
possible-worlds semantics, and other useful non-
classical logics. A novel procedural semantics is given
which extends SLDNF-resolution and can retrieve both
negative and positive information about a particular
goal in a uniform setting. The proposed procedural
semantics is based on an AND-parallel computational
model for logic programs. The concept of substitution
unification is introduced and many of its properties are
studied in the context of the proposed computational
model. Some of these properties may be of independent
interest, particularly in the implementation of parallel
and distributed logic programs. Finally, soundness and
completeness results are proved for the proposed logic
programming system. It is further shown that for finite
distributive bilattices (and, more generally, bilattices
with the descending chain property), an alternate
procedural semantics can be developed based on a small
subset of special truth values which turn out to be the
join irreducible elements of the knowledge part of the
bilattice. The algebraic properties of these elements
and their relevance to the corresponding logic
programming system are extensively studied.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  2644 </NUMBER>
<ORDER>   AAG9503566 </ORDER>
<TITLE> ADVANCED FUZZY LOGIC CONTROLLERS AND SELF-TUNING STRATEGY </TITLE>
<AUTHOR> HUANG, SHOU-HENG </AUTHOR>
<YEAR> 1994 </YEAR>
<INSTITUTION> IOWA STATE UNIVERSITY; 0097 </INSTITUTION>
<DESCRIPTORS> ENGINEERING, MECHANICAL; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> RON M. NELSON </ADVISER>
<CLASSIFICATIONS> NIL </CLASSIFICATIONS>
<ABSTRACT>
This study has concentrated on fuzzy logic controllers
from the basic aspects to an advanced self-tuning
strategy. Fuzzy logic provides a very good technique for
knowledge representation which makes it possible to
incorporate the experience of human operators in the
design of controllers.
The basic concepts of fuzzy set theory, fundamental
definitions of fuzzy logic, and basic structure of fuzzy
logic controllers are introduced and a guideline for
building the fuzzy rule-based system is developed. The
rule development and adjustment strategies for fuzzy
logic controllers are presented and experimentally
identified. The fuzzy logic control system is analyzed
on a linguistic plane with a performance trajectory. Non-
linear multilevel relay property is indicated as the
intrinsic feature of fuzzy logic controllers. The
computer simulations and laboratory experiments indicate
that the fuzzy logic controllers perform better than
conventional PID controllers.
Fuzzy model identification is the base to establish the
initial rule set for self-tuning fuzzy logic
controllers. It includes delay time determination and
fuzzy parameter estimation. An artificial neural network
is used as a mapping function to determine the delay
time for a HVAC plant. The neural network has a feed-
forward data flow mode and uses General Delta Rule as a
back-propagation learning algorithm. In this study, an
acceleration technique is proposed to improve the
General Delta Rule. A linguistic identification method
is developed to estimate fuzzy parameters for the
controlled plant.
A self-tuning strategy is proposed in this study as an
extension of simple fuzzy logic controllers to avoid the
laborious task of adjusting fuzzy logic controllers. A
desired optimal performance trajectory is used as a
control model. The deviation of actual performance
trajectory from the desired one is used to improve the
fuzzy logic controllers. The detailed performance
measurement and modification procedure are developed.
The self-tuning algorithm has been successfully verified
in experiments.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  2645 </NUMBER>
<ORDER>   AAG9502765 </ORDER>
<TITLE> A STUDY OF SOIL COMPACTION WITH MINIATURE SHEEPS-FOOT ROLLERS AND DEVELOPMENT OF A KNOWLEDGE-BASED SYSTEM </TITLE>
<AUTHOR> KOTDAWALA, SHRINATH JAYANT </AUTHOR>
<YEAR> 1994 </YEAR>
<INSTITUTION> KANSAS STATE UNIVERSITY; 0100 </INSTITUTION>
<DESCRIPTORS> ENGINEERING, CIVIL; APPLIED MECHANICS; GEOTECHNOLOGY; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> MUSTAQUE HOSSAIN </ADVISER>
<CLASSIFICATIONS> NIL </CLASSIFICATIONS>
<ABSTRACT>
Earthwork and ground modification are the most
voluminous construction jobs. Both processes require
soil compaction. The design, planning and execution of
compaction involve use of soil compactors and results of
laboratory-based standard Proctor test or other similar
test. The inherent differences between laboratory-based
soil compaction tests, developed in the early thirties,
and contemporary roller-based compaction in the field,
may result in an inferior end product. A close
simulation of the field compaction process can be
achieved by using miniature sheep-foot rollers in the
laboratory. Such rollers simulate the kneading action of
soil compaction in the field more realistically. Also,
kneading action of the miniature rollers generate a
higher degree of saturation than the standard Proctor
test at the optimum moisture content in the compacted
soil.
To ensure the required degree of compaction in the
field, control of the compaction process is essential.
In addition, instant control of dynamic variables in the
field, such as soil moisture, compactive effort, soil
type, roller type and specifications of contract needs
some expertise for an efficient compaction process.
Since the cost of hiring an expert at every site is
high, a knowledge-based expert system is useful for
guiding the field compaction processes. Acquisition of
knowledge from the experts in the field is possible
through interviews and interpretation of published
information. The acquired information can be
restructured to an expert system using logical rule-
based decision making. This system along with the
databases of soil properties and rollers can help in
evaluating guiding strategies for efficient compaction.
The outputs from such systems can be lift thickness,
number of roller passes, speed of compaction, moisture
content of the soil, solutions to compaction problems
and guidelines to meet the regulations of compaction
practices mandated by the contracting agencies.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  2646 </NUMBER>
<ORDER>   AAINN01287 </ORDER>
<TITLE> COMBINATION OF MULTIPLE CLASSIFIERS FOR THE RECOGNITION OF TOTALLY UNCONSTRAINED HANDWRITTEN NUMERALS </TITLE>
<AUTHOR> HUANG, YEA-SHUAN </AUTHOR>
<YEAR> 1994 </YEAR>
<INSTITUTION> CONCORDIA UNIVERSITY (CANADA); 0228 </INSTITUTION>
<DESCRIPTORS> COMPUTER SCIENCE; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> C. Y. SUEN </ADVISER>
<CLASSIFICATIONS> NEURAL NETWORKS </CLASSIFICATIONS>
<ABSTRACT>
Due to different writing styles and various kinds of
noise, the recognition of hand-written numerals is an
extremely challenging problem. Recently, a new approach
has emerged to tackle this problem by the use of
multiple classifiers. This method is called "Combination
of Multiple Experts" (CME). It combines individual
classification decisions to derive the final decisions.
This thesis focuses on methodologies which lead to
efficient and effective decision combination schemes.
In general, the output information supplied by various
classifiers can be divided into two levels: (1) The
abstract level: a classifier only outputs a unique
class; and (2) The measurement level: a classifier
assigns a measurement value to each class to indicate
how closely a certain class corresponds to the input
pattern. Because of the different nature of the two
levels of output information (one is discrete and
finite, and the other one is continuous and infinite),
intrinsically there are two kinds of combination
approaches: abstract-level CME and measurement-level
CME.
For abstract-level CME, a novel combination model is
proposed, i.e., the Behavior-Knowledge Space (BKS)
method. Many advantageous properties have been derived
from this method: most importantly, in theory the BKS
method is able to produce the highest recognition
accuracy for the combination of abstract-level
classifiers. For measurement-level CME, individual
classifiers can be regarded as feature extractors. A
neural network approach based on a multi-layer
perceptron is proposed to perform the combination
function, because the multi-layer perceptron has been
shown to be effective in solving various pattern
recognition problems. Strategies on improving multi-
layer perceptrons are presented.
Since the basic components of a multi-classifier system
are the classifiers, it is essential to construct
classifiers with high recognition accuracy. In this
research, two directions are taken to pursue this goal.
The first is to apply the concept of CME to design new
classifiers by using subsets of a large set of features.
The second is to improve the recognition accuracy of the
commonly-used nearest neighbor classifier by finding
better representative prototypes. Obviously, the new
classifier design techniques and the improvement of
existing classifiers will further strengthen CME.
The efficiency of the proposed methods has been
demonstrated in a series of experiments with a large
data base of handwritten numerals. The results indicate
that a multi-classifier recognition system outperforms
the individual classifiers, and is able to achieve a
very high recognition performance. It appears,
therefore, that CME is a promising avenue to develop
human-compatible and highly reliable OCR machines.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  2647 </NUMBER>
<ORDER>   AAG9502765 </ORDER>
<TITLE> A STUDY OF SOIL COMPACTION WITH MINIATURE SHEEPS-FOOT ROLLERS AND DEVELOPMENT OF A KNOWLEDGE-BASED SYSTEM </TITLE>
<AUTHOR> KOTDAWALA, SHRINATH JAYANT </AUTHOR>
<YEAR> 1994 </YEAR>
<INSTITUTION> KANSAS STATE UNIVERSITY; 0100 </INSTITUTION>
<DESCRIPTORS> ENGINEERING, CIVIL; APPLIED MECHANICS; GEOTECHNOLOGY; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> MUSTAQUE HOSSAIN </ADVISER>
<CLASSIFICATIONS> NIL </CLASSIFICATIONS>
<ABSTRACT>
Earthwork and ground modification are the most
voluminous construction jobs. Both processes require
soil compaction. The design, planning and execution of
compaction involve use of soil compactors and results of
laboratory-based standard Proctor test or other similar
test. The inherent differences between laboratory-based
soil compaction tests, developed in the early thirties,
and contemporary roller-based compaction in the field,
may result in an inferior end product. A close
simulation of the field compaction process can be
achieved by using miniature sheep-foot rollers in the
laboratory. Such rollers simulate the kneading action of
soil compaction in the field more realistically. Also,
kneading action of the miniature rollers generate a
higher degree of saturation than the standard Proctor
test at the optimum moisture content in the compacted
soil.
To ensure the required degree of compaction in the
field, control of the compaction process is essential.
In addition, instant control of dynamic variables in the
field, such as soil moisture, compactive effort, soil
type, roller type and specifications of contract needs
some expertise for an efficient compaction process.
Since the cost of hiring an expert at every site is
high, a knowledge-based expert system is useful for
guiding the field compaction processes. Acquisition of
knowledge from the experts in the field is possible
through interviews and interpretation of published
information. The acquired information can be
restructured to an expert system using logical rule-
based decision making. This system along with the
databases of soil properties and rollers can help in
evaluating guiding strategies for efficient compaction.
The outputs from such systems can be lift thickness,
number of roller passes, speed of compaction, moisture
content of the soil, solutions to compaction problems
and guidelines to meet the regulations of compaction
practices mandated by the contracting agencies.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  2648 </NUMBER>
<ORDER>   AAG9433920 </ORDER>
<TITLE> REPRESENTING PHYSICAL AND DESIGN KNOWLEDGE IN INNOVATIVE DESIGN  </TITLE>
<AUTHOR> SGOUROS, NIKITAS MARINOS </AUTHOR>
<YEAR> 1994 </YEAR>
<INSTITUTION> NORTHWESTERN UNIVERSITY; 0163 </INSTITUTION>
<DESCRIPTORS> COMPUTER SCIENCE; ARTIFICIAL INTELLIGENCE; ENGINEERING, CHEMICAL </DESCRIPTORS>
<ADVISER> KENNETH D. FORBUS </ADVISER>
<CLASSIFICATIONS> SEPARATION SYSTEMS, INTELLIGENT ARTIFACTS </CLASSIFICATIONS>
<ABSTRACT>
The ability to design is one of the hallmarks of
intelligent behavior, since it allows an agent to shape
its environment according to its needs. Therefore
developing computational models of design should be one
of the primary goals for a discipline such as Artificial
Intelligence that aims to create intelligent artifacts.
This thesis describes DIAS, a computational framework
for innovative engineering design. This framework
provides ways for representing the physical and design
knowledge in a domain, along with methods for allowing
these different types of knowledge to interact during
the design process. This model has been instantiated in
OUZO, a program that designs separation systems in
chemical engineering.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  2649 </NUMBER>
<ORDER>   AAG9502576 </ORDER>
<TITLE> AN ARTIFICIAL INTELLIGENCE APPLICATION OF BACKPROPAGATION NEURAL NETWORKS TO SIMULATE ACCOUNTANTS' ASSESSMENTS OF INTERNAL CONTROL SYSTEMS USING COSO GUIDELINES </TITLE>
<AUTHOR> O'CALLAGHAN, SUSANNE </AUTHOR>
<YEAR> 1994 </YEAR>
<INSTITUTION> UNIVERSITY OF CINCINNATI; 0045 </INSTITUTION>
<DESCRIPTORS> BUSINESS ADMINISTRATION, ACCOUNTING; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> J. TIMOTHY SALE </ADVISER>
<CLASSIFICATIONS> NIL </CLASSIFICATIONS>
<ABSTRACT>
The objective of this study was to explore a form of
artificial intelligence, neural network modelling, to
examine variables that are crucial to technological
implementation in accounting settings. The experiment
utilized an accounting framework, assessing internal
controls under COSO guidelines.
The results of this experiment suggest that a neural
network model can be developed such that the decision
processes of external auditors in assessing internal
controls can be reasonably modelled. A significant
difference exists between the classification precision
of network models (a) using one hidden layer as opposed
to two hidden layers, (b) between models with differing
configurations of neurons within the hidden layer(s) and
(c) a regression model for certain conditions.
A study of the incorrect decisions made by a neural
network indicates that while reliance on a network would
result in making some incorrect decisions, the threat of
over-relying on internal controls is not extremely high.
By eliminating noise in the research instrument, a
network can be modelled that will be able to predict a
higher number of correct assessments than was possible
with the full experimental model.
A sensitivity analysis revealed that none of the five
COSO inputs individually has an extreme effect on the
neural network's ability to make internal control
assessments. Self assessments by auditors who rate
themselves as experts reveals that their models have a
higher prediction rate at assessing internal controls
than does the network developed from responses of lower
self-assessed experts. Analysis reveals that auditors
are extremely conservative in their response, especially
in assessing controls over compliance with rules and
regulations. Neural networks that were developed using
effectiveness of internal controls as an outcome
measure, had higher accuracy predictions than networks
developed using quality of internal controls as an
outcome measure.
This research demonstrates the usefulness of applying a
neural network paradigm in assessing the effectiveness
of internal control systems.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  2650 </NUMBER>
<ORDER>   AAG1358258 </ORDER>
<TITLE> FUZZY LOGIC CONTROL FOR A LIFTING MACHINE </TITLE>
<AUTHOR> OSQUEEZADEH, MASOUD </AUTHOR>
<YEAR> 1994 </YEAR>
<INSTITUTION> UTAH STATE UNIVERSITY; 0241 </INSTITUTION>
<DESCRIPTORS> ENGINEERING, ELECTRONICS AND ELECTRICAL; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> ROBERT GUNDERSON </ADVISER>
<CLASSIFICATIONS> NIL </CLASSIFICATIONS>
<ABSTRACT>
Weight training is slowly being transferred from regular
gyms to homes, where individuals usually train alone.
Regular home gyms in the market today do not satisfy
most professional trainers' recommendation that a
partner must be present during weight-lifting exercises.
A new weight machine that can help "spot" the trainee is
needed to provide this "partner." This new machine would
be the first in a new generation of fitness equipment.
This thesis investigates the feasibility of applying a
fuzzy algorithm in a microcontroller-based DC motor
controller to simulate the free weight and the partner.
Such a machine would help a user enjoy most, if not all,
of the privileges he or she would receive in a regular
gym.
Fuzzy logic controllers are a relatively new development
in control systems technology. They would appear to have
their best application in cases in which the objective
is to develop control characteristics that are close to
those achievable by a human operator. Although fuzzy
logic may seem to imply imprecision, it is based on a
reliable and rigorous discipline. So far as the author
is aware, no one has connected the need for the human-
like control qualities of the "spotter" with the newly
emerging technology offered by fuzzy logic.
This new machine was designed around a permanent magnet
DC motor run by a constant current source. Fuzzy
algorithms were used to control the motor and to provide
an intelligent "partner." Fuzzy rules were simplified to
allow usage of a look-up table that was implemented with
an 8-bit microcontroller, Microchip's PIC16C57. The
complete unit was then tested, with very satisfactory
results, and tuned for optimal performance.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  2651 </NUMBER>
<ORDER>   AAG1358242 </ORDER>
<TITLE> PARTIAL AUTOMATION OF FEATURE SELECTION IN A NEURAL NETWORK PATTERN CLASSIFIER </TITLE>
<AUTHOR> KO, YOUNG JUNE </AUTHOR>
<YEAR> 1994 </YEAR>
<INSTITUTION> UNIVERSITY OF LOWELL; 0111 </INSTITUTION>
<DESCRIPTORS> PHYSICS, OPTICS; COMPUTER SCIENCE; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> RICHARD W. STIMETS </ADVISER>
<CLASSIFICATIONS> NIL </CLASSIFICATIONS>
<ABSTRACT>
In pattern classifier the features are usually generated
by a knowledgeable and experienced human observer. In
this work we attempted to create a pattern classifier
for fish outlines in which the features were generated
automatically based on general criteria such as
symmetry, convexity versus concavity, and reliability of
dominant points on the boundary. The feature generator
generated eight features initially which were reduced to
six based on criteria of estimated correct
classification and low correlation with other features.
During the learning of the neural network, the six
remaining features were used and the weights and biases
in the network were modified through less than 2000
iterations. The trained network was tested with one
hundred 5% noisy patterns (test patterns) generated for
each species of fish.
In this research, we achieved an average correct
classification of 89.3%.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  2652 </NUMBER>
<ORDER>   AAG1357851 </ORDER>
<TITLE> DESIGN OF A FUZZY LOGIC CONTROL SYSTEM FOR BIAXIAL EXTRUSION THICKNESS GAUGING </TITLE>
<AUTHOR> MCNABB, JOHN C. </AUTHOR>
<YEAR> 1994 </YEAR>
<INSTITUTION> UNIVERSITY OF LOWELL; 0111 </INSTITUTION>
<DESCRIPTORS> PLASTICS TECHNOLOGY; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> NICK R. SCHOTT </ADVISER>
<CLASSIFICATIONS> NIL </CLASSIFICATIONS>
<ABSTRACT>
Three typical approaches for controlling the flatness of
polystyrene or polypropylene on a biaxially oriented
line by a beta gauge are examined based upon control of
product flatness, simplicity, and cost. A new approach
is developed using the best features of each while
improving other features.
The new approach uses a downstream Krypton beta gauge, a
downstream data to die bolt alignment algorithm, and a
fuzzy logic controller to control the flatness of the
product. The downstream data to die bolt alignment
algorithm assigns downstream measured product to a
particular die bolt on the die. The alignment uses nylon
line placed inside the product in 5 zones. The beta
gauge detects the nylon line and determines the
stretching in each zone. Accurate alignment of
downstream product to die bolt is achieved. The fuzzy
logic controller adjusts PID loop control gains and
outputs a product flatness control correction signal to
the die bolts.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  2653 </NUMBER>
<ORDER>   AAG1357713 </ORDER>
<TITLE> MINIATURIZED FACTORY FOR GLOBAL MANUFACTURING </TITLE>
<AUTHOR> STEPHENS, CRAIG PETER </AUTHOR>
<YEAR> 1994 </YEAR>
<INSTITUTION> CALIFORNIA STATE UNIVERSITY, LONG BEACH; 6080 </INSTITUTION>
<DESCRIPTORS> ENGINEERING, INDUSTRIAL; ENGINEERING, HEAT AND THERMODYNAMICS </DESCRIPTORS>
<ADVISER> ROBERT J. KUNST </ADVISER>
<CLASSIFICATIONS> NIL </CLASSIFICATIONS>
<ABSTRACT>
The purpose of this study was to design a full sized
factory, miniaturized to a model mechatronic workcell.
Factory technology, and miniaturization processes were
reviewed in four areas of technology/ information as:
material science/natural resources, education/culture,
information systems/artificial intelligence, and
robotics/technology.
This study concluded that current technology to
implement miniaturized mechatronic factories was
possible. Further studies are required to explore why
this manufacturing advantage has yet to be fully
exploited for competition globally.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  2654 </NUMBER>
<ORDER>   AAG1357516 </ORDER>
<TITLE> DISTRIBUTED ARTIFICIAL INTELLIGENCE </TITLE>
<AUTHOR> ANDRE, LEE MCBENNETT </AUTHOR>
<YEAR> 1994 </YEAR>
<INSTITUTION> CALIFORNIA STATE UNIVERSITY, LONG BEACH; 6080 </INSTITUTION>
<DESCRIPTORS> COMPUTER SCIENCE; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> DAR-BIAU LIU </ADVISER>
<CLASSIFICATIONS> NIL </CLASSIFICATIONS>
<ABSTRACT>
Distributed artificial intelligence (DAI) represents the
combination of artificial intelligence (AI) design
techniques and applications with the field of
distributed systems. By combining AI with distributed
systems, a unique perspective is generated on
cooperating, semi-autonomous agents working together to
solve a single problem. The Hearsay-II project, the PUP6
testbed and the Contract Net experiment represent three
influential DAI architectures that changed the
development of the DAI field at different stages early
in its development. Six dimensions of DAI exist. The
first three dimensions are the distribution of data,
processing and control. The last three dimensions are
organizational decomposition, task versus result sharing
and product versus functional decomposition. Newer
developments within the field are typified by the
distributed knowledge object model (DKOM) and by
research focused on fundamental properties of DAI.
Recent research and development indicates the importance
of three aspects of DAI systems: mapping of sub-problems
to nodes to ensure efficient problem solving with
minimal communication; a communications architecture
that encourages global coherency; and a communications
protocol to facilitate high-level, efficient messaging
between nodes.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  2655 </NUMBER>
<ORDER>   AAINN00171 </ORDER>
<TITLE> EMERGENT INTELLIGENCE IN A DISTRIBUTED ADAPTIVE CONTROL SYSTEM </TITLE>
<AUTHOR> DIGNEY, BRUCE LEONARD </AUTHOR>
<YEAR> 1994 </YEAR>
<INSTITUTION> THE UNIVERSITY OF SASKATCHEWAN (CANADA); 0780 </INSTITUTION>
<DESCRIPTORS> ENGINEERING, ELECTRONICS AND ELECTRICAL; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> M. M. GUPTA </ADVISER>
<CLASSIFICATIONS> ROBOTICS, ARTIFICIAL INTELLIGENCE </CLASSIFICATIONS>
<ABSTRACT>
A method is presented in this thesis whereby
reinforcement learning can be incorporated into a
behavioral based control system for mobile robotic
applications. In many situations the skills and
behaviors required by the robot for productive operation
and survival are impractical or impossible to
predetermine and embed within the robot's control
systems. In this method developed in this research, such
skills and behaviors are automatically learned through
self-exploration and self-organization using an
incremental dynamic programing technique. Conventional
predetermined responses are replaced with the learned
responses form the Adaptive Behavior Modules (ABMs)
developed in this thesis. These ABMs are capable of the
autonomous discovery and learning of useful skills
through unaided interaction within the environment. The
robotic control system is distributed over many
interacting behavioral levels with and ABM responsible
for learning the sensory-response couplings at each
behavioral level. Each behavioral level is established
through its sensory and reinforcement signal connections
with the environment. When these ABMs and low level
actuator systems are assembled using command and
reinforcement connections into an adaptive framework,
what is referred to as a Distributed Adaptive Control
System (DACS) results. This DACS can be considered as
the robot's artificial adaptive nervous system. The
resulting self-learning and self-repairing DACS is
capable of controlling a mobile robot within the bounds
established by the robot's physical and sensory
configurations.
Within the DACS framework learning is accomplished, not
with an external teacher suppling direction, but by
using goal, environmental and sensory based
reinforcements inherently available through the robot's
interactions with the environment. The operating
characteristics of the robot are then dependent upon the
particular environmental conditions in which the robot
finds itself and not on the preconceived notions of a
human designer. Cooperative and collective behaviors
within populations of robots are shown as extensions of
the DACS framework.
The complex nature of the unaided interactions of a
mobile robot within its surrounding environment
prevented in this research all but the basic analytical
studies. For this reason the proposed DACS method was
studied using a simulated quadrupled mobile robot.
Useful skills and behaviors were found to emerge at all
behavioral levels as they were autonomously discovered
and learned. When confronted with unforeseeable changes
and malfunctions, the DACS framework was affected to
various extents depending upon the severity of the
changes. The DACS adapted either the single behavioral
level at the origin of the change or other higher
behavioral levels as required in response to more sever
changes.
Although this research was performed in the context of
mobile robots, the principles developed in this thesis
might be applied to areas such as process control,
flexible manufacturing, power transmission and
communication systems. (Abstract shortened by UMI.)
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  2656 </NUMBER>
<ORDER>   AAG1357516 </ORDER>
<TITLE> DISTRIBUTED ARTIFICIAL INTELLIGENCE </TITLE>
<AUTHOR> ANDRE, LEE MCBENNETT </AUTHOR>
<YEAR> 1994 </YEAR>
<INSTITUTION> CALIFORNIA STATE UNIVERSITY, LONG BEACH; 6080 </INSTITUTION>
<DESCRIPTORS> COMPUTER SCIENCE; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> DAR-BIAU LIU </ADVISER>
<CLASSIFICATIONS> NIL </CLASSIFICATIONS>
<ABSTRACT>
Distributed artificial intelligence (DAI) represents the
combination of artificial intelligence (AI) design
techniques and applications with the field of
distributed systems. By combining AI with distributed
systems, a unique perspective is generated on
cooperating, semi-autonomous agents working together to
solve a single problem. The Hearsay-II project, the PUP6
testbed and the Contract Net experiment represent three
influential DAI architectures that changed the
development of the DAI field at different stages early
in its development. Six dimensions of DAI exist. The
first three dimensions are the distribution of data,
processing and control. The last three dimensions are
organizational decomposition, task versus result sharing
and product versus functional decomposition. Newer
developments within the field are typified by the
distributed knowledge object model (DKOM) and by
research focused on fundamental properties of DAI.
Recent research and development indicates the importance
of three aspects of DAI systems: mapping of sub-problems
to nodes to ensure efficient problem solving with
minimal communication; a communications architecture
that encourages global coherency; and a communications
protocol to facilitate high-level, efficient messaging
between nodes.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  2657 </NUMBER>
<ORDER>   AAG9501980 </ORDER>
<TITLE> ON DESIGNING AN AI BASED GENERIC SCHEDULING FRAMEWORK </TITLE>
<AUTHOR> SRINIVASAN, VENKATESH </AUTHOR>
<YEAR> 1994 </YEAR>
<INSTITUTION> CASE WESTERN RESERVE UNIVERSITY; 0042 </INSTITUTION>
<DESCRIPTORS> COMPUTER SCIENCE; ENGINEERING, INDUSTRIAL; OPERATIONS RESEARCH; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> LEON STERLING </ADVISER>
<CLASSIFICATIONS> JOB SHOP </CLASSIFICATIONS>
<ABSTRACT>
This thesis provides an answer to a question of
practical significance: "Can a generic scheduler be
designed that would significantly shorten the
development time of individual schedulers?" In response
this thesis presents a generic scheduling framework
which makes it easier for scheduler developers to build
customized scheduling applications, and provides end
users a quick and easy means to test and implement new
scheduling strategies.
The scheduling framework is organized as a collection of
scheduler clusters where each scheduler cluster
represents a class of schedulers solving related
problems. Jobshop, transportation, timetabling, and
process plant scheduler clusters are examples of
scheduler clusters that are presented in great detail in
this thesis, and specific schedulers namely carshop
scheduler, tanker scheduler, examination scheduler,
blending scheduler have been developed by instantiating
the appropriate scheduler cluster following a systematic
approach proposed in this thesis. The generic scheduler
is essentially a generate and test system which resides
behind an extensive user interface. During schedule
generation, resources are allocated to tasks
iteratively. Each iteration consists of choosing a task
to be scheduled, choosing appropriate resources to be
allocated, allocation of resources to tasks followed by
constraint propagation which affects the remaining
unscheduled tasks. This basic scheduling strategy is
common to all schedulers developed within the framework.
Sample empirical results for three scheduler instances
namely jobshop, transportation and timetabling are
provided, these results show how the quality of the
schedule generated depends on the problem instance, and
choice of task and resource selection heuristics.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  2658 </NUMBER>
<ORDER>   AAG9501714 </ORDER>
<TITLE> KNOWLEDGE BASE ACQUISITION FOR A JAPANESE LANGUAGE INTELLIGENT TUTORING SYSTEM </TITLE>
<AUTHOR> KANG, YUN-SUN </AUTHOR>
<YEAR> 1994 </YEAR>
<INSTITUTION> PURDUE UNIVERSITY; 0183 </INSTITUTION>
<DESCRIPTORS> ENGINEERING, ELECTRONICS AND ELECTRICAL; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> ANTHONY A. MACIEJEWSKI </ADVISER>
<CLASSIFICATIONS> NIL </CLASSIFICATIONS>
<ABSTRACT>
This work describes the development of a student model
that is used in a Japanese language intelligent tutoring
system to assess a pupil's proficiency at reading
technical Japanese. One of the goals of this work is to
develop a model representing a student's proficiency in
reading one of the distinct orthographies of Japanese,
known as katakana. While the effort required to memorize
the relatively few katakana symbols and their associated
pronunciations is not prohibitive, a major difficulty in
reading katakana is associated with the phonetic
modifications which occur when English words which are
transliterated into katakana are made to conform to the
more restrictive rules of Japanese phonology. To
accomplish this goal an algorithm is first developed to
automatically generate a katakana to English dictionary
from raw Japanese text and its English translation. This
dictionary is then used as input into a second algorithm
that is used to generate the phonological rules that
govern the transformations that English words undergo
when being transliterated into katakana. This set of
phonological transformation rules is treated as the
domain knowledge base that the student must acquire in
order to become proficient at reading katakana. A
student model is designed to assess a student's
proficiency, and then appropriately individualize the
student's instruction.
The other goal of this work is to develop a model
representing a student's proficiency in the grammar
associated with reading technical Japanese. To
accomplish this goal, first, a computer-assisted
knowledge acquisition system is developed to generate a
domain knowledge base that represents a model of the
syntactical knowledge that a native English speaker must
acquire in order to be proficient at reading technical
Japanese. These rules are used as the domain knowledge
base against which a student's performance is measured.
A student model is designed to assess a student's
competence of the Japanese grammar, and to individualize
the instruction of an intelligent tutoring system.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  2659 </NUMBER>
<ORDER>   AAG9501447 </ORDER>
<TITLE> THE THEORETICAL ANALYSIS OF ART NEURAL NETWORKS AND THEIR APPLICATION IN FREQUENCY SELECTIVE SURFACES </TITLE>
<AUTHOR> HUANG, JUXIN </AUTHOR>
<YEAR> 1994 </YEAR>
<INSTITUTION> UNIVERSITY OF CENTRAL FLORIDA; 0705 </INSTITUTION>
<DESCRIPTORS> BIOLOGY, NEUROSCIENCE; ENGINEERING, ELECTRONICS AND ELECTRICAL; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> MICHAEL GEORGIOPOULOS </ADVISER>
<CLASSIFICATIONS> NIL </CLASSIFICATIONS>
<ABSTRACT>
Artificial neural networks have attracted considerable
attention in the past few years. Nevertheless, more work
needs to be done on the theoretical analysis of the
network behaviors. An important class of self-organizing
neural network models--ART (Adaptive Resonance Theory)
is analyzed in this dissertation. Our results answer
questions such as: How many epochs are needed for a
specific ART model to learn a list of input patterns?
How do the network parameters affect the learning
properties? What is the maximum size of the network
needed to learn a list of patterns? In particular, we
have analyzed ART1, which clusters arbitrary binary
patterns in an unsupervised fashion, Fuzzy ART, which
clusters arbitrary analog or binary patterns also in an
unsupervised fashion; ARTMAP, which learns any
classification of binary patterns in a supervised
fashion. Our extensive analysis provides many insights
on how these networks operate.
Furthermore, a real world application dealing with the
frequency selective surfaces (FSS) is performed. The
problem is to derive the appropriate FSS parameters
which would yield the desired frequency response. We
have investigated four approaches: (1) Back-prop
inversion algorithm. (2) Back-prop with the input-output
reversed. (3) Fuzzy ARTMAP. (4) Modified Fuzzy ARTMAP.
Approaches (2)-(4) are novel in the FSS design. The
simulation results show that the modified Fuzzy ARTMAP
always performs the best and Fuzzy ARTMAP performs
better than back-prop based approaches.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  2660 </NUMBER>
<ORDER>   AAG9500986 </ORDER>
<TITLE> HEURISTIC SEARCH AND ITS TRANSIT APPLICATIONS </TITLE>
<AUTHOR> LIAW, CHING-FANG </AUTHOR>
<YEAR> 1994 </YEAR>
<INSTITUTION> THE UNIVERSITY OF MICHIGAN; 0127 </INSTITUTION>
<DESCRIPTORS> ENGINEERING, INDUSTRIAL; OPERATIONS RESEARCH; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> CHELSEA C. WHITE </ADVISER>
<CLASSIFICATIONS> ROUTING, SCHEDULING </CLASSIFICATIONS>
<ABSTRACT>
This dissertation is concerned with the development,
analysis, and application of solution techniques for any
discrete optimization problem that can be represented by
a locally finite graph. These solution techniques are
based on heuristic search procedures from the artificial
intelligence (AI) literature. Application is made to the
problem of scheduling and routing paratransit vehicles
in an intermodal itinerary selection problem involving
fixed-route buses.
Relevant background on heuristic search theory is
presented. We then investigate a multiobjective
generalization of AO*, an important AI-based AND/OR
graph search algorithm. Similar to AO*, this
generalization is found to be complete and admissible
under appropriately adjusted assumptions. Other relevant
properties of this generalization that are considered
include termination, comparison of heuristics, and
efficiency. We also develop two new OR graph search
algorithms, BA* and DA*, which are both extensions of
A*. Under reasonable conditions, these two algorithms
find a minimum cost path from the start node to a finite
goal node set in a directed OR graph, assuming that
estimates of the optimal costs from each node to the
goal node set are given, estimates of all arc costs are
given, but that actual arc costs require determination.
Characteristics of these two algorithms and results
concerning the comparison of these two algorithms are
presented.
A complex vehicle routing and scheduling problem, called
the multimodal dial-a-ride problem, is defined in this
dissertation. A multimodal dial-a-ride problem is a dial-
a-ride problem that involves both paratransit vehicles
and fixed route buses. We develop a solution procedure
for the multimodal dial-a-ride problem by integrating
heuristic search techniques with simulated annealing, a
solution technique for combinatorial optimization
problems. Computational experience with simulated data
and real data is provided. Finally, some extensions to
the work reported in this dissertation and possible
directions for future research are discussed.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  2661 </NUMBER>
<ORDER>   AAG9500644 </ORDER>
<TITLE> TRANSPARENTLY-MOTIVATED METAPHOR GENERATION </TITLE>
<AUTHOR> JONES, MARK ALAN </AUTHOR>
<YEAR> 1994 </YEAR>
<INSTITUTION> UNIVERSITY OF DELAWARE; 0060 </INSTITUTION>
<DESCRIPTORS> COMPUTER SCIENCE; LANGUAGE, LINGUISTICS; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> KATHLEEN MCCOY </ADVISER>
<CLASSIFICATIONS> NIL </CLASSIFICATIONS>
<ABSTRACT>
This dissertation is the first attempt at generating
metaphors in a general manner. It introduces and defines
the class of transparently-motivated (T-M) metaphor, and
describes a method for generating them via a set of top-
down rules that transform a literal expression into one
containing a T-M metaphor. Our aim is to provide a
generation system with the same conceptual groundings
that people often use to communicate. This approach is
strongly motivated by several fields of study, including
the fields that comprise cognitive science: linguistics,
computer science, psychology, and philosophy. Because of
this motivation, this dissertation is the first to
investigate the uses for metaphor from the point of view
of the natural language generation paradigm. This work
introduces a computational approach to provide
additional metaphorical options for a text planner to
express itself so that the text generated will be easier
for the reader to comprehend. We show these metaphors
can be used to achieve specific textual goals for
natural language generation (i.e., manipulating focus of
attention, and increasing comprehensibility). A computer
implementation which embodies many of the ideas in this
work, called Quipper, is described in detail.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  2662 </NUMBER>
<ORDER>   AAG9500319 </ORDER>
<TITLE> A COMPUTATIONAL MODEL OF AUDITORY PATTERN RECOGNITION </TITLE>
<AUTHOR> ANDERSON, SVEN ERIC </AUTHOR>
<YEAR> 1994 </YEAR>
<INSTITUTION> INDIANA UNIVERSITY; 0093 </INSTITUTION>
<DESCRIPTORS> COMPUTER SCIENCE; LANGUAGE, LINGUISTICS; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> ROBERT F. PORT </ADVISER>
<CLASSIFICATIONS> SPEECH </CLASSIFICATIONS>
<ABSTRACT>
Auditory perception builds on the ability of the nervous
system to perceive sequential cues in an unsegmented,
unending stream of acoustic stimulation. The development
of sequential pattern recognition abilities is not
entirely the result of genetic specification; rather, it
is shaped by auditory experience. This report develops
and tests principles that enable an artificial neural
network to structure itself to detect the most salient
sequences in its sound environment.
The network comprises clusters of units connected by
time-delayed lateral excitatory connections. Over time,
adaptive mechanisms cause individual units in the
network to become sensitive to particular sequential
patterns. Units within each cluster compete to encode
patterns within their initial receptive fields.
Connection strengths between units adapt to reflect
statistically important dynamic features present in the
environment. In the resultant network, these connections
support real-time sequence recognition. A network of two
such sub-networks is shown to learn more complex
sequential patterns. Levels of the network farther from
the periphery learn to segment and encode increasingly
complex patterns using the features developed by earlier
sub-networks.
The model's performance is evaluated by exposing a two-
layer network to a small set of English stop-vowel
syllables. Each layer develops units of increasing
selectivity. The first layer develops units sensitive to
upward and downward frequency modulations. The second
layer develops units that are selective for complex
auditory features. It is argued that these feature
detectors may be useful to auditory pattern recognition.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  2663 </NUMBER>
<ORDER>   AAG9434585 </ORDER>
<TITLE> ENTROPY-BASED RELIABILITY ASSESSMENT FOR INTELLIGENT MACHINES </TITLE>
<AUTHOR> MUSTO, JOSEPH C. </AUTHOR>
<YEAR> 1994 </YEAR>
<INSTITUTION> RENSSELAER POLYTECHNIC INSTITUTE; 0185 </INSTITUTION>
<DESCRIPTORS> ENGINEERING, MECHANICAL; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> GEORGE N. SARIDIS; STEPHEN J. DERBY </ADVISER>
<CLASSIFICATIONS> NIL </CLASSIFICATIONS>
<ABSTRACT>
Intelligent machines and systems are often called upon
to perform high precision tasks in uncertain
environments. If such a system can be expected to
function autonomously, the high-level control system
must be capable of synthesizing and evaluating the most
reliable system design alternative for execution of a
high-precision task. This requires the ability to
identify and evaluate the uncertainties which plague the
system, and assess the impact of each uncertainty on the
execution of the desired task. Through the judicious
selection of appropriate control variables, the effects
of these uncertainties can be minimized, and more
reliable task execution can be achieved. Selection of an
alternative which minimizes the effect of uncertainties
and satisfies the desired performance characteristics is
done through optimization of some metric which describes
the performance of the system. In this thesis, a new
cost metric for performance assessment of Intelligent
Machines has been developed. The method fuses concepts
from the Theory of Intelligent Machines proposed by
Saridis with traditional reliability analysis in the
development of a cost function which reflects both the
uncertainty inherent in the Intelligent Machine and the
uncertainty allowed by the task description. The cost
function is entropy based, and can be shown to be
analogous to a measure of system reliability. In
addition, this function can be used to develop a loose-
bound measure of system performance, where the design of
a system and the design of a proposed task can be
decoupled. Techniques for utilizing this entropy-based
analysis in the design of intelligent systems have been
developed, and demonstrated in a case study involving a
robotic assembly system.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  2664 </NUMBER>
<ORDER>   AAG9434502 </ORDER>
<TITLE> DISTRIBUTED SEARCH AND CONFLICT MANAGEMENT AMONG REUSABLE HETEROGENEOUS AGENTS </TITLE>
<AUTHOR> LANDER, SUSAN ELLEN </AUTHOR>
<YEAR> 1994 </YEAR>
<INSTITUTION> UNIVERSITY OF MASSACHUSETTS; 0118 </INSTITUTION>
<DESCRIPTORS> COMPUTER SCIENCE; ENGINEERING, MECHANICAL; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> VICTOR R. LESSER </ADVISER>
<CLASSIFICATIONS> NIL </CLASSIFICATIONS>
<ABSTRACT>
The current state of knowledge-based technology is such
that most application systems are built from scratch. In
order to move beyond the prohibitive cost of constantly
reinventing, rerepresenting, and reimplementing the
wheel, researchers are beginning to examine the
feasibility of building application systems with
heterogeneous and reusable agents. In this dissertation,
we explore a comprehensive model of distributed-search
systems comprising multiple agents where each agent is a
complete and independent system that represents a
specific area of expertise. Our approach acknowledges
the inevitability of conflict among the agents, and
exploits that conflict to drive agent interaction and
guide local search.
A primary objective of the research is to understand how
to build distributed-search systems that can integrate
multiple heterogeneous computational agents. These
systems must be able to: (1) solve large-scale problems;
(2) take advantage of knowledge embodied in existing
reusable agents; (3) effectively coordinate the actions
of agents to achieve efficient and coherent problem
solving; and (4) effectively manage conflicts among
agents, allowing them to find high-quality solutions
despite inherent inconsistency. A second objective is to
understand how to build expert reusable computational
agents that (1) use the most appropriate
representations, algorithms, and inference engines for
their area of expertise; (2) coordinate with other
agents to effectively work within a team; and (3) are
developed outside the scope of particular application
system.
In this dissertation, we introduce the conceptual model
we have developed for distributed search and conflict
management among reusable heterogeneous agents. We
present an implemented framework that provides flexible
architectural support for agent integration,
coordination, conflict management, and for multiagent
solution evaluation. We also describe two implemented
application systems built within the framework, and
report results from our experimental investigation of
the efficiency and effectiveness of agent configurations
within those systems.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  2665 </NUMBER>
<ORDER>   AAINN00170 </ORDER>
<TITLE> DEVELOPMENT OF DYNAMIC NEURAL STRUCTURES WITH CONTROL APPLICATIONS  </TITLE>
<AUTHOR> DANDINA, HULIKUNTA RAO </AUTHOR>
<YEAR> 1994 </YEAR>
<INSTITUTION> THE UNIVERSITY OF SASKATCHEWAN (CANADA); 0780 </INSTITUTION>
<DESCRIPTORS> ENGINEERING, ELECTRONICS AND ELECTRICAL; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> M. M. GUPTA; H. C. WOOD; P. N. NIKIFORUK </ADVISER>
<CLASSIFICATIONS> NEURAL NETWORKS, ARTIFICIAL INTELLIGENCE </CLASSIFICATIONS>
<ABSTRACT>
Dynamic neural networks, because they offer
computational advantages over purely static neural
networks. have many potential applications in a number
of fields. The objective of the research described in
this thesis was to develop dynamic neural structures for
control applications. A dynamic model of the biological
neuron called the dynamic neural unit (DNU) was
developed for this purpose. The structure of the DNU is
inspired by the topology of a reverberating circuit in a
neuronal pool of the central nervous system. The DNU
consists of internal feedforward and feedback synaptic
weights followed by a nonlinear activation operator. It
is thus different from the conventionally assumed
structure of an artificial neuron. It is demonstrated in
this thesis that a DNU can control unknown linear and
simple nonlinear systems to track adaptively desired
trajectories.
The efficacy of artificial neural networks comes more
from the number of neurons connected in the network and
from the topology rather than from the computational
ability of an isolated neuron. Considering the DNU as
the basic functional element, a multi-stage dynamic
neural network has been developed. One of the most
important characteristics of neural networks is their
ability to approximate arbitrary nonlinear functions.
While most of the research work in this area has
concentrated on static neural networks, a theoretical
foundation of functional approximation using a dynamic
neural network has been developed. Computer simulation
studies are provided to substantiate the theoretical
developments. Following this development, the dynamic
neural network has been used in a direct adaptive
control mode to cause unknown nonlinear systems to
follow desired reference signals. In conventional static
neural structures, the optimum slope of a nonlinear
activation function is usually determined by trial and
error. An improper selection of the slope may lead to
instability. The importance of using an adaptive
activation operator in neural networks has been
demonstrated through computer simulations. In this
context, the concept of somatic addition for dynamic
neural structures has been introduced. The significance
of this concept as applied to the control of unknown
nonlinear dynamic systems has been extensively studied
through computer simulations.
A new dynamic neural structure called the dynamic neural
processor (DNP) that emphasizes the aggregate dynamic
properties of a neural population has also been proposed
and reported in this thesis. This structure is based
upon the hypothesis that the neuro-physiological
activities of any complexity are dependent upon the
interaction of antagonistic (excitatory and inhibitory)
neural subpopulations. The DNP consists of two DNUs
which are configured to function as excitatory and
inhibitory neurons. A mathematical model and an
algorithm to modify the parameters of the DNP have been
developed. Four applications of the DNP, the functional
approximation of nonlinear functions, computation of
inverse kinematic transformations of a two-link robot,
control of unknown single-input-single-output nonlinear
systems, and coordination and control of multiple-input-
multiple-output systems, are presented. A brief
comparative study of the performance of this neural
model with that of conventionally used recurrent neural
networks has also been presented. A generalized dynamic
neural model based on the concept of neural
subpopulations has been proposed in this thesis. It is
shown that many existing neural structures can be
derived from this generalized neural model.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  2666 </NUMBER>
<ORDER>   AAG9434105 </ORDER>
<TITLE> CONNECTIONIST CONSTRUCTIVE LEARNING FOR AUTONOMOUS KNOWLEDGE ACQUISITION  </TITLE>
<AUTHOR> FANG, FRANK WENZHEN </AUTHOR>
<YEAR> 1994 </YEAR>
<INSTITUTION> THE FLORIDA STATE UNIVERSITY; 0071 </INSTITUTION>
<DESCRIPTORS> COMPUTER SCIENCE; BIOLOGY, NEUROSCIENCE; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> R. C. LACHER </ADVISER>
<CLASSIFICATIONS> NEURAL NETWORK </CLASSIFICATIONS>
<ABSTRACT>
This dissertation investigates constructive neural
network learning algorithms that acquire knowledge by
dynamically constructing the representation of knowledge
as well as concept acquisition techniques that extract
and transform knowledge from constructively trained
neural networks into symbolic representations. An
automatic concept acquisition system that hybridizes the
robust learning of artificial neural networks and the
transparent reasoning of knowledge based systems is
developed. Knowledge is acquired by a constructive
neural network learning algorithm and then transformed
into symbolic concept representations by a knowledge
extraction procedure.
A constructive neural network learning algorithm called
stack is designed. The stack learning algorithm
dynamically changes its internal knowledge
representation (the network) to store the knowledge
learned from the training examples. By allowing the
topological structure of the neural network to grow, the
algorithm seeks to balance the complexity of the neural
architecture with the complexity of the learning task.
Stack provides a connectionist learning technique that
automatically determines the network topology for a
given problem. Non-linear functionality of a stack
network is formed by stacking nodes onto the top of the
output nodes which are then frozen and re-assigned as
hidden nodes. Freezing the trained connections
accumulates knowledge incrementally as well as avoids
training the hidden nodes.
Knowledge learned by the constructive learning algorithm
is distributed in the compositional components of a
network. The subsymbolic knowledge representation is not
transparent to humans. A concept acquisition algorithm
called CA-algorithm is developed to construct symbolic
knowledge (concepts) from stack networks. The target
concept to be acquired is specified by the output node
of a stack network. Other nodes represent the coarse
description (intermediate concepts with errors) of the
target concept. The K-algorithm employs the ideas of
Karnaugh map with the principles of mathematical
hypercubes to find generalized functions for a given set
of examples.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  2667 </NUMBER>
<ORDER>   AAG9434017 </ORDER>
<TITLE> AN ASSOCIATIVE ARCHITECTURE FOR MACHINE LEARNING BY GENETIC ALGORITHMS IN EMBEDDED SYSTEMS </TITLE>
<AUTHOR> TWARDOWSKI, KIRK EDWARD </AUTHOR>
<YEAR> 1994 </YEAR>
<INSTITUTION> SYRACUSE UNIVERSITY; 0659 </INSTITUTION>
<DESCRIPTORS> ENGINEERING, ELECTRONICS AND ELECTRICAL; COMPUTER SCIENCE; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> NIL </ADVISER>
<CLASSIFICATIONS> NIL </CLASSIFICATIONS>
<ABSTRACT>
This dissertation describes an associative architecture
specifically designed to support a general purpose
learning system suited to classification and prediction
tasks. Such tasks are essential to autonomous and
intelligent systems. One difficulty of machine learning
systems is that of meeting their computational demand,
often in the form of highly repetitive, yet very simple
search operations; hence, an associative architecture is
an intuitive approach to meeting the processing
requirements.
The machine learning paradigm investigated in that of a
genetic algorithm based machine learning approach called
a Learning Classifier System (LCS). The LCS is a
synthesis of a parallel rule-based production system, a
credit assignment component, and rule discovery
heuristics which include a genetic algorithm. One
advantage of the LCS is that the algorithms have been
designed with the goal of producing a system that can
parallelize efficiently. This makes it possible to
consider a parallel hardware solution that is physically
small enough to be used in embedded system environments.
Based on a requirements analysis of the LCS, an
associative architecture is designed with the objective
of providing highly parallel support for the rules in
the LCS. This architecture couples a 64-bit content-
addressable memory with a very basic 1-bit processing
element (PE) and includes a reconfigurable bus under the
autonomous control of each PE. A programming model for
mapping parallel data onto the architecture is described
with an emphasis on using multiple PEs to support large
data records. A simulator for the architecture is
described with attention to the support of the
programming model and the monitoring of run-time
statistics. A library of low-level operations for this
architecture is developed which includes arithmetic,
communication, global feedback, scan, and segmented
functions. An LCS implementation is developed which
makes extensive use of these low-level operations. A
performance evaluation of the architecture is presented,
and the results indicate that while the architecture
performs quite well, there are several areas where the
architecture and algorithms can be improved.
Enhancements to the original architecture are proposed
and projected performance improvements are discussed.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  2668 </NUMBER>
<ORDER>   AAG9433966 </ORDER>
<TITLE> FAULT TOLERANCE OF FEEDFORWARD NEURAL NETWORKS: ANALYSIS AND ALGORITHMS </TITLE>
<AUTHOR> CHIU, CHING-TAI </AUTHOR>
<YEAR> 1994 </YEAR>
<INSTITUTION> SYRACUSE UNIVERSITY; 0659 </INSTITUTION>
<DESCRIPTORS> COMPUTER SCIENCE; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> NIL </ADVISER>
<CLASSIFICATIONS> NIL </CLASSIFICATIONS>
<ABSTRACT>
Artificial neural networks are considered to be fault
tolerant since they often contain a large number of
computational units, in excess of the minimum required.
However, classical neural learning algorithms such as
backpropagation do not make an attempt to develop fault
tolerant neural networks.
In this dissertation, we propose measures for fault
tolerance of artificial feed-forward neural networks and
develop algorithms to improve the robustness of the
networks. We design methods to inject artificial faults
to networks. Based on these methods, we define the
sensitivities of each component of neural networks to
help us make quantitative judgements in comparing the
sensitivity of different networks. Then we develop the
different algorithms to improve the robustness of neural
networks to conform to various requirements. These
requirements include improved fault tolerance after
training process is completed, during training process,
and with hardware limitations. All of these algorithms
have achieved some degree of improvement in fault
tolerance compared to backpropagation networks of the
same size trained randomly.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  2669 </NUMBER>
<ORDER>   AAG9433907 </ORDER>
<TITLE> OPPORTUNITIES AND PLANNING IN AN UNPREDICTABLE WORLD </TITLE>
<AUTHOR> PRYOR, LOUISE MARGARET </AUTHOR>
<YEAR> 1994 </YEAR>
<INSTITUTION> NORTHWESTERN UNIVERSITY; 0163 </INSTITUTION>
<DESCRIPTORS> COMPUTER SCIENCE; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> NIL </ADVISER>
<CLASSIFICATIONS> INFORMATION ACQUISITION </CLASSIFICATIONS>
<ABSTRACT>
An agent operating in an unpredictable world cannot
simply construct plans ahead of time and expect them to
work perfectly. Instead, it must adapt its plans to the
circumstances that it actually encounters. To do this,
it must acquire information about the actual state of
the world, and recognize when unpredicted situations
affect its goals. Both problems are addressed in this
thesis.
The requirement for information arises out of the need
to make decisions, and is thus a goal-directed activity.
Plans to achieve information goals can be constructed in
the same way as plans for other goals. This thesis
describes Cassandra, a contingency planner whose plans
include provisions for explicit decisions and the
resulting information acquisition; and PARETO, a plan
execution system whose plans also make explicit
provision for information acquisition arising out of the
need to make decisions.
Plan adaptation during execution requires a unifying
framework within which the plan construction and plan
execution processes can be integrated. In this thesis
the argument is made that the consideration of
opportunities provides such a framework, and a mechanism
is presented that enables an agent to recognize
unexpected opportunities on the fly and respond to them
appropriately and in a timely manner. Its implementation
in PARETO is described.
This mechanism is based on reference features, features
that are both cheap and functional. These features
appear to be prevalent in everyday life. Reference
features form the basis of a powerful focusing mechanism
that can help an agent balance deliberation and action
by indicating both when deliberation would be productive
and what the deliberation should be about. Their use by
PARETO in recognizing and reasoning about opportunities
is described.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  2670 </NUMBER>
<ORDER>   AAG9433738 </ORDER>
<TITLE> ARTIFICIAL VISION: THREE-DIMENSIONAL OBJECT RECOGNITION USING NEURAL NETWORKS </TITLE>
<AUTHOR> ROSANDICH, RYAN GEORGE </AUTHOR>
<YEAR> 1994 </YEAR>
<INSTITUTION> UNIVERSITY OF MISSOURI - ROLLA; 0135 </INSTITUTION>
<DESCRIPTORS> ENGINEERING, INDUSTRIAL; COMPUTER SCIENCE; ENGINEERING, ELECTRONICS AND ELECTRICAL; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> CIHAN H. DAGLI </ADVISER>
<CLASSIFICATIONS> NIL </CLASSIFICATIONS>
<ABSTRACT>
An intelligent artificial vision system is developed
which employs biologically inspired techniques for image
processing and an artificial neural network for object
recognition. Particular emphasis is placed on the
identification and classification of objects and visual
features in manufacturing environments.
Past and current research into the physiological
structure and function of the mammalian vision system
are reviewed, and relationships between this research
and neural-network based models of visual processing are
developed. The psychological research on the subject of
human visual cognition is also reviewed, with the goal
of shedding some light on the processes that humans use
to identify and classify features and objects. Several
vision system models are also reviewed, with emphasis on
recently developed models based on artificial neural
networks.
A new neural network based vision model is developed
based on this research, and this model is implemented as
part of an artificial vision system. The system is
designed to be robust, practical, and fast. The
performance of the system is evaluated on a variety of
objects. The ability of neural networks to learn is
exploited, with the emphasis being placed on learning
from examples and experience rather than on programming
based on a priori knowledge or object models. The system
is shown to be capable of learning and later recognizing
two-dimensional and three-dimensional objects under
varying conditions. Potential applications for this
system include the sorting of three-dimensional
manufactured objects and the identification and
classification of surface defects in manufactured
materials.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  2671 </NUMBER>
<ORDER>   AAG9432098 </ORDER>
<TITLE> INFORMATION-SENSITIVE FUZZY DATABASE SYSTEM FOR DECISION- MAKING AND CONTROL USING INFORMATION INVARIANCE PRINCIPLE </TITLE>
<AUTHOR> YOO, MYOUNGKWAN </AUTHOR>
<YEAR> 1994 </YEAR>
<INSTITUTION> STATE UNIVERSITY OF NEW YORK AT BINGHAMTON; 0792 </INSTITUTION>
<DESCRIPTORS> COMPUTER SCIENCE; ENGINEERING, INDUSTRIAL; ENGINEERING, SYSTEM SCIENCE </DESCRIPTORS>
<ADVISER> GEORGE KLIR </ADVISER>
<CLASSIFICATIONS> NIL </CLASSIFICATIONS>
<ABSTRACT>
The most powerful method for manipulation and storage of
information is the database system. Yet, conventional
database systems cannot process real world information
which contains fuzziness. Therefore, the fuzzified
database system which is based on the fuzzy set theory
is a necessary approach dealing with humanistic types of
information. Currently, the area of fuzzy database
systems has broadened widely to intelligent information
processing. This process can be performed with two basic
approaches which are knowledge base and artificial
intelligence.
In this dissertation an intelligent information
processing system, the Information-Sensitive Fuzzy
Database System (ISFDBS), is described. This system is
based on the concepts localization and approximation.
Localization can build a local membership grade for each
relation based on the information contained in the
database, while approximation can retrieve the
appropriate result according to the information
invariance principle.
One example of implementation of a fuzzy control system
is central air-conditioning. This expert system uses the
concepts of ISFDBS in order to reduce the variance in
the temperature of each zone. Another example is an
expert system of the fuzzy inventory, which determines
the reorder point and quantity for the savings of the
total inventory cost.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  2672 </NUMBER>
<ORDER>   AAGNN89563 </ORDER>
<TITLE> A KNOWLEDGE-BASED SYSTEM FOR THE INTEGRATION OF COMPUTER- INTEGRATED MANUFACTURING DATABASES </TITLE>
<AUTHOR> WU, WENHUA </AUTHOR>
<YEAR> 1994 </YEAR>
<INSTITUTION> UNIVERSITY OF WATERLOO (CANADA); 1141 </INSTITUTION>
<DESCRIPTORS> ENGINEERING, SYSTEM SCIENCE; COMPUTER SCIENCE </DESCRIPTORS>
<ADVISER> DAVID M. DITTS </ADVISER>
<CLASSIFICATIONS> NIL </CLASSIFICATIONS>
<ABSTRACT>
This thesis presents an intelligent framework for the
integration of four autonomous data bases in Computer
Integrated Manufacturing (CIM): design, planning,
manufacturing and accounting data bases. The thesis
begins with a discussion of the problems of
heterogeneous, distinct, autonomous CIM databases, and
presents alternative methods to approach these problems.
Then a review of literature in three related areas--
coupling of artificial intelligence and database
technology, database integration, and CIM data
requirements--is given. Following this is a presentation
of the architecture of a knowledge-based framework,
which consists of the four heterogeneous CIM databases
along with their database management systems (DBMSs), a
knowledge-based system (KBS) for each database that
couples the local database with the global system, a
global manager that coordinates the entire integration
effort and maintains the global schema and data
consistency among the databases, and a natural language
interface that handles global queries and provides an
integrated access to these autonomous databases.
Specifically, the structure, the features and the
knowledge representation of a proposed KBS are
described. And the six types of knowledge in each KBS
are classified as well, which are knowledge associated
with application domain, knowledge dealing with
conceptual schema and data structure, knowledge about
the underlying DBMS, knowledge pertaining to
environmental changes, knowledge in linguistics of the
query language and knowledge for maintaining
interdatabase consistency. In order to make such a
system dynamic, flexible and adaptive to a wide variety
of situations and environments, the knowledge-based
technology used to control the knowledge base and the
database is also discussed.
Furthermore, a formal knowledge-based methodology for
schema integration is proposed, which includes the four
concrete steps: (1) determination of integration schema;
(2) schema transformation: 3) conflict identification &
resolution; and (4) evolutionary schema merging and
restructuring. To keep the generated global schema
consistent with the component schemas, an algorithm for
updating the global schema with respect to changes of
the component schemas is elaborated in detail. In
addition, to demonstrate the feasibility of the proposed
architecture and methodology, a research prototype of
the entire system and an example of schema integration &
global query processing are presented. The built
prototype provides a uniform interface to the four
autonomous CIM databases, which improves the global
accessibility and shareability of these heterogeneous
databases. Finally, the thesis concludes with a
discussion of limitations of the proposed system, and
directions of the future research.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  2673 </NUMBER>
<ORDER>   AAGNN89433 </ORDER>
<TITLE> DECISION GRAPHS: ALGORITHMS AND APPLICATIONS TO INFLUENCE DIAGRAM EVALUATION AND HIGH-LEVEL PATH PLANNING UNDER UNCERTAINTY </TITLE>
<AUTHOR> QI, RUNPING </AUTHOR>
<YEAR> 1994 </YEAR>
<INSTITUTION> THE UNIVERSITY OF BRITISH COLUMBIA (CANADA); 2500 </INSTITUTION>
<DESCRIPTORS> COMPUTER SCIENCE </DESCRIPTORS>
<ADVISER> DAVID POOLE </ADVISER>
<CLASSIFICATIONS> NIL </CLASSIFICATIONS>
<ABSTRACT>
Decision making under uncertainty has been an active
research topic in decision theory, operations research
and Artificial Intelligence. The main objective of this
thesis is to develop a uniform approach to the
computational issues of decision making under
uncertainty. Towards this objective, decision graphs
have been proposed as an intermediated representation
for decision making problems, and a number of search
algorithms have been developed for evaluating decision
graphs. These algorithms are readily applicable to
decision problems given in the form of decision trees
and in the form of finite stage Markov decision
processes.
In order to apply these algorithms to decision problems
given in the form of influence diagrams, a stochastic
dynamic programming formulation of influence diagram
evaluation has been developed and a method to
systematically transform a decision making problem from
an influence diagram representation to a decision graph
representation is presented. Through this
transformation, a decision making problem represented as
an influence diagram can be solved by applying the
decision graph search algorithms. One of the advantages
of our method for influence diagram evaluation is its
ability to exploit asymmetry in decision problems, which
can result in exponential savings in computation.
Some problems that can be viewed as decision problems
under uncertainty, but are given neither in the form of
Markov decision processes, nor in the form of influence
diagrams, can also de transformed into decision graphs,
though this transformation is likely to be problem-
specific. One problem of this kind, namely high level
navigation in uncertain environments, has been studied
in detail. As a result of this case study, a decision
theoretic formulation and a class of off-line path
planning algorithms for the problem have been developed.
Since the problem of navigation in uncertain
environments is of importance in its own right, an on-
line path planning algorithm with polynomial time
complexity for the problem has also been developed.
Initial experiments show that the on-line algorithm can
result in satisfactory navigation quality.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  2674 </NUMBER>
<ORDER>   AAGC538140 </ORDER>
<TITLE> MEASUREMENT OF R AT THE Z BOSON PEAK USING NEURAL NETWORKS </TITLE>
<AUTHOR> ARIZTIZABAL, FRANCISCO </AUTHOR>
<YEAR> 1994 </YEAR>
<INSTITUTION> UNIVERSITAT AUTONOMA DE BARCELONA (SPAIN); 5852 </INSTITUTION>
<DESCRIPTORS> PHYSICS, ELEMENTARY PARTICLES AND HIGH ENERGY; ARTIFICIAL INTELLIGENCE BARCELONA-SPAIN </DESCRIPTORS>
<ADVISER> NIL </ADVISER>
<CLASSIFICATIONS> NIL </CLASSIFICATIONS>
<ABSTRACT>
In this thesis a determination of the quotient of the
hadronic and leptonic widths of the $rm Zsb0$ is
presented, through the measurement of the ratio of cross
sections $rmsigma (esp+esp-to hadrons)/sigma (esp+esp-to
leptons)$ where leptons are muons or taus. The
classification of the different $rm Zsb0$ decay modes is
based on the Neural Network technique. An algorithm of
"learn and grow" has been developed to train the Neural
Network. The data used were collected by the ALEPH
detector at CERN'S LEP accelerator during the 1991
running period.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  2675 </NUMBER>
<ORDER>   AAI9607236 </ORDER>
<TITLE> USING DECISION TREES AND FEATURE CONSTRUCTION TO DESCRIBE CHANGING CONSUMER LIFE-STYLES AND EXPECTATIONS </TITLE>
<AUTHOR> MAJOR, RAYMOND LEE </AUTHOR>
<YEAR> 1994 </YEAR>
<INSTITUTION> UNIVERSITY OF FLORIDA; 0070 </INSTITUTION>
<DESCRIPTORS> EDUCATION, BUSINESS; COMPUTER SCIENCE </DESCRIPTORS>
<ADVISER> GARY J. KOEHLER </ADVISER>
<CLASSIFICATIONS> NIL </CLASSIFICATIONS>
<ABSTRACT>
Using artificial intelligence methods to acquire expert
knowledge inductively is a key area of interest in
Expert-Systems Development. This dissertation
investigates the theoretical properties of feature-
construction learning algorithms and uses them to
develop an empirical model to examine several issues
related to the 1990-1991 recession. Empirical results
show that feature construction can improve the
performance of an induced decision tree. We develop an
analytical model of learning with feature construction.
Our model characterizes the time complexity of learning
boolean functions with polynomial size DNF expressions,
when bounded-rank decision trees are used as a concept
description language. Results show that limiting the
number of new features may improve the computational
efficiency of feature construction. Our procedure uses
the dual of a decision tree when forming new features.
We then use our empirical model to (1) describe changes
in consumer life-styles and expectations for time
periods associated with the 1990-1991 recession, and,
(2) show that current practice for creating quantitative
measures of consumer confidence is sometimes
inappropriately used. Finally, we examine tradeoffs
between expert comprehensibility and formal power, when
choosing a representation to use in expert-system
applications.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  2676 </NUMBER>
<ORDER>   AAGNN89432 </ORDER>
<TITLE> DEVELOPING CONCEPTUAL FRAMEWORKS FOR STRUCTURING LEGAL KNOWLEDGE TO BUILD KNOWLEDGE-BASED SYSTEMS </TITLE>
<AUTHOR> DEEDMAN, GALVIN CHARLES </AUTHOR>
<YEAR> 1994 </YEAR>
<INSTITUTION> THE UNIVERSITY OF BRITISH COLUMBIA (CANADA); 2500 </INSTITUTION>
<DESCRIPTORS> COMPUTER SCIENCE; ARTIFICIAL INTELLIGENCE; LAW </DESCRIPTORS>
<ADVISER> J. C. SMITH </ADVISER>
<CLASSIFICATIONS> NERVOUS SHOCK, LAWYERS </CLASSIFICATIONS>
<ABSTRACT>
This dissertation adopts a interdisciplinary approach to
the field of law and artificial intelligence. It argues
that the conceptual structuring of legal knowledge
within an appropriate theoretical framework is of
primary importance when building knowledge-based
systems. While technical considerations also play a
role, they must take second place to an in-depth
understanding of the law.
Two alternative methods of structuring legal knowledge
in very different domains are used to explore the
thesis. A deep-structure approach is used on nervous
shock, a rather obscure area of the law of negligence. A
script-based method is applied to impaired driving, a
well-known part of the criminal law. A knowledge-based
system is implemented in each area. The two systems,
Nervous Shock Advisor (NSA) and Impaired Driving Advisor
(IDA), and the methodologies they embody, are described
and contrasted.
In light of the work undertaken, consideration is given
to the feasibility of lawyers without much technical
knowledge using general-purpose tools to build knowledge-
based systems for themselves.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  2677 </NUMBER>
<ORDER>   AAG9433087 </ORDER>
<TITLE> NETWORK KNOWLEDGE BASE PROCESSING USING MARKER PASSING ON PARALLEL MACHINES </TITLE>
<AUTHOR> MIKULA, TIMOTHY LOREN </AUTHOR>
<YEAR> 1994 </YEAR>
<INSTITUTION> UNIVERSITY OF MINNESOTA; 0130 </INSTITUTION>
<DESCRIPTORS> COMPUTER SCIENCE </DESCRIPTORS>
<ADVISER> VIPIN KUMAR; JAMES R. SLAGLE </ADVISER>
<CLASSIFICATIONS> NIL </CLASSIFICATIONS>
<ABSTRACT>
Although the human brain operates at millisecond speeds,
it can quickly manipulate a huge database of knowledge
and experiences. Clearly, the brain is using massive
parallelism to achieve this performance. Research
suggests that much of this information is stored in a
hierarchical semantic network representation. Although
also a fundamental representation in AI (Artificial
Intelligence), our serial computers cannot manipulate
these networks at acceptable speeds. AI researchers are
beginning to realize that our serial approaches are up
against fundamental physical limits. Marker Passing is
naturally parallel and will be used as the low-level
inference method to support network knowledge base
operations. Several SIMD (Single Instruction/Multiple
Data) parallel computer solutions have been proposed,
but their implementations have had discouraging results.
Even though there is little computation needed to
resolve indirect references, there is communication
overhead associated with each traversal step. This
dissertation will outline a MIMD (Multiple
Instruction/Multiple Data) approach to the computational
challenge. With several concepts (hundreds) assigned
each processor, the assignment of the concepts becomes
an important problem. In this dissertation, we shall
explore processor mapping based on common traversal
routes, to minimize communication. We shall follow this
discussion by exploring an automatic (network and
traversal independent) solution we call ASNA (Automatic
Semantic Network Allocation). We have identified the
processing nature of network knowledge applications and
pointed out the performance hurdles. Some obstacles have
been removed (for example, idle time) and others reduced
(for example, unproductive communication). We believe
this research is a solid step towards building large
efficient applications working from billion-concept
networks.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  2678 </NUMBER>
<ORDER>   AAG9432680 </ORDER>
<TITLE> AN EVALUATION OF THE USE OF AN ARTIFICIAL NEURAL NETWORK TO ANALYZE THE EFFECT OF STARTUP MILK PRODUCTION ON REPRODUCTIVE PERFORMANCE OF HIGH PRODUCING HOLSTEIN DAIRY CATTLE </TITLE>
<AUTHOR> FOURDRAINE, ROBERT HANS </AUTHOR>
<YEAR> 1994 </YEAR>
<INSTITUTION> TEXAS A&M UNIVERSITY; 0803 </INSTITUTION>
<DESCRIPTORS> AGRICULTURE, GENERAL; COMPUTER SCIENCE; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> MICHAEL A. TOMASZEWSKI </ADVISER>
<CLASSIFICATIONS> NIL </CLASSIFICATIONS>
<ABSTRACT>
Through the use of an artificial neural network the
analysis of reproductive performance in high producing
dairy cattle using startup lactation information was
evaluated. Data was obtained from monthly DHIA tapes and
used to build a database utilizing current and
historical lactation records from both multiparous and
primiparous cows.
A preliminary statistical analysis was conducted to
identify those variables that showed the largest
influence upon days open. These variables were then used
to define the training datasets. Training was performed
with two different neural network structures, one hidden
layer versus two hidden layers. Initial neural network
results showed that neither of the neural networks
improved training and testing results (from the start of
training).
A statistical analysis was performed to identify those
parameters that have the largest influence upon days
open. These parameters (previous days open, previous
lactation last milk weight, first milk weight, change in
milk production from test day 1 to test day 2, change in
milk production from test 2 and test day 3, days dry,
difference between milk fat and protein for 1st test
day, average milk weight for test day 2 and test day 3,
average milk weight for test day 1 and test day 3, and
protein average for test day 1 and test day 3) were used
to define new training datasets. Both neural networks
performed at a higher level with the number of correctly
estimated days open increasing dramatically (92%
correct). However, the margin in which days open is
estimated allowed a plus or minus 30-day range from the
actual days open. When the days open margin was reduced
to a smaller range of days, the effect was poor training
and testing results. These results were attributed to
numerous contradictions in the data. An analysis of
variance was performed for primiparous and multiparous
cows with the goal of identifying those variables that
statistically differed across days open intervals. Only
previous lactation days open, days dry and protein
percent showed statistical significance (P $<$ 0.05).
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  2679 </NUMBER>
<ORDER>   AAG9432678 </ORDER>
<TITLE> SPATIO-TEMPORAL NEURAL NETWORKS IN HIGH IMPEDANCE FAULT DETECTION  </TITLE>
<AUTHOR> FERNANDO, M. A. SUSITH ROHANA </AUTHOR>
<YEAR> 1994 </YEAR>
<INSTITUTION> TEXAS A&M UNIVERSITY; 0803 </INSTITUTION>
<DESCRIPTORS> ENGINEERING, ELECTRONICS AND ELECTRICAL; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> KARAN L. WATSON </ADVISER>
<CLASSIFICATIONS> ARTIFICIAL NEURAL NETWORKS </CLASSIFICATIONS>
<ABSTRACT>
The timely detection and isolation of High Impedance
Faults (HIFs) are important to ensure the safety of the
public and the property around power distribution lines.
The existing protection measures are highly inadequate
for this task. Although a number of attempts to develop
HIF detectors were made, all of them were unable to
provide a complete solution to this problem. The
inability of conventional pattern recognition approaches
to classify noisy spatio-temporal patterns in
environments such as, inexact detection knowledge and
multi-parameter relationships, is considered to be the
primary reason for the status quo. The objective of this
research work is to explore the use of Artificial Neural
Network (ANN) techniques in developing a HIF detection
system. As the first step towards this ultimate goal,
the capabilities of three ANN architectures to detect
these faults were investigated for this research work.
The network architecture is critical to the success of
any classifier developed using ANN approaches. This is
so, because, the architecture dictates the network
topology, the training algorithm to be used to train
networks, and the training procedure. Since HIF
detection is a spatio-temporal pattern recognition
problem, the capabilities of three spatio-temporal ANN
approaches, buffered Multi-Layer Perceptron (MLP), Time-
Delay Neural Network (TDNN), and Simple Recurrent
Network (SRN), were investigated for this research.
This dissertation describes the work we have done to
explore the use of the three ANN architectures in
detecting HIFs. Two of those architectures, TDNN and
SRN, were applied outside of their primary operational
domains and paradigms. The details of the new modular
feature extraction process that was developed to
facilitate HIF detection, the issues involved in
training networks from the three ANN architectures, the
output performances of the developed networks are
described in this dissertation. Additionally, the
network analysis work that was done to determine the
characteristics of the detection procedures used by the
networks are also described.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  2680 </NUMBER>
<ORDER>   AAG9432267 </ORDER>
<TITLE> COMPETITIVE LEARNING WITH LINEAR NEURAL NETS </TITLE>
<AUTHOR> SHA, YUNG-CHING </AUTHOR>
<YEAR> 1994 </YEAR>
<INSTITUTION> STEVENS INSTITUTE OF TECHNOLOGY; 0733 </INSTITUTION>
<DESCRIPTORS> COMPUTER SCIENCE; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> STANLEY H. SMITH </ADVISER>
<CLASSIFICATIONS> FUZZY LOGIC </CLASSIFICATIONS>
<ABSTRACT>
The purpose of this dissertation is to introduce a new
model for competitive learning neural nets. This new
model is called the Competitive Learning Linear Model
(CLLM). It is constructed from combined concepts in
neural nets, linear systems and fuzzy logic. The
learning algorithm of CLLM is quite different from other
neural nets models. The weights of CLLM are polarized
based upon their corresponding input. The CLLM has
similar performance to the ART (Adaptive Resonance
Theory) but some significant advantages such as simpler
structure and more efficient algorithms. In this
dissertation, we use CLLM system in the following areas;
binary pattern recognition, grayscale pattern
recognition, pattern search, pattern classification of
supervised learning and clustering of unsupervised
learning.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  2681 </NUMBER>
<ORDER>   AAG9432136 </ORDER>
<TITLE> PASSIVE MAP LEARNING AND VISUAL PLACE RECOGNITION </TITLE>
<AUTHOR> ENGELSON, SEAN PHILIP </AUTHOR>
<YEAR> 1994 </YEAR>
<INSTITUTION> YALE UNIVERSITY; 0265 </INSTITUTION>
<DESCRIPTORS> COMPUTER SCIENCE; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> DREW V. MCDERMOTT </ADVISER>
<CLASSIFICATIONS> MAP LEARNING </CLASSIFICATIONS>
<ABSTRACT>
An autonomous mobile robot needs to learn about its
environment while pursuing other tasks. This
dissertation investigates the problem of passive map
learning, where the robot is not allowed to rely on
exploration for learning. Forbidding exploration makes
the problem more difficult, since the true state of the
world cannot always be inferred from the incomplete and
noisy information available at any one point in time. If
the robot cannot actively explore in order to verify the
state of the world, the mapping system will inevitably
make errors. Two main ideas contribute to the operation
of the passive mapping system described here: (a) robot
localization and map updating follows a principle of
least commitment, with a proper treatment of estimation
ambiguity, and (b) errors in mapping are allowed, but
explicitly diagnosed and eventually corrected. The map
representation used is path-based, but incorporates
metric information to provide the constraints necessary
for passive mapping. These metric constraints allow the
system to diagnose mapping errors and to correct them.
The system has been shown empirically to converge on
correct maps of its environment in a realistic
simulation.
Another important part of map learning is place
recognition, or deciding where the robot is in its map.
This dissertation also presents a novel image-based
method for using vision to aid in place recognition,
using image signatures. An image signature is an array
of values derived by evaluating a measurement function
over large blocks of pixels. Measurements are chosen to
be characteristic of a location yet invariant over
different viewing conditions. Signature matching is
performed quickly by element-wise comparison.
Experiments on a large image corpus demonstrate that
image signatures give an accurate and efficient method
for visual place recognition.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  2682 </NUMBER>
<ORDER>   AAG9431875 </ORDER>
<TITLE> RECURRENT NEURAL NETWORKS FOR GRAMMATICAL INFERENCE </TITLE>
<AUTHOR> ZENG, ZHENG </AUTHOR>
<YEAR> 1994 </YEAR>
<INSTITUTION> CALIFORNIA INSTITUTE OF TECHNOLOGY; 0037 </INSTITUTION>
<DESCRIPTORS> ENGINEERING, ELECTRONICS AND ELECTRICAL; COMPUTER SCIENCE; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> RODNEY M. GOODMAN </ADVISER>
<CLASSIFICATIONS> NEURAL NETWORKS </CLASSIFICATIONS>
<ABSTRACT>
In this thesis, various artificial recurrent neural
network models are investigated for the problem of
deriving grammar rules from a finite set of example
"sentences." A general discrete network framework and
its corresponding learning algorithm are presented and
studied in detail in learning three different types of
grammars.
The first type of grammars considered is regular
grammars. Experiments with conventional analog recurrent
networks in learning regular grammars are presented to
demonstrate the unstable behavior of such networks in
processing very long strings after training. A new
network structure to force recurrent networks to learn
stable states by discretizing the internal feedback
signals is constructed. For training such discrete
networks a "pseudo-gradient" learning rule is applied.
As an extension to the discrete network model, an
external discrete stack is added to accommodate the
inference of context-free grammars. A composite error
function is devised to deal with various situations
during learning. The pseudo-gradient method is also
extended to train such a network to learn context-free
grammars with the added option of operating on the
external stack.
Another extension to the discrete network structure is
made for the purpose of learning probabilistic finite
state grammars. The network consists of a discrete
portion which is intended to represent the structure of
the grammar, and an analog portion which is intended to
represent the transition probabilities. Two criteria for
the network to verify the correctness of its solution
during training are proposed. Theoretical analysis of
the necessary and sufficient conditions for the correct
solution is presented.
Experimental results show that the discrete network
models have similar capabilities in learning various
grammars as their analog counterparts, and have the
advantage of being provably stable.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  2683 </NUMBER>
<ORDER>   AAG9431711 </ORDER>
<TITLE> MAPPING ARTIFICIAL NEURAL NETWORKS ON MASSIVELY PARALLEL ARCHITECTURES  </TITLE>
<AUTHOR> MALLUHI, QUTAIBAH MARWAN </AUTHOR>
<YEAR> 1994 </YEAR>
<INSTITUTION> UNIVERSITY OF SOUTHWESTERN LOUISIANA; 0233 </INSTITUTION>
<DESCRIPTORS> COMPUTER SCIENCE; ENGINEERING, ELECTRONICS AND ELECTRICAL; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> MAGDY A. BAYOUMI; T. R. N. RAO </ADVISER>
<CLASSIFICATIONS> NEURAL NERWORKS </CLASSIFICATIONS>
<ABSTRACT>
Recently, Artificial Neural Networks (ANNs) have
received a great deal of researchers attention. One of
the main motivations for this increased attention is the
utilization of parallel computers which allowed ANN
investigators to simulate and test their ideas in ways
not available before. This research concentrates on the
use of massively parallel machines for efficient
implementation of neural networks.
In this dissertation, we review the state of the art in
the area of parallel ANN implementation. Then we present
a class of efficient ANN implementation techniques. As
typical ANN examples, the multilayer feedforward with
backpropagation (FFBP) and the Hopfield ANN models are
selected. Parallel algorithms to implement the recall
and the training phases of the FFBP model as well as the
recall phase of the Hopfield model are provided. A major
advantage of our approach is high performance. Unlike
almost all other techniques presented in the literature
which require O(N) time, where N is the size of the
largest layer, our implementation only requires O(log N)
time. Moreover, it allows the pipelining of more than
one input pattern which further improves the
performance.
A parallel structure, called the mesh-of-appendixed-
trees (MAT), is proposed for efficient implementation of
ANNs. The MAT is utilized for developing two fast
special purpose neural computers. A recursive procedure
to embed the MAT structure into the hypercube topology
is developed. This procedure is used as the basis for an
efficient mapping technique to map ANN computations on
general purpose hypercube massively parallel systems.
The MAT structure is based on the binary tree. Three
structures based on a special kind of trees, called
sheered trees, are also employed for mapping ANNs on
hypercubes. The sheered tree approach is easier than the
binary tree approach, demands less processor memory, and
is very convenient for SIMD hypercubes. Moreover, it
produces algorithms that can be easily simulated on
several other hypercubic topologies like, the CCC, HHC,
and shuffle exchange. For a MIMD environment, several
improvements of the original SIMD algorithms are
described. The different algorithm variations and
alternatives are carefully studied and investigated.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  2684 </NUMBER>
<ORDER>   AAG9431682 </ORDER>
<TITLE> NEURAL NETWORK MODEL-BASED CONTROL OF DISTILLATION COLUMNS  </TITLE>
<AUTHOR> RAMCHANDRAN, BALSHEKAR </AUTHOR>
<YEAR> 1994 </YEAR>
<INSTITUTION> TEXAS TECH UNIVERSITY; 0230 </INSTITUTION>
<DESCRIPTORS> ENGINEERING, CHEMICAL; COMPUTER SCIENCE; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> R. RUSSELL RHINEHART </ADVISER>
<CLASSIFICATIONS> PROCESS CONTROL </CLASSIFICATIONS>
<ABSTRACT>
Distillation control is difficult because of its
nonlinear, interactive and nonstationary behavior; but,
improved distillation control techniques can have a
significant impact on improving product quality and
environmental resource protection. Advanced control
strategies use a model of the process to select the
desired control action. While phenomenological models
have demonstrated efficient control of highly nonlinear
and interactive distillation columns, they can get
complicated and computationally intensive. Further,
these models may require frequent reparametrization to
eliminate any process-model mismatch that may have
accrued with time.
Neural networks provide an alternate approach to
modeling process behavior, and have received much
attention because of their wide range of applicability,
and their ability to handle complex and nonlinear
problems. The main advantage in using neural networks is
that neural network models are computationally simple,
and possess enormous processing power, speed, and
generality.
In this study, neural network process-inverse models
were developed for two different methanol-water
distillation columns: (i) a lab-scale column; and (ii)
an industrial-scale high-purity column. The data
required for "training" and "testing" the neural
networks for the two distillation columns were obtained
from steady-state simulations of the two distillation
columns developed using a commercial steady-state
simulation package. The neural networks were trained
using a very efficient nonlinear optimization algorithm
based on the Levenberg-Marquardt method.
The neural network steady-state process-inverse models
were used in conjunction with a reference system
synthesis based on first-order dynamics. The neural
network model-based controllers were tested on dynamic
simulations of the two distillation columns for both
servo and regulatory modes of operation, and their
performances were compared with conventional static
feedforward Proportional-Integral controllers.
The simplicity and directness of the novel approach
presented in this study addresses issues such as
obtaining training and testing data from steady-state
simulation packages, training the neural networks with a
more robust and efficient nonlinear optimization
algorithm, the use of steady-state process-inverse
neural network models, and incorporating the model with
a reference system synthesis to formulate a very simple
multivariable control structure that make it distinct
and better when compared with conventional Proportional-
Integral controllers. The methodology offers the
advantages of easy implementation and a practical
solution to difficult control problems.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  2685 </NUMBER>
<ORDER>   AAG9431654 </ORDER>
<TITLE> A PROBLEM-BASED CURRICULUM IN A COMPUTERIZED LEARNING ENVIRONMENT FOR TRAINING IN THE FIELD OF AUDIOLOGY </TITLE>
<AUTHOR> THARPE, ANNE MARIE </AUTHOR>
<YEAR> 1994 </YEAR>
<INSTITUTION> VANDERBILT UNIVERSITY; 0242 </INSTITUTION>
<DESCRIPTORS> HEALTH SCIENCES, AUDIOLOGY; COMPUTER SCIENCE; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> GAUTAM BISWAS </ADVISER>
<CLASSIFICATIONS> NIL </CLASSIFICATIONS>
<ABSTRACT>
It is a generally held belief among audiology
professionals that master's level audiologists are no
longer adequately prepared to provide the services that
are required of clinical practitioners. One way to
enhance the clinical training of audiology students is
to provide them with a richer clinical experience
consisting of readily available patients exhibiting a
variety of disorders. For many reasons, however, this is
not always feasible. As a supplement to real patient
exposure, this project focused on designing a curriculum
to encourage self-directed, independent learning skills
by solving realistic patient problems. The result was
SIMON SAYS, a computerized learning environment that
provides (1) a mechanism for presenting realistic
patient problems for students to solve and (2) a
realistic medium for experimenting with complex test
equipment.
In addition to the development of the learning
environment, a series of experiments were conducted to
characterize diagnostic problem-solving in audiology.
Studies in other domains characterize experts as
spending more time and effort in understanding a problem
before they begin to solve it. That is, at the beginning
of a problem-solving episode, experts work to
circumscribe the problem space. On the other hand,
novices plunge immediately into the solution process.
Such findings received support in the experiments
reported here. Effective diagnosis in audiology appears
to be related to (1) the ability to set up patient
problem contexts by analyzing presenting symptoms and
history information and (2) using the more focused
context to better interpret test data.
Characterizing diagnostic problem-solving by students,
novices, and experts develops an understanding of how to
aid individuals in attaining required cognitive skills,
which is essential for building effective computerized
learning environments. It must be noted, however, that
this information is not only useful in the development
of computerized systems but also in training of
audiologists in more traditional classroom and clinical
settings.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  2686 </NUMBER>
<ORDER>   AAIMM99687 </ORDER>
<TITLE> DEVELOPPEMENT D'UN SYSTEME A RESEAUX NEURONAUX POUR LES STATIONNEMENT D'UN VEHICULE AUTONOME GUIDE PAR VISION </TITLE>
<AUTHOR> DRISS, ANISS </AUTHOR>
<YEAR> 1994 </YEAR>
<INSTITUTION> UNIVERSITE DE MONTREAL (CANADA); 0992 </INSTITUTION>
<DESCRIPTORS> ENGINEERING, ELECTRONICS AND ELECTRICAL; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> PAUL COHEN </ADVISER>
<CLASSIFICATIONS> FRENCH TEXT </CLASSIFICATIONS>
<ABSTRACT>
We present a neural network approach for the parking
operation of an autonomous vehicle having the same
kinematic properties as an automobile. This operation is
performed in two successive steps: recognition of a
parking place and execution of the parking maneuvers.
The translation of rotation parameter values are
estimated as results of non-linear mappings from the
visual 3-D (depth of the scene) and displacement data of
the vehicle. We use recurrent Back-Propagation Neural
Network trained in simulated environments. This network
estimates both the state of the parking and the action
to be performed. Thus, in this network, the inputs are
associated to the current recognition state and the
action estimation at the output. For the maneuvering
task, a Markov-based model is proposed to define the
actions that the vehicle must perform. In the model, a
summarized set of non-redundant visual profiles are
associated to a constrained set of vehicle orientations
to define an internal state space. We are using Q-
learning (a kind of reinforcement learning) which
enables association of a probability value to each
state/action pair in the Markovian model. The
maneuvering task is implemented by a set of 3 Back-
Propagation neural networks. By a set of
experimentations in different parking trajectories, the
vehicle learns how to choose appropriate actions that
maximize its performance. Another network, called
planner, is responsible for the transfer from the
recognition to the maneuvering task. (Abstract shortened
by UMI.)
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  2687 </NUMBER>
<ORDER>   AAG9431622 </ORDER>
<TITLE> INCREASING RELIABILITY AND EFFICIENCY FOR KNOWLEDGE- BASED SYSTEMS  </TITLE>
<AUTHOR> LEE, GYESUNG </AUTHOR>
<YEAR> 1994 </YEAR>
<INSTITUTION> VANDERBILT UNIVERSITY; 0242 </INSTITUTION>
<DESCRIPTORS> COMPUTER SCIENCE; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> GAUTAM BISWAS </ADVISER>
<CLASSIFICATIONS> GEOLOGICAL EXPERT SYSTEMS </CLASSIFICATIONS>
<ABSTRACT>
In fuzzy domains where precise and well-defined problem
solving domain models do not exist or are hard to
derive, two important issues dominate knowledge-based
systems development: efficiency and reliability.
Moreover, for complex applications, as the size of
knowledge bases increases, the search for specialized
knowledge in particular problem solving situations
becomes the computational bottleneck.
In this work, we focus on an approach to improve
efficiency that directly exploits domain structure
present in the problem solving knowledge encoded as
rules in the knowledge base. Domain structure refers to
inherent regularities and differences that can be
observed in the expert-supplied knowledge. This
structure should have a direct bearing on problem
solving tasks, and it can be exploited to reorganize the
expert-supplied problem solving knowledge and to make
access of problem solving knowledge faster and more
reliable. In this framework, we introduce the concept of
rule models and build a rule model hierarchy using
ITERATE, an unsupervised conceptual clustering
algorithm. The advantage of using the rule model
hierarchy is that it suggests the most relevant form of
knowledge at an appropriate level of detail to best suit
the problem solving task.
The lack of precise domain models makes it difficult to
develop or apply systematic knowledge acquisition
methodologies. A practical solution is to adopt
incremental knowledge acquisition methodologies, and try
and maintain consistency using rule models and knowledge
refinement techniques. We have developed a framework in
which the expert interacts with the system and performs
a four-step knowledge refinement task: discrepancy
detection, fault location, repair suggestion, and repair
validation.
These research contributions have been put together to
build a general-purpose knowledge-based system
construction tool called MIDST (Mixed-Inferencing
Dempster Shafer Tool), which contains the following
primary modules: a knowledge acquisition tool for
building initial knowledge bases, reasoning system using
rule models and problem-solving primitives for efficient
reasoning, an efficient Dempster-Shafer combination
scheme for evidence combination in uncertain reasoning
environments, and knowledge refinement tool for
maintaining the knowledge base. MIDST is used to build
PLAYMAKER, a geological expert-system for characterizing
hydrocarbon plays, as the focus of our expert system
development research.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  2688 </NUMBER>
<ORDER>   AAG9431372 </ORDER>
<TITLE> A NEURAL NETWORK MODEL FOR TRAFFIC MANAGEMENT IN BROADBAND NETWORKS </TITLE>
<AUTHOR> TARRAF, AHMED ABD EL HAMEED </AUTHOR>
<YEAR> 1994 </YEAR>
<INSTITUTION> CITY UNIVERSITY OF NEW YORK; 0046 </INSTITUTION>
<DESCRIPTORS> ENGINEERING, ELECTRONICS AND ELECTRICAL; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> TAREK SAADAWI; IBRAHIM HABIB </ADVISER>
<CLASSIFICATIONS> NIL </CLASSIFICATIONS>
<ABSTRACT>
Asynchronous Transfer Mode (ATM) Broadband networks
support a wide range of multimedia traffic (e.g. voice,
video, image, and data). This research presents a novel
framework for traffic management at the cell level using
Neural Networks (NNs). Our new approach incorporates
bank of NNs for traffic characterization and
description, another NN system for traffic enforcement,
and finally a reinforcement learning-based NN to provide
a rate-based feedback access control. The NN traffic
description method presents a novel approach to
characterize and model the multimedia traffic. A bank of
backpropagation NNs is used to characterize and predict
the time bit-rate variations of the multimedia packet's
arrival process. The NN traffic enforcement system
includes two policing mechanisms: one is the "Neural
Network Traffic Enforcement Mechanism (NNTEM)", the
second is the "Reinforcement Learning Neural Network
Controller". Both mechanisms do not rely upon the
policing of simple parameters such as mean bit-rate,
peak bit-rate, or burst duration, but rather an
elaborate and very accurate policing of all higher-order
moments via the probability density function (pdf) of
the traffic. The rate-based feedback control is applied
at the access node of the network and is implemented by
the reinforcement learning method which, also, ensures
an optimal control approach. The algorithm utilizes a
feedback control signal to throttle the peak bit-rate of
the arrival stochastic process to the input statistical
multiplexer. The feedback control signal is produced
(using the NN controller) such that the system
performance is maximized. The system performance is
defined in terms of the buffer overflow and the coding
rate of the input source(s). The results of our new
approach show that it is extremely effective in
controlling and managing the ATM multimedia traffic when
compared to existing methods such as Leaky Bucket and
other window-type mechanisms.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  2689 </NUMBER>
<ORDER>   AAG9431263 </ORDER>
<TITLE> GENERATING MULTIPLE DESIGN ALTERNATIVES OF COMPOSITE MATERIALS USING A GENERIC TASK APPROACH </TITLE>
<AUTHOR> KAMEL, AHMED MOHAMED </AUTHOR>
<YEAR> 1994 </YEAR>
<INSTITUTION> MICHIGAN STATE UNIVERSITY; 0128 </INSTITUTION>
<DESCRIPTORS> COMPUTER SCIENCE; ENGINEERING, MATERIALS SCIENCE; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> JON STICKLEN </ADVISER>
<CLASSIFICATIONS> NIL </CLASSIFICATIONS>
<ABSTRACT>
Many engineering design situations require the
generation of multiple designs to meet a common set of
specifications. This research introduces an effective
approach for generating multiple designs. The introduced
architecture both produces multiple designs, and in a
second step ranks the resultant designs according to set
criteria.
The method developed utilizes and builds on the generic
task approach to knowledge-based systems, as well as the
specific design technique, known as Routine Design.
This research has five main contributions in design
knowledge-based systems and in polymer composite
materials design.
In knowledge-based systems, there are three
contributions: (1) The proposal of an integrated
architecture for knowledge-based design problem solving.
This architecture can produce designs by altering
previous similar designs as well as produce designs
"from scratch". The architecture also provides a means
for "testing" the generated designs. (2) The development
of an effective approach for generating multiple designs
to meet a common set of specifications. (3) The
definition of MDSPL, a language for analyzing and
implementing design systems based on the Multiple Design
approach. This language is implemented in the form of a
set of diagrammatic browsers for browsing and editing
design problem solving systems.
In polymer composite materials, there are also 2
contributions: (1) This research introduces an
integrated architecture for the material design for
polymer composite materials. (2) The design and
implementation of a thin film fiber reinforced polymer
composite materials design system using the MDSPL
language. This system is intended to be an industrial
aid for composite materials designers. It is also
intended to be part of the integrated design
architecture intended for automating the design process.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  2690 </NUMBER>
<ORDER>   AAG9431134 </ORDER>
<TITLE> THE ELASTIC STRING MODEL OF NON-RIGID EVOLVING CONTOURS AND ITS APPLICATIONS IN COMPUTER VISION </TITLE>
<AUTHOR> SHEMLON, STEPHEN </AUTHOR>
<YEAR> 1994 </YEAR>
<INSTITUTION> RUTGERS THE STATE UNIVERSITY OF NEW JERSEY - NEW BRUNSWICK; 0190 </INSTITUTION>
<DESCRIPTORS> ENGINEERING, ELECTRONICS AND ELECTRICAL; COMPUTER SCIENCE; ENGINEERING, BIOMEDICAL; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> STANLEY M. DUNN </ADVISER>
<CLASSIFICATIONS> NIL </CLASSIFICATIONS>
<ABSTRACT>
Non-rigid deformation and dynamic evolution of objects
in imaged physical processes often pose some of the most
challenging problems in the application of the AI
techniques of computer vision to the analysis and
interpretation of images of these processes. In
applications system design, the ability to effectively
model the dynamic behavior of physical systems
mathematically results in more flexibility and improved
intelligent capabilities for the system. This is the
main objective of this research.
The choice of methods was influenced by the
psychophysical interpretation of image object shape as
memory from which its past can be inferred, its present
interpreted, and its future predicted. Dynamic modeling
is therefore studied here as a technique for computer
implementation of the contour evolution theories of
computational vision.
We first examine the vision theories of planar object
evolution and then extract the evolution laws that
provide a psychological visual summary of a deforming
object's shape. We study some deformable models, and
justify our motivation for choosing the elastic string
model (ElaStriM) for implementing the deformation laws.
We present a full development of the differential
geometry of the elastic string model, and an examination
of the best physical approximate solutions of the system
equations.
The convolution integral solution of the elastic string
system is implemented using FFTs and techniques of scale-
space processing. Inverting the deformation process is
unstable, so homomorphic deconvolution with a novel
exponential weighting of the kernel is used to implement
the reverse deformation process.
We report results of experiments involving the spatial
tracking of evolving object silhouettes, the detection
and quantification of planar object motion, and the
analysis and explanation of non-rigid deformation. Most
of our application examples are in microscopy. We report
experimental results in object matching and alignment in
TEM studies, non-rigid motion analysis, and deformable
growth studies.
This research work also resulted in an improved
technique for image thresholding, the definition of
novel object matching and alignment metrics, and the
proposal of new object similarity measures, all based on
the ElaStriM.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  2691 </NUMBER>
<ORDER>   AAG9430975 </ORDER>
<TITLE> TEMPORAL INTERVAL MODELING OF ACTIONS AND EVENTS IN DYNAMIC SYSTEMS </TITLE>
<AUTHOR> NEAL, JONATHAN PAUL </AUTHOR>
<YEAR> 1994 </YEAR>
<INSTITUTION> LEHIGH UNIVERSITY; 0105 </INSTITUTION>
<DESCRIPTORS> COMPUTER SCIENCE; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> DONALD HILLMAN </ADVISER>
<CLASSIFICATIONS> NIL </CLASSIFICATIONS>
<ABSTRACT>
We present a representation of events and actions based
on interval temporal logic that is significantly more
expressive than other AI approaches. By explicitly
representing events and the time intervals they occur
over, we are able to represent complex temporal
relationships in a more intuitive manner. The formal
basis of the representation is presented in detail, from
the axiomization of time periods to the relationship
between actions, and events, and their effects. The
power of the representation is illustrated by applying
it to the axiomization and solution of several standard
problems from the AI literature on action and change. In
addition, we illustrate our approach in the
manufacturing domain, specifically the area of shop-
floor scheduling. We further show how our representation
supports external events and simultaneous actions and
why this support is significant.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  2692 </NUMBER>
<ORDER>   AAG9426046 </ORDER>
<TITLE> AN INTELLIGENT KNOWLEDGE-BASED APPROACH TO OPPORTUNISTIC PART SCHEDULING IN FLEXIBLE MANUFACTURING </TITLE>
<AUTHOR> AL-NAJJAR, MAZEN A. </AUTHOR>
<YEAR> 1994 </YEAR>
<INSTITUTION> UNIVERSITY OF SOUTH FLORIDA; 0206 </INSTITUTION>
<DESCRIPTORS> ENGINEERING, INDUSTRIAL; ENGINEERING, SYSTEM SCIENCE; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> RAFAEL A. PEREZ; O. GEOFFREY OKOGBAA </ADVISER>
<CLASSIFICATIONS> NIL </CLASSIFICATIONS>
<ABSTRACT>
A Flexible Manufacturing System is an integrated system
capable of automatic routing and random processing of
palletized parts across various work stations. However,
flexibility has resulted in new problems in the area of
scheduling and control. The difficulties associated with
managing an FMS can be sorted as: complexity of the
system, constraints imposed upon the system,
uncertainties associated with the system.
The classic analytical approaches to FMS scheduling
possess limited potentials to fully describe or model
the behavior of such a complex system. In general,
analytical approaches use an enumerative search to find
an optimal schedule resulting in computational
complexity. However, the Intelligent Knowledge-Based
System (IKBS) approach to the scheduling problem
provides heuristic search strategies that reduce the
search space and improve the computational efficiency
and reasons with both judgmental and formal knowledge.
The primary research goal of this research was to
develop a generic approach to FMS part scheduling, in
the shop floor operational level, based on the
application of the Rule-Based methodology and the
proposed opportunistic scheduling strategy. Thus, an
intelligent dispatcher ROPS (Rule-based Opportunistic
Part Scheduler) was developed as a research prototype
for dispatching decisions for machines and routing
decisions for parts/jobs. Also, ROPS control functions
include: (1) simulating random job launching, (2)
generating and updating job attributes, (3) determining
and pursuing dispatching goals, (4) monitoring jobs,
machines, queues of idle jobs and machines, process
plans, and job status, (5) evaluating different
processing alternatives, (6) computing different
evaluation measures, (7) triggering milestones or target
dates upon the completion or starting of certain
activities, (8) propagating resource and temporal
constraints to avoid conflicts, (9) dispatching matching
idle jobs to the currently available machine, and (10)
collecting statistics for performance measures.
This research focuses on how individual parts advance
within the system. The inherent flexibility of a FMS is
exploited via the notion of alternative processing for
each operation. The approach attempts to identify the
most solvable portions of a problem and considers these
as "islands of certainty". Premature commitments are
avoided and decision making is postponed as much as
possible so as to secure the most current information
about the problem. The proposed opportunistic scheduling
strategy comprises three major attributes: a resource-
based routing policy, a composite decision policy
(simultaneous routing and loading), and a global options
policy. In each decision making round, several
evaluation measures are utilized to determine which
matching job should be selected by the currently
available machine. A significant contribution of this
research is the adoption of the notion of global "task"
bidding instead of the common "problematic" approach of
problem decomposition. The approach supports three
scheduling objectives: throughput acceleration,
reduction of tardy jobs, and increase in system
utilization.
The performance of ROPS was tested and compared with the
performance of four conventional dispatching rules
(DRs). ROPS outperformed these four DRs with respect to
the aforementioned objectives as well as other relevant
performance measures.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  2693 </NUMBER>
<ORDER>   AAG9431469 </ORDER>
<TITLE> A SCENARIO GENERATOR FOR PUBLIC POLICY AND PROGRAM IMPLEMENTATION </TITLE>
<AUTHOR> LEEKLEY, EDWARD HARLOW </AUTHOR>
<YEAR> 1994 </YEAR>
<INSTITUTION> VIRGINIA POLYTECHNIC INSTITUTE AND STATE UNIVERSITY; 0247 </INSTITUTION>
<DESCRIPTORS> POLITICAL SCIENCE, PUBLIC ADMINISTRATION; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> JOHN W. DICKEY </ADVISER>
<CLASSIFICATIONS> NIL </CLASSIFICATIONS>
<ABSTRACT>
Public policy and program implementation has come to be
regarded as a significant problem area in the governance
process. Research has provided insights but falls short
of totally satisfactory prescriptions for operational
success. The literature on policy and program
implementation reflects a dichotomy of means between
centralized control and delegation of substantial
discretionary authority. The resulting theory leaves a
gap with practice. Scenario writing is one of the
techniques available to practitioners that might be
employed to assist in the execution of their
responsibilities. Scenarios can be useful tools, but
their preparation is costly and time consuming. It was
hypothesized that computer modeling techniques and
artificial intelligence could be applied to scenario
generation to create an effective, practical instrument
to permit wider and more effective use of scenarios for
planning and management. A computer supported procedure
is presented for generating scenarios which describe
alternative sequences of future events for a given
situation and proposed policy. The generator design
reflects a three-way compromise between processing
flexibility, data-base structure, and user workload
requirements. This prototype generator was subjected to
exploratory trials. The lessons learned highlight some
potentially valuable program improvements, the
importance of focusing the scenario at a level useful to
the reader, and the need for a common set of
definitions.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  2694 </NUMBER>
<ORDER>   AAG9429930 </ORDER>
<TITLE> A FRAMEWORK FOR REASONING PRECISELY WITH VAGUE CONCEPTS </TITLE>
<AUTHOR> GOYAL, NITA </AUTHOR>
<YEAR> 1994 </YEAR>
<INSTITUTION> STANFORD UNIVERSITY; 0212 </INSTITUTION>
<DESCRIPTORS> COMPUTER SCIENCE; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> YOAV SHOHAM </ADVISER>
<CLASSIFICATIONS> KNOWLEDGE REPRESENTATION </CLASSIFICATIONS>
<ABSTRACT>
Many knowledge-based systems need to represent vague
concepts such as "old" and "tall". The practical
approach of representing vague concepts as precise
intervals over numbers (e.g., "old" as the interval
(70,110)) is well-accepted in Artificial Intelligence.
However, there have been no systematic procedures, but
only ad hoc methods to delimit the boundaries of
intervals representing the vague predicates. A key
observation is that the vague concepts and their
interval boundaries are constrained by the underlying
domain knowledge. Therefore, any systematic approach to
assigning interval boundaries must take the domain
knowledge into account. Hence, in the dissertation, we
present a framework to represent the domain knowledge
and exploit it to reason about the interval boundaries
via a query language. This framework is comprised of a
constraint language to represent logical constraints on
vague concepts, as well as numerical constraints on the
interval boundaries; a query language to request
information about the interval boundaries; and an
algorithm to answer the queries. The algorithm
preprocesses the constraints by extracting the numerical
information from the logical constraints and combines
them with the given numerical constraints. We have
implemented the framework and applied it to medical
domain to illustrate its usefulness.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  2695 </NUMBER>
<ORDER>   AAG9429807 </ORDER>
<TITLE> ISSUES OF SEMANTICS IN A SEMANTIC-NETWORK REPRESENTATION OF BELIEF  </TITLE>
<AUTHOR> HILL, ROBIN K. </AUTHOR>
<YEAR> 1994 </YEAR>
<INSTITUTION> STATE UNIVERSITY OF NEW YORK AT BUFFALO; 0656 </INSTITUTION>
<DESCRIPTORS> COMPUTER SCIENCE; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> NIL </ADVISER>
<CLASSIFICATIONS> CIRCULAR STRUCTURES </CLASSIFICATIONS>
<ABSTRACT>
Knowledge representation and reasoning systems that are
used for cognitive modeling must capture mental
intensions, i.e., senses of linguistic or other semantic
constructions, as opposed to (or, rather, in addition
to) references, such as physical objects, of those
constructions. A semantic-network system used for this
purpose needs a semantics in which the nodes of a
network are terms in the language of thought of the
modeled cognitive agent and represent entities in the
agent's mental universe. SNePS ("Semantic Network
Processing System") is such a system.
With SNePS as the framework, specific issues studied
include how different types of nodes (concepts) are to
be interpreted and used by the cognitive agent and the
different types of computations required to support
these uses; how nodes come to be distinct or similar,
from both inter-agent and intra-agent perspectives; how
(and why) circularity of meaning may be accommodated in
a semantic network; and to what extent the coherence of
the cognitive structure of the agent may be maintained
under such circularity.
Non-well-founded set theory, with its legitimization of
truly circular structures, is of special interest to
providing a semantics for SNePS in accordance with its
design principles. A certain category of SNePS node, the
base node, representing a discrete concept, is given a
semantics that is both influenced by and influences its
dominating compound (molecular) nodes, lending a
controlled cyclicity to networks. A semantic function
$mu$ is defined that assigns a "hyperset", or non-well-
founded set, formed from the outermost sensory nodes of
the cognitive agent, to each other node of that agent.
Investigation shows that this hyperset semantics
supports representational principles of SNePS, such as
the conceptual uniqueness of every node, and allows no
node to be circular to the point of vacuity. Further
discussion shows how this contribution from SNePS may
illuminate the role that semantic networks and graphical
representation in general have to play in artificial
intelligence.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  2696 </NUMBER>
<ORDER>   AAG9429246 </ORDER>
<TITLE> KNOWLEDGE-BASED DESIGN OF RIGGING SYSTEMS FOR STRUCTURAL INVESTMENT CASTINGS </TITLE>
<AUTHOR> MANNA, SHANTANU KISHORE </AUTHOR>
<YEAR> 1994 </YEAR>
<INSTITUTION> THE UNIVERSITY OF ALABAMA; 0004 </INSTITUTION>
<DESCRIPTORS> ENGINEERING, MECHANICAL; COMPUTER SCIENCE; ARTIFICIAL INTELLIGENCE; ENGINEERING, METALLURGY </DESCRIPTORS>
<ADVISER> JAMES L. HILL </ADVISER>
<CLASSIFICATIONS> NIL </CLASSIFICATIONS>
<ABSTRACT>
Rigging system design is an art based on the science of
fluid flow, heat transfer, and metallurgy. Accumulated
knowledge of experienced methods engineers is an
important ingredient for producing a defect free
casting. In this research, a prototype expert system has
been developed using CLIPS for the rigging system design
of structural investment castings. The knowledge base
was built with expert system rules derived from
knowledge and practice of experienced methods engineers.
A CAD solid model of the part is input to a software
module that extracts the key geometric features,
relevant to the rigging design consideration, of the
part. The expert system module then designs number,
size, and location of various rigging components guided
by expert rules of the knowledge base and based on the
geometric features. Finally, another module generates
solid models of rigging components such as the
downsprue, cup, gates, and risers. The expert system has
been applied to a class of structural investment casting
which is circularly symmetric with hub and rim. The
results of the research are encouraging. The research
can be extended to include other classes of parts
commonly used in the industry.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  2697 </NUMBER>
<ORDER>   AAIMM99684 </ORDER>
<TITLE> ETUDE SUR LA REALISATION DES RESEAUX DE NEURONES ARTIFICIELS: COMPARAISON DES TECHNOLOGIES ET ARCHITECTURE DU RESEAU ART1 </TITLE>
<AUTHOR> CRESPO, JEAN-FRANCOIS </AUTHOR>
<YEAR> 1994 </YEAR>
<INSTITUTION> UNIVERSITE DE MONTREAL (CANADA); 0992 </INSTITUTION>
<DESCRIPTORS> ENGINEERING, ELECTRONICS AND ELECTRICAL; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> YVON SAVARIA </ADVISER>
<CLASSIFICATIONS> FRENCH TEXT </CLASSIFICATIONS>
<ABSTRACT>
This work is divided into two parts. Part one is a
comparative study of the implementation technologies for
artificial neural networks. The technologies considered
are optics and electronics. For the optics technology,
we consider optical algebraic processors based
architectures, correlator based architectures and
holographic interconnection based architectures. For the
electronics technology, we consider digital and analog
architectures. Both technologies are confronted on the
basis of performance, technological and practicality
criteria. Optics allows for the highest performances for
correlator based architectures which take full advantage
of the superior interconnecting power of that
technology. However, the limited maturity of optics
hinders commercialization. Digital electronics
outperforms the other architectures because of its
flexibility and the accuracy of computation it provides.
It is also the most successfully commercialized
approach. However, subthreshold analog electronics is
the most power-efficient approach.
In part two, a new learning law, the Direct Coding Rule,
is proposed for bottom-up long term memory learning in
Adaptive Resonance Theory (ART) networks. This law
requires less computational precision than the
traditional Weber Law Rule and modifies the search
dynamics of the network to accelerate convergence.
Following a brief mathematical analysis of the new
learning law, an ART1 network based on this law is
applied to a passive radar detection problem. Simulation
results show that for a quantization level of 7 bits in
the weights, the Direct Coding Rule speeds up
convergence by a factor of 10 compared to the Weber Law
Rule.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  2698 </NUMBER>
<ORDER>   AAG9428927 </ORDER>
<TITLE> AN AUTOMATED KNOWLEDGE EXTRACTION SYSTEM </TITLE>
<AUTHOR> LEE, YOUNGJUN </AUTHOR>
<YEAR> 1994 </YEAR>
<INSTITUTION> UNIVERSITY OF MINNESOTA; 0130 </INSTITUTION>
<DESCRIPTORS> COMPUTER SCIENCE; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> JAMES R. SLAGLE; VLADIMIR CHERKASSKY </ADVISER>
<CLASSIFICATIONS> MACHINE LEARNING, FUZZY RULES </CLASSIFICATIONS>
<ABSTRACT>
With the advent of computer technology, many
organizations have more data than they can deal with.
The number and size of available databases is growing so
fast that there will never be enough human analysts to
interpret all the data. Therefore, what we need is
intelligent systems that analyze data to discover
patterns, regularities, and knowledge. The cost of
computing is less than that of a professional's time
spent on analyzing data and the cost of collecting data.
The system thus has to discover only a few unexpected
relationships to pay for itself.
Extracting knowledge from the data can be automated,
making a significant impact on the human decision-making
process. We developed a Fuzzy Generalized Exemplar (FGE)
learning and inference model. It produces generalized
exemplars. Each is augmented with its own distance
metric. Each generalized exemplar can be considered a
fuzzy rule. Human subjects are highly flexible in that
they can selectively weight an attribute differently
depending on the region of the instance space in which
it is located. Like humans, the FGE based learning
system can allow the importance of attributes to be a
function of its region of instance space.
Based on the FGE model, we designed and implemented a
system to extract fuzzy rules from data. These fuzzy
rules capture the essential information contained within
the patterns and relationships in the data. The rules
can be used in two ways. The first way is to use the
rules directly to interpret and understand the active
mechanism underlying the data. The second way is to
apply the rules to new data and predict new outcomes.
We performed extensive comparisons of the system with
several advanced machine-learning approaches and human
experts, where such comparisons were possible. The
simulation results demonstrate that an FGE based
learning model can learn effectively in a diverse set of
domains. The performance of the system compares
favorably with that of other machine learning methods
and human experts.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  2699 </NUMBER>
<ORDER>   AAG9428476 </ORDER>
<TITLE> THE DESIGN OF A MULTIPLE-VALUED AUTOMATIC MODEL GENERATION SYSTEM FOR DIGITAL SYSTEM SIMULATIONS </TITLE>
<AUTHOR> CHANG, SHUCHIH ERNEST </AUTHOR>
<YEAR> 1994 </YEAR>
<INSTITUTION> THE UNIVERSITY OF TEXAS AT AUSTIN; 0227 </INSTITUTION>
<DESCRIPTORS> COMPUTER SCIENCE; ENGINEERING, ELECTRONICS AND ELECTRICAL; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> STEPHEN A. SZYGENDA </ADVISER>
<CLASSIFICATIONS> CAD </CLASSIFICATIONS>
<ABSTRACT>
Logic Simulators are used as CAD tools to perform
digital logic simulations for verification of digital
system designs and for evaluation of test patterns.
Simulation models are created and added into a simulator
as the most fundamental and important components in the
simulation software. Traditionally, simulator designers
can only develop simulation models through a knowledge
intensive design process, which is difficult, time
consuming, and expensive. Automatic Programming (AP) is
the automation of the computer programming process. AP
research tries to help human beings to write programs in
a higher and more natural level of abstraction, so that,
the human programmer can develop programs with greater
ease, accuracy, and efficiency. Automatic Functional
Model Generation (AFMG) is a project of applying AP
techniques to the model generation process, such that
the model generation process can take advantage of the
AP benefits.
The multiple-valued AFMG system can generate functional
models conforming to signal models with 3, 5, or 6 logic
values. For complex timing simulation, 5 or 6 value
models must be generated. Using 5 or 6 logic values is
more difficult than using 3 values, because many issues,
regarding the input specification, the bit
representation, the algorithms and data structures used
for the program transformation processes, and the code
generation, become very complex. Specification tools are
desired to provide AFMG users a versatile and user-
friendly front-end. The front-end should be able to take
various input specifications, including: truth tables,
boolean equations, HDL's, and schematic diagrams. In
addition, it should be smart enough to handle incomplete
specifications. Choosing an efficient bit representation
is very important, since it affects the overall
performance of the models. Optimization of code is
indispensable, because the code size becomes much larger
than that needed for 3 value models. Designing
algorithms and selecting data structures, to integrate
the domain related systems modeling knowledge and the
program synthesis knowledge, are key issues in the
process of transforming the input description to a
target language implementation. Each of these issues
described above has been carefully addressed and
resolved during the design process of the multiple-
valued AFMG system.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  2700 </NUMBER>
<ORDER>   AAG9428297 </ORDER>
<TITLE> SYNTHESIS OF NONLINEAR CONTROL SYSTEMS USING NEURAL NETWORKS </TITLE>
<AUTHOR> MUKHOPADHYAY, SNEHASIS </AUTHOR>
<YEAR> 1994 </YEAR>
<INSTITUTION> YALE UNIVERSITY; 0265 </INSTITUTION>
<DESCRIPTORS> ENGINEERING, ELECTRONICS AND ELECTRICAL; COMPUTER SCIENCE; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> K. S. NARENDRA </ADVISER>
<CLASSIFICATIONS> NIL </CLASSIFICATIONS>
<ABSTRACT>
Control systems are increasingly being required to
perform well in the presence of nonlinearity,
uncertainty and complexity. It is argued in this thesis
that artificial neural networks offer a new class of
useful tools for the synthesis of controllers that can
cope with all the above difficulties. While from a
purely mathematical perspective these networks are
merely programmable nonlinear maps, they nevertheless
possess several attractive features. They can
approximate continuous maps arbitrarily closely in a
compact domain. There are also methods for their
realization based on only input-output data. Finally,
their parallel distributed nature makes them ideally
suited to deal with high dimensional problems.
In this thesis neural networks are used in different
capacities to realize controllers for nonlinear
dynamical systems. In particular, they are used to
approximate various nonlinear maps in identifiers,
controllers and pattern recognizers. The existence of
such maps is demonstrated using theoretical arguments
and following this, gradient methods are used for the
adjustment of the parameters of different neural
networks in a dynamical context. Extensive computer
simulation studies reported in the thesis clearly show
that the methods suggested have great potential in
practical problems.
Four problems in nonlinear control are considered in the
thesis. These are the control of single-input single-
output nonlinear dynamical systems using simpler models,
the rejection of input disturbances in such systems, the
independent tracking of several outputs in nonlinear
multivariable systems, and the control of a nonlinear
system in the presence of structural failures. All of
these represent difficult control problems from the
point of view of both analysis and synthesis. In each
case, dynamical systems theory is used to provide
analytical justification, while artificial neural
networks are used to address the synthesis problems.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  2701 </NUMBER>
<ORDER>   AAG9428159 </ORDER>
<TITLE> PERFORMANCE OF MULTILAYER NEURAL NETWORKS UNDER FAULTY CONDITIONS  </TITLE>
<AUTHOR> MERCHAWI, NAJWA SARA </AUTHOR>
<YEAR> 1994 </YEAR>
<INSTITUTION> THE PENNSYLVANIA STATE UNIVERSITY; 0176 </INSTITUTION>
<DESCRIPTORS> ENGINEERING, INDUSTRIAL; COMPUTER SCIENCE; ENGINEERING, ELECTRONICS AND ELECTRICAL; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> SOUNDAR R. T. KUMARA </ADVISER>
<CLASSIFICATIONS> MULTILAYER NETWORKS </CLASSIFICATIONS>
<ABSTRACT>
One of the main advantages of using neural networks in
engineering problems, as claimed in the literature, is
their tolerance to incomplete or erroneous data as well
as to internal failures. Many research efforts have
attempted to study this tolerance capability using
simulation techniques. A few other efforts used purely
theoretical techniques but these were applied to
networks of restricted size and/or to restricted fault
size. In this research, a new probability-based
theoretical model of the performance of neural networks
under faulty conditions is developed. The multilayer
feedforward neural network model used in binary-to-
binary mappings is considered in this thesis, making use
of the advantage of its simplicity and popularity. The
performance measure is the probability that the neural
network makes a misclassification. Three faulty
conditions are studied: erroneous weight values, broken
connections, and failed nodes. The theoretical models
are derived using a bottom-up approach, tackling the
problem for a single-node network, a single-layer
network, and then multilayer networks.
The theoretical results are tested with simulations of
example applications, including classification of
mechanical parts; the boolean "exclusive or" problem;
and a group technology application. Theoretical results
matched simulation results, showing that, in some cases,
weight error standard deviations as large as 16% of the
weight values can be tolerated. The results also showed
a good tolerance to first layer link failures, when up
to 13% of link failures did not significantly affect
performance. The theory derived for the performance
under node failure was used to investigate the relative
performance networks of different sizes. Contributions
include: (1) Demonstration that increasing the number of
nodes can improve the fault tolerance of the network, if
an appropriate weight vector is found; (2) The proposed
methodology allows, for the first time, neural network
designers to choose an appropriate network size in order
to achieve a certain desired fault tolerance; (3) No
restrictions need to be made on the network size with
the probability based method developed.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  2702 </NUMBER>
<ORDER>   AAG9426619 </ORDER>
<TITLE> INTELLIGENT CONTROL OF MECHANICALLY FLEXIBLE SYSTEMS USING ARTIFICIAL NEURAL NETWORKS </TITLE>
<AUTHOR> CHIU, HSIN-TAN </AUTHOR>
<YEAR> 1994 </YEAR>
<INSTITUTION> UNIVERSITY OF ILLINOIS AT CHICAGO; 0799 </INSTITUTION>
<DESCRIPTORS> ENGINEERING, MECHANICAL; ENGINEERING, ELECTRONICS AND ELECTRICAL; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> SABRI CETINKUNT </ADVISER>
<CLASSIFICATIONS> NIL </CLASSIFICATIONS>
<ABSTRACT>
In this thesis, motion control problems of mechanically
flexible systems are conducted using one intelligent
control paradigm--that is, artificial neural networks to
assess the potential of this emerging scheme. In the
realm of controls, the significance of neural networks
are their properties to deal with nonlinear systems, or
complex phenomena that cannot be accommodated using
classical control methodologies. Generally, the distinct
features pertaining to neural networks include their
parallel structures and distributed processing of
informations, functional approximation, autonomous
learning and adaptation, data fusion (qualitative &
quantitative) as well as hardware implementations and so
forth. Above all, most interesting nature associated
with neural networks lies in their ability to learn
either in a prescribed format or unsupervised way. To
explore this, two diverse architectures of neural
networks are demonstrated to address their potential
implementation as motion controller and estimator for
intelligent control of mechanically flexible systems. A
flexible beam model is used as an example in the
application of intelligent controllers.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  2703 </NUMBER>
<ORDER>   AAG0575121 </ORDER>
<TITLE> M-LATTICE: A SYSTEM FOR SIGNAL SYNTHESIS AND PROCESSING BASED ON REACTION-DIFFUSION </TITLE>
<AUTHOR> SHERSTINSKY, ALEXANDER SEMYON </AUTHOR>
<YEAR> 1994 </YEAR>
<INSTITUTION> MASSACHUSETTS INSTITUTE OF TECHNOLOGY; 0753 </INSTITUTION>
<DESCRIPTORS> ENGINEERING, ELECTRONICS AND ELECTRICAL; COMPUTER SCIENCE; ENGINEERING, SYSTEM SCIENCE; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER>  ROSALIND W. PICARD </ADVISER>
<CLASSIFICATIONS> NEURAL NETWORKS </CLASSIFICATIONS>
<ABSTRACT>
This research begins with reaction-diffusion, first
proposed by Alan Turing in 1952 to account for
morphogenesis--the formation of hydranth tentacles,
leopard spots, zebra stripes, etc. Reaction-diffusion
systems have been researched primarily by biologists
working on theories of natural pattern formation and by
chemists modeling dynamics of oscillating reactions. The
past few years have seen a new interest in reaction-
diffusion spring up within the computer graphics and
image processing communities. However, reaction-
diffusion systems are generally unbounded, making them
impractical for many applications. In this thesis we
introduce a bounded and more flexible non-linear system,
the "M-lattice", which preserves the natural pattern-
formation properties of reaction-diffusion.
On the theoretical front, we establish relationships
between reaction-diffusion systems and paradigms in
linear systems theory and certain types of artificial
"neurally-inspired" systems. The M-lattice is closely
related to the analog Hopfield network and the cellular
neural network, but has more flexibility in how its
variables interact. The bounded M-lattice enables
computer or analog VLSI implementations to serve as
simulation "engines" for a wide variety of systems of
partial and ordinary differential equations.
On the practical front, we have developed new
applications of reaction-diffusion (formulated as the
new M-lattice). These include the synthesis of visual
and sound textures, restoration and enhancement of
fingerprints, non-linear programming, and digital
halftoning of images. Halftones were synthesized in the
creatively hand-drawn "special-effects" style of the
Wall Street Journal portraits as well as in the
"faithful-rendition" style of error-diffusion. (Copies
available exclusively from MIT Libraries, Rm. 14-0551,
Cambridge, MA 02139-4307. Ph. 617-253-5668; Fax 617-253-
1690.)
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  2704 </NUMBER>
<ORDER>   AAG0575115 </ORDER>
<TITLE> INTERACTION AND INTELLIGENT BEHAVIOR </TITLE>
<AUTHOR> MATARIC, MAJA J. </AUTHOR>
<YEAR> 1994 </YEAR>
<INSTITUTION> MASSACHUSETTS INSTITUTE OF TECHNOLOGY; 0753 </INSTITUTION>
<DESCRIPTORS> COMPUTER SCIENCE; ENGINEERING, ELECTRONICS AND ELECTRICAL; PSYCHOLOGY, BEHAVIORAL; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> RODNEY A. BROOKS </ADVISER>
<CLASSIFICATIONS> ROBOTICS </CLASSIFICATIONS>
<ABSTRACT>
This thesis addresses situated, embodied agents
interacting in complex domains. It focuses on two
problems: (1) synthesis and analysis of intelligent
group behavior, and (2) learning in complex group
environments.
Behaviors are proposed as the appropriate level for
control and learning. Basic behaviors are introduced as
building blocks for synthesizing and analyzing system
behavior. The thesis describes the process of selecting
such basic behaviors, formally specifying them,
algorithmically implementing them, and empirically
evaluating them. All of the proposed ideas are validated
with a group of up to 20 mobile robots using a basic
behavior set consisting of: avoidance, following,
aggregation, dispersion, and homing. The set of basic
behaviors acts as a substrate for achieving more complex
high-level goals and tasks. Two behavior combination
operators are introduced, and verified by combining
subsets of the above basic behavior set to implement
collective flocking and foraging.
A methodology is introduced for automatically
constructing higher-level behaviors by learning to
select among the basic behavior set. A novel formulation
of reinforcement learning is proposed that makes
behavior selection learnable in noisy, uncertain multi-
agent environments with stochastic dynamics. It consists
of using conditions and behaviors for more robust
control and minimized state-spaces, and a reinforcement
shaping methodology that enables principled embedding of
domain knowledge with two types of shaping functions:
heterogeneous reward functions and progress estimators.
The methodology outperforms two alternatives when tested
on a collection of robots learning to forage. The
proposed formulation enables and accelerates learning in
complex multi-robot domains. The generality of the
approach makes it compatible with the existing
reinforcement learning algorithms, allowing it to
accelerate learning in a variety of domains and
applications.
The presented methodologies and results are aimed at
extending our understanding of synthesis, analysis, and
learning of group behavior. (Copies available
exclusively from MIT Libraries, Rm. 14-0551, Cambridge,
MA 02139-4307. Ph. 617-253-5668; Fax 617-253-1690.)
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  2705 </NUMBER>
<ORDER>   AAIMM99509 </ORDER>
<TITLE> ARTIFICIAL NEURAL NETWORK FLUX ESTIMATION FOR FIELD ORIENTED CONTROL </TITLE>
<AUTHOR> TOH, ALLAN K. P. </AUTHOR>
<YEAR> 1994 </YEAR>
<INSTITUTION> UNIVERSITY OF CALGARY (CANADA); 0026 </INSTITUTION>
<DESCRIPTORS> ENGINEERING, ELECTRONICS AND ELECTRICAL; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> E. P. NOWICKI </ADVISER>
<CLASSIFICATIONS> NIL </CLASSIFICATIONS>
<ABSTRACT>
Field oriented control (FOC), sometimes referred to as
vector control, is used in inverter-fed induction motor
drives to obtain high performance speed response. For
field oriented control it is necessary to know the
instantaneous magnitude and position of the rotor flux.
The magnitude and position of the rotor flux is
approximated based on flux measurements in the direct
FOC scheme and estimated in the indirect FOC scheme. In
this thesis, a novel flux estimator, the artificial
neural network estimator, is presented. The neural
network is able to estimate accurately the rotor flux
magnitude or position (maximum absolute error is less
than 0.03 p.u.) for line-start operation of an induction
motor as well as for field oriented control. A
sensitivity study indicates that the neural network is
quite insensitive to variations in the rotor resistance
(maximum absolute error is about 0.10 p.u. if rotor
resistance is increased to twice the nominal value). Its
ability to estimate flux response that lies outside of
the neural network training data set is another one of
its strengths. This preliminary work indicates that the
neural network flux estimator is a practical alternative
to other flux estimation methods.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  2706 </NUMBER>
<ORDER>   AAG0575103 </ORDER>
<TITLE> KNOWLEDGE-BASED TREND DETECTION AND DIAGNOSIS </TITLE>
<AUTHOR> HAIMOWITZ, IRA JOSEPH </AUTHOR>
<YEAR> 1994 </YEAR>
<INSTITUTION> MASSACHUSETTS INSTITUTE OF TECHNOLOGY; 0753 </INSTITUTION>
<DESCRIPTORS> COMPUTER SCIENCE; HEALTH SCIENCES, MEDICINE AND SURGERY; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> PETER SZOLOVITS </ADVISER>
<CLASSIFICATIONS> NIL </CLASSIFICATIONS>
<ABSTRACT>
This thesis presents a knowledge-based approach to
diagnostic process monitoring. The cornerstone of this
work is the representation and detection of multivariate
trends in process data. The trend representation, called
a trend template, denotes a time-varying pattern in
multiple variables common to a diagnostic population.
Each pattern contains representations for landmark
events and a set of phases, each temporally uncertain.
The phases are represented by a partially ordered set of
temporal intervals. Bound to each interval are
constraints on real-valued functions of measurable
parameters. The constraints are low-order polynomial
regression models, with either qualitative or
quantitative coefficient estimates. A computer program
called TrenDx diagnoses trends by matching process data
to a set of competing trend templates within a clinical
context. The matching score of a trend template
hypothesis is based on the mean absolute percentage
error between the regression models and the data. TrenDx
not only maintains alternate hypotheses of different
trends, but also optimizes over different chronologies
within each trend description. Therefore TrenDx can
report both what the most significant trend is and when
events and phases take place within that trend.
The thesis describes how TrenDx can be extended to
complete an architecture for automated diagnostic
process monitoring. A faulty trend is judged significant
if over time it matches process data better than the
expected trend. Significance of a faulty trend may
trigger an alarm, switch the clinical context, or filter
data for an intelligent display.
TrenDx has been applied to diagnosis of trends in two
medical domains. The program diagnoses trends in
pediatric growth from heights, weights, bone ages, and
sexual staging data. TrenDx also detects trends in
intensive care unit patients from hemodynamic and
respiratory data. The techniques of TrenDx are intended
as general purpose, and may be applicable to other
diagnostic monitoring applications such as industrial
process control, telecommunications, economics, and
finance. (Copies available exclusively from MIT
Libraries, Rm. 14-0551, Cambridge, MA 02139-4307. Ph.
617-253-5668; Fax 617-253-1690.)
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  2707 </NUMBER>
<ORDER>   AAG9429236 </ORDER>
<TITLE> AN INTELLIGENT COMPUTER-ASSISTED RATER TRAINER </TITLE>
<AUTHOR> JEONG, JONG SIK </AUTHOR>
<YEAR> 1994 </YEAR>
<INSTITUTION> THE UNIVERSITY OF ALABAMA; 0004 </INSTITUTION>
<DESCRIPTORS> BUSINESS ADMINISTRATION, MANAGEMENT; EDUCATION, BUSINESS; COMPUTER SCIENCE; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> JOSEPH M. MELLICHAMP </ADVISER>
<CLASSIFICATIONS> ICART </CLASSIFICATIONS>
<ABSTRACT>
The training of raters is one practical way for
enhancing the accuracy of performance ratings.
Traditional methods for presenting the training, such as
lecture, group discussion, and practice/feedback, are
subject to certain weaknesses. A new ICART training
method, which is an application of knowledge-based
systems, was suggested to overcome the weaknesses of
these traditional training methods.
The objectives of this study were three-fold: (1)
preparing a proposal for training raters, (2) developing
the ICART system according to proposal guidelines, and
(3) examining whether the developed ICART system may
improve the accuracy of performance ratings.
The fault tree analysis technique was used to
effectively define the training content. During this
analysis of the problem domain, biases that occurred in
judgmental activities were considered as rating-error
sources. Based on a questionnaire survey and factor
analysis, relationships between rating errors and error
sources were explored. The results of the fault tree
analysis defined the scope and the order of training
tasks.
Based on the defined training content, the ICART system
was developed as a prototype in accordance with
formalities of intelligent tutoring systems. The system
was composed of three functional modules: a domain-
expert knowledge module, a teaching knowledge module,
and a user-interface module. Production systems and
hypertext techniques were utilized to represent
knowledge for the modules in the system. The Exsys
Professional shell was used as a development tool.
The developed ICART system was tested in the situation
of evaluating an individual performing a briefing. A
total of twenty-eight ROTC cadets participated in two
scheduled training sessions. The control group was
trained by the traditional lecture and practice method;
the experimental group was trained by interacting with
the ICART system. Five accuracy components, elevation,
differential elevation, stereotype accuracy,
differential accuracy, and overall accuracy, were used
as dependent variables for analyzing training effects.
It was found that training by the ICART system improved
accuracy components of differential elevation and
overall accuracy.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  2708 </NUMBER>
<ORDER>   AAG9429090 </ORDER>
<TITLE> ELEMENTS OF READING PROCESSING IN BEGINNING READERS: A CONSTRUCTIVE APPROACH </TITLE>
<AUTHOR> CLAYPOOL, ANNE MCCALL </AUTHOR>
<YEAR> 1994 </YEAR>
<INSTITUTION> UNIVERSITY OF KENTUCKY; 0102 </INSTITUTION>
<DESCRIPTORS> EDUCATION, PSYCHOLOGY; EDUCATION, READING </DESCRIPTORS>
<ADVISER> EMANUEL J. MASON </ADVISER>
<CLASSIFICATIONS> NIL </CLASSIFICATIONS>
<ABSTRACT>
The present research draws heavily from artificial
intelligence, which emphasizes the importance of
knowledge and logical processing. The approach taken is
unique from what is reflected in the literature in that
it addresses what a child brings to the learning
situation in the form of existing knowledge and how new
knowledge develops. In this research, beginning readers'
declarative, procedural, and conditional knowledge of
the reading task, and how this beginning reading
knowledge affected the acquisition of reading skills
were examined. The 23 students, identified as beginning
readers by their teachers, were selected from three
diverse ungraded primary program classrooms (grades 1-3)
in two public school districts. Formal and informal
measures representing student, parent, and teacher
perspectives were used to assess students' reading-
related knowledge and processing. The beginning reader
was described in terms of his or her knowledge and how
that knowledge affected the acquisition of reading
skills. The measure specifically designed for the study
addressed knowledge type, processing, and understanding
of prior knowledge and its relationship to the
acquisition of new knowledge. Furthermore, differences
between what beginning readers knew and what teachers
thought they knew were found. Despite the study's
tentative methodology and need for refined measures, it
was concluded that a constructive approach toward
reading acquisition holds promise.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  2709 </NUMBER>
<ORDER>   AAG9428610 </ORDER>
<TITLE> AUTOMATING HUMAN SERVICE EXPERTISE: THE VALIDATION OF KNOWLEDGE-BASED EXPERT SYSTEMS IN SOCIAL WORK PRACTICE </TITLE>
<AUTHOR> MILLEA, SUSAN ELIZABETH </AUTHOR>
<YEAR> 1994 </YEAR>
<INSTITUTION> THE UNIVERSITY OF TEXAS AT AUSTIN; 0227 </INSTITUTION>
<DESCRIPTORS> SOCIAL WORK; COMPUTER SCIENCE; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> A. JAMES SCHWAB </ADVISER>
<CLASSIFICATIONS> NIL </CLASSIFICATIONS>
<ABSTRACT>
This dissertation project addresses the question of
whether the practice knowledge of social work can be
effectively represented in a knowledge-based (expert
system) computer application to assist in the direct
delivery of services. It centers on the validation of
formally represented practice knowledge in a computer.
It involves a transfer of technology from computer
science to professional social work practice. Not only
is the application of this technology to social work
practice new, but the methods for validating such
systems are still emerging in computer science. Framed
within a paradigm of developmental research, the study
is exploratory in nature. It addresses the means by
which such systems are tested and validated in practice.
The theoretical tradition from which this study draws,
and to which it contributes, is quite interdisciplinary.
Its elements include such diverse areas of literature as
social work, computer science, organizational behavior,
business management and information services, the
processes of technology transfer, and communication
theory. A model for the validation-in-practice of
complex innovations is developed which integrates these
various elements. That model is then tested through its
application to a case study in which an expert system is
evaluated in the setting for which it was designed.
The use of replicated small-scale studies integrating
qualitative and quantitative measures of effectiveness
has been found to be a very useful approach for
establishing the validity of social work practice
innovations. Applying this approach to the validation of
a computer program suggests that the application is
perceived as an innovation in social helping. Because
the expert system captures both policy rules and
knowledge about the processes of helping which can guide
non-expert practitioners, this is fitting.
Advances in information technology are providing new
ways and opportunities for professional social workers
to develop, scrutinize and critique practice knowledge,
including additional means to monitor service outcomes.
Effective use of the tool requires practitioners to be
open to alternative analytical approaches to inquiry,
and the development of some new skills to thoughtfully
apply the technology to practice.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  2710 </NUMBER>
<ORDER>   AAG9427546 </ORDER>
<TITLE> LOGIC PROGRAMMING IN INTUITIONISTIC LINEAR LOGIC: THEORY, DESIGN, AND IMPLEMENTATION </TITLE>
<AUTHOR> HODAS, JOSHUA SETH </AUTHOR>
<YEAR> 1994 </YEAR>
<INSTITUTION> UNIVERSITY OF PENNSYLVANIA; 0175 </INSTITUTION>
<DESCRIPTORS> COMPUTER SCIENCE; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> DALE MILLER </ADVISER>
<CLASSIFICATIONS> NIL </CLASSIFICATIONS>
<ABSTRACT>
It is an unfortunate reality that in "logic programming"
as exemplified by Prolog few interesting problems can be
solved using the purely logical fragment of the
language. The programmer must instead resort to the use
of extra-logical features about which sound reasoning is
difficult or impossible. When logic programming is based
on the theory of intuitionistic logic, it is natural to
allow implications in goals and in the bodies of
clauses. This extension has been studied in depth by
Miller, Nadathur, Gabbay, and others and yields many
useful features at the language level. There are many
problems, though, which cannot be given an attractive
treatment in systems based on classical or
intuitionistic logic because, in those settings, no
control is possible over whether, and how often, a
formula is used during a proof. These are called the
relevant and affine constraints. These limitations can
be addressed by using Girard's linear logic to refine
the intuitionistic notion of context. In this thesis I
discuss the theory, design, and implementation of a
logic programming language based on linear logic as
first proposed by Hodas and Miller in 1991. Several
example applications, including some taken from database
reasoning and natural language processing, are given to
justify the language design. It is shown how issues that
do not arise in implementing traditional systems can
prove crippling to a naive implementation of this logic.
A formal operational semantics is proposed which
circumvents these problems by delaying otherwise non-
deterministic choices in the proof search. A further
refinement of the system, in which the programmer can
specify the relevant and affine constraints
independently, is also discussed.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  2711 </NUMBER>
<ORDER>   AAG9427280 </ORDER>
<TITLE> ANALOG VLSI SUPERVISED LEARNING SYSTEM </TITLE>
<AUTHOR> BENSON, RONALD GARY </AUTHOR>
<YEAR> 1994 </YEAR>
<INSTITUTION> CALIFORNIA INSTITUTE OF TECHNOLOGY; 0037 </INSTITUTION>
<DESCRIPTORS> ENGINEERING, ELECTRONICS AND ELECTRICAL; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> JOHN J. HOPFIELD </ADVISER>
<CLASSIFICATIONS> NIL </CLASSIFICATIONS>
<ABSTRACT>
I built an analog very large-scale integration (VLSI)
chip that learns in real-time. I have designed and
tested this network in a 2$mu$m complementary metal-
oxide-silicon (CMOS) process. The chip was fabricated
through the Metal-Oxide-Silicon Implementation Service
(MOSIS). This fabricated chip contains 12 neurons, each
fully connected to the other 11 neurons, but with no
self-feedback connection.
The goal of this research is to build a supervised-
learning neural-network VLSI chip. This neural chip
could reside at a remote site unattended by a
microcontroller, be battery operated, and be able to
adapt autonomously to a changing environment. The neural
chip has connection weights (or synapses) which are
analog nonvolatile memories programmed in the presence
of ultra-violet light. The chip consumes ultra-low power
(less than one nW per synapse). Several other features
of the chip distinguish it from previous work: the
feedforward nonlinear mapping proceeds concurrently with
the training process in real time; the weight
modifications are performed in parallel and are
calculated collectively as part of the network.
I have successfully trained this chip to perform various
mappings. The test mappings performed by the chip have
two inputs and one output with four hidden units
recruited by the network. The chip is presented with
inputs and target outputs and proceeds to learn the
mapping from input space to output space. Additional
memory on the chip allows any or all of the input units
to be enabled; similarly, the neurons can be configured
as output units or hidden units. The weights, teaching
signals, neuron outputs, error units, inputs, and target
outputs can all be displayed on a multisync monitor to
aid in debugging while the chip is being trained or run
in feedforward mode. I show data of the chip learning.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  2712 </NUMBER>
<ORDER>   AAG9427247 </ORDER>
<TITLE> A PARALLEL GENETIC ALGORITHM FOR THE SET PARTITIONING PROBLEM  </TITLE>
<AUTHOR> LEVINE, DAVID MARK </AUTHOR>
<YEAR> 1994 </YEAR>
<INSTITUTION> ILLINOIS INSTITUTE OF TECHNOLOGY; 0091 </INSTITUTION>
<DESCRIPTORS> COMPUTER SCIENCE; OPERATIONS RESEARCH; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> THOMAS CHRISTOPHER </ADVISER>
<CLASSIFICATIONS> CREW SCHEDULING </CLASSIFICATIONS>
<ABSTRACT>
In this dissertation we report on our efforts to develop
a parallel genetic algorithm and apply it to the
solution of the set partitioning problem--a difficult
combinatorial optimization problem used by many airlines
as a mathematical model for flight crew scheduling. We
developed a distributed steady-state genetic algorithm
in conjunction with a specialized local search heuristic
for solving the set partitioning problem. The genetic
algorithm is based on an island model where multiple
independent subpopulations each run a steady-state
genetic algorithm on their own subpopulation and
occasionally fit strings migrate between the
subpopulations. Tests on forty real-world set
partitioning problems were carried out on up to 128
nodes of an IBM SP1 parallel computer. We found that
performance, as measured by the quality of the solution
found and the iteration on which it was found, improved
as additional subpopulations were added to the
computation. With larger numbers of subpopulations the
genetic algorithm was regularly able to find the optimal
solution to problems having up to a few thousand integer
variables. In two cases, high-quality integer feasible
solutions were found for problems with 36,699 and 43,749
integer variables, respectively. A notable limitation we
found was the difficulty solving problems with many
constraints.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  2713 </NUMBER>
<ORDER>   AAG9426464 </ORDER>
<TITLE> TECHNIQUES FOR SELF-RECOVERING NEURAL NETWORKS AND THEIR APPLICATIONS  </TITLE>
<AUTHOR> KHUNASARAPHAN, CHULARAT </AUTHOR>
<YEAR> 1994 </YEAR>
<INSTITUTION> UNIVERSITY OF SOUTHWESTERN LOUISIANA; 0233 </INSTITUTION>
<DESCRIPTORS> COMPUTER SCIENCE; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> CHIDCHANOK LURSINSAP </ADVISER>
<CLASSIFICATIONS> NEURAL NETWORKS, ARABIC DIGITS </CLASSIFICATIONS>
<ABSTRACT>
This dissertation proposes techniques for self-
recovering neural networks and their applications. For a
self-recovering neural network model, we propose an
efficient technique called Weight Shifting Technique,
and for the recognition application, we propose a new
preprocessing technique called Light Receptor Model.
Light receptor model is a technique to simulate visual
cerebrum and visual cortex models. The idea is to
transform the irregular and deformed patterns into a
domain that is easy to manipulate and recognize. The
model causes the reduction of time and space
complexities of the network considerably. Weight
shifting techniques propose to increase the fault
tolerance of the network during the operational period.
The idea is to shift the faulty weights of faulty links
to other healthy links of the same neuron. The aim of
this technique is to recover the network in a short time
without any retraining and hardware repair. Weight
shifting techniques can also be applied to prune the
converged network to find the suitable number of hidden
neurons and links of the network successfully. The model
is applied for solving handwritten Arabic digits
recognition problem and Thai handwritten characters
recognition problem. The experimental results support
the success in the application of the model.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  2714 </NUMBER>
<ORDER>   AAIMM99350 </ORDER>
<TITLE> POWER SYSTEM STABILIZER BASED ON FUZZY LOGIC </TITLE>
<AUTHOR> EL-METWALLY, KHALED ALI M. </AUTHOR>
<YEAR> 1994 </YEAR>
<INSTITUTION> UNIVERSITY OF CALGARY (CANADA); 0026 </INSTITUTION>
<DESCRIPTORS> ENGINEERING, ELECTRONICS AND ELECTRICAL; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> O. P. MALIK </ADVISER>
<CLASSIFICATIONS> NIL </CLASSIFICATIONS>
<ABSTRACT>
In this thesis, the development of a fuzzy logic based
power system stabilizer (FLPSS) is described. The FLPSS
is responsible for maintaining the power system
stability and enhancing the closed loop performance.
The FLC structure, design, and sensitivity is
investigated. An automatic Parameters tuning algorithm
is proposed to tune the FLC parameters in order to
achieve the desired performance. Two new rule generation
methods are proposed to automatically generate the fuzzy
rule set from a sampled data set.
An interactive simulation fuzzy logic design tool (FDT)
is developed using C++/C programing languages. The FDT
facilitates the understanding and the design of the
fuzzy logic controllers.
Simulation studies and comparison between the FLPSS and
the conventional power system stabilizer (CPSS) using a
single machine model connected to an infinite bus are
conducted. For further verification, the FLPSS has been
applied to a multi-machine model of the power system.
The performance of the FLPSS is satisfactory and is
discussed.
The FLPSS has also been implemented using a low cost
Intel 8051FA micro controller and tested on an
experimental physical power system laboratory set up to
model a simple power system of one machine connected to
the infinite bus through a double circuit transmission
line. The 8051FA micro-controller based FLPSS handles at
the same time the data acquisition system and the fuzzy
logic control algorithm. Experimental tests and results
are fully discussed.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  2715 </NUMBER>
<ORDER>   AAG9426428 </ORDER>
<TITLE> RADIAL BASIS FUNCTIONS NEURAL NETWORKS, FUZZY INFERENCE SYSTEMS AND THEIR APPLICATIONS IN OFF-LINE SYSTEM IDENTIFICATION AND ADAPTIVE CONTROL OF FLEXIBLE ROBOTIC MANIPULATORS </TITLE>
<AUTHOR> ARCINIEGAS-ORTEGA, JORGE IVAN </AUTHOR>
<YEAR> 1994 </YEAR>
<INSTITUTION> THE UNIVERSITY OF TOLEDO; 0232 </INSTITUTION>
<DESCRIPTORS> ENGINEERING, ELECTRONICS AND ELECTRICAL; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> ADEL H. ELTIMSAHY </ADVISER>
<CLASSIFICATIONS> NIL </CLASSIFICATIONS>
<ABSTRACT>
The identification and control of flexible robotics
manipulators using tools from the fields of artificial
neural networks and fuzzy systems is examined. First, a
Lagrangian formulation of the equations of motion of
flexible robotic manipulators is presented. Two cases,
the single and multiple link cases, are considered.
Second, fundamental notions of artificial neural
networks and fuzzy systems are reviewed as a means of
introducing radial basis functions (RBF) neural networks
and fuzzy inference systems. Then, the approximation
power of RBF networks is studied. Special attention is
given to the problem of determining the number and
location of radial units. The orthogonal least squares
(OLS) algorithm is an efficient solution to this
problem. This algorithm is outlined and used to develop
networks of radial units capable of successfully
learning the input-output behavior of flexible arms.
Next, an analogy based on their mathematical structure,
is established between RBF neural networks and a class
of fuzzy inference systems. It is shown that this
analogy can be exploited to synthesize effective
controllers. Finally, the dynamic equations of flexible
robotic manipulators are revisited to study a RBF neural
network based adaptive control technique. An adaptive
control law is proposed. The resulting controller is
analyzed and the overall stability of the system is
proven. The above system identification and control
techniques are tested in a number of simulated
experiments. The results are satisfactory.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  2716 </NUMBER>
<ORDER>   AAG9426258 </ORDER>
<TITLE> VOLTAGE-SOURCE INVERTER OUTPUT WAVEFORM COMPENSATION USING ADAPTIVE INTELLIGENT CONTROL </TITLE>
<AUTHOR> BARNES, LEMUEL GREGORY, III </AUTHOR>
<YEAR> 1994 </YEAR>
<INSTITUTION> VIRGINIA POLYTECHNIC INSTITUTE AND STATE UNIVERSITY; 0247 </INSTITUTION>
<DESCRIPTORS> ENGINEERING, ELECTRONICS AND ELECTRICAL; ENGINEERING, SYSTEM SCIENCE; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> KRISHNAN RAMU </ADVISER>
<CLASSIFICATIONS> NIL </CLASSIFICATIONS>
<ABSTRACT>
A single-layer neural network-based voltage compensation
technique which generates minimum-distortion sinusoidal
output voltages from a three-phase PWM inverter used for
uninterruptible power supplies (UPS) is described. The
proposed compensation technique is implemented in a
microprocessor-based controller constructed in the
stationary d-q frame where the controller sampling rate
is twice the inverter switching frequency. The structure
of a feed-forward artificial neural network connects
network inputs and outputs through multiple linear or
nonlinear neuron models, and processes these
input/output data associations in a parallel distributed
manner. Network inputs in the form of UPS load voltage
commands and load current feedback are propagated
forward in the network each controller sampling period
generating the inverter output voltage commands, the
network outputs, which are converted to three-phase
inverter switching signals using the space vector PWM
waveform generation process. Each controller sampling
period, the network weights are modified by the
controller learning process with the objective of
minimizing the cost function $01over
20cdotlbrackepsilonsb0rm dvsp2 + epsilonsb0rm
qvsp2rbrack$ where $epsilonsb0rm dv$ and $epsilonsb0rm
qv$ are the measured d- and q-axis UPS load voltage
errors. Once the cost function is minimized, the neural
network input/output mapping approximates the PWM
inverter/output filter circuit inverse transfer
characteristics.
Three neural network-based controller configurations
were studied via computer simulation: (i) A controller
with one hidden layer and hyperbolic tangent squashing
functions (six hidden layer nodes used) and the
conventional backpropagation learning algorithm
utilized. (ii) A controller without hidden layers
(single-layer network) and the conventional
backpropagation learning algorithm utilized. (iii) A
controller without hidden layers and a modified
backpropagation learning algorithm utilized.
The third controller configuration was incorporated into
the design of an experimental controller. Three-phase
UPS system experiments and simulations using this
control technique were run using balanced passive,
unbalanced passive, and nonlinear loads at inverter
switching frequencies consistent with the use of GTO
technology. Using the same load models and system
parameters, three-phase UPS system simulations were run
utilizing average load voltage control and the
repetitive controller technique described in (3).
Results obtained from these simulations were served as a
basis for evaluating the performance of the neural
network-based controller.
The application of the neural network-based inverter
controller concept is intended for high-power three-
phase UPS systems where inverter switching frequencies
are reduced and a broad range of UPS loads and output
filter designs are encountered. (Abstract shortened by
UMI.)
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  2717 </NUMBER>
<ORDER>   AAG9426222 </ORDER>
<TITLE> A METAPLANNING EXPERT SYSTEM FOR A COMPUTER-SUPPORTED MEETING ENVIRONMENT: DEFINITION AND VALIDATION OF A PROTOTYPE </TITLE>
<AUTHOR> WYSK, RUDIGER BRUNO </AUTHOR>
<YEAR> 1994 </YEAR>
<INSTITUTION> THE UNIVERSITY OF ARIZONA; 0009 </INSTITUTION>
<DESCRIPTORS> BUSINESS ADMINISTRATION, GENERAL; BUSINESS ADMINISTRATION, MANAGEMENT; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> DOUGLAS R. VOGEL </ADVISER>
<CLASSIFICATIONS> NIL </CLASSIFICATIONS>
<ABSTRACT>
As competitive environments become more complex, demands
for flexible strategic management increase and responses
become more dependent on information technology.
Computer Supported Meeting Environments (CSMEs) have
been successful in reducing the time needed for meetings
and supporting strategic management processes. Because
of its toolkit structure, a CSME is an information
technology that allows for process flexibility.
Metaplanning expert systems can support the decision to
use a specific string of tools for each different client
in each different meeting, particularly in strategic
management. To develop an appropriate metaplanning
expert system and to improve effectiveness and
efficiency of using CSME for strategic planning, it is
critical to assess both the user competence assumptions
and the effectiveness of such system.
The purpose of this dissertation is to assess the impact
the user's interpretive competence (context sensitivity)
and inductive competence (analog awareness) have on the
selection of GroupSystems tools and to validate an
expert system prototype developed to support the
selection of GroupSystems tools in relation to types of
user and use.
Given the novelty and the interdisciplinary nature of
this effort, the initial study is developed to test for
differences in relation to interpretive and inductive
effects, evaluate individual characteristics, and
increase our understanding of the variables at play. The
subjects were students in a capstone MBA business policy
class. No significant differences were found in relation
to context sensitivity. Analog awareness was found to
have a significant impact on the decision of choosing a
divergent tool and a people oriented convergent tool.
The second study defines, develops, and validates a
metaplanning expert system prototype. The prototype can
be adapted to other process/stages focused domains that
could use a string of GroupSystems tools. The main
module of the prototype captures a group profile based
on divergence/convergence factors associated with the
group and the documentation produced by the CSME. No
significant differences were found between facilitators
and non-facilitators. Subjects (MIS PhD students) who
used the prototype to answer to environmental analysis,
strategy formulation, and strategy evaluation test cases
scored, significantly better than those who have not
used the system.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  2718 </NUMBER>
<ORDER>   AAG1356752 </ORDER>
<TITLE> HANDPRINTED CHARACTER RECOGNITION AND ALOPEX ALGORITHM ANALYSIS </TITLE>
<AUTHOR> DU, JIAN </AUTHOR>
<YEAR> 1994 </YEAR>
<INSTITUTION> FLORIDA ATLANTIC UNIVERSITY; 0119 </INSTITUTION>
<DESCRIPTORS> ENGINEERING, ELECTRONICS AND ELECTRICAL; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> RAVI SHANKAR </ADVISER>
<CLASSIFICATIONS> NIL </CLASSIFICATIONS>
<ABSTRACT>
A novel neural network, trained with the Alopex
algorithm to recognize handprinted characters, was
developed in this research. It was constructed by an
encoded fully connected multi-layer perceptron (EFCMP).
It consists of one input layer, one intermediate layer,
and one encoded output layer. The Alopex algorithm is
used to supervise the training of the EFCMP. Alopex is a
stochastic algorithm used to solve optimization
problems. The Alopex algorithm has been shown to
accelerate the rate of convergence in the training
procedure. Software simulation programs were developed
for training, testing and analyzing the performance of
this EFCMP architecture. Several neural networks with
different structures were developed and compared.
Optimization of the Alopex algorithm was explored
through simulations of the EFCMP training procedure with
the use of different parametric values for Alopex.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  2719 </NUMBER>
<ORDER>   AAG9424950 </ORDER>
<TITLE> GLOBAL OPTIMIZATION VIA NEURAL NETWORKS AND D.C. PROGRAMMING  </TITLE>
<AUTHOR> RODDIER, NICOLAS </AUTHOR>
<YEAR> 1994 </YEAR>
<INSTITUTION> THE UNIVERSITY OF ARIZONA; 0009 </INSTITUTION>
<DESCRIPTORS> ENGINEERING, ELECTRONICS AND ELECTRICAL; OPERATIONS RESEARCH; MATHEMATICS; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> FRANCOIS CELLIER </ADVISER>
<CLASSIFICATIONS> DIFFERENCE OF CONVEX </CLASSIFICATIONS>
<ABSTRACT>
The ultimate goal of this work is to provide a general
global optimization method. Due to the difficulty of the
problem, the complete task is divided into several
sections. These sections can be collected into a
modeling phase followed by a global minimization phase.
Each of the various sections draws from different
engineering fields. What this work suggests is an
interface and common ground between these fields.
The modeling phase of the procedure consists of
converting a general problem into a given formulation
using a particular type of neural network. The
architecture required for the neural network forms a new
class: the pseudo multilayer neural network. It is
introduced and compared to more classical neural network
architectures such as the regular multilayer neural
network. However, a key difference between these two
classes is that the behavior of the usual multilayer
network has to be programmed via iterative training,
while an extremely efficient direct procedure is given
here to synthesize the pseudo multilayer neural network.
Therefore any initial problem can be systematically
converted into a pseudo multilayer network without going
through the undesired programming steps such as the
backpropagation rule.
The second phase of the work consists of translating the
initial global optimization problem into the global
minimization of a target function related to the neural
network model. Systematic procedures are again given
here.
The last phase consists of globally minimizing the
target function. This is done via the so-called DC
programming technique where DC stands for "Difference of
Convex". The pseudo multilayer was created such that it
can systematically be converted into a DC formulation,
and therefore be compatible with DC programming. A
translation procedure to go from the pseudo multilayer
neural network model to the DC formulation is given.
When a DC program is applied to this last formulation,
the resulting solution can be directly mapped to the
global minimum of the target function previously
defined, thereby producing the global optimal solution
of the neural network modeling the initial problem.
Therefore, the optimal solution of the original problem
is known as well.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  2720 </NUMBER>
<ORDER>   AAG9424793 </ORDER>
<TITLE> RULE EXTRACTION USING DESTRUCTIVE LEARNING IN ARTIFICIAL NEURAL NETWORKS </TITLE>
<AUTHOR> YOON, BYUNGJOO </AUTHOR>
<YEAR> 1994 </YEAR>
<INSTITUTION> THE FLORIDA STATE UNIVERSITY; 0071 </INSTITUTION>
<DESCRIPTORS> COMPUTER SCIENCE; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> R. C. LACHER </ADVISER>
<CLASSIFICATIONS> NIL </CLASSIFICATIONS>
<ABSTRACT>
The use of inductive learning to extract general rules
from examples would be a promising way to overcome the
knowledge acquisition bottleneck. Over the last decade,
many such techniques have been proposed. None of these
have proved to be the efficient, general rule-extractors
for complex real-world applications. Recent research has
indicated that some kinds of hybrid-learning techniques
which integrate two or more learning strategies
outperform single learning techniques. In designing such
a hybrid-learning method, neural network learning can be
expected to be a good partner because it is tolerant for
noisy data and is very flexible for approximate data.
This dissertation proposes another such method--a rule
extraction method using an artificial neural network
(ANN) that is trained by destructive learning. Unlike
other published methods, the method proposed here takes
advantage of the smart (pruned) network which contains
more exact knowledge regarding the problem domain
(environment). The method consists of three phases:
training, pruning, and rule-extracting. The training
phase is concerned with ANN learning, using a general
backpropagation (BP) learning algorithm. In the pruning
phase, redundant hidden units and links are deleted from
a trained network, and then, the link weights remaining
in the network are retrained to obtain near-saturated
outputs from hidden units. The rule extraction algorithm
uses the pruned network to extract rules.
The proposed method is evaluated empirically on three
application domains--the MONK's problems, the IRIS-
classification data set, and the thyroid-disease
diagnosis data set--and its performance is compared with
that of other classification and/or machine learning
methods. It is shown that for discrete samples, the
proposed method outperforms others, while for continuous
samples it can beat most other methods with which it is
compared. The classifying accuracy of the proposed
method is higher than that of either backpropagation
learning or the pruned network on which it is based.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  2721 </NUMBER>
<ORDER>   AAG9424656 </ORDER>
<TITLE> RADIAL BASIS FUNCTION NEURAL NETWORKS FOR STATE ESTIMATION  </TITLE>
<AUTHOR> RIGDON, DEBRA ALICE </AUTHOR>
<YEAR> 1994 </YEAR>
<INSTITUTION> FLORIDA INSTITUTE OF TECHNOLOGY; 0473 </INSTITUTION>
<DESCRIPTORS> ENGINEERING, ELECTRONICS AND ELECTRICAL; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> D. G. LAINIOTIS </ADVISER>
<CLASSIFICATIONS> KALMAN FILTERS </CLASSIFICATIONS>
<ABSTRACT>
The traditional techniques for state estimation, the
Kalman and extended Kalman filters, are replaced in this
study by radial basis function neural networks. The
feasibility of such an approach is analyzed through
simulation for various linear and non-linear models.
Since the traditional approach of Kalman filtering
requires most system parameters to be known, a neural
approach would be advantageous in that it requires only
sufficient training data to behave as an estimation
filter. Various potential neural architectures and
algorithms were studied and then compared to the
appropriate Kalman filter to determine if comparable
performance may be achieved.
Extensive simulations were performed for each example
and the results of these simulations are provided to
demonstrate the effectiveness of this type of neural
network for the state estimation problem. In addition,
the training methodology used for both types of models
is discussed.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  2722 </NUMBER>
<ORDER>   AAG9424550 </ORDER>
<TITLE> ARTIFICIAL NEURAL NETWORKS AND MODEL-BASED RECOGNITION OF THREE-DIMENSIONAL OBJECTS FROM TWO-DIMENSIONAL IMAGES </TITLE>
<AUTHOR> CHAO, CHIH-HO </AUTHOR>
<YEAR> 1994 </YEAR>
<INSTITUTION> UNIVERSITY OF CINCINNATI; 0045 </INSTITUTION>
<DESCRIPTORS> ENGINEERING, ELECTRONICS AND ELECTRICAL; COMPUTER SCIENCE; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> ATAM P. DHAWAN </ADVISER>
<CLASSIFICATIONS> NEURAL NETWORKS </CLASSIFICATIONS>
<ABSTRACT>
A computer vision system is developed for 3-D object
recognition from a 2-D gray-scale image with the
application of artificial neural networks in both low-
level and high-level process and with the usage of a
model-based top-down feedback analysis approach. This
vision system can adequately address the problems caused
by using an incomplete edge map which is provided by the
low-level processor for 3-D representation and
recognition. This system uses the key patterns which are
assigned with priorities by the intermediate-level
organizer. The highest priority is given to a key
pattern with the most connected node and associated
features including the space invariant structure and the
information of orientation of edge primitives. The
labeled key features are mapped to real space and
provided as input to an artificial neural network for
the purpose of matching.
Hopfield-Tank neural networks have been applied to low-
level edge detection and to high-level matching. In the
intermediate level, the edges extracted by the low-level
processor are reprocessed and organized into various
edge key patterns with priorities assigned. The features
of the connected edge primitives are mapped to
computable real numbers. A candidate with the highest
priority is selected and sent to the high level for
matching through the model base. The first match is to
choose the class of possible model, the second match is
to find the model closest to the candidate. In the end,
the closest model is rotated in 3-D space to achieve the
best match with the candidate. The result of such match
is utilized in generating the model-driven top-down
feedback analysis to verify the recognition and to
provide the inherent 3-D features of objects. In the
case of multiple objects, this matching strategy is very
active and powerful in its ability to recognize objects
using one pattern at a time. It is also suitable to
recognize partially occluded objects.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  2723 </NUMBER>
<ORDER>   AAG9424346 </ORDER>
<TITLE> AN ARCHITECTURE FOR JOB SHOP SCHEDULING WITH GENETIC ALGORITHMS  </TITLE>
<AUTHOR> DAVERN, JAMES JOHN </AUTHOR>
<YEAR> 1994 </YEAR>
<INSTITUTION> UNIVERSITY OF CENTRAL FLORIDA; 0705 </INSTITUTION>
<DESCRIPTORS> ENGINEERING, INDUSTRIAL; OPERATIONS RESEARCH; COMPUTER SCIENCE </DESCRIPTORS>
<ADVISER> JOHN E. BIEGEL </ADVISER>
<CLASSIFICATIONS> SCHEDULING </CLASSIFICATIONS>
<ABSTRACT>
Job Shop Scheduling (JSS) problems continue to be among
the most challenging problems to solve. Perhaps the best
that can be expected for these difficult NP-complete
problems is that near-optimal, better-than-average
solutions will be developed. Due to the repetitive and
computation intensive nature of scheduling problems, the
JSS problem domain is well positioned to take advantage
of improved computer hardware and software as-well-as
emerging Artificial Intelligence (AI) techniques.
Further, a general purpose approach to JSS problems
could have the potential for more widespread use than
any specialized approach. However, to provide a general
purpose scheduling solution approach for real-world
problems, it is necessary to establish an architecture
to integrate the scheduling problem domain components
with the selected AI technique components.
This paper offers an architecture and an implementation
approach for providing optimal or near-optimal solutions
to complex real-world sequencing, scheduling, and
rescheduling problems. The architecture combines JSS
solution components with the AI-based cognitive
computing technology of Genetic Algorithms (GAs). The
architecture is based on a constraint structure
component, a straightforward rule-based scheduler, and a
schedule evaluation component that are integrated with
the stochastic process employed in the GA optimizing
search component. Using this architecture as the model,
a general purpose prototype application for solving JSS
problems is developed and demonstrated.
Example problems illustrate the architecture's
flexibility in solving traditionally difficult problems
involving multiple objectives and relaxed constraints.
For example, Cmax (makespan) can be minimized while
concurrently handling a combination of other scheduling
objectives and constraints including job priorities,
ready times and due dates, and sequence-dependent setup
times. Problem setup for initial scheduling solutions as-
well-as for the dynamic cases involving rescheduling are
handled within the same architecture.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  2724 </NUMBER>
<ORDER>   AAIMM01418 </ORDER>
<TITLE> AN APPROACH TO COMMONSENSE REASONING: DEFAULT LOGIC AUGMENTED WITH CERTAINTY FACTORS </TITLE>
<AUTHOR> PARASRAM, VIREN </AUTHOR>
<YEAR> 1994 </YEAR>
<INSTITUTION> UNIVERSITY OF WINDSOR (CANADA); 0115 </INSTITUTION>
<DESCRIPTORS> COMPUTER SCIENCE; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> JOAN MORRISSEY </ADVISER>
<CLASSIFICATIONS> NIL </CLASSIFICATIONS>
<ABSTRACT>
An active area of research is to find a logic which
models human commonsense reasoning. Several non-
monotonic logics have been proposed. However, each has
deficiencies associated with it. Default Logic is one
such non-monotonic formalism.
We examine some of the problems with Default Logic as
pointed out by (Nut83, Nut87, Isr80, Pea90) and present
an approach which addresses some of these deficiencies.
In our approach, we attach a certainty factor to each
statement in the knowledge base and use this information
to give the user the most certain answer to a query.
This gives us a certainty factor default logic (CFDL).
We present the syntax semantics and proof theory for
this logic.
A resolution algorithm has been developed and
implemented. This implementation shows that the proposed
logic works with some benchmark examples (Lif89) for non-
monotonic reasoning. It can also be used as a testbed
for different calculi of uncertainty.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  2725 </NUMBER>
<ORDER>   AAG9423730 </ORDER>
<TITLE> A SELF-ORGANIZING NEURAL-FUZZY SYSTEM FOR KNOWLEDGE EXTRACTION </TITLE>
<AUTHOR> LIU, XIAODI </AUTHOR>
<YEAR> 1994 </YEAR>
<INSTITUTION> WAYNE STATE UNIVERSITY; 0254 </INSTITUTION>
<DESCRIPTORS> ENGINEERING, INDUSTRIAL; ENGINEERING, ELECTRONICS AND ELECTRICAL; COMPUTER SCIENCE; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> OLUGBENGA O. MEJABI </ADVISER>
<CLASSIFICATIONS> NIL </CLASSIFICATIONS>
<ABSTRACT>
A neural network based fuzzy logic system is presented.
The backbone of this research is an algorithm of a
learning mechanism which combines self-learning and
reasoning with vagueness. The algorithm is derived from
neural networks and fuzzy logic to form a new system
which captures the true meaning of Artificial
Intelligence (AI). The algorithm is composed of multiple
phase calculations through the use of fuzzy clustering,
neural network supervised learning, and fuzzy based
principle systems. The algorithm adopts the learning
ability of neural networks and forms the rule-based
structure of a fuzzy logic system. Convergence in the
new system is faster than the normal back-propagation
algorithm, and it also avoids the rule-matching by the
skilled experts for developing the inference engine for
traditional fuzzy logic systems. Moreover, this system
provides understandable model for the user; not just the
black boxes that result from standard neural network
computations. Therefore the new system is easier to
modify and has broader applications. The new model is
illustrated by an example in flexibility analysis and a
simulation model of a truck backing-up.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  2726 </NUMBER>
<ORDER>   AAG9423212 </ORDER>
<TITLE> INSTRUCTABLE AUTONOMOUS AGENTS </TITLE>
<AUTHOR> HUFFMAN, SCOTT BRADLEY </AUTHOR>
<YEAR> 1994 </YEAR>
<INSTITUTION> THE UNIVERSITY OF MICHIGAN; 0127 </INSTITUTION>
<DESCRIPTORS> COMPUTER SCIENCE; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> JOHN E. LAIRD </ADVISER>
<CLASSIFICATIONS> MACHINE LEARNING, TUTORIAL INSTRUCTION </CLASSIFICATIONS>
<ABSTRACT>
In contrast to current intelligent systems, which must
be laboriously programmed for each task they are meant
to perform, instructable agents can be taught new tasks
and associated knowledge. This thesis presents a general
theory of learning from tutorial instruction and its use
to produce an instructable agent. Tutorial instruction
is a particularly powerful form of instruction, because
it allows the instructor to communicate whatever kind of
knowledge a student needs at whatever point it is
needed. To exploit this broad flexibility, however, a
tutorable agent must support a full range of interaction
with its instructor to learn a full range of knowledge.
Thus, unlike most machine learning tasks, which target
deep learning of a single kind of knowledge from a
single kind of input, tutorability requires a breadth of
learning from a broad range of instructional
interactions.
The theory of learning from tutorial instruction
presented here has two parts. First, a computational
model of an intelligent agent, the problem space
computational model, indicates the types of knowledge
that determine an agent's performance, and thus, that
should be acquirable via instruction. Second, a learning
technique, called situated explanation, specifies how
the agent learns general knowledge from instruction. The
theory is embodied by an implemented agent, Instructo-
Soar, built within the Soar architecture. Instructo-Soar
is able to learn hierarchies of completely new tasks, to
extend task knowledge to apply in new situations, and in
fact to acquire every type of knowledge it uses during
task performance--control knowledge, knowledge of
operators' effects, state inferences, etc.--from
interactive natural language instructions. This variety
of learning occurs by applying the situated explanation
technique to a variety of instructional interactions
involving a variety of types of instructions (commands,
statements, conditionals, etc.). By taking seriously the
requirements of flexible tutorial instruction, Instructo-
Soar demonstrates a breadth of interaction and learning
capabilities that goes beyond previous instructable
systems, such as learning apprentice systems. Instructo-
Soar's techniques could form the basis for future
"instructable technologies" that come equipped with
basic capabilities, and can be taught by novice users to
perform any number of desired tasks.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  2727 </NUMBER>
<ORDER>   AAG9418946 </ORDER>
<TITLE> AUTOMATED COMPUTER-AIDED DESIGN OF CONTROL SYSTEMS THROUGH ARTIFICIAL INTELLIGENCE </TITLE>
<AUTHOR> SMITH, RONALD EUGENE </AUTHOR>
<YEAR> 1994 </YEAR>
<INSTITUTION> THE UNIVERSITY OF WISCONSIN - MADISON; 0262 </INSTITUTION>
<DESCRIPTORS> ENGINEERING, CHEMICAL; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> W. HARMON RAY </ADVISER>
<CLASSIFICATIONS> NIL </CLASSIFICATIONS>
<ABSTRACT>
Computer-Aided Design (CAD) packages have greatly
increased the average engineer's design potential in
recent years. However, that potential is sometimes
unrealized if the CAD package requires more expertise to
use than the average engineer possesses. Creating an
expert system that interfaces with the CAD package and
provides the expertise needed to achieve this unrealized
potential.
CONSYD (CONtrol SYstem Design) is a CAD package for
control system design which was developed by researchers
at the University of Wisconsin-Madison and at the
California Institute of Technology. CONSYD offers a wide
choice of process model descriptions and control system
design and analysis tools. However, a moderately high
level of control theory expertise is required to use the
package effectively. To bring the powerful control
system design strategies of the package to the average
engineer, an expert system, CONSYDEX (CONtrol SYstem
Design EXpert) has been developed.
In this report, the first version of the expert system
(implemented with the development tool, NEXPERT Object)
is presented and some of the issues which arise in
realizing the project are discussed. CONSYDEX will
ultimately have the ability to begin with a process
model or input-output data records and design single
loop or multivariable controllers via a variety of
design strategies. This expert system calls the
appropriate CONSYD programs for the necessary technical
calculations and synthesizes the results into the
desired design(s). The capabilities of CONSYDEX are
illustrated by a variety of examples.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  2728 </NUMBER>
<ORDER>   AAG9425564 </ORDER>
<TITLE> ANALYSIS OF PERFORMANCE INSTRUCTION DELIVERY METHODS ON STUDENT ACHIEVEMENT IN PRINCIPLES OF MARKETING </TITLE>
<AUTHOR> BROWN, BRUCE EDWARD </AUTHOR>
<YEAR> 1994 </YEAR>
<INSTITUTION> VIRGINIA POLYTECHNIC INSTITUTE AND STATE UNIVERSITY; 0247 </INSTITUTION>
<DESCRIPTORS> EDUCATION, COMMUNITY COLLEGE; EDUCATION, BUSINESS; EDUCATION, CURRICULUM AND INSTRUCTION </DESCRIPTORS>
<ADVISER> DANIEL E. VOGLER </ADVISER>
<CLASSIFICATIONS> NIL </CLASSIFICATIONS>
<ABSTRACT>
This study investigated the use of alternative
performance instruction delivery methods on student
achievement in a Principles of Marketing course taught
at New River Community College during the 1993 fall
semester. The study sought to determine if alternative
delivery methods of performance instruction would
influence students' achievement in the course.
The design of the study was quasi-experimental. Two
treatment groups were engaged by this study. One group
received performance instruction using group-directed
lecture methods. The other group received performance
instruction using distance-learning methods.
The planning and evaluation of course content goals were
held constant utilizing an expert system, artificial
intelligence (AI) application software suite developed
by Instructional Performance Systems, Inc. Delivery of
course content goals was controlled, in that, the same
instructor taught both sections of the course. Student
achievement in the course was measured with teacher
developed criterion-referenced mid-term and final
examinations.
The study tested the null hypothesis that performance
instruction delivery methods have no significant effect
on student achievement at the 0.05 level. The study was
enhanced by the collection and analysis of qualitative
student data. A Student Profile Data Survey was
developed and piloted. The student data provided the
basis to profile the student groups and accent study
habits.
Descriptive statistics and unpaired t-tests were used to
analyze student achievement on the mid-term and final
examinations. The analysis found no significant
difference in student achievement resulting from
performance instruction delivery methods. Descriptive
statistics and unpaired t-tests were also used to
profile student groups and accent study habits.
It was concluded, if course syllabi and evaluation are
held constant; and delivery is controlled, one can
reasonably expect achievement will be the same for group-
directed and distance learners.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  2729 </NUMBER>
<ORDER>   AAG9424980 </ORDER>
<TITLE> CONCEPTUAL FLUX: THE CASE AGAINST MENTAL MISREPRESENTATION  </TITLE>
<AUTHOR> PERLMAN, MARK DAVID </AUTHOR>
<YEAR> 1994 </YEAR>
<INSTITUTION> THE UNIVERSITY OF ARIZONA; 0009 </INSTITUTION>
<DESCRIPTORS> PHILOSOPHY </DESCRIPTORS>
<ADVISER> ROBERT CUMMINS </ADVISER>
<CLASSIFICATIONS> MENTAL REPRESENTATION, NATURALISTIC THEORY </CLASSIFICATIONS>
<ABSTRACT>
Naturalistic theories of the content of mental
representations almost universally hold that mental
content is a function of the use of mental
representations. However, use theories of meaning have a
problem explaining how misrepresentation could be
possible. If all uses count in fixing meaning, then none
of them can be misuses, and there can be no
misrepresentation (as well as no conceptual error or
false belief). Typical use theories seek to limit the
uses which count towards meaning, and they propose
criteria which are supposed to make some uses not count
in the determination of the meaning of a mental
representation, so that some of those non-meaning-fixing
uses could be misrepresentations. I argue that none of
these attempts can succeed. They are either
inconsistent, or question-begging and arbitrary. This
includes all two-factor conceptual role theories, causal
theories, informational theories, and adaptational role
theories. Most also cannot allow for misrepresentation,
and those which can do so by invoking some non-
naturalistic source of meaning. So, I conclude that no
naturalistic theory of content is consistent with the
possibility of misrepresentation.
Moreover, I propose a way to make sense of content
without misrepresentation, by adopting a pragmatic view
of representation, inference, and learning. On such a
view, identification of an 'error' is interpreted as the
adoption of a new concept and discontinuation of the use
of the old concept. Concepts are judged with an eye not
to truth, but rather, to their utility. We adopt some
concepts and not others in virtue of their success in
maneuvering through the world, and the social pressure
to speak and think using the concepts which others use.
Communication between people holding different concepts
is still possible provided that the concepts are similar
enough for the differences to be irrelevant in the
context of the communication. This pragmatic view of
meaning and concept change has significant implications
for epistemology, metaphysics, truth, philosophy of
science, psychology, and artificial intelligence. I pay
special attention to the issue of meaning holism,
explaining the various levels of holism that the no-
misrepresentation can entail.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  2730 </NUMBER>
<ORDER>   AAG9424651 </ORDER>
<TITLE> A FUZZY REASONING EXPERT SYSTEM FOR PLANNING-STAGE MATERIALITY JUDGEMENTS </TITLE>
<AUTHOR> MCEACHARN, ELIZABETH MICHELLE </AUTHOR>
<YEAR> 1994 </YEAR>
<INSTITUTION> LOUISIANA TECH UNIVERSITY; 0109 </INSTITUTION>
<DESCRIPTORS> BUSINESS ADMINISTRATION, ACCOUNTING; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> NIL </ADVISER>
<CLASSIFICATIONS> NIL </CLASSIFICATIONS>
<ABSTRACT>
This research effort was directed toward the development
of an expert system which incorporates fuzzy logic into
planning-stage materiality judgements. The research
resulted in the extension of previous materiality
judgement models and illustrated the applicability of
fuzzy logic to ambiguous accounting decision situations.
Planning-stage audit materiality judgements typically
involve a large amount of subjectiveness and qualitative
factor consideration. Fuzzy logic, a mathematical means
which specifically addresses vagueness and ambiguity,
permitted explicit consideration of these subjective and
qualitative factors.
Previous research, authoritative literature, and auditor
advice provided the expertise used to design the
materiality model. These knowledge sources revealed many
characteristics which, because of their ambiguous
nature, had not been incorporated into previous models.
Using a development system shell which relied upon fuzzy
reasoning, the detailed design of the materiality model
was used to develop the knowledge base for the expert
system. The user interface developed for the fuzzy
materiality system permits auditor responses which are
more characteristics of natural language.
The fuzzy materiality system was tested to determine
whether it performed appropriately. Verification
techniques, used to assess system technical accuracy,
included modular development, software error-checking
capabilities, and the use of test data. These techniques
insured that the fuzzy system conforms to orignal model
design characteristics, is free of technical errors,
exhibits an efficient and effective use of rules, and
maintains logical program consistency. Validation
techniques, used to determine the decision usefulness of
the system, included review of the construct and logic
validity of the system by expert auditors and use of the
fuzzy system in a sample of test cases. These validation
techniques provided evidence that the system was
complete and relevant with respect to the use of
variables and inferencing processes, and the system
performs in a manner consistent with actual materiality
decision processes.
Contributions of the research include a better
understanding of the materiality decision process and
increased awareness as to the benefits of fuzzy logic.
Future research extensions include refinement of the
fuzzy materiality system and application of fuzzy logic
to other areas of accounting and auditing.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  2731 </NUMBER>
<ORDER>   AAG9423411 </ORDER>
<TITLE> THE HISTORY AND DEVELOPMENT OF ALGORITHMS IN MUSIC COMPOSITION, 1957-1993  </TITLE>
<AUTHOR> BURNS, KRISTINE HELEN </AUTHOR>
<YEAR> 1994 </YEAR>
<INSTITUTION> BALL STATE UNIVERSITY; 0013 </INSTITUTION>
<DESCRIPTORS> MUSIC; COMPUTER SCIENCE </DESCRIPTORS>
<ADVISER> CLEVE L. SCOTT </ADVISER>
<CLASSIFICATIONS> SOUND SYNTHESIS </CLASSIFICATIONS>
<ABSTRACT>
This dissertation traces the history and development of
algorithms in musical composition from ca. 1957 to 1993
and attempts to clarify related terminology from the
contexts of computer science, information science, and
music theory and composition.
The first of three sections begins with an extensive
definition of the term algorithm. Because this term is
relatively new to musical vocabulary, the definition
appearing in this dissertation will include both musical
and non-musical applications.
Historically and currently, there are three major
approaches to algorithmic composition with computers:
(1) algorithms for sound synthesis; (2) algorithms for
compositional structure; and (3) algorithms for the
correlation of sound synthesis with structure.
Consideration will be given to the latter two
approaches, algorithms for the generation of the micro-
and macrostructural elements of musical composition.
Several different processes exist under the umbrella of
algorithmic composition. Included in the body of this
dissertation are detailed explanations and descriptions
of specific software and hardware from the following
processes: stochastic, chaotic, rule-based, grammars,
and artificial intelligence.
Second, an historical survey of musical compositions and
related written literature covering musical and non-
musical resources organized into three chapters: 1957-
1972, 1973-1982, and 1983-1993. These compositions and
written resources have had significant impact on
determining how subsequent composers made use of
computers for composition.
In the third section an annotated study of the
algorithmic compositions from ca. 1957-1993 will be
presented. Special emphasis has been placed on
information garnered from personal correspondence and
interviews.
Five appendices are devoted to relevant cross-
disciplinary information from the fields of computer
science, information science, and music theory and
composition; included are: (1) a list of terms; (2) an
alphabetical listing of algorithmic compositions; (3) a
discography; (4) a bibliography of relevant information
from the disciplines discussed; and (5) a list of
algorithmic computer systems, languages, and programs
covered in this research. There is significant overlap
in the use of computer algorithms by the scientific and
the musical communities, therefore, the inclusion of
definitions and terminology is necessary for a deeper
understanding of the musical applications.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  2732 </NUMBER>
<ORDER>   AAG9422445 </ORDER>
<TITLE> SYNTHESIZING NEURAL NETWORK AND SYMBOLIC KNOWLEDGE PROCESSING </TITLE>
<AUTHOR> TAN, AH-HWEE </AUTHOR>
<YEAR> 1994 </YEAR>
<INSTITUTION> BOSTON UNIVERSITY; 0017 </INSTITUTION>
<DESCRIPTORS> MATHEMATICS; COMPUTER SCIENCE; BIOLOGY, NEUROSCIENCE; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> GAIL A. CARPENTER </ADVISER>
<CLASSIFICATIONS> NIL </CLASSIFICATIONS>
<ABSTRACT>
Distributed neural networks and Artificial Intelligence
(AI) symbolic systems have long been regarded as two
fundamentally different computational paradigms for
knowledge representation and processing. This
dissertation integrates the complementary strengths of
symbolic knowledge processing and a family of self-
organizing neural networks called Adaptive Resonance
Theory (ART) systems. Part one couples symbolic rule-
based representation with fuzzy ARTMAP, a supervised ART
model. To tackle the neural network interpretation
problem, the thesis presents a rule extraction algorithm
for deriving symbolic knowledge from ARTMAP networks. To
incorporate a priori symbolic knowledge in neural
network learning and recognition, a generalized fuzzy
ARTMAP model, termed Cascade ARTMAP, is introduced.
Cascade ARTMAP explicitly represents intermediate
variables and rule cascades of rule-based knowledge. A
rule insertion algorithm translates if-then symbolic
rules into recognition categories of Cascade ARTMAP.
Initializing networks with prior knowledge can improve
predictive accuracy and learning efficiency. The
inserted symbolic knowledge can also be refined and
enhanced by the Cascade ARTMAP learning algorithm.
Part two of the thesis focuses on associative memory and
conceptual knowledge representation. A compressed and
bidirectional ARTMAP architecture called Adaptive
Resonance Associative Map (ARAM) is introduced for fast
yet stable heteroassociative learning. By encoding
pattern pairs as cognitive chunks explicitly, ARAM
guarantees perfect storage and recall of an arbitrary
number of arbitrary pattern pairs. By its symmetrical
structure, ARAM generalizes readily to K-way ARAM that
learns pattern association across multiple pattern
channels. Based on K-way ARAM, a cognitive architecture
termed Concept Hierarchy Memory Model (CHMM) is proposed
that provides a systematic way to create new concepts
and to organize a concept hierarchy. Through a unified
inferencing mechanism, CHMM performs types of
commonsense reasoning such as recognition, whereby a
concept is identified based on its property values, and
inheritance, whereby the properties of a concept (class)
are inferred from the properties of its defining
concepts (super-classes).
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  2733 </NUMBER>
<ORDER>   AAG9422444 </ORDER>
<TITLE> NEURAL NETWORK MODELS OF ATTENTIVE VISUAL SEARCH AND OBJECT RECOGNITION </TITLE>
<AUTHOR> ROSS, WILLIAM D. </AUTHOR>
<YEAR> 1994 </YEAR>
<INSTITUTION> BOSTON UNIVERSITY; 0017 </INSTITUTION>
<DESCRIPTORS> COMPUTER SCIENCE; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> GAIL A. CARPENTER </ADVISER>
<CLASSIFICATIONS> NIL </CLASSIFICATIONS>
<ABSTRACT>
The visual system allows humans to recognize camouflaged
multi-faceted objects in cluttered natural scenes.
Neural networks of preattentive and attentive vision
model elements of this complex task. A neural model of
the processes of segregation and analysis of emergent
visual groupings explains data on human visual search. A
neural network architecture for 3-D object recognition
achieves efficient performance by synthesizing
predictive evidence across 2-D views.
Visual search data are given a unified quantitative
explanation by a model of how spatial maps in the
parietal cortex and object recognition categories in the
inferotemporal cortex deploy attentional resources as
they reciprocally interact with visual representations
in the prestriate cortex. Visual search performance is
modeled by organizing multiple experimental items that
lie within a given boundary or surface representation
into a candidate grouping. These items are compared with
learned object recognition categories. Mismatches can
trigger deeper searches and recursive selection of new
groupings until a target object is identified. This
search model is algorithmically specified to
quantitatively simulate search data using a single set
of parameters, as well as to qualitatively explain a
still larger data base.
A neural network architecture is introduced that uses
spatial and temporal evidence for pattern class
identification after supervised and unsupervised
learning. Applications include image understanding and
prediction and 3-D object recognition from a series of
ambiguous 2-D views. The architecture, called ART-EMAP,
achieves a synthesis of adaptive resonance theory (ART)
and spatial and temporal evidence integration for
dynamic predictive mapping (EMAP). ART-EMAP extends the
capabilities of fuzzy ARTMAP in four incremental stages.
Stage 1 introduces distributed pattern representation at
a view category field. Stage 2 adds a decision criterion
to the mapping between view and object categories. Stage
3 augments the system with a field where evidence
accumulates over multiple views. Stage 4 adds an
unsupervised learning process to fine-tune performance.
Each ART-EMAP stage is illustrated with a benchmark
simulation example and a more difficult 3-D object
recognition problem, using both noisy and noise-free
data.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  2734 </NUMBER>
<ORDER>   AAIMM01410 </ORDER>
<TITLE> A 1.2 MICRON NEURAL NETWORK DESIGN </TITLE>
<AUTHOR> LEI, KA WA </AUTHOR>
<YEAR> 1994 </YEAR>
<INSTITUTION> UNIVERSITY OF WINDSOR (CANADA); 0115 </INSTITUTION>
<DESCRIPTORS> ENGINEERING, ELECTRONICS AND ELECTRICAL; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> W. C. MILLER; G. A. JULLIEN </ADVISER>
<CLASSIFICATIONS> NIL </CLASSIFICATIONS>
<ABSTRACT>
This thesis explores the design and implementation of a
multilayer programmable optically coupled neural network
in the Northern Telecom 1.2$mu$ Complementary Metal
Oxide Semiconductor (CMOS) process. The motivation for
this work originated from the results obtained from the
fabricated implementation of fixed weight optically
coupled neural networks in the Northern Telecom 3$mu$
CMOS process. Previous designs were fabricated and
tested with remarkable results. The new design of the
optically coupled neural network is a translation of the
previous designs from 3$mu$ to 1.2$mu$ CMOS technology
with the improvement of the programmability. The new
programmable neural network contains 5 x 5
photosensitive elements as the input devices, 7 neurons,
and 112 synaptic weights. Also, the design includes 596
bit memory as the on-chip weight storage. This digital
memory, along with other analog circuitries, makes the
network a hybrid network. Each synaptic weight is
represented by a 5-bit digital signal, and digital to
analog (D/A) conversion is followed for the analog
computation. The Very Large-Scale Integration (VLSI)
implementation mask layouts of this network are
completely verified. Functionality of the building
blocks for the network is proved by the SPICE
simulations. The main usage of this network is for the
pattern recognition which is currently involved in
another industrial research project at the University of
Windsor. The programmability of the network provides the
feature of multi-set of patterns. It also develops the
features of a training loop network.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  2735 </NUMBER>
<ORDER>   AAG9422343 </ORDER>
<TITLE> A COMPUTER ARCHITECTURE FOR IMPLEMENTATION WITHIN AUTONOMOUS MACHINES  </TITLE>
<AUTHOR> COLLINS, THOMAS RILEY </AUTHOR>
<YEAR> 1994 </YEAR>
<INSTITUTION> GEORGIA INSTITUTE OF TECHNOLOGY; 0078 </INSTITUTION>
<DESCRIPTORS> ENGINEERING, ELECTRONICS AND ELECTRICAL; COMPUTER SCIENCE; ENGINEERING, MECHANICAL; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> CECIL O. ALFORD </ADVISER>
<CLASSIFICATIONS> ROBOTICS </CLASSIFICATIONS>
<ABSTRACT>
As additional capabilities are added to intelligent
machines, they are increasingly likely to require
sophisticated parallel architectures, but no general
consensus has developed with regard to the basic form of
such architectures. A structure called ANIMA is
proposed, derived from basic principles, which is
capable of implementing approaches generally considered
to be incompatible, allowing it to serve as a platform
for comparing methodologies on a single machine. ANIMA
is targeted for all types of intelligent sensor-based
systems and can be implemented in a variety of ways,
including heterogeneous processor networks. The
architecture is described symbolically in the language
of CSP (Communicating Sequential Processes), and a proof
of freedom from deadlock is given. The timing
characteristics of ANIMA are analyzed from the
standpoint of response to machine perceptions. An
implementation based on the Inmos transputer is
developed, with the ability to control either an actual
mobile robot or a simulated machine, with the simulation
occurring within the same processor network. The
implementation includes a variety of modular components,
each described as a separate case study. These include
low-level sensor and effector subsystems, as well as
several different reasoning structures. A complete
functional robot using ANIMA has participated in a
mobile robot competition with entries from other schools
and institutions. Follow-on systems have targeted
another competition and a hazardous waste application
for the Department of Energy.
The fundamental goal of this research is to establish a
useful framework of abstractions for truly autonomous
machines and to relate them to actual hardware
requirements. In so doing, an architectural basis is
established for a family of robots, which can evolve
merely through improvements in algorithms, technology
enhancements in the hardware modules, and expansion by
adding modules.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  2736 </NUMBER>
<ORDER>   AAG9422133 </ORDER>
<TITLE> ABSTRACTION PLANNING IN REAL TIME </TITLE>
<AUTHOR> WASHINGTON, RICHARD MARVIN </AUTHOR>
<YEAR> 1994 </YEAR>
<INSTITUTION> STANFORD UNIVERSITY; 0212 </INSTITUTION>
<DESCRIPTORS> COMPUTER SCIENCE; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> BARBARA HAYES-ROTH </ADVISER>
<CLASSIFICATIONS> NIL </CLASSIFICATIONS>
<ABSTRACT>
When a planning agent works in a complex, real-world
domain, it is unable to plan for and store all possible
contingencies and problem situations ahead of time. The
agent needs to be able to fall back on an ability to
construct plans at run time under time constraints. This
thesis presents a method for planning at run time that
incrementally builds up plans at multiple levels of
abstraction. The plans are continually updated by
information from the world, allowing the planner to
adjust its plan to a changing world during the planning
process. All the information is represented over
intervals of time, allowing the planner to reason about
durations, deadlines, and delays within its plan. In
addition to the method, the thesis presents a formal
model of the planning process and uses the model to
investigate planning strategies. The method has been
implemented, and experiments have been run to validate
the overall approach and the theoretical model.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  2737 </NUMBER>
<ORDER>   AAG9422076 </ORDER>
<TITLE> DECIDING WHETHER TO PLAN TO REACT </TITLE>
<AUTHOR> DABIJA, VLAD GRIGORE </AUTHOR>
<YEAR> 1994 </YEAR>
<INSTITUTION> STANFORD UNIVERSITY; 0212 </INSTITUTION>
<DESCRIPTORS> COMPUTER SCIENCE; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> BARBARA HAYES-ROTH </ADVISER>
<CLASSIFICATIONS> CONTROL, PLANNING TIME </CLASSIFICATIONS>
<ABSTRACT>
Intelligent agents that operate in real-world real-time
environments have limited resources. An agent must take
these limitations into account when deciding which of
two control modes--planning versus reaction--should
control its behavior in a given situation. The main goal
of this thesis is to develop a framework that allows a
resource-bounded agent to decide at planning time which
control mode to adopt for anticipated possible run-time
contingencies. Using our framework, the agent: (a)
analyzes a complete (conditional) plan for achieving a
particular goal; (b) decides which of the anticipated
contingencies require and allow for preparation of
reactive responses at planning time; and (c) enhances
the plan with prepared reactions for critical
contingencies, while maintaining the size of the plan,
the planning and response times, and the use of all
other critical resources of the agent within task-
specific limits. For a given contingency, the decision
to plan or react is based on the characteristics of the
contingency, the associated reactive response, and the
situation itself. Contingencies that may occur in the
same situation compete for reactive response preparation
because of the agent's limited resources. The thesis
also proposes a knowledge representation formalism to
facilitate the acquisition and maintenance of knowledge
involved in this decision process. We also show how the
proposed framework can be adapted for the problem of
deciding, for a given contingency, whether to prepare a
special branch in the conditional plan under development
or to leave the contingency for opportunistic treatment
at execution time. We make a theoretical analysis of the
properties of our framework and then demonstrate them
experimentally. We also show experimentally that this
framework can simulate several different styles of human
reactive behaviors described in the literature and,
therefore, can be useful as a basis for describing and
contrasting such behaviors. Finally we demonstrate that
the framework can be applied in a challenging real
domain. That is: (a) the knowledge and data needed for
the decision making within our framework exist and can
be acquired from experts, and (b) the behavior of an
agent that uses our framework improves according to
response time, reliability and resource utilization
criteria.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  2738 </NUMBER>
<ORDER>   AAG9421063 </ORDER>
<TITLE> A STATISTICAL FUZZY ASSOCIATIVE LEARNING APPROACH TO INTELLIGENT CONTROL  </TITLE>
<AUTHOR> MURRELL, JAMES ARTHUR </AUTHOR>
<YEAR> 1994 </YEAR>
<INSTITUTION> GEORGIA INSTITUTE OF TECHNOLOGY; 0078 </INSTITUTION>
<DESCRIPTORS> ENGINEERING, SYSTEM SCIENCE; ENGINEERING, INDUSTRIAL; COMPUTER SCIENCE; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> A. O. ESOGBUE </ADVISER>
<CLASSIFICATIONS> NEURAL NETWORKS </CLASSIFICATIONS>
<ABSTRACT>
An approach to intelligent control is developed
integrating mathematical learning theory and neural
network techniques with fuzzy association and inference,
using the procedures and techniques of statistical
modeling as a framework. A statistical fuzzy associative
learning controller (SFAL-C) is proposed and studied for
application to a class of control problems. The problem
objective is to drive the system state to a goal state
in a manner which tends to optimize some measure of
performance. Simulation experiments demonstrate the
effectiveness of the controller for two types of systems
in this class. Process control for dynamical systems is
in many cases difficult to obtain by theoretical models
due to unknown or nonlinear dynamics. The SFAL-C has
produced comparable or better performance than several
recently introduced intelligent controllers in some
benchmark test problems of this type. The second type of
system is a communication network modeled as a network
of queues in which the problem is routing messages. The
practical demands of adaptation to increasingly fast
network changes is challenging the practicality of
standard optimization algorithms. For a rapidly time-
varying network, the SFAL-C has produced performance
which approaches that of an idealized dynamic shortest
path algorithm and which surpasses that of stochastic
learning automata, a leading alternative intelligent
control method. A key advantage of the SFAL-C is that it
learns a complete control law as a function of the
state, rather than only providing control that is tuned
to a particular initial state or that attempts to
adaptively track the state of the system.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  2739 </NUMBER>
<ORDER>   AAG9421027 </ORDER>
<TITLE> ON-LINE DAMAGE IDENTIFICATION AND MOTION CONTROL OF ADAPTIVE STRUCTURES: AN INTELLIGENT CONTROL APPROACH </TITLE>
<AUTHOR> TSOU, PO-YU </AUTHOR>
<YEAR> 1994 </YEAR>
<INSTITUTION> THE OHIO STATE UNIVERSITY; 0168 </INSTITUTION>
<DESCRIPTORS> ENGINEERING, AEROSPACE; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> M.-H. HERMAN SHEN </ADVISER>
<CLASSIFICATIONS> NIL </CLASSIFICATIONS>
<ABSTRACT>
In this dissertation, an on-line damage identification
technique and a motion controller for the adaptive
structure are developed under the scope of an
intelligent control framework. The computational
intelligence techniques, especially neural networks and
fuzzy logic control, are studied on their application to
the adaptive truss structure.
The adaptive structure has the ability to change the
configuration and/or physical properties amenable to the
varying environment or to accomplish various mission
requirements. This dissertation first overviews an
intelligent control framework specified for the adaptive
structures. The intelligent control system consists of
three hierarchical levels, from up to down, Management
and Organisation level, Coordination level, and
Execution level. The elementary classification of the
levels and the responsibilities of major functions in
each level are described in this study.
The work then investigates two major functions in the
Execution level: structural damage detection and
identification, and motion control. A neural-network-
based damage identification technique which is able to
detect the damage location accurately and then to
identify the damage severity with reasonable precision
is proposed. The new architecture of neural network
provides several advantages over conventional
approaches: first, this technique only needs as few as
possible modal data, i.e. eigenvalues and normalised
mode shape, to identify structural damages; second, it
can detect multiple damages case; third, the process can
be realized on-line, moreover, the damage location
detection can be done in real-time.
Next, a fuzzy logic controller is used for the motion
control of the adaptive truss structure. A systematical
procedure to design fuzzy controller is proposed. The
fuzzy rules can be constructed by referring the
kinematics of the structure, thus omitting conventional
trial-and-error approach. The controller was tested on
several different tasks such as rendezvous/docking,
target pursuing, and trajectory tracking. The results
show the control scheme is effective and reliable. The
effects of the performance by varying design parameters
are also investigated. The general guidelines for
selecting the design parameters are addressed.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  2740 </NUMBER>
<ORDER>   AAG9420951 </ORDER>
<TITLE> IDENTIFICATION AND ANALYSIS OF MANUFACTURING PROCESS DATA RELATIONSHIPS: INVESTIGATION AND DEMONSTRATION </TITLE>
<AUTHOR> EVANS, PATRICIA ANN </AUTHOR>
<YEAR> 1994 </YEAR>
<INSTITUTION> THE OHIO STATE UNIVERSITY; 0168 </INSTITUTION>
<DESCRIPTORS> ENGINEERING, INDUSTRIAL; COMPUTER SCIENCE; ENGINEERING, CHEMICAL; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> RICHARD ALLEN MILLER </ADVISER>
<CLASSIFICATIONS> EXPERT SYSTEMS, GLASS TRANSITION TEMPERATURE </CLASSIFICATIONS>
<ABSTRACT>
This research addressed analysis and interpretation of
manufacturing data, demonstrated using autoclave curing
of bismaleimide matrix composite materials. The purpose
was to assist materials or manufacturing specialists in
analyzing and learning about materials and processes by
exploiting meaning behind manufacturing data
relationships. Steps included finding kinds of data to
analyze and semantic relationships among them, exploring
analysis techniques and their synthesis, developing a
system construction procedure, and prototyping an
automated customized analysis tool.
Seventy-six kinds of data were identified and structured
with their known interrelationships in a hypertext
database. Analysis techniques and tools were cataloged.
Causal analysis was used to analyze data in a prototype
analysis system.
Glass transition temperature, time the part spent over
some temperature, and maximum part temperature during
processing were analyzed. Known relationships were
retrieved from the database, data were read into a
spreadsheet, and a plot was created. The program
determined whether the glass transition temperature was
below, above, or at the expected value. Conclusions were
made about the significance of various temperatures and
the resulting glass transition temperature.
A second analysis was for autoclave pressure and
dielectric measurements. It searched for patterns such
as two variables consistently increasing or decreasing
together or one immediately after the other, or one
variable consistently increasing immediately before,
during or immediately after another decreases.
Relationships discovered were presented to the user.
The system itself did not provide new information.
Results of the first analysis gave the user ideas for
further experimentation. The user suggested the second
analysis might be useful for a different material
composition. This analysis also suggested a relationship
that was known to the user but unknown to this
researcher.
The contributions this research makes include
identification and structuring of semantic data
relationships for a specific domain, categorization of
analysis techniques, some synthesis of analyses, a data
analysis tool customization method, and demonstration of
feasibility for writing an analysis tool in a specific
domain. Contributions exist in both the analysis tool
design area and in the domain area. There is also
potential for generality across hardware, software,
processes, products, and users.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  2741 </NUMBER>
<ORDER>   AAG9420949 </ORDER>
<TITLE> FLUID-FILM LUBRICATION WITH AN APPLICATION TO PISTON RINGS </TITLE>
<AUTHOR> ESFAHANIAN, MOHSEN </AUTHOR>
<YEAR> 1994 </YEAR>
<INSTITUTION> THE OHIO STATE UNIVERSITY; 0168 </INSTITUTION>
<DESCRIPTORS> ENGINEERING, MECHANICAL; ENGINEERING, AUTOMOTIVE </DESCRIPTORS>
<ADVISER> BERNARD J. HAMROCK </ADVISER>
<CLASSIFICATIONS> NIL </CLASSIFICATIONS>
<ABSTRACT>
This dissertation consists of four related studies. The
first part provides dimensionless film thickness
equations for four fluid-film lubrication regimes found
for nonconformal surfaces while considering side-leakage
effects. These regimes are isoviscous rigid,
piezoviscous rigid, isoviscous elastic, and piezoviscous
elastic. The influence or lack of influence of elastic
effects from the solid surfaces and pressure-viscosity
effects from the lubricant is a factor that
distinguishes these regimes. Results are presented as a
map of the lubrication regimes for four values of the
ellipticity parameter.
The second part deals with integrating artificial
intelligence and conventional numerical design
techniques to aid in tribological design. The study
concentrates on the application of contact stresses. The
result is a computer code, the Design Expert for Contact
Stress, which incorporates and combines an expert system
with numerical analysis techniques to aid the user in
designing machine elements. This menu-driven program
also performs a design compatibility analysis, which
evaluates the compatibility between the specifications
and the design, provides a rating on the overall design,
lists reasons for the evaluation, and gives suggestions
for improvements.
The third part investigates the rheological effects in
elastohydrodynamic lubrication. In this study the
effects on fluid viscosity of pressure, temperature,
shear strain rate, shear stress, and time are examined.
A number of non-Newtonian models are introduced. The
effects of pressure on fluid density are described. The
role of solidification pressure on the density of the
lubricants is also examined. The possible influence of a
lubricant's viscoelastic behavior on its viscosity is
considered. Finally, the influence of rheological
effects on elastohydrodynamic lubrication is explained.
The last part describes fundamental research into the
basic mechanisms involved in piston ring lubrication. A
recently developed system numerical approach is used for
obtaining the lubrication characteristics of the piston
ring-cylinder liner conjunction. A complete hydrodynamic
and elastohydrodynamic lubrication analysis considering
lubricant film shapes and pressure profiles is
performed. This requires the simulation of both squeeze
and entraining motion of the piston ring throughout an
engine cycle. Existence of fluid-film lubrication
throughout the engine cycle is examined.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  2742 </NUMBER>
<ORDER>   AAG9420712 </ORDER>
<TITLE> A KNOWLEDGE-BASED ARCHITECTURE FOR QUERY FORMULATION AND PROCESSING IN FEDERATED HETEROGENEOUS DATABASES </TITLE>
<AUTHOR> WEISHAR, DOYLE JOSEPH </AUTHOR>
<YEAR> 1994 </YEAR>
<INSTITUTION> GEORGE MASON UNIVERSITY; 0883 </INSTITUTION>
<DESCRIPTORS> COMPUTER SCIENCE; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> LARRY KERSCHBERG </ADVISER>
<CLASSIFICATIONS> NIL </CLASSIFICATIONS>
<ABSTRACT>
Existing (or legacy) databases are typified by
differences in data representation, data access
languages, and differing data models. Data
representation differences include name, format and
structural differences for identical and similar data
stored in more than one legacy database. Data access
language differences may require multiple queries to
complete the retrieval of all values of a data element
stored in more than one legacy database. And differences
in data model constructs may result in similarly named
data elements being represented at different levels of
abstraction which exhibit different properties. These
differences make access difficult for most users.
To resolve such problems, this dissertation addresses a
user's need to formulate queries to multiple
heterogeneous databases easily, and to have confidence
in the results that are returned.
The Intelligent Heterogeneous Autonomous Database
Architecture (InHead) approach involves the use of
Artificial Intelligence tools and techniques to
construct "domain models," that is data and knowledge
representations of the constituent databases and an
overall domain model of the semantic interactions among
the databases. These domain models are represented as
Knowledge Sources (KSs) in a blackboard architecture.
The work described in this dissertation provides four
major contributions. The first is the specification of
an active and intelligent global thesaurus. The second
contribution is the extension of the traditional notion
of an export schema into that of an "Export
Data/Knowledge/Task" schema. The third contribution is
the specification and use of "Data/knowledge Packets,"
which are a means of encapsulating object structure,
relationships, operations, constraints, and rules into a
meaningful unit, or packet. The fourth contribution is
the specification an intelligent heterogeneous database
architecture that provides a framework for the above.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  2743 </NUMBER>
<ORDER>   AAG9420690 </ORDER>
<TITLE> LEARNING TO SOLVE MARKOVIAN DECISION PROCESSES </TITLE>
<AUTHOR> SINGH, SATINDER PAL </AUTHOR>
<YEAR> 1994 </YEAR>
<INSTITUTION> UNIVERSITY OF MASSACHUSETTS; 0118 </INSTITUTION>
<DESCRIPTORS> COMPUTER SCIENCE; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> ANDREW G. BARTO </ADVISER>
<CLASSIFICATIONS> MACHINE LEARNING </CLASSIFICATIONS>
<ABSTRACT>
This dissertation is about building learning control
architectures for agents embedded in finite, stationary,
and Markovian environments. Such architectures give
embedded agents the ability to improve autonomously the
efficiency with which they can achieve goals. Machine
learning researchers have developed reinforcement
learning (RL) algorithms based on dynamic programming
(DP) that use the agent's experience in its environment
to improve its decision policy incrementally. This is
achieved by adapting all evaluation function in such a
way that the decision policy that is "greedy" with
respect to it improves with experience. This
dissertation focuses on finite, stationary and Markovian
environments for two reasons: it allows the development
and use of a strong theory of RL, and there are many
challenging real-world RL tasks that fall into this
category.
This dissertation establishes a novel connection between
stochastic approximation theory and RL that provides a
uniform framework for understanding all the different RL
algorithms that have been proposed to date. It also
highlights a dimension that clearly separates all RL
research from prior work on DP. Two other theoretical
results showing how approximations affect performance in
RL provide partial justification for the use of compact
function approximators in RL. In addition, a new family
of "soft" DP algorithms is presented. These algorithms
converge to solutions that are more robust than the
solutions found by classical DP algorithms.
Despite all of the theoretical progress, conventional RL
architectures scale poorly enough to make them
impractical for many real-world problems. This
dissertation studies two aspects of the scaling issue:
the need to accelerate RL, and the need to build RL
architectures that can learn to solve multiple tasks. It
presents three RL architectures, CQ-L, H-DYNA, and BB-
RL, that accelerate learning by facilitating transfer of
training from simple to complex tasks. Each architecture
uses a different method to achieve transfer of training;
CQ-L uses the evaluation functions for simple tasks as
building blocks to construct the evaluation function for
complex tasks, H-DYNA uses the evaluation functions for
simple tasks to build an abstract environment model, and
BB-RL uses the decision policies found for the simple
tasks as the primitive actions for the complex tasks. A
mixture of theoretical and empirical results are
presented to support the new RL architectures developed
in this dissertation.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  2744 </NUMBER>
<ORDER>   AAG9419477 </ORDER>
<TITLE> FLUENT.1: TOWARD A SYSTEM FOR FOREIGN LANGUAGE UNDERSTANDING ENGENDERED BY NATURALISTIC TECHNIQUES </TITLE>
<AUTHOR> MANEY, TUCKER H. </AUTHOR>
<YEAR> 1994 </YEAR>
<INSTITUTION> GEORGE MASON UNIVERSITY; 0883 </INSTITUTION>
<DESCRIPTORS> COMPUTER SCIENCE; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> HENRY HAMBURGER </ADVISER>
<CLASSIFICATIONS> NIL </CLASSIFICATIONS>
<ABSTRACT>
The FLUENT (Foreign language understanding engendered by
naturalistic techniques) project is an attempt to
specify and implement an intelligent computational
environment for learning foreign languages.
Specifically, this effort seeks to create an immersion-
style learning environment based on the premise that
language is best learned in the course of meaningful
communication. Immersion means using the new language in
authentic situations, not analyzing or consciously
constructing grammatical sentences. Hence, the system
would incorporate no first language/second language
translation or explicit teaching of grammatical or
morphological rules. The student would learn a second
language by interacting with the system both graphically
and through conversation.
The purpose of this project is to identify the immersive-
style pedagogical strategies supported by current second
language acquisition research and explore how these
techniques can be adapted to a computer-based situation.
This study describes FLUENT.1, a FLUENT prototype system
that shows that it is feasible to create a computational
environment in which students can get a sense of an
immersion experience. As a prototype, the system
provides a framework in which to address the problems
and issues involved in building the FLUENT tutoring
system.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  2745 </NUMBER>
<ORDER>   AAIMM00525 </ORDER>
<TITLE> RECOGNITION OF OVERLAPPING OBJECTS </TITLE>
<AUTHOR> DAMERJI, TAIEB R. </AUTHOR>
<YEAR> 1994 </YEAR>
<INSTITUTION> UNIVERSITY OF OTTAWA (CANADA); 0918 </INSTITUTION>
<DESCRIPTORS> ENGINEERING, ELECTRONICS AND ELECTRICAL; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> DAN IONESCU </ADVISER>
<CLASSIFICATIONS> NIL </CLASSIFICATIONS>
<ABSTRACT>
This thesis describes the design and implementation of a
model-based vision system for the recognition of
partially occluded objects. The system can detect
occlusion. It can also recognize and locate the objects
forming the occlusion scene.
The system has two modes of operation: a learning mode
and a recognition mode. In the learning mode the objects
to be recognized are analyzed, their boundaries
processed and a model representing each object is
created and added to a list of object models. In the
recognition mode the system analyzes the image which may
contain several objects, the objects may occlude each
other. The system processes the image, detects whether
there is occlusion and then identifies and locates the
objects present in the image.
The objects' models are based on the parameters of an
auto-regressive (AR) filter.
In the recognition mode the system first generates the
scene sub-parts, then it goes through the three phases
of the recognition: namely hypotheses generation,
pruning and verification. (Abstract shortened by UMI.)
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  2746 </NUMBER>
<ORDER>   AAG9422563 </ORDER>
<TITLE> FUZZY REPRESENTATION OF THE LANDSCAPE IN A NEURAL NETWORK FOR CLASSIFICATION OF REMOTE SENSING DATA </TITLE>
<AUTHOR> SHYY, TUNG-KAI </AUTHOR>
<YEAR> 1994 </YEAR>
<INSTITUTION> THE UNIVERSITY OF OKLAHOMA; 0169 </INSTITUTION>
<DESCRIPTORS> GEOGRAPHY; REMOTE SENSING; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> T. H. LEE WILLIAMS </ADVISER>
<CLASSIFICATIONS> LAND USE MAPPING </CLASSIFICATIONS>
<ABSTRACT>
High resolution satellite data, combined with image
processing and advanced techniques such as fuzzy sets
and neural networks, can be valuable tools for land
use/cover mapping. The conventional multispectral
classification cannot properly represent class mixture
in a pixel. This is a problem typically found in urban
landscapes. The objective of this research was to study
in which form the landscape should be represented in a
neural network for obtaining the best possible
classification of Landsat Thematic Mapper (TM) data. The
landscape attributes (e.g. spectral and spatial
characteristics of the landscape) are measured from TM
data using automated image processing. Fuzzy membership
functions encoded in linear, non-linear, and min-max non-
linear forms are developed to determine grades of
membership for fuzzy representation of the landscape. A
back-propagation network (BPN) classifier is created for
land use/cover classification of Norman, Oklahoma.
Training data derived from the grades of membership are
incorporated into a neural network classification. The
accuracies of classification are assessed and compared
with those obtained from a maximum likelihood (MLH)
classifier. The Kappa-like coefficient of agreement is
calculated as an accuracy measure for each of the two
classifications. Tests for statistical significance of
the difference between two Kappa-like coefficients are
performed by Z-test. The performance of the min-max non-
linear encoding using appropriate training data in a BPN
classifier is significantly better than the MLH
classifier in terms of classification accuracy. The
representation and arrangement (allocation and volume)
of the training data are crucial factors that influence
the BPN classification results.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  2747 </NUMBER>
<ORDER>   AAG9422357 </ORDER>
<TITLE> BUILDING ENERGY DESIGN AND OPTIMIZATION: INTELLIGENT COMPUTER-AIDED THERMAL DESIGN </TITLE>
<AUTHOR> MALKAWI, ALI MAHMOUD </AUTHOR>
<YEAR> 1994 </YEAR>
<INSTITUTION> GEORGIA INSTITUTE OF TECHNOLOGY; 0078 </INSTITUTION>
<DESCRIPTORS> ARCHITECTURE; ENGINEERING, HEAT AND THERMODYNAMICS; COMPUTER SCIENCE </DESCRIPTORS>
<ADVISER> J. M. AKRIDGE </ADVISER>
<CLASSIFICATIONS> ENERGY OPTIMIZATION </CLASSIFICATIONS>
<ABSTRACT>
Thermal comfort is an essential consideration in
building design. Due to the mathematical nature of
evaluating and optimizing thermal comfort in buildings,
architects tend to avoid energy design simulation. The
issues of evaluation and criticism regarding energy
optimization in building design are seldom considered
during the design process. These issues depend on
interpretation of the complex figures that rely on a
thorough understanding of the nature of load generation
and building configuration of a particular site.
The scope of this study is to propose a theory for a
rigorous design oriented method to evaluate, critique
and optimize energy use and design in buildings. The
focus is on the relationship between detailed thermal
analysis and advice and criticism for case sensitive
energy design optimization. The method is based on a
hierarchical representation of building elements in the
simulation mode to establish a well-defined output
taking into consideration possible element interactions
and conflicts. This output is designed to provide
changeable factual knowledge of the proposed design and
is used to build associations with the inference process
and related knowledge sources. The inference process is
used to optimize the building energy design by providing
criticism and advice. The criticism and advice are
conducted based on problem detection and their locations
using Artificial Intelligence uncertain reasoning,
heuristics and search methods. Their framework utilizes
the Blackboard model to facilitate dynamic multi-
knowledge interaction and conflict avoidance within
problem solving. The proposed method is tested by
developing an intelligent computational model that
simulates, evaluates and aids in thermal design
decisions. The system critiques designs, gives advice
and provides guidance and justification for its optimal
solution recommendations.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  2748 </NUMBER>
<ORDER>   AAG9420091 </ORDER>
<TITLE> A NEURAL NETWORK APPROACH TO GEOGRAPHICAL ANALYSIS OF POPULATION PATTERN CHANGE </TITLE>
<AUTHOR> CHANG, KUO-CHEN </AUTHOR>
<YEAR> 1994 </YEAR>
<INSTITUTION> UNIVERSITY OF MINNESOTA; 0130 </INSTITUTION>
<DESCRIPTORS> GEOGRAPHY; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> DWIGHT A. BROWN </ADVISER>
<CLASSIFICATIONS> SPATIAL DISTRIBUTIONS </CLASSIFICATIONS>
<ABSTRACT>
Spatial distributions are a central interest in
geography. These patterns often represent a temporal
dynamic state between explanatory variables that control
the dispersing process of the objects. Population
patterns of different groups or classes of objects
change in space through processes of birth, death,
migration, and dispersion. Some population patterns
result from the evolution of successful dispersal
strategies, and others involve conscious thought. The
former is exemplified by plants that disperse into new
territories. The latter characterizes winter traveling
decision-making processes of human, based on the
learning of individuals.
In spite of the differences between processes of non-
thinking plant dispersion and thoughtful human
movements, the spatial changes are similar in many
respects. The distributions of available resources
constrain how spatial pattern can change. Different
geological structures, rocks, soil, relief, climate, and
vegetation bias how humans, other animals, and plants
move to find suitable places. All actors share some
common characteristics: they move to new environments,
compete with each other for the limited, but vital,
resources, and are subject to similar types of
geographical analysis.
Many statistical methods have been used for spatial
analyses, including correlation regression, factor
analysis, trend surface analysis spatial auto-
correlation, and Monte Carlo diffusion simulation. The
considerations of (1) data distribution unknown, (2)
mixture of variables with different levels of
measurement, (3) no formal, explicit knowledge available
to describe relationship between variables involved make
us believe that there is a continuous need for new
geographical analysis tools that are free of these
limitations.
A neural network is an artificial network connection
designed to mimic the function and behaviors of
biological neurons and human's brain, especially in
learning and memorizing from the previous experiences.
It is independent of the distribution of data. The
interactions and relationships are represented as
weights of linkages connecting from input variables to
output variables. To further our understanding, I
proposed to examine, develop, and apply neural network
as an alternative to define the interactions and
relationships that underlie population pattern changes.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  2749 </NUMBER>
<ORDER>   AAG9418633 </ORDER>
<TITLE> ANALOG VLSI AUTONOMOUS SYSTEMS FOR LEARNING AND OPTIMIZATION </TITLE>
<AUTHOR> CAUWENBERGHS, GERT </AUTHOR>
<YEAR> 1994 </YEAR>
<INSTITUTION> CALIFORNIA INSTITUTE OF TECHNOLOGY; 0037 </INSTITUTION>
<DESCRIPTORS> ENGINEERING, ELECTRONICS AND ELECTRICAL; COMPUTER SCIENCE; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> AMNON YARIV </ADVISER>
<CLASSIFICATIONS> VLSI </CLASSIFICATIONS>
<ABSTRACT>
The integration of adaptive functions within analog
neural hardware, while certainly promising to enhance
system performance, has for long been hindered by
technological difficulties due to the complexity and
sensitivity of standard adaptation algorithms. We
present a general framework for self-contained
adaptation in analog VLSI supporting a broad class of
supervised learning and optimization tasks, which
largely alleviates the implementation problems by virtue
of a robust system approach exploiting statistics and
redundancy in stochastic processes. Specifically, the
framework includes: (i) a perturbative algorithm based
on stochastic approximation to optimize a set of
parameters in an arbitrary deterministic system, these
parameters being adjusted according to global
performance evaluations rather than using explicit
knowledge about the internal structure of the system;
and (ii) a scalable and modular CMOS architecture that
implements this algorithm, and that additionally
provides for embedded long-term dynamic storage of the
volatile analog parameter values, quantized locally and
refreshed autonomously on capacitors with direct
external access in both digital and analog formats. We
analyze the convergence and scaling properties of the
stochastic algorithm, present on-line versions of the
algorithm for supervised learning in dynamical systems,
and provide experimental results demonstrating real-time
trajectory learning on an analog CMOS chip containing a
network of six fully recurrent dynamical neurons. We
also include results demonstrating robust long-term
retention of locally stored volatile information in
analog VLSI using the autonomous refresh technique.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  2750 </NUMBER>
<ORDER>   AAG9418485 </ORDER>
<TITLE> ECLECTIC MACHINE LEARNING </TITLE>
<AUTHOR> BARKER, JOSEPH CORY </AUTHOR>
<YEAR> 1994 </YEAR>
<INSTITUTION> BRIGHAM YOUNG UNIVERSITY; 0022 </INSTITUTION>
<DESCRIPTORS> COMPUTER SCIENCE; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> TONY R. MARTINEZ </ADVISER>
<CLASSIFICATIONS> LEARNING ALGORITHMS, NEURAL NETWORKS </CLASSIFICATIONS>
<ABSTRACT>
This dissertation presents a family of inductive
learning systems that derive general rules from specific
examples. These systems combine the benefits of neural
networks, ASOCS, and symbolic learning algorithms. The
systems presented here learn incrementally with good
speed and generalization. They are based on a parallel
architectural model that adapts to the problem being
learned. Learning is done without requiring user
adjustment of sensitive parameters, and noise is
tolerated with graceful degradation in performance.
The systems described in this work are based on
features. Features are subsets of the input space. One
group of learning algorithms begins with general
features and specializes those features to match the
problem that is being learned. Another group creates
specific features and then generalizes those features.
The final group combines the approaches used in the
first two groups to gain the benefits of both.
The algorithms are O(m log m), where m is the number of
nodes in the network, and the number of inputs and
output values are treated as constants. An enhanced
network topology reduces time complexity to O(log m).
Empirical results show that the algorithms give good
generalization and that learning converges in a small
number of training passes.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  2751 </NUMBER>
<ORDER>   AAG9418338 </ORDER>
<TITLE> APPLYING DISTRIBUTED ARTIFICIAL INTELLIGENCE TO THE PREQUALIFICATION OF CONSTRUCTION CONTRACTORS </TITLE>
<AUTHOR> TAHA, MAHMOUD ABD-ELSALAM </AUTHOR>
<YEAR> 1994 </YEAR>
<INSTITUTION> THE UNIVERSITY OF WISCONSIN - MADISON; 0262 </INSTITUTION>
<DESCRIPTORS> ENGINEERING, CIVIL; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> JEFFREY SCOTT RUSSELL </ADVISER>
<CLASSIFICATIONS> NIL </CLASSIFICATIONS>
<ABSTRACT>
The construction industry has been criticized, to a
large extent, for its slow acceptance and use of
technological improvements to plan and execute projects.
The changing global environment and the increasing
complexity of the industry has created a need for
adopting advanced technologies. Computer-based
technologies such as artificial intelligence techniques
are generating interest as potential aids for decision
making in different engineering and management decision
domains. Knowledge-based systems have steadily been
introduced for different applications in the
construction industry. Most of the knowledge-based
system applications currently available for the
construction industry can be described as a single agent
system in which a single body of knowledge is used to
solve the entire problem. Such systems require intensive
software development and maintenance in addition to
large allocated memory. They also lack the ability to
learn by themselves, generalize solutions and adequately
respond to highly correlated, noisy or previously unseen
data. Moreover, single agent systems are not adequate
for solving human problems that usually requires the
involvement of multiple decision makers.
This dissertation illustrates the capabilities of
distributed artificial intelligence in representing and
using knowledge in the construction industry. The
objective of this study is two-fold: (1) to introduce a
methodology, that uses the distributed artificial
intelligence capabilities, to develop adaptive DSS for
solving construction industry problems and (2) to
develop an adaptive computerized tool for performing
owner-contractor prequalification. These objectives were
achieved through the development of the Contractor
Selector Decision Support System, CONSEL, an adaptive
DSS for prequalifying construction contractors. The
problem solving strategy of the developed DSS was
distributed among eight problem solvers to mimic the
actual prequalification procedure that involves several
tasks. Different problem solvers of the system were
developed by using the learning capabilities of neural
networks and production rules. The distributed
artificial intelligence architecture suits the area of
contractor prequalification in which several tasks are
examined and integrated to arrive at the final decision.
A learning subsystem is included to modify its problem
solving knowledge through experience. These learning
capabilities will constantly improve the system's
performance.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  2752 </NUMBER>
<ORDER>   AAG9417902 </ORDER>
<TITLE> GENETIC-NEURO SCHEDULER </TITLE>
<AUTHOR> SITTISATHANCHAI, SINCHAI </AUTHOR>
<YEAR> 1994 </YEAR>
<INSTITUTION> UNIVERSITY OF MISSOURI - ROLLA; 0135 </INSTITUTION>
<DESCRIPTORS> OPERATIONS RESEARCH; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> CIHAN H. DAGLI </ADVISER>
<CLASSIFICATIONS> SCHEDULING, JOB SHOP </CLASSIFICATIONS>
<ABSTRACT>
In this study, a hybrid approach between two new
techniques, Genetic Algorithm and Artificial Neural
Network, is described for generating Job Shop Schedules
(JSS) in a discrete manufacturing environment based on
nonlinear multi-objective function. Genetic Algorithm
(GA) is used as an effective search technique for
finding an optimal schedule via a population of gene
strings which represent alternative feasible schedules.
GA propagates a new population of genes through a number
of cycles called generations by implementing natural
genetic mechanism. The other technique is an Artificial
Neural Network that performs multiobjective schedule
evaluator. The intention is to establish an effective
model that maps a complex set of scheduling criteria
(i.e. flowtime, lateness) to appropriate values provided
by experienced expert schedulers. This neural network is
later combined with Genetic Algorithm. Specifically, GA
uses the Neural Network evaluator to access the fitness
performance of gene strings simulated.
The proposed approach is prototyped and tested on four
different JSS problems based on the sizes of the
problem, namely small, medium, large, and real problems
provided by a company. The comparative results indicate
that the proposed approach is consistently better than
those of heuristic algorithms used extensively in
industry.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  2753 </NUMBER>
<ORDER>   AAG9417251 </ORDER>
<TITLE> PREDICTION OF GENERALIZATION ABILITY IN LEARNING MACHINES  </TITLE>
<AUTHOR> CORTES, CORINNA </AUTHOR>
<YEAR> 1994 </YEAR>
<INSTITUTION> THE UNIVERSITY OF ROCHESTER; 0188 </INSTITUTION>
<DESCRIPTORS> COMPUTER SCIENCE; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> RANDAL NELSON </ADVISER>
<CLASSIFICATIONS> MARGIN CLASSIFICATION </CLASSIFICATIONS>
<ABSTRACT>
Training a learning machine from examples is
accomplished by minimizing a quantitative error measure,
the training error defined over a training set. A low
error on the training set does not, however, guarantee a
low expected error on any future example presented to
the learning machine--that is, a low generalization
error.
The main goal of the dissertation is to merge theory and
practice: to develop theoretically based, but
experimentally adapted tools that allow an accurate
prediction of the generalization error of an arbitrarily
complex classifier.
This goal is reached through experimental and
theoretical studies of the relationship between the
training and generalization error for a variety of
learning machines.
The result is the introduction of a practical and
principled method for predicting the generalization
error. The power and accuracy of the predictive
procedure is illustrated from application to real-life
problems.
Theoretical inspiration for the model arises from
calculations of the expected difference between the
training and generalization error for some simple
learning machines. Novel computations of this character
are included in the dissertation.
Experimental studies yield experience with the
performance ability of real-life classifiers, and result
in new capacity measures for a set of classifiers.
The dissertation also presents a new classification
algorithm, the Soft Margin Classifier algorithm, for
learning with errors on the training set. The algorithm
is an extension of the Optimal Margin Classifier
algorithm, and is consistently found to outperform its
predecessor because it absorbs out-lying and erroneous
patterns in flexible margins.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  2754 </NUMBER>
<ORDER>   AAG9416918 </ORDER>
<TITLE> ARTIFICIAL NEURAL NETWORK CONFIGURATIONS FOR PREDICTING CORN YIELD AS A FUNCTION OF WATER REGIME </TITLE>
<AUTHOR> KOCH, PAUL ROBERT </AUTHOR>
<YEAR> 1994 </YEAR>
<INSTITUTION> THE UNIVERSITY OF NEBRASKA - LINCOLN; 0138 </INSTITUTION>
<DESCRIPTORS> ENGINEERING, AGRICULTURAL; AGRICULTURE, AGRONOMY; ECONOMICS, AGRICULTURAL; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> GLENN J. HOFFMAN </ADVISER>
<CLASSIFICATIONS> NEBRASKA </CLASSIFICATIONS>
<ABSTRACT>
Several feedforward artificial neural networks with
error back-propagation were trained to predict corn
yield as a function of the timing and volume of water
applications. One set of artificial neural networks
(ANNs) was developed using simulated water delivery and
yield data. The growing season was divided into time
intervals of equal length, and each ANN input node
represented the total amount of water applied within
each time interval. When an optimal time interval was
found and sufficient training data were provided,
independent tests of the trained ANNs gave r$sp2$
correlations greater than 0.90 between the predicted and
actual yields. These correlations tended to approach a
maximum value asymptotically as the size of the training
data set increased.
In a similar fashion, another set of ANNs was developed
using six years of field data from North Platte,
Nebraska. An additional input node incorporated a
measurement of soil moisture taken early in the growing
season. Depending on which data were selected for
training and testing, r$sp2$ correlations between the
predicted and actual relative yields were as high as
0.89. An ANN analysis of crop sensitivity to drought as
a function of growth stage produced values consistent
with data in the literature.
An ANN crop production model can be used with three
different iterative algorithms to allocate water among
growth stages in a manner which is optimal or nearly
optimal. The first of these algorithms begins with a
superfluous amount of water allocated across the growing
season and, with each iteration, decreases the water
allocation to that stage in which the decrement will
result in the least reduction in yield. The second of
these algorithms begins with no water allocated across
the growing season and, with each iteration, increases
the water allocation to that stage in which the
increment will result in the greatest return to yield.
The third of these algorithms begins with an assumed
seasonal supply of water applied at a constant rate
across the growing season and, with each iteration,
reallocates a marginal amount of water from a less
productive stage to a more productive stage.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  2755 </NUMBER>
<ORDER>   AAIMM00498 </ORDER>
<TITLE> AN OBJECT ORIENTED INTERACTIVE SIMULATOR FOR DISCRETE EVENT SYSTEMS IN A TEMPORAL LOGIC FRAMEWORK </TITLE>
<AUTHOR> SISIRUCA, ALFREDO </AUTHOR>
<YEAR> 1994 </YEAR>
<INSTITUTION> UNIVERSITY OF OTTAWA (CANADA); 0918 </INSTITUTION>
<DESCRIPTORS> COMPUTER SCIENCE; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> DAN IONESCU </ADVISER>
<CLASSIFICATIONS> NIL </CLASSIFICATIONS>
<ABSTRACT>
As more sophisticated systems are being developed,
powerful approaches for modeling their behavior and test
their reliability are necessary. The research work in
this thesis takes on the problem of building a Graphical
Programming Environment that permits to create models of
DESs in a timed temporal logic framework and simulate
the DES models in real-time using an object oriented
environment through the interconnection of visual
symbols.
A temporal logic framework is developed to write the
formal models of the temporal references of DESs. This
approach is enhanced by the inclusion of a global clock
variable to add real-time properties to the formal
specifications of real-time DESs.
The interactive visual environment allows the programmer
to activate graphical symbols by means of menu
selections. The graphical symbols are grouped into
classes which are eventually properly interconnected,
parsed and mapped into source code written in the timed
temporal logic language.
A knowledge-based system is composed of knowledge
databases (database of facts and database of rules),
These databases, representing the system behavior, can
be created using this tool, for which a reasoning
mechanism is required. An inference engine is designed
to interpret these knowledge databases.
An OO programming language is used, Objective-C. It is
used throughout the design, however, when using the
tool, the user does not notice the underlying
programming language, in other words, the programming
language is transparent to the user.
The Graphical Programming Environment designed in this
thesis can be used to build the specifications of real-
time DESs. Different knowledge databases have been
created using this interactive tool for three examples
to verify their behaviors, such examples are: The ABP
communication protocol, the packet-switched
communication protocol, and the telephone system.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  2756 </NUMBER>
<ORDER>   AAG9416363 </ORDER>
<TITLE> QUARK AND GLUON JET DISCRIMINATION BY NEURAL NETWORKS </TITLE>
<AUTHOR> GRAHAM, MARY ANN </AUTHOR>
<YEAR> 1994 </YEAR>
<INSTITUTION> UNIVERSITY OF ILLINOIS AT URBANA-CHAMPAIGN; 0090 </INSTITUTION>
<DESCRIPTORS> PHYSICS, ELEMENTARY PARTICLES AND HIGH ENERGY; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> LORELLA JONES </ADVISER>
<CLASSIFICATIONS> NIL </CLASSIFICATIONS>
<ABSTRACT>
As the energy scales of high energy physics experiments
increase, the amount of data which is available becomes
difficult to manage. A method that can increase the
signal to background ratio would be a clear advantage.
The focus of the study reported here is on increasing
the light quark jet signal to gluon jet background.
We begin by demonstrating that there are characteristics
common to quark jets and to gluon jets regardless of the
interaction that produced them. The classification
technique we use depends on the mass of the jet as well
as center-of-mass energy of the hard subprocess that
produces the jet.
In addition, we present the quark-gluon jet separability
results of an artificial neural network trained on three-
jet $esp+esp-$ events at the $Zsp0$ mass, using a
backpropagation algorithm. The inputs to the network are
the longitudinal momenta of the leading hadrons in the
jet. We tested the network with quark and gluon jets
from both $esp+ esp-$ $to$ 3jets and pp $to$ 2jets.
Finally, we compare the performance of the artificial
neural network with the results of making well chosen
physical cuts.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  2757 </NUMBER>
<ORDER>   AAG1355589 </ORDER>
<TITLE> TRAINING NEURAL NETWORKS USING A RANDOM SEQUENCE OUT OF A TRAINING SET </TITLE>
<AUTHOR> SUKIRYA, SUKENTO </AUTHOR>
<YEAR> 1994 </YEAR>
<INSTITUTION> TEXAS A&M UNIVERSITY-KINGSVILLE; 1187 </INSTITUTION>
<DESCRIPTORS> ENGINEERING, ELECTRONICS AND ELECTRICAL; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> C. S. LEUNG </ADVISER>
<CLASSIFICATIONS> NIL </CLASSIFICATIONS>
<ABSTRACT>
Training neural networks is an emerging discipline that
involves aspects of programming, statistics and signal
processing (1). The back-propagation algorithm has
become the standard algorithm used in training fully
connected feed-forward multilayer perceptron neural
networks. However, there are many shortcomings in which
this algorithm suffered. One such shortcoming is the
rate of convergence. A large number of iterations are
required to train small networks and it may even take
days or weeks to train large networks. A new approach,
using the random sequence out of a training set, is
being presented to improve the performance of
backpropagation algorithm. The improvement will vary
according to the correlation coefficient of the training
set.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  2758 </NUMBER>
<ORDER>   AAG1355549 </ORDER>
<TITLE> A COMPARISON BETWEEN BACK-PROPAGATION AND K/N NEURAL NETWORKS </TITLE>
<AUTHOR> SALIMI, PARISA </AUTHOR>
<YEAR> 1994 </YEAR>
<INSTITUTION> CALIFORNIA STATE UNIVERSITY, FULLERTON; 6060 </INSTITUTION>
<DESCRIPTORS> ENGINEERING, ELECTRONICS AND ELECTRICAL; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> JESUS TUAZON </ADVISER>
<CLASSIFICATIONS> NIL </CLASSIFICATIONS>
<ABSTRACT>
A comparison of two pattern recognition networks is
presented. The two networks are a back-propagation
neural network and a K/N network. Both networks are
examined on their capacity to recognize hand-written
numbers "0" to "9". The networks are first analyzed
using simplified perfect patterns, and then are modified
to recognize non-perfect patterns. The steps taken for
training and design of these networks and the results of
the experiments on the two networks are compared. It was
found that for a limited number of patterns, K/N network
has a better performance. However, the network requires
extensive supervision before its completion. In cases
where there is a large set of patterns to recognize, the
design of K/N network becomes tedious and the back-
propagation neural network can be more useful because of
its self-organizing nature.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  2759 </NUMBER>
<ORDER>   AAG9414751 </ORDER>
<TITLE> OPTIMIZING RANKING FUNCTIONS: A CONNECTIONIST APPROACH TO ADAPTIVE INFORMATION RETRIEVAL </TITLE>
<AUTHOR> BARTELL, BRIAN THEODORE </AUTHOR>
<YEAR> 1994 </YEAR>
<INSTITUTION> UNIVERSITY OF CALIFORNIA, SAN DIEGO; 0033 </INSTITUTION>
<DESCRIPTORS> COMPUTER SCIENCE; INFORMATION SCIENCE; LIBRARY SCIENCE; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> GARRISON W. COTTRELL </ADVISER>
<CLASSIFICATIONS> TEXT RETRIEVAL, NEURAL NETWORKS </CLASSIFICATIONS>
<ABSTRACT>
This dissertation examines the use of adaptive methods
to automatically improve the performance of ranked text
retrieval systems. The goal of a ranked retrieval system
is to manage a large collection of text documents and to
order documents for a user based on the estimated
relevance of the documents to the user's information
need (or query). The ordering enables the user to
quickly find documents of interest. Ranked retrieval is
a difficult problem because of the ambiguity of natural
language, the large size of the collections, and because
of the varying needs of users and varying collection
characteristics.
We propose and empirically validate general adaptive
methods which improve the ability of a large class of
retrieval systems to rank documents effectively. Our
main adaptive method is to numerically optimize free
parameters in a retrieval system by minimizing a non-
metric criterion function. The criterion measures how
well the system is ranking documents relative to a
target ordering, defined by a set of training queries
which include the users' desired document orderings.
Thus, the system learns parameter settings which better
enable it to rank relevant documents before irrelevant.
The non-metric approach is interesting because it is a
general adaptive method, an alternative to supervised
methods for training neural networks in domains in which
rank order or prioritization is important. A second
adaptive method is also examined, which is applicable to
a restricted class of retrieval systems but which
permits an analytic solution.
The adaptive methods are applied to a number of problems
in text retrieval to validate their utility and
practical efficiency. The applications include: A
dimensionality reduction of vector-based document
representations to a vector space in which inter-
document similarity more accurately predicts semantic
association; the estimation of a similarity measure
which better predicts the relevance of documents to
queries; and the estimation of a high-performance neural
network combination of multiple retrieval systems into a
single overall system. The applications demonstrate that
the approaches improve performance and adapt to varying
retrieval environments. We also compare the methods to
numerous alternative adaptive methods in the text
retrieval literature, with very positive results.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  2760 </NUMBER>
<ORDER>   AAG9414750 </ORDER>
<TITLE> MODELING DYNAMICAL SYSTEMS WITH RECURRENT NEURAL NETWORKS  </TITLE>
<AUTHOR> TSUNG, FU-SHENG </AUTHOR>
<YEAR> 1994 </YEAR>
<INSTITUTION> UNIVERSITY OF CALIFORNIA, SAN DIEGO; 0033 </INSTITUTION>
<DESCRIPTORS> COMPUTER SCIENCE; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> GARRISON W. COTTRELL </ADVISER>
<CLASSIFICATIONS> NEURAL NETWORKS, TRAINING </CLASSIFICATIONS>
<ABSTRACT>
Training recurrent neural networks to perform complex
temporal tasks is of interest to many fields, such as
speech recognition, feedback control, and biological
modeling. General gradient descent learning algorithms
for recurrent networks, however, have not performed up
to expectations, compared to the success of feedforward
neural networks.
We use the theory and tools of dynamical systems
analysis to understand the difficulty involved and
present solutions to overcome these problems. To explore
the potential of recurrent neural networks, we first
present a network model of a lobster ganglion, which is
composed of 11 neurons and generates a specific, robust
rhythm. To understand the learning process better, we
carefully examine a reduced two-unit network trained to
oscillate, and show that it goes through a Hopf
bifurcation. We find, however, that continued on-line
training reverses the bifurcation, only to rebifurcate
again and again. This "Hopf-hopping" results in more
robust oscillations, but also make it difficult to know
when to stop training.
These studies bring forth several problems of recurrent
training with existing learning algorithms. The first is
that of distortions in very finely sampled trajectories.
We present the "delta net" algorithm, using Euler
approximation of continuous time dynamics, to overcome
this problem. We then give a detailed analysis showing
that many other problems are due to the inability of
gradient descent to manage the recurrent hidden units
appropriately. We propose the phase-space learning
method, which is a general framework with the iterated-
prediction network as a dominant example, that overcomes
the recurrent hidden unit problem. Within this framework
it is clear how to train multiple trajectories, ensure
stability, and ultimately design dynamical systems with
neural networks. We show several simulations to
illustrate this method. These examples show that phase-
space learning is a useful framework, providing both
practical algorithms and deeper understanding of
recurrent neural networks.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  2761 </NUMBER>
<ORDER>   AAG9414675 </ORDER>
<TITLE> FINITE IMPULSE RESPONSE NEURAL NETWORKS WITH APPLICATIONS IN TIME SERIES PREDICTION </TITLE>
<AUTHOR> WAN, ERIC ANDREW </AUTHOR>
<YEAR> 1994 </YEAR>
<INSTITUTION> STANFORD UNIVERSITY; 0212 </INSTITUTION>
<DESCRIPTORS> ENGINEERING, ELECTRONICS AND ELECTRICAL; COMPUTER SCIENCE; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> BERNARD WIDROW </ADVISER>
<CLASSIFICATIONS> ADAPTIVE FILTERS </CLASSIFICATIONS>
<ABSTRACT>
Traditional feedforward neural networks are static
structures which simply map input to output. Motivated
from biological considerations, a dynamic network is
proposed which uses Finite Impulse Response (FIR) linear
filters to model the processes of axonal transport,
synaptic modulation, and membrane charge dissipation.
Effectively all weights in the static feedforward
network are replaced by adaptive FIR filters.
A training algorithm based on gradient descent is
derived for the FIR structure. The algorithm, termed
temporal backpropagation, is shown to be a direct
temporal and vectorial extension of the popular
backpropagation algorithm. Various properties including
computational complexity and learning characteristics
are explored.
The FIR network can be viewed as an adaptive nonlinear
filter with applications encompassing those of
traditional adaptive filters and systems. In this
dissertation, we concentrate on the FIR network for use
in nonlinear time series prediction. Various examples
including laboratory data, chaotic time series, and
financial data are studied. Iterated predictions and
reconstruction of underlying chaotic attractors are used
to demonstrate the capabilities of the network and
methodology. The theoretical motivations for using
networks in prediction are also addressed.
In looking for a more direct method to derive temporal
backpropagation, we introduce and prove a unifying
principle called Network Reciprocity. The method, based
on simple rules of block diagram manipulation, allows
for an almost effortless formulation of neural network
algorithms. The approach is illustrated by deriving a
variety of algorithms including standard and temporal
backpropagation, backpropagation-through-time for
recurrent networks and control structures, an efficient
method for training cascaded nonlinear filters, and
algorithms for networks composed of Infinite Impulse
Response (IIR) and lattice filters.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  2762 </NUMBER>
<ORDER>   AAG9411162 </ORDER>
<TITLE> COORDINATION AND CONTROL IN DISTRIBUTED WORK: TOWARDS INTELLIGENT DESIGN </TITLE>
<AUTHOR> JOHAR, HARDEEP SINGH </AUTHOR>
<YEAR> 1994 </YEAR>
<INSTITUTION> NEW YORK UNIVERSITY, GRADUATE SCHOOL OF BUSINESS ADMINISTRATION; 0868 </INSTITUTION>
<DESCRIPTORS> COMPUTER SCIENCE; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> VASANT DHAR </ADVISER>
<CLASSIFICATIONS> NIL </CLASSIFICATIONS>
<ABSTRACT>
Recent advances in computer networks and media has made
it possible for organizations to create powerful product
groups by involving more designers, and by bringing
together designers from disparate geographical areas.
However, because of the size, and distributed nature of
these teams, new coordination and control problems
arise.
Process knowledge is the knowledge that designers use to
arrive at design decisions. The central idea of this
dissertation is that this knowledge can be used to
provide support to the different stakeholders in design
teams: individual designers, and project managers. The
research questions addressed are: (1) what elements of
process knowledge are useful for coordination and
control in software development projects, and (2) how
can this knowledge be represented and used to support
the different stakeholders.
We address the first question by building a descriptive
model of the software development process. This model
focuses on the processes that result in design errors,
and the processes used to resolve these errors. The
model highlights the role of designer assumptions as an
important cause of design errors. The model is based on
a case study of a large project at a fortune 50
corporation, and on previous research in design and
software development.
The second question is addressed in three parts. First
we develop on the active role of the machine by
identifying conditions under which the machine should
involve designers in an act of coordination. We develop
a set of formalisms that are used to detect actual and
potential conflicts, find minimal sets of affected
designers, and determine a parsimonious set of conflict
causing assumptions.
The issue of knowledge representation is addressed by
designing a shared memory that provides a group context
for individual action, and adheres to the organizational
principle of responsibility. The shared memory is an
extension of the artificial intelligence system,
assumption based truth maintenance system. The shared
memory and the active role elements are then combined
into an architecture for supporting the two stakeholders
in design. As a proof of concept we implement a
prototype coordination support system.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  2763 </NUMBER>
<ORDER>   AAG9412189 </ORDER>
<TITLE> AN APPROACH TO REPAIRING AND EVALUATING FIRST-ORDER THEORIES CONTAINING MULTIPLE CONCEPTS AND NEGATION </TITLE>
<AUTHOR> WOGULIS, JAMES LEE </AUTHOR>
<YEAR> 1994 </YEAR>
<INSTITUTION> UNIVERSITY OF CALIFORNIA, IRVINE; 0030 </INSTITUTION>
<DESCRIPTORS> COMPUTER SCIENCE; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> MICHAEL J. PAZZANI </ADVISER>
<CLASSIFICATIONS> MACHINE LEARNING </CLASSIFICATIONS>
<ABSTRACT>
This dissertation addresses the problem of theory
revision in machine learning. The task requires the
learner to minimally revise an initial incorrect theory
such that the revised theory explains a given set of
training data. A learning system, A3 is presented that
solves this task.
The main contributions of this dissertation include the
learning system A3 that can revise theories containing
multiple concepts expressed as function-free first-order
Horn clauses, an approach to repairing theories
containing negation, and the introduction of a distance
metric between theories to evaluate the degree of
revision performed. Experimental evidence is presented
that demonstrates A3's ability to solve the theory
revision task.
Assumptions commonly made by other approaches to theory
revision such as whether a theory needs to be
generalized or specialized with respect to misclassified
examples are shown to be incorrect for theories
containing negation. A3 is able to repair theories
containing negation and demonstrates a simple, general
approach to identifying types of errors in a theory
using a single mechanism for handling positive and
negative examples as well as examples of multiple
concepts.
The syntactic distance between two theories is proposed
as an evaluation metric for theory revision systems.
This distance is defined in terms of the minimum number
of edit operations required to transform one theory into
another. This allows for a precise measurement of how
much a theory has been revised and allows for comparison
of different systems' abilities to perform minimal
revisions. This distance metric is also used by A3 in
order to bias it towards finding minimal revisions that
accurately explain the data.
The distance metric also leads to insights about the
theory revision task. In particular, it is shown that
the theory revision task is underconstrained if the
additional goal of learning a particular correct theory
is to be met. Without additional constraints, there are
potentially many accurate revisions that are far apart
syntactically. It is shown that providing examples of
multiple concepts in the theory can provide some of
these constraints.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  2764 </NUMBER>
<ORDER>   AAIMM00487 </ORDER>
<TITLE> TOWARDS KNOWLEDGE-BASE SYSTEMS FOR TRANSLATORS </TITLE>
<AUTHOR> MILLER, DAVID R. </AUTHOR>
<YEAR> 1994 </YEAR>
<INSTITUTION> UNIVERSITY OF OTTAWA (CANADA); 0918 </INSTITUTION>
<DESCRIPTORS> LANGUAGE, GENERAL; INFORMATION SCIENCE; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> DOUGLAS SKUCE; BRIAN HARRIS </ADVISER>
<CLASSIFICATIONS> NIL </CLASSIFICATIONS>
<ABSTRACT>
The aim of this thesis is twofold. First, on a
theoretical level, it aims to examine knowledge from two
standpoints: translation theory and artificial
intelligence (AI). Second, on a more practical level, it
aims to explore the applicability of research in the
branch of AI known as knowledge engineering to the
eventual development of knowledge-base systems for
translators (KBSTs).
The "opaqueness" of a text, or its resistance to
understanding, often reflects a difference between the
translator's knowledge profile and the knowledge profile
that the author of the original text assumed for his
reader. Consequently, knowledge maximization can be
considered a viable translation strategy for countering
opaqueness. When translators work without sufficient
knowledge, they are forced to fall back on a
"transcoding" or word-bound approach, which, although it
sometimes produces acceptable results, is likely to
produce an unidiomatic text and is much more prone to
serious translation errors. The goal of a KBST,
therefore, must be to provide enough knowledge to allow
the translator to engage his "interpretative" or meaning-
based mode of translating.
A knowledge-management system developed at the
University of Ottawa called CODE (Conceptually Oriented
Description Environment) offers a knowledge acquisition
and retrieval environment that can be adapted to the
needs of translators. A knowledge base on stock-market
options, called optionCODE, was developed by the present
author using the system to explore the principle and
problems of designing and using KBSTs. An informal
experiment demonstrated that translators using this
knowledge base as their sole source of knowledge to
translate a text concerning options performed as well
as, if not better than, a translator using traditional
sources. (Abstract shortened by UMI.)
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  2765 </NUMBER>
<ORDER>   AAG9412184 </ORDER>
<TITLE> APPLICATION OF THE TRION MODEL IN OBJECT CLASSIFICATION AND PATTERN RECOGNITION </TITLE>
<AUTHOR> SARDESAI, MILIND SITAKANT </AUTHOR>
<YEAR> 1994 </YEAR>
<INSTITUTION> UNIVERSITY OF CALIFORNIA, IRVINE; 0030 </INSTITUTION>
<DESCRIPTORS> PHYSICS, GENERAL; COMPUTER SCIENCE; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> GORDON L. SHAW </ADVISER>
<CLASSIFICATIONS> VERTEX CELLS </CLASSIFICATIONS>
<ABSTRACT>
Object classification using the newly proposed vertex
cells in secondary visual cortex is studied. Vertex
cells are the logical next step up from the simple and
complex line-detecting cells of Hubel and Wiesel. They
take input from simple cells and respond to vertices.
The trion model is applied to differentiate objects
which trigger the same number of vertex cells for
patterns such as a C and a U. The trion model is a model
of cortical organization in the brain, and is formulated
in the spirit of Mountcastle's organizational principle
for neocortical function and is strongly motivated by
Fisher and Selke's axial next-nearest neighbor Ising
model. A small structured network of trions can excite a
large number of quasi-stable, periodic spatial-temporal
patterns, called magic patterns (MP), that can evolve
from one to another. It is shown how letters such as C
and U can be classified via an appropriate mapping onto
the trion model. A particular MP can be learned through
a Hebb learning algorithm. It is shown how an
appropriate mapping on to a trion network from the
feature detecting cells in the visual cortex with
learning causes all Ys to recall one MP and all $Delta$s
to recall a different MP. How this scheme, built
analogous to the human visual system, can in principle
be used to recognize the capital alphabet faster than
existing technology with robustness is shown.
It is proposed that this scheme, with the trion model,
may be used in particle physics experiments, to
recognize novel events, and to lower the energy
threshold. Also discussed, is how to couple two or three
trion networks to keep an MP cycling for a longer time
to improve the reliability in the trion model.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  2766 </NUMBER>
<ORDER>   AAG9411471 </ORDER>
<TITLE> OPTIMAL METHODS FOR IMAGE RECONSTRUCTION USING NEURAL NETWORKS </TITLE>
<AUTHOR> STERITI, RONALD J. </AUTHOR>
<YEAR> 1994 </YEAR>
<INSTITUTION> UNIVERSITY OF LOWELL; 0111 </INSTITUTION>
<DESCRIPTORS> ENGINEERING, ELECTRONICS AND ELECTRICAL; MATHEMATICS; COMPUTER SCIENCE; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> MICHAEL A. FIDDY </ADVISER>
<CLASSIFICATIONS> NIL </CLASSIFICATIONS>
<ABSTRACT>
This thesis centers on the use of the Hopfield neural
network to solve image reconstruction problems. The
field of neural networks has recently undergone a
resurgence of popularity and many researchers are
reporting positive results. Historically, so-called
parallel computing architectures were overlooked in
favor of digital computers. However there are many
problems that have been difficult to solve on
conventional computers using parallel processing, and
neural network solutions are being explored as
alternatives. The first section of this thesis describes
the image reconstruction problem and several methods of
solution and then introduces the mathematical background
to the Hopfield neural network. A matrix inversion
algorithm is developed and used to reconstruct images
from limited Fourier data. This neural network algorithm
is compared with the singular value decomposition matrix
inversion method. In the second part of this thesis a
novel algorithm for solving the blind deconvolution
problem using two Hopfield neural networks is proposed
and tested.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  2767 </NUMBER>
<ORDER>   AAG9405368 </ORDER>
<TITLE> AN APPROACH TO THE DEVELOPMENT OF EXECUTIVE SUPPORT SYSTEMS FOR THE HEALTHCARE INDUSTRY BY UTILIZING ELECTRONIC MEETING SOFTWARE  </TITLE>
<AUTHOR> EMERY, CHARLES CHRISTIAN, JR. </AUTHOR>
<YEAR> 1994 </YEAR>
<INSTITUTION> THE CLAREMONT GRADUATE SCHOOL; 0047 </INSTITUTION>
<DESCRIPTORS> BUSINESS ADMINISTRATION, MANAGEMENT; COMPUTER SCIENCE; HEALTH SCIENCES, HOSPITAL MANAGEMENT; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> PAUL GRAY </ADVISER>
<CLASSIFICATIONS> HEALTH CARE </CLASSIFICATIONS>
<ABSTRACT>
The goal of this study was to develop and test a new
method to radically improve the process of eliciting the
information requirements for an executive information
system. This study was successfully completed through
the development of a new requirements elicitation
process utilizing an electronic meeting system, along
with the utilization of new collaborative software tools
to construct a proof-of-concept prototype. The process
improvement reduced the time to accomplish this effort
from a previously reported six month duration to one
week.
The study was accomplished through a replicated case
study method where all firms or institutions
participating in this study were from the healthcare
sector.
Confirmation that the proof-of-concept prototype met the
requirements of the executives was accomplished through
a review of the prototype by the participating
executives.
An expert panel, external to the elicitation process,
was used to judge the technical quality of the
requirements elicited through the electronic meeting
session for each case. The panel found the results to be
as effective as traditional interviewing techniques used
previously to construct executive support systems.
Other benefits derived from this study include the
development of experience with the use of an electronic
meeting system with practicing healthcare executives,
the development of understanding on how electronic
meeting systems can be used in the knowledge elicitation
for executive support system and other application
system implementations. Increased insight into what
healthcare executives require in an executive
information system was gained. Successive prototypes
found a common body of knowledge with regard to overall
content and structure of a healthcare executive support
system. Hard data, in the form of reports, graphs and
statistics, were specified by each team of executives.
The ability to address non quantitative issues, or soft
data issues, emerged as a requirement of equal
importance to the hard data capabilities.
The results and techniques developed in this study may
be generalizable into the knowledge acquisition process
for the development of expert systems.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  2768 </NUMBER>
<ORDER>   AAG1354233 </ORDER>
<TITLE> OBJECT ORIENTED ARTIFICIAL NEURAL NETWORK SIMULATOR IN TEXT AND SYMBOL RECOGNITION </TITLE>
<AUTHOR> PISZCZ, ALAN T. </AUTHOR>
<YEAR> 1994 </YEAR>
<INSTITUTION> STATE UNIVERSITY OF NEW YORK INSTITUTE OF TECHNOLOGY AT UTICA-ROME; 1026 </INSTITUTION>
<DESCRIPTORS> COMPUTER SCIENCE; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> NASEEM ISHAQ </ADVISER>
<CLASSIFICATIONS> NIL </CLASSIFICATIONS>
<ABSTRACT>
Objected oriented languages and artificial neural
networks are new areas of research and development. This
thesis investigates the application of artificial neural
networks using an object oriented C++ backpropagation
simulator. The application domain investigated is hand
printed text and engineering symbol recognition.
An object oriented approach of the simulator allows
other simulator paradigms to reuse a large body of the
object classes developed for this particular
application. The review and implementation of image
feature extraction methodologies is another area
researched in this paper. Four feature techniques are
researched, developed, applied and tested, using digits,
upper case alphabet characters and engineering symbol
images. Final implementation and testing of the feature
extraction methods with a baseline technique is analyzed
for applicability in the domain of hand printed text and
engineering symbols.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  2769 </NUMBER>
<ORDER>   AAG9404448 </ORDER>
<TITLE> NEURAL NETWORK ARCHITECTURES FOR LEARNING, PREDICTION, AND PROBABILITY ESTIMATION </TITLE>
<AUTHOR> REYNOLDS, JOHN HUNTINGTON </AUTHOR>
<YEAR> 1994 </YEAR>
<INSTITUTION> BOSTON UNIVERSITY; 0017 </INSTITUTION>
<DESCRIPTORS> BIOLOGY, NEUROSCIENCE; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> GAIL A. CARPENTER </ADVISER>
<CLASSIFICATIONS> NIL </CLASSIFICATIONS>
<ABSTRACT>
A new neural network architecture, called ARTMAP, is
developed for incremental, nonparametric, supervised
learning of recognition categories, multidimensional
maps, and probability estimates. ARTMAP extends Adaptive
Resonance Theory (ART) into the domain of supervised
learning by incorporating environmental feedback and
associative learning into the ART learning processes.
Tested on benchmark classification problems such as
distinguishing poisonous and edible mushrooms based on
their visual features, ARTMAP outperforms a variety of
systems in terms of speed, accuracy, and code
compression. ARTMAP is also successfully applied to the
incremental approximation of piecewise continuous
functions, and to three probability estimation problems.
The ARTMAP network includes a pair of Adaptive Resonance
Theory modules, ART$sb0a$ and ART$sb0b.$ During
training, input patterns are presented to ART$sb0a$ and
output patterns are presented to ART$sb0b.$ During
testing, input patterns are presented alone to ART$sb0a$
and ART$sb0b$ generates the system's predictions.
ART$sb0a$ and ART$sb0b$ are linked by an associative
learning network and an internal controller that
conjointly maximize predictive generalization and
minimize predictive error. When a predictive error
occurs, the system's internal category structure is
expanded by the minimum amount needed to correct the
error, through an automatically controlled hypothesis
testing process. ARTMAP is hereby a type of self-
organizing expert system that calibrates the selectivity
of its hypotheses based upon predictive success. As a
result, rare but important events can be quickly and
sharply distinguished even if they are similar to
frequent events with different consequences. Because
ARTMAP learning is self-stabilizing, it can continue
learning one or more databases, without degrading its
corpus of memories, until its full memory capacity is
utilized.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  2770 </NUMBER>
<ORDER>   AAG9402952 </ORDER>
<TITLE> HARDWIRED ELEMENTARY FUNCTION GENERATORS FOR NEURAL NETWORK EMULATORS </TITLE>
<AUTHOR> ZHANG, MING </AUTHOR>
<YEAR> 1994 </YEAR>
<INSTITUTION> STATE UNIVERSITY OF NEW YORK AT BINGHAMTON; 0792 </INSTITUTION>
<DESCRIPTORS> ENGINEERING, ELECTRONICS AND ELECTRICAL; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> NIL </ADVISER>
<CLASSIFICATIONS> NIL </CLASSIFICATIONS>
<ABSTRACT>
In this study we present a number of schemes for the
generation of elementary functions for hardwired neural
network emulators. We propose approaches for the
hardware design of the sigmoid and the logarithm
function based on a hybrid approach. The hybrid approach
requires access to lookup tables and direct
computations. Our proposed approaches outperform
existing schemes in terms of speed and hardware
requirements, while keeping an accuracy in the order of
the IEEE double precision floating point format.
Additionally, ten elementary functions that are commonly
used in the neural network paradigm have been designed
using first and second degree piece-wise approximations.
These functions have a precision on the order of 2-
$sp010$ with inexpensive hardware. The elementary
functions are: the sigmoid and its derivative, the
logarithm, the sine and cosine trigonometric functions,
the exponential, the hyper tangent, the square root, the
inverse and inverse square. The proposed design
approaches outperform existing schemes in terms of
performance, hardware cost, and precision. It is shown
that one of the proposed designs can accommodate all ten
elementary functions without loss of performance.
Furthermore, the function generator can be programmable;
this in turn provides the capability of extending the
computations to other elementary functions with no
penalties in terms of performance, hardware cost, or
additional design effort. Those features make our low
precision schemes suitable for neural network emulators
that require "moderate" precision for the computation of
elementary functions. Their inclusion in the design
allows those emulators to achieve high performance
computations with low hardware cost.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  2771 </NUMBER>
<ORDER>   AAGC530062 </ORDER>
<TITLE> MODULARISATION, UNCERTAINTY, REFLECTIVE CONTROL AND DEDUCTION BY SPECIALISATION IN MILORD II, A LANGUAGE FOR KNOWLEDGE-BASED SYSTEMS  </TITLE>
<AUTHOR> PUYOL I GRUART, JOSEP </AUTHOR>
<YEAR> 1994 </YEAR>
<INSTITUTION> UNIVERSITAT DE BARCELONA (SPAIN); 1129 </INSTITUTION>
<DESCRIPTORS> COMPUTER SCIENCE; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> NIL </ADVISER>
<CLASSIFICATIONS> EXPERT SYSTEMS </CLASSIFICATIONS>
<ABSTRACT>
MILORD II is an architecture for developing knowledge-
based systems. In particular we are interested in real
expert systems, that is, those that are useful in a real
environment and that have real purposes. To do that we
propose a language based on modules as a method for
programming in the large. Modules, generic modules and a
set of operations among them are the basis of this
language. A program in MILORD II is then a hierarchical
structure of modules. Modules are encapsulated
components with a well-defined interface. Each module is
composed of deductive knowledge (weighted facts and
rules), local logic (an algebra declaration) and a local
control component (Horn-like metarules).
Each module contains its own local logic to deal with
approximate reasoning. An algebra of truth-values is
proposed to make deductions in a weighted rule-based
language (deductive knowledge). A mechanism is provided
to find valid translations of the terms communicated
between modules with different logics.
Deduction of MILORD II is based on specialisation. This
leads to a new inference engine providing improvements
with respect to the engines based on Modus ponens. These
improvements affect the communication, the validation
and the understanding of expert systems.
Finally we explain a set of applications and examples
developed using MILORD II.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  2772 </NUMBER>
<ORDER>   AAIMM00461 </ORDER>
<TITLE> MULTI-SENSOR </TITLE>
<AUTHOR> GAL, CAROL </AUTHOR>
<YEAR> 1994 </YEAR>
<INSTITUTION> UNIVERSITY OF OTTAWA (CANADA); 0918 </INSTITUTION>
<DESCRIPTORS> ENGINEERING, ELECTRONICS AND ELECTRICAL; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> EMIL PETRIU </ADVISER>
<CLASSIFICATIONS> IR </CLASSIFICATIONS>
<ABSTRACT>
The main topic of the thesis is the multi-sensor data
fusion in the context of mobile robot navigation. The
work presented has been part of a continuous research
done in the field of mobile robots. In that respect, a
mobile robot platform with an onboard manipulation
capability has been developed as an experimental
platform for a multi-sensor system for teleautonomous
applications in an unstructured environment. Different
types of sensors have been provided to gather
information about the environment: infrared (IR) range
finders, vision, tactile, position. While vision and
tactile sensors were approached by other related work,
this thesis is essentially aimed to solve the following
problems: (1) Mobile robot navigation, in terms of
electronic interface and computerized control with real-
time range data acquisition for obstacle avoidance,
using a GUI (Graphical User Interface); (2) Occupancy
grid method implementation using Bayesian analysis for
the case of an IR ranging sensor; (3) Unstructured
environment mapping, in the context of multi-sensor data
fusion of mobile robot views taken from different given
positions; (4) Global map integration with other types
of sensory information (vision).
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  2773 </NUMBER>
<ORDER>   AAIMM00374 </ORDER>
<TITLE> KNOWLEDGE BASE SPECIFICATION FOR DESIGN COST ESTIMATION </TITLE>
<AUTHOR> GESNER, SHAUNA MAE </AUTHOR>
<YEAR> 1994 </YEAR>
<INSTITUTION> THE UNIVERSITY OF NEW BRUNSWICK (CANADA); 0823 </INSTITUTION>
<DESCRIPTORS> COMPUTER SCIENCE; ARTIFICIAL INTELLIGENCE; BUSINESS ADMINISTRATION, ACCOUNTING </DESCRIPTORS>
<ADVISER> BRAD NICKERSON </ADVISER>
<CLASSIFICATIONS> NIL </CLASSIFICATIONS>
<ABSTRACT>
This thesis presents an effective method of representing
cost estimate knowledge in a readily accessible format
for generating accurate cost estimates. The
investigation also includes development of a prototype
tool for modifying this knowledge and producing cost
estimates.
Models of the important cost estimate inputs (equipment
lists and device lists) and the resulting cost estimate
have been developed. The cost estimate model is
represented in the form of a context-free grammar. Key
concepts and heuristics were abstracted following
various discussions with an electrical engineer familiar
with producing estimates. The individual was also
consulted during the implementation of a user interface
for the prototype tool.
An investigation into the integration of the prototype
with other software tools (e.g., Lotus 1-2-3, WKS
Library of C functions) was also conducted. The
resulting prototype is called Assistant for Cost
Estimating (ACE). It permits the user to record a
client's preferences for a particular manufacturer and
use this information to generate an estimate which
reflects the economy and even geographic location of the
project.
The prototype was developed using ART-TM version 2.1
(Automatic Reasoning Tool - Information Manager) and the
WKS Library of C functions using an IBM PS/2 Model 70
(Intel 80386 processor).
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  2774 </NUMBER>
<ORDER>   AAG9803043 </ORDER>
<TITLE> A HYBRID INTELLIGENT ARCHITECTURE FOR REVISING DOMAIN KNOWLEDGE  </TITLE>
<AUTHOR> TAHA, ISMAIL ABD ELHAMID </AUTHOR>
<YEAR> 1997 </YEAR>
<INSTITUTION> THE UNIVERSITY OF TEXAS AT AUSTIN; 0227 </INSTITUTION>
<DESCRIPTORS> COMPUTER SCIENCE; ENGINEERING, ELECTRONICS AND ELECTRICAL; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> JOYDEEP GHOSH </ADVISER>
<CLASSIFICATIONS> NEURAL NETWORK, EXPERT SYSTEM, RULE ORDERING </CLASSIFICATIONS>
<ABSTRACT>
This dissertation introduces a novel Hybrid Intelligent
Architecture (HIA) that augments a knowledge-based
system with a connectionist model and a statistical
model to help the former to refine its domain knowledge.
Key innovations of the introduced HIA include its
capability to learn fast, refine prior domain knowledge,
enhance its generalization capability, and support its
output decisions with the required explanation power.
These abilities are made possible by efficiently
incorporating the features of seven main modules in the
structure of HIA.
The first module is a knowledge-based module that
represents initial domain knowledge acquired from domain
experts in a well defined format. The second is a
statistical module that analyses available data sets and
extracts correlation rules to supplement the extracted
prior domain knowledge. The third is a mapping module
where all extracted prior domain knowledge are mapped
into a uniform initial connectionist architecture. This
mapping module is also able to bound the search space
for the optimal parameters of the connectionist
architecture before training. Therefore, the learning
time required to train the mapped initial architecture
is reduced. The fourth module of HIA is a discretization
module used as a front-end to the connectionist module,
the fifth module of HIA, to discretize its inputs into
multi-interval inputs. In the training phase of the
connectionist module, an augmented backpropagation
algorithm is developed to provide the system with the
ability to refine its input characterization parameters
while updating and learning new domain concepts. The
sixth module of HIA is a rule extraction module. In this
module, the topology of the trained connectionist
architecture, that represents the refined domain
knowledge and new learned concepts, is mapped into an
updated rule-based system. This dissertation introduces
three new rule extraction techniques. The suitability of
each technique depends on the network architecture,
nature of inputs, and the transparency level of the
required explanation power. The last module of HIA is an
integration module that integrates the outputs of the
extracted rules and the trained connectionist
architecture and provides the final explained and
revised outputs of the system.
The introduced HIA concepts were applied to a real
control problem and three classification problems.
Experimental results show that a connectionist network
generated by HIA generalizes better and faster than
other connectionist architectures. Moreover, HIA shows
its capability to refine prior domain knowledge and
extract updated and new domain concepts. Furthermore, it
supports its output decisions with a powerful rule-based
explanation utility even in cases where prior domain
knowledge is not available.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  2775 </NUMBER>
<ORDER>   AAG9803035 </ORDER>
<TITLE> NONLINEAR MEMORY DYNAMIC NEURAL NETWORKS FOR SPATIO- TEMPORAL CLASSIFICATION </TITLE>
<AUTHOR> STILES, BRYAN WAITSEL </AUTHOR>
<YEAR> 1997 </YEAR>
<INSTITUTION> THE UNIVERSITY OF TEXAS AT AUSTIN; 0227 </INSTITUTION>
<DESCRIPTORS> ENGINEERING, ELECTRONICS AND ELECTRICAL; BIOLOGY, NEUROSCIENCE; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> JOYDEEP GHOSH </ADVISER>
<CLASSIFICATIONS> SIGNAL PROCESSING, PATTERN RECOGNITION, HABITUATION </CLASSIFICATIONS>
<ABSTRACT>
This dissertation introduces a number of dynamic neural
networks that are capable of approximating input-output
maps of nonlinear discrete-time systems. Among these are
several novel networks based upon the biologically
observed habituation mechanism. We produce a general
approximation result which applies to a large class of
structures including the habituation based networks. In
particular, we introduce the concept of a "complete
memory." A structure with a complete memory dynamical
stage followed by sufficiently powerful memory-less
stage is shown to be capable of approximating
arbitrarily well a wide class of discrete time systems.
Several examples of linear and nonlinear complete
memories are presented. We demonstrate that with finite
resources, linear memory structures have certain
limitations in the types of systems they can effectively
model. Several novel nonlinear memory structures without
these limitations are introduced and analyzed both
theoretically and empirically.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  2776 </NUMBER>
<ORDER>   AAG9802963 </ORDER>
<TITLE> SYMBIOTIC EVOLUTION OF NEURAL NETWORKS IN SEQUENTIAL DECISION TASKS </TITLE>
<AUTHOR> MORIARTY, DAVID ERIC </AUTHOR>
<YEAR> 1997 </YEAR>
<INSTITUTION> THE UNIVERSITY OF TEXAS AT AUSTIN; 0227 </INSTITUTION>
<DESCRIPTORS> COMPUTER SCIENCE; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> RISTO MIIKKULAINEN </ADVISER>
<CLASSIFICATIONS> NIL </CLASSIFICATIONS>
<ABSTRACT>
Sequential decision tasks appear in many practical
situations ranging from robot navigation to stock market
trading. Because of the complexity of such tasks, it is
often difficult to perceive the direct consequences of
individual decisions and even harder to generate
examples of correct behavior. Consequently, difficult
decision problems such as routing traffic, autonomous
control, and resource allocation are often unautomated
or are only semi-automated using "rule-of-thumb"
strategies or simple heuristics. This dissertation
proposes a general methodology for automating these
tasks using techniques from machine learning.
Specifically, this research studies the combination of
evolutionary algorithms and artificial neural networks
to learn and perform difficult decision tasks.
Evolutionary algorithms provide an efficient search
engine for building decision strategies and require only
minimal reinforcement or direction from the environment.
Neural networks provide an efficient storage mechanism
for the decision policy and can generalize experiences
from one situation to another. The learning system
developed in this dissertation called SANE contains an
evolutionary algorithm specifically tailored to
sequential decision learning. Populations evolve faster
than previous methods and rarely converge on suboptimal
solutions. SANE is extensively evaluated and compared to
existing decision learning systems and other
evolutionary algorithms. SANE is shown to be
significantly faster, more robust, and more adaptive in
almost every situation. Moreover, SANE's efficient
searches return more profitable decision strategies. The
flexibility and scope of SANE is demonstrated in two
real-world applications. First, SANE significantly
improves the play of a world champion Othello program.
Second, SANE successfully forms neural networks that
guide a robot arm to target objects while avoiding
randomly placed obstacles. The contributions of this
research are twofold: a novel integration of
evolutionary algorithms and neural networks and an
efficient system for learning decision strategies in
complex problems.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  2777 </NUMBER>
<ORDER>   AAG9802954 </ORDER>
<TITLE> CAUSALITY IN COMMONSENSE REASONING ABOUT ACTIONS </TITLE>
<AUTHOR> MCCAIN, NORMAN CLAYTON </AUTHOR>
<YEAR> 1997 </YEAR>
<INSTITUTION> THE UNIVERSITY OF TEXAS AT AUSTIN; 0227 </INSTITUTION>
<DESCRIPTORS> COMPUTER SCIENCE; PHILOSOPHY; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> VLADIMIR LIFSCHITZ; ROBERT KOONS </ADVISER>
<CLASSIFICATIONS> ACTION DOMAINS, ARTIFICIAL INTELLIGENCE </CLASSIFICATIONS>
<ABSTRACT>
In this dissertation, we investigate the role of causal
knowledge in commonsense reasoning about action and
change. We define a language in which a relatively
simple form of causal knowledge is expressed. Using this
language, we describe a novel approach to formalizing
action domains as "causal theories"--including domains
that involve concurrency, nondeterminism, and things
that change by themselves. We show that a subclass of
causal theories can be translated into propositional
logic by a generalization of Clark's completion
procedure for logic programs. Finally, we describe an
implemented approach to automated query answering and
"satisfiability planning" which is based on this
translation.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  2778 </NUMBER>
<ORDER>   AAG9802566 </ORDER>
<TITLE> GUIDING INTERACTIVE DRAMA </TITLE>
<AUTHOR> WEYHRAUCH, PETER WILLIAM </AUTHOR>
<YEAR> 1997 </YEAR>
<INSTITUTION> CARNEGIE-MELLON UNIVERSITY; 0041 </INSTITUTION>
<DESCRIPTORS> COMPUTER SCIENCE; THEATER; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> JOSEPH BATES </ADVISER>
<CLASSIFICATIONS> MOE, DRAMATIC GUIDANCE, ARTIFICIAL INTELLIGENCE </CLASSIFICATIONS>
<ABSTRACT>
In traditional drama, an audience watches a story
presented by characters on a stage. Interactive Drama
changes the audience to a single User who enters that
stage, interacting with the characters, and
participating in the story. Computer-based interactive
drama allows a User to interact with simulated worlds
which are inhabited by dynamic and complex autonomous
characters and shaped by a flexible, aesthetically
pleasing story. Unlike the actions of characters in a
play, the actions of the User are not controlled by the
artist. The problem is to shape the User's experience to
conform to the set of themes and ideas to be conveyed.
This work proposes this problem can be solved by
dynamically monitoring and subtly guiding the experience
of the User.
This dissertation describes an architecture called Moe
that is designed to provide dramatic guidance. Moe uses
abstract, adversary search with an aesthetic evaluation
function to decide how and when to guide the User's
experience. The first technical achievement of this work
is a demonstration of the ability to capture a dramatic
aesthetic (for one interactive drama) in an automated
evaluation function that can examine an experience and
determine its quality, much as a movie critic determines
the quality of a film. This result is supported by
statistically demonstrating a high degree of correlation
(r =.87) between the evaluation function and the human
artist.
The second main technical achievement of this work is
the implementation of three such strategies (SAS and
SAS+, both based on random sampling; and MMFC, which
uses memoization to implement a full-depth search) and a
search state that seem capable of effectively modelling
and guiding an interactive dramatic experience. Moe has
not yet been connected to a running interactive
experience, but instead Moe has been tested with a
variety of Simulated User Types. On "average" Users,
SAS, SAS+, and MMFC are able to improve Users'
experiences from the 50th percentile, to the 94th, 98th,
and 99th percentile, respectively. This is a large and
artistically meaningful increase.
This dissertation describes the first implementation of
a system designed to provide centralized dramatic
guidance in an interactive drama.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  2779 </NUMBER>
<ORDER>   AAIC446800 </ORDER>
<TITLE> L'APPORT DES RESEAUX CONNEXIONNISTES A LA GEOPHYSIQUE. APPLICATION AU TRAITEMENT DES SIGNAUX SISMIQUES; CONTRIBUTION OF CONNECTIONIST NETWORKS TO GEOPHYSICS. APPLICATION TO SEISMIC SIGNAL PROCESSING </TITLE>
<AUTHOR> MOUSSET, ERIC </AUTHOR>
<YEAR> 1994 </YEAR>
<INSTITUTION> UNIVERSITE DE PARIS VI (FRANCE); 0788 </INSTITUTION>
<DESCRIPTORS> ENGINEERING, ELECTRONICS AND ELECTRICAL; GEOPHYSICS; COMPUTER SCIENCE; ARTIFICIAL INTELLIGENCE DE BOIS-PREAU - B.P. 311 -  F-92506 RUEIL MALMAISON CEDEX, FRANCE FRANCE </DESCRIPTORS>
<ADVISER> NIL </ADVISER>
<CLASSIFICATIONS> NOISE DETECTION, NEURAL NETWORKS </CLASSIFICATIONS>
<ABSTRACT>
Situated on the borderline of connectionism and
geophysics, this work deals with a study of
connectionist solutions for automatic noise detection in
raw data (acquired by seismic-reflection).
The state of the art of neural network application in
geophysics is presented and complementary approaches are
suggested. We study the problem of time-localization
(i.e. detection) of noises of limited duration.
Impulsive noises--spikes, and non-impulsive ones, are
considered separately one from another. In the first
case, we present a neural-network-based approach of
local signal analysis, versus a more conventional
technique, based on a local median criterion. The main
problem of non-impulsive noise detection is split in two
subproblems: the localization of a noise within a trace
that is known to be noisy and the determination of
whether a trace is noisy or not. Our approach is based
on several associations between multiresolution
representation of signals (obtained by discrete
orthogonal wavelets transformation) and appropriate
neural networks architectures.
Finally, we discuss several upstream aspects of
connectionism. A particular category of classification
problems is studied: the one where the two classes to be
separated have disproportionate sizes. We raise several
other problematics, concerning the study of multilayer
networks properties for local signal processing. We
establish formal links between multilayer neural
networks and other paradigms such as median filters (and
several other related filters) and data analysis
techniques which take into account explicit topological
relations between data.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  2780 </NUMBER>
<ORDER>   AAG9802201 </ORDER>
<TITLE> UTILIZATION OF STATE INFORMATION VIA RECURRENT CONNECTIONS IN EXPERT NETWORKS </TITLE>
<AUTHOR> LEBLANC, CATHERINE </AUTHOR>
<YEAR> 1997 </YEAR>
<INSTITUTION> THE FLORIDA STATE UNIVERSITY; 0071 </INSTITUTION>
<DESCRIPTORS> COMPUTER SCIENCE; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> SUSAN I. HRUSKA </ADVISER>
<CLASSIFICATIONS> NEURAL NETWORKS, ARTIFICIAL INTELLIGENCE </CLASSIFICATIONS>
<ABSTRACT>
Hybrid systems which combine rule-based knowledge about
a problem domain with data-driven knowledge discovery
methods have been implemented in a number of ways,
including expert networks. An expert network is a
computational network whose topology is derived from an
underlying knowledge base. Each of the nodes in the
network has a unique functionality according to the role
the node plays in encoding the knowledge base. Such
systems allow human expert knowledge to be explicitly
encoded in the system and then refined by automated
examination of data. The topologies and learning
algorithms developed for expert networks prior to the
work described in this dissertation have been strictly
feedforward.
Some classification tasks, however, are difficult to
complete using a strictly feedforward architecture. In
particular, the solution to many problems requires that
state information be maintained. State information is
the context in which the problem is currently being
solved. The context of a problem solution will change as
the solution proceeds and certain sets of rules need
only be considered in certain contexts. In order to
maintain such state information, I have added recurrent
connections to the topologies and modified the learning
algorithms allowed for expert networks.
A particular problem domain for which state information
is important is the problem of predicting the secondary
structure of a protein from its primary sequence.
Algorithms developed for prediction of protein secondary
structure do not take into account information
concerning interactions between amino acids which occur
far apart along the protein primary sequence although
many studies have shown that such interactions play a
significant role in the formation of actual protein
structure. Information concerning these long-range
interactions constitutes the state information necessary
to adequately address this prediction problem.
I have encoded the rules from the Chou-Fasman protein
secondary structure prediction algorithm into an expert
network and augmented this expert network with knowledge
about longer-range amino acid interactions. Results of
protein secondary structure prediction experiments show
that the addition of state knowledge to existing
algorithms encoded as expert networks aids in the
development of better prediction tools.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  2781 </NUMBER>
<ORDER>   AAG9801716 </ORDER>
<TITLE> INTEGRATED ANALYSIS AND PATTERN RECOGNITION OF SWISS CHEESE AROMA BY SPME/GC, SPME/GC/MS AND ELECTRONIC NOSES </TITLE>
<AUTHOR> JOU, KUEN-DA </AUTHOR>
<YEAR> 1997 </YEAR>
<INSTITUTION> THE OHIO STATE UNIVERSITY; 0168 </INSTITUTION>
<DESCRIPTORS> AGRICULTURE, FOOD SCIENCE AND TECHNOLOGY; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> W. JAMES HARPER </ADVISER>
<CLASSIFICATIONS> NEURAL NETWORK </CLASSIFICATIONS>
<ABSTRACT>
Two objective methods: (a) Electronic Noses, (b) Solid
Phase Micro Extraction (SPME)/GC, were utilized to
differentiate the aroma portion of Swiss cheese volatile
compounds and these results were cross compared to
sensory evaluation. Investigation was conducted in two
trials. In both trials, Alpha M.O.S. Fox 2000 and Fox
3000 electronic noses differentiated cheeses by
discriminant analysis, which could be related to flavor
characteristics of Swiss cheese.
SPME/GC was found to provide for quantitative analysis
of the head space volatiles of Swiss cheese. Thirty
predominant and common peaks found in all cheeses were
integrated by the internal HP ChemStation software and
selected for further data analysis.
The GC data were further analyzed by discriminant
analysis. The discriminant plots of major GC peaks were
compared with that of the Electronic Nose sensory
discriminant patterns. Similar results were observed
with both instruments. Acetoin and C-2 to C-6 fatty
acids were primary compounds that affected the
differentiation of the cheeses by the electronic nose.
An Artificial Neural Networks (ANN) program with back
propagation learning mechanism was programmed in PASCAL
computer language. In trial one, ANN was trained with
the first batch of data comprising of five replicates of
each cheese sample. An optimum performance was
determined by the training time and number of hidden
units. Another batch of GC data obtained at different
dates were fed into the ANN to test the performance of
this ANN. ANN was able to recognize all cheeses
perfectly. By adding noise to ANN, the relationship of
different cheeses to one another could be determined.
ANN was not successful in recognizing all of the cheeses
when it as applied to Electronic Nose data.
Overall the results suggest that discriminant analysis
of Electronic Nose odor maps and pattern recognition by
ANN on GC peaks complement human sensory evaluation and
can provide an objective approach to aroma analysis. The
combination of both Electronic Nose and SPME/GC provided
more information than either method alone.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  2782 </NUMBER>
<ORDER>   AAG9801559 </ORDER>
<TITLE> MATHEMATICAL PROGRAMMING NEURAL NETWORK </TITLE>
<AUTHOR> LI, JIANMIN </AUTHOR>
<YEAR> 1997 </YEAR>
<INSTITUTION> UNIVERSITY OF ILLINOIS AT CHICAGO; 0799 </INSTITUTION>
<DESCRIPTORS> ENGINEERING, MECHANICAL; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> NIL </ADVISER>
<CLASSIFICATIONS> MPNN) FOR MECHANISM DESIGN  (OPTIMIZATION, HESSIAN MATRIX </CLASSIFICATIONS>
<ABSTRACT>
This dissertation develops Mathematical Programming
Neural Network (MPNN) theory and algorithms for solving
highly nonlinear optimization problems of mechanical
design.
Based upon a comprehensive investigation of the
prevalent MPNN models, a MPNN model for unconstrained
optimization is proposed first, and then applied to the
optimal synthesis of the planar-four bar linkage. After
combining with the Augmented Lagrange Multiplier (ALM)
methods, the proposed MPNN model is extended to the
constrained optimization and applied to the constrained
optimization of mechanisms. The applications show that
the new MPNN model has a global convergence property.
In the first part of MPNN, the exact Hessian matrices of
the objective functions and the constraints are
required. In the second part, the 'approach' matrix is
developed from the two previous first derivative
information and the exact Hessian matrix is not needed
any more; therefore, the algorithm not only needs less
amount of computation but also is applicable to the
problems where exact Hessian matrices are very difficult
to get.
The relation between the least square and mini-max norm
of the function generating mechanisms is also developed
and implemented in the algorithm to avoid the direct
minimization of the complex structural error.
The applications considered include the optimal
synthesis of planar four-bar mechanism, spatial R-S-S-R
mechanism, and a beam with variable cross-section.
Results show the attractive properties of robustness and
global convergence for the proposed MPNN models.
A brief introduction, basic terminology and an outline
of new contributions are given in Chapter I. Chapter II
includes literature review for mechanism optimization,
prevalent MPNN models and Augmented Lagrange Multiplier
methods. The function formulation for generating
mechanism and the relation between the least square and
mini-max norms are described in Chapter III. The MPNN
models using the exact Hessian matrix for both
unconstrained and constrained optimization are developed
in Chapter IV. Chapter V develops the theory of MPNN
without using the exact Hessian matrix for both the
unconstrained and constrained optimization. Another
application of MPNN in the optimization of a beam design
is illustrated in Chapter VI.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  2783 </NUMBER>
<ORDER>   AAG9801088 </ORDER>
<TITLE> NONLINEAR EXTENSIONS TO THE MINIMUM AVERAGE CORRELATION ENERGY FILTER  </TITLE>
<AUTHOR> FISHER, JOHN W., III </AUTHOR>
<YEAR> 1997 </YEAR>
<INSTITUTION> UNIVERSITY OF FLORIDA; 0070 </INSTITUTION>
<DESCRIPTORS> ENGINEERING, ELECTRONICS AND ELECTRICAL; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> JOSE C. PRINCIPE </ADVISER>
<CLASSIFICATIONS> PATTERN RECOGNITION, MACHINE LEARNING, LINEAR ASSOCIATIVE MEMORY </CLASSIFICATIONS>
<ABSTRACT>
The major goal of this research is to develop efficient
methods by which the family of distortion invariant
filters, specifically the minimum average correlation
energy (MACE) filter, can be extended to a general
nonlinear signal processing framework. The primary
application of MACE filters has been to pattern
classification of images. Two desirable qualities of
MACE-type correlators are ease of implementation via
correlation and analytic computation of the filter
coefficients.
Our motivation for exploring nonlinear extensions to
these filters is due to the well-known limitations of
the linear systems approach to classification. Among
these limitations the attempt to solve the
classification problem in a signal representation space,
whereas the classification problem is more properly
solved in a decision or probability space. An additional
limitation of the MACE filter is that it can only be
used to realize a linear decision surface regardless of
the means by which it is computed. These limitations
lead to suboptimal classification and discrimination
performance.
Extension to nonlinear signal processing is not without
cost. Solutions must in general be computed iteratively.
Our approach was motivated by the early proof that the
MACE filter is equivalent to the linear associative
memory (LAM). The associative memory perspective is more
properly associated with the classification problem and
has been developed extensively in an iterative
framework.
In this thesis we demonstrate a method emphasizing a
statistical perspective of the MACE filter optimization
criterion. Through the statistical perspective efficient
methods of representing the rejection and recognition
classes are derived. This, in turn, enables a machine
learning approach and the synthesis of more powerful
nonlinear discriminant functions which maintain the
desirable properties of the linear MACE filter, namely,
localized detection and shift invariance.
We also present a new information theoretic approach to
training in a self-organized or supervised manner.
Information theoretic signal processing looks beyond the
second order statistical characterization inherent in
the linear systems approach. The information theoretic
framework probes the probability space of the signal
under analysis. This technique has wide application
beyond nonlinear MACE filter techniques and represents a
powerful new advance to the area of information
theoretic signal processing.
Empirical results, comparing the classical linear
methodology to the nonlinear extensions, are presented
using inverse synthetic aperture radar (ISAR) imagery.
The results demonstrate the superior classification
performance of the nonlinear MACE filter.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  2784 </NUMBER>
<ORDER>   AAG9801058 </ORDER>
<TITLE> ASIC IMPLEMENTATION OF THE SYMMETRIC FUZZY PROCESSOR AND ITS APPLICATION TO ADAPTIVE SYSTEMS </TITLE>
<AUTHOR> ABDEL-HAFEEZ, SALEH MESBAH </AUTHOR>
<YEAR> 1997 </YEAR>
<INSTITUTION> THE UNIVERSITY OF TEXAS AT EL PASO; 0459 </INSTITUTION>
<DESCRIPTORS> ENGINEERING, ELECTRONICS AND ELECTRICAL; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> SCOTT STARKS </ADVISER>
<CLASSIFICATIONS> FUZZIFICATION, KNOWLEDGE BASE </CLASSIFICATIONS>
<ABSTRACT>
This dissertation presents a VLSI design of a symmetric
fuzzy processor. The design features fuzzification,
defuzzification and inference operations while allowing
the implementation of a knowledge base via rules. By
combining the inherent advantages of symmetric
triangular membership functions and fuzzy singleton
sets, a novel structure for the fuzzification model is
obtained. The structure accelerates the evaluation of
the antecedent degree which is evaluated by a simple
mathematical relation which calculates the resulting
value using the end-points of matched fuzzy member
functions. This feature enables the processor to avoid
the requirement of storing all the sample values of the
fuzzy membership function in memory as is the case with
other approaches. In addition, the resulting design
structure simplifies computations associated with
centroid defuzzication in that certain simplifying
assumptions eliminate the need for a divider circuit. By
using a very high speed integrated circuit hardware
description language (VHDL) compiler and by making use
of a simulator provided through the Mentor Graphics EDA
design tool, optimization of the VLSI design has been
obtained. Results show that the resulting fuzzy
processor can be implemented on a single 1.2$mu$m CMOS
VLSI chip with 16.7 mm$sp2$ die size and a total of
36,080 transistors. Moreover, simulation indicates that
numerical computations including centroid
defuzzification can be accomplished in 0.55 $mu$s.
within an accuracy of 96%, thus making it suitable for a
wide range of real-time applications. Up to 49
consequent knowledge rules based for seven fuzzy
membership functions associated with the chip's two
input variables can be downloaded into a 64-byte static
RAM allowing designers to create a fuzzy processing
system without the need for additional on-board memory.
Finally, as an example of the application of the
proposed fuzzy processor model, results are presented
from a study to simulate a second order linear control
system and a non-linear structure for adaptive channel
equalization of a bipolar signal passed through a
dispersive channel in the presence of additive noise. It
is shown that difficulties commonly associated with
channel non-linearity and additive noise correlation can
be overcome by the use of an equalizer employing the
developed fuzzy structure.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  2785 </NUMBER>
<ORDER>   AAG9800812 </ORDER>
<TITLE> TRANSFERRING ASSEMBLY SKILLS TO ROBOTS: LEARNING FORCE SENSORY PATTERNS AND SKILLS FROM HUMAN DEMONSTRATION </TITLE>
<AUTHOR> SKUBIC, MARJORIE A. </AUTHOR>
<YEAR> 1997 </YEAR>
<INSTITUTION> TEXAS A&M UNIVERSITY; 0803 </INSTITUTION>
<DESCRIPTORS> COMPUTER SCIENCE; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> RICHARD A. VOLZ </ADVISER>
<CLASSIFICATIONS> NIL </CLASSIFICATIONS>
<ABSTRACT>
Robots are distinguished from other automated machines
by their capability of being programmed to perform a
variety of tasks. However, the difficulty in programming
robots remains one of the barriers preventing their full
utilization. This is especially true in tasks such as
assembly operations, which involve the robot making
contact with its environment.
This research addresses the problem by studying methods
of transferring human, force-based assembly skills to
robots, with the use of a natural interface between the
human operator and the robot. The interface is modeled
as a teacher-student relationship, where the human
demonstrator acts as a teacher and the robot plays the
role of student. A hybrid control system (HCS) is used
for modeling assembly skills, because it provides a
means of interfacing the symbol processing used by the
human teacher with the signal processing used by the
robot. Using the HCS model, an assembly skill is
described as a sequence of qualitative states and the
desired transitions between the states. In this case,
the qualitative state takes the form of a single-ended
contact formation, which describes how a workpiece
touches its environment. Skill acquisition involves
learning the sequence of qualitative states, the
transitions between those states, and the mapping from
sensor signals to the qualitative states.
We discuss two methods of classifying single-ended
contact formations from force sensory patterns, without
using geometric models of the workpieces. In the first
method, fuzzy logic is used to model the patterns in the
force signals, with membership functions being generated
automatically from training data. In the second method,
a neural network architecture is used to learn the
mapping from force signals to the qualitative states.
The training and performance of the classifiers is
discussed.
Experimental results are presented which illustrate and
validate the approach. The technique is used to extract
skill information from human demonstration data.
Successful test runs show how the classification
technique and the HCS model can be used to provide
robust execution of the skill, even without prior
position information.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  2786 </NUMBER>
<ORDER>   AAG9800756 </ORDER>
<TITLE> DIMENSIONALITY IN FUZZY SYSTEMS </TITLE>
<AUTHOR> KELLY, WALLACE EUGENE, III </AUTHOR>
<YEAR> 1997 </YEAR>
<INSTITUTION> TEXAS A&M UNIVERSITY; 0803 </INSTITUTION>
<DESCRIPTORS> ENGINEERING, ELECTRONICS AND ELECTRICAL; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> JOHN H. PAINTER </ADVISER>
<CLASSIFICATIONS> BAYESIAN PROBABILITY, HYPERTRAPEZOIDAL FUZZY MEMBERSHIP, ARTIFICIAL INTELLIGENCE </CLASSIFICATIONS>
<ABSTRACT>
This dissertation explores the theoretical and practical
aspects of dimensionality in fuzzy systems. First, the
author shows that fuzzy logic can be formulated from
first principles of Bayesian probability theory. Such a
formulation helps focus theoretical development of fuzzy
logic techniques. For example, the effect of anomalous
inputs on various forms of fuzzy inference can be
understood and considered during the design process. The
Bayesian interpretation of fuzzy logic has also guided a
fundamental improvement in the state-of-the-art of fuzzy
system engineering. Known as hypertrapezoidal fuzzy
membership functions (HFMF), this new method of defining
multidimensional fuzzy relationships is motivated by an
on-going research project in smart-cockpit technologies.
The Automated Safety and Training Avionics project of
Texas A&M seeks to improve the safety of the general
aviation industry by utilizing artificial intelligence
techniques in on-board avionics systems. Efforts to
enhance on-board situational awareness revealed a
fundamental weakness in fuzzy logic systems. HFMFs
address this weakness by enabling the design of
correlated fuzzy models with relatively few parameters.
HFMFs can be successfully used for automatic flight mode
interpretation and hold promise for many other
applications. Finally, the author suggests directions
for future research related to multidimensional fuzzy
engineering.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  2787 </NUMBER>
<ORDER>   AAG9800724 </ORDER>
<TITLE> INTELLIGENT AGENTS APPLIED TO SOFTWARE MANAGEMENT </TITLE>
<AUTHOR> GARCIA ESPINOSA, MARIO ALBERTO </AUTHOR>
<YEAR> 1997 </YEAR>
<INSTITUTION> TEXAS A&M UNIVERSITY; 0803 </INSTITUTION>
<DESCRIPTORS> COMPUTER SCIENCE </DESCRIPTORS>
<ADVISER> DICK B. SIMMONS </ADVISER>
<CLASSIFICATIONS> NIL </CLASSIFICATIONS>
<ABSTRACT>
Intelligent Agents (IAs) are an area of Artificial
Intelligence (AI) that has recently attracted the
attention of many researchers.
In this research, three IAs were applied to Software
Management. An IA uses a set of rules to determine the
best action to take according to the inputs received. To
implement the rules for the three agents two things are
needed: First, a set of software metrics, and second,
for each metric, ranges of admissible values (minimum,
average, and maximum).
The set of metrics used by the IAs were selected from
the following sources: Software Engineering Institute
(SEI); IEEE; Army; Department of Defense; and PAMPA.
To find ranges of admissible values for the metrics in
the set, three databases containing data from past
software projects were analyzed. The first was the
National Software and Information Repository (NSDIR)
sponsored by the Air Force; the second was the Data
Analysis Center for Software (DACS) sponsored by the
Department of Defense; and the third was the Software
Engineering Laboratory (NASA - SEL) sponsored by the
National Aeronautics and Space Administration/ Goddard
Space Flight Center NASA/GSFC. In addition, a Software
Engineering student project developed at Texas A&M
University was measured and analyzed.
The first IA is used to estimate the phase of a project.
The second IA is used to estimate the effort,
development time, staff, paperwork, and number of
defects in a software product. The third IA is used to
diagnose problems in software products.
The IAs will give a warning to software managers if they
detect that a metric is out of the admissible range of
values. Hopefully, this warning will lead to actions
that solve problems before they grow and endanger the
software project.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  2788 </NUMBER>
<ORDER>   AAG9800707 </ORDER>
<TITLE> APPLYING NEURAL NETWORKS TO DETECT QUANTITATIVE TRAIT LOCI WITH THE AID OF GENETIC MARKERS </TITLE>
<AUTHOR> CHOU, CHIEN-JU </AUTHOR>
<YEAR> 1997 </YEAR>
<INSTITUTION> TEXAS A&M UNIVERSITY; 0803 </INSTITUTION>
<DESCRIPTORS> BIOLOGY, GENETICS; COMPUTER SCIENCE </DESCRIPTORS>
<ADVISER> JOHN P. WALTER </ADVISER>
<CLASSIFICATIONS> BACKPROPAGATION, PRUNING </CLASSIFICATIONS>
<ABSTRACT>
A new approach using neural networking technology to
detect major genes influencing discrete and quantitative
phenotypes in cattle and sorghum was investigated.
Original genotypic and phenotypic data on 529 cattle and
370 observations from sorghum were used. Marker
genotypes from bovine chromosomes 1 to 6, and 18 and
sorghum chromosomes A, B, D, F, G, and J were used as
inputs.
Two stages of investigation were conducted. A
backpropagation algorithm was applied to detect the
presence of one or more major genes on a chromosome.
Results indicated the most likely chromosomes harboring
major genes for discrete traits are 1 for polledness and
18 for coat color, and for quantitative traits in
sorghum are D for both average height and average days
to first flowering. These results confirmed reports from
previous research.
Pruning was conducted to locate the markers nearest to
the affecting gene on the designated chromosome. Results
showed one or more major genes were determined to exist
near the markers 2, 4, and 5 (BM6438, TGLA49, and
INRA117, respectively) on chromosome 1 for polledness,
markers 1 and 2 (BM856/BR4206 and BMS1322, respectively)
on chromosome 18 for coat color, markers 7, 8, and 12
(pSB189, pSB188x, and SHO74, respectively) for average
height, and genes near markers 7, 8, 9, and 12 (pSB189,
pSB188x, pSB580, and SHO74, respectively) for average
days to first flowering. These results also confirmed
previous research.
Results from this study indicated that neural networking
technology shows promise for the detection of certain
major genes. Further investigation on this matter is
encouraged. User-friendly software using artificial
intelligence technology would be a great assistance for
geneticists in their research.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  2789 </NUMBER>
<ORDER>   AAG9800533 </ORDER>
<TITLE> SPOKEN-LANGUAGE HELP FOR HIGH-FUNCTIONALITY APPLICATIONS </TITLE>
<AUTHOR> JONES, MICHAEL PAUL </AUTHOR>
<YEAR> 1997 </YEAR>
<INSTITUTION> UNIVERSITY OF COLORADO AT BOULDER; 0051 </INSTITUTION>
<DESCRIPTORS> COMPUTER SCIENCE; ARTIFICIAL INTELLIGENCE; INFORMATION SCIENCE </DESCRIPTORS>
<ADVISER> JAMES H. MARTIN </ADVISER>
<CLASSIFICATIONS> INFORMATION RETRIEVAL, NATURAL LANGUAGE PROCESSING </CLASSIFICATIONS>
<ABSTRACT>
Modern, high-functionality computer applications are
difficult to learn and use. Users of these applications
frequently need help to complete their work. However,
traditional keyword-based help systems are awkward to
use and they frequently fail to satisfy their users'
information needs. Allowing users to ask for help in
their own words offers a more natural interaction than
provided by keyword systems. Analysis of the language
used in the questions facilitates the successful
retrieval of answers at a far superior rate than
traditional systems.
This dissertation describes SAGE, a help system
developed by combining techniques gleaned from the
information retrieval (IR) and artificial intelligence
(AI) communities. SAGE responds to users' questions by
retrieving answers from an existing collection of help
text. The kernel of SAGE is based on an advanced IR
technique called Latent Semantic Indexing (LSI), a
variant of the vector space model. This kernel is then
enhanced by adding robust natural language processing
and machine learning techniques.
Both the development and evaluation of SAGE have been
empirical efforts. Live user studies with a simulated
system were used to gather data crucial to the design of
the system. Evaluation of the system was based on live
user studies and on relevance judgments for a set of
naturally occurring queries.
The results of these evaluations indicate that the SAGE
approach can be quite effective when deployed in
realistic settings. In particular, the SAGE results have
shown that given unconstrained natural language
questions, answers to users' information needs can be
retrieved from existing help text.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  2790 </NUMBER>
<ORDER>   AAG9800256 </ORDER>
<TITLE> FUZZY MULTI-CRITERIA DECISION MAKING </TITLE>
<AUTHOR> GOGUS, OZERK MEHMET </AUTHOR>
<YEAR> 1997 </YEAR>
<INSTITUTION> RUTGERS THE STATE UNIVERSITY OF NEW JERSEY - NEW BRUNSWICK; 0190 </INSTITUTION>
<DESCRIPTORS> ENGINEERING, INDUSTRIAL; BUSINESS ADMINISTRATION, MANAGEMENT; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> THOMAS O. BOUCHER </ADVISER>
<CLASSIFICATIONS> FUZZY LOGIC, DECISION MAKING, NONTRADITIONAL CAPITAL INVESTMENT CRITERIA </CLASSIFICATIONS>
<ABSTRACT>
Multi-criteria decision making (MCDM) models, like the
Analytic Hierarchy Process and the Non-Traditional
Capital Investment Criteria, have been developed to
incorporate the difficult-to-quantify criteria into the
decision making process. One shortcoming of these
methods is the failure to realistically represent the
imprecision of the decision makers' judgments. In this
aspect, the use of fuzzy logic and linguistic variables
have attracted some attention.
Due to the advantages of the Non-Traditional Capital
Investment Criteria (NCIC) over the Analytic Hierarchy
Process (AHP), we extended NCIC to include fuzzy logic.
We studied the mathematical relationship between AHP and
NCIC as a foundation for the development of the fuzzy
NCIC methodology. We generated equations to map the
outcome of one method into a set of data comparable with
the outcome of the other method and demonstrated their
use through an application to a real world decision
making problem.
A problem well-documented in the use of fuzzy pairwise
comparisons in decision models is that of the irrational
fuzzy weight vector. We investigated the cause of
obtaining irrational weight vectors when pairwise
comparisons matrices contained Triangular Fuzzy Numbers
as decision makers' judgments. We determined the
underlying cause of this phenomenon and developed a
testing procedure that will prevent these
irrationalities from occurring in the weight vectors.
We extended the strong transitivity axiom to fuzzy
pairwise comparisons matrices and developed a method to
check for the internal consistency of decision makers
when judgments are presented as fuzzy numbers. We
studied the relationships between the irrationality of
the weight vectors, internal consistency of the decision
makers and the satisfaction of the weak monotonicity
axiom of measurement theory.
To have a complete fuzzy MCDM method, the use of three
different instruments for eliciting judgments from the
decision makers in making pairwise comparisons are
evaluated. The problem of representing the imprecision
as realistically and correctly as possible is addressed
by comparing these three instruments through an
experimental design using a large panel of subjects.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  2791 </NUMBER>
<ORDER>   AAG9738990 </ORDER>
<TITLE> UNIT COMMITMENT BY ARTIFICIAL INTELLIGENCE TECHNIQUES </TITLE>
<AUTHOR> MANTAWY, ABDEL-AAL HASSAN ISMAIL </AUTHOR>
<YEAR> 1997 </YEAR>
<INSTITUTION> KING FAHD UNIVERSITY OF PETROLEUM AND MINERALS (SAUDI ARABIA); 1088 </INSTITUTION>
<DESCRIPTORS> ENGINEERING, ELECTRONICS AND ELECTRICAL; OPERATIONS RESEARCH; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> NIL </ADVISER>
<CLASSIFICATIONS> SIMULATED ANNEALING, GENETIC ALGORITHMS, SCHEDULING, THERMAL GENERATION, ECONOMIC DISPATCH PROBLEM </CLASSIFICATIONS>
<ABSTRACT>
The present work deals with thermal generation
scheduling, which could be considered the major part of
the overall scheduling problem of hydrothermal power
systems. The scheduling problem of thermal generating
units can be considered as two linked optimization
problems. It comprises the solution of both the Unit
Commitment Problem (UCP) and the Economic Dispatch
Problem (EDP). The former is a combinatorial
optimization problem with very hard constraints, while
the later is a nonlinear programming problem.
The growing interest in the application of Artificial
Intelligence (AI) techniques to power system engineering
has introduced the potentials of using this state-of-the-
art technology in the thermal generation scheduling of
electric power systems. AI techniques, unlike strict
mathematical methods, have the apparent ability to adapt
to nonlinearities and discontinuities commonly found in
power systems. The best known algorithms in this class
include evolution programming, genetic algorithms,
simulated annealing, tabu search, and neural networks.
In the present work, seven different AI-based algorithms
have been developed to solve the UCP. Two of these
algorithms namely, simulated annealing and genetic
algorithms, are implemented in a novel way. The other
five proposed algorithms are applied for the first time
to solve the UCP. The algorithms are a Simple Tabu
Search Algorithm (STSA), an Advanced Tabu Search (ATSA),
a hybrid of Simulated annealing and Tabu search
algorithms (ST), a hybrid of Genetic and Tabu search
algorithms (GT), and a hybrid of Genetic, Simulated
annealing, and Tabu search algorithms (GST).
As a first step to solve the UCP, some modifications to
the existing problem formulation have been made to
render the formulation more generalized. An augmented
model including all the problem constraints is
presented.
A major step in the course of solving the UCP, is the
solution of the EDP. In this regard, an efficient and
fast nonlinear programming routine is implemented and
tested. The implemented routine is based on a linear
complementary algorithm for solving the quadratic
programming problems as a linear program in a tableau
form. Comparing the results of our proposed routine, it
is found that the results obtained are more accurate
than that obtained using an IMSL quadratic programming
routine. The application of this routine to the EDP is
original.
The corner stone in solving the combinatorial
optimization problems is to come up with good rules for
finding randomly feasible trial solutions from an
existing feasible solution, in an efficient way. Because
of the constraints in the UCP this is not a simple
matter. The most difficult constraints to satisfy are at
the minimum up/down times. A major contribution of this
work is the implementation of new rules to get randomly
feasible solutions faster.
All the proposed algorithms have been tested on several
practical systems reported in the literature, with
different complexities. The numerical results obtained
by the proposed algorithms are superior to the results
reported in the literature.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  2792 </NUMBER>
<ORDER>   AAG9802032 </ORDER>
<TITLE> ENDGAMES: GAME AND PLAY AT THE END OF PHILOSOPHY </TITLE>
<AUTHOR> FRANCHI, STEFANO </AUTHOR>
<YEAR> 1997 </YEAR>
<INSTITUTION> STANFORD UNIVERSITY; 0212 </INSTITUTION>
<DESCRIPTORS> PHILOSOPHY; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> JOHN PERRY </ADVISER>
<CLASSIFICATIONS> ARTIFICIAL INTELLIGENCE, COGNITIVE SCIENCE, CLAUDE LEVI- STRAUSS, GEORG WILHELM FRIEDRICH HEGEL </CLASSIFICATIONS>
<ABSTRACT>
This dissertation examines the contention that
philosophy might have recently come to an end and that a
decisive use of the concepts of game and play may prove
crucial to a successful overcoming or a definitive
replacement of Western metaphysics. I show that this
double contention is marred by two difficult problems
that must be clarified: (a) the possibility of the "end
of philosophy" (which underlies the possibility of an
overcoming or of a replacement) pervades the very
definition of philosophy at work in the Western canon,
and (b) the concept of play, or a family of concepts
related to play, have classically been used in
conjunction with the project of "ending philosophy."
A close reading of the Lectures on the History of
Philosophy and of the Phenomenology of Spirit provides
ample evidence for the general validity of the Hegelian
argument: philosophy must reach an end, in all the
variety of meanings of this term (e.g termination,
accomplishment, etc.), if the discipline is to have any
hope to be transformed from a mere love of knowledge
into an accomplished Wissenschaft. The second point is
established through a broad analysis of both Hegelian
philosophy and other traditions that see themselves as
non-philosophy, i.e. as replacements of metaphysics
(Artificial Intelligence and Cognitive Science, Claude
Levi-Scrauss's Structuralism, post-Hegelian philosophy):
in all cases, a wide recourse to the concept of play is
crucial, but ultimately unsuccessful, to either the
accomplishment or the overcoming of metaphysics.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  2793 </NUMBER>
<ORDER>   AAG9801923 </ORDER>
<TITLE> SOVEREIGN NATIONS FINANCIAL DISTRESS: AN EARLY WARNING SYSTEM FOR PREDICTING PARIS CLUB DEBT RE-SCHEDULING EVENTS FROM FINANCIAL RATIOS, AND NEURAL NETWORK INDEXING MODEL </TITLE>
<AUTHOR> WOLF, FRANK E. </AUTHOR>
<YEAR> 1997 </YEAR>
<INSTITUTION> NOVA SOUTHEASTERN UNIVERSITY; 1191 </INSTITUTION>
<DESCRIPTORS> BUSINESS ADMINISTRATION, BANKING; COMPUTER SCIENCE; OPERATIONS RESEARCH; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> NIL </ADVISER>
<CLASSIFICATIONS> NIL </CLASSIFICATIONS>
<ABSTRACT>
Government leaders and Bretton Woods institutions
managers have called for the development of early
warning systems for predicting financial stress of
nations. This research addresses that problem by drawing
on theories from commercial bankruptcy prediction, and
finding a similarity between corporate financial ratios
and those of nations, and also finding a similarity
between chapter XI corporate restructuring and a Paris
Club event, in which multilateral debt is rescheduled to
achieve a sustainable debt service status.
Grounded in the literature, four sovereign nation ratios
relative to creditworthiness, liquidity, ability to pay,
and economic activity were selected. Such ratios include
elements of GNP, short-term and total debt, export
earnings, internal and external reserves, and debt
service requirements. With the exception of the
creditworthiness ratio, the study found a significant
difference between Paris Club nations and those not
defaulting.
A ratio-based neural network was trained on 90
observations from 40 defaulting nations for the period
1989 to 1993, and 45 observations from 45 non-defaulting
debtor nations for 1993. The trained neural network was
then tested on all 208 nations in the World Bank STAR
database for 1994. The neural network was programed to
classify 208 nations into probable defaulting and non-
defaulting groups, 1994 to 1996.
The neural network correctly classified 77% of
defaulting and non-defaulting nations. Its output
weights were found to act, look and feel like Zeta-
Scores used in corporate bankruptcy classification. On a
range of values from 0.0 to 1.0, a nations' neural
weight of $<$0.73 successfully separated 95% of Paris
Club and non-Paris Club nations.
IMF and World Bank policies, and how these changed over
recent decades, are discussed, together with social
objectives of default prevention, poverty alleviation,
and the perspectives of donor nations and debtor nations
alike. Future research should address shorter prediction
horizons with increased emphasis on commercial debt.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  2794 </NUMBER>
<ORDER>   AAG9801335 </ORDER>
<TITLE> THE REPRESENTATION OF GRADATION IN GEOGRAPHIC INFORMATION SYSTEMS </TITLE>
<AUTHOR> PLEWE, BRANDON STANLEY </AUTHOR>
<YEAR> 1997 </YEAR>
<INSTITUTION> STATE UNIVERSITY OF NEW YORK AT BUFFALO; 0656 </INSTITUTION>
<DESCRIPTORS> GEOGRAPHY; REMOTE SENSING; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> BARBARA BUTTENFIELD </ADVISER>
<CLASSIFICATIONS> GIS </CLASSIFICATIONS>
<ABSTRACT>
In the past, for various reasons, GIS software has not
been able to represent many of the complexities of the
world and human perceptions of it. Along with concepts
such as the temporal change, three-dimensionality, and
uncertainty inherent in reality and cognition, gradation
plays an important role in how the world works. This
dissertation pulls together previous work concerning
geographical entities with gradual boundaries into a
single framework and vocabulary.
Once a degree of understanding is obtained concerning
the variety of causes and forms of gradation, the
representation of this phenomenon in GIS is
investigated. Several possible data models and
structures are described, including some introduced
elsewhere and some developed by the author, and an
evaluation of the effectiveness of each in dealing with
a particular application.
Through this research, it is found that the variety of
characteristics found in gradation situations leads to a
variety of relevant solutions. Several of the proposed
structures appear to be practical to implement in
current software, while others would require a total
redesign of GIS.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  2795 </NUMBER>
<ORDER>   AAG9738878 </ORDER>
<TITLE> "MONA LISA" THINSPACE'S MODERNITY: QUEER THEORIES THROUGH PATER AND FREUD  </TITLE>
<AUTHOR> DAVIS, MICHAEL FRANCIS </AUTHOR>
<YEAR> 1997 </YEAR>
<INSTITUTION> UNIVERSITY OF VIRGINIA; 0246 </INSTITUTION>
<DESCRIPTORS> LITERATURE, MODERN; ART HISTORY; PHILOSOPHY; PSYCHOLOGY, GENERAL </DESCRIPTORS>
<ADVISER> MICHAEL LEVENSON; PAT GILL </ADVISER>
<CLASSIFICATIONS> WALTER PATER, SIGMUND FREUD </CLASSIFICATIONS>
<ABSTRACT>
As early as 1864, Walter Pater began to identify not
only a homosexual character but also a homosexual
intelligence, what we might call in the terms of current
criticism, a queer theory. In his first published essay,
Pater struggled with Coleridge, the critical father,
from whose writing he tried to elicit the authorizing
ideas for such a radical theory. Failing that, Pater
turned away from Coleridge and the English critical
tradition to Winckelmann and the Germanic. In
Winckelmann, Pater found a substitute father and an
alternative hermeneutic practice that interpolated
feeling into the interpretive function. In Winckelmann's
finding of Greek art and in his recognition of the Greek
ideal, Pater discovered a legitimating precedent for a
homosexual inquiry. Pater individuated as a critic and
in his next essays, "Aesthetic Poetry" and "Leonardo da
Vinci," and began to conceptualize a homosexual world
view. Pater's emergent intelligence came to climax in
his overdetermined Mona Lisa reverie, which we can take
as the origin of Modern queer theory. As medical science
and the law began to categorize the homosexual in 1869,
Pater was already subtly theorizing it.
In 1873 in his Studies in the History of the
Renaissance, Pater queered the Renaissance. He perceived
the Renaissance to be what Jonathan Goldberg has called
a "crucial and potentially disruptive" movement "in the
foundations of the modern socio-sexual order." Pater did
not just expose and reveal the representation of same-
sex desire but uncovered a whole culture of queer
desire, including a set of queer ideas, a series of
queer intellectual and artistic acts, a queer psychology
and a queer historiography.
Pater conducted into modernity a powerful current of
homosexual thought that flowed directly to Freud. From
The Interpretation of Dreams on, Freud and
psychoanalysis were engaged in a self-reflexive
hermeneutic struggle with homosexual desire. While Freud
repeatedly pictures the homosexual motif in his dreams,
he repeatedly represses it in his interpretations. His
homosexual desire is in fundamental conflict with his
desire to consolidate the science of psychoanalysis.
Freud's inability to interpolate his desire in the
interpretive function, however, paradoxically leads to
the failure to solve the case of Dora. From Dora,
however, Freud learns the hysterical solution, which
takes paradox into account. As Dora stands before the
Dresden Madonna, Freud stands before the Mona Lisa and
conceives the theory of Narcissism. Through the
Narcissus trope and in "On Narcissism" Freud
incorporates homosexual desire into the body of
psychoanalysis and into the mind of the modern, breaking
down the artificial opposition of the ego and the id
that had structured psychoanalytic theory until then.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  2796 </NUMBER>
<ORDER>   AAG1385822 </ORDER>
<TITLE> OPTIMAL CONTROL OF NONLINEAR PLANTS USING ARTIFICIAL NEURAL NETWORKS </TITLE>
<AUTHOR> AL DAJANI, MANSOUR ABDULAZIZ </AUTHOR>
<YEAR> 1997 </YEAR>
<INSTITUTION> KING FAHD UNIVERSITY OF PETROLEUM AND MINERALS (SAUDI ARABIA); 1088 </INSTITUTION>
<DESCRIPTORS> ENGINEERING, SYSTEM SCIENCE; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> NIL </ADVISER>
<CLASSIFICATIONS> NIL </CLASSIFICATIONS>
<ABSTRACT>
In this thesis, algorithms for application of Artificial
Neural Network in solving nonlinear optimal control
problems are developed. The conventional Multi-layers
Feed-forward Neural Network is employed as the state
feedback optimal controller. The newly developed Block
Partial Derivatives concept is used to compute the
gradient needed for neural network training. State
tracking, regulation, terminal control, minimum control
effort, minimum time, and output tracking problems are
attempted. The performance of the proposed algorithms is
investigated through application on simulated plants.
Results obtained agree with the ones found through other
standard techniques.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  2797 </NUMBER>
<ORDER>   AAG1385781 </ORDER>
<TITLE> INVERSE MAPPING OF CONTINUOUS FUNCTIONS USING FEEDFORWARD NEURAL NETWORKS </TITLE>
<AUTHOR> DEIF, HATEM MOHAMED </AUTHOR>
<YEAR> 1997 </YEAR>
<INSTITUTION> UNIVERSITY OF LOUISVILLE; 0110 </INSTITUTION>
<DESCRIPTORS> ENGINEERING, ELECTRONICS AND ELECTRICAL; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> JACEK M. ZURADA </ADVISER>
<CLASSIFICATIONS> NIL </CLASSIFICATIONS>
<ABSTRACT>
This work presents a new methodology for solving inverse
mapping of continuous functions modeled by multilayer
feedforward neural networks. An introduction to
multilayer feedforward neural networks and their use in
function approximation is given followed by a
description of the gradient descent inverse mapping.
Then, a new methodology which consists of an update rule
associated with a technique for escaping local minima is
presented.
The methodology is based on an iterative update of the
input vector towards a solution, while escaping local
minima of the energy function. The update rule is able
to detect local minima through a phenomenon called
"update explosion." The input vector is then relocated
to a new position based on a probability density
function (PDF) constructed over the input vector space.
The PDF is built using local minima detected during the
past search process.
A software program was developed to implement the new
algorithm. The program should be able to perform inverse
mapping modeled by two layer feedforward neural networks
with few neurons in its input layer.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  2798 </NUMBER>
<ORDER>   AAG1385659 </ORDER>
<TITLE> APPLICATIONS OF NEURAL NETWORKS USING EXTENDED KALMAN FILTERING </TITLE>
<AUTHOR> OWEN, MARK WILLIAM </AUTHOR>
<YEAR> 1997 </YEAR>
<INSTITUTION> CALIFORNIA STATE UNIVERSITY, LONG BEACH; 6080 </INSTITUTION>
<DESCRIPTORS> ENGINEERING, ELECTRONICS AND ELECTRICAL; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> BAHRAM SHAHIAN </ADVISER>
<CLASSIFICATIONS> NIL </CLASSIFICATIONS>
<ABSTRACT>
A Kalman filter is augmented by a neural network to
achieve robust performance for nonlinear systems without
requiring a priori knowledge of the nonlinearities. The
filter and neural network combination is called a neuro-
observer. The neural network is trained on-line to
identify system nonlinearities, which are then added to
a linear system model to better estimate the states of a
nonlinear system. A performance comparison is made
between a discrete Kalman filter estimator and a neuro-
observer for the nonlinear control problem of a single
joint robotic arm. A computer simulation is used for the
robotic arm and the actuator. A neuro-observer is used
as a state estimator in a standard linear quadratic
Gaussian design to improve the performance of the
robotic arm system response.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  2799 </NUMBER>
<ORDER>   AAG1385455 </ORDER>
<TITLE> TRAINING FUZZY NEURONS WITH BACKPROPAGATION ALGORITHMS </TITLE>
<AUTHOR> VIJAY, ABHIMANYU MANSINGHKA </AUTHOR>
<YEAR> 1997 </YEAR>
<INSTITUTION> TEXAS A&M UNIVERSITY-KINGSVILLE; 1187 </INSTITUTION>
<DESCRIPTORS> COMPUTER SCIENCE; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> CHUNG S. LEUNG </ADVISER>
<CLASSIFICATIONS> NIL </CLASSIFICATIONS>
<ABSTRACT>
In the training of the Neural Networks, the most
commonly used algorithm is the Backpropagation
algorithm. A major drawback of this algorithm is that
its training time is very long for most of the everyday
applications, another drawback is if the test pattern is
not identical with one of the trained patterns in the
training set, the outcome is unpredictable. Thus a
perfect classification of ideal input vectors and a
reasonably accurate classification of noise vectors are
both required. In this research a newly developed
algorithm is proposed so as to create a network that can
be trained within a reasonable time frame and also
handle noisy vectors with high accuracy. This is done by
using fuzzy logic to control the adaptive learning rate,
eliminating the painstaking and time consuming process
of finding the optimum learning rate and the selection
of a perfect training set.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  2800 </NUMBER>
<ORDER>   AAINN99408 </ORDER>
<TITLE> AN INTELLIGENT SUBSTATION ALARM PROCESSOR  </TITLE>
<AUTHOR> LI, HEPING </AUTHOR>
<YEAR> 1994 </YEAR>
<INSTITUTION> UNIVERSITY OF CALGARY (CANADA); 0026 </INSTITUTION>
<DESCRIPTORS> ENGINEERING, ELECTRONICS AND ELECTRICAL; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> O. P. MALIK </ADVISER>
<CLASSIFICATIONS> EXPERT SYSTEM, KNOWLEDGE BASED MANAGEMENT </CLASSIFICATIONS>
<ABSTRACT>
This study explores the building of a domain and
application specific expert system development tool to
build an effective and efficient expert system for
substation alarm processing easily and in a short time.
The knowledge base management system (KBMS) in this
system is embedded into the C++ object oriented
programming language. All operations for dealing with
storage, retrieval and message passing functions are
defined in two built-in classes: KBPersistentObject and
KBLinkedPersistentObject. Just by declaring a user-
defined class as the subclasses of either
KBPersistentObject or KBLinkedPersistentObject, the
objects in this class will inherit aIl the
characteristics defined in KBPersistentObject or
KBLinkedPersistentObject, and become smart to know how
to store and retrieve their own attribute values and
deal with messages themselves. The KBMS also includes a
set of classes representing an object-oriented knowledge
representation model which covers the majority of common
knowledge needed in substation alarm processing.
The general purpose rule-based inference engine in this
system can perform nonmonotonic reasoning and dynamic
reasoning. The shell also includes five problem solving
modules; alarm synthesis, alarm classification, fault
diagnosis, topology analysis, and recovery operation
advice, to solve many common problems in substation
alarm processing. These modules are specially designed
based on the features of the substation alarm
processing, without restrictions on the methods used, to
get higher efficiency and effectiveness.
The developed system has been tested on five typical
substation configurations. The results show that the
system satisfactorily performs the functions for which
it is designed.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  2801 </NUMBER>
<ORDER>   AAG1385450 </ORDER>
<TITLE> INTELLIGENT CONTROL OF A REDUNDANT THREE-LINK PLANAR ROBOTIC MANIPULATOR </TITLE>
<AUTHOR> SAPORITO, FRANK CHARLES </AUTHOR>
<YEAR> 1997 </YEAR>
<INSTITUTION> TEXAS A&M UNIVERSITY-KINGSVILLE; 1187 </INSTITUTION>
<DESCRIPTORS> ENGINEERING, MECHANICAL; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> ROBERT A. MCLAUCHLAN </ADVISER>
<CLASSIFICATIONS> NIL </CLASSIFICATIONS>
<ABSTRACT>
This thesis investigates the intelligent control of
redundant robotic manipulators. The research focuses on
a three-link planar manipulator oriented in the vertical
plane. The redundancy resolution is based on task
augmentation by maximization of the manipulability
measure. Global optimization with respect to
manipulability and closed path continuity are achieved.
A neural network is used to solve the inverse kinematic
equations and map task space trajectories into joint
space. The trajectory planning algorithm does not
require the computationally intensive Jacobian
determination and is fast enough for real time
implementation.
End-effector positioning is achieved by independent
joint torque control via adaptive fuzzy PD gain
scheduling, constant integral gain, and gravity
compensation controllers. With the exception of the
gravity term, the control strategy does not require
system identification or knowledge of the equations of
motion. The MATLAB/SIMULINK environment is used to
implement and validate proposed concepts.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  2802 </NUMBER>
<ORDER>   AAG1385385 </ORDER>
<TITLE> ENHANCEMENTS TO THE GENETIC PROGRAMMING PARADIGM FOR IMPROVED ROBUSTNESS, ACCURACY, AND SPEED </TITLE>
<AUTHOR> HOOPER, DALE C. </AUTHOR>
<YEAR> 1997 </YEAR>
<INSTITUTION> UTAH STATE UNIVERSITY; 0241 </INSTITUTION>
<DESCRIPTORS> COMPUTER SCIENCE; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> NICHOLAS S. FLANN </ADVISER>
<CLASSIFICATIONS> NIL </CLASSIFICATIONS>
<ABSTRACT>
Genetic programming (GP) is a powerful technique for
creating computer programs from a limited number of
example input-output pairs of the desired program. The
problem solved by GP systems is one of inductive
learning since the program identified must reproduce the
behavior of the desired program over all the input
space, not just the space represented in the training
examples. While GP systems do well at achieving accuracy
over the training examples, they often produce
inaccurate results over the whole input space. In
addition, traditional GP systems search the space of
computer programs using methods based on natural
selection. While these methods tend to avoid local
minima, they can be very slow to generate large, complex
programs due to bloating.
This thesis introduces general solutions to these
problems. An approach to producing more accurate results
over the entire program space is to apply Occam's razor
and introduce a bias for simplicity. This thesis shows
that use of a truth-preserving expression simplifier
works well to improve the accuracy and robustness of
solutions. Also introduced is an alternative search
strategy for GP called recombinative hill-climbing
(RHC), which combines the power of the recombination
operator from GP with a simple population-based hill-
climbing selection method. The RHC search method
overcomes problems with local minima common in hill-
climbing approaches. It is found to be robust, accurate,
and much faster than traditional GP. This thesis also
shows that the above methods are more resilient than
traditional GP in the presence of noisy data.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  2803 </NUMBER>
<ORDER>   AAGMM20523 </ORDER>
<TITLE> A BIOLOGICALLY INSPIRED CONTROL SYSTEM FOR AUTONOMOUS ROBOT NAVIGATION </TITLE>
<AUTHOR> ROZANSKI, BONNIE GAIL </AUTHOR>
<YEAR> 1997 </YEAR>
<INSTITUTION> UNIVERSITY OF GUELPH (CANADA); 0081 </INSTITUTION>
<DESCRIPTORS> COMPUTER SCIENCE; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> DEBORAH STACEY </ADVISER>
<CLASSIFICATIONS> NIL </CLASSIFICATIONS>
<ABSTRACT>
This thesis is an investigation of whether simple
control systems, using few explicit instructions but
incorporating biologically-inspired subsystems of
motivation and learning, are capable of enabling a robot
to navigate a maze.
This "brain" consists of a discrete autocorrelator for
recognition of spatial configurations in the
environment, a counterpropagation network for learning
successful stimulus-response pairs, and a generally
distributed architecture of simpler, interconnected
modules. It also includes basic principles of drives and
reinforcement from psychology to cue and to evaluate
action.
The model is designed to enable an autonomous robot
bearing sonar, light, and touch sensors to seek out a
foodlike goal. It identifies sets of spatial
configurations from noisy sonar signals, and learns the
best-fitting response to each set. This study has shown
the capacity of imprecise mechanisms to guide navigation
in a maze, and the emergence of complex behavioural
strategy from a design of local, distributed components.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  2804 </NUMBER>
<ORDER>   AAGMM20171 </ORDER>
<TITLE> CLASSIFICATION CONCEPTUELLE A L'AIDE DE LA MSG SUR MACHINE PARALLELE VOLVOX </TITLE>
<AUTHOR> JEAN, FRANCOIS </AUTHOR>
<YEAR> 1997 </YEAR>
<INSTITUTION> UNIVERSITE LAVAL (CANADA); 0726 </INSTITUTION>
<DESCRIPTORS> COMPUTER SCIENCE; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> GUY WILLIAM MINEAU; BRAHIM CHAIB-DRAA </ADVISER>
<CLASSIFICATIONS> FRENCH TEXT </CLASSIFICATIONS>
<ABSTRACT>
L'apprentissage automatique est un champ de
l'intelligence artificielle qui permet aux ordinateurs
de traiter de l'information d'une facon autonome afin de
parfaire un ensemble de connaissances de base. Un sous-
champ de l'apprentissage automatique, la classification
conceptuelle, s'interesse plus particulierement a la
classification d'informations representees sous diverses
formes. Par le passe, beaucoup de chercheurs ont essaye
de developper des algorithmes de classfication
performants. Par performants, nous entendons les
algorithmes capables de traiter de grandes bases de
connaissances. Sachant que le parallelisme a deja permis
d'ameliorer les performances de certaines algorithmes
d'intelligence artificielle, nous avons decide
d'implanter un algorithme de classification, connu sous
le nom de MSG, sur une machine parallele MIMD. Cette mai
trise presentera donc notre methodologie d'implantation,
les difficultes rencontrees et les resultats obtenus.
Dans l'ensemble, l'experience est positive. Elle
demontre une amelioration par rapport a l'implantation
sequentielle du meme algorithme, repoussant ainsi ses
limites. La methodologie que nous proposons nous permet
donc de classifier des ensembles encore plus volumineux
d'objets structures.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  2805 </NUMBER>
<ORDER>   AAG9738588 </ORDER>
<TITLE> EXPLOITING STRUCTURE FOR PLANNING AND CONTROL </TITLE>
<AUTHOR> LIN, SHIEU-HONG </AUTHOR>
<YEAR> 1997 </YEAR>
<INSTITUTION> BROWN UNIVERSITY; 0024 </INSTITUTION>
<DESCRIPTORS> COMPUTER SCIENCE; ENGINEERING, SYSTEM SCIENCE; MATHEMATICS; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> THOMAS L. DEAN </ADVISER>
<CLASSIFICATIONS> STATE SPACE, DECISION MAKING, ARTIFICIAL INTELLIGENCE, PROBLEM DECOMPOSITION </CLASSIFICATIONS>
<ABSTRACT>
Discrete dynamical systems in the form of finite
automata or Markov decision processes have been used as
a representational and computational foundation for
planning under uncertainty. Many AI planning problems
can be conveniently viewed as control problems over the
underlying discrete dynamical systems. Using AI-style
representation, the features of application domains are
represented as state variables, and planning problem
instances compactly encode very large discrete dynamical
systems. The standard algorithms to solve the
corresponding control problems require explicit
enumeration of the underlying state spaces. This is
impractical since the sizes of the state spaces are
exponential in the number of state variables.
In this thesis, we develop decomposition techniques to
exploit structure for planning problems in different
application domains. Given a problem instance, we first
symbolically decompose the underlying dynamical system
into subsystems. After analyzing the local dynamics
within subsystems and the dependency across subsystems,
we decompose the original planning problem into a
sequence of subproblems governing the subsystems. Rather
than explicitly constructing the entire system, we
compactly construct each subsystem by abstracting away
the state variables that are irrelevant to the subsystem
and its interactions with the other subsystems.
Solutions of the planning subproblems can be derived by
applying standard algorithms for the corresponding
control problems to these compactly constructed
subsystems, while a solution to the original planning
problem is derived by systematically compiling and
propagating the solutions to the planning subproblems.
These decomposition techniques shed light on how to
exploit locality and dependency to cope with very large
state spaces.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  2806 </NUMBER>
<ORDER>   AAG9738585 </ORDER>
<TITLE> IMPLICIT POLYNOMIAL SHAPE MODELING AND RECOGNITION, AND APPLICATION TO IMAGE/VIDEO DATABASES </TITLE>
<AUTHOR> LEI, ZHIBIN </AUTHOR>
<YEAR> 1997 </YEAR>
<INSTITUTION> BROWN UNIVERSITY; 0024 </INSTITUTION>
<DESCRIPTORS> COMPUTER SCIENCE; ENGINEERING, ELECTRONICS AND ELECTRICAL; MATHEMATICS; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> DAVID B. COOPER </ADVISER>
<CLASSIFICATIONS> IMAGE PROCESSING, ARTIFICIAL INTELLIGENCE </CLASSIFICATIONS>
<ABSTRACT>
Implicit polynomials are among the most effective
representations for complex object recognition because
of their stability, robustness and invariant
characteristics. This thesis presents a general overview
of the problem and focuses on the key issues of implicit
polynomial technology for representing and recognizing
complicated 2D and 3D shapes subject to partial
occlusion and missing data. It covers new concepts and
results for fast, robust, and repeatable fitting of
implicit polynomials to data, invariantly representing
and recognizing complicated shapes, mutual geometry and
mutual invariants, object signature curves and invariant
patches/parts, PIMs (Polynomial Interpolated Measures)
and orthogonal decomposition, and closed-form pose
estimation, etc. With these, we lay down a foundation
that enables a technology based on implicit polynomial
curves and surfaces for various object
representation/recognition applications.
This thesis also discusses our approaches in applying
this implicit polynomial technology to the content-based
large pictorial database indexing and searching area. It
deals with the following problems: (1) 3D shape
reconstruction and modeling from video data. We present
a methodology of 3D string geometry-based indexing of
video data. (2) Image query using sketches. A fully
automatic curvelet structure (segments of implicit
polynomial curves) extraction method is introduced. We
built a prototype image-query-by-sketch system using
this representation and Java technology which allows
queries over the web. Special attention is also given to
the user interface part in such applications. The
preliminary results are very promising. The method
performs much better than does a pixel-based method that
has been adopted by a number of well-known content-based
image indexing and retrieval systems.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  2807 </NUMBER>
<ORDER>   AAG9737696 </ORDER>
<TITLE> THREE-DIMENSIONAL OBJECT RECOGNITION </TITLE>
<AUTHOR> CHEN, KEHANG </AUTHOR>
<YEAR> 1997 </YEAR>
<INSTITUTION> IOWA STATE UNIVERSITY; 0097 </INSTITUTION>
<DESCRIPTORS> ENGINEERING, MECHANICAL; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> JERRY LEE HALL </ADVISER>
<CLASSIFICATIONS> FEATURE CONSTRUCTION, NEURAL NETWORK </CLASSIFICATIONS>
<ABSTRACT>
In the development of an object pattern recognition
system, feature construction is always the problem
issue. Due to the large amount of information contained
in three dimensional (3D) objects, features extracted to
efficiently and sufficiently represent 3D objects are
difficult to obtain. Thus, current commercially
available object recognition systems mostly emphasize
the classification of two dimensional objects or
patterns. This work presents a paradigm to develop a
complete 3D object recognition system that uses simple
and efficient features, and supports the integration of
CAD/CAM models.
In this research, several proposed algorithm for
extracting features representing 3D objects are
constructed based on the properties of the Radon
transform. Two of these algorithms have been
successfully implemented for manufacturing applications.
The implemented systems use the artificial neural
network as the classifier to learn features and to
identify 3D objects. A statistical model has also been
established based on the output node values of a
perceptron neural network to predict the future
misclassifications of features which have not been
learned by the neural network in the training stage.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  2808 </NUMBER>
<ORDER>   AAG9737694 </ORDER>
<TITLE> THE FUZZY-NETS BASED APPROACH IN PREDICTING THE CUTTING POWER OF END MILLING OPERATIONS </TITLE>
<AUTHOR> CHANG, CHUAN-TEH </AUTHOR>
<YEAR> 1997 </YEAR>
<INSTITUTION> IOWA STATE UNIVERSITY; 0097 </INSTITUTION>
<DESCRIPTORS> ENGINEERING, INDUSTRIAL; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> JOSEPH C. CHEN </ADVISER>
<CLASSIFICATIONS> NIL </CLASSIFICATIONS>
<ABSTRACT>
Process planning is a major determinant of manufacturing
cost. The selection of machining parameters is an
important element of process planning. The development
of a utility to show the cutting power on-line would be
helpful to programmers and process planners in selecting
machining parameters. The relationship between the
cutting power and the machining parameters is nonlinear.
Presently there is no accurate or simple algorithm to
calculate the required cutting power for a selected set
of parameters. Although machining data handbooks,
machinability data systems, and machining databases have
been developed to recommend machining parameters for
efficient machining, they are basically for general
reference and hard to use as well.
In this research, a self-organizing fuzzy-nets
optimization system was developed to generate a
knowledge bank that can show the required cutting power
on-line for a short length of time in an NC verifier.
The fuzzy-nets system (FNS) utilizes a five-step self-
learning procedure. A generic FNS program consisting of
fuzzification and defuzzification modules was
implemented in the C++ programming language to perform
the procedure. The FNS was assessed before an actual
experiment was set up to collect data.
The performance of the FNS was then examined for end
milling operations on a Fadal VMC40 vertical machining
center. The cutting force signals were measured by a
three-component dynamometer mounted on the table of the
Fadal CNC machine with the workpiece mounted on it.
Amplified signals were collected by a personal computer
on which an Omega DAS-1401 analog-to-digital (A/D)
converter was installed to sample the data on-line. Data
sets were collected to train and test the system. The
results showed that the FNS possessed a satisfactory
range of accuracy with the intended applications of the
model. The values of cutting power predicted by the FNS
were more accurate than the formula values. Compared to
the FNS system, dynamometers and amplifiers are very
expensive. Thus, most of them could be replaced with the
FNS.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  2809 </NUMBER>
<ORDER>   AAG9737566 </ORDER>
<TITLE> LEARNING SITUATION-SPECIFIC CONTROL IN MULTI-AGENT SYSTEMS  </TITLE>
<AUTHOR> NAGENDRAPRASAD, MARAM V. </AUTHOR>
<YEAR> 1997 </YEAR>
<INSTITUTION> UNIVERSITY OF MASSACHUSETTS; 0118 </INSTITUTION>
<DESCRIPTORS> COMPUTER SCIENCE; ENGINEERING, SYSTEM SCIENCE; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> NIL </ADVISER>
<CLASSIFICATIONS> MACHINE LEARNING </CLASSIFICATIONS>
<ABSTRACT>
The work presented in this thesis deals with techniques
to improve problem solving control skills of cooperative
agents through machine learning. In a multi-agent
system, the local problem solving control of an agent
can interact in complex and intricate ways with the
problem solving control of other agents. In such
systems, an agent cannot make effective control
decisions based purely on its local problem solving
state. Effective cooperation requires that the global
problem-solving state influence the local control
decisions made by an agent. We call such an influence
cooperative control. An agent with a purely local view
of the problem solving situation cannot learn effective
cooperative control decisions that may have global
implications, due to the uncertainty about the overall
state of the system. This gives rise to the need for
learning more globally situated control knowledge. An
agent needs to associate appropriate views of the global
situation with the knowledge learned about effective
control decisions. We call this form of knowledge
situation-specific control. This thesis investigates
learning such situation-specific cooperative control
knowledge.
Despite the agreement among researchers in multi-agent
systems about the importance of the ability for agents
to learn and improve their performance, this work
represents one of the few attempts at demonstrating the
utility and viability of machine learning techniques for
learning control in complex heterogeneous multi-agent
systems. More specifically, this thesis empirically
demonstrates the effectiveness of learning situation-
specific control for three aspects of cooperative
control: (1) Organizational roles. Organizational roles
are policies for assigning responsibilities for various
tasks to be performed by each of the agents in the
context of global problem solving. This thesis studies
learning organizational roles in a multi-agent
parametric design system called L-TEAM. (2) Negotiated
search. One way the agents can overcome the partial
local perspective problem is by engaging in a failure-
driven exchange of non-local requirements to develop the
closest possible approximation to the actual composite
search space. This thesis uses a case-based learning
method to endow the agents with the capability to
approximate non-local search requirements in a given
situation, thus avoiding the need for communication. (3)
Coordination strategies. Coordination mechanisms provide
an agent with the ability to behave more coherently in a
particular problem solving situation. The work presented
in this thesis deals with incorporating learning
capabilities into agents to enable them to choose a
suitable subset of the coordination mechanisms based on
the present problem solving situation to derive
approximate coordination strategies.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  2810 </NUMBER>
<ORDER>   AAG9737108 </ORDER>
<TITLE> AN ARCHITECTURE FOR COLLABORATIVE PROBLEM-SOLVING CONTROL IN ASSOCIATE SYSTEMS </TITLE>
<AUTHOR> FU, MICHAEL CHIN-MING </AUTHOR>
<YEAR> 1997 </YEAR>
<INSTITUTION> UNIVERSITY OF ILLINOIS AT URBANA-CHAMPAIGN; 0090 </INSTITUTION>
<DESCRIPTORS> COMPUTER SCIENCE; ENGINEERING, INDUSTRIAL; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> CAROLINE C. HAYES </ADVISER>
<CLASSIFICATIONS> HUMAN COMPUTER, ATTENTION SYNCHRONIZATION </CLASSIFICATIONS>
<ABSTRACT>
In the past, AI systems have strived to automate problem-
solving processes completely. However, in recent years
researchers have come to realize that it is not always
possible or desirable to aim for total automation.
Researchers are realizing the importance of human-
computer collaborative systems in which the human and
the computer work as a team in solving problems. This
approach raises the question of how to design systems
that support effective collaborative problem-solving
between humans and computers. The primary contribution
of this thesis is an architecture for coordination of
collaborative problem-solving (CO-SOLVE) for an
important class of human-computer collaborative systems
called associate systems. Associate systems are
knowledge-based systems which share the cognitive
workload with their human partners. Designers of
associate systems must deal with the complexities of
integrating mixed-initiative (i.e. human and computer)
control with the general issues of problem-solving
control faced by traditional AI systems. CO-SOLVE
provides mechanisms for attention synchronization and
collaborative alternatives exploration. The Attention
Synchronization Model (ASM) allows the system to track
(rather than direct) the user's activities in order to
provide advice relevant to the current user activities.
The Collaborative Alternatives Exploration Model (CAEM)
is a mixed-initiative approach to exploring large,
complex solution spaces. In this collaborative framework
the user serves as solution evaluator and system
controller and the computer as solution alternative
generator. System developers using CAEM explicitly lay
out steps in the problem-solving process for a given
task and define points of human-computer interaction
within the sequence of process steps. The other
contribution of this thesis is a proof-of-concept
prototype of CO-SOLVE, called SEDAR, which is
implemented for a real-world, complex domain (flat and
low-slope roof design). Two evaluations were conducted
on SEDAR. The first assessed the effectiveness and
usability of the ASM and its critiquing strategies as
implemented in SEDAR. The evaluation showed that SEDAR
reduced the error rate of experienced architects and
also which advising strategies they preferred. The
second evaluation assessed the effectiveness of the CAEM
as implemented in SEDAR and showed that SEDAR (1) helped
experienced architects reduce the amount of time spent
developing solutions, and (2) increased the number of
alternatives searched in the solution space.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  2811 </NUMBER>
<ORDER>   AAI9602229 </ORDER>
<TITLE> TOWARD A NORMATIVE KNOWLEDGE-BASED LEGAL DECISION SUPPORT SYSTEM FOR THE PENALTY PHASE OF CAPITAL MURDER TRIALS </TITLE>
<AUTHOR> JENSEN, LYNN ALAN </AUTHOR>
<YEAR> 1994 </YEAR>
<INSTITUTION> VIRGINIA COMMONWEALTH UNIVERSITY; 2383 </INSTITUTION>
<DESCRIPTORS> BUSINESS ADMINISTRATION, MANAGEMENT; INFORMATION SCIENCE; LAW; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> A. JAMES WYNNE </ADVISER>
<CLASSIFICATIONS> EXPERT SYSTEMS </CLASSIFICATIONS>
<ABSTRACT>
In a real world environment, decision making is not
always a predictable, rational activity. Often the
decision environment requires an action based upon a
dynamically changing situation that emerges in response
to complex and unpredictable on-going pressures. In this
environment, access to modern decision support tools
that analyze and interpret critical data is essential to
making informed decisions.
Most decision support systems (DSS) are designed to
support specific, quantifiable semi-structured decision
situations where the choice is between known
alternatives and potential outcomes. Expert systems (ES)
are designed to assist decision makers in arriving at
decisions where the decision process is complex and
primarily structured and the data is often ambiguous and
incomplete. However, the situation facing decision
makers often requires them to make decisions in a
complex environment that is simultaneously structured
and semi-structured and that relies extensively on
multiple streams of quantitative and qualitative data.
This widely divergent data must be analyzed, classified
and interpreted before decision alternatives can be
envisioned and an informed decision made.
Initiated in this dissertation is the development of a
model of a generalizable knowledge-based system designed
to support this unique class of problems. This research
attempts to contribute to the current thinking on
integrating DSS and ES support tools into a single
system architecture, referred to as a knowledge-based
decision support system (KBDSS). To demonstrate the
feasibility of this developmental activity, the penalty
phase of the capital trial in the Commonwealth of
Virginia was selected as the domain of the research. The
generalizable KBDSS model proposed in this dissertation
has the following major knowledge-based decision support
system components: an intelligent dialogue management
system, a central blackboard architecture, an
independent, inductive case-based reasoning expert
system, and an independent, deductive reasoning hybrid
expert system that utilizes a level two blackboard
architecture to link its four independent, deductive
knowledge sources. These components are tightly
integrated into a system capable of providing the
decision maker with support for assisting in the
analysis and interpretation of multiple streams of
widely divergent quantitative and qualitative data in a
complex decision environment.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  2812 </NUMBER>
<ORDER>   AAG9736114 </ORDER>
<TITLE> ADAPTIVE NEURO-FUZZY CONTROLLER FOR PASSIVE NONLINEAR SYSTEMS </TITLE>
<AUTHOR> KUMBLA, KISHAN KUMAR </AUTHOR>
<YEAR> 1997 </YEAR>
<INSTITUTION> THE UNIVERSITY OF NEW MEXICO; 0142 </INSTITUTION>
<DESCRIPTORS> ENGINEERING, ELECTRONICS AND ELECTRICAL; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> NIL </ADVISER>
<CLASSIFICATIONS> ROBOTICS, NEURAL NETWORK </CLASSIFICATIONS>
<ABSTRACT>
The primary idea behind fuzzy control which has proven
to be a very successful method, is to build a model of a
human control expert that is capable of controlling the
plant without the knowledge of the mathematical model of
the system. Fuzzy control has a feature by which the
control is capable of incorporating expert's knowledge
or control rules using linguistic description of the
rules. A fuzzy logic controller maps complex nonlinear
relations of the control function by a set of IF--THEN
rules with associated fuzzy variables described by its
membership functions. There are two difficulties with
the current fuzzy control methodology. First, a
universal fuzzy controller does not exist for all
control applications, implying that a seperate set of
rule base and membership functions are needed for each
individual application. Second, once the rule base and
membership functions are developed and implemented for a
particular application there is no means of
automatically modifying them to changing environment and
operating conditions. This means fuzzy logic controller
lacks a learning function. Neural network, on the other
hand, self-organizes the mapping relationship by
learning. So by integrating neural networks and fuzzy
logic and with a suitable rule generation mechanism it
is possible to overcome these problems. A novel
technique which uses two neural networks and a rule
generation mechanism which adapts a fuzzy controller is
developed here. The adaptation is based on the previous
temporal response of the system. One neural network has
the ability to identify the pattern of the response and
other is used to map the nonlinearity of the system. The
rule generation mechanism uses the temporal data to
create new fuzzy rules. By combining these an
intelligent controller is derived. This algorithm is
simulated on several non-linear systems such as
desalination process, two-link manipulator and AdeptTwo
industrial robot, to evaluate the controller
performance. The results show that the adaptive neuro-
fuzzy controller successfully self-organizes to improve
the dynamic response of the system under consideration.
Also a real-time control of a direct drive motor is
implemented using a digital signal processor chip and a
486 PC. The result show real-time adaptation in the
control architecture. The work has also created,
software environment called Dynamic-Fuzzy$spcopyright$
for self-modification of controller's structure once it
has been designed. Other software for multi-layer
perception neural network and real time interface have
also been developed.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  2813 </NUMBER>
<ORDER>   AAG9735791 </ORDER>
<TITLE> ACQUISITION OF HISTORICAL KNOWLEDGE FROM ENCYCLOPEDIC TEXTS  </TITLE>
<AUTHOR> HULL, RICHARD DOUGLAS </AUTHOR>
<YEAR> 1997 </YEAR>
<INSTITUTION> UNIVERSITY OF CENTRAL FLORIDA; 0705 </INSTITUTION>
<DESCRIPTORS> COMPUTER SCIENCE; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> FERNANDO GOMEZ </ADVISER>
<CLASSIFICATIONS> KNOWLEDGE ACQUISITION, ARTIFICIAL INTELLIGENCE </CLASSIFICATIONS>
<ABSTRACT>
Automatic acquisition of historical knowledge from
encyclopedic texts involves addressing three issues in
the field of artificial intelligence: natural language
understanding, knowledge representation, and knowledge
acquisition. Semantic interpretation, a component of
natural language understanding, is responsible for the
construction of logical forms from syntactic relations
produced by the parser. Nominalized verbs, or
nominalizations, contribute the same knowledge as their
verbal counterparts, and behave like their verbal forms
in that they license prepositional phrases. The
nominalizations found in these texts are often
ambiguous. Unlike previous treatments of nominalizations
which skirted the ambiguity issue, the problems of
choosing between the verbal and non-verbal senses of
nominalizations and handling the polysemy of the
nominalized verb were addressed head on.
Another key principle for semantic interpretation is the
the creation of verbal knowledge, in the form of verb
meaning (VM) rules and verbal concepts. Both of these
constructs require a hierarchy of concepts to specify
selectional restrictions. Over 220 new VM rules and 140
new verbal concepts were written, covering a wide range
of relations. Testing of the system with this verbal
knowledge and its supporting ontology showed that the
correct sense of the verb and the correct attachment and
meaning for prepositional phrases were determined more
than 90% of the time.
An investigation into how to recognize semantic
connections between sentences and how to use those
connections to acquire implicit knowledge was performed.
Temporal connections are particularly important because
they provide a foundation for acquiring other, more
challenging relations such as causal connections.
Representations of temporal and causal relations are
presented along with methods for automatically acquiring
them.
These algorithms were tested on articles of the
electronic version of the World Book Encyclopedia. An
application was created which accepts questions about
historical figures and using knowledge acquired from
encyclopedic articles, answers them. This application,
called SNOWY-BIOS, was tested on ninety-one different
English questions. The answers produced by the system
were compared against answers produced by two human
subjects using the same version of the encyclopedia.
Recall and precision scores of 54% and 85% respectively
were found when compared against the humans'
performance.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  2814 </NUMBER>
<ORDER>   AAG9735642 </ORDER>
<TITLE> APPLICATIONS OF EVOLUTIONARY ALGORITHMS IN MECHANICAL ENGINEERING  </TITLE>
<AUTHOR> NELSON, KEVIN M. </AUTHOR>
<YEAR> 1997 </YEAR>
<INSTITUTION> FLORIDA ATLANTIC UNIVERSITY; 0119 </INSTITUTION>
<DESCRIPTORS> ENGINEERING, MECHANICAL; COMPUTER SCIENCE; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> MING HUANG </ADVISER>
<CLASSIFICATIONS> GLOBAL OPTIMIZATION, ARTIFICIAL INTELLIGENCE </CLASSIFICATIONS>
<ABSTRACT>
Many complex engineering designs have conflicting
requirements that must be compromised to effect a
successful product. Traditionally, the engineering
approach breaks up the complex problem into smaller sub-
components in known areas of study. Tradeoffs occur
between the conflicting requirements and a sub-optimal
design results. A new computational approach based on
the evolutionary processes observed in nature is
explored in this dissertation. Evolutionary algorithms
provide methods to solve complex engineering problems by
optimizing the entire system, rather than sub-components
of the system. Three standard forms of evolutionary
algorithms have been developed: evolutionary
programming, genetic algorithms and evolution
strategies. Mathematical and algorithmic details are
described for each of these methods. In this
dissertation, four engineering problems are explored
using evolutionary programming and genetic algorithms.
Exploiting the inherently parallel nature of evolution,
a parallel version of evolutionary programming is
developed and implemented on the MasPar MP-1. This
parallel version is compared to a serial version of the
same algorithm in the solution of a trial set of
unimodal and multi-modal functions. The parallel version
had significantly improved performance over the serial
version of evolutionary programming. An evolutionary
programming algorithm is developed for the solution of
electronic part placement problems with different
assembly devices. The results are compared with
previously published results for genetic algorithms and
show that evolutionary programming can successfully
solve this class of problem using fewer genetic
operators. The finite element problem is cast into an
optimization problem and an evolutionary programming
algorithm is developed to solve 2-D truss problems. A
comparison to LU-decomposition showed that evolutionary
programming can solve these problems and that it has the
capability to solve the more complex nonlinear problems.
Finally, ordinary differential equations are discretized
using finite difference representation and an objective
function is formulated for the application of
evolutionary programming and genetic algorithms.
Evolutionary programming and genetic algorithms have the
benefit of permitting over-constraining a problem to
obtain a successful solution. In all of these
engineering problems, evolutionary algorithms have been
shown to offer a new solution method.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  2815 </NUMBER>
<ORDER>   AAG9735453 </ORDER>
<TITLE> TAXONOMIC INFORMATION RETRIEVAL </TITLE>
<AUTHOR> SCIME, ANTHONY </AUTHOR>
<YEAR> 1997 </YEAR>
<INSTITUTION> GEORGE MASON UNIVERSITY; 0883 </INSTITUTION>
<DESCRIPTORS> COMPUTER SCIENCE; INFORMATION SCIENCE; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> LARRY KERSCHBERG </ADVISER>
<CLASSIFICATIONS> TAXIR </CLASSIFICATIONS>
<ABSTRACT>
The purpose of this research is to establish a
methodology for selecting the best solution from
available candidates. Currently, the Internet and the
World Wide Web provide a laboratory for this research.
The Web also allows access to a great deal of
information about a vast array of subjects. A user can
begin a search for information by selecting a Web page
and following the embedded links from page to page
looking for clues to the desired information. An
alternative method is to use one of the Web-based search
engines to select the Web pages that refer to the
general subject of the information desired. In either
case, a vast amount of information is retrieved. The
quantity can be overwhelming, and much of the
information may be irrelevant to the user's needs.
We present a methodology for query construction and
results analysis that provides the user with a ranking
of choices based on the user's determination of
importance. The query is initially designed by the user
with assistance from the user's profile, a thesaurus,
and previously constructed queries as a taxonomy of the
information need. After the query has returned its
results, decision analytic methods and information
source reliability knowledge are used on the expanded
taxonomy to rank the solution candidates.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  2816 </NUMBER>
<ORDER>   AAG9735259 </ORDER>
<TITLE> ARTIFICIAL NEURAL NETWORKS AS A NOVEL APPROACH TO PHARMACOKINETICS  </TITLE>
<AUTHOR> GOBBURU, JOGARAO V. S. </AUTHOR>
<YEAR> 1997 </YEAR>
<INSTITUTION> NORTH DAKOTA STATE UNIVERSITY OF AGRICULTURE AND APPLIED SCIENCE; 0157 </INSTITUTION>
<DESCRIPTORS> HEALTH SCIENCES, PHARMACOLOGY; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> WILLIAM H. SHELVER </ADVISER>
<CLASSIFICATIONS> ARTIFICIAL INTELLIGENCE </CLASSIFICATIONS>
<ABSTRACT>
The present study demonstrates the application of
artificial neural networks to drug design and
development. Neural networks were developed to predict
the pharmacokinetic parameters of beta-adrenoreceptor
antagonists in humans. A congeneric series of 10 beta
blockers, whose critical pharmacokinetic parameters are
well established, was selected for the study. An
appropriate neural network system was constructed and
tested for its ability to predict the pharmacokinetic
parameters from the octanol/water partition coefficient,
the pKa, and/or the fraction drug bound to plasma
proteins. Neural networks successfully trained and the
predicted pharmacokinetic values agreed well with the
experimental values (average difference = 8%). The
neural network predicted values showed better agreement
with the experimental values than those predicted by
multiple linear regression (average difference = 47%).
The leave-one-out method verified the generalization of
the networks by demonstrating that any of the compounds
could be deleted from the training set and its value
correctly predicted by the new network (average error =
19%). The second test involved the prediction of
pharmacokinetic properties of compounds never seen by
the network, and reasonable results were obtained for
three out of four compounds tested. The results indicate
neural networks can be a powerful tool in exploration of
quantitative structure-pharmacokinetic relationships.
Neural networks not being prone to the stringent
assumptions of classical pharmacokinetic analyses are a
reliable technique to define the time course of drug
molecules in the body. The study also demonstrated the
ability of neural networks to emulate drug concentration-
time profiles derived from either linear or non-linear
kinetic behavior. Various conditions like variable
transformation, scaling of the data, and network
connectivity that could affect the performance of neural
networks were investigated. Robustness toward initial
estimates of the weights of the connections and toward
noise in the data was also assessed. Although neural
networks are not replacements to phenomena based
approaches in pharmacokinetics, certainly they are a
flexible technique with pragmatic potential.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  2817 </NUMBER>
<ORDER>   AAG9736480 </ORDER>
<TITLE> THE RESOLUTION OF AMBIGUITY IN ENGLISH LANGUAGE EPISODES THROUGH THE ACHIEVEMENT OF A MINIMUM GLOBAL ENERGY STATE IN A BOLTZMANN MACHINE NEURAL NETWORK ARCHITECTURE </TITLE>
<AUTHOR> ZIGH, TERESA STEPHANIE </AUTHOR>
<YEAR> 1997 </YEAR>
<INSTITUTION> STEVENS INSTITUTE OF TECHNOLOGY; 0733 </INSTITUTION>
<DESCRIPTORS> LANGUAGE, LINGUISTICS; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> M. PETER JURKAT </ADVISER>
<CLASSIFICATIONS> NIL </CLASSIFICATIONS>
<ABSTRACT>
A proposed methodology using neural networks for the
resolution of ambiguity in episodes (multi-sentence
texts telling a story) is presented. Stories are
characterized by a higher level of organization than
that which occurs in strings of sentences. A story's
structure also consists of more than an ordinary
pairwise relationship among sentences. Backpropagation,
recirculation, the Hopfield memory model and the
Boltzmann machine neural network architectures are
examined with learning schedules of 500 to 1000 using
two-, three- and four-sentence texts. The models are
trained using a set of forty episodes with a vocabulary
of over 500 words. When the network performances (global
energy function value at equilibrium) are compared, the
Boltzmann machine neural network reached lower energy
levels than the three other network architectures. The
investigation of four distinct architectures on the same
corpus of ambiguous episodes has not been made
previously. Existing studies have investigated ambiguous
sentences, but not ambiguous stories; and their stories
have been associated with well-defined scripts or plans.
Comparisons of each network's effectiveness was made and
correlation of global energy reduction to ambiguity
reduction was seen. The Boltzmann machine was found to
provide the highest rate of ambiguity resolution in
episodes, with a 20%-35% greater accuracy than the
backpropagation model, the Hopfield memory model and the
recirculation model.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  2818 </NUMBER>
<ORDER>   AAG9736464 </ORDER>
<TITLE> INTEGRATING FUZZY HASSE DIAGRAM WITH MULTISTRATEGY LEARNING FOR STUDENT MODELING IN INTELLIGENT TUTORING SYSTEMS </TITLE>
<AUTHOR> HUANG, MU-JUNG </AUTHOR>
<YEAR> 1997 </YEAR>
<INSTITUTION> STEVENS INSTITUTE OF TECHNOLOGY; 0733 </INSTITUTION>
<DESCRIPTORS> BUSINESS ADMINISTRATION, MANAGEMENT; INFORMATION SCIENCE; COMPUTER SCIENCE; EDUCATION, TECHNOLOGY; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> M. PETER JURKAT </ADVISER>
<CLASSIFICATIONS> NIL </CLASSIFICATIONS>
<ABSTRACT>
This research makes an attempt to provide an extending
current student modeling method for Intelligent Tutoring
Systems (ITSs). When a student is learning a subject
with an ITS, the interaction between the student and the
system are characterized by several fundamental
features: dynamic interaction, incompleteness,
ambiguity, and inconsistency. These features are still
difficult tasks for current student models to deal with.
In addition to combining the bug library and the overlay
strategies, this research also incorporates fuzzy
theories, classification tree concepts, Hasse diagrams,
and layered structure to develop a nonmonotonic student
modeling method. The theories of fuzzy sets are
developed to model imprecision of the real world. By
extending the classification tree concepts, the system
can compute the score of partial correctness for a more
accurate student model and identify the student's
misconceptions. The Hasse Diagram can be used to present
the dynamic feature and to reason for overcoming the
problem of incompleteness.
This research describes not only a method to deal with
the student's inconsistent behaviors, but also tries to
build a blackboard multistrategy learning model for
preventing the student's inconsistent behaviors. That
means this research concentrates on resolving the
contradictions before or as they happen. Integrated with
Object-Oriented approaches and blackboard techniques,
this research uses multistrategy learning techniques to
identify the student's inconsistent behaviors and then
to induce and learn the properties of the student's
inconsistent behaviors. According to the properties of
the student's inconsistent behaviors, the ITS may then
take appropriate strategies to prevent the happening of
the student's inconsistent behaviors.
As a proof of prototype, this research uses C++ to build
a prototype of a Fuzzy Hasse Diagram for testing the
functions of dealing with dynamic interaction,
incompleteness, ambiguity, and inconsistency. This
research also employs decision table techniques to
assist the validation of the models.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  2819 </NUMBER>
<ORDER>   AAG9735054 </ORDER>
<TITLE> A STUDY OF THE WELL-FOUNDED AND STABLE LOGIC PROGRAMMING SEMANTICS  </TITLE>
<AUTHOR> SEITZER, JENNIFER </AUTHOR>
<YEAR> 1997 </YEAR>
<INSTITUTION> UNIVERSITY OF CINCINNATI; 0045 </INSTITUTION>
<DESCRIPTORS> COMPUTER SCIENCE; MATHEMATICS </DESCRIPTORS>
<ADVISER> JOHN S. SCHLIPF </ADVISER>
<CLASSIFICATIONS> NP-COMPLETENESS </CLASSIFICATIONS>
<ABSTRACT>
Logic programming semantics produce the sets of all
logically deducible propositions from a set of logic
formulas called a logic program. The stable and the well-
founded semantics give meaning to logic programs
containing rules with negative hypotheses such as "the
specimen is not a mammal". Computation of these
semantics in the propositional case is (worst case)
exponential and quadratic, respectively.
This doctoral dissertation presents a multi-faceted
pursuit involving these semantics. These facets include
results from complexity theory, graph theory, and
machine learning. Some of the important results are: (1)
the computation of the stable semantics in linear time
for five newly discovered classes of normal logic
programs, (2) the computation of the well-founded
semantics in linear time for uni-rule programs, another
newly discovered class of logic programs, (3) the NP-
completeness proof of existence of stable models for uni-
rule programs, (4) the application of the well-founded
and stable semantics to a related subdiscipline of
artificial intelligence, inductive logic programming.
Limiting the number of times a variable appears in
either the head or the body of a rule, we identify five
classes of normal propositional logic programs. These
classes have the desirable property that stable models,
if they exist, can be found in linear time (worst case).
This work is presented in Chapters 4 and 5. In Chapter 6
we identify a related class containing programs for
which the well-founded model can be acquired in linear
time, yet for which computing the stable model(s)
remains NP-complete. We show in Chapter 7 how, by
relaxing one constraint of this class, previously linear
complexity is increased to intractability. In Chapter 8,
two new classes of unit programs, and another class of
uni-rule programs (different from the class presented in
Chapter 4) are found. It is then proved that these, too,
have the property of linear time determination of stable
models.
In Chapter 9 we introduce stable ILP, a cross-
disciplinary concept straddling machine learning and
nonmonotonic reasoning. It is here that we apply stable
and well-founded models to real world applications. In
Chapter 10 we present a description of the author's
implementation of stable-ILP in system INDED.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  2820 </NUMBER>
<ORDER>   AAG9734920 </ORDER>
<TITLE> APPLICATION OF ARTIFICIAL INTELLIGENCE </TITLE>
<AUTHOR> KRISHNAN, GOVINDARAJAPURAM SUBRAMANIAM </AUTHOR>
<YEAR> 1997 </YEAR>
<INSTITUTION> THE GEORGE WASHINGTON UNIVERSITY; 0075 </INSTITUTION>
<DESCRIPTORS> COMPUTER SCIENCE; ENGINEERING, ELECTRONICS AND ELECTRICAL; ENGINEERING, AEROSPACE; ENGINEERING, SYSTEM SCIENCE </DESCRIPTORS>
<ADVISER> JOHN R. HARRALD; THOMAS ANDREW MAZZUCHI; HENNING W. LEIDECKER </ADVISER>
<CLASSIFICATIONS> AI </CLASSIFICATIONS>
<ABSTRACT>
The National Aeronautics & Space Administration (NASA),
the European Space Agency (ESA), and the Canadian Space
Agency (CSA) missions involve the performance of
scientific experiments in Space. Instruments used in
such experiments are fabricated using electronic parts
such as microcircuits, inductors, capacitors, diodes,
transistors, etc.
For instruments to perform reliably the selection of
commercial parts must be monitored and strictly
controlled. The process used to achieve this goal is by
a manual review and approval of every part used to build
the instrument. The present system to select and approve
parts for space applications is manual, inefficient,
inconsistent, slow and tedious, and very costly. In this
dissertation a computer based decision support model is
developed for implementing this process using artificial
intelligence concepts based on the current information
(expert sources). Such a model would result in a greater
consistency, accuracy, and timeliness of evaluation.
This study presents the methodology of development and
features of the model, and the analysis of the data
pertaining to the performance of the model in the field.
The model was evaluated for three different part types
by experts from three different space agencies. The
results show that the model was more consistent than the
manual evaluation for all part types considered. The
study concludes with the cost and benefits analysis of
implementing the models and shows that implementation of
the model will result in significant cost savings. Other
implementation details are highlighted.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  2821 </NUMBER>
<ORDER>   AAG9734534 </ORDER>
<TITLE> A GENERIC SUM OF PRODUCTS PARALLEL PROCESSOR FOR NEURAL NETWORKS AND DIGITAL SIGNAL PROCESSING </TITLE>
<AUTHOR> AIKENS, VALENTINE ST CHRISTOPHER, II </AUTHOR>
<YEAR> 1997 </YEAR>
<INSTITUTION> STATE UNIVERSITY OF NEW YORK AT BINGHAMTON; 0792 </INSTITUTION>
<DESCRIPTORS> ENGINEERING, ELECTRONICS AND ELECTRICAL; COMPUTER SCIENCE; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> NIL </ADVISER>
<CLASSIFICATIONS> NIL </CLASSIFICATIONS>
<ABSTRACT>
In this dissertation a processor which targets
algorithms using, as the core operation, the sum of
products calculation is introduced and evaluated. The
programmable parallel pipelined processor provides
extremely good performance and flexibility and requires
a small amount of hardware.
There are classes of algorithms and applications that
when implemented on general purpose uniprocessors result
in poor performance. One class in particular contains
algorithms which use, as the core operation, the sum of
products calculation. These algorithms are typically
applied to large sets of data. Areas in this class
include artificial neural networks (ANN) learning
algorithms for ANNs, and digital signal processing
(DSP).
A set of computational, communication, and storage
requirements for general learning in ANNs and digital
signal processing have been identified. A number of
diverse algorithms for learning in ANNs and DSP are then
programmed using the generic sum of products processor
(GSPP) to show the flexibility of this processor. The
processor performance for these algorithms has been
evaluated using a novel evaluation approach as well as a
simulator of the machine.
Applications such as NETtalk for ANN learning and 1-K
discrete Fourier transform (DFT) for digital signal
processing are used as benchmarks. These benchmarks have
been used to compare the performance of the proposed
GSPP to a number of other machines. GSPP performs
extremely well when compared to other processors that
require significantly more hardware.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  2822 </NUMBER>
<ORDER>   AAIMM99478 </ORDER>
<TITLE> POWER SYSTEM STABILIZER DESIGN USING FUZZY LOGIC </TITLE>
<AUTHOR> SANAYE-PASAND, MAJID </AUTHOR>
<YEAR> 1994 </YEAR>
<INSTITUTION> UNIVERSITY OF CALGARY (CANADA); 0026 </INSTITUTION>
<DESCRIPTORS> ENGINEERING, ELECTRONICS AND ELECTRICAL; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> O. P. MULIK </ADVISER>
<CLASSIFICATIONS> NIL </CLASSIFICATIONS>
<ABSTRACT>
Power system stabilizers are responsible for maintaining
power system stability and improving dynamic
performance. A power system stabilizer based on the
fuzzy logic control method is proposed and designed in
this thesis. The design procedure is described and the
Fuzzy Power System Stabilizer (FPSS) results are
compared to those of a conventional stabilizer.
Using a single-machine infinite-bus power system model,
simulation studies are performed. To evaluate the
performance of the FPSS, a variety of disturbances are
applied to the system and results with both stabilizers
are compared. The simulation studies show that the fuzzy
stabilizer provides better performance than that of the
conventional stabilizer over a wide range of operating
conditions.
A new method of constructing automatically the rule
table for fuzzy logic controllers is proposed. This new
method is employed to design a New Fuzzy PSS (NFPSS) and
the performance of the NFPSS is compared to that of the
previous fuzzy stabilizer which uses the conventional
rule table.
An Intel single board computer, iSBC386/21, is used to
implement the proposed FPSS and the FPSS behavior is
investigated on a physical power system model in the
power research laboratory at the University of Calgary.
Experimental tests and results are discussed.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  2823 </NUMBER>
<ORDER>   AAG9734528 </ORDER>
<TITLE> EVIDENCE SETS AND CONTEXTUAL GENETIC ALGORITHMS: EXPLORING UNCERTAINTY, CONTEXT, AND EMBODIMENT IN COGNITIVE AND BIOLOGICAL SYSTEMS  </TITLE>
<AUTHOR> ROCHA, LUIS MATEUS </AUTHOR>
<YEAR> 1997 </YEAR>
<INSTITUTION> STATE UNIVERSITY OF NEW YORK AT BINGHAMTON; 0792 </INSTITUTION>
<DESCRIPTORS> ENGINEERING, SYSTEM SCIENCE; COMPUTER SCIENCE; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> NIL </ADVISER>
<CLASSIFICATIONS> ARTIFICIAL INTELLIGENCE </CLASSIFICATIONS>
<ABSTRACT>
This dissertation proposes a systems-theoretic framework
to model biological and cognitive systems which requires
both self-organizing and symbolic dimensions. The
framework is based on an inclusive interpretation of
semiotics as a conceptual theory used for the simulation
of complex systems capable of representing, as well as
evolving in their environments, with implications for
Artificial Intelligence and Artificial Life. This
evolving semiotics is referred to as Selected Self-
Organization when applied to biological systems, and
Evolutionary Constructivism when applied to cognitive
systems. Several formal avenues are pursued to define
tools necessary to build models under this framework.
In the Artificial Intelligence camp, Zadeh's Fuzzy Sets
are extended with the Dempster-Shafer Theory of Evidence
into a new mathematical structure called Evidence Sets,
which can capture more efficiently all recognized forms
of uncertainty in a formalism that explicitly models the
subjective context dependencies of linguistic
categories. A belief-based theory of Approximate
Reasoning is proposed for these structures, as well as
new insights as to the measurement of uncertainty in
nondiscrete domains. Evidence sets are then used in the
development of a relational database architecture useful
for the data mining of information stored in several
networked databases. This useful data mining application
is an example of the semiotic framework put into
practice and establishes an Artificial Intelligence
model of Cognitive Categorization with a hybrid
architecture that possesses both connectionist and
symbolic attributes.
In the Artificial Life camp, Holland's Genetic
Algorithms are extended to a new formalism called
Contextual Genetic Algorithms which introduces nonlinear
relationships between genetic descriptions and solutions
for a particular problem. The nonlinear relationship is
defined by an indirect scheme based on Fuzzy Sets which
implements the simulation of dynamic development after
genetic transcription. Genetic descriptions encode
dynamic building blocks that self-organize into
solutions. Since the self-organizing process may depend
on environmental information, the process is thus
contextualized. The main advantage of this scheme is the
ability to reduce dramatically the information
requirements of genetic descriptions, it also allows the
transformation of real-encoded to binary-encoded
problems. The scheme is used successfully to evolve
Neural Network architectures as well as Cellular
Automata rules for non-trivial tasks. It is also used to
model the biological process of RNA Editing. Contextual
Genetic Algorithms are an instance of the semiotic
framework proposed and of Selected Self-Organization in
particular.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  2824 </NUMBER>
<ORDER>   AAG9734401 </ORDER>
<TITLE> ROBUST DESIGN OPTIMIZATION WITH APPLICATIONS TO COMPOSITE-MATERIAL STRUCTURES </TITLE>
<AUTHOR> MAKKAPATI, SATHEESH </AUTHOR>
<YEAR> 1997 </YEAR>
<INSTITUTION> WEST VIRGINIA UNIVERSITY; 0256 </INSTITUTION>
<DESCRIPTORS> ENGINEERING, MECHANICAL; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> EVER BARBERO </ADVISER>
<CLASSIFICATIONS> TAGUCHI DESIGNS, NEURAL NETWORKS </CLASSIFICATIONS>
<ABSTRACT>
The problem of robust design and optimization for
designs with varying operating conditions is considered
in this work. A robust design optimization tool (RDOT)
has been developed in this work. The tool is constructed
with building blocks: an Artificial Neural Network, a
Response Evaluator (e.g., FEA, etc.), an Optimizer based
on Quadratic Programming, Cooperative Game Theory,
Design of Experiments, and Taguchi Methods. The tool is
fully codified into a computer program, and it demands
very little designer insight into the problem under
consideration.
Design optimization is necessary to efficiently
accomplish a design that, while satisfying the desired
functionality, also uses minimum amount of resources.
Robust design optimization (RDO) is designing such a
product to exhibit insensitivity to the variations in
the operating conditions. The objective of RDOT is to
help the designer identify the settings of the design
variables that result in a robust product. The current
optimization methodology has been illustrated with
composite material structures to highlight the
advantages of RDOT. These structures do not possess a
closed form solution for the responses (e.g.,
deflection, strength, etc.) and changes in the design
variables and operating conditions often produce
conflicting changes in the responses. The utility of
RDOT has been verified with the help of several
examples. RDOT also deals with problems whose response
surfaces are non-convex. The tool can be used in a
generic engineering design problem whose response
evaluation is either too expensive to compute
analytically/numerically, or can only be evaluated
experimentally.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  2825 </NUMBER>
<ORDER>   AAG9734398 </ORDER>
<TITLE> AN APPROACH TO NONLINEAR SYSTEM IDENTIFICATION AND CONTROL  </TITLE>
<AUTHOR> HWANG, HOKYUNG </AUTHOR>
<YEAR> 1997 </YEAR>
<INSTITUTION> WEST VIRGINIA UNIVERSITY; 0256 </INSTITUTION>
<DESCRIPTORS> ENGINEERING, SYSTEM SCIENCE; ENGINEERING, ELECTRONICS AND ELECTRICAL; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> PARVIZ FAMOURI </ADVISER>
<CLASSIFICATIONS> NEURAL NETWORKS, FEEDBACK LINEARIZATION </CLASSIFICATIONS>
<ABSTRACT>
In this research, an integrated method of system
identification and control via neural networks and
feedback linearization theories was developed. Two
different approaches (network and mathematical) are
integrated to identify and control nonlinear dynamic
systems. The neural network is used as a nonlinear
system identifier to extract system equations/parameters
with assistance from mathematical concepts such as multi-
dimensional curve fitting techniques. Nonlinear feedback
controller design based on differential geometry and
linear state feedback control theories are then used to
design a controller for the identified system.
This approach has been investigated on an academic
problem, a brushless dc motor, Chua's chaotic circuit,
and a dc series motor. The algorithm was successfully
tested on a dc series motor in a laboratory setting.
Generally, the applicability of this methodology can be
extended to a class of dynamic systems that can be
described by a set of nonlinear ordinary differential
equations in a form of $underline0dot x =
f(underline0x,underline0u$), for which measurements
sufficient to identify them are available.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  2826 </NUMBER>
<ORDER>   AAG9733971 </ORDER>
<TITLE> MULTISCALE ATTENTION AS A GLOBALLY CONVERGENT FRAMEWORK FOR LARGE SCALE NONLINEAR OPTIMIZATION </TITLE>
<AUTHOR> TSIOUTSIAS, DIMITRIS IOANNIS </AUTHOR>
<YEAR> 1997 </YEAR>
<INSTITUTION> YALE UNIVERSITY; 0265 </INSTITUTION>
<DESCRIPTORS> COMPUTER SCIENCE; ENGINEERING, ELECTRONICS AND ELECTRICAL; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> ERIC MJOLSNESS </ADVISER>
<CLASSIFICATIONS> NEURAL NETWORKS </CLASSIFICATIONS>
<ABSTRACT>
The optimization of objective functions has long been
one of the important and interesting problems in the
modeling, simulation and verification of many physical
processes. However, practical instances of most problems
(e.g. in the areas of computer vision, VLSI circuit
design, operations research, etc.), often involve large-
scale nonlinear, nonconvex objective functions making
the derivation of efficient techniques a challenging
(and sometimes an impossible) effort.
This dissertation addresses the task of how to
consistently and computationally efficiently solve
problems governed by a class of objective functions
associated with relaxation-based neural networks. We
introduce a novel optimization framework involving a
combination of techniques: deterministic annealing,
clocked objectives, multiscale optimization, attention
mechanisms, trust region optimization, and a pre-
conditioned conjugate-gradient method.
The optimization framework is applied to representative
objective functions from two research areas: computer
vision and combinatorial optimization. The first problem
is the 2D image segmentation problem, and the second the
graph multi-partitioning problem. Large-scale objective
function formulations of these problems are being
solved, of $O(10sp4)$ to nearly $O(10sp6)$ size for the
former problem, and up to $O(10sp4)$ size for the
latter. Finally, the relaxation dynamics for partitioned
neural networks is examined, which allows us to map the
2D image estimation and segmentation objective function
onto a parallel computing environment, and to model the
slower inter-module communication channels by means of
certain fixed-point-preserving algebraic
transformations.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  2827 </NUMBER>
<ORDER>   AAG9733936 </ORDER>
<TITLE> NONLINEAR ARMA MODELS AND THE GENERAL TRACKING PROBLEM FOR DISCRETE-TIME DYNAMICAL SYSTEMS </TITLE>
<AUTHOR> CABRERA, JOAO B.D. </AUTHOR>
<YEAR> 1997 </YEAR>
<INSTITUTION> YALE UNIVERSITY; 0265 </INSTITUTION>
<DESCRIPTORS> ENGINEERING, ELECTRONICS AND ELECTRICAL; ENGINEERING, SYSTEM SCIENCE; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> KUMPATI S. NARENDRA </ADVISER>
<CLASSIFICATIONS> CONTROL SYSTEMS, NEURAL NETWORKS </CLASSIFICATIONS>
<ABSTRACT>
Starting in the late 1980s artificial neural networks
have been employed extensively for the identification
and control of complex nonlinear systems using
input/output data. Central to most applications of
neural networks in control is the nonlinear ARMA model,
a representation in which the output of the system is
expressed as a nonlinear function of a finite number of
past values of inputs and outputs. Identification using
neural networks consists of training a neural network to
approximate the nonlinear ARMA model using input-output
data collected from the system. Once this is
accomplished, a second neural network is trained to
approximate a controller. This controller is supposed to
be given as a function of past values of inputs and
outputs, and also as a function of the reference
trajectory to be followed.
This thesis examines this two-step procedure from the
point view of control systems theory. For nonlinear
discrete-time systems admitting a state space
representation of a given order, sufficient conditions
are derived for the existence of a nonlinear ARMA model
in the neighborhood of an equilibrium state. The order,
the relative degree, and the zero dynamics of both
representations are related through the normal form
state space representation.
The general tracking problem for discrete-time systems
is stated as the mathematical formalization for the
second step of neurocontrol design: to determine a
feedback control with bounded inputs capable of forcing
the output of the system to follow an arbitrary
reference trajectory asymptotically. Under very general
conditions on the admissible control laws, it is
demonstrated that this problem can be solved if and only
if the system has a well-defined relative degree and an
asymptotically stable zero dynamics. The relationship
between a system's state space representation and its
nonlinear ARMA model discussed earlier is used to
express the conditions for solvability of the general
tracking problem solely in terms of the nonlinear ARMA
model.
Various related problems are examined, including the
possibility of effecting exact tracking in a finite
number of steps, the problem of set-point regulation,
the problem of following a periodic trajectory, and the
problem of decoupling using state feedback in the case
of nonlinear multivariable systems. The normal form is
used to derive a more parsimonious input-output
representation for multivariable systems, making use of
information concerning the system's vector relative
degree.
Numerical simulations are presented, examining the
relevance of the results on this thesis for the practice
of neurocontrol.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  2828 </NUMBER>
<ORDER>   AAG9733570 </ORDER>
<TITLE> INTEGRATING HUMAN-COMPUTER INTERACTION WITH PLANNING FOR A TELEROBOTIC SYSTEM </TITLE>
<AUTHOR> KAZI, ZUNAID HAMID </AUTHOR>
<YEAR> 1997 </YEAR>
<INSTITUTION> UNIVERSITY OF DELAWARE; 0060 </INSTITUTION>
<DESCRIPTORS> COMPUTER SCIENCE; ENGINEERING, ELECTRONICS AND ELECTRICAL </DESCRIPTORS>
<ADVISER> DANIEL CHESTER </ADVISER>
<CLASSIFICATIONS> TIME DELAY, LEARNING </CLASSIFICATIONS>
<ABSTRACT>
Many real-world unstructured tasks, such as manipulation
of hazardous materials, space and under-sea exploration,
and assistive technology for people with disabilities
require human control of telerobots. However, existing
interface strategies for telemanipulation under
circumstances where direct physical control is limited
due to time delay, lack of sensation, and coordination
have been generally ineffective. This dissertation
addresses the need for a new telemanipulation technique
that reduces the requirements of highly coordinated
physical control, but does not call upon capabilities
for autonomous operation that exceed the current state
of the art in Artificial Intelligence, machine vision
and robotics.
This dissertation demonstrates that by combining current
state of the art in natural language processing,
robotics, computer vision, planning, machine learning,
and human-computer interaction, building a practical
telemanipulative robot without having to solve the major
problems in each of these fields is possible.
Difficulties involving full text understanding,
autonomous robot-arm control, real-time object
recognition in an unconstrained environment, planning
for all contingencies and levels of problem difficulty,
speedy supervised and unsupervised learning, and
intelligent human-computer interfaces, illustrate but
some of the open issues. Current solutions to each of
these problems, when combined with each other and with
the intelligence of the user, can compensate for the
inadequacies that each solution has individually.
We claim that the symbiosis of the high level cognitive
abilities of the human, such as object recognition, high
level planning, and event driven reactivity, with the
native skills of a robot can result in a human-robot
system that will function better than both traditional
robotic assistive systems and current autonomous
systems. We describe a system that can exploit the low-
level machine perceptual and motor skills and excellent
AI planning tools that are currently achievable, while
allowing the user to concentrate on handling the
problems that they are best suited for, namely high-
level problem solving, object recognition, error
handling and error recovery. By doing so, the cognitive
load on the user is decreased, the system becomes more
flexible and less fatiguing, and is ultimately a more
effective assistant.
A general-purpose telerobotic manipulation aid for
people with disabilities was chosen as a test-bed to
test the validity of the core ideas of this
dissertation. This offers a domain where the physical
control of the potential user is less than optimal, and
the environment involves known tasks and objects which
are used in an inherently unstructured manner. A system,
MUSIIC--Multimodal User Supervised Interface and
Intelligent Control, was designed and built that uses
knowledge-driven planning integrated with a multimodal
(speech and gesture) human-machine interface to operate
an assistive robot.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  2829 </NUMBER>
<ORDER>   AAG9733037 </ORDER>
<TITLE> EFFICIENT PRODUCTION SYSTEM MATCH AND CONSTRAINT SATISFACTION PROBLEM SOLVING </TITLE>
<AUTHOR> CHO, BONGHAN </AUTHOR>
<YEAR> 1997 </YEAR>
<INSTITUTION> UNIVERSITY OF SOUTHERN CALIFORNIA; 0208 </INSTITUTION>
<DESCRIPTORS> COMPUTER SCIENCE; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> NIL </ADVISER>
<CLASSIFICATIONS> COMBINATORICS, ARTIFICIAL INTELLIGENCE </CLASSIFICATIONS>
<ABSTRACT>
Combinatorics has been a problem in building efficient
Artificial Intelligence (AI) systems. While production
systems and Constraint Satisfaction Problems (CSP)
provide a useful structure for such AI systems,
combinatoric production match process or CSPs are
problematic in situations requiring real-time
performance or scaling up. The goal of this thesis is to
alleviate the combinatorics from both areas without
sacrificing their functionality. We examine the causes
of the combinatorics by constructing a generalized
search model based on an analysis of the commonality
between production match and CSP solving, revealing that
a significant amount of the search space explored by
conventional production match algorithms or CSP
techniques is redundant. We develop domain-independent
techniques which eliminate the major causes of the
redundancy. ERMA and EDCON, the newly developed
algorithms for production match and CSP, respectively,
demonstrate orders of magnitude speedup over the
existing state-of-the-art Rete match algorithm and
highly optimized CSP solving algorithms, respectively.
In addition to regular CSPs, EDCON efficiently solve
CSPs that allow dynamic changes or need to find all
solutions.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  2830 </NUMBER>
<ORDER>   AAG9732548 </ORDER>
<TITLE> VISION-BASED PLACE RECOGNITION FOR MOBILE ROBOTS </TITLE>
<AUTHOR> YEH, ERLIANG </AUTHOR>
<YEAR> 1997 </YEAR>
<INSTITUTION> YALE UNIVERSITY; 0265 </INSTITUTION>
<DESCRIPTORS> ENGINEERING, ELECTRONICS AND ELECTRICAL; COMPUTER SCIENCE; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> NIL </ADVISER>
<CLASSIFICATIONS> PATTERN RECOGNITION, ARTIFICIAL INTELLIGENCE, COMPUTER VISION </CLASSIFICATIONS>
<ABSTRACT>
In this thesis, methods for representation, recognition,
and prediction of environmental features such as
landmarks and places using monocular image data for
mobile robot navigation are developed. Landmarks are
often used as a basis for mobile robot navigation. We
consider the problem of automatically selecting from a
set of 3D features the subset which is most likely to be
recognized from noisy monocular image data and is least
likely to be confused with any of the other groups of
features. Assuming perspective projection, real valued
recognition functions are constructed for a set of
features. The value returned from such functions are
invariant to changes of viewpoint and can be evaluated
directly from image measurements without prior knowledge
of the position and orientation of the camera. With
image noise, the recognition function no longer
evaluates to a constant value. Because of the
possibility of false matches, a Bayes detector is used
to determine the optimal range of values of the
recognition function that will be accepted. The
collection of features with the lowest Bayes cost is
selected as the most distinguishable landmark. We show
implementation results for real 3D objects.
Central to many mobile robot navigation systems is a
graph-based representation or map of space whose nodes
are places and whose arcs are actions or behaviors that
can be executed to move a robot between places. To
automatically construct such a representation as a robot
explores, it is necessary to recognize when the robot
has revisited a place. Here the notion of place is
extended beyond a neighborhood of a point in space to a
large region (e.g. a room), and a method for place
recognition from a single image is presented. Places are
represented using a set of images of the place, taken
from different viewpoints. An algorithm to automatically
choose the most salient groups of features to model a
place from image data is described. Places are
recognized by establishing correspondences of point and
line segment features through constrained search and
geometric invariants. The constrained motion of a mobile
robot reduces the combinatorics of the matching process,
leading to fast, effective place recognition.
While following a path using vision-based robot
navigation, visual landmarks can be tracked and their
image locations can be used to control robot motion. In
general, tracking algorithms take advantage of the fact
that features only move a short distance between images,
and so only a small area of the image needs to be
searched. During navigation, landmarks must be located
and acquired as they come into view. The ability of the
robot to predict the locations of the landmark features
from image data will reduce the search area and simplify
the tracking process. We discuss methods for direct
image-based prediction of line segment and straight line
features for a mobile system operating on a planar
surface. Preliminary experimental results suggest that
image-based prediction can by performed efficiently and
with sufficient accuracy to ensure robust acquisition of
navigational landmarks. Some issues, improvements and
extensions to the method are discussed for all the
algorithms developed.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  2831 </NUMBER>
<ORDER>   AAG9732392 </ORDER>
<TITLE> DEVELOPMENT OF AN INTELLIGENT CONTROL SYSTEM WITH A HIGH DEGREE OF AUTONOMY AND APPLICATION TO NUCLEAR POWER SYSTEMS  </TITLE>
<AUTHOR> WALTER, PHILLIP B. </AUTHOR>
<YEAR> 1997 </YEAR>
<INSTITUTION> THE PENNSYLVANIA STATE UNIVERSITY; 0176 </INSTITUTION>
<DESCRIPTORS> ENGINEERING, NUCLEAR; OPERATIONS RESEARCH; ENGINEERING, SYSTEM SCIENCE; ARTIFICIAL INTELLIGENCE; ENERGY </DESCRIPTORS>
<ADVISER> ROBERT M. EDWARDS </ADVISER>
<CLASSIFICATIONS> ARTIFICIAL INTELLIGENCE </CLASSIFICATIONS>
<ABSTRACT>
The advances in computer technology, information
processing, and control system theory in the last decade
allow much more sophisticated control systems with
higher degrees of autonomy than previously possible. A
control system with a high degree of autonomy is capable
of maintaining the desired performance under significant
system uncertainty and outside disturbances and can
accommodate system failures over an extended period of
time without external intervention. In most cases, and
especially for complex process systems, the benefits of
these advanced control systems can far outweigh the
additional controller complexity. Control systems with
higher degrees of autonomy can provide increased overall
process system performance due to better optimization of
system interactions, less downtime because of better
fault accommodation, and increased safety by allowing
more human operator response time to anomalous events.
A high autonomy, three level, hierarchical control
system concept is presented that incorporates new
algorithms made possible by the recent advances in
technology. Algorithm development and implementation for
the middle supervision level of the control architecture
is the focus of this research. Well-developed algorithms
that address the fundamental implementation issues
pertaining to supervisory reconfigurable control,
anomalous event handling, and automatic controller
design are the significant contributions of this
research. Simple models of the Penn State Breazeale
Reactor are used to demonstrate the implementation of
the first two levels of the control architecture and to
develop the new supervision level algorithms. The
approach used in this research to achieve the desired
system performance is to describe the outside
disturbances and system faults as system uncertainties,
and subsequently to analyze and partition these
uncertainties. Modern robust control theory and fuzzy
inference approximate reasoning techniques provide
appropriate and compatible methods to produce desired
system performance using these partitioned
uncertainties.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  2832 </NUMBER>
<ORDER>   AAG9731775 </ORDER>
<TITLE> A HYBRID INTELLIGENT SYSTEM FOR PROCESS MODELING AND CONTROL USING A NEURAL NETWORK AND A GENETIC ALGORITHM </TITLE>
<AUTHOR> CHEN, TA-CHENG </AUTHOR>
<YEAR> 1997 </YEAR>
<INSTITUTION> THE UNIVERSITY OF IOWA; 0096 </INSTITUTION>
<DESCRIPTORS> ENGINEERING, INDUSTRIAL; EDUCATION, ADMINISTRATION; HEALTH SCIENCES, PHARMACY; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> GARY W. FISCHER </ADVISER>
<CLASSIFICATIONS> EXPERT SYSTEM </CLASSIFICATIONS>
<ABSTRACT>
A hybrid expert system has been developed for system
modeling and optimization by using a backpropagation
neural network to represent a complex system and a
genetic algorithm to find the optimal control solutions.
The values are self-generated and can used to reset the
system process in order to maintain a prescribed desired
output.
Two applications, continuous casting process and the
drug dosage in organ transplant, have been applied by
using the proposed system. The conventional methods,
such as mathematical model or experimental model, cannot
achieve satisfactory control performance. Therefore, the
neural network model is constructed for modeling a
complex system and the genetic algorithm model is
developed for finding the optimal control variables.
Numerical results show satisfactory control performance
and reveal the hybrid expert system based on genetic
algorithm and neural network has the capability to
optimally control for both applications, and has the
potential for more applications.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  2833 </NUMBER>
<ORDER>   AAIMM99434 </ORDER>
<TITLE> REAL TIME CONTROL OF MANUFACTURING CELLS UTILIZING FUZZY LOGIC PART DISPATCHING </TITLE>
<AUTHOR> NAUMANN, ANDRE JOACHIM </AUTHOR>
<YEAR> 1994 </YEAR>
<INSTITUTION> UNIVERSITY OF CALGARY (CANADA); 0026 </INSTITUTION>
<DESCRIPTORS> ENGINEERING, INDUSTRIAL; ENGINEERING, SYSTEM SCIENCE; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> P. GU </ADVISER>
<CLASSIFICATIONS> NIL </CLASSIFICATIONS>
<ABSTRACT>
This thesis presents a manufacturing cell control
structure and fuzzy logic part dispatching method which
represent original contributions to the field of
manufacturing cell control. The control structure
consists of a supervisor module comprised of primary and
secondary control levels, and a scheduler module
containing a fuzzy logic part dispatching method. The
fuzzy logic part dispatching method considers many
aspects of the shop floor and shows better performance
in terms of the number of late parts and average buffer
maximum loading than five common dispatching rules (EDD,
LIFO, FIFO, SPT, Slack/OPNR). The control structure has
proven to be very expandable and flexible, deals
effectively with breakdowns and disruptions in real
time, and also incorporates mechanisms whereby part
dispatching can be optimized. The structure is portable
and can be used at different control levels as well as
in a decentralized control environment. Finally the
structure supports the concept of intelligent part and
machine entities.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  2834 </NUMBER>
<ORDER>   AAGNN16637 </ORDER>
<TITLE> A STUDY ON QUARTZ CRYSTAL SENSOR ARRAYS FOR THE DETECTION OF VOLATILE ORGANIC CONTAMINANTS USING NEURAL NETWORK </TITLE>
<AUTHOR> CHU, GUO-ZHU </AUTHOR>
<YEAR> 1997 </YEAR>
<INSTITUTION> UNIVERSITY OF GUELPH (CANADA); 0081 </INSTITUTION>
<DESCRIPTORS> ENGINEERING, CHEMICAL; CHEMISTRY, ANALYTICAL; ENVIRONMENTAL SCIENCES </DESCRIPTORS>
<ADVISER> G. HAYWORD </ADVISER>
<CLASSIFICATIONS> VOC </CLASSIFICATIONS>
<ABSTRACT>
This thesis is an investigation of the quartz crystal
sensor arrays for the detection of volatile organic
compounds using neural network. Continuous measurement
of volatile organic compounds in ground and surface
water systems is required for environmental monitoring,
and pollution control. Recent advances in the field of
the chemical sensors based on Quartz Crystal
Microbalances (QCM) have led to the development of
electronic systems which meet this requirement for
environmental monitoring.
A sensor array system, employing an array of QCMs and
hollow fiber membranes, for the detection of volatile
organic compounds is designed and tested. A novel
approach for optimizing the operation of this sensor
array system using an artificial neural network is
proposed and implemented. The experimental results
demonstrate that the proposed optimization method can
achieve comparable or even better analytical results
than classical statistical methods. Combining the
technologies developed in the fields of artificial
intelligence and array systems, this sensor system has
successfully identified six kinds of volatile organic
compounds in water solution.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  2835 </NUMBER>
<ORDER>   AAG1384871 </ORDER>
<TITLE> ONTOLOGIES AND SOFTWARE REUSE </TITLE>
<AUTHOR> SACKS, TRACEY H. Z. </AUTHOR>
<YEAR> 1997 </YEAR>
<INSTITUTION> UNIVERSITY OF HOUSTON-CLEAR LAKE; 1251 </INSTITUTION>
<DESCRIPTORS> COMPUTER SCIENCE; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> DAVID EICHMANN </ADVISER>
<CLASSIFICATIONS> KNOWLEDGE BASES </CLASSIFICATIONS>
<ABSTRACT>
Software reuse is the use of existing software
components to build new systems. It applies to source
code as well as to the products of other phases of the
life cycle. Knowledge reuse allows the sharing of
knowledge between knowledge bases. Although there is an
interest in reuse, formal and systematic reuse practices
of software and knowledge bases are not widespread in
corporate organizations. Reasons contributing to the
lack of software reuse include the manually intensive
techniques of classification and retrieval. In AI
research and development, the current knowledge base
design lacks methods for exchanging and sharing
knowledge bases, thus making it difficult to evaluate
and build on research results which depend on "domain
theories" or "background knowledge" (Gruber, 1991).
Ontologies may be a solution for promoting software
reuse and for building sharable, reusable knowledge
bases. An ontology is a precise specification of a
conceptualization using both formal and textual
definitions. The use of ontologies in both software and
knowledge reuse is discussed.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  2836 </NUMBER>
<ORDER>   AAG1384589 </ORDER>
<TITLE> AN EXPLORATION AND DEVELOPMENT OF CURRENT ARTIFICIAL NEURAL NETWORK THEORY AND APPLICATIONS WITH EMPHASIS ON ARTIFICIAL LIFE </TITLE>
<AUTHOR> CAVUTO, DAVID JAMES </AUTHOR>
<YEAR> 1997 </YEAR>
<INSTITUTION> THE COOPER UNION FOR THE ADVANCEMENT OF SCIENCE AND ART; 0057 </INSTITUTION>
<DESCRIPTORS> ENGINEERING, ELECTRONICS AND ELECTRICAL; BIOLOGY, NEUROSCIENCE; HEALTH SCIENCES, HUMAN DEVELOPMENT; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> SIMON BEN-AVI </ADVISER>
<CLASSIFICATIONS> NIL </CLASSIFICATIONS>
<ABSTRACT>
The purpose of this study is to explore the
possibilities offered by current Artificial Neural Net
(ANN) structures and topologies and determine their
strengths and weaknesses. The biological inspiration
behind ANN structure is reviewed, and compared and
contrasted with existing models. Traditional experiments
are performed with these existing structures to verify
theory and investigate more possibilities. This study is
conducted to the end of examining the possibility of
using ANNs to create "artificial life," which is defined
here as a structure or algorithm which displays
characteristics typically only attributed to biological
organisms, usually nonrepeating, nonrandom processes.
Although some ANN topology is shown to be highly similar
to that of biological systems, existing ANN algorithms
are determined be insufficient to generate the defined
type of behavior. A new ANN structure, termed a
"Temperon", is designed, which encompasses more
properties in common with biological neurons than did
its predecessors. A virtual environment based on turtle
graphics is used as a testbed for a neural net built
with the new type of neuron. Experiments performed with
the Temperon seem to confirm its ability to learn in an
unassisted fashion.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  2837 </NUMBER>
<ORDER>   AAG1384531 </ORDER>
<TITLE> NEURAL NETWORK CLASSIFICATION OF ELECTROMYOGRAM DATA FOR THE CONSTRUCTION OF A HUMAN/COMPUTER INTERFACE </TITLE>
<AUTHOR> KEENE, KEVIN WARD </AUTHOR>
<YEAR> 1997 </YEAR>
<INSTITUTION> UNIVERSITY OF ALABAMA IN HUNTSVILLE; 0278 </INSTITUTION>
<DESCRIPTORS> ENGINEERING, ELECTRONICS AND ELECTRICAL; ENGINEERING, BIOMEDICAL; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> NIL </ADVISER>
<CLASSIFICATIONS> NIL </CLASSIFICATIONS>
<ABSTRACT>
It is proposed in this work that an alternative means of
interaction with a computer is possible. This method
uses electromyographic (EMG) signals generated from
voluntary muscle activity. The EMG signals were recorded
while the subject performed various facial gestures. No
movement below the subject's neck was required, implying
a potential for use when limited voluntary muscle
actuation is possible. Data recorded during the EMG
acquisition sessions were formulated into input vectors
and used to train a neural network. The single-layer
network with a non-linear activation function was
trained using the standard backpropagation of errors
method. Various techniques to optimize the learning and
generalization capabilities of the network were
employed. The results obtained show that a
human/computer interface based on EMG signal
classification is possible. Additional experimentation
points to the potential for neural network EMG
classification in other applications such as eye
tracking. Recommendations for further study and
implementation of an interface are also presented.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  2838 </NUMBER>
<ORDER>   AAGMM17870 </ORDER>
<TITLE> GILBERT RYLE AND PHENOMENOLOGY: A COMPARISON OF TWO NON- REDUCTIVIST APPROACHES TO PHILOSOPHY </TITLE>
<AUTHOR> VOS, ALEXANDER EDWARD </AUTHOR>
<YEAR> 1997 </YEAR>
<INSTITUTION> QUEEN'S UNIVERSITY AT KINGSTON (CANADA); 0283 </INSTITUTION>
<DESCRIPTORS> PHILOSOPHY </DESCRIPTORS>
<ADVISER> HENRY LAYCOCK </ADVISER>
<CLASSIFICATIONS> NIL </CLASSIFICATIONS>
<ABSTRACT>
The aim of this thesis is twofold. On one level it
examines the sense in which Gilbert Ryle's philosophy
can be described as 'phenomenological'. Various elements
of Ryle's thought are compared to similar ideas found in
the works of mainstream phenomenologists like Husserl,
Heidegger and Merleau-Ponty. Similarities are brought
out in a discussion of four different topics. The first
deals with methodological issues. Ryle's strategy of
analysis is compared to that of Husserl. The proper
subject matter of philosophy is identified as the
general structure of our conceptual scheme and the world
as we experience it (i.e. the life world). The second
discussion is an examination of the life-world with
special reference to meaningful and purposive human
behaviour. It is shown that Ryle cannot be classified as
a 'reductive behaviourist.' In the third discussion,
Ryle's views on the primacy of engaged thinking and
knowing-how, along with similar phenomenological
doctrines, are shown to raise doubts about the
possibility of artificial intelligence. These same
views, coupled with Strawson's idea of 'soft
naturalism', provide justification for the view that one
can avoid the threat of scepticism. This is the topic of
the final chapter. (Abstract shortened by UMI.)
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  2839 </NUMBER>
<ORDER>   AAGMM16673 </ORDER>
<TITLE> A VISUAL EXPERT SYSTEM FOR ATMOSPHERIC POLLUTION MODELLING USING CAUSAL PROBABILISTIC NETWORKS </TITLE>
<AUTHOR> HUANG, LIUSHA TONY </AUTHOR>
<YEAR> 1997 </YEAR>
<INSTITUTION> UNIVERSITY OF GUELPH (CANADA); 0081 </INSTITUTION>
<DESCRIPTORS> COMPUTER SCIENCE; ARTIFICIAL INTELLIGENCE; PHYSICS, ATMOSPHERIC SCIENCE; ENVIRONMENTAL SCIENCES </DESCRIPTORS>
<ADVISER> D. A. SWAYNE </ADVISER>
<CLASSIFICATIONS> NIL </CLASSIFICATIONS>
<ABSTRACT>
In this project, we present a knowledge-based system as
an alternative to determine source/receptor
relationships of long range transport of air pollutants.
The system is based on Causal Probabilistic Networks
(CPN) which have proved to be a useful knowledge
representative tool for modeling domains where causal
relationships are a natural way of relating domain
objects. We propose the CPN paradigm can be demonstrated
as a feasible approach for describing source/receptor
relationships of long range transport of air pollutants.
The introduction of intermediate nodes in CPN makes our
causal model more meaningful and explainable. The use of
sub-networks attached to nodes on the main simplifies
the appearance of the entire network. A well designed
graphical user interface provides user more space to
adjust pre-input probabilistic data according to
evidence or user's belief. A set of approximate data is
used and the yielded result is discussed.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  2840 </NUMBER>
<ORDER>   AAGMM16670 </ORDER>
<TITLE> AN ARTIFICIAL NEURAL NETWORK HIERARCHY FOR THE ANALYSIS OF CERVICAL SMEARS </TITLE>
<AUTHOR> HODGE, LOVELL ANDERS S. </AUTHOR>
<YEAR> 1997 </YEAR>
<INSTITUTION> UNIVERSITY OF GUELPH (CANADA); 0081 </INSTITUTION>
<DESCRIPTORS> COMPUTER SCIENCE; ARTIFICIAL INTELLIGENCE; HEALTH SCIENCES, OBSTETRICS AND GYNECOLOGY </DESCRIPTORS>
<ADVISER> DEBORAH STACEY </ADVISER>
<CLASSIFICATIONS> NIL </CLASSIFICATIONS>
<ABSTRACT>
This thesis is an investigation of the use of artificial
neural networks in a hierarchical arrangement for the
classification of cervical cell image data. The aim is
to distinguish between normal cervical cells and
abnormal or dysplastic cells based on one or more
distinct feature sets obtained from the image data. The
cervical cell image data presents a real world
classification problem with no easy solution. The
classes are severely overlapping and in many cases
poorly defined. The thesis focuses on the use of
backpropagation and Learning Vector Quantization as the
artificial neural network classifiers. Each level in the
hierarchy refines the output of the preceding level so
that the lowest level produces the desired
classifications.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  2841 </NUMBER>
<ORDER>   AAGMM16103 </ORDER>
<TITLE> SELECTING FEATURE DETECTORS FOR ARTIFICIAL NEURAL NETWORKS USING GENETIC ALGORITHMS </TITLE>
<AUTHOR> BROWN, ANDREW DENIS </AUTHOR>
<YEAR> 1997 </YEAR>
<INSTITUTION> THE UNIVERSITY OF MANITOBA (CANADA); 0303 </INSTITUTION>
<DESCRIPTORS> ENGINEERING, ELECTRONICS AND ELECTRICAL; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> HOWARD CARD </ADVISER>
<CLASSIFICATIONS> NIL </CLASSIFICATIONS>
<ABSTRACT>
This thesis is concerned with evolutionary artificial
neural networks (ANNs) which combine genetic algorithms
(GAs) with local neural learning using gradient descent
methods. Experiments of a previous study on the use of
GAs to produce a single feature detector for a two-layer
neural network are reproduced. Also, a more thorough
comparison of this method with back-propagation (BP)
using cross-validation is presented. The comparison
shows that on the test problem--a font independent digit
classification task--the GA method does not
significantly outperform BP with cross-validation. A
second method, which uses the GA to find multiple
feature detectors which further reduce the
dimensionality of the input patterns is then proposed.
In addition three methods of encoding the feature
detectors in the chromosome are implemented. A simple
image classification problem which contains features
local to portions of the input field is the basis for
evaluation. These experiments show that the GA can
correctly determine a set of feature detectors which the
network uses to accurately classify the data set.
Finally, a set of experiments is presented which test
the generalization of these network training algorithms
on a noisy, single-font digit recognition task. The
experiments show that the three algorithms are
comparable at promoting generalization to previously
unseen data, but the multiple template version of the
genetic algorithm produces the networks which most
consistently and accurately classify the training and
validation data with high confidence. Between the two
algorithms which partition the chromosomes, there is a
noticeable difference in the performance of the average
network produced by each algorithm, but the best
networks produced by each process are almost the same.
(Abstract shortened by UMI.)
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  2842 </NUMBER>
<ORDER>   AAG9731324 </ORDER>
<TITLE> PROCESS MONITORING AND ANALYSIS USING NONLINEAR DATA DIMENSIONALITY REDUCTION </TITLE>
<AUTHOR> REDDY, VENKATRAMANA N. </AUTHOR>
<YEAR> 1997 </YEAR>
<INSTITUTION> NORTHWESTERN UNIVERSITY; 0163 </INSTITUTION>
<DESCRIPTORS> ENGINEERING, CHEMICAL; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> NIL </ADVISER>
<CLASSIFICATIONS> NONLINEAR PCA, NEURAL NETWORKS </CLASSIFICATIONS>
<ABSTRACT>
Dimensionality reduction is a way of summarizing, with a
few latent variables, information carried by a large
number of observed variables. Principal Component
Analysis (PCA) is a commonly used dimensionality
reduction technique; it uses linear functions to model
relationships between observed variables and latent
variables. In this dissertation, we present a new method
(Input-Training Neural Networks) for reducing data
dimensionality using neural networks as nonlinear models
between observed variables and latent variables. In an
input-training neural network (IT-net) only one single-
hidden-layer network is needed for dimensionality
reduction of data. We demonstrate the use of IT-nets for
data dimensionality reduction, data recovery, missing
sensor replacement, gross error detection, and
classification.
The most significant non-random behavior from a set of
variables is captured as an IT-net model. The process of
mapping (dimensionality reduction) a data matrix and
conversely demapping the reduced data using an IT-net
helps to eliminate random variation in the data. When
the data from a variable is unavailable (missing sensor)
the IT-net provides the best estimate of the data which
minimizes the error in the remaining variables, based on
the nonlinear model retained by the IT-net. Faulty
sensors are identified by examining the prediction
errors from a previously trained IT-net. Large
prediction errors for a particular variable or a group
of variables indicate that the data from such variables
are inconsistent with the IT-net model and most likely
contain gross errors. A two-dimensional plot of
nonlinear features extracted by the IT-net convey
information about the measurements which lead to
applications in fault diagnosis and pattern
classification. An important feature of IT-nets is that
they can be trained even on incomplete process data.
A second technique presented in this dissertation
focuses on signals which display variation in time
scales and are especially difficult to model with linear
relationships. We present a method for transforming such
signals in order to efficiently apply PCA and illustrate
the method in two examples.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  2843 </NUMBER>
<ORDER>   AAG9731198 </ORDER>
<TITLE> LOW BIT RATE SPEECH CODING BASED ON THE SINUSOIDAL MODEL </TITLE>
<AUTHOR> AHMADI, SASSAN </AUTHOR>
<YEAR> 1997 </YEAR>
<INSTITUTION> ARIZONA STATE UNIVERSITY; 0010 </INSTITUTION>
<DESCRIPTORS> ENGINEERING, ELECTRONICS AND ELECTRICAL; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> NIL </ADVISER>
<CLASSIFICATIONS> NIL </CLASSIFICATIONS>
<ABSTRACT>
This dissertation addresses the design, development, and
implementation of efficient low bit rate speech coding
algorithms based on the sinusoidal model. The choice of
the sinusoidal model in this research is justified by
the fact that sinusoidal modeling provides an efficient
and compact set of parameters in the frequency-domain
for representing short-time speech segments, as well as
providing reproduced speech of high quality,
intelligibility, and naturalness, using a reasonable
amount of computational complexity and storage. Other
speech coding algorithms such as code excited linear
prediction (CELP), multi-band excitation (MBE), and a
variety of coding systems based on linear predictive
coding (LPC) method were also studied and evaluated.
The research results described in this dissertation
represent significant contributions to the state of the
art in terms of a series of new algorithms that are
shown to noticeably and in some cases substantially
improve the performance of the sinusoidal coders at low
bit rates. Among these contributions, there are
algorithms developed for accurate pitch frequency
detection and voicing estimation, minimum variance phase
estimation, simultaneous modeling of the sinusoidal
amplitudes and phases, and frame interpolation. The data
provided in this document is supported by statistical
results obtained from comprehensive experimentation. The
perceptual properties of the human auditory system are
effectively exploited in the developed algorithms.
The performance of the developed coders has been
evaluated in terms of informal subjective tests such as
the mean opinion score (MOS) and the diagnostic rhyme
test (DRT), as well as other meaningful objective
distortion measures, and compared to other speech coders
operating at the same bit rate.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  2844 </NUMBER>
<ORDER>   AAIMM99052 </ORDER>
<TITLE> THE USE OF SMART GRAPHICS FOR THE REDEVELOPMENT OF HISTORICAL STRUCTURES </TITLE>
<AUTHOR> HILL, SHAUNA MARIE </AUTHOR>
<YEAR> 1994 </YEAR>
<INSTITUTION> THE UNIVERSITY OF MANITOBA (CANADA); 0303 </INSTITUTION>
<DESCRIPTORS> ARCHITECTURE; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> WILLIAM P. THOMPSON </ADVISER>
<CLASSIFICATIONS> NIL </CLASSIFICATIONS>
<ABSTRACT>
The redevelopment of historical structures is
particularly difficult because it involves capturing and
managing large amounts of existing building data and
analysis of that data using specialized expertise from a
variety of disciplines. With the advent of affordable
and powerful computer-based information technologies
researchers are becoming interested in developing design
decision-making support systems capable of providing
designers with access to both digital building data and
special expertise. The Smart Graphic Environment
developed and evaluated in this thesis is a type of
Intelligent Computer Aided Design (ICAD) or Knowledge
Assisted Design (KAD) system that integrates a
commercially available CAD system with expertise encoded
in a Knowledge Base (expert) System. The purpose of this
environment is to provide designers working with
heritage structures access to specialized expertise from
within the CAD environment for improved design decision-
making.
This thesis research includes an investigation of
existing research in this area and the development of a
conceptual framework for a Smart Graphic Environment.
Object-based techniques for design data and knowledge
acquisition and representation on the computer are
explained. The conceptual framework was tested and
evaluated through the implementation of a working
prototype system. This system analyses CAD files for
building code violations.
The findings of this research identify the potential of
such environments for information management, increasing
productivity, and to improving the quality of design
decision-making. One of the observations of this study
is that because of current limitations of CAD models and
knowledge representation the principle role of such
computer systems is to augment rather than replace the
skill and expertise of a human designer.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  2845 </NUMBER>
<ORDER>   AAG9730786 </ORDER>
<TITLE> MULTI-AGENT REINFORCEMENT LEARNING IN MARKOV GAMES </TITLE>
<AUTHOR> SHEPPARD, JOHN WILBUR </AUTHOR>
<YEAR> 1997 </YEAR>
<INSTITUTION> THE JOHNS HOPKINS UNIVERSITY; 0098 </INSTITUTION>
<DESCRIPTORS> COMPUTER SCIENCE </DESCRIPTORS>
<ADVISER> STEVEN L. SALZBERG </ADVISER>
<CLASSIFICATIONS> GAME THEORY </CLASSIFICATIONS>
<ABSTRACT>
Game playing has been a popular problem area for
research in artificial intelligence and machine learning
for many years. In almost every study of game playing
and machine learning, the focus has been on games with a
finite set of states and a finite set of actions.
Further, most of this research has focused on a single
player or team learning how to play against another
player or team that is applying a fixed strategy for
playing the game.
In this dissertation, we provide and evaluate algorithms
for learning strategies in two player games with large
state and action spaces. First, we focus on the class of
differential games in which the state space and the
action space are both continuous. We model these games
as discrete Markov games and provide methods for
representing the state and actions spaces at varying
levels of resolution. Second, we explore multi-agent
learning and develop algorithms for "co-learning" in
which all players attempt to learn their optimal
strategies simultaneously.
Specifically, in this dissertation we compare several
algorithms for a single player to learn an optimal
strategy against a fixed opponent. Next we combine the
results of one algorithm--a genetic algorithm--with a
second algorithm--a memory-based learning algorithm--to
yield performance exceeding the capabilities of either
algorithm alone. Then we explore two approaches to co-
learning in which both players learn simultaneously. We
demonstrate strong performance by a memory-based
reinforcement learner and comparable but faster
performance with a tree-based reinforcement learner. In
addition to the experimental results, we also provide an
overview of machine learning and game playing as well as
an overview of differential and Markov games.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  2846 </NUMBER>
<ORDER>   AAG9730310 </ORDER>
<TITLE> LOW-ORDER DYNAMICAL MODELING AND INTELLIGENT CONTROL OF THERMO-FLUID SYSTEMS VIA PROPER ORTHOGONAL DECOMPOSITION </TITLE>
<AUTHOR> SAHAN, RIDVAN AMIR </AUTHOR>
<YEAR> 1997 </YEAR>
<INSTITUTION> LEHIGH UNIVERSITY; 0105 </INSTITUTION>
<DESCRIPTORS> ENGINEERING, MECHANICAL; PHYSICS, FLUID AND PLASMA; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> ANTONIOS LIAKOPOULOS </ADVISER>
<CLASSIFICATIONS> NIL </CLASSIFICATIONS>
<ABSTRACT>
In the present investigation, low-order dynamical models
of transitional thermo-fluid systems in complex
configurations have been developed. Proper orthogonal
decomposition (POD) has been applied to supercritical
oscillatory solutions, obtained by solving the flow
governing partial differential equations (PDEs) with a
spectral element method at Reynolds numbers, $Resb0o$
and Grashof numbers, $Grsb0o,$ higher than the critical
values, $Resb0c$ and $Grsb0c.$ POD enables us to extract
the empirical eigenfunctions, to compress the data and
to identify the organized spatio-temporal (coherent)
structures. Low-order models (LOMs) consisting of
reduced number of nonlinear ordinary differential
equations (ODEs) are derived for isothermal and
nonisothermal transitional flow in a grooved channel and
transitional free convective flow in a vertical channel
using the computed empirical eigenfunctions as basis
functions and applying Galerkin projection (GP). The
ability of the reduced models to describe the dynamics
of the flow and temperature field at "design" and "off-
design" conditions is studied. The developed LOMs are
used to investigate stability and bifurcation behavior
of the dynamical systems, to explore possible routes to
chaos and active and passive intelligent flow control
ideas using artificial neural networks (ANNs).
For fixed values of Prandtl number, Pr, the eigenvalues,
eigenfunctions and spatio-temporal structures depend on
the variation of the flow controlling parameters of
Reynolds number, Re in forced convective case, and
Grashof number, Gr in free convective case. The
eigenfunctions associated with the largest eigenvalues
are the modes that contain the largest fraction of the
total flow and temperature fluctuation "energy" and
explain the dynamical attributes of the thermo-fluid
systems. The dynamical spatio-temporal structures of the
thermo-fluid systems under investigation are identified
as travelling waves. The accuracy of the developed low-
order dynamical models strongly depends on the number of
modes retained in the series expansion. For the range of
$430le Rele 1050$ and $22500le Grle 30000$ studied, at
least four modes for velocity and four modes for
temperature are required to predict self-sustained
oscillations in time at "design" conditions. Close to
the "design" conditions, the LOM predictions are in
excellent agreement with the full model results,
capturing the short and long-time nonlinear dynamical
behavior of the thermo-fluid systems. Far from the
"design" conditions, the LOMs exhibit different routes
to chaos depending on the order of truncation (number of
modes retained). Ranges of Reynolds and Grashof numbers
for which quasi-periodic, period-doubling and
intermittent bifurcations exist have been determined by
numerically solving the resulting ODEs. The developed
LOMs of transitional isothermal flow system in a grooved
channel are used to efficiently train an artificial
neural network (ANN), resulting in accurate ANN-based
low-order dynamical models. Low-order modeling has the
potential of becoming very useful tool for transitional
and turbulent flow systems in the study of coherent
structure dynamics, bifurcation and flow stability, and
in exploring ideas in the context of intelligent flow
control schemes with the use of ANNs.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  2847 </NUMBER>
<ORDER>   AAG9730135 </ORDER>
<TITLE> A NEUROCOMPUTING APPROACH TO SOLVING PARTIAL DIFFERENTIAL EQUATIONS  </TITLE>
<AUTHOR> ALHARBI, ABIR H. </AUTHOR>
<YEAR> 1997 </YEAR>
<INSTITUTION> FLORIDA INSTITUTE OF TECHNOLOGY; 0473 </INSTITUTION>
<DESCRIPTORS> MATHEMATICS; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> LAURENE V. FAUSETT </ADVISER>
<CLASSIFICATIONS> FINITE ELEMENT, HOPFIELD NEURAL NETWORK </CLASSIFICATIONS>
<ABSTRACT>
Differential equations in science and engineering are
tools to describe the actual behavior of physical
systems. Physical situations involving more than one
variable can often be expressed using equations
involving partial derivatives (PDEs). While there
already exists many analytical and numerical techniques
for solving PDEs, recent advances in an alternative
problem solving approach, artificial neural networks,
suggest that this methodology may have potential in this
area. Neural nets are of interest to researchers in many
areas of science. They are a powerful tool for modeling
problems for which explicit solutions are not known or
can not be easily obtained. Since PDEs can lead to
challenging numerical problems, it is advantageous to
develop methods for applying neural nets to solving
partial differential equations.
This dissertation introduces a new approach to
approximate solutions of differential equations using
the recently developed Hopfield neural networks. The
Hopfield neural network is designed to solve constrained
optimization problems; it is a recurrent net where the
weights are fixed to represent the constraints and the
quantity to be optimized. Our approach consists of two
new techniques developed to solve both boundary value
problem (BVP) and PDE, by combining the two standard
numerical methods, finite-differences and finite-
elements, with the Hopfield neural net. The new
approaches are denoted the Hopfield-finite-difference
(HFD) and Hopfield-finite-element (HFE) methods.
The use of the HFD and HFE methods are illustrated for
several simple problems. Sensitivity tests on the
parameters involved in these methods demonstrate the
robustness of these methods. Moreover, several forms of
the Hopfield neural net are explored, namely, parallel
computation, sequential mode, and random order of
updates. The stability characteristics of the Hopfield
nets developed in the research are summarized. The
developed methods are then used to approximate the
solutions of a variety of problems, and the results are
compared with those obtained by numerical methods.
Many examples of basic PDEs and BVPs are successfully
solved using the proposed approaches, demonstrating the
effectiveness of these methods. The problems discussed
in the research are a brief sample of the applications
in which HFD and HFE can be used; they suggest the
breadth of the neural net's applicability in
approximating solutions to partial differential
equations.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  2848 </NUMBER>
<ORDER>   AAG9730129 </ORDER>
<TITLE> A ROBUST PARTIAL LEAST SQUARES NEURAL NETWORK </TITLE>
<AUTHOR> MCDOWALL, THOMAS MICHAEL </AUTHOR>
<YEAR> 1997 </YEAR>
<INSTITUTION> FLORIDA INSTITUTE OF TECHNOLOGY; 0473 </INSTITUTION>
<DESCRIPTORS> ENGINEERING, ELECTRONICS AND ELECTRICAL; COMPUTER SCIENCE; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> F. M. HAM </ADVISER>
<CLASSIFICATIONS> ROBUST LEARNING, PARTIAL LEAST SQUARES REGRESSION </CLASSIFICATIONS>
<ABSTRACT>
A robust learning strategy for partial least-squares
(PLS) regression has been developed. In the original
work of Ham and Kostanic, a modular neural network
architecture for linear PLS (PLSNET) allowed the PLS
weight loading vectors, loading vectors, and regression
coefficients (three sets of synaptic weights) to be
computed from successive inputs (i.e., single
measurements and their associated scalar target values).
Three Hebbian learning rules, derived from three
quadratic performance measures, were used to adaptively
compute the PLSNET synaptic weights using supervised
learning. Unlike some nonlinear PLS neural networks,
e.g., multi-layer perceptrons trained by back-
propagation, PLSNET has distinct stages (modules) which
are directly related to each factor in the statistical
calibration model.
The robust learning strategy is derived from three
statistical representation error performance measures.
Each performance measure contains a weighting function
that grows less than quadratically. For robust PLSNET,
the learning rules are generalizations of the Hebbian
learning rules for the linear PLSNET. That is, when the
weighting functions are assumed to be quadratic in the
statistical representation error performance measures,
the original Hebbian learning rules can be recovered.
Moreover, when the statistical representation error
performance measures are defined with a positive
definite symmetric weighting matrix, a variety of
learning rules result, including weighted least squares
and Newton's method versions of PLSNET. A new regression
method has also been developed through optimization of
inverse models of the error functions, i.e., an inverse
least squares approach. This inverse modeling approach
has additional advantages, including fewer floating
point operations per training epoch and better outlier
and noise rejection.
The examples presented demonstrate that robust PLSNET
can improve the predictive performance of the resulting
statistical calibration model when the input data used
to develop the model contains impulse noise, colored
noise, and outliers, as compared to linear PLS,
classical least-squares, and nonlinear PLS neural
networks trained by back-propagation.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  2849 </NUMBER>
<ORDER>   AAG9729723 </ORDER>
<TITLE> AGING IN ARTIFICIAL NEURAL NETWORKS: CAUSES AND PREVENTION OF REPETITION INDUCED INCOMPETENCE IN REINFORCEMENT LEARNING </TITLE>
<AUTHOR> YUAN, LILI </AUTHOR>
<YEAR> 1997 </YEAR>
<INSTITUTION> THE FLORIDA STATE UNIVERSITY; 0071 </INSTITUTION>
<DESCRIPTORS> COMPUTER SCIENCE; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> R. C. LACHER </ADVISER>
<CLASSIFICATIONS> NIL </CLASSIFICATIONS>
<ABSTRACT>
Repetition Induced Incompetence (RII) is the degradation
of both skill level and learning ability associated with
long periods of repeated execution of a single task. RII
has been consistently observed in a pole balancing
control system, a classic example of a reinforcement
learning system. RII not only prevents knowledge
accumulating but also destroys the acquired knowledge
forever. Although the RII phenomenon is observed in
supervised learning systems as catastrophic
interference, it has up to now not been addressed in the
reinforcement learning literature.
The RII phenomenon in reinforcement learning systems is
investigated. The concept and the learning model of RII
in reinforcement learning systems based on the
observations are defined. The causes of RII are analyzed
theoretically and experimentally by examining individual
factors of the learning systems. The theoretical
investigation focuses on the compatibility of different
methods used in reinforcement learning systems. Weight
changes of the neural networks in the learning systems
are closely observed in the experiments. Weight changes
provide internal evidence of the impact of the
individual factors. The classic pole balancing control
system is used as a testbed throughout the dissertation.
The investigation reveals several possible causes of
RII, and at the same time, confirms many similarities
between human learning and machine learning. The
proposed five independent prevention methods permit the
system to learn in the same efficient way as the
original system without the degradation of performance
and stunted learning ability associated with RII.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  2850 </NUMBER>
<ORDER>   AAG9729019 </ORDER>
<TITLE> DETECTION AND RESOLUTION OF LEARNING CONFLICT IN BACKPROPAGATION NETWORKS  </TITLE>
<AUTHOR> KERSTETTER, DEREK EDWARD </AUTHOR>
<YEAR> 1997 </YEAR>
<INSTITUTION> UNIVERSITY OF ALABAMA IN HUNTSVILLE; 0278 </INSTITUTION>
<DESCRIPTORS> COMPUTER SCIENCE; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> NIL </ADVISER>
<CLASSIFICATIONS> ARTIFICIAL NEURAL NETWORKS, PATTERN RECOGNITION </CLASSIFICATIONS>
<ABSTRACT>
The backpropagation network is one of the most widely
used neural classifiers. One impediment to training a
backpropagation network is conflicting information in
the training patterns. If there is sufficient conflict
within the training set, the backpropagation network
will enter into a gridlock condition during training.
When the network enters into gridlock, the network stops
learning. This dissertation presents a method for
detecting and overcoming the learning problems caused by
conflict in training pattern sets. This method is used
to create a new class of neural networks, the auto-
partitioning neural networks.
Auto-partitioning neural networks are characterized by
their ability to detect and rectify learning conflict.
Several methods are developed for measuring intra-class
conflict for patterns in a given class of the training
set. Both the network architecture and training
alogrithm are taken into consideration for computing the
conflict measures. Based on intra-class conflict
measures, patterns of a given class are partitioned into
an appropriate number of groups. Two different
partitioning methods are developed. Depending on the
partitioning method used, the auto-partitioning neural
network is called the self partitioning neural network
or the recursive partitioning neural network, regardless
of the patterns in each group. Because there is little
intra-class conflict within a partition, each subnetwork
requires few training iterations to reach convergence.
After training is completed, the outputs of the
subnetworks are combined to produce the final response.
This approach is shown to improve classification
accuracy, reduce training time and support incremental
learning.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  2851 </NUMBER>
<ORDER>   AAG9728447 </ORDER>
<TITLE> LEARNING TO SOLVE MULTIPLE GOALS </TITLE>
<AUTHOR> KARLSSON, JONAS </AUTHOR>
<YEAR> 1997 </YEAR>
<INSTITUTION> THE UNIVERSITY OF ROCHESTER; 0188 </INSTITUTION>
<DESCRIPTORS> COMPUTER SCIENCE; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> DANA H. BALLARD </ADVISER>
<CLASSIFICATIONS> TASK DECOMPOSITION, ARTIFICIAL INTELLIGENCE </CLASSIFICATIONS>
<ABSTRACT>
In many domains, the task can be decomposed into a set
of independent sub-goals. Often, such tasks are too
complex to be learned using standard techniques such as
Reinforcement Learning. The complexity is caused by the
learning system having to keep track of the status of
all sub-goals concurrently. Thus, if the solution to one
sub-goal is known when another sub-goal is in some given
state, the known solution must be relearned when the
status of the other sub-goal changes.
This dissertation presents a modular approach to
reinforcement learning that takes advantage of task
decomposition to avoid unnecessary relearning. In the
modular approach, modules are created to learn each sub-
goal. Each module receives only those inputs relevant to
its associated sub-goal, and can therefore learn without
being affected by the state of other sub-goals.
Furthermore, each module searches a much smaller space
than that defined by all inputs considered together,
thereby greatly reducing learning time. Since each
module learns how to achieve a separate sub-goal, at any
given time it may recommend an action different from
that recommended by other modules. To select an action
that best satisfies as many of the modules as possible,
a simple arbitration strategy is used. One such
strategy, explored in this dissertation, is called
greatest mass which simply combines action utilities
from all modules and selects the one with the largest
combined utility.
Since the modular approach limits and separates
information given to the modules, the solution learned
must necessarily differ from that learned by a standard,
non-modular approach. However, experiments in a simple
driving world indicate that while sub-optimal, the
solution learned by the modular system only makes minor
errors when compared with that learned by the standard
approach. A complex task can thus be learned very
quickly, using only small amounts of computational
resources, with only small sacrifices in solution
quality, using the modular approach.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  2852 </NUMBER>
<ORDER>   AAG9728235 </ORDER>
<TITLE> VISUAL INTERPRETATION OF HAND GESTURES AS A PRACTICAL INTERFACE MODALITY  </TITLE>
<AUTHOR> KJELDSEN, FREDERIK C. M. </AUTHOR>
<YEAR> 1997 </YEAR>
<INSTITUTION> COLUMBIA UNIVERSITY; 0054 </INSTITUTION>
<DESCRIPTORS> COMPUTER SCIENCE; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> JOHN R. KENDER </ADVISER>
<CLASSIFICATIONS> NEURAL NETWORKS </CLASSIFICATIONS>
<ABSTRACT>
This dissertation describes a user interface in which
many tasks traditionally performed by a mouse are
instead performed using visual recognition of hand
gestures. The goals are to explore both how a vision
system should be designed to recognize hand gestures,
and how they are best used in a general purpose
interface.
Observed by a camera below the screen, the user
manipulates objects directly with gestures incorporating
both motion and pose. Task and domain knowledge provide
context, allowing real-time recognition on standard PC
hardware.
A color-based algorithm is trained to segment user's
hands from complex backgrounds without visual aids.
Training uses a novel combination of both positive and
negative data to improve segmentation quality.
The apparent path of the hand is smoothed with an
algorithm which reduces the types of noise inherent in
the domain but leaves a cursor motion on the screen that
feels natural for the user. Salient features of the
motion are extracted, including a newly discovered
natural gesture (a "Comma"), which helps provide
punctuation for each gestural sentence.
Neural networks are trained to classify the pose of the
user's hand from cropped and preprocessed images. The
nets correctly classify 90-95% of the hand images in
real time.
A transition network encodes the interaction language.
It controls the application of feature extraction
operators and interprets their results to determine when
to perform actions on the user's behalf. The style of
interaction is based on studies of natural gesticulation
and incorporates various features designed to make it
natural and easy for the user to remember.
The system demonstrates a 80-90% success rate on most
tasks. Object selection time for large objects is
demonstrated to be equal or superior to that of a mouse.
Object selection performance is modeled accurately by
augmenting Fitts' Law with terms for lag and random
cursor noise.
Finally, the suitability of gesture for this type of
task is considered. Various interaction styles are
examined, and problems specific to hand gesture are
discussed.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  2853 </NUMBER>
<ORDER>   AAG9727754 </ORDER>
<TITLE> APPROXIMATING HUMAN TEXTURE PERCEPTION: FUZZY DETECTION OF WOLD COMPONENTS AND THEIR TREE CLASSIFICATION </TITLE>
<AUTHOR> LANDISMAN, ANDREW MICHAEL </AUTHOR>
<YEAR> 1997 </YEAR>
<INSTITUTION> UNIVERSITY OF CALIFORNIA, IRVINE; 0030 </INSTITUTION>
<DESCRIPTORS> ENGINEERING, ELECTRONICS AND ELECTRICAL; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> RUI J. P. DE FIGUEIREDO </ADVISER>
<CLASSIFICATIONS> NIL </CLASSIFICATIONS>
<ABSTRACT>
A texture classification system is presented which
assigns texture images to known classes from
psychophysical research of others. The system is
composed of two major subsystems, namely a texture
feature extractor and a binary tree classifier which
takes the features as its input.
The texture feature extractor, based upon the theory of
the 2-D Wold decomposition, applies a technique of
treating the central segment of the thresholded
autocovariance function as an image itself in order to
parametrically characterize its spatial moments. The
features extracted are the spatial second order moment
in the primary orientation, the ratio of this moment for
the primary and secondary orientations, and the ratio of
the energy in the central segment of the thresholded
autocovariance to the energy in the entire
autocovariance. These features are then applied as
inputs to a fuzzy system to detect the presence of two
of the three Wold components in a texture sample.
The second subsystem then utilizes the fuzzy membership
values so assigned, along with the characterization
parameters, to generate a binary tree classifier. The
binary tree classifier relies upon the Classification
and Regression Trees (CART) technique. In this process,
texture class labels from psychophysical research of
others are used as training labels to construct the
tree. The generation of trees by CART produces not only
a classifier, but also useful statistics associated with
the classifier, notably an estimate of the true
misclassification rate by use of cross-validation.
The system is applied to a subset of the texture images
taken from the Brodatz album. A series of experiments
using different subsets of the above features and
characterization parameters were run. The results
demonstrate that the two stage technique is able to
produce estimated overall true misclassification rates
which are as good as those generated using
psychophysical inputs. A further experiment using a
composite of image parameters yields improved results
and provides data for interpretation of the best tree.
This interpretation shows that the best tree in some
ways mimics the clustering of textures in the original
psychophysical experiment. Thus, the system is shown to
succeed in approximating human texture perception.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  2854 </NUMBER>
<ORDER>   AAG9727750 </ORDER>
<TITLE> CHARACTERISTIC CONCEPT REPRESENTATIONS </TITLE>
<AUTHOR> DATTA, PIEW </AUTHOR>
<YEAR> 1997 </YEAR>
<INSTITUTION> UNIVERSITY OF CALIFORNIA, IRVINE; 0030 </INSTITUTION>
<DESCRIPTORS> COMPUTER SCIENCE; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> DENNIS F. KIBLER </ADVISER>
<CLASSIFICATIONS> INSTANCE-BASED LEARNING, CLASS PREDICTION </CLASSIFICATIONS>
<ABSTRACT>
In machine learning, concepts have traditionally been
represented and learned using algorithms that represent
only those characteristics that discriminate between two
or more classes. Representations such as decision trees
and rules provide increased classification ability, but
do not provide a general characteristic description of
the concepts. This dissertation explores the use of
characteristic descriptions for concepts in the
classification task.
In our research, characteristic descriptions are
represented by prototypes. The methods described focus
on the issue of learning multiple prototypes for a class
when necessary. Two diverse methods are developed. The
first method, PL (Prototype Learner), attempts to
separate examples into smaller subgroups with similar
characteristics. The second method, SNMC (Symbolic
Nearest Mean with Clustering), applies clustering
techniques to separate groups of examples, using
classification accuracy on the training set as its
heuristic. The groups of examples in each of these
algorithms are simplified into prototypes representing
the examples and a nearest neighbor classification
approach is used for class prediction.
Our empirical results show that SNMC has an increase in
average classification accuracy of about 2% over C4.5
and PEBLS on 20 domains from the UCI data repository.
The experimental results on the UCI domains showed that
SNMC classifies the best in average rank and accuracy of
the six algorithms compared. PL classifies favorably to
C4.5 and PEBLS on the same domains. These results show
that prototype concept representations can be
successfully applied to the classification task.
The last portion of this dissertation introduces a task,
inductive inference, which is a generalization of
classification. In this task the algorithm must make
predictions about any of the attribute values. We
discuss five subtasks of the inductive inference task,
including the classification task. We also discuss
metrics that can be used to evaluate algorithms on these
tasks. We contend that these metrics used in conjunction
with classification accuracy provides a more general
evaluation methodology than classification accuracy
alone. We provide comparisons among PL, C4.5, PEBLS, and
COBWEB.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  2855 </NUMBER>
<ORDER>   AAIMM99039 </ORDER>
<TITLE> TOPICS IN PATTERN RECOGNITION USING UNSUPERVISED LEARNING  </TITLE>
<AUTHOR> CZEZOWSKI, PETER JOHN </AUTHOR>
<YEAR> 1994 </YEAR>
<INSTITUTION> THE UNIVERSITY OF MANITOBA (CANADA); 0303 </INSTITUTION>
<DESCRIPTORS> ENGINEERING, ELECTRONICS AND ELECTRICAL; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> WITOLD PEDRYCZ </ADVISER>
<CLASSIFICATIONS> ARTIFICIAL NEURAL NETWORKS </CLASSIFICATIONS>
<ABSTRACT>
This thesis investigates the use of unsupervised
learning algorithms in applications of pattern
recognition and data representation. Various classical
and artificial neural network algorithms were included
in the investigation. Particular attention was devoted
to the topics of valid clustering and input component
prediction applications. Through the examination of
experiments on the algorithms considered, it was
determined that the growing cell structure was the most
promising. With respect to valid clustering, an
improvement is suggested for the self-organizing map
interpretation problem, and a new process for
interpreting the growing cell structure is suggested. A
new technique in the application of these algorithms to
problems in the prediction of missing variables is
evaluated. It was concluded that these algorithms are
effectively able to form compressed representations of
their original data sets which are useful in
classification and prediction applications.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  2856 </NUMBER>
<ORDER>   AAG0598118 </ORDER>
<TITLE> MATERIAL DESIGN IN STEEL MAKING UTILISING MATHEMATICAL MODELLING, KNOWLEDGE-BASED AND FUZZY LOGIC APPROACHES </TITLE>
<AUTHOR> SHIVATHAYA, SEETARAM SAHADEV </AUTHOR>
<YEAR> 1997 </YEAR>
<INSTITUTION> UNIVERSITY OF WOLLONGONG (AUSTRALIA); 0727 </INSTITUTION>
<DESCRIPTORS> ENGINEERING, MECHANICAL; ARTIFICIAL INTELLIGENCE; ENGINEERING, METALLURGY </DESCRIPTORS>
<ADVISER> NIL </ADVISER>
<CLASSIFICATIONS> NIL </CLASSIFICATIONS>
<ABSTRACT>
This thesis discusses a material design system which
deals with the determination of the steelmaking aim
chemistry. If an attempt is made to design aim chemistry
only based on a mathematical approach of utilising the
empirical models between various design parameters, it
would result in unrealistic design because relationships
between various design parameters are not always linear.
The approach put forward in this thesis is a hybrid
approach, where the knowledge-base is applied at every
stage of the design process to utilise the expert as
well as the heuristic knowledge of metallurgists to
obtain the designs which are realistic and which take
into account various limitations and constraints
encountered in steel making. The inputs to the system
are through interactive dialogue sessions and the inputs
consist of the material standards, size, quantity,
tonnage, end use and the customer special requirements.
These inputs along with the numerous rules in the
knowledge-bases as well as the mathematical modelling
enable the effective design of the steelmaking aim
chemistry.
Knowledge Elicitation (KEL) is the most important stage,
but it is often the principal bottleneck in the
development of knowledge-based systems. Due to the
difficulties faced in the knowledge elicitation process,
development of a knowledge-based system for material
design in steel making industry is a complex task. An
attempt is made in this thesis to present a novel
approach to deal with knowledge elicitation for material
design problems in steel making industry. This research
centres around the human aspects and is based on
practical experience gained while developing a knowledge-
based system for material design at BHP Steel,
Australia. This approach involves codification of the
customer special requirements to identify the knowledge
sources involved in the design process. This is followed
by the use of paper models to improve the efficiency of
KEL process. The second stage of the structured
interviews is based on the customer special requirement
codes for eliciting the missing information and for
clarifying any ambiguities or inconsistencies. The
knowledge representation scheme developed for the
material design system aims at reducing the search time
and storage space by utilising the codification scheme
to classify various knowledge sources into appropriate
categories.
The thesis then presents the application of fuzzy logic
to the material design system to rank the alternative
steel making aim chemistries according to the degree
which will satisfy the customer's requirements of
chemistry and mechanical properties, which due
consideration given to the economic aspects and the
complexity involved in the production. Statistical data
regarding the performance of the grades produced in the
past are also utilised in this process.
Finally the thesis presents the development of an
interactive graphical user interface for a material
design knowledge-based system based on a three character
alphanumeric codification scheme for customer special
requirements. This user interface makes the material
design system more user friendly and enables error free
and fast input of the basic information and the customer
special requirements, corresponding to any customer
order for steel plates. (Abstract shortened by UMI.)
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  2857 </NUMBER>
<ORDER>   AAGC569820 </ORDER>
<TITLE> AN AGENT-BASED INTERACTIVE INSTRUCTION SYSTEM </TITLE>
<AUTHOR> MASTHOFF, JUDITH FRANCOISE MARIA </AUTHOR>
<YEAR> 1997 </YEAR>
<INSTITUTION> TECHNISCHE UNIVERSITEIT EINDHOVEN (THE NETHERLANDS); 0426 </INSTITUTION>
<DESCRIPTORS> COMPUTER SCIENCE; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> NIL </ADVISER>
<CLASSIFICATIONS> MACHINE LEARNING, ARTIFICIAL INTELLIGENCE </CLASSIFICATIONS>
<ABSTRACT>
This dissertation describes the design of an interactive
instruction system which adapts its behaviour to the
performance of the individual student. Central in the
dissertation is not the system itself, but an approach
for designing such a system: using, on the one hand,
existing models of human learning processes and, on the
other hand, experimental evaluation.
The design of an interactive instruction system can be
viewed as the design of an artificial teacher. The
difference between a good and a poor teacher is hardly
determined by a difference in domain knowledge, but
mainly by a difference in capability to adapt to the
students, an ability independent of the learning domain.
The purpose of this project has been to model these
general, domain independent aspects of teaching.
An approach has been chosen in which the domain
independent teacher is viewed as a highly autonomous
agent which can adapt its behaviour to the student. This
agent is composed of a collection of simpler agents,
which all represent a competence of a teacher. The
agents operate in parallel and have a close coupling
between their actions and their perception of the
environment (e.g., actions of the student and of the
other agents). From the interaction between the agents
and between the agents and their environment emerges the
adaptive functionality of a domain independent teacher.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  2858 </NUMBER>
<ORDER>   AAGC569758 </ORDER>
<TITLE> FUZZY CONTROL IN MANUFACTURING SYSTEMS </TITLE>
<AUTHOR> WANG, HONG GUANG </AUTHOR>
<YEAR> 1997 </YEAR>
<INSTITUTION> TECHNISCHE UNIVERSITEIT EINDHOVEN (THE NETHERLANDS); 0426 </INSTITUTION>
<DESCRIPTORS> ENGINEERING, SYSTEM SCIENCE; ARTIFICIAL INTELLIGENCE; ENGINEERING, INDUSTRIAL NETHERLANDS </DESCRIPTORS>
<ADVISER> NIL </ADVISER>
<CLASSIFICATIONS> NIL </CLASSIFICATIONS>
<ABSTRACT>
Because of the increasing international competition and
the increasing complexity of manufacturing systems,
production planning and control is becoming more and
more important for manufacturers besides the continuous
improvement of manufacturing technologies and innovation
of products. The economic pressures and the more general
commercial issues like demanding for increased product
variety, delivery performance, quality and reduced
inventory are drives that have led to the current
development in manufacturing technology and approaches
to manufacturing control. These current control
approaches are more or less developed on the basis of
experts' knowledge and operators' experience and are
subjected to further development in the course of time
when the manufacturing systems and their environment
change.
In recent years, the desire to make controllers more
autonomous and intelligent led to much attention being
paid to artificial intelligence methods, such as fuzzy
control and neural network, that are expected to be
successful. Fuzzy control theory which is based on the
fuzzy theory is supposed to have the ability to imitate
the human reasoning and thinking in control. Fuzzy
control provides an effective way to model operators' or
experts' controlling behaviour and experience which may
enable a computer to perform a good and flexible control
instead of human beings. Thus it might be a useful
technique for manufacturing system control.
In this thesis a broad investigation on the basis of
simulation experiments has been carried out in order to
provide an insight into the applicability of this
control concept in manufacturing systems.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  2859 </NUMBER>
<ORDER>   AAGC569623 </ORDER>
<TITLE> FUZZY MODELING AND IDENTIFICATION </TITLE>
<AUTHOR> BABUSKA, ROBERT </AUTHOR>
<YEAR> 1997 </YEAR>
<INSTITUTION> TECHNISCHE UNIVERSITEIT TE DELFT (THE NETHERLANDS); 0951 </INSTITUTION>
<DESCRIPTORS> ENGINEERING, ELECTRONICS AND ELECTRICAL; ARTIFICIAL INTELLIGENCE DELFT, THE NETHERLANDS NETHERLANDS </DESCRIPTORS>
<ADVISER> NIL </ADVISER>
<CLASSIFICATIONS> TAGAKI-SUGENO MODEL, PREDICTIVE CONTROL, CLUSTERING </CLASSIFICATIONS>
<ABSTRACT>
Fuzzy modeling has been recognized as a powerful
technique for the modeling of nonlinear, uncertain and
complex systems. Fuzzy models use if-then rules and
logical connectives to establish qualitative
relationships among the variables in the model. This
structure allows the use of qualitative information,
expressed in the form of natural language statements,
and makes the models transparent to interpretation and
analysis.
The main part of this thesis is devoted to the
acquisition of fuzzy models from numerical data. First
the structures of linguistic, relational, and Takagi-
Sugeno fuzzy models are presented. An extension of the
inference scheme in the Takagi-Sugeno model is proposed
to achieve better balance between a global numerical
accuracy of the model and the validity of the local
consequent models, with respect to the local behavior of
the modelled system.
Subsequently, methods are developed to automatically
generate fuzzy rule-based models from numerical
measurements. Fuzzy clustering with adaptive distance
measure is applied in the product space of the model
inputs and outputs to obtain an effective partitioning
of the data set and to generate the membership
functions. This technique can approximate complex
nonlinearities without requiring detailed prior
knowledge about the system. The relations between fuzzy
clustering and linear regression techniques are
highlighted.
To determine an appropriate number of clusters in the
data, validity measures are applied. In addition, a
compatible cluster merging technique has been developed,
which starts with a large number of clusters and
proceeds by successively merging geometrically similar
clusters, until a specified threshold is reached. In
order to enhance the interpretability of fuzzy models
generated from data, simplification and linguistic
approximation techniques based on fuzzy similarity
measures are applied.
Finally, control design based on a fuzzy model of a
nonlinear dynamic process is addressed, using the
concepts of model-based predictive control and internal
model control with an inverted fuzzy model. To this end,
a method to exactly invert a class of fuzzy models has
been developed. The use of a discrete optimization
scheme based on a branch-and-bound method is
investigated in the context of predictive control.
Three real-world applications are presented. By
combining expert knowledge with field measurements, a
linguistic fuzzy model is developed to predict the
performance and tool wear of a rock-excavation machine.
Identification by fuzzy clustering has been applied to
model highly nonlinear pressure dynamics in a laboratory
fermenter. Experimental results of real-time predictive
control based on the developed fuzzy model are
presented. A semi-mechanistic approach which combines an
available first-principle model with fuzzy
identification was used to develop a model for an
enzymatic penicillin G conversion process. This approach
results in an accurate prediction model which also
allows for qualitative interpretation of the unknown
relationships learnt from data.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  2860 </NUMBER>
<ORDER>   AAGC563908 </ORDER>
<TITLE> ANALYSIS OF ELECTROCARDIOGRAMS USING ARTIFICIAL NEURAL NETWORKS  </TITLE>
<AUTHOR> HEDEN, BO ERIK </AUTHOR>
<YEAR> 1997 </YEAR>
<INSTITUTION> LUNDS UNIVERSITET (SWEDEN); 0899 </INSTITUTION>
<DESCRIPTORS> BIOPHYSICS, MEDICAL; ENGINEERING, BIOMEDICAL; ARTIFICIAL INTELLIGENCE S-221 85 LUND,  SWEDEN </DESCRIPTORS>
<ADVISER> NIL </ADVISER>
<CLASSIFICATIONS> MYOCARDIAL INFARCTION </CLASSIFICATIONS>
<ABSTRACT>
Most conventional ECG interpretation programs use
decision tree logic for interpretation of the ECG. The
performance is generally good but can be improved.
Artificial neural networks represent a new computer
method, which has proved to be of value in pattern
recognition and classification tasks.
The purpose of the studies in this thesis was to improve
the analysis/interpretation of the 12-lead ECG by using
artificial neural networks. The input values to the
networks are extracted from the measurement section of a
commercially available interpretation program. No
special recording technique or devices have to be used.
The results show that artificial neural networks improve
computerized ECG interpretation for the diagnosis of
acute and healed myocardial infarction. They also
perform well in quality control of the ECG recordings by
detecting lead reversals with high sensitivity and
specificity.
The output values from an accurately trained neural
network can, under certain conditions, be regarded as a
posteriori probabilities for a diagnosis. The output
values can also be transformed to verbal statements
concerning different probability levels for healed
myocardial infarction. The agreement between these
probability estimates and those of an experienced
electrocardiographer was high.
The results indicate that artificial neural networks, if
properly trained and validated, will be a useful aid in
the attempt to improve the diagnostic yield of the 12-
lead ECG.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  2861 </NUMBER>
<ORDER>   AAGC547441 </ORDER>
<TITLE> CONSTRUCTION OF INTELLIGENT ALARM SYSTEMS USING MATHEMATICAL MODELS AND AUTOMATIC LEARNING TECHNIQUES </TITLE>
<AUTHOR> MULLER, LAMBIRTUS MICHAEL </AUTHOR>
<YEAR> 1997 </YEAR>
<INSTITUTION> TECHNISCHE UNIVERSITEIT EINDHOVEN (THE NETHERLANDS); 0426 </INSTITUTION>
<DESCRIPTORS> ENGINEERING, BIOMEDICAL; ARTIFICIAL INTELLIGENCE DOLECH 2, P.O. BOX 513, EH 8. 8,  NL-5600 M.B. EINDHOVEN, THE NETHERLANDS </DESCRIPTORS>
<ADVISER> NIL </ADVISER>
<CLASSIFICATIONS> MACHINE LEARNING, BREATHING CIRCUITS, AIRWAY RESISTANCE </CLASSIFICATIONS>
<ABSTRACT>
During this study it was investigated whether
intelligent alarm systems can be obtained automatically
from mathematical models, as an alternative for human
experts. As a problem domain monitoring of mechanical
ventilation of patients was chosen.
Two types of breathing circuits were modeled using the
PSPice simulation program: an open circuit and a semi-
closed circuit. These models comprise the lungs, the
airways, the breathing circuit tubes and the ventilator.
Gas flows, pressures and CO$sb2$ concentrations
throughout the breathing circuit can be simulated by
these models.
Breathing signals were simulated for a group of
'patients', during normal functioning of the breathing
circuit and during mishaps. Each patient was assigned a
unique airway resistance and lung/thorax compliance
value pair. Each breath was described by a set of signal
features and a label that constituted during which event
it was recorded. With an inductive machine learning
program classification trees were created from the
simulated data. Signals from 17 mechanically ventilated
animals were recorded. Leaks and obstructions were
introduced. Alarm systems were created, using simulated
patient data and the machine learning program. The
resulting classification trees, when tested with the
test animal data, detected 93 to 100% of all mishaps
correctly, while the false positive rates were low.
Generally, it can be concluded that the new technique of
developing intelligent alarm systems yields promising
results. The results that were obtained in the various
experiments are comparable with the results that were
obtained in other research projects where more
conventional techniques were used to develop intelligent
alarm systems.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  2862 </NUMBER>
<ORDER>   AAG9728574 </ORDER>
<TITLE> MODEL LEARNING WITH PROBABILISTIC NETWORKS </TITLE>
<AUTHOR> LIU, JUN </AUTHOR>
<YEAR> 1997 </YEAR>
<INSTITUTION> GEORGE MASON UNIVERSITY; 0883 </INSTITUTION>
<DESCRIPTORS> COMPUTER SCIENCE; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> KUO-CHU CHANG </ADVISER>
<CLASSIFICATIONS> ARTIFICIAL INTELLIGENCE, BAYESIAN NETWORKS, TARGET RECOGNITION </CLASSIFICATIONS>
<ABSTRACT>
A main purpose of this dissertation is to develop novel
learning algorithms for Bayesian networks. The
asymptotic convergency and computational feasibility of
the algorithms are addressed. The focus is on two types
of learning algorithms: the conditional independence
test based algorithms and the score metric based
algorithms. Theoretical properties of conditional
independence and asymptotic properties of the popular
score metrics are investigated. We show that three
different score metrics, the information criterion with
proper penalty functions, the MDL score, and the
Bayesian score are asymptotically consistent. We also
introduce a so-called local asymptotic property of the
score metrics. We then develop three basic local search
algorithms: the simple search (SS), the descent search
(DS), and the descent greedy search (DGS). With these
local search algorithms, we introduce several learning
algorithms that can be used in situations where partial
or no topological information is available. We have
proved that these algorithms will converge to a minimal
I-map of the underlying distribution as the sample size
of database approaches to infinity. The new algorithms
are tested and evaluated based on the simulated
databases with different sample sizes.
As an application, a general framework of using Bayesian
network in a feature-based automatic target recognition
(ATR) system is introduced. The problems such as feature
selection, network construction, parameter estimation,
and decision making are discussed and illustrated with
several examples. When applying a simple Bayesian
network model to a SAR image dataset, the performance
results indicate that new approach is better than the
traditional classifiers such as the nearest mean and the
Fisher pairwise. When discriminating objects using
featured data, the most difficult task is to select
useful features. We show that if the Bayesian network
model is learned from the training dataset using a
learning algorithm, the useful features can be
automatically selected through the learning process. The
results indicate that the learned model with
automatically selected features works better than an
assumed model with all features.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  2863 </NUMBER>
<ORDER>   AAG9728573 </ORDER>
<TITLE> THE DESIGN AND ANALYSIS OF A COMPUTATIONAL MODEL OF COOPERATIVE COEVOLUTION </TITLE>
<AUTHOR> POTTER, MITCHELL A. </AUTHOR>
<YEAR> 1997 </YEAR>
<INSTITUTION> GEORGE MASON UNIVERSITY; 0883 </INSTITUTION>
<DESCRIPTORS> COMPUTER SCIENCE; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> KENNETH A. DE JONG </ADVISER>
<CLASSIFICATIONS> GENETIC ALGORITHMS, MACHINE LEARNING </CLASSIFICATIONS>
<ABSTRACT>
As evolutionary algorithms are applied to the solution
of increasingly complex systems, explicit notions of
modularity must be introduced to provide reasonable
opportunities for solutions to evolve in the form of
interacting coadapted subcomponents. The difficulty
comes in finding computational extensions to our current
evolutionary paradigms in which such subcomponents
"emerge" rather than being hand designed. At issue is
how to identify and represent such subcomponents,
provide an environment in which they can interact and
coadapt, and apportion credit to them for their
contributions to the problem-solving activity such that
their evolution proceeds without human involvement.
We begin by describing a computational model of
cooperative coevolution that includes the explicit
notion of modularity needed to provide reasonable
opportunities for solutions to evolve in the form of
interacting coadapted subcomponents. In this novel
approach, subcomponents are represented as genetically
isolated species and evolved in parallel. Individuals
from each species temporarily enter into collaborations
with members of the other species and are rewarded based
on the success of the collaborations in solving
objective functions.
Next, we perform a sensitivity analysis on a number of
characteristics of decomposable problems likely to have
an impact on the effectiveness of the coevolutionary
model. Through focused experimentation using tunable
test problems chosen specifically to measure the effect
of these characteristics, we provide insight into their
influence and how any exposed difficulties may be
overcome.
This is followed by a study of the basic problem-
decomposition capability of the model. We show, within
the context of a relatively simple environment, that
evolutionary pressure can provide the needed stimulus
for the emergence of an appropriate number of
subcomponents that cover multiple niches, are evolved to
an appropriate level of generality, and can adapt to a
changing environment. We also perform two case studies
in emergent decomposition on complex problems from the
domains of artificial neural networks and concept
learning. These case studies validate the ability of the
model to handle problems only decomposable into subtasks
with complex and difficult to understand
interdependencies.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  2864 </NUMBER>
<ORDER>   AAG9728568 </ORDER>
<TITLE> EXTENDING AND REFINING KNOWLEDGE BASES WITH AN INTERACTIVE MULTISTRATEGY CONCEPT LEARNER </TITLE>
<AUTHOR> LEE, OCKKEUN </AUTHOR>
<YEAR> 1997 </YEAR>
<INSTITUTION> GEORGE MASON UNIVERSITY; 0883 </INSTITUTION>
<DESCRIPTORS> COMPUTER SCIENCE; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> GHEORGHE TECUCI </ADVISER>
<CLASSIFICATIONS> NIL </CLASSIFICATIONS>
<ABSTRACT>
This dissertation presents an interactive multistrategy
learner (MTLS) which extends and refines knowledge bases
by learning from input examples, discovering new
knowledge, and cooperating with a user. MTLS integrates
techniques from the fields of machine learning and
knowledge acquisition, exploiting their complementary
approaches to building knowledge bases.
MTLS is based on the multistrategy learning with
plausible justification trees approach (MTL-JT). MTLS
extends this approach to better deal with the problems
caused by incomplete and partially incorrect knowledge
bases. A goal-driven knowledge discovery method has been
developed and integrated into the MTL-JT approach to
produce additional knowledge needed by the system. MTLS
also allows a human expert to guide the learner to
refine and extend the knowledge base. This cooperation
between a human expert and the learner enables the
system to perform tasks that are intrinsically difficult
for an autonomous system.
Given a set of input examples and an incomplete and
partially incorrect knowledge base, MTLS learns a
concept definition and improves the knowledge base to
entail the concept definition. The resulting knowledge
base may include new rules discovered from data, as well
as revised rules, and new facts learned by analogy. MTLS
has been developed as a tool to be used by a domain
expert to build a knowledge base to reduce the need of
assistance from a knowledge engineer. Experiments
performed on an automobile domain with human subjects
demonstrate that MTLS has increased the accuracy of the
learned concept definition and improved the knowledge
base significantly.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  2865 </NUMBER>
<ORDER>   AAG9728567 </ORDER>
<TITLE> DOCUMENT ANALYSIS AND LABELLING SYSTEM </TITLE>
<AUTHOR> LE, DANIEL X. D. </AUTHOR>
<YEAR> 1997 </YEAR>
<INSTITUTION> GEORGE MASON UNIVERSITY; 0883 </INSTITUTION>
<DESCRIPTORS> COMPUTER SCIENCE; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> HARRY WECHSLER </ADVISER>
<CLASSIFICATIONS> IMAGING, ARTIFICIAL INTELLIGENCE </CLASSIFICATIONS>
<ABSTRACT>
This dissertation describes a system of new and robust
computer algorithms used to develop a Document Analysis
and Labelling System for conversion of paper-based
documents to electronic image format. The system
consists of three major components: preprocessing,
document analysis, and document labelling.
The preprocessing component is required for the system
to deal with a variety of document quality including
skewing and bordering. It detects the page orientation
(portrait/landscape), the page border areas, and the
page skew angle, removes the page border areas, and
rotates to correct skewed document page. Page
orientation is accomplished using local analysis, while
skew angle detection is based on the processing of
pixels of the last black runs of binary image objects.
The detection of border areas are relied upon the
classification of text/non-text rows and columns, the
smearing procedure, and objects' segmentation and the
analysis of projection profiles and cross counts.
The document analysis component segments the page into
blocks using an adaptive bottom-up approach and
classifies blocks as text blocks or non-text blocks
using neural network models. Four neural networks are
considered and they include back-propagation (BP),
radial basis functions (RBF), probabilistic neural
network (PNN), and Kohonen's self-organizing feature
maps (SOFM). The performance and behavior of these
neural network models are analyzed and compared in terms
of training times, memory requirements, and
classification accuracy.
The document labelling component detects the number of
page columns, the text orientation (up or down), the
reading order of the document, and provides the
meaningful labels for the contents of textual blocks
such as title, author, affiliation, header, footer, page
number, sections, and paragraphs. It is based on image
processing and a set of rules that is derived from
generic typesetting knowledge for English text.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  2866 </NUMBER>
<ORDER>   AAGMM11399 </ORDER>
<TITLE> PREDICTING HUMAN-CAUSED FOREST FIRE OCCURRENCE IN WHITECOURT FOREST, ALBERTA </TITLE>
<AUTHOR> VEGA GARCIA, CRISTINA </AUTHOR>
<YEAR> 1994 </YEAR>
<INSTITUTION> UNIVERSITY OF ALBERTA (CANADA); 0351 </INSTITUTION>
<DESCRIPTORS> AGRICULTURE, FORESTRY AND WILDLIFE; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> PAUL M. WOODARD </ADVISER>
<CLASSIFICATIONS> NIL </CLASSIFICATIONS>
<ABSTRACT>
The present study models the daily human-caused wildfire
occurrence in Whitecourt Forest, Alberta, using
geographic and temporal variables from the forest
environment. The main hypothesis in the study was that
the extent and location of fire-producing activities are
determined by the state of the forest environment at any
given time. The following variables were identified as
relevant to the human-caused fire problem: distance to
closest road, town, and campsite, elevation, fuel
category, land ownership, forest commerciality, and
location on a certain forest district, and Fire Weather
Index, Initial Spread Index, Build-Up Index, Fine Fuel
Moisture Code, Duff Moisture Code, relative humidity,
wind speed, and month. These variables were used for
building logit models and neural network predictive
models.
A binary logit model was successfully developed to
predict daily human-caused fire occurrence in eight fire
occurrence prediction units (all less than 5,000
km$sp2)$ in the Whitecourt Forest.
A back-propagation neural network model was developed to
predict the daily probability of fire occurrence in the
same eight fire occurrence prediction units.
The general conclusion of the study was that both logit
models and neural network models can be effectively used
for human-caused wildfire occurrence prediction.
(Abstract shortened by UMI.)
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  2867 </NUMBER>
<ORDER>   AAIMM98998 </ORDER>
<TITLE> A FLEXIBLE ROBOT CONTROL SYSTEM AND ITS APPLICATION TO LASER-BASED OBJECT RECOGNITION USING NEURAL NETWORKS </TITLE>
<AUTHOR> TYC, RICHARD </AUTHOR>
<YEAR> 1994 </YEAR>
<INSTITUTION> THE UNIVERSITY OF MANITOBA (CANADA); 0303 </INSTITUTION>
<DESCRIPTORS> ENGINEERING, MECHANICAL; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> S. BALAKRISHNAN </ADVISER>
<CLASSIFICATIONS> NIL </CLASSIFICATIONS>
<ABSTRACT>
An artificial neural network based object recognition
system was developed for robotic applications and
tested. This system was designed to recognize and then
determine an object's position and orientation within a
robot's working envelope by using a gripper mounted,
laser range finder. A flexible, microprocessor based,
robot control system, also developed as part of this
thesis, made this implementation possible. The new
control procedure provided effective multi-axis control
through a modular software design.
Two separate, neural networks were required to first
identify the object and, subsequently, to measure the
object's angular position or orientation. The
recognition involved extracting edge detection
information over specific regions of the object and
calculating a unique position and rotation invariant
feature pattern, which could be classified by the first
network. This procedure required a high resolution, line
scan image of the object. Object position was found by
calculating the centroid of the image whereas the
orientation was found by formulating a pattern of edge
detection time histories. A second neural network
provided a non-linear transformation of the resulting
pattern to form an output which was related directly to
the object's orientation.
By using a relatively low image resolution (98 laser
scans), object recognition successes of at least 99.9%
were achieved with relatively few training patterns and
teaching cycles. The methodology, however, assumes that
the object is known a priori to be one of several
different shapes through training of the first
'recognition' network. The second network was capable of
measuring an object's angular rotation to within 2-
9$spcirc$. Position accuracy was of the order of 1-5 mm
in trial tests. This level of performance is well suited
to many practical applications requiring intelligent
robot motion control in unstructured environments.
(Abstract shortened by UMI.)
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  2868 </NUMBER>
<ORDER>   AAG9728524 </ORDER>
<TITLE> INFERRING DNA STRUCTURES FROM SEGMENTATION AND SEQUENCE DATA VIA INTELLIGENT SEARCH </TITLE>
<AUTHOR> INGLEHART, JAMES ALMON </AUTHOR>
<YEAR> 1997 </YEAR>
<INSTITUTION> UNIVERSITY OF ILLINOIS AT CHICAGO; 0799 </INSTITUTION>
<DESCRIPTORS> COMPUTER SCIENCE; BIOLOGY, MOLECULAR; MATHEMATICS; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> PETER C. NELSON </ADVISER>
<CLASSIFICATIONS> ARTIFICIAL INTELLIGENCE, PATTERN RECOGNITION </CLASSIFICATIONS>
<ABSTRACT>
Using artificial intelligence search and pattern
recognition techniques, new algorithms and methods were
developed in two related areas of applied computer
science: automated DNA restriction mapping, and
automated DNA transcriptional enhancer element
detection.
Two general techniques, using (i) the Dempster-Shafer
theory of evidential reasoning, and (ii) a trained
neural network, were developed for finding plausible
solutions to systems of difference constraints, in cases
where the differences are the observed values of random
variables, instead of known constants.
A series of experimental restriction mapping algorithms
were designed, implemented, and tested. Additional
experimentation led to the development of an input
preprocessing module which significantly speeds up
searches, and an output post-processing module which
enables users to analyze large solution sets and reduce
their apparent complexity. These techniques were
incorporated into a powerful public domain multiple-
enzyme restriction mapping tool, Mapper, which will be
distributed via the World Wide Web.
A series of experimental neural networks were created,
to determine if neural networks could be trained to
recognize transcriptional enhancer elements. Networks
trained using $>$100 instances of a particular enhancer
performed well, and a methodology was developed for
producing enhancer-recognizing networks with an average
false negative rate on the order of 0.1%, and an average
false positive rate below 0.01%.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  2869 </NUMBER>
<ORDER>   AAG9728355 </ORDER>
<TITLE> A SEQUENTIAL MEMORY ADAPTIVE RESONANCE THEORY NEURAL NETWORK, WITH APPLICATION TO THREE-DIMENSIONAL OBJECT RECOGNITION </TITLE>
<AUTHOR> VOGH, JAMES WILLIAM </AUTHOR>
<YEAR> 1997 </YEAR>
<INSTITUTION> BOSTON UNIVERSITY; 0017 </INSTITUTION>
<DESCRIPTORS> ENGINEERING, ELECTRONICS AND ELECTRICAL; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> FRANK GUENTHER </ADVISER>
<CLASSIFICATIONS> NIL </CLASSIFICATIONS>
<ABSTRACT>
Learning, recognizing, and recalling sequences of
patterns is an important task for both humans and
machines. This dissertation describes a neural network
architecture that learns, recognizes, and recalls
sequences of patterns and also reproduces a wide range
of psychological and neurological data. The network
replicates the observed human behavior of learning
sequences in an unsupervised manner, recognizing a
sequence when part of the sequence is presented, and
recalling a sequence when part of the sequence is
presented or when a top-down representation of the
sequence is presented. The neural network architecture
is applied to the problem of 3-D object recognition and
achieves efficient performance by accumulating temporal
evidence and making choices at critical times.
The neural network, called SMART, is a synthesis of the
Adaptive Resonance Theory (ART) and a model of temporal
order memory that combines spatial pattern and
associative chain representations of temporal order. A
variety of psychological data are examined and explained
by the SMART model. Data from visual memory experiments
that investigate associations between temporally related
2-D images are explained by the model's associative
chain components. Timing patterns produced during list
recall experiments are explained by the combination of
the model's associative chain components and spatial
pattern components. Recognition scores from list recall
experiments are explained by the model's spatial pattern
components.
The SMART neural network model is applied to the problem
of 3-D object recognition from sequences of 2-D views of
aircraft. The SMART model is suited to the problem of 3-
D object recognition because of its temporal order
memory and its ability to detect an incorrect
categorization of an object. The performance of SMART is
evaluated under noise-free and noisy conditions and
compared to two similar neural network models, ART-EMAP
and the Aspect network. The SMART network scored 99.9%
correct under noise-free conditions and 99.9% and 99.3%
correct for five and ten percent noise respectively. ART-
EMAP gave the next best performance, with 97.7%, 96.7%,
and 92.1% correct for zero, five, and ten percent noise,
respectively.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  2870 </NUMBER>
<ORDER>   AAG9728076 </ORDER>
<TITLE> A UNIFIED APPROACH TO CONCEPT LEARNING </TITLE>
<AUTHOR> DOMINGOS, PEDRO MORAIS DELGADO </AUTHOR>
<YEAR> 1997 </YEAR>
<INSTITUTION> UNIVERSITY OF CALIFORNIA, IRVINE; 0030 </INSTITUTION>
<DESCRIPTORS> COMPUTER SCIENCE; STATISTICS; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> DENNIS F. KIBLER </ADVISER>
<CLASSIFICATIONS> RULE INDUCTION, INSTANCE-BASED LEARNING </CLASSIFICATIONS>
<ABSTRACT>
This dissertation proposes a unification of two leading
approaches to concept learning: rule induction and
instance-based learning.
Current rule induction algorithms based on the "separate
and conquer" paradigm suffer from the fragmentation of
the training set produced as induction progresses, and
from high error rates in rules covering few examples
(the "small disjuncts problem"). Current instance-based
learners are unable to select different attributes in
different regions of the instance space. The limitations
of either approach can be addressed by bringing in
elements of the other.
In this dissertation, the two paradigms are unified by
noting the relationship between the representations they
use, and introducing a new algorithm to learn concept
descriptions in the unified representation. Instances
and rules are unified syntactically by viewing instances
as maximally specific rules, and semantically by
allowing rules to match examples approximately. The RISE
algorithm learns rules by gradually generalizing
instances until no improvement in accuracy is obtained.
Theoretical analysis shows this approach to be efficient
and asymptotically optimal. An extensive empirical study
using benchmark datasets shows that RISE consistently
succeeds in improving on the predictive accuracy of its
parent paradigms, and also on the accuracy of state-of-
the-art decision tree learners. Lesion studies verify
that each of RISE's components is essential to its
performance. Studies in carefully controlled artificial
domains show that RISE's advantage relative to other
rule induction algorithms is at least partly due to its
ability to reduce the fragmentation and small disjuncts
problems, and that its advantage relative to other
instance-based learners is at least partly due to its
ability to select different attributes in different
regions of the instance space.
The application of RISE to large databases is made
possible through the use of sampling techniques, most
notably partitioning, which can sometimes simultaneously
reduce running time and improve accuracy. Finally, a
data mining algorithm based on RISE's "conquering
without separating" strategy is introduced, and shown to
have linear worst-case running time in all the relevant
parameters, while achieving accuracies at the level of
more expensive state-of-the art systems, producing much
simpler output, and being highly robust with respect to
noise.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  2871 </NUMBER>
<ORDER>   AAG9727686 </ORDER>
<TITLE> A NEURAL NETWORK BASED INFERENCE ENGINE GENERATOR FOR COMPREHENSION AND TRANSLATION OF ENGLISH AND SPANISH COMMANDS TO UNIX "E-MAIL" AND "VI" EDITOR </TITLE>
<AUTHOR> MOOZOUN, MOHAMMAD REZA </AUTHOR>
<YEAR> 1997 </YEAR>
<INSTITUTION> WEST VIRGINIA UNIVERSITY; 0256 </INSTITUTION>
<DESCRIPTORS> ENGINEERING, ELECTRONICS AND ELECTRICAL; COMPUTER SCIENCE; ARTIFICIAL INTELLIGENCE; LANGUAGE, LINGUISTICS </DESCRIPTORS>
<ADVISER> ROY S. NUTTER </ADVISER>
<CLASSIFICATIONS> NIL </CLASSIFICATIONS>
<ABSTRACT>
Since the advent of computers, scientists have tried to
use the human languages for communication with
computers. This pursuit has led several scientists, such
as Chomsky to establish that there must be a specific
part of the brain adapted to language learning and
processing genetically, namely the "language organ".
Humans are able to understand and produce sentences that
they may have never heard. This leads to the
understanding that language must follow some strict
rules of processing which is referred to as "grammar of
a language".
The Artificial Neural Networks (NN) inspired by the
neural networks of biological systems have inspired many
to attempt to solve many of the pattern recognition
problems which have been quite impossible or inefficient
to solve with today's computers. Many of the features of
NN have attracted a few to application of NN to process
natural language.
This research applies NN to natural language processing.
In this research the ART-1 and backpropagation networks
have been used to learn language. First, the intended
system learns simple phrases. Using the simple phrases
more complex phrases at a higher level are learned. The
phrases are used in various combinations to form
meaningful sentences. Thematic roles of the various
constituents are learned at the sentence level. From the
limited number of samples the system can successfully
produce the intermediate form of a sentence (deep
structure), which it has not encountered. Since the
computer languages and commands follow the same
structural rules as human language the same process is
applied to the most popular Unix "mail" and Unix "vi"
editor commands. The deep structure produced from
natural language is used to translate into computer
commands.
Since humans are capable of understanding incomplete
sentences, a system is devised using backpropagation NN
to correct and produce complete sentences from partially
incomplete sentences. The system fails to produce an
output if the incomplete sentence is incomprehensible
which corresponds to a meaningless sentence or a
sentence that has a correct syntactic form but incorrect
semantic form.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  2872 </NUMBER>
<ORDER>   AAG9727326 </ORDER>
<TITLE> ADVANCES IN INSTANCE-BASED LEARNING ALGORITHMS </TITLE>
<AUTHOR> WILSON, D. RANDALL </AUTHOR>
<YEAR> 1997 </YEAR>
<INSTITUTION> BRIGHAM YOUNG UNIVERSITY; 0022 </INSTITUTION>
<DESCRIPTORS> COMPUTER SCIENCE; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> TONY R. MARTINEZ </ADVISER>
<CLASSIFICATIONS> MACHINE LEARNING </CLASSIFICATIONS>
<ABSTRACT>
The nearest neighbor algorithm and its derivatives,
which are often referred to collectively as instance-
based learning algorithms, have been successful on a
variety of real-world applications. However, in its
basic form, the nearest neighbor algorithm suffers from
inadequate distance functions, large storage
requirements, slow execution speed, a sensitivity to
noise and irrelevant attributes, and an inability to
adjust its decision surfaces after storing the data.
This dissertation presents a collection of papers that
seek to overcome each of these disadvantages. The most
successful enhancements are combined into a
comprehensive system called the Integrated Decremental
Instance-Based Learning algorithm, which in experiments
on 44 applications achieves higher generalization
accuracy than other instance-based learning algorithms.
It also yields higher generalization accuracy than that
reported for 16 major machine learning and neural
network models.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  2873 </NUMBER>
<ORDER>   AAG9727193 </ORDER>
<TITLE> REINFORCEMENT LEARNING OF REACTIVE NAVIGATION FOR COMPUTER ANIMATION OF SIMULATED AGENTS </TITLE>
<AUTHOR> BECKET, WELTON MACDONALD </AUTHOR>
<YEAR> 1997 </YEAR>
<INSTITUTION> UNIVERSITY OF PENNSYLVANIA; 0175 </INSTITUTION>
<DESCRIPTORS> COMPUTER SCIENCE; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> NORMAN I. BADLER </ADVISER>
<CLASSIFICATIONS> BEHAVIORAL CONTROL, ARTIFICIAL INTELLIGENCE </CLASSIFICATIONS>
<ABSTRACT>
Behavioral control has been an effective method for
controlling low-level motion for autonomous agents.
However, one difficulty is the complexity of designing
behaviors and arbitration among behaviors for all but
the simplest navigation or motor control tasks. The
approach taken here applies reinforcement learning
techniques with delayed rewards to behavioral control,
building on existing approaches from robotics, computer
graphics, and machine learning by dealing with issues
specific to autonomous agents for computer animation. In
addition, behaviors are assumed to be part of a larger
architecture, such as a symbolic reasoner or task-
network system, so that the learning can focus on
problems for which behavioral control is most
appropriate.
Three learning approaches are first considered and
compared on two single-agent navigation problems where
agents have only local information through simulated
sensors. The first uses numerical optimization to find a
single configuration of parameters of behaviors. This
method is very fast and takes advantage of pre-defined
behaviors. However, it is conceptually limited because
it does not change parameters over time. The second
approach models the problem as a Markov Decision Process
(MDP) and finds a policy (a mapping from states to
actions) that directly learns behavior from delayed
reinforcement without the use of pre-defined behaviors.
This approach, though conceptually very powerful, is
extremely slow even when a generalization method is
applied. The third approach, behavior-parameter learning
(BP-learning), combines advantages of the first two
approaches by learning a policy from perceived state to
parameters of pre-defined behaviors using an MDP model:
it uses the second approach to schedule rather than
optimize the parameters of the first approach. This
solution is both powerful, due to varying parameters,
and quick, to converge because it takes advantage of pre-
defined behaviors.
The power of BP-learning for animation is then
demonstrated on a group navigation problem which is
extremely-difficult to solve by hand. Finally, all three
methods are found to be applicable in different
situations and can apply to other single-agent and group
navigation problems for computer animation.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  2874 </NUMBER>
<ORDER>   AAG9727132 </ORDER>
<TITLE> ADAPTIVE PROCESSING OF MULTIMEDIA: IMAGE UNDERSTANDING, VIDEO COMPRESSION AND COMMUNICATION </TITLE>
<AUTHOR> FENG, YUTAO </AUTHOR>
<YEAR> 1997 </YEAR>
<INSTITUTION> DUKE UNIVERSITY; 0066 </INSTITUTION>
<DESCRIPTORS> ENGINEERING, ELECTRONICS AND ELECTRICAL; COMPUTER SCIENCE; ARTIFICIAL INTELLIGENCE; INFORMATION SCIENCE </DESCRIPTORS>
<ADVISER> EROL GELENBE </ADVISER>
<CLASSIFICATIONS> NEURAL NETWORKS, CLASSIFICATION </CLASSIFICATIONS>
<ABSTRACT>
This dissertation is devoted to information processing
methods in multimedia systems. Our focus is on
information reduction because of various fundamental
considerations. Simplified representation of information
can help better understand data. Furthermore, reduced
information is essential to multimedia data storage and
transmission because of bandwidth and memory
limitations.
In particular, we present: (1) The results of our
research on image content classification using
artificial neural networks. (2) A new adaptive object
tracking and video compression system using the active
contour model. (3) A method for ATM network performance
evaluation with bursty traffic generated by multimedia
communication systems.
We design a novel image content classification method
that uses multiple recurrent random neural networks
(RNN) to classify different image contents by learning
their texture characteristics. The method is applied to
image segmentation of human brain magnetic resonance
images. Combined with rule based post-processing, our
method gives good quantitative results comparable to
manual segmentation by a human expert. The method can be
used for brain MRI tissue volume computation.
Current video conferencing systems suffer from lack of
bandwidth which results in inferior visual quality. We
propose an object oriented video compression system
aiming at more efficient usage of the available network
bandwidth.
We studied existing algorithms for identifying the
energy function, especially the energy terms in the
greedy algorithm that control the contour movements. By
recognizing the function of each energy term we improve
the performance of the active contour, e.g. the contour
can converge to desired irregular boundaries, and has
less computational complexity. The active contour
algorithm is used for the automatically tracking of the
region of interest in a video sequence, and adapt the
encoding and decoding process so that more bandwidth can
be allocated for more important part of the images. The
proposed method is implemented using the ITU H.263
standard. Our system achieves an average bit rate
reduction in the neighborhood of 30% over a range of
quality levels, and is especially effective at bit rate
of 100 kbps or higher.
Compressed video in general will tend to generate bursty
traffic over time because of the removal of temporal and
spatial redundancies, thus causing problems in the
communications network. We present a new method for
estimating cell loss ratio for multiclass bursty traffic
over the ATM switch, based on a diffusion model. Our
result gives a more accurate upper bound for cell loss
ratio compared with currently widely used schemes.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  2875 </NUMBER>
<ORDER>   AAG9726342 </ORDER>
<TITLE> BIOLOGICALLY INSPIRED NEURAL NETWORK CONNECTIONIST MODELS FOR USE IN ARTIFICIAL VISION SYSTEMS </TITLE>
<AUTHOR> ENKE, DAVID LEE </AUTHOR>
<YEAR> 1997 </YEAR>
<INSTITUTION> UNIVERSITY OF MISSOURI - ROLLA; 0135 </INSTITUTION>
<DESCRIPTORS> ENGINEERING, ELECTRONICS AND ELECTRICAL; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> CIHAN H. DAGLI </ADVISER>
<CLASSIFICATIONS> MACHINE VISION, IMAGE PROCESSING </CLASSIFICATIONS>
<ABSTRACT>
Within industry, artificial vision systems have proven
beneficial for a number of engineering and manufacturing
applications. Although at times successful, the
performance of these systems has been known to degrade
considerably in the presence of noise, and become
inflexible when encountering varying levels of image
information. As a result, it is not uncommon for these
systems to be dedicated to an isolated process, often in
a tightly controlled environment. Although advances have
been made to help overcome these difficulties, the
visual abilities of most artificial systems still pale
in comparison to those of humans. Fortunately, the human
visual system itself may offer the necessary knowledge
and structure for adding more versatility to existing
artificial systems.
Over the last thirty years a wealth of information has
surfaced regarding the components and structure of the
primate visual system. While this research has led to a
deeper understanding of the visual abilities and
limitations of humans, it has also provided researchers
with the knowledge necessary to construct models of the
cells and neural networks involved in vision. Therefore,
the task of the present research has been to extend this
effort by utilizing the existing knowledge of artificial
neural networks to redesign their structure and
component interactions to mimic what is currently known
about aspects of the human visual system.
To achieve this, the modeling of the visual system has
revolved around the brain regions involved in image
acquisition, filtering, edge detection, noise reduction,
feature detection, and visual attention. Knowledge from
each of these areas is used to develop simple
mathematical and computational models that can be easily
coded into a computer program and implemented into an
existing camera-based artificial vision system.
Implementation issues, including future areas of
research for biologically inspired neural models, are
also discussed.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  2876 </NUMBER>
<ORDER>   AAG9726250 </ORDER>
<TITLE> INTELLIGENT CONNECTIONIST PATTERN RECOGNITION SYSTEM: THE PARTIAL IMPLEMENTATION OF EXPERT NETVIS A USER- DRIVEN DATA EXPLORATION SYSTEM  </TITLE>
<AUTHOR> ALVAREZ, ENRIQUE HUMBERTO </AUTHOR>
<YEAR> 1997 </YEAR>
<INSTITUTION> UNIVERSITY OF LOWELL; 0111 </INSTITUTION>
<DESCRIPTORS> COMPUTER SCIENCE; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> CHARLES STEELE </ADVISER>
<CLASSIFICATIONS> NEURAL NETWORK, ARTIFICIAL INTELLIGENCE </CLASSIFICATIONS>
<ABSTRACT>
Pattern Recognition in Large Databases can be
implemented in a variety of ways which are reasonably
well understood. This thesis proposes a technique which
combines Artificial Intelligence (i.e., Knowledge-Based
Systems and Neural Networks) with Visualization
methodologies to aid the user in reducing the amount of
work required to explore, recognize, retrieve and/or
classify a large amount of data records when the user
does not have a clear definition in his/her mind of an
appropriate formulation for the identification and
classification of the patterns found in the dataset.
Recognizing and Visualizing Patterns found in a large
database of information brings into play many factors
which may help or hinder the desired outcome. The user
may want to be able to easily identify patterns in the
data through the use of neural networks. This process
may be enhanced through the use of a set of tools aimed
at identifying user-defined patterns and then
revisualizing the data. In effect this is a new
presentation of the originally visualized set of data,
but with added user-driven characteristics.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  2877 </NUMBER>
<ORDER>   AAG9726094 </ORDER>
<TITLE> NEURAL NETWORKS AND FUZZY CONTROL WITH APPLICATIONS TO TEXTILE MANUFACTURING AND MANAGEMENT </TITLE>
<AUTHOR> WU, PEITSANG </AUTHOR>
<YEAR> 1997 </YEAR>
<INSTITUTION> NORTH CAROLINA STATE UNIVERSITY; 0155 </INSTITUTION>
<DESCRIPTORS> OPERATIONS RESEARCH; ENGINEERING, ELECTRONICS AND ELECTRICAL; ARTIFICIAL INTELLIGENCE; TEXTILE TECHNOLOGY; ENGINEERING, INDUSTRIAL </DESCRIPTORS>
<ADVISER> SHU-CHERNG FANG; HENRY L. W. NUTTLE </ADVISER>
<CLASSIFICATIONS> NIL </CLASSIFICATIONS>
<ABSTRACT>
The objective of this dissertation is to develop
different algorithms for neural network training and
investigate the impacts of performances for these
algorithms. The resulting networks are then used in the
decision surface models in textile manufacturing and
management. Five different neural network models, namely
the "back propagation neural network" (BPNET), "BPNET
with fuzzy control" (BPNET-FC), "BPNET with curved
search method" (BPNET-CS), "BPNET-CS with a fuzzy
controller" (BPNET-CSFC) and, "BPNET-CS with the fuzzy
neuron controller" (BPNET-CSFNC) are investigated.
First, the traditional back propagation neural network
with delta learning is introduced. Later, to improve the
speed of network training, a fuzzy controller for the
learning rate is applied in the back propagation neural
network training. Then, a new learning algorithm using a
curved search method, which incorporates second-order
information, is investigated. A fuzzy controller for
choosing step size in the curve search algorithm is
added to replace the commonly used line search method.
Results obtained using the curved search method and the
fuzzy controller indicate a great potential for saving
computational time in the network training. Finally a
fuzzy neuron controller is incorporated in the BPNET-CS
to simplify the design process for the fuzzy controller.
Three small-scale and two larger textile real-life
examples are illustrated and discussed.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  2878 </NUMBER>
<ORDER>   AAIMM98938 </ORDER>
<TITLE> DEVELOPMENT OF AN ALGORITHM TO DETECT SUBSURFACE FRACTURES USING CONVENTIONAL WELL LOGS AND FUZZY INFERENCE: PRACTICAL APPLICATION AT THE TERRA NOVA OIL FIELD, OFFSHORE NEWFOUNDLAND </TITLE>
<AUTHOR> SHIMELD, JOHN WILLIAM </AUTHOR>
<YEAR> 1994 </YEAR>
<INSTITUTION> DALHOUSIE UNIVERSITY (CANADA); 0328 </INSTITUTION>
<DESCRIPTORS> GEOPHYSICS; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> MARK WILLIAMSON; MARCOS ZENTILLI </ADVISER>
<CLASSIFICATIONS> NIL </CLASSIFICATIONS>
<ABSTRACT>
It is implicit in many studies that subsurface fractures
are an integral part of the geologic processes that
occur in the Earth's crust; fractures are both a control
on and a result of fluid/rock interaction. Examples of
the importance of fractures are found in diverse areas
such as groundwater contaminant transport modelling,
studies of hydrothermal ore deposit genesis, prediction
of earthquake failure mechanisms, and hydrocarbon charge
modelling. Despite their importance, detection of
subsurface fractures remains a difficult problem for
geologists and geophysicists.
The algorithm developed in this thesis approaches the
problem through the use of conventional well logs, which
are usually the most readily available and detailed
source of fracture information. The use of conventional
well logs is not straightforward, though, since each
well logging tool responds to a different set of bulk
rock properties from the surrounding mass and no single
well log signature is diagnostic of fracturing.
Traditionally, fracture detection with conventional well
logs is a qualitative and subjective exercise that
relies upon the simultaneous interpretation of multiple
well logs. The fracture detection algorithm developed in
this thesis uses fuzzy inference as a tool to manage
uncertainty in well log interpretations, and to
calculate the relative likelihood of fracturing down the
length of a borehole in a uniform, automated, and semi-
quantitative manner.
The algorithm is tested using two case studies that
illustrate situations where conventional well logs are
suitable, and where they are not suitable, for fracture
detection. Then the Terra Nova oil field, located in the
Jeanne d'Arc Basin offshore Eastern Canada, is used as a
site for practical application of the fracture detection
algorithm. These re are integrated with interpretation
of 3D seismic data and fission track analysis to provide
a detailed description of fracturing and its influence
on fluid distribution at Terra Nova.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  2879 </NUMBER>
<ORDER>   AAG9726064 </ORDER>
<TITLE> MULTIMEDIA SENSOR FUSION FOR INTELLIGENT CAMERA CONTROL AND HUMAN-COMPUTER INTERACTION </TITLE>
<AUTHOR> GOODRIDGE, STEVEN GEORGE </AUTHOR>
<YEAR> 1997 </YEAR>
<INSTITUTION> NORTH CAROLINA STATE UNIVERSITY; 0155 </INSTITUTION>
<DESCRIPTORS> ENGINEERING, ELECTRONICS AND ELECTRICAL; COMPUTER SCIENCE; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> RONALD S. GYURCSIK; MICHAEL G. KAY </ADVISER>
<CLASSIFICATIONS> FUZZY, COMPUTER VISION, ACTIVE VISION </CLASSIFICATIONS>
<ABSTRACT>
This dissertation presents a novel technique for pixel-
level fusion of spatial sound and color information for
the detection and tracking of human beings, coupled with
a behavior-based camera control system. Such a system
can be used for videoconferencing, surveillance, and
human-computer-interaction applications that require
automatic camera control and/or machine perception of
people. Binaural sound localization is used to assist
the task of extracting faces from video images and to
turn the camera toward sound sources outside the current
field of view. A digital audio preprocessing technique
for developing onset signals from each microphone is
introduced. The time-domain cross-correlation between
these onset signals provides a sharp peak at the
interaural delay that corresponds to the target
location. The resulting peak is narrow enough to
distinguish multiple speaker locations without the
degree of ambiguity ordinarily present with cross-
correlation methods. Onset correlation and skin color
statistics are used jointly for the classification of
"talking face" and "background" pixels in the camera
image. Occasional classification and measurement errors
are compensated for by Kalman filtering and reactive
fuzzy control behaviors. The test system, which is based
on an ordinary personal computer, can automatically
point the camera at the person or persons speaking and
adjust the camera zoom as appropriate.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  2880 </NUMBER>
<ORDER>   AAG9726027 </ORDER>
<TITLE> THE SEMANTIC ANALYSIS OF MOTION BY NONLINEAR ESTIMATION METHODS  </TITLE>
<AUTHOR> SCHLENZIG, JENNIFER </AUTHOR>
<YEAR> 1997 </YEAR>
<INSTITUTION> UNIVERSITY OF CALIFORNIA, SAN DIEGO; 0033 </INSTITUTION>
<DESCRIPTORS> ENGINEERING, ELECTRONICS AND ELECTRICAL; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> RAMESH JAIN </ADVISER>
<CLASSIFICATIONS> COMPUTER VISION, ARTIFICIAL INTELLIGENCE </CLASSIFICATIONS>
<ABSTRACT>
The objective of motion understanding is to provide
computers with the ability to identify motions captured
by video cameras. The definition of what is a motion
varies across applications. For example, in a dance
application the motions could be the possible movements
(plie, pirouette, etc.) in ballet. A characteristic of
motions that does extend across applications is the fact
that they occur in the spatiotemporal domain where both
the evolving shape and the trajectory of the object can
be expressed. Motion understanding differs from the
classical problem of object tracking in that for
tracking, the output of the system is a trajectory
defining the position of the object in time. The output
of a motion understanding system is a sequence of
semantic labels (typically verbs) describing the motions
identified in the video sequence. Motivating the
development of motion understanding is the possibility
of applications such as computerized sports analysis,
immersive entertainment, intelligent surveillance
systems and intuitive machine interfaces.
Previous attempts at motion understanding have typically
concentrated on the interpretation of trajectories of
feature points which have been extracted from each
image, but common problems such as occlusion of the
features and changes in lighting conditions in the image
can hinder the feature finding algorithm. This requires
assumptions such as smoothness of motion which may not
necessarily be relevant. Once the trajectory has been
obtained, a measure of similarity must be found that
allows for the expected temporal and spatial variations
across instantiations of the motions while still
providing the necessary discrimination behavior.
The work presented here overcomes these difficulties.
Although for a given application object trajectories may
be important, and hence computed, there is no dependence
on trajectories for the purpose of motion understanding.
In fact, we are able to interpret the motions without
using any of the traditional motion analysis techniques
for image sequences. Instead, the determination of the
current motion relies on the symbol stream which is
extracted from the image sequence. The symbols are high
level descriptions of the object, and are less
susceptible to noise than low level features such as
edges and bright spots. This information is used to
update an estimate of the probability of occurrence for
each of the possible motions. The maximum probability is
then used to identify the current motion.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  2881 </NUMBER>
<ORDER>   AAG9725854 </ORDER>
<TITLE> LEARNING SITE-SETTLEMENT PATTERNS FROM LARGE SPATIO- TEMPORAL DATABASES WITH CULTURAL ALGORITHMS </TITLE>
<AUTHOR> NAZZAL, AYMAN HAMDAN </AUTHOR>
<YEAR> 1997 </YEAR>
<INSTITUTION> WAYNE STATE UNIVERSITY; 0254 </INSTITUTION>
<DESCRIPTORS> COMPUTER SCIENCE; ARTIFICIAL INTELLIGENCE; ANTHROPOLOGY, ARCHAEOLOGY </DESCRIPTORS>
<ADVISER> ROBERT REYNOLDS </ADVISER>
<CLASSIFICATIONS> OAXACA VALLEY, MEXICO, SOIL, MULTIPLE CRITERIA SPANNING, DECISION TREE </CLASSIFICATIONS>
<ABSTRACT>
This thesis demonstrates the feasibility of applying
Artificial Intelligence (AI) and data mining techniques
as reliable research tools towards the verification of
hypotheses derived from archeological or other research
and scientific works. Unraveling the mysteries that
still surround ancient civilizations poses a challenge
to the scientific mind, how best to treat their faint
traces to bring to light the underlying factors in their
development or to answer questions as those from
archaeologists and social scientists, as to how they
started, developed, and finally became extinct.
The solution to the scientific predicament of
discovering the past may be done through inference from
artifacts found at or taken from these human settlements
of antiquity. With the passage of time, these
settlements leave traces no matter how faint or
divergent which lend themselves to examination and
verification as to give a closer and clearer picture of
their existence. Data mining which is the process of
pooling together various types of data to determine
properties or characteristics of an object site is
highly reliable, particularly as databases from previous
works are used as bases herein.
These databases are subjected to a process of selection
or filtering through knowledge discovery which generate
networks of sites within a historical database of sites
for the Valley of Oaxaca. These networks are described
in terms of multiple criteria spanning trees (MC-MST)
computed by Cultural Algorithms with an evolutionary
programming shell. The results are used to explain
changes in site location decision-making over time in
the valley.
Three new procedures are introduced here. These are: (1)
increase in granularity of the site cells from the 4 x 4
kms to 1 x 1 km. for greater detail and accuracy (2)
Population formula, and (3) Corn Yield formula.
The site settlement survey catalogued over 2,700
archeological sites with each site described in terms of
over 125 physical, environmental, architectural, and
social variables. This range of variables were
classified into six categories or factors of which this
thesis focuses on two deemed most important in effecting
decisions to locate a new site, namely: the
environmental and soil productivity. The remaining four
factors are relegated to future work.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  2882 </NUMBER>
<ORDER>   AAG9725822 </ORDER>
<TITLE> KNOWLEDGE-BASED APPROACHES TO SELF-ADAPTATION IN CULTURAL ALGORITHMS  </TITLE>
<AUTHOR> CHUNG, CHAN-JIN </AUTHOR>
<YEAR> 1997 </YEAR>
<INSTITUTION> WAYNE STATE UNIVERSITY; 0254 </INSTITUTION>
<DESCRIPTORS> COMPUTER SCIENCE; MATHEMATICS; OPERATIONS RESEARCH; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> ROBERT G. REYNOLDS </ADVISER>
<CLASSIFICATIONS> FUZZY, EVOLUTIONARY COMPUTATION </CLASSIFICATIONS>
<ABSTRACT>
Cultural Algorithms are computational self-adaptive
models which consist of a population and a belief space.
Problem solving experience of individuals selected from
the population space by the acceptance function is
generalized and stored in the belief space. This
knowledge can then control the evolution of the
population component by means of the influence function.
Here, we examine the role that different forms of
knowledge can play in the self-adaptation process for
evolution-based function optimizers. In particular, we
compare various approaches using normative and
situational knowledge in guiding the search process.
Also we investigate the impact of different acceptance
and influence functions on the system's performance by
employing both static and flexible fuzzy approaches.
Evolutionary Programming is used to implement the
population space.
The best performance is produced using knowledge to
decide both step size and direction in most cases. In
addition, the use of a fuzzy acceptance and influence
function appears to be a promising one.
All the results in this study exhibit that Cultural
Algorithms are a naturally useful framework for self-
adaptation and that the use of a cultural framework to
support self-adaptation in Evolutionary Programming can
produce substantial performance improvements as
expressed in terms of (1) system success ratio, (2)
execution CPU time, and (3) convergence (mean best
solution) for a given set of function minimization
problems. The nature of these improvements and the type
of knowledge that is most effective in producing them
depends on the structure of the problem. While in most
cases, the best performance is produced using knowledge
to decide both step size and direction, there are
situations where controlling only the direction or the
step size produces the best results. Also normative
knowledge appears to be the dominant and general purpose
knowledge source for the optimization functions here.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  2883 </NUMBER>
<ORDER>   AAG9725369 </ORDER>
<TITLE> TOPICS IN COMPUTATIONAL HIDDEN STATE MODELING </TITLE>
<AUTHOR> YIANILOS, PETER NICHOLAS </AUTHOR>
<YEAR> 1997 </YEAR>
<INSTITUTION> PRINCETON UNIVERSITY; 0181 </INSTITUTION>
<DESCRIPTORS> COMPUTER SCIENCE; STATISTICS; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> NIL </ADVISER>
<CLASSIFICATIONS> MACHINE INTELLIGENCE, STOCHASTIC, SPEECH RECOGNITION, GAUSSIAN MIXTURES, ASSEMBLY LANGUAGE, OPTIMIZATION, IMAGE MODELING </CLASSIFICATIONS>
<ABSTRACT>
Motivated by the goal of establishing stochastic and
information theoretic foundations for the study of
intelligence and synthesis of intelligent machines, this
thesis probes several topics relating to hidden state
stochastic models.
Finite Growth Models (FGM) are introduced. These are
nonnegative functionals that arise from parametrically-
weighted directed acyclic graphs and a tuple observation
that affects these weights. Using FGMs the parameters of
a highly general form of stochastic transducer can be
learned from examples, and the particular case of
stochastic string edit distance is developed.
Experiments are described that illustrate the
application of learned string edit distance to the
problem of recognizing a spoken word given a phonetic
transcription of the acoustic signal. With FGMs one may
direct learning by criteria beyond simple maximum-
likelihood. The MAP (maximum a posteriori estimate) and
MDL (minimum description length) are discussed along
with the application to causal-context probability
models and unnormalized noncausal models. The FGM
framework, algorithms, and data structures describe
hidden Markov models, stochastic context free grammars,
and many other conventional similar models while
providing a unified and natural way for computer
scientists to learn and reason about them and their many
variations. A software system and scripting language is
proposed to serve as an assembly language or sorts for
many higher level model types.
This thesis also illuminates certain fundamental aspects
of the nature of normal (Gaussian) mixtures and the
reparameterization of related optimization problems. The
use of conditional normal mixtures is proposed as a tool
for image modeling, and issues relating to the
estimation of their parameters are discussed.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  2884 </NUMBER>
<ORDER>   AAG9725346 </ORDER>
<TITLE> FAULT-IMMUNIZED STATE OBSERVER AND FUZZY DECISION-MAKING FOR DYNAMIC-SYSTEM FAULT DIAGNOSIS </TITLE>
<AUTHOR> WANG, XIANZHONG </AUTHOR>
<YEAR> 1997 </YEAR>
<INSTITUTION> ARIZONA STATE UNIVERSITY; 0010 </INSTITUTION>
<DESCRIPTORS> ENGINEERING, ELECTRONICS AND ELECTRICAL; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> KEITH E. HOLBERT </ADVISER>
<CLASSIFICATIONS> ARTIFICIAL NEURAL NETWORK </CLASSIFICATIONS>
<ABSTRACT>
More and more large dynamic processes with a high degree
of automation demand that an on-line fault diagnosis
function is incorporated into their supervision and
monitoring system. In this dissertation, research
literature on fault diagnosis since the 1970s are
reviewed, and, to contribute to this area, new
techniques have been invented. A new state and fault
observer is developed for dynamic systems with discrete
time stochastic models. This observer is able to give
unbiased state estimates even in the presence of target
faults. The fuzzy decision making is developed to remove
the hard boundaries of hypothesis tests. It also
provides a way to take advantage of experts' knowledge
about the process and fault. Some improvements to state-
of-the-art techniques are made and included in the fault
diagnosis system to increase its effectiveness. An
improvement to the parity space approach is proposed for
redundant sensor management systems, and it is more
robust than the original parity space algorithm to
noises in the sensors. For general dynamic systems, a
Kalman filter and Rauch-Tung-Striebel smoother
combination is proposed to extract the fault information
from the measurements and control signals. All of the
above fault detection and isolation methods are applied
to a dynamic fault diagnosis system designed for a power
plant boiler model. Biased sensor, noisy sensor, biased
control actuators, and waterwall leakage faults are
simulated, and successfully detected and isolated.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  2885 </NUMBER>
<ORDER>   AAG9725194 </ORDER>
<TITLE> ADDING INTELLIGENCE TO THE CONTROL OF MOBILE MANIPULATORS: A COMPARATIVE STUDY </TITLE>
<AUTHOR> SON, CHANG MAN </AUTHOR>
<YEAR> 1997 </YEAR>
<INSTITUTION> GEORGIA INSTITUTE OF TECHNOLOGY; 0078 </INSTITUTION>
<DESCRIPTORS> ENGINEERING, ELECTRONICS AND ELECTRICAL; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> JOHN F. DORSEY </ADVISER>
<CLASSIFICATIONS> ASSEMBLY, ROBOTS, NEURAL NETWORKS, FUZZY CONTROL </CLASSIFICATIONS>
<ABSTRACT>
The proposed research addresses the problem of part
assembly. This process can be broken down into macro-
assembly, bringing the part to a target, and micro-
assembly, mating the part with a socket or receptacle.
The distinguishing feature of the robotic control
developed in this research is part assembly in unknown
or uncertain environments, that is, environments that
contain obstacles whose size and location are not
initially known. To cope with such an environment
requires that the control strategies have a high degree
of artificial intelligence. This intelligence in large
part depends upon the ability of the control strategy to
improve with time, that is, to learn. One of the popular
methods of incorporating learning is via neural
networks. Intelligence, and to a lesser degree learning,
can also be incorporated using fuzzy set theory and
fuzzy control. The proposed research uses both neural
networks and fuzzy control. One of the main goals of
this research is to determine how best to combine,
conventional control with other forms of control, such
as neural networks and fuzzy control. Another main goal
of the research is to explore and clarify the concept of
learning in artificial intelligence. Another
distinguishing feature of this research is the
incorporation of a cost function, based on fuzzy
entropy, to provide a measure of optimality of the
control. The addition of the cost function proves very
fruitful. For example, its presence enhances the
learning capabilities of several of the algorithms. Two
final goals of the research are to investigate how
different assembly strategies can benefit from sensor
fusion and to determine which of the strategies are most
compatible with hierarchical control.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  2886 </NUMBER>
<ORDER>   AAG9725186 </ORDER>
<TITLE> A DESIGN METHODOLOGY FOR THE CONFIGURATION OF BEHAVIOR- BASED MOBILE ROBOTS </TITLE>
<AUTHOR> MACKENZIE, DOUGLAS CHRISTOPHER </AUTHOR>
<YEAR> 1997 </YEAR>
<INSTITUTION> GEORGIA INSTITUTE OF TECHNOLOGY; 0078 </INSTITUTION>
<DESCRIPTORS> COMPUTER SCIENCE; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> RONALD C. ARKIN </ADVISER>
<CLASSIFICATIONS> NIL </CLASSIFICATIONS>
<ABSTRACT>
Behavior-based robotic systems are becoming both more
prevalent and more competent. However, operators lacking
programming skills are still forced to use canned
configurations hand-crafted by experienced roboticists.
This inability of ordinary people to specify tasks for
robots is inhibiting the spread of robots into everyday
life. Even expert roboticists are unable to share
solutions in executable forms since there is no
commonality of configuration descriptions. Further, a
configuration commonly requires significant rework
before it can be deployed on a different robot, even one
with similar capabilities. The research documented in
this dissertation attacks this problem from three
fronts.
First, the foundational Societal Agent theory is
developed to describe how agents form abstract
structures at all levels in a recursive fashion. It
provides a uniform view of agents, no matter what their
physical embodiment. Agents are treated consistently
across the spectrum, from a primitive motor behavior to
a configuration coordinating large groups of robots. The
recursive nature of the agent construction facilitates
information hiding and the creation of high-level
primitives.
Secondly, the MissionLab toolset is developed which
supports the graphical construction of architecture- and
robot-independent configurations. This independence
allows users to directly transfer designs to be bound to
the specific robots at the recipient's site. The
assemblage construction supports the recursive
construction of new coherent behaviors from coordinated
groups of other behaviors. This allows users to build
libraries of increasingly high-level primitives which
are directly tailored to their needs. MissionLab support
for the graphical construction of state-transition
diagrams allows use of temporal sequencing to partition
a mission into discrete operating states, with
assemblages implementing each state. Support for
multiple code generators (currently existing for AuRA
and SAUSAGES) ensures that a wide variety of robots can
be supported.
Finally, specific usability criteria for toolsets such
as MissionLab are established. Three usability studies
are defined to allow experimental establishment of
values for these criteria. The results of carrying out
these studies using the MissionLab toolset are
presented, confirming its benefits over conventional
techniques.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  2887 </NUMBER>
<ORDER>   AAG9724979 </ORDER>
<TITLE> A COMBINED ARTIFICIAL INTELLIGENCE APPROACH TO ANESTHESIA-RELATED OPERATING ROOM SAFETY MONITORING </TITLE>
<AUTHOR> PATTERSON, DUANE LEONARD </AUTHOR>
<YEAR> 1997 </YEAR>
<INSTITUTION> VANDERBILT UNIVERSITY; 0242 </INSTITUTION>
<DESCRIPTORS> ENGINEERING, BIOMEDICAL; ENGINEERING, ELECTRONICS AND ELECTRICAL; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> NIL </ADVISER>
<CLASSIFICATIONS> NIL </CLASSIFICATIONS>
<ABSTRACT>
Several systems have been developed in recent years
investigating the application of artificial intelligence
techniques to the problem of patient safety monitoring
in the setting of general anesthesia. Detection of
breathing circuit faults has been the main focus of
these studies since simulated data for system
development and test are relatively easy to obtain.
However, the concepts developed and the lessons learned
are also directly applicable to the detection and early
warning of physiologic problems.
These former studies have all used airway waveforms as
the data source, typically, airway pressure and flow and
CO$sb2$ concentration. However, two separate development
tracks have been maintained in the past. There have been
expert system designs which maintain a knowledge base
and use an inference algorithm to search the knowledge
base. These systems diagnose a problem through a logical
sequence of data gathering and hypothesis review. Other
designs have used the connectionist models of artificial
neural networks which learn by training to classify new
events which are similar to those used for training.
This dissertation describes a system which combines both
an expert system and artificial neural networks to
cooperatively diagnose and locate a fault when one of
fourteen possible breathing circuit faults is induced.
This system also investigates the use of additional
instrumentation in the breathing circuit for its
effectiveness in localizing faults.
Another new area of investigation is the use of wavelet
transform coefficients as the input to the neural
networks instead of using features extracted from the
airway waveforms. Ninety-three percent of 998 fault
patterns were correctly diagnosed using this approach.
This dissertation also describes a statistical
discriminant analysis of a common set of extracted
features used in past studies. The purpose was to
determine which of that set of 28 features are most
important for classification of fault events.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  2888 </NUMBER>
<ORDER>   AAG9724746 </ORDER>
<TITLE> SELECTION OF DISTANCE METRICS AND FEATURE SUBSETS FOR K- NEAREST NEIGHBOR CLASSIFIERS </TITLE>
<AUTHOR> BARKER, ALLEN LAWRENCE </AUTHOR>
<YEAR> 1997 </YEAR>
<INSTITUTION> UNIVERSITY OF VIRGINIA; 0246 </INSTITUTION>
<DESCRIPTORS> COMPUTER SCIENCE; STATISTICS; ENGINEERING, SYSTEM SCIENCE; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> NIL </ADVISER>
<CLASSIFICATIONS> NEURAL NETWORK, PATTERN CLASSIFICATION </CLASSIFICATIONS>
<ABSTRACT>
The k-nearest neighbor (kNN) classifier is a popular and
effective method for associating a feature vector with a
unique element in a known, finite set of classes. A
common choice for the distance metric used in kNN
classification is the quadratic distance $Q(x, A, y) =
(x - y)spprime A(x - y)$, where x and y are n-vectors of
features, A is a symmetric $n times n$ matrix, and prime
denotes transpose. For finite sets of training samples
the choice of matrix A is important in optimizing
classifier performance. We show that A can be
approximately optimized via gradient descent on a
sigmoidally smoothed estimate of the classifier's
probability of error. We describe an algorithm for
performing the metric selection, and compare the
performance of our method with that of other methods. We
demonstrate that adding noise during the descent process
can reduce the effects of overfitting. We further
suggest how feature subset selection can be treated as a
special case of this metric selection.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  2889 </NUMBER>
<ORDER>   AAIMM98730 </ORDER>
<TITLE> RESEAU EXPERT POUR GERER LE PROCESSUS ITERATIF DE CONCEPTION DE RESEAUX DE NEURONES ARTIFICIELS UTILISANT LA RETROPROPAGATION STANDARD  </TITLE>
<AUTHOR> MICHAUD, FRANCOIS </AUTHOR>
<YEAR> 1994 </YEAR>
<INSTITUTION> UNIVERSITE DE SHERBROOKE (CANADA); 0512 </INSTITUTION>
<DESCRIPTORS> ENGINEERING, ELECTRONICS AND ELECTRICAL; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> RUBEN GONZALEZ-RUBIO </ADVISER>
<CLASSIFICATIONS> FRENCH TEXT </CLASSIFICATIONS>
<ABSTRACT>
Les reseaux de neurones artificiels (RNA) prouvent de
plus en plus leur utilite a resoudre des problemes
complexes, difficilement traitables par les techniques
courantes comme les systemes experts ou les modeles
mathematiques traditionnels. En employant une structure
similaire a celle du systeme nerveux et de ses neurones,
un RNA vient etablir une fonction de correspondance
entre un domaine d'entree et un domaine de sortie par
l'apprentissage de donnees typiques de l'application a
traiter. Cependant, leur conception demande un certain
nombre d'essais afin de fixer les differentes
caracteristiques de structure et d'apprentissage du RNA.
Ces iterations sont habituellement fonction de
l'expertise et de l'intuition du concepteur. Il serait
interessant de laisser la gestion de ces iterations a un
systeme automatique capable de poser les choix adequats
pour optimiser la conception de RNA. Ce memoire presente
un reseau expert, compose d'un systeme expert et d'un
simulateur de RNA, qui prend en charge le processus
iteratif de conception de RNA. Le systeme expert soumet
des demandes de simulation a un simulateur logiciel de
RNA. Ce dernier fournit les resultats utiles au systeme
expert pour qu'il puisse, en fonction des specifications
de l'application a traiter, trouver un RNA capable
d'etablir correctement la fonction de correspondance
souhaitee. Bien qu'un tel systeme devrait etre capable
de gerer l'apprentissage de plusieurs lois
d'apprentissage, les travaux se sont limites a la
gestion d'une seule loi, soit la retropropagation
standard. Toutefois, la conception du systeme tient
compte de la possibilite d'etendre facilement ses
fonctionnalites a de nouvelles lois et de nouvelles
techniques de gestion pour la conception de RNA.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  2890 </NUMBER>
<ORDER>   AAG9724346 </ORDER>
<TITLE> NEURAL NETWORKS FOR APPROXIMATION AND CONTROL OF CONTINUOUS TIME NONLINEAR SYSTEMS </TITLE>
<AUTHOR> LUZARDO-FLORES, JOSE ALBERTO </AUTHOR>
<YEAR> 1997 </YEAR>
<INSTITUTION> THE CLAREMONT GRADUATE SCHOOL; 0047 </INSTITUTION>
<DESCRIPTORS> ENGINEERING, SYSTEM SCIENCE; ENGINEERING, ELECTRONICS AND ELECTRICAL; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> ANASTASSIOS CHASSIAKOS; ROBERT WILLIAMSON </ADVISER>
<CLASSIFICATIONS> NIL </CLASSIFICATIONS>
<ABSTRACT>
This dissertation deals with the approximation and
control of continuous time nonlinear systems using two-
layers neural networks (NNs). For the first part of the
dissertation (dynamical approximation), we introduce the
concept of "dynamical system representation" to point
out that a complete dynamical system approximation must
involve two aspects: the trajectory approximation itself
and the duplication of the orbit structure. The latter
aspect implies that both the original system and its
approximation must be topologically equivalent in a
compact subset of the state space. The topological
equivalence guarantees that the NN approximation will
duplicate the state space portrait (orbit structure),
having the same qualitative features as the original
system in the region where the approximation is valid.
Furthermore, we introduce the concept of dynamical
neural networks (DNNs) as an alternative to recurrent
neural networks (RNNs) for dynamical approximation. We
consider different classes of dynamical systems to be
represented by DNNs: scalar systems, conservative
systems and gradient systems. In these cases the
dynamical representation is achieved due to the NN
capabilities of (a) approximating functions and their
derivatives, and (b) matching functions and their
derivatives at isolated points. The dynamical
representation captures the intrinsic features of the
original state space portrait, leading to an overall
trajectory approximation.
The second part of this dissertation is on the control
of continuous time nonlinear systems. The results of the
first part of the dissertation suggest that a linearly
parameterized NN approximation model is sufficient to
duplicate the structural properties of a stable control
system. This linear model with respect to the parameters
allows us to use Lyapunov techniques to prove the
convergence of the two adaptive neural network
controllers (NNCs) proposed in this dissertation. These
NNCs are formulated for linear and nonlinear systems.
The proposed adaptive NNCs are simple because they do
not require an accurate approximation of the plant, but
rather of some hypothetical controller not needed to be
known. The proposed NNCs need relatively few neurons.
This simplification makes the proposed NNCs susceptible
of being implemented in real time.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  2891 </NUMBER>
<ORDER>   AAG9722562 </ORDER>
<TITLE> A FRAMEWORK FOR THE DESIGN OF A VOICE-ACTIVATED, INTELLIGENT, AND HYPERMEDIA-BASED AIRCRAFT MAINTENANCE MANUAL </TITLE>
<AUTHOR> PATANKAR, MANOJ SHASHIKANT </AUTHOR>
<YEAR> 1997 </YEAR>
<INSTITUTION> NOVA SOUTHEASTERN UNIVERSITY; 1191 </INSTITUTION>
<DESCRIPTORS> COMPUTER SCIENCE; ARTIFICIAL INTELLIGENCE; ENGINEERING, AEROSPACE; ENGINEERING, ELECTRONICS AND ELECTRICAL </DESCRIPTORS>
<ADVISER> GERTRUDE W. ABRAMSON </ADVISER>
<CLASSIFICATIONS> SMART MANUAL, SPEECH INPUT, EXPERT SYSTEMS </CLASSIFICATIONS>
<ABSTRACT>
Federal Aviation Regulations require Aviation
Maintenance Technicians (AMTs) to refer to approved
maintenance manuals when performing maintenance on
airworthy aircraft. Because these manuals are paper-
based, larger the size of the aircraft, more cumbersome
are the manuals. Federal Aviation Administration (FAA)
recognized the difficulties associated with the use of
large manuals and conducted studies on the use of
electronic media as an alternative to the traditional
paper format. However, these techniques do not employ
any artificial intelligence technologies and the user
interface is limited to either a keyboard or a stylus
pen. The primary emphasis of this research was to design
a generic framework that would allow future development
of voice-activated, intelligent, and hypermedia-based
aircraft maintenance manuals. A prototype (VIHAMS--Voice-
activated, Intelligent, and Hypermedia-based Aircraft
Maintenance System) was developed, as a secondary
emphasis, using the design and development techniques
that evolved from this research.
An evolutionary software design approach was used to
design the proposed framework and the structured rapid
prototyping technique was used to produce the VIHAMS
prototype. VoiceAssist by Creative Labs was used to
provide the voice interface so that the users (AMTs)
could keep their hands free to work on the aircraft
while maintaining complete control over the computer
through discrete voice commands. KnowledgePro for
Windows $rmsp0TM,$ an expert system shell, provided
"intelligence" to the prototype. As a result of this
intelligence, the system provided expert guidance to the
user. The core information contained in conventional
manuals was available in a hypermedia format. The
prototype's operating hardware included a notebook
computer with a fully functional audio system. An
external microphone and the built-in speaker served as
the input and output devices (along with the color
monitor), respectively.
Federal Aviation Administration estimates the United
States air carriers to operate 3,991 large jet aircraft
in the year 1996 (FAA Aviation Forecasts, 1987-1998).
With an estimate of seventy manuals per such aircraft,
the development of intelligent manuals is expected to
impact 279,370 manuals in this country. Soon, over 55
thousand maintenance technicians will be able to carry
the seven pound system to an aircraft, use voice
commands to access the aircraft's files on the system,
seek assistance from the expert system to diagnose the
fault, and obtain instructions on how to rectify the
fault.
The evolutionary design approach and the rapid
prototyping techniques were very well suited for the
spiral testing strategy. Therefore, this strategy was
used to test the structural and functional validity of
this research. Professors Darrell Anderson and Brian
Stout (Aviation faculty at San Jose State University)
and Mr. Gregory Shea (a United Airlines mechanic and
SJSU student) are representatives of the real-world
users of the final product. Therefore, they conducted
the alpha test of this prototype. Mr. Daniel Neal and
Mr. Stephen Harms have been actively involved in light
aircraft maintenance for more than ten years. They
evaluated the prototype's usability. All the above
evaluators used standard testing tools and evaluated the
prototype under field conditions.
The evaluators concluded that the VIHAMS prototype used
a valid fault diagnosis strategy, the system
architecture could be used to develop similar systems
using off-the-shelf tools, and the voice input system
could be refined to improve its usability.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  2892 </NUMBER>
<ORDER>   AAG9728031 </ORDER>
<TITLE> A TEMPORAL EXTENSION AND FRAMEWORK FOR EXPERT SYSTEMS WITH APPLICATIONS FOR WORKFLOW MANAGEMENT SYSTEMS </TITLE>
<AUTHOR> CHINN, SUSAN JANET </AUTHOR>
<YEAR> 1997 </YEAR>
<INSTITUTION> KENT STATE UNIVERSITY; 0101 </INSTITUTION>
<DESCRIPTORS> BUSINESS ADMINISTRATION, MANAGEMENT; COMPUTER SCIENCE; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> GREGORY R. MADEY </ADVISER>
<CLASSIFICATIONS> NIL </CLASSIFICATIONS>
<ABSTRACT>
Many management problems that lend themselves to an
expert system solution include "time" as a problem
dimension, yet expert system requirements for temporal
application categories such as monitoring and planning
have not been enumerated and analyzed for business
applications. This dissertation presents a framework for
systems developers in business to use when selecting or
using an expert system shell for temporal problems. We
describe the framework in terms of the requirements for
temporal expert systems and the problems that meeting
some of these requirements produce. We expand the
framework by evaluating features that support temporal
requirements in expert systems that are either currently
available or are in development. We demonstrate the use
of the framework by applying it to an in-depth analysis
of a particular expert system shell, CLIPS (C Language
Integrated Production System).
As a corollary of our efforts to develop a framework, we
built an extension to CLIPS for temporal representation
and reasoning. Our extension, which generates temporal
relations among facts in the knowledge base, simplifies
program development by reducing the number of constructs
that would otherwise be necessary to support temporal
representation. We evaluate the effectiveness of the
extension by comparing it to a version of the same
application written without the extension.
Workflow management has a strong temporal aspect.
Temporal expert systems, which use knowledge-based
constructs to represent and reason about time, can be
used to enhance the capabilities of workflow software.
Our temporal expert system component of a workflow
system uses our extension to enhance the decision-
making, timing, and routing activities in the
engineering design change review process.
This dissertation makes several contributions. First, it
develops a framework for temporal expert systems from a
synthesis and analysis of AI efforts that can be of use
to developers and managers in business. Second, it
presents an extension to an expert system shell that
"automatically" generates temporal facts. Third, it
demonstrates how the results of temporal representation
and reasoning can be applied to an engineering
management workflow scenario.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  2893 </NUMBER>
<ORDER>   AAG9724345 </ORDER>
<TITLE> KNOWLEDGE BASE CLUSTERING FOR KBS MAINTENANCE </TITLE>
<AUTHOR> LEE, OOK </AUTHOR>
<YEAR> 1997 </YEAR>
<INSTITUTION> THE CLAREMONT GRADUATE SCHOOL; 0047 </INSTITUTION>
<DESCRIPTORS> BUSINESS ADMINISTRATION, GENERAL; COMPUTER SCIENCE; INFORMATION SCIENCE; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> NIL </ADVISER>
<CLASSIFICATIONS> RULE BASE </CLASSIFICATIONS>
<ABSTRACT>
Software Engineering provides many tools for maintenance
of the conventional software such as code scanner,
program analyzer, and code dictionary. Unfortunately,
very few tools exist that aid Knowledge-Based System
(KBS) maintenance. This dissertation presents tools that
can aid the maintainer in maintaining KBS.
The first tool is the Rule Base Clusterizer (RBC) which
structures the rule base to make it appear easy to
understand for the maintainer. The maintainer's first
job is to understand the rules in the KBS just as the
maintainer of conventional software tries to understand
the program code before taking action. Clustering rules
based on their static distance (lexical information) are
a good way of structuring the rule base to make it easy
to understand in the mind of the maintainer. The
clustering algorithm is based on the Hopfield Net
Algorithm, a variation of a neural net algorithm, which
clusters automatically based on lexical similarity.
This dissertation demonstrates that the quantity of
information increases with cluster size by using the
entropy concept. At the same time, using the limit of
human cognition (Miller's magic number), the
dissertation shows that increasing cluster size produces
clusters that are beyond easy human recognition. The
entropy and Miller's number are inversely related to one
another. Thus by juxtapositioning these two measures, we
find the best clustering that produces an adequate
amount of information and acceptable size clusters. We
have tested the RBC on three real world rule bases.
The second tool is the Rule Base Scanner (RBS) which
scans a rule base and performs anomaly checking using
lexical information. The RBS produces all the relevant
rules' rule number for every term in a given rule. Thus
the RBS is a kind of dictionary of rules. To change a
rule, a maintainer can look up the RBS and find all
other rules that use any of the same terms. The RBS also
checks anomalies such as dead-end rules, redundant
rules, circular rule sets, and subsumption using only
the lexical information.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  2894 </NUMBER>
<ORDER>   AAG1384479 </ORDER>
<TITLE> MISSING DATA IMPUTATION:  A NOVEL APPROACH </TITLE>
<AUTHOR> PURANKAR, ASHISH DIWAKAR </AUTHOR>
<YEAR> 1997 </YEAR>
<INSTITUTION> UNIVERSITY OF NEVADA, RENO; 0139 </INSTITUTION>
<DESCRIPTORS> ENGINEERING, ELECTRONICS AND ELECTRICAL; STATISTICS; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER>  DWIGHT EGBERT </ADVISER>
<CLASSIFICATIONS> NIL </CLASSIFICATIONS>
<ABSTRACT>
Incomplete data occur frequently. It is important to
know how to deal with missing data. Most of the
approaches aim at imputing the missing data. The
complete cases, thus formed, are then presented to
another model to do further analyses, which could just
be predicting the output variable.
We have integrated two functionalities--missing data
imputation and output prediction--in a single model. We
have implemented a backpropagation recurrent neural
network that uses the well-established principle from
statistics--k nearest neighbors, to estimate missing
data.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  2895 </NUMBER>
<ORDER>   AAG1384468 </ORDER>
<TITLE> COMPUTER COMMAND PREDICTION </TITLE>
<AUTHOR> ANDREWS, THOMAS EDWIN </AUTHOR>
<YEAR> 1997 </YEAR>
<INSTITUTION> UNIVERSITY OF NEVADA, RENO; 0139 </INSTITUTION>
<DESCRIPTORS> COMPUTER SCIENCE; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> SUSHIL J. LOUIS </ADVISER>
<CLASSIFICATIONS> NIL </CLASSIFICATIONS>
<ABSTRACT>
This thesis examines the problem of predicting a
computer user's next command. We discuss two types of
prediction, matrix and classifier system and present the
results of performance tests using variations of each
method with real user command history data. Based on the
results, classifier methods appear to outperform the
purely statistical matrix methods. The best performing
classifier methods we tested were a two condition
classifier system variation and four, five and six
condition rule variations with built in detection of
conflicts in command sequences. The test results are
promising and offer the prospect of improving human-
computer interaction. Our predictor techniques are not
restricted to text commands, but rather are applicable
to any kind of user interface. We suggest several
potential applications including using command
prediction as part of the operating system shell and to
prioritize menu items and predict mouse movements within
a graphical interface.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  2896 </NUMBER>
<ORDER>   AAG1384042 </ORDER>
<TITLE> APPLICATION OF FUZZY LOGIC FOR THE SOLUTION OF INVERSE KINEMATICS AND HIERARCHICAL CONTROLS OF ROBOTIC MANIPULATORS </TITLE>
<AUTHOR> HOWARD, DAVID WILLIAM </AUTHOR>
<YEAR> 1997 </YEAR>
<INSTITUTION> FLORIDA ATLANTIC UNIVERSITY; 0119 </INSTITUTION>
<DESCRIPTORS> ENGINEERING, ELECTRONICS AND ELECTRICAL; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> ALI ZILOUCHIAN </ADVISER>
<CLASSIFICATIONS> NIL </CLASSIFICATIONS>
<ABSTRACT>
In this thesis work, hierarchical control techniques
will be used for controlling a robotic manipulator. The
hierarchical control will be implemented with fuzzy
logic to improve the robustness and reduce the run time
computational requirements. Hierarchical control will
consist on solving the inverse kinematic equations using
fuzzy logic to direct each individual joint. A
commercial Micro-robot with three degrees of freedom
will be used to evaluate this methodology.
A decentralized fuzzy controller will be used for each
joint, with a Fuzzy Associative Memories (FAM)
performing the inverse kinematic mapping in a
supervisory mode. The FAM determines the inverse
kinematic mapping which maps the desired Cartesian
coordinates to the individual joint angles. The
individual fuzzy controller for each joint will generate
the required control signal to a DC motor to move the
associated link to the new position. The proposed
hierarchical fuzzy controller will be compared to a
conventional PD controller.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  2897 </NUMBER>
<ORDER>   AAG1384032 </ORDER>
<TITLE> INFORMATION-THEORETICS BASED GENETIC ALGORITHM: APPLICATION TO HOPFIELD'S ASSOCIATIVE MEMORY MODEL OF NEURAL NETWORKS </TITLE>
<AUTHOR> ARREDONDO, TOMAS VIDAL </AUTHOR>
<YEAR> 1997 </YEAR>
<INSTITUTION> FLORIDA ATLANTIC UNIVERSITY; 0119 </INSTITUTION>
<DESCRIPTORS> ENGINEERING, ELECTRONICS AND ELECTRICAL; ARTIFICIAL INTELLIGENCE; INFORMATION SCIENCE </DESCRIPTORS>
<ADVISER> P. S. NEELAKANTA </ADVISER>
<CLASSIFICATIONS> NIL </CLASSIFICATIONS>
<ABSTRACT>
This thesis refers to a research addressing the use of
information-theoretic techniques in optimizing an
artificial neural network (ANN) via a genetic selection
algorithm. Pertinent studies address emulating relevant
experiments on a test ANN (based on Hopfield's
associative memory model) wherein the said optimization
is tried with different sets of control parameters.
These parameters include a new entity based on the
concept of entropy as conceived in the field of
information theory. That is, the mutual entropy (Shannon
entropy) or information-distance (Kullback-Leibler-
Jensen distance) measure between a pair of candidates is
considered in the reproduction process of the genetic
algorithm (GA) and adopted as a selection-constraint
parameter.
The research envisaged further includes a comparative
analysis of the test results which indicate the
importance of proper parameter selection to realize an
optimal network performance. It also demonstrates the
ability of the concepts proposed here in developing a
new neural network approach for pattern recognition
problems.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  2898 </NUMBER>
<ORDER>   AAG9723459 </ORDER>
<TITLE> INTER-DIAGRAMMATIC REASONING </TITLE>
<AUTHOR> ANDERSON, MICHAEL EDWARD </AUTHOR>
<YEAR> 1997 </YEAR>
<INSTITUTION> THE UNIVERSITY OF CONNECTICUT; 0056 </INSTITUTION>
<DESCRIPTORS> COMPUTER SCIENCE; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> NIL </ADVISER>
<CLASSIFICATIONS> ARTIFICIAL INTELLIGENCE, SPATIAL REASONING </CLASSIFICATIONS>
<ABSTRACT>
Although research in diagrammatic reasoning is as old as
research in artificial intelligence itself, it has only
recently aroused from a long dormancy induced by a bias
toward symbolic computing. This resurgence of interest
has been almost exclusively slanted towards the
investigation of how a computer might be coaxed into
generating information from isolated diagrams. In
contrast, we examine how a computer might reason with
groups of related diagrams inferring, for example,
weather information from a suite of cartograms or the
best move in a game from a sequence of diagrams
delineating moves up to the current point. Diagrammatic
reasoning research has rarely been conducted from this
perspective and never with this distinction in mind. We
contend that there are many diagrammatic domains that
will prove amenable to this inter-diagrammatic
perspective and that much can be learned about
diagrammatic reasoning in general from such research. In
particular, we (1) distinguish inter-diagrammatic and
intra-diagrammatic reasoning, (2) define the syntax and
semantics of a general diagram useful across a number of
domains, (3) define a set of operators and functions
that can effect inter-diagrammatic reasoning across a
number of domains, (4) describe the formal properties of
this set, and explore the relationship of this set with
more traditional sets of operators, (5) codify the
process by which a diagrammatic domain can be suitably
defined to profit from these diagrammatic operators, (6)
develop a variety of examples of inter-diagrammatic
reasoning in a number of different domains including
formal presentation and coding, (7) examine the
possibility and utility of combining inter-diagrammatic
reasoning with other AI reasoning paradigms, and (8)
provide a selection of topics for further research in
inter-diagrammatic reasoning.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  2899 </NUMBER>
<ORDER>   AAG9723376 </ORDER>
<TITLE> ENHANCEMENTS TO THE DATA MINING PROCESS </TITLE>
<AUTHOR> JOHN, GEORGE HARRISON </AUTHOR>
<YEAR> 1997 </YEAR>
<INSTITUTION> STANFORD UNIVERSITY; 0212 </INSTITUTION>
<DESCRIPTORS> COMPUTER SCIENCE; ECONOMICS, FINANCE; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> NILS J. NISSON </ADVISER>
<CLASSIFICATIONS> MACHINE LEARNING, PATTERN RECOGNITION, STOCK SELECTION </CLASSIFICATIONS>
<ABSTRACT>
Data mining is the emerging science and industry of
applying modern statistical and computational
technologies to the problem of finding useful patterns
hidden within large databases. This thesis describes the
data mining process and presents advances and novel
methods for the six steps in the data mining process:
extracting data from a database or data warehouse,
cleaning the data, data engineering, algorithm
engineering, data mining, and analyzing the results.
We show how the standard data extraction process can be
improved by building a direct interface between a data-
mining algorithm and a relational database management
system. Next, in data cleaning, we show how
automatically iterating through the data mining process
can identify records that can be profitably ignored
during data mining. For data engineering, we develop an
automated way to iterate through the data mining process
to choose the subset of attributes that yields the best
estimated results. In algorithm engineering, a similar
process is used to automatically set the parameters of a
mining algorithm.
For the data mining algorithms, we study enhancements to
classification tree induction methods and Bayesian
methods. Our new flexible Bayes data-mining algorithm is
fast, understandable, and more accurate than the
standard Bayesian classifier in most situations. In
classification tree induction we study various
univariate splitting criteria and multivariate
partitions.
The analysis of results is necessarily domain-dependent.
In an example applying data mining to stock selection,
we discuss a key requirement in real-world applications:
using appropriate domain-dependent methods to evaluate
the proposed solution.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  2900 </NUMBER>
<ORDER>   AAIMM98709 </ORDER>
<TITLE> RAISONNEMENT HYPOTHETIQUE PAR LES RESEAUX DE NEURONES </TITLE>
<AUTHOR> GE, JIFENG </AUTHOR>
<YEAR> 1994 </YEAR>
<INSTITUTION> UNIVERSITE DE SHERBROOKE (CANADA); 0512 </INSTITUTION>
<DESCRIPTORS> BIOLOGY, NEUROSCIENCE; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> SHENGRUI WANG; BECHIR EL AYEB </ADVISER>
<CLASSIFICATIONS> FRENCH TEXT </CLASSIFICATIONS>
<ABSTRACT>
Bien que les reseaux de neurones soient largement
utilises pour resoudre les problemes diagnostiques, la
plupart d'entre eux se limitent au diagnostic deductif
(type effet-a-cause). Nous proposons un modele des
reseaux de neurones pour le diagnostic abductif (type
cause-a-effet). Notre modele est un des rares modeles
qui existent pour le raisonnement abductif. En se basant
sur des systemes de neurones biologiques, les mises a
jour d'activite de neurones et de poids de connexions
sont modelisees. Le diagnostic approprie est genere par
la competition entre causes et la cooperation entre
causes et effets. Deux criteres, la cardinalite minimale
et la plausibilite maximale, sont utilises dans la
generation du diagnostic. Nous prouvons formellement que
notre modele minimise effectivement une fonction
d'energie incorporant les deux criteres mentionnes ci-
dessus.
De plus, les extensions sont portees sur notre modele
pour resoudre des problemes de diagnostic complexes.
Plus particulierement, nous considerons les trois
aspects suivants: (1) Modelisation de l'additivite des
causes: la cause c$sb0rm i$ ou c$sb0rm m$ ne peut toute
seule entrai ner la manifestation m$sb0rm j$, cependant,
l'ensemble de c$sb0rm i$ et c$sb0rm m$ peut entrai ner
m$sb0rm j$. (2) Modelisation de l'incertitude de
manifestation: la presence/absence de certaines
manifestations est inconnue. (3) Modelisation de
l'incompatibilite des causes: deux causes sont
incompatibles si leur presence simultanee cree des
contradictions.
Une centaine de problemes de diagnostic sont simules.
Les resultats nous permettent d'estimer l'applicabilite
de ce modele aux problemes de diagnostic reels.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  2901 </NUMBER>
<ORDER>   AAG9723358 </ORDER>
<TITLE> MODELING BELIEFS IN DYNAMIC SYSTEMS </TITLE>
<AUTHOR> FRIEDMAN, NIR </AUTHOR>
<YEAR> 1997 </YEAR>
<INSTITUTION> STANFORD UNIVERSITY; 0212 </INSTITUTION>
<DESCRIPTORS> COMPUTER SCIENCE; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> JOSEPH Y. HALPERN </ADVISER>
<CLASSIFICATIONS> ARTIFICIAL INTELLIGENCE </CLASSIFICATIONS>
<ABSTRACT>
The problem of belief change--that is, how beliefs
change over time--is a central problem in AI. In this
dissertation, we propose a new approach to dealing with
belief change. This approach is based on developing a
semantics for beliefs. This semantics is embedded in a
framework that models agents' knowledge (or information)
as well as their beliefs, and how these change in time.
We argue, and demonstrate by examples, that this
framework can naturally model any dynamic system.
Moreover, the framework allows us to consider what the
properties of well-behaved belief change should be.
As we show, such a framework can give us a much deeper
understanding of how and why beliefs change. In
particular, we can gain a better understanding of the
current approaches to belief change--belief revision and
belief update. Roughly, revision treats a surprising
observation (one that is inconsistent with the agent's
current beliefs) as a sign that the beliefs are
incorrect, while update treats a surprising observation
as an indication that the world has changed. We show how
belief revision and belief update can be captured in the
proposed framework. This allows us to compare the
assumptions made by each method and to better understand
the principles underlying them.
This analysis shows that revision and update are only
two points on a spectrum. In general, we would expect
that an agent making an observation may both want to
revise some earlier beliefs and assume that some change
has occurred in the world. We describe a novel approach
to belief change that allows us to do this, by applying
ideas from probability theory. This approach is based on
a qualitative analogue of the Markov assumption, which
gives us a well-behaved notion of belief change, without
making the occasionally unreasonable assumptions made by
belief revision and update. In particular, it allows a
user to weigh the relative plausibility that a given
observation is due to a change in the world or due to an
inaccuracy in previous beliefs.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  2902 </NUMBER>
<ORDER>   AAG9723343 </ORDER>
<TITLE> NON-MONOTONICITY AND CHANGE </TITLE>
<AUTHOR> COSTELLO, TOM </AUTHOR>
<YEAR> 1997 </YEAR>
<INSTITUTION> STANFORD UNIVERSITY; 0212 </INSTITUTION>
<DESCRIPTORS> COMPUTER SCIENCE; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> JOHN MCCARTHY </ADVISER>
<CLASSIFICATIONS> CIRCUMSCRIPTION, ARTIFICIAL INTELLIGENCE </CLASSIFICATIONS>
<ABSTRACT>
Non-monotonic reasoning is reasoning that will deny
conclusions in the light of new evidence. This kind of
reasoning is important for many common-sense phenomena.
In particular it is useful in reasoning about change.
Circumscription is a common methodology for capturing
non-monotonic inferences. I characterize its expressive
power, and show how it can be extended to be more
tolerant of new defaults and so that it can capture
defaults that current versions of circumscription cannot
express.
Examples from reasoning about action are used as the
primary motivating tool.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  2903 </NUMBER>
<ORDER>   AAG9722063 </ORDER>
<TITLE> LATERAL VEHICLE CO-PILOT TO AVOID UNINTENDED ROADWAY DEPARTURE  </TITLE>
<AUTHOR> PILUTTI, THOMAS E. </AUTHOR>
<YEAR> 1997 </YEAR>
<INSTITUTION> THE UNIVERSITY OF MICHIGAN; 0127 </INSTITUTION>
<DESCRIPTORS> ENGINEERING, MECHANICAL; ENGINEERING, SYSTEM SCIENCE; ENGINEERING, AUTOMOTIVE; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> A. GALIP ULSOY </ADVISER>
<CLASSIFICATIONS> WARNING SYSTEMS, VARIABLE RUMBLE STRIP, INTELLIGENT VEHICLE HIGHWAY SYSTEMS </CLASSIFICATIONS>
<ABSTRACT>
A detailed investigation of road departure warning
systems is presented. A method known as time-to-lane-
crossing is compared with rumble strips placed a fixed
distance from the road edge, and is found to provide
enhanced performance in terms of reduced false warnings
and increased warning anticipation. A new approach,
called variable rumble strip (VRBS), is proposed as an
electronic implementation of rumble strips where the
rumble strip threshold is allowed to vary according to
the risk of the vehicle departing the road. The rule-
based system is realized using a fuzzy logic structure.
Performance of the VRBS system is similar to that of the
time-to-lane-cross based approach, but requires less
sensor information. Performance is measured by
comparison with a validation warning set generated by
static rumble strip warnings, and subjective assessment
of road departure criticality. The algorithms are tested
on 12 two-hour driving runs conducted in a full-vehicle
driving simulator.
One extension of the VRBS system involves an estimate of
driver lane-keeping performance used to modify the VRBS
threshold adjustment. The estimate, based on the
standard deviation of lateral vehicle position, is
effective at increasing the anticipatory warning time,
and is readily implemented in the fuzzy rule structure.
A separate driver modeling effort was undertaken using a
system identification approach to develop a driver
model, and to update its parameters during driving.
Although preliminary driving simulator results indicated
that changes in the damping ratio, natural frequency,
and DC gain of such a model may be useful indicators of
driver fatigue, the identified model parameters were
found to not exhibit the expected trends as lane-keeping
performance deteriorated on more extensive data sets.
Addition of an intervention function is the topic of a
second extension, and examines the usefulness of a brake
steer system which uses differential brake forces for
steering intervention. The steering function achieved
can be used to provide limited control authority on
vehicle lateral position. Control design models for the
vehicle and the brake system are presented. Computer
simulation results, using a nonlinear seven degree-of-
freedom vehicle model are included, and show the
feasibility and limitations of brake steer.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  2904 </NUMBER>
<ORDER>   AAG9721976 </ORDER>
<TITLE> PREDICATE LOGIC REPRESENTATIONS FOR DESIGN CONSTRAINTS ON UNCERTAINTY SUPPORTING THE SET-BASED DESIGN PARADIGM </TITLE>
<AUTHOR> FINCH, WILLIAM WALTER </AUTHOR>
<YEAR> 1997 </YEAR>
<INSTITUTION> THE UNIVERSITY OF MICHIGAN; 0127 </INSTITUTION>
<DESCRIPTORS> ENGINEERING, MECHANICAL; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> ALLEN C. WARD </ADVISER>
<CLASSIFICATIONS> ARTIFICIAL INTELLIGENCE </CLASSIFICATIONS>
<ABSTRACT>
This thesis shows how predicate logic can be used in
conjunction with algebraic constraints to mathematically
represent engineering problems dominated by causally
related variations in parameter values. Uncertainty
enters design processes from many sources, including:
manufacturing variations, environmental changes,
operator adjustments, and uncertainty in the decisions
of engineers. These variations complicate design
processes in a wide variety of product domains.
Conventional approaches to including uncertainty in
engineering analysis and design, interval propagation
for example, ignore how and when different variations
affect system parameters. However, this can lead to
incorrect inferences. This work solves the problem of
including this missing information about uncertainty in
engineering calculations.
This dissertation combines elements from predicate
logic, constraint satisfaction, and Ward's Set-Based
Design paradigm into a collection of tools for
automating calculations about design variations. First,
causal tables and graphs represent the causality of
engineering systems, that is how and when variations
affect the precise value of system parameters. These
models help engineers understand complex interactions of
multiple sources of variation. Second, quantified
relations are predicate logic constraints on design,
manufacturing, adjustment, and other variations.
Construction of their patterns of quantified variables
is guided by causal table entries. Third, two new
theorems constitute an inference mechanism which
operates on quantified relations involving monotonic,
asymptote-free equations. It makes correct inferences
about sets of variations in many cases where
conventional methods fail. In isolation, however, the
inference mechanism is not very useful for design
automation.
This dissertation also develops an algorithm, based on
arc consistency techniques, which eliminates provably
infeasible variation sets, simplifying engineers' tasks
by reducing the size of design spaces. This requires
extension of existing constraint satisfaction techniques
to variables which are assigned sets. This dissertation
appears to potentially subsume Ward's prior work on the
Label Interval Calculus (LIC), extending the approach to
a wider range of engineering design problems.
Application of these tools to three example problems
provides evidence that this work may lead to the
development of useful automated design tools.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  2905 </NUMBER>
<ORDER>   AAG9721493 </ORDER>
<TITLE> LEARNING TEXT ANALYSIS RULES FOR DOMAIN-SPECIFIC NATURAL LANGUAGE PROCESSING </TITLE>
<AUTHOR> SODERLAND, STEPHEN GLENN </AUTHOR>
<YEAR> 1997 </YEAR>
<INSTITUTION> UNIVERSITY OF MASSACHUSETTS; 0118 </INSTITUTION>
<DESCRIPTORS> COMPUTER SCIENCE; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> WENDY G. LEHNERT </ADVISER>
<CLASSIFICATIONS> MACHINE LEARNING, ARTIFICIAL INTELLIGENCE </CLASSIFICATIONS>
<ABSTRACT>
An enormous amount of knowledge is needed to infer the
meaning of unrestricted natural language. The problem
can be reduced to a manageable size by restricting
attention to a specific domain, which is a corpus of
texts together with a predefined set of concepts that
are of interest to that domain.
Two widely different domains are used to illustrate this
domain-specific approach. One domain is a collection of
Wall Street Journal articles in which the target concept
is management succession events: identifying persons
moving into corporate management positions or moving
out. A second domain is a collection of hospital
discharge summaries in which the target concepts are
various classes of diagnosis or symptom.
The goal of an information extraction system is to
identify references to the concept of interest for a
particular domain. A key knowledge source for this
purpose is a set of text analysis rules based on the
vocabulary, semantic classes, and writing style peculiar
to the domain.
This thesis presents CRYSTAL, an implemented system that
automatically induces domain-specific text analysis
rules from training examples. CRYSTAL learns rules that
approach the performance of hand-coded rules, are robust
in the face of noise and inadequate features, and
require only a modest amount of training data.
CRYSTAL belongs to a class of machine learning
algorithms called covering algorithms, and presents a
novel control strategy with time and space complexities
that are independent of the number of features. CRYSTAL
navigates efficiently through an extremely large space
of possible rules.
CRYSTAL also demonstrates that expressive rule
representation is essential for high performance, robust
text analysis rules. While simple rules are adequate to
capture the most salient regularities in the training
data, high performance can only be achieved when rules
are expressive enough to reflect the subtlety and
variability of unrestricted natural language.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  2906 </NUMBER>
<ORDER>   AAG9721453 </ORDER>
<TITLE> AN EXPERT SYSTEM FOR THE SYNTHESIS OF SOLID-LIQUID- LIQUID SEPARATIONS  </TITLE>
<AUTHOR> GIANNELOS, NIKOLAOS FOTIOS </AUTHOR>
<YEAR> 1997 </YEAR>
<INSTITUTION> UNIVERSITY OF MASSACHUSETTS; 0118 </INSTITUTION>
<DESCRIPTORS> ENGINEERING, CHEMICAL; ARTIFICIAL INTELLIGENCE; COMPUTER SCIENCE </DESCRIPTORS>
<ADVISER> JAMES M. DOUGLAS </ADVISER>
<CLASSIFICATIONS> PROCESS SYNTHESIS </CLASSIFICATIONS>
<ABSTRACT>
The synthesis of separation systems involving solid-
liquid-liquid mixtures is an important problem that has
not received appreciable attention in the literature of
process synthesis in the past.
The main objective of this research is the development
of a complete design methodology for solid-liquid-liquid
separations in the context of total flowsheet synthesis,
along with its computer implementation, including the
initial synthesis of flowsheet structures, the
generation of process alternatives, and a preliminary
cost analysis. The implementation part of this work is
stressed as a means of testing heuristics and
formalizing the design activity.
The proposed synthesis approach is heuristic in nature.
Separation methods are selected and the interconnections
among equipment types are deduced based on expert
knowledge in the form of rules. Short-cut calculations
are employed for equipment design and cost estimations.
The final product of this research has been implemented
in a prototype expert system, facilitating the screening
of alternative separation schemes and the invention of
preliminary flowsheets.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  2907 </NUMBER>
<ORDER>   AAG9721271 </ORDER>
<TITLE> MASSIVELY PARALLEL REASONING IN TRANSITIVE RELATIONSHIP HIERARCHIES </TITLE>
<AUTHOR> LEE, YUGYUNG </AUTHOR>
<YEAR> 1997 </YEAR>
<INSTITUTION> NEW JERSEY INSTITUTE OF TECHNOLOGY; 0152 </INSTITUTION>
<DESCRIPTORS> COMPUTER SCIENCE; INFORMATION SCIENCE; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> JAMES GELLER </ADVISER>
<CLASSIFICATIONS> NIL </CLASSIFICATIONS>
<ABSTRACT>
This research focuses on building a parallel knowledge
representation and reasoning system for the purpose of
making progress in realizing human-like intelligence. To
achieve human-like intelligence, it is necessary to
model human reasoning processes by programs. Knowledge
in the real world is huge in size, complex in structure,
and is also constantly changing even in limited domains.
Unfortunately, reasoning algorithms are very often
intractable, which means that they are too slow for any
practical applications. One technique to deal with this
problem is to design special-purpose reasoners. Many
past AI systems have worked rather nicely for limited
problem sizes, but attempts to extend them to realistic
subsets of world knowledge have led to difficulties.
Even special purpose reasoners are not immune to this
impasse. In this work, to overcome this problem, we are
combining special purpose reasoners with massive
parallelism.
We have developed and implemented a massively parallel
transitive closure reasoner, called Hydra, that can
dynamically assimilate any transitive, binary relation
and efficiently answer queries using the transitive
closure of all those relations. Within certain
limitations, we achieve constant-time responses for
transitive closure queries. Hydra can dynamically insert
new concepts or new links into a knowledge base for
realistic problem sizes. To get near human-like
reasoning capabilities requires the possibility of
dynamic updates of the transitive relation hierarchies.
Our incremental, massively parallel, update algorithms
can achieve "almost" constant time updates of large
knowledge bases.
Hydra expands the boundaries of Knowledge Representation
and Reasoning in a number of different directions: (1)
Hydra improves the representational power of current
systems. We have developed a set-based representation
for class hierarchies that makes it easy to represent
class hierarchies on arrays of processors. Furthermore,
we have developed and implemented two methods for
mapping this set-based representation onto the processor
space of a Connection Machine. These two
representations, the Grid Representation and the Double
Strand Representation successively improve transitive
closure reasoning in terms of speed and processor
utilization. (2) Hydra allows fast retrieval and dynamic
update of a large knowledge base. New fast update
algorithms are formulated to dynamically insert new
concepts or new relations into a knowledge base of
thousands of nodes. (3) Hydra provides reasoning based
on mixed hierarchical representations. We have designed
representational tools and massively parallel reasoning
algorithms to model reasoning in combined IS-A, Part-of,
and Contained-in hierarchies. (4) Hydra's reasoning
facilities have been successfully applied to the Medical
Entities Dictionary, a large medical vocabulary of
Columbia Presbyterian Medical Center.
As a result of (1) $-$ (3), Hydra is more general than
many current special-purpose reasoners, faster than
currently existing general-purpose reasoners, and its
knowledge base can be updated dynamically.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  2908 </NUMBER>
<ORDER>   AAG9719995 </ORDER>
<TITLE> NEURAL NETWORKS FOR IDENTIFICATION AND CONTROL OF SMART STRUCTURES </TITLE>
<AUTHOR> DAMLE, RAJENDRA RATNAKANT </AUTHOR>
<YEAR> 1997 </YEAR>
<INSTITUTION> UNIVERSITY OF MISSOURI - ROLLA; 0135 </INSTITUTION>
<DESCRIPTORS> ENGINEERING, ELECTRONICS AND ELECTRICAL; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> VITTAL RAO </ADVISER>
<CLASSIFICATIONS> NIL </CLASSIFICATIONS>
<ABSTRACT>
The application of neural network technology for
mathematical modeling and robust control of experimental
smart structural system is studied. Four smart structure
test articles were designed and fabricated to
incorporate Nickel Titanium Naval Ordinance Lab
(NiTiNOL) and Lead Zirconate Titanate (PZT) actuators
and strain gauge and Poly Vinyledene Fluoride (PVDF)
film sensors. A neural network based technique to
directly identify a state space model of a structural
system with direct state measurement has been developed.
For a more general case where only the output
measurements are available, a feedforward neural network
has been incorporated with the Eigensystem Realization
Algorithm (ERA) to obtain a discrete time state space
model. An adaptive learning rate algorithm and a
selective training scheme have been developed to
significantly reduce the training time and improve the
error performance of the networks with large numbers of
neurons in the input and hidden layers. A single chip
implementation of neural network based robust
controllers for smart structures has been successfully
demonstrated for the first time using Intel's
Electronically Trainable Analog Neural Network (ETANN)
chip and the analog delay line chip by Tanner Research.
Custom interface hardware required for this
implementation has been developed. Finally, a neural
network based optimizing controller scheme based on the
minimization of a Linear Quadratic (LQ) performance
index which can directly incorporate structural
nonlinearities, all the a priori information about the
system, such as control effort and bandwidth limits, and
adaptation to the time varying dynamics has been
developed. Both simulation and experimental results have
been included to demonstrate the effectiveness of neural
networks as a good tool in the identification and robust
control implementation for smart structural systems.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  2909 </NUMBER>
<ORDER>   AAG9719992 </ORDER>
<TITLE> DAMAGE DETECTION IN COMPOSITE STRUCTURES USING MULTI- SENSING, ACTUATION, AND NEURAL NETWORK SYSTEMS </TITLE>
<AUTHOR> JIANG, YUPING </AUTHOR>
<YEAR> 1997 </YEAR>
<INSTITUTION> UNIVERSITY OF MISSOURI - ROLLA; 0135 </INSTITUTION>
<DESCRIPTORS> ENGINEERING, MECHANICAL; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> A. C. OKAFOR; K. CHANDRASHEKHARA </ADVISER>
<CLASSIFICATIONS> DELAMINATION </CLASSIFICATIONS>
<ABSTRACT>
This dissertation presents the results of the research
investigation on damage detection in composite
structures using multi-sensing, actuation, and neural
network systems. The effect of prescribed delamination
on natural frequency of laminated beam specimen is
examined both experimentally and theoretically. Modal
testing of a perfect beam and beams with different
delamination size is conducted. A back propagation
neural network model is developed using the results from
the beam theory and used to predict the delamination
size. The neural network model successfully predicted
delamination size. Broadband acoustic emission (AE)
signatures are also used to detect delaminations in
composite beams. The AE wave propagation along a perfect
composite beam and composite beams with known
delamination sizes are investigated. The results show
that AE strength and AE energy decrease significantly
over delamination area. This phenomenon is used
successfully to determine delamination location and size
in composite beams. Waveform-based acoustic emission
technique is used to determine the location of low
velocity impact in composite plates. The Gaussian cross-
correlation method and the Hilbert transformation are
used to obtain arrival time differences among three
broadband AE sensors and to overcome dispersion
problems. The locations of impact points are
successfully determined. A method for determining the
low velocity impact induced contact force on laminated
composite plates is developed using finite element
method. A backpropagation neural network is used to
estimate the contact force on the composite plates using
strain signals. The neural network approach for
estimation of contact force proves to be a promising
alternative to more tradition techniques, particularly
for an on-line health monitoring system.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  2910 </NUMBER>
<ORDER>   AAG9719148 </ORDER>
<TITLE> THE HARDWARE IMPLEMENTATION OF NEURAL NETWORKS </TITLE>
<AUTHOR> LU, NAIQIAN </AUTHOR>
<YEAR> 1997 </YEAR>
<INSTITUTION> STATE UNIVERSITY OF NEW YORK AT BUFFALO; 0656 </INSTITUTION>
<DESCRIPTORS> COMPUTER SCIENCE; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> NIL </ADVISER>
<CLASSIFICATIONS> NIL </CLASSIFICATIONS>
<ABSTRACT>
The precision for computation and data is limited in the
hardware implementations of back-propagation. The change
from floating point to integer computing introduces the
new error into the neural network and affects the
performance of the neural networks. The impact changes
with the complexity of the neural networks. This
dissertation analysis the error models that come with
this change.
One of the error, computation error, is often ignored by
previous research. Lacking the hardware analysis in
error analysis is the main reason. Considering the
limitation of hardware structure, we extract the data
storage error from the computation error. The impact of
data storage accuracy was studied by using the BP
algorithm on handwritten character recognition networks.
The theoretical analysis with the algorithm and hardware
architecture point out that the storage error actively
involves in BP training of neural network. It is a major
error source that causes the computational errors. The
extensive simulation was done on middle scale neural
network with large size of data. Different precision is
used to find the optimal point. The research results
shows two interesting points. First, the 16 bit accuracy
is necessary to hold the performance up, and it is
mainly affected by back-propagation on weight update.
Second, by only making a little change, the short
floating format can be used in hardware implementation
with low cost 16 bit design, and get higher system
accuracy.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  2911 </NUMBER>
<ORDER>   AAIMM98618 </ORDER>
<TITLE> PROVIDING SUPPORT FOR THE SCENARIO SELECTION PROBLEM: AN INTELLIGENT ASSISTANT FOR DEMOGRAPHIC PROJECTIONS </TITLE>
<AUTHOR> DAWSON, RONALD SYLVESTER </AUTHOR>
<YEAR> 1994 </YEAR>
<INSTITUTION> CARLETON UNIVERSITY (CANADA); 0040 </INSTITUTION>
<DESCRIPTORS> BUSINESS ADMINISTRATION, GENERAL; SOCIOLOGY, DEMOGRAPHY; ENGINEERING, SYSTEM SCIENCE; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> WOJTEK MICHALOWSKI; ROLAND THOMAS </ADVISER>
<CLASSIFICATIONS> NIL </CLASSIFICATIONS>
<ABSTRACT>
This paper represents research in the application of
Expert System methodology to the area of population
projections. When government demographic agencies
publish a set of population projections, often only a
sub-set is published. The reasons for publishing a sub-
set include cost, but additionally there are issues
associated with the value of a smaller sub-set to the
users of population projections. The process of
selecting which scenarios to include in a publication is
a complex and time consuming process. Artificial
Intelligence, and Expert Systems in particular, could
potentially provide effective support to demographers in
the scenario selection process. This paper outlines this
process and discusses research into the applicability of
Expert Systems in supporting this process.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  2912 </NUMBER>
<ORDER>   AAG9718609 </ORDER>
<TITLE> HYBRID CONTROLLER FOR ACTIVE VIBRATION SUPPRESSION: INTEGRATING PHYSICAL AND MODAL INFORMATION USING FUZZY REASONING </TITLE>
<AUTHOR> ASDIGHA, MEHRAN </AUTHOR>
<YEAR> 1997 </YEAR>
<INSTITUTION> TUFTS UNIVERSITY; 0234 </INSTITUTION>
<DESCRIPTORS> ENGINEERING, MECHANICAL; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> ROBERT GREIF </ADVISER>
<CLASSIFICATIONS> NIL </CLASSIFICATIONS>
<ABSTRACT>
Independent Modal space Control (IMSC) is a well
established method in active control of vibration. In
this method, the control law is developed exclusively in
the modal space, allowing for independent design of
modal control forces. These forces are then transformed
to the physical space by modal transformation. The
resulting controller is fixed-gain, with the active
damping introduced to the system determined
independently for each mode. This damping is directly
proportional to the modal velocity in the under-damped
case. In this research, we propose to use IMSC to
articulate a new control architecture. The result is a
new non-linear control law, embedding fuzzy reasoning
that transforms the standard algorithm from a fixed-
gain, to a variable-gain controller. This new algorithm
uses information about the state profile (velocity or
displacement) across the sensed locations to distribute
the active damping rationally among the modal
controllers. It complements the local view of the
traditional algorithm in the modal space, with a global
view of the velocities in the physical space. Three
variants of the new control architecture are developed,
discussed and studied in this research, and their
performance compared with the standard method. A
simulation model of a vibration control system is
developed in LabVIEW development environment, where the
performance of the fuzzy/IMSC method and its variants
are simulated. Parametric studies are performed on the
new architecture, where the effect of algorithm delay,
and actuator omission are analyzed. The results show
significant improvement in the settling time as the
performance criterion, and the total amount of modal
work done.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  2913 </NUMBER>
<ORDER>   AAG9718495 </ORDER>
<TITLE> APPLICATION OF NEURAL NETWORK CONTROL TO DISTILLATION </TITLE>
<AUTHOR> DUTTA, PRIYABRATA </AUTHOR>
<YEAR> 1997 </YEAR>
<INSTITUTION> TEXAS TECH UNIVERSITY; 0230 </INSTITUTION>
<DESCRIPTORS> ENGINEERING, CHEMICAL; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> ROBERT RUSSELL RHINEHART </ADVISER>
<CLASSIFICATIONS> PROCESS CONTROL </CLASSIFICATIONS>
<ABSTRACT>
Distillation control is challenging due to its coupled,
nonlinear, nonstationary and slow dynamic behavior. Like
distillation columns, most chemical processes are
usually nonlinear and nonstationary. This greatly limits
the effectiveness of linear controllers, specially when
the process is operated away from the nominal operating
region. Nonlinear controllers, based on phenomenological
models, can be developed. But, it is still a very
difficult task in real practice, in terms of
computational power, to implement these as on-line
controllers because the entire model needs to be solved
within each control interval. Neural networks give us an
alternative approach to model a nonlinear process, and a
controller based on this model can overcome the issues
of on-line computational problems. Besides nonlinearity,
many practical control problems possess constraints on
the input. state and output variables. The ability to
handle constraints is essential for any algorithm to be
implemented on real processes. Thus strategies for
constraint handling within model based controllers have
become one of the more popular research topics.
In this dissertation, a constrained optimization
technique for control which uses a neural network gain
prediction approach has been developed and implemented
on a laboratory distillation column as well as on a
dynamic simulator. Here, the neural networks are trained
based on a phenomenological model. Also, experimental
results are developed to confirm the applicability of a
neural network model based controller using an inverse
of a state prediction approach that was developed and
simulated earlier by Ramchandran (Ramchandran and
Rhinehart, 1994). In addition, two separate single-input-
single-output (SISO) neural network controllers using
the inverse of the state prediction approach are
implemented on the feed and reflux preheaters of the
column.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  2914 </NUMBER>
<ORDER>   AAG9717869 </ORDER>
<TITLE> BUILDING BLOCKS FOR A FILTER TUNING SYSTEM USING AN ANALOG VLSI FUZZY LOGIC CONTROLLER </TITLE>
<AUTHOR> CHOI, SEUNG CHUL </AUTHOR>
<YEAR> 1997 </YEAR>
<INSTITUTION> NEW MEXICO STATE UNIVERSITY; 0143 </INSTITUTION>
<DESCRIPTORS> ENGINEERING, ELECTRONICS AND ELECTRICAL; PHYSICS, SOLID STATE; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> JAIME RAMIREZ-ANGULO </ADVISER>
<CLASSIFICATIONS> NIL </CLASSIFICATIONS>
<ABSTRACT>
The coverage of the present research is the analog VLSI
implementation of a fuzzy logic controller to tune
monolithic filters and the software verification of the
overall system to tune these filters. The building
blocks of the fuzzy controller for filter tuning include
a membership function generator, min and max circuits, a
second-order low pass filter using BiCMOS
transconductance multipliers, analog multipliers,
defuzzifiers, and oscillators. The goal of the hardware
implementation is to have good programmability, small
silicon area requirements, high speed, and low power.
Simulation results of all building blocks are in good
agreement with the ideal response and verify the high
speed operation of the circuit.
Chip measurement results of three analog multipliers, a
voltage-mode defuzzifier, a charge-mode defuzzifier, and
a second-order low pass filter using a transconductance
multiplier, were in good agreement with the simulation
results. The analog Orbit 2$mu$m low noise N-well MOSIS
fabrication technology was used for chip fabrication.
The MATLAB implementation for the functional
verification of a proposed fuzzy tuning filter system
was performed using a simple linear model. The proposed
MatLab architecture allows programmable window
specifications. A total of 52 rules were used for the
fuzzy inference engine based on the results of extensive
SPICE simulations of a second-order low pass filter. In
most cases of different initial variable settings, the
fuzzy logic controller converged to the filter window
specifications within at most ten iterations.
The proposed fuzzy filter has two possible
implementations. In the first implementation the filter
system and fuzzy logic processor can be built on the
same chip, while in the second implementation the two
blocks can be built on separate chips. The advantage of
the single chip implementation is reliability, but at
the expense of silicon area. Suitable applications for
the single chip are in mass produced items such as
television. In the separate chip implementation, one
fuzzy logic processor chip can be used to tune any
number of filter system chips. In this approach, each
filter will be tuned with one chip which will be
programmed in advance and a circuit to compensate for
temperature variations must be included in each chip.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  2915 </NUMBER>
<ORDER>   AAG9717351 </ORDER>
<TITLE> NEURAL NETWORK MATERIAL MODELS DETERMINED FROM STRUCTURAL TESTS  </TITLE>
<AUTHOR> ZHANG, MINGFU MICHAEL </AUTHOR>
<YEAR> 1997 </YEAR>
<INSTITUTION> UNIVERSITY OF ILLINOIS AT URBANA-CHAMPAIGN; 0090 </INSTITUTION>
<DESCRIPTORS> ENGINEERING, CIVIL; APPLIED MECHANICS; COMPUTER SCIENCE; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> J. GHABOUSSI; D. PECKNOLD </ADVISER>
<CLASSIFICATIONS> COMPRESSION, SHEAR </CLASSIFICATIONS>
<ABSTRACT>
Two major difficulties in the traditional material
modeling are mathematical formulation of complex
constitutive behavior and multi-axial material tests. To
avoid these difficulties, a method is proposed in this
study to extract neural network material models directly
from structural tests. Because a single structural test,
if properly designed, may contain far more material
information than a battery of material tests. The
proposed method uses non-linear finite element method to
extract local material information from structural
measurements, and a neural network material model which
is capable of adjusting itself to learn the newly
acquired material information. The method is first
demonstrated on a truss example and then applied to
model the progressive in-plane damage in T300/976
Graphite/Epoxy laminae. After the neural network
material model had been trained on the structural test
data from $rmlbrack (pm 45)sb6rbrack sb0s$ and $rmlbrack
(0/0pm45)sb4rbracksb0s$ laminates under compressive
loading, it was used as the lamina material model to
predict the structural behavior of $rmlbrack (pm
45)sb6rbracksb0s, lbrack (pm 30)sb6rbracksb0s, lbrack
(0/0pm 45)sb4rbracksb0s, lbrack (0/0pm
40/90)sb3rbracksb0s,$ and $rmlbrack (0/90)sb6rbracksb0s$
laminates under the compressive loading. A good
agreement was achieved between the neural network
predictions and the experimental data.
A nested modular neural network structure is introduced
in this study and applied to model uniaxial concrete
behavior under cyclic loading and biaxial concrete
behavior under monotonic loading and unloading. The
results show that the nested modular neural network
structure is more flexible and efficient to model path-
dependent material behavior than the fully-connected
internal neural network structure.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  2916 </NUMBER>
<ORDER>   AAG9717326 </ORDER>
<TITLE> LEARNING DESPITE COMPLEX ATTRIBUTE INTERACTION: AN APPROACH BASED ON RELATIONAL OPERATORS </TITLE>
<AUTHOR> PEREZ, EDUARDO </AUTHOR>
<YEAR> 1997 </YEAR>
<INSTITUTION> UNIVERSITY OF ILLINOIS AT URBANA-CHAMPAIGN; 0090 </INSTITUTION>
<DESCRIPTORS> COMPUTER SCIENCE; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> LARRY A. RENDELL </ADVISER>
<CLASSIFICATIONS> MACHINE LEARNING, ARTIFICIAL INTELLIGENCE, PROTEIN FOLDING, FEATURE CONSTRUCTION </CLASSIFICATIONS>
<ABSTRACT>
When shortage of knowledge prevents human experts from
choosing good attributes to represent empirical
observations, learning is difficult. Expressing concepts
by using only primitive (low-level) attributes is
intricate because the contribution of each attribute to
the definition is almost unnoticeable. This aggravates
attribute interaction, a situation where an attribute's
effect on classification depends on the value of other
attributes. When attribute interaction is complex,
involving many combinations of several attributes,
current learners cannot handle it. Such complex
interaction appears in real-world domains (e.g., protein
folding). These domains are not random; they have
structure although it may be concealed by the complexity
of the interactions. Concepts in these domains often
have embedded, implicit structure, which may be revealed
through explicit relations. Because of the existence of
structure, there is still hope for learning despite
complex attribute interaction if appropriate techniques
are devised. The design of these techniques, however,
must be guided by a required functionality: finding
interactions, more precisely, finding relations. In
particular, this thesis focuses on interactions due to
complex relations among primitive attributes. Then,
concepts can be simple in terms of relations, but
complex in terms of primitive attributes. Such focus is
motivated by relations that appear in protein folding
and other domains. To facilitate learning when relations
create complex interactions, an approach based on the
algebraic notions of relation and relational operators
is proposed. The approach is implemented in MRP, a
learning system that relies on multidimensional
relational projection to find relations and hence, find
interactions that can be captured as relations among
attributes. Synthetic and real-world problems are used
to empirically evaluate MRP with respect to five
classical and advanced machine learning systems. MRP's
distinctive behavior is analyzed in terms of concept
characteristics (such as DNF size, entropy, variation,
and Fourier spectrum), and related to the system's
performance in real-world domains. Finally, a small
family of simplified versions of MRP is evaluated
empirically to analyze what components of MRP are
responsible for its improved performance, and this
analysis is used to focus the proposal for future
research directions and system extensions.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  2917 </NUMBER>
<ORDER>   AAG9716114 </ORDER>
<TITLE> NAGGING: A GENERAL, FAULT-TOLERANT APPROACH TO PARALLEL SEARCH PRUNING  </TITLE>
<AUTHOR> STURGILL, DAVID BRIAN </AUTHOR>
<YEAR> 1997 </YEAR>
<INSTITUTION> CORNELL UNIVERSITY; 0058 </INSTITUTION>
<DESCRIPTORS> COMPUTER SCIENCE; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> NIL </ADVISER>
<CLASSIFICATIONS> THEOREM PROVING, ARTIFICIAL INTELLIGENCE </CLASSIFICATIONS>
<ABSTRACT>
For some interesting problems, all known algorithms
rely, to some degree, on exhaustive search. Since
combinatorial search cannot scale to large problem
instances, no general-case solutions to these problems
are available. However, because solutions to many of
these problems have practical value, various software
techniques have been developed to avoid or reduce search
in a number of useful, special cases. Unfortunately,
different software techniques exhibit varying
performance advantages from one problem instance to the
next; given a particular problem instance, it is not
always clear which approach would be most effective.
This paper introduces a parallel search-pruning
technique called nagging which is a means of
coordinating the activity of a number of different
search procedures. Under this technique, search-based
problem solvers compete in parallel to solve parts of a
particular problem instance. Each problem solver
contributes to advancing the search wherever it is the
most effective.
Nagging's intrinsic fault tolerance and scalability make
it particularly suitable for commonly available, low-
bandwidth, high-latency distributed computing
environments. It s sufficiently general to be effective
in a number of domains. A prototype implementation has
been developed for first-order theorem proving, a domain
both responsive to a very simple nagging model and
amenable to many refinements of this model. Nagging is
evaluated by testing this implementation on a suite of
well-known theorem proving problems.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  2918 </NUMBER>
<ORDER>   AAG9714900 </ORDER>
<TITLE> NEURAL NETWORK TRAINING ALGORITHMS BASED ON QUADRATIC ERROR SURFACE MODELS </TITLE>
<AUTHOR> MUKHERJEE, SAYANDEV </AUTHOR>
<YEAR> 1997 </YEAR>
<INSTITUTION> CORNELL UNIVERSITY; 0058 </INSTITUTION>
<DESCRIPTORS> ENGINEERING, ELECTRONICS AND ELECTRICAL; STATISTICS; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> TERRENCE L. FINE </ADVISER>
<CLASSIFICATIONS> NIL </CLASSIFICATIONS>
<ABSTRACT>
Nonlinear parametric estimators, such as neural
networks, have found wide use in a variety of fields,
including digital communications, but their increasing
utility is predicated upon the development of efficient
training algorithms, i.e., schemes to select the
parameters of the network so as to minimize mean squared
error upon a given training set in the hope that the
expected squared error upon a fresh observation is also
minimized. We shall consider only neural networks, but
the results are also applicable to other parametric
models.
All the usual numerical methods used to minimize the
training error only converge to one of possibly
exponentially many local minima of the highly irregular
error surface. Thus, knowledge of the nature of the
error surface would be helpful in training. Our
investigation of the failure of conventional statistical
models for surfaces leads us to revert to the simple
locally-quadratic model for the error surface which has
the advantage of robustness.
Iterative optimization leads to a sequence of errors and
gradients. The information contained in this sequence is
ignored in steepest-descent training algorithms, and in
second-order algorithms like the Levenberg-Marquardt
algorithm (though not in quasi-Newton or Conjugate
Gradient algorithms). Our locally-quadratic error
surface model leads us to propose a new training
algorithm that is able to utilize the information
contained in the previous weight estimates during the
course of iterative training.
The error surface contains many local minima of varying
depths, and the training algorithm may get stuck at a
suboptimal local minimum. To attack this problem, we
present a class of algorithms based upon the concept of
"ensemble pruning" that permits us to assess the promise
of networks trained starting from an ensemble of
networks with possibly different architectures and
different random initializations, and eliminate many of
them early in their training. This process yields a
small group of good, well-trained networks, selected
within given bounds on total training time. Our
conclusions are supported by analysis and simulations.
We also illustrate this with a practical application to
short-term load forecasting.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  2919 </NUMBER>
<ORDER>   AAG9714887 </ORDER>
<TITLE> EXPERT SYSTEM DEVELOPMENT FOR SOIL TAXONOMY </TITLE>
<AUTHOR> GALBRAITH, JOHN MICHAEL </AUTHOR>
<YEAR> 1997 </YEAR>
<INSTITUTION> CORNELL UNIVERSITY; 0058 </INSTITUTION>
<DESCRIPTORS> AGRICULTURE, SOIL SCIENCE; AGRICULTURE, AGRONOMY; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> RAY B. BRYANT </ADVISER>
<CLASSIFICATIONS> CLASSIFICATION </CLASSIFICATIONS>
<ABSTRACT>
Expert systems, computer programs that aid decision
making by employing the knowledge and reasoning of human
experts, are becoming mainstream technology for encoding
identification keys of natural objects. This study
determined the feasibility of developing an automated
expert system as a tool for using Soil Taxonomy to
identify soils from stored data, using the most
appropriate methods and features of existing expert
systems for natural objects. The rules for the first
four soil orders were translated into decision tree
format and heuristic knowledge (expert rules) added to
prevent indecision in case of missing data. A prototype
expert system was developed and tested on example data
sets using an object-oriented expert system shell to
encode the logic, calculate properties, and build
objects to represent the pedon and its subsections. A
combination of forward- and backward-chaining inference
procedure using an on-line key identification method was
found most suitable for Soil Taxonomy because of the
purely phenetic nature and single-access approach of the
keys. The characteristics of the rules and the polypedon
required object-oriented programming techniques to
represent and manage properties for the pedon and its
subsections. Almost 200 decision trees were encoded with
the expert system shell to evaluate pedon data. The
minimum set of data required to prevent indecision
included 13 independent properties from field
descriptions that were required to contain data for each
soil horizon; 20 independent properties with default
values, and three properties that supplied estimated
values with case statements. Sixty-seven objects, 70
independent properties, and 135 calculated properties
were needed to define the 27 subsections and nonspatial
differentiae named in the rules to identify the first
four soil orders. The final prototype quickly and
correctly identified the diagnostic subsections and the
soil order. We recommend changes in policy and
procedures for recording soil description data;
development of the knowledge base to incorporate fuzzy
logic techniques for identification and improve the
expert rules with links to demon GIS program data input;
and prototype feature improvement to complete a user-
friendly expert system for all orders in Soil Taxonomy.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  2920 </NUMBER>
<ORDER>   AAG9715311 </ORDER>
<TITLE> THE EFFECTS OF STUDENT CREATED EXPERT SYSTEMS ON THE REASONING AND CONTENT LEARNING OF DEAF STUDENTS </TITLE>
<AUTHOR> WILSON, LOUISE MARIAN </AUTHOR>
<YEAR> 1997 </YEAR>
<INSTITUTION> UNIVERSITY OF MINNESOTA; 0130 </INSTITUTION>
<DESCRIPTORS> EDUCATION, SPECIAL; EDUCATION, CURRICULUM AND INSTRUCTION; ARTIFICIAL INTELLIGENCE; EDUCATION, SECONDARY </DESCRIPTORS>
<ADVISER> SUSAN ROSE </ADVISER>
<CLASSIFICATIONS> COMPUTERS, PROGRAMMING </CLASSIFICATIONS>
<ABSTRACT>
This study investigated the impact of teaching deaf
students to become developers of simple expert system
knowledge bases. The students studied content, created
problem solving flowcharts and decision trees and
entered the resulting problem-solving knowledge base
into an expert system shell. It was hypothesized that
student experiences with the design process and the
computer modeling tool would positively affect content
learning and reasoning in the areas of categorization
and conditional reasoning.
Twenty-one deaf high school students from the Minnesota
State Academy for the Deaf participated in one of three
groups: an Initial Treatment group (IT) which designed
three knowledge bases; a Delayed Treatment group (DT)
which designed two knowledge bases; and a Non-Treatment
control group (NT). Two of the knowledge bases and
resulting expert systems dealt with content in social
studies: current events and geographical continents. The
third project involved the writing of an advice-giving
expert system on a topic of the students' choosing.
Statistically significant learning of content was
demonstrated for both treatment groups though no
significant increase in the two reasoning processes was
demonstrated. Differences between the two treatment
groups was significant in the area of conditional
reasoning. Analysis of taped protocols during
independent student group revealed active levels of
participation and demonstrated spontaneous use of the
two reasoning processes. Knowledge of content and
evidence of categorical and conditional reasoning was
present as well during post-treatment student
interviews. Value of the structured process, use of
modeling tools, and cooperative team work were
demonstrated.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  2921 </NUMBER>
<ORDER>   AAG9714203 </ORDER>
<TITLE> STOCHASTIC NEURAL NETWORKS AND THEIR APPLICATIONS TO REGRESSION ANALYSIS AND TIME SERIES FORECASTING </TITLE>
<AUTHOR> WONG, SAMUEL PO-SHING </AUTHOR>
<YEAR> 1997 </YEAR>
<INSTITUTION> STANFORD UNIVERSITY; 0212 </INSTITUTION>
<DESCRIPTORS> STATISTICS; COMPUTER SCIENCE; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> TZE-LEUNG LAI </ADVISER>
<CLASSIFICATIONS> NIL </CLASSIFICATIONS>
<ABSTRACT>
Neural networks recently attracted a lot of attention
from a variety of disciplines including engineering,
finance, computer science, applied mathematics and
statistics. Although the methodology has been claimed to
be successful in different areas, the commonly-used
estimation algorithm "back-propagation" is still
difficult to apply, especially when the number of
parameters is large.
In order to ease the estimation difficulty, we propose a
new model, namely, the stochastic neural network (SNN).
SNN shares the universal approximation property with the
neural networks and provides a parallel estimation
procedure which is an application of the EM algorithm
(Dempster, Laird and Rubin (1977)). Besides, we provide
a stepwise model selection procedure for SNN to avoid
overfitting. Both estimation and model selection
procedures are shown to be successful in simulated and
real examples.
Another popular application of neural networks is time
series forecasting. An easy-to-check condition for the
geometric ergodicity of SNN is given. SNN gives reliable
non-linear forecasts for various simulated and real time
series.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  2922 </NUMBER>
<ORDER>   AAIMM98577 </ORDER>
<TITLE> TRAJECTORY CONTROL OF ROBOTIC MANIPULATORS BY USING A FEEDBACK-ERROR-LEARNING NEURAL NETWORK </TITLE>
<AUTHOR> HAMAVAND, ZARYAB </AUTHOR>
<YEAR> 1994 </YEAR>
<INSTITUTION> CARLETON UNIVERSITY (CANADA); 0040 </INSTITUTION>
<DESCRIPTORS> ENGINEERING, MECHANICAL; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> H. M. SCHWARTZ; D. L. RUSSELL </ADVISER>
<CLASSIFICATIONS> NIL </CLASSIFICATIONS>
<ABSTRACT>
This thesis presents a neural network based control
strategy for trajectory control of robot manipulators.
The neural network learns the inverse dynamics of a
robot manipulator without any a priori knowledge of the
manipulator's inertial parameters nor any a priori
knowledge of the equation of dynamics. A two step
feedback-error-learning process is proposed.
Strategies for selection of the training trajectories is
discussed. The methods of finding the training
trajectories for the simulation and the experiment have
been presented. The difficulties with on-line training
are discussed and simulation results show these
difficulties. A simulation of a two degree of freedom
serial link manipulator illustrates the effectiveness of
the proposed method. The output of the neural network
was compared with the actual inverse dynamic function of
the manipulator. The neural network learned the diverse
dynamic of the manipulator and was able to follow any
arbitrary trajectory in the robot workspace with a high
degree of accuracy. Experiments were performed on a two
degree of freedom, direct drive manipulator. The
experimental results are very good.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  2923 </NUMBER>
<ORDER>   AAG9714113 </ORDER>
<TITLE> A NEURAL NETWORK MODEL OF MICRO- AND MACROPROSODY </TITLE>
<AUTHOR> FLEMING, MICHAEL KENYATTA </AUTHOR>
<YEAR> 1997 </YEAR>
<INSTITUTION> STANFORD UNIVERSITY; 0212 </INSTITUTION>
<DESCRIPTORS> PSYCHOLOGY, COGNITIVE; LANGUAGE, LINGUISTICS; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> DAVID RUMELHART </ADVISER>
<CLASSIFICATIONS> MICROPROSODY, CONNECTIONISM </CLASSIFICATIONS>
<ABSTRACT>
Prosodic variation is an essential factor in human
speech. Changes in the pitch and rhythm of speech over
the course of an utterance can completely alter it's
meaning, and the listener's impression of the speaker's
intent and internal state. Accordingly, prosody and
models of prosody are extremely relevant to areas in
psychology such as human factors, second language
acquisition, affective communication, and
neuropsychology. However, traditional models of prosody,
as measured by their performance in speech synthesis
applications, fail to produce reasonable output:
computer speech is currently flat, inappropriate and
stilted.
It is hypothesized that the main source of this deficit
is an absence of microprosodic variation. By generating
intonations through the concatenation of predefined
pitch contour segments traditional models may eliminate
vital prosodic details at the syllabic and phonetic
levels. In order to test this theory a connectionist
model of intonation was constructed with explicit
attention to microprosody. This network model was then
trained on a set of 330 simple statements read from text
by a single individual. A random portion of these
statements were withheld as a validation set on each
run, and numerical results for this set were collected
as a means of measuring generalization. The model
outperformed all systems (on their own metrics) that the
author was able to locate in the literature.
However, the ultimate test of prosodic quality is human
judgment. In order to measure the model's performance
more accurately, eight human subjects were asked to
listen to and evaluate as 'human' or 'computer' 99 of
the 330 statements. A formant synthesizer was used to
overlay intonations from the human reader, the network
model, and a state-of-the-art synthesizer from AT&T onto
these utterances in equal proportions before
presentation. The network model's intonations were rated
'human' much more often than AT&T's, yet were
statistically indistinguishable from the human's.
These results strongly support the hypothesized
importance of microprosody. While the model presented
here is only a first step and the domain addressed is a
relatively small one, the performance obtained is
unprecedented and clearly justifies further work in this
area.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  2924 </NUMBER>
<ORDER>   AAG9714078 </ORDER>
<TITLE> LEARNING ACTION MODELS FOR REACTIVE AUTONOMOUS AGENTS </TITLE>
<AUTHOR> BENSON, SCOTT SHERWOOD </AUTHOR>
<YEAR> 1997 </YEAR>
<INSTITUTION> STANFORD UNIVERSITY; 0212 </INSTITUTION>
<DESCRIPTORS> COMPUTER SCIENCE; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> NILS NILSSON </ADVISER>
<CLASSIFICATIONS> MACHINE LEARNING, ARTIFICIAL INTELLIGENCE, PLANNING </CLASSIFICATIONS>
<ABSTRACT>
To be maximally effective, autonomous agents such as
robots must be able both to react appropriately in
dynamic environments and to plan new courses of action
in novel situations. Reliable planning requires accurate
models of the effects of actions--models which are often
more appropriately learned through experience than
design. This thesis describes TRAIL (Teleo-Reactive
Agent with Inductive Learning), an integrated agent
architecture which learns models of actions based on
experiences in the environment. These action models are
then used to create plans that combine both goal-
directed and reactive behaviors.
Previous work on action-model learning has focused on
domains that contain only deterministic, atomic action
models that explicitly describe all changes that can
occur in the environment. The thesis extends this
previous work to cover domains that contain durative
actions, continuous variables, nondeterministic action
effects, and actions taken by other agents. Results have
been demonstrated in several robot simulation
environments and the Silicon Graphics, Inc. flight
simulator.
The main emphasis in this thesis is on the action-model
learning process within TRAIL. The content begins the
learning process by recording experiences in its
environment either by observing a trainer or by
executing a plan. Second, the agent identifies instances
of action success or failure during these experiences
using a new analysis demonstrating nine possible causes
of action failure. Finally, a variant of the Inductive
Logic Programming algorithm DINUS is used to induce
action models based on the action instances. As the
action models are learned, they can be used for
constructing plans whose execution contributes to
additional learning experiences. Diminishing reliance on
the teacher signals successful convergence of the
learning process.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  2925 </NUMBER>
<ORDER>   AAG9714251 </ORDER>
<TITLE> PREDICTING STOCK INDEX RETURNS BY MEANS OF GENETICALLY ENGINEERED NEURAL NETWORKS </TITLE>
<AUTHOR> WESTHEIDER, OLAF </AUTHOR>
<YEAR> 1997 </YEAR>
<INSTITUTION> UNIVERSITY OF CALIFORNIA, LOS ANGELES; 0031 </INSTITUTION>
<DESCRIPTORS> ECONOMICS, FINANCE; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> E. BURTON SWANSON </ADVISER>
<CLASSIFICATIONS> MARKET EFFICIENCY </CLASSIFICATIONS>
<ABSTRACT>
Artificial intelligence techniques such as neural
networks and genetic algorithms are gaining increased
attention by the financial investment community. In this
dissertation, the ability of genetically engineered
neural networks to predict monthly stock index returns
is compared to that of traditional linear techniques.
Using stock index and economic data from 1954 to 1992, a
standard genetic algorithm is used to determine the
architectures of backpropagation neural networks and to
identify, the most powerful network inputs from a pool
of potential input variables.
This dissertation confirms earlier findings in the
finance literature that monthly stock index returns are
not completely unpredictable and that predictability was
highest during periods of high volatility, in particular
during the 1970s. The results from this research project
suggest that neural networks are superior in forecasting
monthly index returns when statistical criteria are used
to measure forecasting performance. However, this
superior forecasting performance does not translate into
higher financial gains when the forecasts are used
within a simple investment strategy, suggesting that
only a weak link exists between statistical and economic
forecasting performance. In addition, this dissertation
finds little evidence that the input variables isolated
within the genetic algorithm lead to better forecasting
performance than simply using all economic variables as
neural network inputs.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  2926 </NUMBER>
<ORDER>   AAG9710122 </ORDER>
<TITLE> PROGRESSIVE PARTIAL MEMORY LEARNING </TITLE>
<AUTHOR> MALOOF, MARCUS ACKLE </AUTHOR>
<YEAR> 1997 </YEAR>
<INSTITUTION> GEORGE MASON UNIVERSITY; 0883 </INSTITUTION>
<DESCRIPTORS> COMPUTER SCIENCE; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> RYSZARD S. MICHALSKI </ADVISER>
<CLASSIFICATIONS> ARTIFICIAL INTELLIGENCE, MACHINE LEARNING </CLASSIFICATIONS>
<ABSTRACT>
A learning methodology called Progressive Partial Memory
Learning (PPML) is presented. PPML takes a partial
memory approach to progressive inductive learning
problems in which training examples are distributed over
time. The partial memory approach retains and uses
representative examples and induced concept descriptions
for future learning. Representative examples are those
training examples that maximally expand and constrain
concept descriptions in the representation space.
Mechanisms such as the selection of representative
examples, forgetting, and aging allow the system to
efficiently learn concepts over time and to track
changing concepts through a representation space. Key
components of the methodology are implemented in an
experimental system called AQ-Partial Memory (AQ-PM),
which is based on the AQ15c inductive learning system.
AQ-PM is experimentally validated against a baseline
AQ15c learning algorithm using both synthetic and real-
world data sets. Synthetic data sets include problems in
which concepts change or drift in the representation
space. Real-world problems include applications to
dynamic knowledge bases (i.e., computer intrusion
detection), intelligent agents (i.e., email sorting),
and computer vision (ie., blasting cap detection in x-
ray images). Results demonstrate that the methodology is
able to perform well on a variety of problems.
Specifically, the method considerably improves memory
requirements and learning time with slight decreases in
predictive accuracy when compared to the baseline
learner. Furthermore, the method is also able to track
concept drift. Results are presented for the STAGGER
concepts in which AQ-PM achieves predictive accuracies
comparable to the FLORA systems, but requires much less
memory. Comparisons are made to the AQ11 and GEM
incremental learning systems using the blasting cap
detection and computer intrusion detection problems in
which they learned more predictive, but more complex
concept descriptions than AQ-PM. Partial memory learning
is also conducted using the incremental learning
algorithms of AQ11 and GEM for the blasting cap
detection and computer intrusion detection problems.
Results for the partial memory versions of these
learners, when compared to the unmodified versions, show
slight decreases in predictive accuracy and concept
complexity with considerable decreases in learning time.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  2927 </NUMBER>
<ORDER>   AAG9709784 </ORDER>
<TITLE> LEARNING, ANISOTROPIC DIFFUSION, NONLINEAR FILTERING AND SPACE-VARIANT VISION </TITLE>
<AUTHOR> FISCHL, BRUCE </AUTHOR>
<YEAR> 1997 </YEAR>
<INSTITUTION> BOSTON UNIVERSITY; 0017 </INSTITUTION>
<DESCRIPTORS> ENGINEERING, ELECTRONICS AND ELECTRICAL; COMPUTER SCIENCE; BIOLOGY, NEUROSCIENCE; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> ERIC SCHWARTZ </ADVISER>
<CLASSIFICATIONS> NIL </CLASSIFICATIONS>
<ABSTRACT>
Images are frequently corrupted by noise and blurring
from various sources. To alleviate these distortions,
many vision systems employ filtering to reduce noise and
enhance contrast in regions which are presumed to
correspond to object borders. The logical extreme of
this process is a piecewise constant image with step
discontinuities at region boundaries. This goal is
unattainable using linear filtering, as it blurs and
possibly destroys boundary information.
Anisotropic diffusion provides noise reduction and
contrast enhancement by modulating the amount of
blurring as a function of local image structure. This
approach can produce impressive quality images, but
suffers from a number of drawbacks. The most prominent
of these are the computational cost of diffusion,
coupled with the need for serial integration. These
computational concerns make diffusion impractical for
most real-time machine vision systems. While nonlinear
diffusion models certain human perceptual phenomena
well, it remains to be determined how such a process is
carried out in vivo. Although complex processing is
possible in these situations, the rapid nature of
perception relative to neural time constants makes it
almost certainly parallel in nature.
These issues are resolved in a number of ways. First, a
learning scheme is developed which obviates the need for
temporal integration of the anisotropic diffusion
equation. This yields an algorithm which is an order of
magnitude faster than anisotropic diffusion, while
resolving drawbacks such as noise intolerance,
instability, seriality, and the need for regularization.
A heuristic extension of this approach achieves noise
reduction and contrast enhancement comparable to
anisotropic diffusion at far less computational cost. An
attentional algorithm for license plate detection in an
unconstrained visual scene is then developed to
quantitatively measure the performance of a variety of
nonlinear filters.
A second approach is to reduce the requisite number of
serial steps by integrating the anisotropic diffusion
equation using an adaptive grid-size algorithm. An
investigation of the geometric structure of the
mammalian retino-cortical mapping reveals that it
implicitly encodes a variable grid-size integration
scheme, achieving exponential integration rates in the
periphery, and producing large-scale image enhancement
in relatively few time steps.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  2928 </NUMBER>
<ORDER>   AAG9629556 </ORDER>
<TITLE> A COMBINATORIAL NEURAL NETWORK EXHIBITING EPISODIC AND SEMANTIC MEMORY PROPERTIES FOR SPATIO-TEMPORAL PATTERNS </TITLE>
<AUTHOR> RINKUS, GERARD J. </AUTHOR>
<YEAR> 1997 </YEAR>
<INSTITUTION> BOSTON UNIVERSITY; 0017 </INSTITUTION>
<DESCRIPTORS> PSYCHOLOGY, COGNITIVE; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> DANIEL H. BULLOCK </ADVISER>
<CLASSIFICATIONS> NIL </CLASSIFICATIONS>
<ABSTRACT>
A model is described in which three types of memory--
episodic memory, complex sequence memory and semantic
memory--coexist within a single distributed associative
memory. Episodic memory stores traces of specific
events. Its basic properties are: high capacity, single-
trial learning, memory trace permanence, and ability to
store non-orthogonal patterns. Complex sequence memory
is the storage of sequences in which states can recur
multiple times: e.g. (A B B A C B A). Semantic memory is
general knowledge of the degree of featural overlap
between the various objects and events in the world. The
model's initial version, TEMECOR-I, exhibits episodic
and complex sequence memory properties for both
uncorrelated and correlated spatio-temporal patterns.
Simulations show that its capacity increases
approximately quadratically with the size of the model.
An enhanced version of the model, TEMECOR-II, adds
semantic memory properties.
The TEMECOR-I model is a two-layer network that uses a
sparse, distributed internal representation (IR) scheme
in its layer two (L2). Noise and competition allow the
IRs of each input state to be chosen in a random
fashion. This randomness effects an orthogonalization in
the input-to-IR mapping, thereby increasing capacity.
Successively activated IRs are linked via Hebbian
learning in a matrix of horizontal synapses. Each L2
cell participates in numerous episodic traces. A
variable threshold prevents interference between traces
during recall.
The random choice of IRs in TEMECOR-I precludes the
continuity property of semantic memory: that there be a
relationship between the similarity (degree of overlap)
of two IRs and the similarity of the corresponding
inputs. To create continuity in TEMECOR-II, the choice
of the IR is a function of both noise ($Lambda$) and
signals propagating in the L2 horizontal matrix and
input-to-IR map. These signals are deterministic and
shaped by prior experience. On each time slice, TEMECOR-
II computes an expected input based on the history-
dependent influences, then computes the difference
between the expected and actual inputs. When the current
situation is completely familiar, $Lambda$ = 0 and the
choice of IRs is determined by the history-dependent
influences. The resulting IR has large overlap with
previously-used IRs. As perceived novelty increases, so
does $Lambda$, with the result that the overlap between
the chosen IR and any previously-used IRs decreases.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  2929 </NUMBER>
<ORDER>   AAG9629548 </ORDER>
<TITLE> NEURAL NETWORKS FOR LEARNING AND PREDICTION WITH APPLICATIONS TO REMOTE SENSING AND SPEECH PERCEPTION </TITLE>
<AUTHOR> GJAJA, MARIN N. </AUTHOR>
<YEAR> 1997 </YEAR>
<INSTITUTION> BOSTON UNIVERSITY; 0017 </INSTITUTION>
<DESCRIPTORS> COMPUTER SCIENCE; REMOTE SENSING; ARTIFICIAL INTELLIGENCE; BIOLOGY, NEUROSCIENCE </DESCRIPTORS>
<ADVISER> GAIL A. CARPENTER </ADVISER>
<CLASSIFICATIONS> ADAPTIVE RESONANCE, COMPUTATIONAL NEUROSCIENCE </CLASSIFICATIONS>
<ABSTRACT>
Neural networks for supervised and unsupervised learning
are developed and applied to problems in remote sensing,
continuous map learning, and speech perception. Adaptive
Resonance Theory (ART) models are real-time neural
networks for category learning, pattern recognition, and
prediction. Unsupervised fuzzy ART networks synthesize
fuzzy logic and neural networks, and supervised ARTMAP
networks incorporate ART modules for prediction and
classification. New ART and ARTMAP methods resulting
from analyses of data structure, parameter
specification, and category selection are developed.
Architectural modifications providing flexibility for a
variety of applications are also introduced and
explored.
A new methodology for automatic mapping from Landsat
Thematic Mapper (TM) and terrain data, based on fuzzy
ARTMAP, is developed. System capabilities are tested on
a challenging remote sensing problem, prediction of
vegetation classes in the Cleveland National Forest from
spectral and terrain features. After training at the
pixel level, performance is tested at the stand level,
using sites not seen during training. Results are
compared to those of maximum likelihood classifiers,
back propagation neural networks, and K-nearest neighbor
algorithms. Best performance is obtained using a hybrid
system based on a convex combination of fuzzy ARTMAP and
maximum likelihood predictions. This work forms the
foundation for additional studies exploring fuzzy
ARTMAP's capability to estimate class mixture
composition for non-homogeneous sites.
Exploratory simulations apply ARTMAP to the problem of
learning continuous multidimensional mappings. A novel
system architecture retains basic ARTMAP properties of
incremental and fast learning in an on-line setting
while adding components to solve this class of problems.
The perceptual magnet effect is a language-specific
phenomenon arising early in infant speech development
that is characterized by a warping of speech sound
perception. An unsupervised neural network model is
proposed that embodies two principal hypotheses
supported by experimental data--that sensory experience
guides language-specific development of an auditory
neural map and that a population vector can predict
psychological phenomena based on map cell activities.
Model simulations show how a nonuniform distribution of
map cell firing preferences can develop from language-
specific input and give rise to the magnet effect.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  2930 </NUMBER>
<ORDER>   AAIMM98039 </ORDER>
<TITLE> CONCEPTION ET REALISATION D'UN PROTOTYPE DE SYSTEME EXPERT D'AIDE A LA PLANIFICATION STRATEGIQUE DANS LES UNIVERSITES </TITLE>
<AUTHOR> OUELLET, STEEVE </AUTHOR>
<YEAR> 1994 </YEAR>
<INSTITUTION> UNIVERSITE LAVAL (CANADA); 0726 </INSTITUTION>
<DESCRIPTORS> COMPUTER SCIENCE; EDUCATION, ADMINISTRATION; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> PIERRE ARDOUIN </ADVISER>
<CLASSIFICATIONS> FRENCH TEXT </CLASSIFICATIONS>
<ABSTRACT>
La realisation d'outils informatiques pour assister des
taches comme la planification strategique implique une
modelisation serieuse. Dans la perspective du
developpement d'un systeme a base de connaissances
permettant de supporter cette activite, cette etude
s'est affairee a appliquer l'approche a base de cas a ce
domaine.
La recherche a donc gravite autour des modeles
d'expertise de la planification de la programmation
d'une universite. Les principaux modeles concernent
l'appariement des cas, base sur une approche de
comparaison d'hypercubes, et les modeles statistiques
d'adaptation des cas. Les consequences de l'approche a
base de cas sur la methodologie de developpement de
systemes experts sont aussi discutees. Consequemment a
cette etude, Le systeme SEAPLANS a ete developpe.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  2931 </NUMBER>
<ORDER>   AAIMM97776 </ORDER>
<TITLE> REPRESENTATION DES CONNAISSANCES DANS LES SYSTEMES EXPERTS TEMPS REEL PAR LE BIAIS DE GRAPHES TEMPORELS: APPLICATION A UN SYSTEME D'AIDE A LA CONDUITE </TITLE>
<AUTHOR> BOUZOUBA, MOHAMED KARIM </AUTHOR>
<YEAR> 1994 </YEAR>
<INSTITUTION> UNIVERSITE LAVAL (CANADA); 0726 </INSTITUTION>
<DESCRIPTORS> COMPUTER SCIENCE; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> GERARD SIMIAN </ADVISER>
<CLASSIFICATIONS> FRENCH TEXT </CLASSIFICATIONS>
<ABSTRACT>
Ces dernieres annees, les Systemes a Base de
Connaissances (SBC) ont connu une tres grande expansion
mais la majorite d'entre eux sont limites de facon
majeure par l'absence d'une representation explicite du
temps, et par la difficulte de prendre en compte des
connaissances temporelles. On parle alors de
raisonnement temporel. De nos jours egalement, les
applications dites temps reel sont tres interessantes et
posent un reel defi quant a leur realisation. Ces
applications se retrouvent dans plusieurs domaines
industriels: le controle de processus, l'aerospatiale,
la robotique ou encore le transport. Un SBC est dit
temps reel s'il garantit un temps de reponse adequat
face aux evenements exterieurs du procede qu'il
controle.
Dans le cadre de ce memoire, et apres une etude des
modeles de raisonnement temporel et temps reel, nous
proposons pour la representation des connaissances de
systemes exploitant ces deux types de raisonnement,
l'utilisation du concept des graphes temporels.
Pour l'"execution" de ces graphes, nous avons developpe
une maquette reposant sur un systeme a base d'acteurs et
nous avons illustre son utilisation dans le contexte des
Systemes Intelligents Vehicules/Routes et plus
particulierement d'un systeme d'aide a la conduite.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  2932 </NUMBER>
<ORDER>   AAIMM97748 </ORDER>
<TITLE> INTEGRATION D'UNE METHODOLOGIE DE DEVELOPPEMENT DE SYSTEMES A BASE DE CONNAISSANCES A UNE METHODOLOGIE DE DEVELOPPEMENT DE SYSTEMES D'INFORMATION </TITLE>
<AUTHOR> BILODEAU, PATRICE </AUTHOR>
<YEAR> 1994 </YEAR>
<INSTITUTION> UNIVERSITE LAVAL (CANADA); 0726 </INSTITUTION>
<DESCRIPTORS> COMPUTER SCIENCE; ARTIFICIAL INTELLIGENCE; INFORMATION SCIENCE </DESCRIPTORS>
<ADVISER> GERARD SIMIAN </ADVISER>
<CLASSIFICATIONS> FRENCH TEXT </CLASSIFICATIONS>
<ABSTRACT>
Les developpements des systemes a base de connaissances
(SBC) s'effectuent tres souvent selon des methodologies
tres particulieres a cause de la nature meme de ces
systemes. Les methodologies traditionnelles sont concues
pour developper des systemes d'information (SI) et ne
sont pas pourvues des particularites methodologiques
necessaires pour developper des SBC. Elles sont ainsi
laissees de cote.
Cependant, il s'avere que si on peut definir un SBC
comme etant un systeme d'information comportant
principalement des composantes a base de connaissances,
il devient possible de developper un tel systeme a
l'aide d'une methodologie traditionnelle a laquelle on
aura ajoute les elements particuliers au developpement
de SBC. C'est afin de fournir une telle methodologie que
le present ouvrage presente une adaptation
methodologique. Celle-ci a ete effectuee sur une
methodologie traditionnelle reconnue, PRODUCTIVITE+ du
groupe DMR (appelee ici methodologie MMSRFP en raison du
Ministere qui l'a utilisee pour l'experimentation) a
laquelle on a integre une methodologie de SBC reconnue,
KADS.
Dans cet ouvrage, nous allons presenter les deux
methodologies, faire ressortir les points communs,
integrer a la methodologie MMSRFP les elements de
developpement de SBC de la methodologie KADS et
presenter une experimentation effectuee dans un projet
reel.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  2933 </NUMBER>
<ORDER>   AAGMM11381 </ORDER>
<TITLE> INTEGRATED DISTRIBUTED INTELLIGENT SYSTEM FOR DIFFERENTIAL PRESSURE FLOWMETER SELECTION AND SIZING </TITLE>
<AUTHOR> STEVENSON, MURRAY GLENN RICHARD </AUTHOR>
<YEAR> 1994 </YEAR>
<INSTITUTION> UNIVERSITY OF ALBERTA (CANADA); 0351 </INSTITUTION>
<DESCRIPTORS> ENGINEERING, CHEMICAL; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> NIL </ADVISER>
<CLASSIFICATIONS> NIL </CLASSIFICATIONS>
<ABSTRACT>
The selection of an appropriate flowmeter for a specific
application is a difficult task because there is a large
decision-making space, numerous considerations and an
ill-structured problem. This results in a problem that
is not applicable to strictly numerical, algorithmic
type solutions. Therefore, artificial intelligence
techniques have been considered, which emphasize
symbolic reasoning and non-algorithmic solutions.
In order to assist non-experts in the selection of an
appropriate flowmeter for a specific application, an
integrated coordinated knowledge environment (computer
program) has been developed. This environment is based
on artificial intelligence and object-oriented program
techniques. In particular, the environment employs the
concept of an integrated distributed intelligent system
(IDIS). An IDIS combines independent specialized
software packages into an integrated coordinated
environment under the control of a meta-system.
In this thesis, an integrated distributed intelligent
system for differential pressure flowmeter selection and
sizing (IDISDPFSS) has been developed that assists non-
expert users select an appropriate flowmeter based on
users' specified requirements. Four flowmeter types can
be selected: variable area, V-Cone, flow nozzle and
orifice plate. If more than one flowmeter type is
applicable, the system will rank them accordingly. Once
the selection process is completed, the selected
flowmeters can be sized with numerical computational
packages integrated into the system. In addition, the
system integrates a viscosity coupling system for fluid
property prediction.
IDISDPFSS has a user-friendly interface and is
constructed so that new knowledge and flowmeter types
can be easily added. In order to achieve the coordinated
distributed knowledge environment, different software
packages, hardware platforms and operating systems are
integrated.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  2934 </NUMBER>
<ORDER>   AAIMM97663 </ORDER>
<TITLE> ADAPTIVE STRUCTURE NEURAL NETWORKS WITH APPLICATIONS TO EEG AUTOMATIC SEIZURE DETECTION </TITLE>
<AUTHOR> WENG, WEI </AUTHOR>
<YEAR> 1994 </YEAR>
<INSTITUTION> CONCORDIA UNIVERSITY (CANADA); 0228 </INSTITUTION>
<DESCRIPTORS> ENGINEERING, ELECTRONICS AND ELECTRICAL; ARTIFICIAL INTELLIGENCE; ENGINEERING, BIOMEDICAL </DESCRIPTORS>
<ADVISER> K. KHORASANI </ADVISER>
<CLASSIFICATIONS> NIL </CLASSIFICATIONS>
<ABSTRACT>
This thesis proposes a novel approach for Back-
Propagation (BP) structure level adaptation for
artificial neural networks (ANN). Back-propagation is
the most commonly used neural network algorithm. Back-
propagation allows the training of the weights in a feed-
forward neural network of arbitrary structure by
following a gradient steepest decent oath in weight
space. However, BP networks have limitations due to
their fixed network structure. This thesis will show how
a BP network may be improved by replacing the fixed
network structure with an adaptive one.
To improve the standard BP algorithm, a new scheme
designated as Adaptive Structure Algorithm (ASA) is
proposed to allow a neural network to adjust its
structure according to the characteristics of the input
data. To overcome the slow convergence of the BP
algorithm, a modified Delta Adaptation (DA) algorithm is
used in the ASA to speed up the training time.
Simulation results are presented to confirm the
improvements obtained as a result of utilizing the
proposed algorithms.
To demonstrate a practical application of the proposed
algorithm, OSLA is applied to automatic seizure
detection in Electroencephalogram (EEG) during long-term
monitoring of epilepsy. Satisfactory results are
obtained, substantiating the effectiveness of the new
algorithm.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  2935 </NUMBER>
<ORDER>   AAIMM97653 </ORDER>
<TITLE> NONPARAMETRIC REGRESSION ESTIMATION WITH APPLICATIONS IN RADIAL BASIS NETWORKS AND LEARNING </TITLE>
<AUTHOR> RAMANAN, SUBHA </AUTHOR>
<YEAR> 1994 </YEAR>
<INSTITUTION> CONCORDIA UNIVERSITY (CANADA); 0228 </INSTITUTION>
<DESCRIPTORS> STATISTICS; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> ADAM KRZYZAK </ADVISER>
<CLASSIFICATIONS> NIL </CLASSIFICATIONS>
<ABSTRACT>
Learning algorithms are analysed from the statistical
and neural network viewpoints. In the first part, the
regression based approach for minimizing the mean
squared error is considered. The decomposition of the
mean squared error into bias and variance components and
their contributions to the error are investigated.
Specifically, the k-nearest neighbor (k-NN) regression
estimator and the kernel regression estimator (KRE) are
studied. The optimal choice of the parameters of these
estimators is discussed. In the second part, the neural
network approach to the learning problem is explored.
Specifically, the Radial basis function (RBF) network is
studied in detail. The random sampling and clustering
methods of choosing the center parameter of the network
are analysed and compared. Comparisons between the RBF
nets and the KRE are studied. For both parts,
performance of the estimators are assessed by the mean
squared error and the results of simulation are
presented.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  2936 </NUMBER>
<ORDER>   AAIMM97635 </ORDER>
<TITLE> NEURAL NETWORK BASED MODELING AND CONTROL OF A FLEXIBLE- LINK MANIPULATOR </TITLE>
<AUTHOR> CHAUDHURI, ALOKE </AUTHOR>
<YEAR> 1994 </YEAR>
<INSTITUTION> CONCORDIA UNIVERSITY (CANADA); 0228 </INSTITUTION>
<DESCRIPTORS> ENGINEERING, ELECTRONICS AND ELECTRICAL; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> NIL </ADVISER>
<CLASSIFICATIONS> NIL </CLASSIFICATIONS>
<ABSTRACT>
Controlling the motion of a flexible-link manipulator
has been an ongoing concern in recent years. This
research work is aimed at developing a neural network
based strategy to solve the problem of tip-position
control for a single flexible-link manipulator. The
proposed controller uses a partitioned strategy, wherein
the inner loop stabilizes the plant, and the outer loop
(servo portion) provides set-point tracking. A
backpropagation network has been trained off-line to
accurately identify the unmodeled and/or inaccurately
modeled dynamics present in an actual manipulator, and
then applied in the inner loop of the closed-loop system
to compensate for these dynamics. A feed-through
compensator has been designed following the method of
transmission zero assignment, and used in the inner loop
to ensure closed-loop stability of this nonminimum phase
system. The serve loop employs a proportional plus
integral control strategy to track a desired trajectory
in two-dimensional space. In addition, a robust servo
controller has been designed using the internal model
principle, and its performance has been compared with
that of the PI type controller mentioned above.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  2937 </NUMBER>
<ORDER>   AAI9602040 </ORDER>
<TITLE> A COMPARISON OF TRAINING STRATEGIES FOR A BACKPROPAGATION NETWORK  </TITLE>
<AUTHOR> BLUME, FREDERICK J. </AUTHOR>
<YEAR> 1994 </YEAR>
<INSTITUTION> WICHITA STATE UNIVERSITY; 0260 </INSTITUTION>
<DESCRIPTORS> COMPUTER SCIENCE; ENGINEERING, INDUSTRIAL; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> NIL </ADVISER>
<CLASSIFICATIONS> NEURAL NETWORK </CLASSIFICATIONS>
<ABSTRACT>
This study examined the effect of fixed size training
strategies on neural network training times. Training
sets of size 20, 40, 80 and 160 exemplar pairs were
developed to map two examples of univariate curves
(single and multiple extrema) in order to examine the
relative effectiveness of ten selected random and
deterministic strategies. Correlation analysis and the
Kolmogorov-Smirnov statistic were used to examine
goodness of fit in mapping, while analysis of variance
was used to examine differences in strategy performance.
The Dudewicz-Dalal weighted ranking technique was used
in an attempt to rank the study strategies by
convergence cycle cost. The results of the study were:
(1) that strategies affect training speed was
demonstrated; (2) the uniform random exemplar selection
strategy was not clearly superior in the experimental
setting; (3) a methodology for assessing performance of
training strategies was demonstrated; and (4) the
uniform random exemplar selection strategy was not
always the best. It was not feasible to rank the
strategies in order of weighted cycles to convergence.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  2938 </NUMBER>
<ORDER>   AAI9601454 </ORDER>
<TITLE> ADVANCED CLASSIFICATION SYSTEM FOR BIOLOGICAL PRODUCTS </TITLE>
<AUTHOR> PRECETTI, CYRILLE JEAN FRANCOIS </AUTHOR>
<YEAR> 1994 </YEAR>
<INSTITUTION> PURDUE UNIVERSITY; 0183 </INSTITUTION>
<DESCRIPTORS> ENGINEERING, AGRICULTURAL; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> GARY W. KRUTZ </ADVISER>
<CLASSIFICATIONS> COLOR CLASSIFICATION </CLASSIFICATIONS>
<ABSTRACT>
Color classification is an important method in grading
agricultural and biological materials. The objective of
this thesis was to develop color classification methods
for biological products, with application to real-time
grading and seed corn husk deduction. A nomenclature of
classification systems was developed to formalize a
review of color classification methods. The description
and functional classifier types were introduced.
To overcome the limitations of available classifiers,
when applied to real-time hardware, two original
classifiers were developed using a binary representation
of class assignments in the color space. The binary
classifier of type one (BC1) used pairwise discriminant
functions, whereas the binary classifier of type two
(BC2) used a more complex logic. The binary
representations can be implemented with look-up tables
or template matching neural networks.
Three software packages and a number of tools,
implementing the color classifiers and error evaluation
methods, were developed. SPR implemented statistical
pattern recognition classifiers, nSPR implemented neural
network based classifiers, and Purclass implemented
binary classifiers. Four methods were developed to
evaluate classifier accuracy: (1) the global error
measurements with resubstitution error, leave-one-out
error, and hold-out error, (2) the confusion matrix
analysis for individual classes, (3) the dimensionality
analysis computing the resubstitution errors for all
possible combinations of color bands and classifiers,
and (4) a set of graphical representations of color
classification problems.
The software allowed further analysis of neural network
classifier' behavior. It was found, for the problem
studied, that the learning coefficient of the binary
linear classifier of type one (BLC1) did not influence
the convergence of the linear algorithms. The number of
iterations necessary to reach the best resubstitution
error was random.
The BC1 and BC2 algorithms were successfully implemented
on real-time image processing hardware. Classification
rate was 6 images per second with the BLC2 classifier,
for a three class problem, and 512 by 220 pixel color
images.
The developed real-time color classification system can
accurately classify seed corn images and the color
vision system improves the method of deduction, over the
current manual method.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  2939 </NUMBER>
<ORDER>   AAI9601062 </ORDER>
<TITLE> SELF-ORGANIZING NEURAL NETWORKS BASED ON GAUSSIAN MIXTURE MODEL FOR PDF ESTIMATION AND PATTERN CLASSIFICATION </TITLE>
<AUTHOR> SHIMOJI, SHUNICHI </AUTHOR>
<YEAR> 1994 </YEAR>
<INSTITUTION> UNIVERSITY OF SOUTHERN CALIFORNIA; 0208 </INSTITUTION>
<DESCRIPTORS> COMPUTER SCIENCE; ENGINEERING, ELECTRONICS AND ELECTRICAL; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> SUKHAN LEE </ADVISER>
<CLASSIFICATIONS> NIL </CLASSIFICATIONS>
<ABSTRACT>
This work proposes three new neural network models in
pattern processing for (1) PDF (probability density
function) estimation, (2) pattern classification, and
(3) feature extraction, while the major emphasis is
placed on the PDF estimation network. The distinctive
features of the proposed PDF estimation method are as
follows: (1) PDF of a class is modeled as being composed
of a number of Gaussian kernels called subclasses
(Gaussian Mixture Model). During the network training,
given class samples are decomposed probabilistically
into subclass samples based on the current subclass
PDFs, and the subclass PDFs are updated iteratively so
that the discrepancy between the current and the actual
subclass PDFs are reduced. (2) Subclasses are
automatically recruited to compensate the inaccuracy of
the PDF estimation, which is caused by the lack of the
number of subclasses and/or the occurrence of local
minima states (Self-Organization). The local minima
states are detected by applying Chi-square tests to
individual subclasses.
The proposed method provides the semi-parametric
estimation of an arbitrary form of PDFs, which allows
the network to avoid local minima. In addition, it is
shown that the parameters obtained by the network
training are equivalent to the maximum likelihood
estimation. As an application of the PDF estimation
network, a pattern classification network is designed
based on Bayesian criterion, which is known as the
theoretically optimal classification rule. Furthermore a
new method of feature extraction is proposed. Unlike
conventional feature extraction systems which process
patterns based on the variance of the distribution, the
proposed method promotes clustering of features to
comply with the classification process based on the
Gaussian Mixture Model. Simulations demonstrate the
superiority of the PDF estimation network, the feature
extraction system and the classification system.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  2940 </NUMBER>
<ORDER>   AAI9600965 </ORDER>
<TITLE> RECOGNITION OF UNCONSTRAINED HANDWRITTEN NUMERALS BASED ON DUAL COOPERATIVE NEURAL NETWORK </TITLE>
<AUTHOR> CHOI, YEONGWOO </AUTHOR>
<YEAR> 1994 </YEAR>
<INSTITUTION> UNIVERSITY OF SOUTHERN CALIFORNIA; 0208 </INSTITUTION>
<DESCRIPTORS> ENGINEERING, ELECTRONICS AND ELECTRICAL; COMPUTER SCIENCE; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> SUKHAN LEE </ADVISER>
<CLASSIFICATIONS> NIL </CLASSIFICATIONS>
<ABSTRACT>
A new neural network architecture called Dual
Cooperative Neural Network (DCN) is presented in this
dissertation for the recognition of totally
unconstrained handwritten numeral patterns with an
expectation of improved accuracy and reduced recognition
time. DCN implements within its structure observations
of human logical understanding and learning of numeral
patterns and invariance properties which are modeled
from biological visual system. The resulting structure
of DCN consists of two cooperative networks: a Cartesian
Network (CN) and a Log-Polar Network (LPN). The CN uses
inputs represented in Cartesian coordinates, and the LPN
uses the same inputs represented after the log-polar
mapping. In log-polar transformed representation,
rotation or scale of inputs in Cartesian coordinates
appears as horizontal or vertical shifts, which can be
easily detected by using nearby horizontal or vertical
feature detecting cells in log-polar feature maps. Also
both data representations have distinctiveness in their
shapes for recognition. Each network is also
hierarchically configured with three layers: a local
feature map layer, a maximum selection layer, and a
decision layer with back-propagation networks. DCN
achieves robustness to positional shift, rotation, and
scale by defining areas of feasible feature locations in
both feature maps. Distortion is handled by multiple and
blurred representative shapes generated by self-
organization of feature maps, and is also handled by
their combinations. The experimental results indicate
that DCN is robust to various forms of local and global
deformations in real data by achieving a 97.33%
recognition rate without rejection and 94.74% with
rejection for a 1% error with Zip code test numerals.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  2941 </NUMBER>
<ORDER>   AAI9600679 </ORDER>
<TITLE> FUZZY LOGIC SYSTEM-BASED MODELING AND CONTROL OF COMPLEX CHEMICAL PROCESSES </TITLE>
<AUTHOR> LISKA, JINDRICH </AUTHOR>
<YEAR> 1994 </YEAR>
<INSTITUTION> CLEMSON UNIVERSITY; 0050 </INSTITUTION>
<DESCRIPTORS> ENGINEERING, CHEMICAL; COMPUTER SCIENCE; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> STEPHEN S. MELSHEIMER </ADVISER>
<CLASSIFICATIONS> NIL </CLASSIFICATIONS>
<ABSTRACT>
Process industries are abundant in complex nonlinear
systems for which it is difficult and costly to build
relevant mathematical models from first principles.
Fuzzy logic systems (FLSs) can be employed to learn
process behavior using operating data. FLSs describe
process behavior in terms of linguistic rules that allow
straightforward incorporation of a priori information
about the process and allow verification of the acquired
knowledge. In an effort to bring this advantageous
modeling technique to wider use, this dissertation
presents systematic design methodology for FLSs as well
as an analysis of fundamental properties of FLS models
and FLS based control schemes.
In FLS design, the following three parts are to be
determined: the number of roles, the structure of each
rule, and the membership function parameters. Most
techniques treat these parts separately, which may
result in a suboptimal solution due to the high
dependence of the design parts on each other. In this
study, two new FLS design methods were developed. Both
are based on genetic algorithms that simultaneously
optimize all three parts. The capabilities of the new
methods and the properties of the resulting FLS models
were tested on several major industrial problems:
dynamic process modeling, material property prediction,
and process fault diagnosis. FLS models developed by the
new design methods compare well with other fuzzy models.
They also compare well with state-of-the-art nonlinear
modeling techniques.
The performance of FLS based model predictive control
(FLS-MPC) was evaluated on two highly nonlinear
processes. Results show that FLS based MPC possesses all
the important qualities of a reliable control scheme,
including good set point tracking and unmodeled
disturbance rejection. It was also shown that FLS models
can be expressed in a state space realization and local
asymptotic stability of their equilibrium points can be
proven. In addition, FLS models can be parameterized as
a linear combination of fuzzy basis functions, providing
ground for adaptive control applications. The results
show that on-line adaptation of FLSs using recursive
least squares provides rapid and reliable convergence to
correct parameter values even in situations when a
sudden change in process parameters occurs.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  2942 </NUMBER>
<ORDER>   AAI9600676 </ORDER>
<TITLE> A NEURAL NETWORK BASED MODEL PREDICTIVE CONTROLLER </TITLE>
<AUTHOR> KUO, LIN-EN </AUTHOR>
<YEAR> 1994 </YEAR>
<INSTITUTION> CLEMSON UNIVERSITY; 0050 </INSTITUTION>
<DESCRIPTORS> ENGINEERING, CHEMICAL; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> STEPHEN S. MELSHEIMER </ADVISER>
<CLASSIFICATIONS> NIL </CLASSIFICATIONS>
<ABSTRACT>
The performance of Model Predictive Control (MPC) is
strongly influenced by the quality of the reference
model which is used in the MPC algorithm to predict the
system outputs into the future. To date, most
applications of MPC are based on linear models which
cannot be expected to describe very nonlinear processes.
Nonlinear MPC can readily be formulated, but nonlinear
process models are often more complex and require
considerable effort to develop. The development of
neural networks in recent years offers the possibility
of powerful and flexible modeling of a wide range of
nonlinear systems with fast computation speed. By using
the strength of neural network modeling techniques, an
advanced and general model predictive control can be
formed.
The Radial Basis Function Neural Network (RBFN), a type
of feedforward neural network, is a particularly
attractive form of neural network for use in MPC
applications because it offers the possibility of rapid
retraining, facilitating adaptation to changing process
behavior. The usual RBFN model is a one-step ahead
predictor. In MPC, multi-step ahead predictions are
needed. Although the RBFN model can be iterated to get
multi-step ahead prediction, errors may accumulate
during the successive iterations. Therefore, a multi-
step Time-Lag Recurrent Radial Basis Function Neural
Network (TLRRBFN) was used. A new and efficient training
algorithm was developed to train the TLRRBFN which
facilitates on-line adaptation of the weights of the
TLRRBFN model.
To implement the Neural Network Based Model Predictive
Control (NNMPC), the TLRRBFN model is used as a
reference model. In this work, the NNMPC was evaluated
on three simulated test systems, including a multi-input-
multi-output (MIMO) Continuous Stirred Tank Reactor
(CSTR) (Li and Biegler, 1988). In each case, for set
point change problem, the NNMPC algorithm shows good
tracking performance without offset. The NNMPC algorithm
also shows good disturbance rejection ability. It was
also found that including a filter in the feedback path
was useful in improving the stability of the NNMPC
algorithm. For all three nonlinear processes studied,
the NNMPC outperformed conventional PID controller.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  2943 </NUMBER>
<ORDER>   AAGMM11366 </ORDER>
<TITLE> LINEAR SEPARABILITY AND CONNECTIONIST CATEGORIZATION: A STUDY OF SPEED AND GENERALIZATION OF TWO CONNECTIONIST NETWORKS </TITLE>
<AUTHOR> SHAMANSKI, KEVIN SCOTT </AUTHOR>
<YEAR> 1994 </YEAR>
<INSTITUTION> UNIVERSITY OF ALBERTA (CANADA); 0351 </INSTITUTION>
<DESCRIPTORS> PSYCHOLOGY, COGNITIVE; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> MICHAEL R. W. DAWSON </ADVISER>
<CLASSIFICATIONS> NIL </CLASSIFICATIONS>
<ABSTRACT>
The explosion in connectionist research that has
occurred in the past decade has produced a large number
of learning rules, each designed to train a specific
network architecture. The generalized delta rule
proposed by Rumelhart, Hinton, and Williams (1986a,
1986b) has become one of the most prominent of these
learning algorithms. The purpose of the research
described is to systematically compare the performance
of two rules used to train connectionist networks: the
standardized generalized delta rule devised by
Rumelhart, Hinton, and Williams (1986a, 1986b); and an
extension of this rule developed by Dawson and
Schopflocher (Dawson and Schopflocher, 1992; Dawson,
Schopflocher, Kidd, and Shamanski, 1992). In order to
make this comparison, the paper proceeds as follows:
First, activation functions and learning rules are
described, and their interrelation is briefly explored.
Second, in depth consideration is given to the logistic
and Gaussian activation functions and how the
generalized delta rule relates to each respective
functions. Third, the results of a series of computer
simulations are reported. The aim of these simulations
was to provide a controlled and systematic comparison of
the two rules.
The results of Experiment 1 demonstrated that the
logistic architecture was more suited to solving a
linearly separable problem than a linearly nonseparable
problem when speed to convergence was considered. A
network of Gaussian units, in contrast, had difficulty
solving the linearly separable problem, but was well
suited to solving the linearly nonseparable problem. The
simulations of Experiment 2 add additional support to
the network type - problem type interaction through a
dependent measure of generalization. Overall, each
network architecture generalized well on only one
specific problem type: value units on the linearly
nonseparable problem, and integration devices on the
linearly separable problem. These results are discussed
within the framework of cognitive science, and
consideration is given to how they might contribute to a
theory of categorization.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  2944 </NUMBER>
<ORDER>   AAI9539631 </ORDER>
<TITLE> BICMOS IMPLEMENTATION OF COUNTERPROPAGATION NEURAL NETWORKS WITH APPLICATIONS </TITLE>
<AUTHOR> CHEW, CHWEI-PO </AUTHOR>
<YEAR> 1994 </YEAR>
<INSTITUTION> UNIVERSITY OF MARYLAND COLLEGE PARK; 0117 </INSTITUTION>
<DESCRIPTORS> ENGINEERING, ELECTRONICS AND ELECTRICAL; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> ROBERT W. NEWCOMB </ADVISER>
<CLASSIFICATIONS> NEURAL NETWORKS, PATTERN CLASSIFICATION </CLASSIFICATIONS>
<ABSTRACT>
This dissertation presents BiCMOS VLSI circuit
realizations of key portions of counterpropagation
neural networks and gives applications including pattern
classification. In particular, the Kohonen layer, the
Grossberg layer, and weight memories are given with
fabrication checking the theory.
A Kohonen layer consists of a learning circuit and a
synapse circuit. First, an analog design of VLSI
circuits for generating the Kohonen learning circuit is
developed. Detailed SPICE simulations check the results
followed by example circuit layouts with measurements
and fabricated chips. Second, an analog VLSI
implementation of Kohonen synapse circuits is presented.
Differential amplifiers are used to sum the synapse
currents while transmission gates are used as resistors.
Circuit diagrams, Spice3e1 circuit simulations, and chip
measurements are shown. A Grossberg layer is a fully
connected layer which basically does the matrix
multiplication. BiCMOS NPN and PNP phototransistors
generate excitatory and inhibitory synapse currents.
These synapse currents are controlled by complementary
MOS transistors which allow us to implement matrix
multiplication between weight vectors and input vectors.
Related circuit diagrams and simulations are presented
along with chip measurements.
Weight memory circuits are mainly used in the
counterpropagation neural networks for storing weights.
In this dissertation, we implement continuous weight
values by programmable weight circuits. This is done by
combining a differential amplifier and a floating gate
transistor. A high voltage write-in circuit for this
programmable weight circuit is presented along with
SPICE3e1 simulation results.
To get around the sensitivity of device mismatches due
to chip fabrication in analog implementations, we
introduce digital counterpropagation neural circuits. We
present an example for digital weight interconnections
with 5 bits resolution plus a sign. Circuit diagrams,
and Spice3e1 circuit simulations of the Kohonen synapse
circuits are given.
In some special cases, multiwinners are allowed in the
Kohonen layer. Therefore, a design theory of VLSI
optoelectronic circuits for generating the learning
neighborhood function of Kohonen's feature map is
mathematically derived. Voltages which are proportional
to the metric distances between the input vector and
each weight vector of the Kohonen layer are generated to
define the learning neighborhood.
Finally, pattern classifiers which use the
counterpropagation neural network circuits of chapter 3
are simulated by using Spice. After counterpropagation
training, the classifiers successfully classify the
distorted patterns. MATLAB simulations for these pattern
classifiers verify the Spice simulations.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  2945 </NUMBER>
<ORDER>   AAI9537242 </ORDER>
<TITLE> AN AUTONOMOUS MOBILE ROBOT SYSTEM WITH ADAPTIVE NAVIGATION STRATEGY AND VISION-BASED MOTION PLANNING </TITLE>
<AUTHOR> LIN, CHENG-CHIH </AUTHOR>
<YEAR> 1994 </YEAR>
<INSTITUTION> MICHIGAN STATE UNIVERSITY; 0128 </INSTITUTION>
<DESCRIPTORS> ENGINEERING, ELECTRONICS AND ELECTRICAL; COMPUTER SCIENCE; ENGINEERING, SYSTEM SCIENCE; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> R. LAL TUMMALA </ADVISER>
<CLASSIFICATIONS> MACHINE VISION </CLASSIFICATIONS>
<ABSTRACT>
Autonomous mobile robots have drawn much attention in
both academic research and industrial applications
because of their intelligent behavior and versatility.
These robots utilize various types of sensors to
"perceive" their environments, and use them to perform
motion planning. This dissertation addresses the
problems of sensor-based navigation in typical
manufacturing environments that are structured,
partially known, and dynamic. The first half of this
work focuses on an adaptive navigation strategy, where
the speed and accuracy constraints during a navigation
process are treated as functions of the changes in the
robot's environment. The second half introduces a new
vision-based mobile robot motion planning system which
can be integrated with the dead-reckoning method to
achieve accurate goal acquisition. At the end, a hybrid
navigation approach is developed to exploit the
flexibility of adaptive navigation strategy and the
advantages of vision-based motion control. This work can
be summarized as follows: (1) Proposed a Weighted
Obstacle Density Function (WODF) for the quantitative
measurement of the clutterness of the robot's workspace.
(2) Developed a quantitative measurement of the quality
of general map construction algorithms, namely the Match
Indices. (3) Developed the Adaptive Navigation Strategy
(ANS) for a mobile robot. This approach is based on
adjusting sensor configuration and motion speed of the
robot according to the clutterness of the environment.
(4) Developed a vision-based self-calibration system
using circular disk landmarks. Designed a visual-servo
motion control system for mobile robot docking
operation. (5) Proposed a hybrid navigation system to
integrate the ANS and the vision-based motion planning
approach.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  2946 </NUMBER>
<ORDER>   AAI0576474 </ORDER>
<TITLE> INVESTIGATION OF PRACTICAL APPLICATION OF AI TECHNOLOGY IN POWER SYSTEM OPERATION AND ANALYSIS </TITLE>
<AUTHOR> ZHU, YILI </AUTHOR>
<YEAR> 1994 </YEAR>
<INSTITUTION> UNIVERSITY OF NEW SOUTH WALES (AUSTRALIA); 0423 </INSTITUTION>
<DESCRIPTORS> ENGINEERING, ELECTRONICS AND ELECTRICAL; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> NIL </ADVISER>
<CLASSIFICATIONS> ARTIFICIAL INTELLIGENCE, EXPERT SYSTEMS, NEURAL NETWORKS </CLASSIFICATIONS>
<ABSTRACT>
With the booming achievements of artificial intelligence
(AI) in the past forty years, the usefulness of this
technology in power engineering has been more and more
clearly recognised. Artificial intelligence, especially
its two major branches: expert systems (ES) and
artificial neural networks (ANN), have been widely used
in many areas. This thesis reports research work on the
practical application of artificial intelligence to
power system problems. The research aims at developing
expert system and artificial neural network packages for
solving practical problems in power system analysis and
operation as well as assessing the advantages and
disadvantages of ES and ANN in some areas of power
engineering.
The thesis reports work in five areas: power system
voltage control, power system restoration, neural
network modelling and their training algorithms,
probabilistic loadflow study and power system voltage
instability analysis. Functional link neural network and
multi-layer feed-forward network models and their
training algorithms have been investigated, upon which
some more effective methods regarding network
construction, data management and training are
developed. Two expert systems have been developed: one
for real-time emergency voltage control by directly
conducting the control operations, the other for off-
line power system operator training and on-line system
black restart assistance in a power system control
centre. The neural network techniques have been applied
to propose two new methods: one for probabilistic
loadflow calculation and the other for on-line voltage
instability indication following sudden system
disturbances.
By applying the expert system and artificial neural
network technologies to power system problems, and
analysing their feasibility regarding the practical
application, this investigation shows the
characteristics and behaviours of ES and ANN and
demonstrates their capabilities in solving various kinds
of power system problems. It is intended that this
investigation not only proposes some practical methods
of power system operation and analysis, but also
presents a clear picture of what the AI technology can
do for power system problems and so to foresee the
future roles of artificial intelligence in power system
engineering.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  2947 </NUMBER>
<ORDER>   AAI0576410 </ORDER>
<TITLE> ARTIFICIAL NEURAL NETWORKS AND THEIR APPLICATIONS IN CONTROL  </TITLE>
<AUTHOR> MOHAMMAD, BAHRAMI </AUTHOR>
<YEAR> 1994 </YEAR>
<INSTITUTION> UNIVERSITY OF NEW SOUTH WALES (AUSTRALIA); 0423 </INSTITUTION>
<DESCRIPTORS> COMPUTER SCIENCE; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> NIL </ADVISER>
<CLASSIFICATIONS> NEUROCONTROLLERS, RADIAL BASIS FUNCTION </CLASSIFICATIONS>
<ABSTRACT>
This thesis comes as the result of investigations into
the structures and learning methods of Artificial Neural
Networks (ANNs) and the application of these systems in
the control of nonlinear plants. A new method of
training neuro-controllers for nonlinear plants is
proposed which does not require identification of the
plant or its inverse model and with certain assumptions
can be utilized when the Jacobian of the plant or the
sign of the Jacobian is not available. A new method of
designing PID controllers for direct control of
nonlinear plants using Radial Basis Function (RBF)
neural networks is also proposed and analysed. The
method of control proposed in this thesis gives a new
approach to adjusting the parameters of PID controllers
with certain advantages over the conventional methods.
Other contributions of this thesis include: proposing a
new method of training neural networks to counteract
their overgeneralization and investigation into the
methods of integration of knowledge acquired by
different neural networks.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  2948 </NUMBER>
<ORDER>   AAINN97768 </ORDER>
<TITLE> CLASSIFICATEUR NEURONIQUE DE GRAPHES CONCEPTUELS: APPLICATION A LA RECONNAISSANCE D'OBJETS 2-D ET 3-D </TITLE>
<AUTHOR> BOULANGER, DENIS </AUTHOR>
<YEAR> 1994 </YEAR>
<INSTITUTION> UNIVERSITE LAVAL (CANADA); 0726 </INSTITUTION>
<DESCRIPTORS> COMPUTER SCIENCE; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> DENIS POUSSANT </ADVISER>
<CLASSIFICATIONS> FRENCH TEXT, TWO DIMENSIONAL OBJECTS, THREE DIMENSIONAL OBJECTS, ADAPTIVE RESONANCE, OBJECT RECOGNITION, NEURAL NETWORKS </CLASSIFICATIONS>
<ABSTRACT>
Cette these porte sur la description d'un nouvel
algorithme de classification et de reconnaissance de
graphes conceptuels. Un graphe est une forme de
representation de haut niveau utilise dans plusieurs
domaines de l'intelligence artificielle dont celui de la
vision par ordinateur. Un graphe est constitue d'un
ensemble de noeuds relies entre eux par des arcs. Par
analogie, ces noeuds representent un element d'une scene
observee tandis que les arcs representent les relations
structurelles entre ces elements.
L'algorithme propose permet la reconnaissance et
l'autoclassification de graphes conceptuels a partir des
reseaux de neurones. Son principe de fonctionnement est
base sur les reseaux de type ART (Adaptive Resonance
Theory) tels que decrit par G. Carpenter et S.
Grossberg. La recherche dans la base de donnees
s'effectue rapidement grace a une technique d'indexage
parallele en deux niveaux. Les graphes selectionnes sont
alors compares a celui presente en effectuant une mise
en correspondance des noeuds des deux graphes. Cette
derniere etape est realisee a l'aide d'un nouvel
algorithme de relaxation d'etiquettes. Le reseau
continue son cycle de selection et de comparaison
jusqu'a ce qu'il trouve un graphe correspondant le mieux
a celui presente. Si aucun graphe de la base de donnees
n'est trouve, le reseau genere automatiquement une
nouvelle classe ou le graphe sera memorise. Cette
memorisation s'effectue en utilisant les sous-graphes
communs entre les graphes precedemment memorises et
celui presente, eliminant ainsi toute redondance entre
les classes memorisees.
Les proprietes du reseau sont illustrees a l'aide
d'exemples de reconnaissance et de classification de
graphes extraits de la description geometrique d'objets
divers en deux et en trois dimensions. Ces exemples
illustrent bien comment le reseau accede a la base de
donnees rapidement et comment la classification est
effectuee. Certains modes d'application sont egalement
illustres. En effet, le reseau est en mesure de reconnai
tre des surfaces partiellement cachees en utilisant la
notion de seuils flous. De plus, le reseau est capable
de reconnai tre tous les objets semblables contenus dans
une scene complexe et cela dans un seul cycle de
fonctionnement. Finalement, le reseau permet d'integrer
les graphes de differentes vues d'un meme objet dans un
seul modele non redondant.
Un des apports originaux qui ressort de cette these est
evidemment la structure du reseau de classification. De
plus, une nouvelle methode de relaxation d'etiquettes a
ete developpee permettant de mettre en correspondance
les noeuds de deux graphes compares en tenant compte des
contraintes exprimees par leurs arcs. L'utilisation des
seuils flous procure une solution alternative
interessante au probleme de la reconnaissance des
surfaces partiellement cachees. Finalement, une nouvelle
methode de segmentation d'images en segments de droite
et en arcs de cercle est egalement presentee.
Cette these comporte quatre chapitres principaux. Dans
le premier chapitre, la description du processus de la
reconnaissance permet de replacer dans son contexte
l'algorithme propose. Le second porte essentiellement
sur la description du reseau de classification des
graphes conceptuels. Le troisieme chapitre porte sur les
applications du reseau a la reconnaissance d'objets
polyedriques en trois dimensions. Le dernier chapitre
porte egalement sur des exemples d'application en
utilisant cependant la description provenant de contours
d'objets reels places sur un plan.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  2949 </NUMBER>
<ORDER>   AAINN97686 </ORDER>
<TITLE> FORMAL METRICS FOR QUANTITATIVE ASSESSMENT OF THE QUALITY OF EXPERT SYSTEMS </TITLE>
<AUTHOR> CHEN, ZHISONG </AUTHOR>
<YEAR> 1994 </YEAR>
<INSTITUTION> CONCORDIA UNIVERSITY (CANADA); 0228 </INSTITUTION>
<DESCRIPTORS> COMPUTER SCIENCE; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> C. Y. SUEN </ADVISER>
<CLASSIFICATIONS> KNOWLEDGE BASE, INFERENCE ENGINE </CLASSIFICATIONS>
<ABSTRACT>
Various systems have to be assessed and evaluated from
time to time to assure their quality, especially in the
engineering and scientific disciplines. As a result,
many metrics have been defined and used. In software
engineering, it has been shown that the use of poor
quality software can become very costly in the long run.
To overcome this, a large number of metrics have been
proposed to quantify the different aspects of
convectional software and much progress has been made.
Expert systems are a special type of software, whose
main components are the knowledge base and inference
engine. They are applied to solve complex problems that
need human expertise, and their applications have
dramatically increased in recent years in many different
disciplines. However, due to their imprecise and
iterative nature, expert systems, especially their
knowledge bases, are subject to more quality problems
than conventional software. Because of this, expert
system metrics are urgently needed to assess and predict
the quality of expert systems. Unfortunately, so far
little work has been done in this area, hence techniques
in assessing the quality of expert systems fall far
behind those in other disciplines. In view of this, an
investigation into the metric measurements for expert
systems was proposed as research for this doctoral
thesis, and it is hoped this work will stimulate more
research and attract more attentions to this area.
Several issues related to expert system metrics are
addressed and discussed in this thesis, such as the
appropriate formulation and definition of expert system
metrics, and the validity assessment of the metrics. In
order to formally describe and measure the
characteristics of expert systems, an AND/OR digraph is
presented. Based on this digraph and the contents of
expert systems, new metrics for measuring ES complexity
have been proposed, which are RC (Rule Base Complexity)
and ERC (Entropy-Based Rule Base Complexity). Five other
metrics are formally presented for the measures of the
size and search space, which are NR (Number of Rules),
ADSS (Average Depth of Search Space), ABSS (Average
Breadth of Search Space), BC (Buchanan's Complexity) and
NAC (Number of Antecedents and Consequents). For
validating the expert system metrics, this thesis
proposes the metric evaluation techniques from two
perspectives: (1) empirical evaluation that is based on
the statistical analysis and testing of the measuring
results; and (2) theoretical evaluation, that is,
evaluating the metrics in an abstract way. Four general
criteria and eleven desired properties regarding the
expectation of metric performance are proposed for this
purpose, against which metrics are further evaluated.
The evaluation results reveal that RC metric, designed
as a hybrid metric that takes into account the matching
patterns, site and search space of expert systems, is
most effective, giving the best performance among all
the presented metrics, and it can serve as a useful tool
in developing quality expert systems.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  2950 </NUMBER>
<ORDER>   AAINN97684 </ORDER>
<TITLE> FEATURE SELECTION IN THE CLASSIFICATION OF TIME-VARIANT PATTERNS </TITLE>
<AUTHOR> SIDDIQUI, KHALID JAVED </AUTHOR>
<YEAR> 1994 </YEAR>
<INSTITUTION> CONCORDIA UNIVERSITY (CANADA); 0228 </INSTITUTION>
<DESCRIPTORS> COMPUTER SCIENCE; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> C. Y. SUEN; D. ROBERT HAY </ADVISER>
<CLASSIFICATIONS> NIL </CLASSIFICATIONS>
<ABSTRACT>
A bottleneck in building and using the knowledge base in
an intelligent system is combining the appropriate
problem solving knowledge with physical observations.
Another problem is to derive pertinent information that
is subtly available in physical observations. These
problems are resolved by using the information and
knowledge processing techniques available in the fields
of signal processing, pattern recognition and knowledge
engineering. Methods are developed to automatically
measure, recognize and interpret the parameters
(features) from the physical observations. A Successive
Feature Elimination Scheme involving multiple steps is
developed to eliminate poorly performing features.
Pseudo-Similarity method which uses inter-class
dissimilarity is introduced for feature ranking. To
minimize the problems of information explosion and
redundancy the concept of Pattern Association Hierarchy
(PAH) is introduced to structure and organize the
features and pattern classes in the form of a knowledge
tree. Several classifiers including the two new
algorithms PAH classifier and entropy based decision
tree classifier are also developed. Based on the nature
of the training data a number of meta rules are
developed to select the best knowledge organization and
classification algorithms. All these components and
concepts are used as a basis to propose a structure of
an intelligent waveform recognition system. This unified
approach will not only automate and accelerate the
knowledge acquisition and organization process, but will
also formalize and structure the decision-making
process, and thus reduce the reliance on a human expert.
The performance of these components is successfully
demonstrated on several time-variant signals from non-
destructive testing (NDT), and non-invasive testing
(NIT) generated from materials (NDT signals), chemical
mixtures (PNA spectra), human brain (EEG signals), and
genetic cells (CEL signals). On the testing set from NDT
data with 10 classes an overall performance reaching 84%
was achieved and up to 95% when it is treated as a four
class problem. Up to 95.67% of the EEG signals with 3
classes were correctly recognized whereas a perfect
score of 100k was obtained on PNA data with 20 classes.
On the CEL data with 19 classes the recognition
performance reached 88.34%.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  2951 </NUMBER>
<ORDER>   AAINN97668 </ORDER>
<TITLE> EXPERT CONTROL OF DEEP HOLE MACHINING SYSTEM: AN ARTIFICIAL INTELLIGENCE TECHNIQUE FOR REAL-TIME CONTROL OF DEEP HOLE MACHINING PROCESS </TITLE>
<AUTHOR> SUBRAMANYA, PERDUR S. </AUTHOR>
<YEAR> 1994 </YEAR>
<INSTITUTION> CONCORDIA UNIVERSITY (CANADA); 0228 </INSTITUTION>
<DESCRIPTORS> ENGINEERING, MECHANICAL; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> NIL </ADVISER>
<CLASSIFICATIONS> NIL </CLASSIFICATIONS>
<ABSTRACT>
Abstract Not Available.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  2952 </NUMBER>
<ORDER>   AAINN97187 </ORDER>
<TITLE> GLOVE-TALKII: MAPPING HAND GESTURES TO SPEECH USING NEURAL NETWORKS. AN APPROACH TO BUILDING ADAPTIVE INTERFACES </TITLE>
<AUTHOR> FELS, SIDNEY S. </AUTHOR>
<YEAR> 1994 </YEAR>
<INSTITUTION> UNIVERSITY OF TORONTO (CANADA); 0779 </INSTITUTION>
<DESCRIPTORS> COMPUTER SCIENCE; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> GEOFFREY HINTON </ADVISER>
<CLASSIFICATIONS> NIL </CLASSIFICATIONS>
<ABSTRACT>
Glove-TalkII is a system which translates hand gestures
to speech through an adaptive interface. Hand gestures
are mapped continuously to 10 control parameters of a
parallel formant speech synthesizer. The mapping allows
the hand to act as an artificial vocal tract that
produces speech in real time. This gives an unlimited
vocabulary in addition to direct control of fundamental
frequency and volume. Currently, the best version of
Glove-TalkII uses several input devices (including a
Cyberglove, a 3-space tracker, a keyboard and a foot-
pedal), a parallel formant speech synthesizer and 3
neural networks. The gesture-to-speech task is divided
into vowel and consonant production by using a gating
network to weight the outputs of a vowel and a consonant
neural network. The gating network and the consonant
network are trained with examples from the user. The
vowel network implements a fixed, user-defined
relationship between hand-position and vowel sound and
does not require any training examples from the user.
Volume, fundamental frequency and stop consonants are
produced with a fixed mapping from the input devices.
One subject has trained to speak intelligibly with Glove-
TalkII. He speaks slowly with speech quality similar to
a text-to-speech synthesizer but with far more natural-
sounding pitch variations.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  2953 </NUMBER>
<ORDER>   AAINN97647 </ORDER>
<TITLE> INTEGRATED BID PREPARATION WITH EMPHASES ON RISK ASSESSMENT USING NEURAL NETWORKS </TITLE>
<AUTHOR> HEGAZY, TAREK M. </AUTHOR>
<YEAR> 1994 </YEAR>
<INSTITUTION> CONCORDIA UNIVERSITY (CANADA); 0228 </INSTITUTION>
<DESCRIPTORS> BUSINESS ADMINISTRATION, MANAGEMENT; ECONOMICS, COMMERCE- BUSINESS; ENGINEERING, CIVIL; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> NIL </ADVISER>
<CLASSIFICATIONS> CONSTRUCTION INDUSTRY </CLASSIFICATIONS>
<ABSTRACT>
Construction estimating works as the basis for various
strategic decisions regarding the preparation of bid
proposals, procurement plans, various levels of
schedules, and job cost control. Under the highly risky
environment of the prevalent competitive bidding
practice, preparation of realistic estimates pertaining
to those management decisions has been a complex task
that is often performed on an ad hoc and piecemeal
manner. Conventional procedures and tools have proved
inadequate to provide a structured decision aid that,
under such environment, maximizes the contractor's
chances of winning a job with maximum potential profit,
and further generates practical baseline plans needed
for job control to maintain this profit. Yet the
situation has been translated into a high percentage of
business failures, a high potential for claims, and at
best a low profit margin in the industry.
This research presents a methodology for an integrated
cost estimation and bid preparation, with emphasis on
the assessment of bidding risks and optimum markup
estimation. The methodology utilizes available tools
(algorithms, database management systems, and Al-based
techniques) that can benefit from current industry
practice and provide an adequate decision aid during bid
preparation. The methodology facilitates integration
among estimating, planning and scheduling, and bid
unbalancing. It incorporates enhancements to the various
functions that cover the quantitative aspects of an
estimate including: direct and indirect cost estimation,
planning and scheduling, and resource utilization. This
enables detailed estimates of costs and durations to be
generated for all the project tasks, with minimal
redundancy and in less time. Such estimates also
establish the baselines needed for efficient job
control.
For practicality, the methodology accounts for the
qualitative (risk-related) factors that play a vital
role in the preparation of competitive bid proposals
(e.g., competition, market conditions, and contractor
keenness for the job). The methodology utilizes Neural
Networks, an Al-based technique that employs a learning
mechanism and emulates the human ability to solve
pattern recognition tasks similar to many problems
encountered in construction. This technique is
introduced as a new tool to the industry, incorporating
several potential applications. A neural network model
is designed and used to arrive at an optimum markup
value that maximizes that contractor's potential profit
and predicts the probability of winning the job at such
level of profit, in response to the project risk
pattern. The methodology then utilizes the data obtained
through the detailed estimate to optimally unbalance the
final bid, in an effort to improve the contractor's cash
flow while maintaining his competitiveness. A PC-based
prototype is developed to automate the bid preparation
process and an example application is presented in order
to demonstrate the effectiveness and practicality of the
proposed methodology. The proposed integrated
methodology contributes to current automation efforts in
construction and its modular architecture allows for
further enhancement and expansions. The developments
made with respect to the markup estimation problem
demonstrates the powerful capabilities of neural
networks and the potential benefits of deriving analogy-
based solutions to complicated construction problems
that are characterized by high uncertainty. This
approach could readily be utilized in other domains in
construction management where solutions are based
primarily on holistic analogy and traditional
algorithmic solutions are inadequate.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  2954 </NUMBER>
<ORDER>   AAGMM11295 </ORDER>
<TITLE> TRAINING REDUNDANT ARTIFICIAL NEURAL NETWORKS: IMPOSING BIOLOGY ON TECHNOLOGY </TITLE>
<AUTHOR> MEDLER, DAVID ALEXANDER </AUTHOR>
<YEAR> 1994 </YEAR>
<INSTITUTION> UNIVERSITY OF ALBERTA (CANADA); 0351 </INSTITUTION>
<DESCRIPTORS> PSYCHOLOGY, EXPERIMENTAL; COMPUTER SCIENCE; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> M. R. W. DAWSON </ADVISER>
<CLASSIFICATIONS> NIL </CLASSIFICATIONS>
<ABSTRACT>
One biological principle that is often overlooked in the
design of artificial neural networks (ANNs) is
redundancy: Redundancy is the replication of processes
within the brain. This paper examines the effects of
redundancy on learning in ANNs when given either a
pattern classification task or a function approximation
task. Two different pattern classification tasks were
used: parity and encoder. The function approximation
task simulated a robotic arm trained to reach towards an
object in two-dimensional space. Initial results
indicate that there is an optimal level of redundancy in
terms of probability of convergence, convergence speed,
and convergence efficiency. When this level of
redundancy is used, redundant ANNs learned the pattern
classification problem much faster, and converged on a
solution 100% of the time whereas standard ANNs
sometimes failed to learn the problem. Furthermore, when
overall network error is considered, redundant ANNs were
significantly more accurate than standard ANNs at
performing the function approximation task. These
results are discussed in terms of the relevance of
redundancy to the performance of ANNs in general, and
the relevance of redundancy in biological systems in
particular.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  2955 </NUMBER>
<ORDER>   AAIC439701 </ORDER>
<TITLE> MONITORIZACION INTELIGENTE DE ISQUEMIA EN SUTIL; INTELLIGENT MONITORING OF ISCHAEMIA USING SUTIL </TITLE>
<AUTHOR> RODRIGUEZ PRESEDO, JESUS </AUTHOR>
<YEAR> 1994 </YEAR>
<INSTITUTION> UNIVERSIDAD DE SANTIAGO DE COMPOSTELA (SPAIN); 5869 </INSTITUTION>
<DESCRIPTORS> COMPUTER SCIENCE; ENGINEERING, BIOMEDICAL; HEALTH SCIENCES, MEDICINE AND SURGERY; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> NIL </ADVISER>
<CLASSIFICATIONS> NIL </CLASSIFICATIONS>
<ABSTRACT>
The work described in the present report is included in
the more general framework of the design, physical
implementation and validation of an electronic computing
system (SUTIL) which, taking into account large amounts
of information extracted mainly from real-time
processing of haemodynamic and electrocardiographic
signals, in a simultaneous, integrated and intelligent
manner, performs an intensive and exhaustive follow-up
of patients with ischemic cardiopathies in Coronary Care
Units (CCUs).
In addition to integrating real-time intelligent
monitoring processes of the physiological signals we
mention, an important aspect of a system with these
characteristics is the user-system interaction
environment, aimed at an adequate and friendly
information recovery, both in time and in format. It
must also allow for the adaptation of the monitoring
process to the specific characteristics of the patient
and their environments as well as the redefinition of
the evaluation of the the real-time information and its
reprocessing in deferred time.
One of the basic objectives of the current design of
SUTIL is to provide a response to the monitoring needs
derived from recent knowledge on the physiopathology of
acute coronary disease and, specifically, to aspects
such as silent ischemia monitoring, whose diagnosis in
daily clinical practice is based on the detection of
changes in the ST segment and the adequate evolutive
follow-up of thrombolitic therapeutics which, from an
electrocardiographic viewpoint, is reflected in the
evolutive changes of the ST. Consequently, apart from
the traditional functions for monitoring arrhythmias, we
have considered it necessary to endow SUTIL with an
optimum design for ST monitoring. In this work, all
algorithms that have been created in order to endow
SUTIL with this capacity for monitoring ischemic
episodes are described.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  2956 </NUMBER>
<ORDER>   AAIC439281 </ORDER>
<TITLE> A KNOWLEDGE-BASED DESIGN ENVIRONMENT FOR ANALOGUE DESIGN AUTOMATION </TITLE>
<AUTHOR> WEE, K. K. </AUTHOR>
<YEAR> 1994 </YEAR>
<INSTITUTION> UNIVERSITY OF ESSEX (UNITED KINGDOM); 0873 </INSTITUTION>
<DESCRIPTORS> ENGINEERING, ELECTRONICS AND ELECTRICAL; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> NIL </ADVISER>
<CLASSIFICATIONS> NIL </CLASSIFICATIONS>
<ABSTRACT>
This thesis presents a hierarchically-structured
analogue design system which provides an expandable and
flexible design environment for analogue design
automation. The system uses a knowledge-based approach,
where circuit equations are its main source of
knowledge, for analogue circuit design. Its design
process is generally based upon hierarchical
decomposition and translation which proceeds from high-
level behavioural specifications to realise a fully
specified circuit. The key features of the system are: a
flexible design process, an expandable design knowledge-
base and wide accessibility to design results.
A flexible design process means that the analogue design
process adopted in the system can be dynamically
customised to suit different analogue circuits and
design styles. A design process customisation mechanism
is introduced which is based upon the decomposition of
the design process into a series of manageable design
activities and the arrangement of these design
activities in a desired execution sequence in order to
form a new design process.
The design knowledge-base of the system can be expanded
to include other analogue circuit designs. A high-level
computer-aided knowledge acquisition approach is
implemented for this knowledge expansion. In this
approach, expert designers supply their design expertise
by the use of the computer-aided agent through a form-
filling interaction. The result of the interaction is
converted automatically into computable design knowledge
which can be used in the analogue design process
effectively.
Wide accessibility means that design results produced by
the system can be accessed by a wide range of CAD tools
in order to perform further evaluations. To do so, the
system is integrated into a commercial design framework
with the result that the design can be accessed by any
CAD tool currently available in the framework.
The above-mentioned features, together with the use of
services and facilities offered by the framework provide
designers with a flexible and expandable design
environment for handling a wide range of analogue
designs.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  2957 </NUMBER>
<ORDER>   AAIC439191 </ORDER>
<TITLE> A PRACTICAL FRAMEWORK FOR TRAINING SIGMA-PI NEURAL NETWORKS WITH AN APPLICATION IN ROTATION INVARIANT PATTERN RECOGNITION </TITLE>
<AUTHOR> HEYWOOD, M. I. </AUTHOR>
<YEAR> 1994 </YEAR>
<INSTITUTION> UNIVERSITY OF ESSEX (UNITED KINGDOM); 0873 </INSTITUTION>
<DESCRIPTORS> ENGINEERING, ELECTRONICS AND ELECTRICAL; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> NIL </ADVISER>
<CLASSIFICATIONS> NIL </CLASSIFICATIONS>
<ABSTRACT>
This thesis proposes a framework for training multi-
layer feedforward neural networks (FFNN) incorporating
product terms (sigma-pi networks) such that the
combinatorial increase in product terms is avoided.
Furthermore, this is achieved without recourse to
problem-specific a priori knowledge or limitations to
the representation of the original data. Such a goal is
achieved by (1) explicitly limiting the number of higher
order monomials included within the network (sub-net
sigma-pi configuration) and (2) accessing the wider
weight space via manipulation of the population of
monomials included within the work during the training
cycle. This necessitates order-specific learning rates
to bias the solution towards the simplest description
and a method for performing irrelevant parameter
identification and replacement during network
adaptation, in this case achieved via a dynamic weight
pruning algorithm. Dynamic weight pruning employs a
stability metric to identify when neurons represent a
specific function for some fraction of the training set.
Such a condition permits the application of a weight
significance measure during the training cycle and the
definition of neural specific training sets. This allows
informed selection of alternative candidate monomials by
way of a linear regression procedure. A complexity
measure, applied locally, avoids over-fitting of the
local training set by prospective monomials.
The use of moment method feature vectors for movement-
invariant object classification is investigated in the
context of a benchmark problem. A new 'low-level' moment
method, denoted fractional central moments, is derived
which demonstrates independence from alternative 'low-
level' moment method techniques whilst providing higher
descriptive qualities than the standard central moment
basis. Furthermore, the fractional central moment method
permits description of pseudo Zernike moments in terms
of 'low-level' moments, thus obtaining complete movement
invariance.
Application of the proposed sub-net sigma-pi framework
is contrasted with that of MLP and sigma-pi networks
using alternative pruning methods within the context of
classification and function approximation problems. It
is demonstrated that the framework is capable of
identifying significant network redundancy during the
training cycle whilst improving on the degree of
generalisation identified using standard learning
algorithms. Furthermore, the method is capable of
identifying redundant networks more efficiently than
standard pruning algorithms applied after convergence.
The performance of the fractional central moment basis
is investigated using discriminant and neural network
classification methods on clean and corrupted data sets.
Extensive simulation studies demonstrate a significant
improvement in descriptive capabilities using the
fractional central moment method, with respect to that
identified using a central moment basis, within the
context of a movement invariant object classification
problem. Combination of the fractional central moment
method and neural network techniques is demonstrated to
yield a system with robust classification properties,
whilst using half the feature vector length as that
required by a system based on the more complex pseudo
Zernike moment method and discriminant analysis
classification.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  2958 </NUMBER>
<ORDER>   AAIC437551 </ORDER>
<TITLE> SOLUCIONES PARA LA COMPUTACION EFICIENTE EN SISTEMAS BASADOS EN LOGICA BORROSA; SOLUTIONS FOR EFFICIENT COMPUTATION IN FUZZY LOGIC-BASED SYSTEMS </TITLE>
<AUTHOR> BUGARIN DIZ, ALBERTO JOSE </AUTHOR>
<YEAR> 1994 </YEAR>
<INSTITUTION> UNIVERSIDAD DE SANTIAGO DE COMPOSTELA (SPAIN); 5869 </INSTITUTION>
<DESCRIPTORS> COMPUTER SCIENCE; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> NIL </ADVISER>
<CLASSIFICATIONS> NIL </CLASSIFICATIONS>
<ABSTRACT>
One of the fundamental problems derived from dealing
with fuzzy logic-based systems is the high computational
cost they demand. In some cases, systems with extreme
requirements for operation time need to have dedicated
fast hardware. In other cases it is convenient to adopt
certain strategies that reduce or simplify the number of
operations to perform.
The hardware implementation of solutions for the
execution of fuzzy logic-based systems has been one of
the aims of this work. Taking into account the way in
which the execution of the knowledge base (KB) is
performed, we classify the hardware solutions in the
literature of fuzzy control according to the inference
methodology they implement. After this, our proposals
for each of these methodologies are described, with a
detailed analysis of their most important features:
flexibility in the operators involved in the execution
process and insensitivity to the parameters that
characterize the size of the fuzzy knowledge base
(number of rules, number of propositions in the
antecedent or consequent part and degree of
discretization of the universes of discourse).
In many other applications knowledge is structured in a
more complex way, i.e., with chained rules. In these
systems, computational efficiency is achieved through a
compaction of the set of rules, which results in a
reduction in the number of operations to be performed
during the execution of the KB. After describing the
general process of compaction in these systems, the
results of the compositional rule of inference "Sup-min"
are obtained. From these results a representation model
based on the petri net formalism is developed. This
model permits the static representation of the fuzzy
knowledge base and the description of some dynamic
processes that can be carried out: inconsistency
checking, data-driven execution strategy for different
situations (complete information, incomplete information
and incremental reasoning) and goal-driven execution
strategy.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  2959 </NUMBER>
<ORDER>   AAIC437279 </ORDER>
<TITLE> EMBEDDED COMMAND AND CONTROL INFRASTRUCTURES FOR INTELLIGENT AUTONOMOUS SYSTEMS </TITLE>
<AUTHOR> FRASER, ROBERT JAMES CAMERON </AUTHOR>
<YEAR> 1994 </YEAR>
<INSTITUTION> UNIVERSITY OF SOUTHAMPTON (UNITED KINGDOM); 5036 </INSTITUTION>
<DESCRIPTORS> ENGINEERING, SYSTEM SCIENCE; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> NIL </ADVISER>
<CLASSIFICATIONS> NIL </CLASSIFICATIONS>
<ABSTRACT>
The issue of Command and Control (C$sp2$) is generally
associated with the management infrastructure of large
scale systems for warfare, public utilities and public
transportation, and is concerned with ensuring that the
distributed human elements of command and control can be
fully integrated into a coherent, total system.
Intelligent Autonomous Systems (LASs) are a class of
complex systems that perform tasks autonomously in
uncertain, dynamic environments, the management of which
can be viewed from the perspective of embedded command
and control systems.
This thesis establishes a vision for the modular
construction of intelligent autonomous embedded C$sp2$
systems, which defines a complex integration problem
characterised by distributed intelligence, world
knowledge and control, concurrent processing on
heterogeneous platforms, and real-time performance
requirements. It concludes that by adopting an
appropriate systems infrastructure model, based on
Object Technology, it is possible to view the
construction of embedded C$sp2$ systems as the
integration of a temporally assembled collection of
reusable components. To support this metaphor it is
necessary to construct a common reference model, or
standards framework, for the representation and
specification of modular C$sp2$ systems. This framework
must support the coherent long term development and
evolution in system capability, ensuring that systems
are extensible, robust and perform correctly. In this
research, which draws together the themes of other
published research in object oriented systems and
robotics, classical AI models for intelligent systems
architectures are used to specify the overall system
structure, with open systems technologies supporting the
interoperation of elements within the architecture. All
elements of this system are modelled in terms of
objects, with well defined, implementation independent
interfaces. This approach enables the system to be
specified in terms of an object model, and the
development process to be framed in terms of object
technology, defining a new approach to IAS development.
The implementation of an On-board Command and Control
System for an Autonomous Underwater Vehicle is used to
validate these concepts. The further application of
emergent industrial standards in distributed object
oriented systems means that this bind of component-based
integration is scalable, providing a near-term solution
to generic command and control problems, including
Computer Integrated Manufacturing and large scale
autonomous systems, where individual autonomous systems,
such as robots, form elements of a complete, total
intelligent system, for application to areas such as
fully automated factories and cooperating intelligent
autonomous vehicles for construction sites.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  2960 </NUMBER>
<ORDER>   AAIC435752 </ORDER>
<TITLE> SISTEMAS EXPERTOS EN AUDITORIA; EXPERT SYSTEMS IN AUDITING </TITLE>
<AUTHOR> SANCHEZ TOMAS, ANTONIO </AUTHOR>
<YEAR> 1994 </YEAR>
<INSTITUTION> UNIVERSITAT DE VALENCIA (SPAIN); 5871 </INSTITUTION>
<DESCRIPTORS> BUSINESS ADMINISTRATION, ACCOUNTING; ARTIFICIAL INTELLIGENCE DE LA NAVE, 2,  E-46003 VALENCIA, SPAIN </DESCRIPTORS>
<ADVISER> NIL </ADVISER>
<CLASSIFICATIONS> NIL </CLASSIFICATIONS>
<ABSTRACT>
The work is included in the mainstreams of accounting
thinking which try to demonstrate the applicability of
computer, computer science, and information technology
on practical and theoretical development of accounting
and auditing.
The main objective of this thesis is to analyze the
application possibilities of expert systems in the
domain of auditing, as well as to do research on the
best methodology to develop applications in this domain.
For that the main applications of expert systems in the
different phases of auditing process are analyzed, and
also the influences of using these systems on the
auditing profession are indicated.
This work is divided in two different parts. The first
of these parts addresses the basis of expert systems and
has as a main objective to obtain a more reasonable
knowledge about the basic concepts of these systems,
which is in turn necessary to be able to understand the
subjects which will be addressed in the second part of
this thesis. The second part addresses the use of expert
systems in the domain of auditing, and has two principal
objectives: (1) to demonstrate the applicability of
these systems on the different domains of auditing, and
(2) to emphasize the main influences of these systems on
the auditing profession.
Across this analysis it is possible to get a reasonable
understanding about the state of the art in every
domain, and the applicability of these systems on
auditing is demonstrated.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  2961 </NUMBER>
<ORDER>   AAGMM16893 </ORDER>
<TITLE> TENSOR REPRESENTATIONS AND HARMONY THEORY: A CRITICAL ANALYSIS </TITLE>
<AUTHOR> GOURLEY, RENE STEPHEN </AUTHOR>
<YEAR> 1995 </YEAR>
<INSTITUTION> SIMON FRASER UNIVERSITY (CANADA); 0791 </INSTITUTION>
<DESCRIPTORS> COMPUTER SCIENCE; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> ROBERT HADLEY </ADVISER>
<CLASSIFICATIONS> NIL </CLASSIFICATIONS>
<ABSTRACT>
Harmony theory and tensor representations have been
proposed as a means by which connectionist models can
accept formal languages. Their proponents aim to provide
a neural explanation of the productivity and
systematicity of cognitive processes, without directly
implementing symbolic algorithms. Via tensor
representation, this theory interprets the activation
vector of a connectionist system as a parse tree for a
string in a particular context free language. Harmony
theory apparently describes how to construct a network
whose stable equilibria represent valid parse trees.
This thesis presents a detailed analysis of tensor
representations and harmony theory. Over the course of
this exposition, errors in the original formulation are
identified and improvements are proposed.
The thesis then goes on to examine some major issues
confronting harmony theory. The first issue is that of
input and output which have not been satisfactorily
defined by harmony theorists. Secondly, we examine the
very large size of the networks. Finally this thesis
inspects harmony theory relative to its own goals and
shows that the constructed networks admit stable
equilibria that do not represent valid parse trees.
Thus, harmony is unable to support its advocates' bold
claims.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  2962 </NUMBER>
<ORDER>   AAGC522815 </ORDER>
<TITLE> A SYSTEMS VIEW OF THE DEVELOPMENT AND IMPLEMENTATION OF INFORMATION SYSTEMS </TITLE>
<AUTHOR> CONNELL, N. A. D. </AUTHOR>
<YEAR> 1995 </YEAR>
<INSTITUTION> UNIVERSITY OF SOUTHAMPTON (UNITED KINGDOM); 5036 </INSTITUTION>
<DESCRIPTORS> BUSINESS ADMINISTRATION, MANAGEMENT; INFORMATION SCIENCE; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> NIL </ADVISER>
<CLASSIFICATIONS> DECISION SUPPORT, EXPERT SYSTEMS </CLASSIFICATIONS>
<ABSTRACT>
This thesis comprises a set of published papers which,
together, focus on a view of the development of
information systems which emphasises the contextual
nature of the system. The thesis consists of twenty
chapters, arranged in four sections, linked by a
preface. Each section contributes a strand to the
arguments supporting a systemic view of information
systems.
Section One introduces the general theme of the
development and implementation of information systems by
focusing on a particular type of decision support system-
-expert systems--and reviewing how such systems have
been used. One of the ways in which this review is
achieved is through an international comparison of
system use. This section includes a novel approach to
classificatory criteria, based on a systems perspective.
Section Two considers in greater depth some of the
contextual characteristics identified in the first
section. By examining applications developed by more
mature users, it enables deeper insights to be drawn
into the direction of expert system development. It
suggests ways in which likely roles for expert systems
could be evaluated or implemented, and considers
frameworks which may help to evaluate the organisational
impact of such systems, particularly in the light of the
contextual perspective. Section Three focuses on the
organisational context of expertise and the implications
this may have for the receptiveness of the organisation
to the development and implementation of expert systems.
A classification of expertise is proposed, and drawn
upon to discuss the possibilities presented for
organisational restructuring in the light of expert
systems use, or potential. The final section extends
some of the ideas developed in the earlier chapters
beyond expert system applications, using as a focus some
information system applications in the Health Service.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  2963 </NUMBER>
<ORDER>   AAI9622427 </ORDER>
<TITLE> SIMULATION-BASED SUPPORT FOR EARLY COLLABORATIVE DESIGN </TITLE>
<AUTHOR> IVEZIC, NENAD </AUTHOR>
<YEAR> 1995 </YEAR>
<INSTITUTION> CARNEGIE-MELLON UNIVERSITY; 0041 </INSTITUTION>
<DESCRIPTORS> ENGINEERING, CIVIL; ENGINEERING, INDUSTRIAL; COMPUTER SCIENCE; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> NIL </ADVISER>
<CLASSIFICATIONS> NEURAL NETWORKS </CLASSIFICATIONS>
<ABSTRACT>
This dissertation describes development and preliminary
analysis of the Simulation-based Decision Support System
(SB-DSS) approach. The SB-DSS enables use of simulation-
based knowledge for support of both estimation of
performances and identification of alternative design
refinements for early, evolving design specifications.
This capability is named Active Design Assistance and
represents a principal requirement for support of early
collaborative design processes using the simulation-
based knowledge. The SB-DSS approach is based on a
developed Behavior-Evaluation model of collaborative
decision making, explicit treatment of uncertainties
inherent in the early stages of design, and an
application of statistical neural networks and Monte
Carlo simulation. Behavior-Evaluation model allows an
integral decision support framework for decision support
of collaborative design. Explicit treatment of
uncertainties is achieved by using probability theory to
reason about these uncertainties and by allowing a
designer to explore alternative solutions in the face of
that uncertainty. Statistical neural networks are used
to learn simulation-based knowledge from design cases
analyzed using simulation tools and, hence, enable a
necessary abstraction mechanism for use of that
knowledge in the early stages of design. Monte Carlo
simulation is used to access learned simulation-based
knowledge by sampling the trained neural networks.
Experimental analysis of this new decision support
approach provides initial results in the capability of
the SB-DSS to learn simulation-based knowledge and allow
use of this knowledge in early stages of collaborative
design.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  2964 </NUMBER>
<ORDER>   AAI9622382 </ORDER>
<TITLE> LOGARITHMIC BARRIER FUNCTIONS AND NEWTON-TYPE METHODS WITH APPLICATIONS TO NEURAL NETWORK TRAINING </TITLE>
<AUTHOR> TUTUNJI, TAREK AQUIL </AUTHOR>
<YEAR> 1995 </YEAR>
<INSTITUTION> THE UNIVERSITY OF OKLAHOMA; 0169 </INSTITUTION>
<DESCRIPTORS> ENGINEERING, INDUSTRIAL; ENGINEERING, ELECTRONICS AND ELECTRICAL; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> NIL </ADVISER>
<CLASSIFICATIONS> NIL </CLASSIFICATIONS>
<ABSTRACT>
Logarithmic Barrier Methods are studied and analyzed.
Barrier methods form a class of Interior Point Methods
that are used to solve general nonlinear constraint
optimization problems. Usually, those methods move in a
Newton-type direction. Emphasis is given on developing
barrier methods for training supervised neural networks.
Two algorithms are presented in this dissertation: a
deterministic logarithmic barrier and a stochastic
logarithmic barrier. Specifically, we consider neural
network training as a nonlinear programming problem and
use barrier methods to find the optimal weights.
Furthermore, we put constraints on the weights to avoid
network paralysis. The search direction is derived using
a recursive prediction error method (RPEM) that
approximates the inverse of the Hessian of a logarithmic
error function iteratively. The weights move on a center
trajectory in the interior of the feasible weight space
and have good convergence properties. For the stochastic
version, random fluctuations are added to the weights in
order to escape local minima. Ill-conditioning problems
are discussed and computational experiments are
provided. Also, the deterministic logarithmic barrier is
extended for the case where the error criterion is the
least absolute error.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  2965 </NUMBER>
<ORDER>   AAI9622175 </ORDER>
<TITLE> ELECTRONIC STABILIZATION AND FEATURE TRACKING IN LONG IMAGE SEQUENCES  </TITLE>
<AUTHOR> YAO, YI-SHENG </AUTHOR>
<YEAR> 1995 </YEAR>
<INSTITUTION> UNIVERSITY OF MARYLAND COLLEGE PARK; 0117 </INSTITUTION>
<DESCRIPTORS> ENGINEERING, ELECTRONICS AND ELECTRICAL; COMPUTER SCIENCE; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> RAMA CHELLAPA </ADVISER>
<CLASSIFICATIONS> COMPUTER VISION, IMAGE PROCESSING, NAVIGATION </CLASSIFICATIONS>
<ABSTRACT>
This dissertation is concerned with processing of visual
motion with application to off-road vehicular
navigation. Several aspects of the problem are
investigated. First, we consider the estimation of total
rotation from a sequence, useful for image
stabilization. This procedure is important for motion
analysis, idependently moving object detection as well
as the recovery of other structural information. We
exploit the dynamic nature of a sequence and use
multiple visual cues to perform image stabilization.
Depending on the knowledge of intrinsic parameters such
as the focal length and the field of view, both
calibrated and uncalibrated stabilization schemes are
designed. The residual motion in a stabilized sequence
is also analyzed. Next we address the issue of selective
stabilization, defined as the separation of the smooth
rotation and the residual oscillatory rotation. In off-
road vehicular navigation, in addition to smooth motion,
a vehicle exhibits residual vibrations. These residual
oscillatory components often affect the interpretation
of visual information. We incorporate a kinetic model to
explicitly account for the phenomena of vibration. A
maneuver detection scheme, for detecting the beginning
and end of smooth rotation, is designed to facilitate
the selective stabilization. The structure parameters
are consequently estimated in a less perturbed frame of
reference. Finally, we study the problem of feature
correspondence. Tracking feature points over a sequence
has been a critical procedure in exploiting an image
sequence. We propose a localized feature point tracking
algorithm. The method employs a 2-D kinematic model and
relies on a Probabilistic Data Association Filter for
the estimation of inter-frame motion. Corresponding
points are identified to sub-pixel accuracy and an
Extended Kalman Filter is employed to process the new
data. The ability to dynamically include new feature
points from subsequent frames also makes the algorithm
suitable for structure from motion and tracking over a
sequence.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  2966 </NUMBER>
<ORDER>   AAI9622097 </ORDER>
<TITLE> NEURAL NETWORK MODELS FOR PREDICTION, ESTIMATION, AND OPTIMIZATION: ALGORITHMS AND APPLICATIONS </TITLE>
<AUTHOR> KWON, OHSEOK </AUTHOR>
<YEAR> 1995 </YEAR>
<INSTITUTION> UNIVERSITY OF MARYLAND COLLEGE PARK; 0117 </INSTITUTION>
<DESCRIPTORS> ENGINEERING, ELECTRONICS AND ELECTRICAL; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> BRUCE L. GOLDEN </ADVISER>
<CLASSIFICATIONS> FEEDFORWARD, HOPFIELD </CLASSIFICATIONS>
<ABSTRACT>
Neural network models are useful for a wide variety of
prediction, classification, optimization, and pattern
recognition problems. A network of neurons can try to
learn the complex relationships between input
(independent) variables and output (dependent)
variables. In this dissertation, we apply neural network
models to important prediction, estimation, and
optimization problems. First, we use feedforward neural
networks to predict Atlantic hurricane activity. Second,
we construct neural network models that estimate the
optimal length of a traveling salesman tour through 10
to 80 points located in a rectangular region. Third, we
construct neural network models that predict initial
returns for initial public offerings. Fourth, we model
several kinds of knapsack problems using a modified
Hopfield neural network. In the first three
applications, we use a backpropagation algorithm with
enhancements and, in the fourth application, we use a
modified Hopfield network.
This dissertation has four objectives. (1) Model four
important prediction, estimation, and optimization
problems using neural network models. (2) Develop and
implement a neural network code that is capable of
solving each problem quickly and accurately. (3) Compare
the outcomes of neural network models to traditional
models, such as regression models, when appropriate. (4)
Discuss how the neural network models can be used in
practice.
The results of our modeling efforts reveal that neural
networks are useful tools for prediction, estimation,
and optimization problems. The adaptive nature of neural
network models makes them very appealing for prediction
and estimation problems. When applied to prediction and
estimation problems, most of our neural network models
outperformed regression models. We also applied Hopfield
network models to several knapsack problems and most of
the Hopfield models produced good results.
In Chapter 2, we provide a general description of the
neural network models that we will use to model the four
problems. In Chapter 3, we describe how we model
hurricane activity. In Chapter 4, we present the
traveling salesman application and, in Chapter 5, we
present the initial public offerings project. In Chapter
6, we describe the application of neural networks to
several knapsack problems. The major research
contributions of this dissertation and the work that
lies ahead are discussed in Chapter 7.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  2967 </NUMBER>
<ORDER>   AAI9622086 </ORDER>
<TITLE> CASE-BASED PLANNING WITH A HIGH-PERFORMANCE PARALLEL MEMORY  </TITLE>
<AUTHOR> KETTLER, BRIAN PATRICK </AUTHOR>
<YEAR> 1995 </YEAR>
<INSTITUTION> UNIVERSITY OF MARYLAND COLLEGE PARK; 0117 </INSTITUTION>
<DESCRIPTORS> COMPUTER SCIENCE; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> JAMES HENDLER </ADVISER>
<CLASSIFICATIONS> ARTIFICIAL INTELLIGENCE </CLASSIFICATIONS>
<ABSTRACT>
Case-based planning (CBP) systems, like other case-based
reasoning systems, can take advantage of previous
planning experience by reusing stored cases (plans) in
similar situations in the future. Advantages of CBP
include speedup over planning from scratch and the
ability to function with limited causal domain
knowledge. "Traditional" CBP systems with the latter
advantage typically cannot produce plans from scratch
because they lack the more powerful adaptation
mechanisms of generative planning systems. These "reuse-
only" CBP systems rely on retrieving a plan from the
casebase that is close to a solution plan. This requires
large casebases with good coverage of the problem space
and the ability to encode and match cases at fine levels
of detail.
Many such CBP systems, however, have fallen short of
these requirements. They support only small, pre-indexed
casebases. Pre-indexing constrains retrieval, as does
the use of less expressive feature-based case
representation schemes. The encoding and matching of
detailed structural relationships in cases is not
possible in such systems. These systems often adapt a
single plan to the target problem using methods that are
ad hoc or heuristic.
CAPER is a novel, domain-independent, case-based
planning system with improvements over traditional reuse-
only CBP systems from its use of techniques that exploit
a high-performance parallel memory of cases. CAPER takes
a memory-intensive approach by making frequent use of
memory during all phases of planning and by using large
casebases, which can be automatically seeded. Because
the parallel retrieval mechanisms scale to real-world
sized casebases of thousands of plans, memory does not
have to be pre-indexed and thus retrieval is more
flexible. Detailed queries can be used to match cases,
which are stored using an expressive, graph-structured
case representation scheme.
Plan adaptation in CAPER borrows techniques from
generative planning, such as the use of plan
validations, which capture dependencies in a plan, and
plan composition. These techniques are incorporated into
a reuse-only CBP framework for a more principled
approach to adaptation than in many reuse-only CBP
systems. CAPER can also use its flexible retrieval
mechanisms and case representations to retrieve patch or
substitute plans from memory.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  2968 </NUMBER>
<ORDER>   AAI9622054 </ORDER>
<TITLE> HIERARCHICAL TASK NETWORK PLANNING: FORMALIZATION, ANALYSIS, AND IMPLEMENTATION </TITLE>
<AUTHOR> EROL, KUTLUHAN </AUTHOR>
<YEAR> 1995 </YEAR>
<INSTITUTION> UNIVERSITY OF MARYLAND COLLEGE PARK; 0117 </INSTITUTION>
<DESCRIPTORS> COMPUTER SCIENCE; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> DANA S. NAU </ADVISER>
<CLASSIFICATIONS> NIL </CLASSIFICATIONS>
<ABSTRACT>
Planning is a central activity in many areas including
robotics, manufacturing, space mission sequencing, and
logistics. As the size and complexity of planning
problems grow, there is great economic pressure to
automate this process in order to reduce the cost of
planning effort, and to improve the quality of produced
plans.
AI planning research has focused on general-purpose
planning systems which can process the specifications of
an application domain and generate solutions to planning
problems in that domain. Unfortunately, there is a big
gap between theoretical and application oriented work in
AI planning. The theoretical work has been mostly based
on state-based planning, which has limited practical
applications. The application-oriented work has been
based on hierarchical task network (HTN) planning, which
lacks a theoretical foundation. As a result, in spite of
many years of research, building planning applications
remains a formidable task.
The goal of this dissertation is to facilitate building
reliable and effective planning applications. The
methodology includes design of a mathematical framework
for HTN planning, analysis of this framework,
development of provably correct algorithms based on this
analysis, and the implementation of these algorithms for
further evaluation and exploration. The representation,
analyses, and algorithms described in this thesis will
make it easier to apply HTN planning techniques
effectively and correctly to planning applications. The
precise and mathematical nature of the descriptions will
also help teaching about HTN planning, will clarify
misconceptions in the literature, and will stimulate
further research.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  2969 </NUMBER>
<ORDER>   AAI9622049 </ORDER>
<TITLE> GEOMETRIC METHODS IN VISUAL MOTION ANALYSIS </TITLE>
<AUTHOR> DURIC, ZORAN </AUTHOR>
<YEAR> 1995 </YEAR>
<INSTITUTION> UNIVERSITY OF MARYLAND COLLEGE PARK; 0117 </INSTITUTION>
<DESCRIPTORS> COMPUTER SCIENCE; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> AZRIEL ROSENFELD </ADVISER>
<CLASSIFICATIONS> RATE OF APPROACH, VEHICLE </CLASSIFICATIONS>
<ABSTRACT>
This thesis makes use of geometric methods in visual
motion analysis in several different ways. Chapter 2
describes robust motion analysis methods based on
geometric properties of the scene, with application to
the estimation of rate of approach (the inverse of "time
to collision"). Chapter 3 introduces a kinematic motion
model based on the differential geometry of curves, and
also describes a robust motion analysis method based on
geometric properties of the flow field. Chapter 4
introduces a kinematic model based on the differential
geometry of surfaces; it also discusses dynamic
constraints on the motion of a ground vehicle and
applies them to the stabilization of image sequences
obtained by a camera carried by the vehicle.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  2970 </NUMBER>
<ORDER>   AAI9621327 </ORDER>
<TITLE> ON THE OPTIMAL PLACEMENT OF HEAT SOURCES IN AN ENCLOSURE BASED ON ADAPTIVE SEARCH AND MACHINE LEARNING </TITLE>
<AUTHOR> QUEIPO, NESTOR VINICIO </AUTHOR>
<YEAR> 1995 </YEAR>
<INSTITUTION> UNIVERSITY OF CALIFORNIA, BERKELEY; 0028 </INSTITUTION>
<DESCRIPTORS> ENGINEERING, MECHANICAL; COMPUTER SCIENCE; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> JOSEPH A. C. HUMPHREY </ADVISER>
<CLASSIFICATIONS> NIL </CLASSIFICATIONS>
<ABSTRACT>
In this study, a model for the optimal placement of
convectively cooled electronic components on printed
wiring boards is formulated and solved using a solution
methodology that combines accurate numerical prediction
of transport quantities, adaptive search and machine
learning.
The electronic components on printed wiring boards are
represented as heated elements placed on the bottom wall
of an air-ventilated two-dimensional channel (laminar
developing flow). The model accommodates both thermal
(minimization of the failure rate due to overheating)
and non-thermal (minimization of the wiring length among
functionally related components) optimization criteria.
The main features of the solution methodology are: (i) a
fluid and heat transfer solver for accurate prediction
of the velocity and temperature fields, including the
maximum temperatures of the heated elements for
different arrangements of elements, (ii) a genetic
algorithm for the adaptive search of optimal or near-
optimal arrangements of the heated elements, and, (iii)
a learning strategy. The learning strategy constructs a
linguistic description of the relationship between the
positioning of the heated elements and failure rate
(fuzzy model) based on the data accumulated during the
adaptive search of optimal solutions. This linguistic
description is then used to accelerate the search for
optimal solutions.
The fluid and heat transfer numerical procedure
developed in this investigation is called FHTS (Fluid
and Heat Transfer Solver). It allows the calculation of
unsteady, three-dimensional, non-isothermal, constant
property laminar flow in cartesian or cylindrical
coordinates. The program FHTS was successfully tested
using well-known benchmark fluid flow and heat transfer
configurations. It was then used to calculate the
maximum temperature of the heated elements by
numerically solving the conservation of mass, momentum
and energy equations in the configuration of interest
subject to appropriate boundary conditions. The genetic
algorithm named CSGA (Combinatorial Simple Genetic
Algorithm) developed as part of this study, incorporates
a variety of selection mechanisms, the partially matched
crossover operator, and a portable random number
generator. The program CSGA also allows for synchronized
execution with the flow and heat transfer solver
(program FHTS).
To evaluate the present solution methodology a case
study was introduced. The case study defines an optimal
placement problem including a channel flow and heat
transfer configuration typical of models of electronic
components on printed wiring boards. The configuration
has eight heated elements, and a Reynolds number
$Resb0h$ of 750, where h is the height of the channel;
this corresponds to air velocities of order 0.5 m/s and
h equal to 0.02 m. The heated elements width (w/h) and
inter-element spacing (s/h) were taken as 0.5; the
heated element heights ($hsb1/h, hsb2/h)$ and heat flux
dissipation rates were in the intervals (0.1,0.2) and
(200 $W/msp2, 300 W/msp2$), respectively. The efficiency
and effectiveness of the proposed solution methodology
is demonstrated for a variation of the case study with
known optimal solutions. Results are also presented for
two different variations of the case study (with unknown
optimal solutions) subject to thermal and non-thermal
optimization criteria. (Abstract shortened by UMI.)
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  2971 </NUMBER>
<ORDER>   AAI9621088 </ORDER>
<TITLE> NEURAL NETWORK CONTROL AND ITS APPLICATION TO AUTOMOTIVE ENGINE CONTROL  </TITLE>
<AUTHOR> CHEN, LI-WEN </AUTHOR>
<YEAR> 1995 </YEAR>
<INSTITUTION> UNIVERSITY OF CALIFORNIA, BERKELEY; 0028 </INSTITUTION>
<DESCRIPTORS> ENGINEERING, MECHANICAL; ENGINEERING, ELECTRONICS AND ELECTRICAL; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> J. KARL HEDRICK </ADVISER>
<CLASSIFICATIONS> ARTIFICIAL INTELLIGENCE </CLASSIFICATIONS>
<ABSTRACT>
In this dissertation, a novel adaptive control
technique, based on the on-line adaptation of neural
networks, is proposed for the design of controllers for
three classes of nonlinear systems. Adaptive algorithms
for weights in neural networks with equally-spaced node
distributions are proposed. The controller design is
based on the sliding mode method. With these on-line
adaptive techniques applied to identify unknown
nonlinear mappings, the control input can be obtained
directly or indirectly from these identified functions
reconstructed by neural networks. If persistency of
excitation conditions are met, system stability and
unknown function estimation errors can be guaranteed to
converge to certain bounds in a Lyapunov sense. Finally,
these schemes are applied to automotive engine speed and
power tracking, and fuel injection controls, which have
severe nonlinearities and conventionally depend on pre-
built tables. Methods which assume that engine and fuel
delivery dynamics are unknown and use the least number
of neural nodes to reconstruct them are proposed.
Simulations and experiments showed that, with all state
variables measurable, the proposed schemes can identify
the plant and achieve superior performance than
conventional methods in controlling unknown nonlinear
systems.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  2972 </NUMBER>
<ORDER>   AAI9618009 </ORDER>
<TITLE> COMPARING TRADITIONAL STATISTICAL MODELS WITH NEURAL NETWORK MODELS: THE CASE OF THE RELATION OF HUMAN PERFORMANCE FACTORS TO THE OUTCOMES OF MILITARY COMBAT </TITLE>
<AUTHOR> HEDGEPETH, WILLIAM OLIVER </AUTHOR>
<YEAR> 1995 </YEAR>
<INSTITUTION> OLD DOMINION UNIVERSITY; 0418 </INSTITUTION>
<DESCRIPTORS> ENGINEERING, INDUSTRIAL; STATISTICS; PSYCHOLOGY, BEHAVIORAL; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> DERYA A. JACOBS </ADVISER>
<CLASSIFICATIONS> NIL </CLASSIFICATIONS>
<ABSTRACT>
Statistics and neural networks are analytical methods
used to learn about observed experience. Both the
statistician and neural network researcher develop and
analyze data sets, draw relevant conclusions, and
validate the conclusions. They also share in the
challenge of creating accurate predictions of future
events with noisy data.
Both analytical methods are investigated. This is
accomplished by examining the veridicality of both with
real system data. The real system used in this project
is a database of 400 years of historical military
combat. The relationships among the variables
represented in this database are recognized as being
hypercomplex and nonlinear.
The historical database was investigated from two
paradigms. Paradigm I states that predicting the winner
of combat can be based on post-combat personnel losses.
Paradigm II states that predicting the winner can be
based on pre-combat initial conditions of personnel
strength and skill factors.
The results give evidence that traditional statistical
methods may provide greater accuracy in predictions when
the data is clean or filtered (perfect) than when it is
noisy and unfiltered (imperfect). Neural networks, on
the other hand, may provide greater accuracy for the
same predictions when the data is left imperfect than
when it is cleaned up and filtered (perfect).
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  2973 </NUMBER>
<ORDER>   AAG9705636 </ORDER>
<TITLE> AN EVALUATION OF A SELF-SUPERVISED TOPOGRAPHIC NEURAL NETWORK USING CORRELATIONS </TITLE>
<AUTHOR> YOO, HYEON JOONG </AUTHOR>
<YEAR> 1995 </YEAR>
<INSTITUTION> UNIVERSITY OF MISSOURI - COLUMBIA; 0133 </INSTITUTION>
<DESCRIPTORS> ENGINEERING, ELECTRONICS AND ELECTRICAL; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> RUSSELL L. PIMMEL </ADVISER>
<CLASSIFICATIONS> ARTIFICIAL INTELLIGENCE </CLASSIFICATIONS>
<ABSTRACT>
We evaluated Luttrell's self-supervised topographic
neural network which is an unsupervised and self-
organizing network. We compared its performance to that
of other self-organizing neural networks including
Kohonen's self-organizing feature map. In a simulation
study, we used the network as a two-channel vector
quantizer to reconstruct two correlated vectors and used
the reconstruction error as a measure of its ability to
use the correlation between different channels. In
another study, we devised a unique scheme for power load
forecasting using Luttrell's network, and we used actual
power system data to compare its performance with that
of conventional algorithms.
In our simulation studies, we used two mathematical
models to provide data to two channels of a self-
organizing network. In the first, we used pairs of two-
dimensional vectors where the second vector was a
rotated version of the first with a random angle of
rotation whose statistics defined the degree of
correlation between the two vectors. The second
(referred to as the AR-like model) also involved vector
pairs where the second vector was a randomly perturbed
version of the first. The size of the random
perturbation, defined by a coefficient in the AR-like
model, controlled the correlation between the two
vectors.
The simulation results indicated Luttrell's network had
a lower reconstruction error than other self-organizing
networks. Also they showed that the mean rotation angle
of the rotation model and the coefficient in the AR-like
model were related to the reconstruction error with
Luttrell's network but not with other self-organizing
networks. These findings indicated that Luttrell's
algorithm took advantage of the correlation in the pair
of patterns processed by the two channels.
Using Luttrell's unsupervised network, we devised a
compact, real-time adaptive power load forecaster with
better performance than conventional load forecasters.
We obtained less than a 1% error and around a 2% error
in hour-ahead and day-ahead forecastings, respectively.
The network could be trained in a few minutes using the
most recent historical data.
Our work shows the advantages of the self-supervised
network. These encouraging results should stimulate
others to explore its use in place of supervised
networks in other applications.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  2974 </NUMBER>
<ORDER>   AAINN06834 </ORDER>
<TITLE> RECIPROCAL-WEDGE TRANSFORM: A SPACE-VARIANT IMAGE REPRESENTATION  </TITLE>
<AUTHOR> TONG, FRANK C. H. </AUTHOR>
<YEAR> 1995 </YEAR>
<INSTITUTION> SIMON FRASER UNIVERSITY (CANADA); 0791 </INSTITUTION>
<DESCRIPTORS> ENGINEERING, ELECTRONICS AND ELECTRICAL; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> ZE-NIAN LI </ADVISER>
<CLASSIFICATIONS> MACHINE VISION </CLASSIFICATIONS>
<ABSTRACT>
The problems in computer vision have traditionally been
approached as recovery problems. In active vision,
perception is viewed as an active process of
exploratory, probing and searching activities rather
than a passive re-construction of the physical world. To
facilitate effective interaction with the environment, a
foveate sensor coupled with fast and precise gaze
control mechanism becomes essential for active data
acquisition.
In this thesis, the Reciprocal-Wedge Transform (RWT) is
proposed as a space-variant image model. The RWT has its
merits in comparison with other alternative foveate
sensing models such as the log-polar transform. The
concise matrix representation makes it enviable for its
simplified computation procedures. Similar to the log-
polar transform, the RWT facilitates space-variant
sensing which enables effective use of variable-
resolution data and the reduction of the total amount of
the sensory data. Most interestingly, its property of
anisotropic mapping yields variable resolution primarily
in one dimension. Consequently, the RWT preserves linear
features and performs especially well on translations in
the images.
A projective model is developed for the transform,
lending it to potential hardware implementation of RWT
projection cameras. The CCD camera for the log-polar
transform requires sensing elements of exponentially
varying sizes. In contrast, the RWT camera achieves
variable resolution with oblique image plane projection,
thus alleviating the need for non-rectangular
tessellation and sensitivity scaling on the sensing
elements. A camera model making use of the available
lens design techniques is investigated.
The RWT is applied to motion analysis and active stereo
to illustrate the effectiveness of the image model. In
motion analysis, two types of motion stereo are
investigated, namely, longitudinal and lateral motion
stereo. RWT motion stereo algorithms are developed for
linear and circular ego motions in road navigation, and
depth recovery from moving parts on an assembly belt.
The algorithms benefit from the perspective correction,
linear feature preservation and efficient data reduction
of the RWT.
The RWT imaging model is also shown to be suitable for
fixation control in active stereo. Vergence and
versional eye movements and scanpath behaviors are
studied. A computational interpretation of stereo fusion
in relation to disparity limit in space-variant imagery
leads to the development of a computational model for
binocular fixation. The unique oculomotor movements for
binocular fixation observed in human system appears
natural to space-variant sensing. The vergence-version
movement sequence is implemented for an effective
fixation mechanism in RWT imaging. An interactive
fixation system is simulated to show the various modules
of camera control, vergence and version. Compared to the
traditional reconstructionist approach, active behavior
is shown to be plausible.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  2975 </NUMBER>
<ORDER>   AAINN06571 </ORDER>
<TITLE> MACHINE LEARNING TECHNIQUES FOR THE CONTROL OF FES- ASSISTED LOCOMOTION AFTER SPINAL CORD INJURY </TITLE>
<AUTHOR> KOSTOV, ALEKSANDAR </AUTHOR>
<YEAR> 1995 </YEAR>
<INSTITUTION> UNIVERSITY OF ALBERTA (CANADA); 0351 </INSTITUTION>
<DESCRIPTORS> HEALTH SCIENCES, REHABILITATION AND THERAPY; HEALTH SCIENCES, PHYSICAL THERAPY; ARTIFICIAL INTELLIGENCE; ENGINEERING, ELECTRONICS AND ELECTRICAL; ENGINEERING, BIOMEDICAL </DESCRIPTORS>
<ADVISER> RICHARD B. STEIN </ADVISER>
<CLASSIFICATIONS> NIL </CLASSIFICATIONS>
<ABSTRACT>
Functional electrical stimulation (FES) has been used as
a substitution for the missing neural excitation of the
paralyzed muscles after spinal cord injury. FES-assisted
walking with preset stimulation patterns is usually
controlled by a therapist or the subject using manual
controls mounted on the handgrips of a walking aid.
Automation of the switching control can be done by
designing a rule-based control algorithm which will
replace the decision making process the person uses to
control the stimulation manually. These rules are
usually designed by intuitive 'hand-crafting' and by
applying them on a set of sensory feedback signals. This
process has to be repeated for each subject due to
highly specific disabilities resulting from physically
similar injuries.
In this thesis a method is proposed, developed, and
applied for automatic generation of control rules, which
may provide a much faster evaluation of new subjects
than the "hand-crafting" method. The rules are extracted
from a set of sensory feedback signals and stimulation
control signals recorded during FES-assisted walking
controlled by a skilled therapist or the subject. The
rule-generation method is evaluated using two different
machine learning techniques, Adaptive Logic Networks
(ALNs) and Inductive Learning (IL). Very fast training
and high generalization of both techniques justified the
design of the integrated control system (ICS). The ICS,
currently based on ALNs, provides an efficient tool to
acquire sensory and control signals, to process these
signals, to train the ALNs in mapping the control
function, to test the trained ALNs and to use them for
control signal generation in real-time control of the
FES-assisted walking of subjects with incomplete spinal
cord injury. The IL technique was also evaluated in rule-
generation for control of walking of subjects with
complete spinal injury and its potential for cloning the
subject's skill in switching the stimulation was
demonstrated. In addition, ALNs were evaluated for
continuous control of single joint flexion-extension,
based on signals recorded from natural sources, such as
nerves and muscles of cat's hind limb. Through
experimental work it has been demonstrated that both
techniques are able to generate control rules quickly
and to generalize, not only over daily subsequent
walking sessions but also over the sessions occurring
several days after the training This provides a good
basis for design of robust control systems for FES-
assisted walking.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  2976 </NUMBER>
<ORDER>   AAINN06188 </ORDER>
<TITLE> SELF-LEARNING PREDICTIVE CONTROL USING RELATIONAL-BASED FUZZY LOGIC  </TITLE>
<AUTHOR> BOURKE, MARY MARGARET </AUTHOR>
<YEAR> 1995 </YEAR>
<INSTITUTION> UNIVERSITY OF ALBERTA (CANADA); 0351 </INSTITUTION>
<DESCRIPTORS> ENGINEERING, ELECTRONICS AND ELECTRICAL; COMPUTER SCIENCE; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> D. G. FISHER </ADVISER>
<CLASSIFICATIONS> ARTIFICIAL INTELLIGENCE </CLASSIFICATIONS>
<ABSTRACT>
This thesis documents the development of a Model-based
Self-Learning Predictive Fuzzy Logic (MSPF) Controller
for use in applications where the inherent uncertainty
in the process model and/or data precludes the use of
conventional discrete control algorithms. This work
required not only a translation of the concepts of
discrete model-based control systems into the fuzzy
domain but also significant extensions to fuzzy logic
theory.
The extensions to fuzzy logic theory in this thesis
pertain mostly to the max-product composition, which
several authors have shown to produce better results
than the widely used max-min composition. The
superiority of the max-product composition was also
confined in this thesis for a variety of process
oriented applications. The new theory developed for the
max-product composition includes eigen fuzzy stability,
powers of $0bf R$ stability, an estimate of a minimum
$0bf R,$ and the complete Cartesian product solution,
parts of which have been published in the Fuzzy Sets and
Systems journal.
Since the max-product composition has not been used
extensively, there was very little existing literature
on effective identification algorithms for this
composition. This thesis therefore reviews and compares
several important fuzzy identification strategies for
the max-min composition and then applies them using the
max-product composition. Based on this work, a new
identification algorithm was developed that is better,
from a least squares perspective, than the existing
algorithms when applies to the Box-Jenkins gas furnace
data. The new identification algorithm also includes a
new procedure that permits an identification aigorithm
to adapt quickly to process changes while maintaining a
complete solution.
Most of the rule-based fuzzy logic controller designs in
the literature are based on a $0bfit PI$ controller
structure. The development of the control algorithm in
this thesis parallel that of conventional k-step-ahead
model-based predictive controllers, but implementation
is significantly different due to the fuzzy environment.
An important feature of this new controller is that the
control action is determined based on the discrete error
between the output and the setpoint. Results from this
thesis clearly show that minimization of a control
objective defined by a fuzzy criterion does not imply
minimization of the corresponding discrete criterion.
Therefore the proposed MSPF controller is ideal for
practical control applications because, in the majority
of cases, the objective is discrete even though the
methodology is fuzzy in order to handle the unavoidable
uncertainties.
The MSPF controller gave very good closed-loop
performance in simulation using underdamped, overdamped
and non-linear processes plus processes with large time
delays and/or disturbances. A direct comparison of the
MSPF controller versus a conventional discrete: it PI
controller using a very (smoothly) non-linear process
showed that (based on minimization of the discrete
control error) the MSPF controller gave better
performances over the full operating domain than PI
control even when three-level gain scheduling was used.
The development and evaluating of the Self-Learning
Predictive Fuzzy Logic Controller described above is
complemented by a extensive fuzzy logic tutorial which
includes a literature survey and examples for each
aspect of the controller development.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  2977 </NUMBER>
<ORDER>   AAINN06071 </ORDER>
<TITLE> A CONTRIBUTION TO ARCHITECTURAL/ENGINEERED DESIGN FOR TIMBER STRUCTURES USING KNOWLEDGE-BASED METHODS </TITLE>
<AUTHOR> TAYLOR, ROBERT JOHN </AUTHOR>
<YEAR> 1995 </YEAR>
<INSTITUTION> THE UNIVERSITY OF BRITISH COLUMBIA (CANADA); 2500 </INSTITUTION>
<DESCRIPTORS> ENGINEERING, CIVIL; AGRICULTURE, WOOD TECHNOLOGY; ARTIFICIAL INTELLIGENCE; ARCHITECTURE </DESCRIPTORS>
<ADVISER> S. F. STIEMER </ADVISER>
<CLASSIFICATIONS> ARTIFICIAL INTELLIGENCE </CLASSIFICATIONS>
<ABSTRACT>
This thesis attempts to synthesize knowledge from the
fields of architecture, engineering, and computer
science in the contest of design. In particular, a novel
approach to modeling the architectural and engineering
design of structural connections is presented. Computer
automation using parametric object-oriented methods for
quantitative design is new for connections, and the
inclusion of qualitative features native to
architectural considerations present a more holistic
view to automated design of connections.
A unique method of representing connections as a kit of
parts for assembly is presented that is based on the
load path within the connection. The configuration model
facilitates engineering discretization and evaluation;
while the connection, if properly designed, can be more
easily "read" by the observer--a desirable feature of a
good work of architecture.
Quantitative aspects, typically thought of as
engineering qualities, are combined with the adapted
qualitative, typically architectural, aspect of a
designed artifact through the use of dynamic fuzzy logic
membership functions. A fuzzy logic adaptation of the
qualitative attributes of the designed artifact can be
used for assessing or generating aesthetics consistent
within the scope of aesthetic definitions offered by the
designer. The adaptation, therefore, does not constrain
the designer to a prescribed attribute definition, but
an architectural expression which is personal and
unique. A brief development of membership function
representation, calibration, and application is offered.
Results from a particular demonstrative study of
proximity, and another on colour reveal a promising
application of fuzzy logic technology to qualitative
design issues.
Among a number of smaller innovations, the main
contribution of this thesis to the advancement of
knowledge is three fold: a new method to represent
structural connection in general; a synthesis of truths
underlying connection configuration design in timber
structures so hat design automation using object-
oriented method can be facilitated; and development of
an automation method for connection design that
separates program control from object data, which is a
significant benefit in ease of automated application
expansion. The work presented here is intended to break
new ground in these areas for others to investigate
further towards resolving a significant need in design.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  2978 </NUMBER>
<ORDER>   AAINN05936 </ORDER>
<TITLE> A QUALITATIVE MODELING FACILITY FOR INTELLIGENT SUPERVISORY CONTROL SYSTEMS </TITLE>
<AUTHOR> CIFUENTES, EDGARDO IVAN </AUTHOR>
<YEAR> 1995 </YEAR>
<INSTITUTION> THE UNIVERSITY OF BRITISH COLUMBIA (CANADA); 2500 </INSTITUTION>
<DESCRIPTORS> ENGINEERING, INDUSTRIAL; ARTIFICIAL INTELLIGENCE; OPERATIONS RESEARCH </DESCRIPTORS>
<ADVISER> JOHN MEECH </ADVISER>
<CLASSIFICATIONS> ISCSS) (ARTIFICIAL INTELLIGENCE </CLASSIFICATIONS>
<ABSTRACT>
Control strategies based on purely mathematical
algorithms have only limited ability to cope with the
type of operating conditions found in full-scale
industrial applications. One approach to overcome this
limitation integrates elements of automatic control
theory, artificial intelligence and operations research
into the design of a control system. This approach is
employed in this research study to design an intelligent
supervisory control system (ISCS). Elements of
artificial intelligence to provide "human-like"
characteristics for the ISCS are central to this
research.
Pseudo-Qualitative Modeling as a central component of an
ISCS is proposed in this research. This approach
provides the mechanisms required by the ISCS to handle
heuristic knowledge and approximate reasoning required
in many supervisory control applications. A simulation
study has been performed to demonstrate the validity of
this approach. Simulation results have shown that this
technique can handle either poorly-defined heuristic
models or accurate models based on mathematical
concepts. In fact, pseudo-qualitative modeling provides
a framework to integrate qualitative and numerical
models into a knowledge-based system.
A prototype of an ISCS was implemented using
ProcessVision, a real-time SCADA (Supervisory Control
And Data Acquisition) software package. This prototype
system was applied to the C-line grinding circuit at
Highland Valley Copper (HVC) to monitor and detect
tonnage restrictions that affect circuit production. The
diagnosis of tonnage restriction is currently performed
manually by metallurgists on a weekly basis. This method
is a heuristic procedure based on highly subjective
judgement. The diagnosis results provided by the ISCS
prototype during the evaluation period were well within
the range of those reported by HVC metallurgists.
Implementation of this ISCS prototype has demonstrated
the feasibility of incorporating qualitative modeling
into a commercial real-time SCADA system widely used in
industrial applications.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  2979 </NUMBER>
<ORDER>   AAINN05910 </ORDER>
<TITLE> FUZZY LOGIC IN POLDER FLOOD CONTROL OPERATIONS IN BANGKOK </TITLE>
<AUTHOR> AGSORN, SONGKRAN </AUTHOR>
<YEAR> 1995 </YEAR>
<INSTITUTION> THE UNIVERSITY OF BRITISH COLUMBIA (CANADA); 2500 </INSTITUTION>
<DESCRIPTORS> ENGINEERING, CIVIL; ARTIFICIAL INTELLIGENCE; HYDROLOGY </DESCRIPTORS>
<ADVISER> S. O. RUSSELL </ADVISER>
<CLASSIFICATIONS> THAILAND, ARTIFICIAL INTELLIGENCE </CLASSIFICATIONS>
<ABSTRACT>
The flood situation in Bangkok and the way in which it
has evolved is described in this study. The present
approach to flood control involves use of the polder
concept. Since excess water in a polder has to be
disposed of either through gravity drainage or pumping,
the way in which the gates and/or pumps are operated
becomes very important. In practice, operators of such
facilities tend to be risk averse and favor operating
according to fixed rules.
Fuzzy logic programming was investigated as a way to
improve operations, while not departing too far from the
fixed rule operation that operators prefer. Some simple
experiments were first done to find the most suitable
alternative to present methods of incorporating fuzzy
information. A new fuzzy algorithm was proposed and
tested.
Due to unavailability of actual data, a simple, but
reasonably representative flood control situation,
typical of those in Bangkok was used. Operating
procedures were developed based on synthetic rainfalls
and runoffs. Then, fuzzy operating rules were derived,
and a fuzzy rule base was set up. Next, simulations were
used in which flood hydrographs were generated and the
system was "operated" using fuzzy logic programming and
the fuzzy rule base which was developed. The results
were compared with three other systems: fixed rule
system, a time varying rule curve, and "optimal"
operation. Besides the main experiments, which involved
only pump operations, additional sets of experiments
were conducted for the cases with combined pump and sate
operations and with tides.
Fuzzy logic programming was demonstrated to be a very
promising tool for improving flood control operating
procedures for polder systems such as those in use in
Bangkok. The procedure can be looked upon as an
extension of the fixed rule operating procedures
presently being used by the operators. Further
extensions are possible, including the use of flow
forecasts. However, the main purpose of this study was
to investigate the feasibility of using fuzzy logic
programming to improve on existing operating procedures.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  2980 </NUMBER>
<ORDER>   AAI9621653 </ORDER>
<TITLE> CALIBRATION AND SENSITIVITY ANALYSIS OF NONLINEAR SYSTEMS WITH APPLICATION TO GRAVITY MODELS </TITLE>
<AUTHOR> XU, RONG </AUTHOR>
<YEAR> 1995 </YEAR>
<INSTITUTION> UNIVERSITY OF SOUTHERN CALIFORNIA; 0208 </INSTITUTION>
<DESCRIPTORS> URBAN AND REGIONAL PLANNING; ECONOMICS, THEORY; OPERATIONS RESEARCH </DESCRIPTORS>
<ADVISER> PETER GORDON </ADVISER>
<CLASSIFICATIONS> NIL </CLASSIFICATIONS>
<ABSTRACT>
This thesis concentrates on several important issues in
the calibration and sensitivity analysis of nonlinear
systems. The major contribution lies in the development
of an innovative sequential procedure to improve poor
initial parameter estimates systematically and
automatically. Based on ideas from the field of
artificial intelligence, this general procedure shows
great promise in reducing the dependence of the
iterative approaches on initial approximations.
Preliminary numerical experiments indicate that rapid
convergence to the true parameter values is the rule
rather than the exception. This ability is especially
prominent when dealing with a large amount of noisy
data.
The thesis also proposed the use of the FEED (Fast and
Efficient Evaluation of Derivatives) approach for
evaluating derivatives of complicated nonlinear
functions. This is a simple, practical, and
computationally inexpensive method. It suggests that
higher-order derivatives can be evaluated exactly and
automatically. It also relieves researchers from the
tedious and error-prone processes of forming analytical
expressions of the derivatives, which then have to be
programmed.
Motivated by the desire to avoid the expensive Monte
Carlo simulations, the thesis provides a short-cut for
obtaining simple statistical properties of nonlinear
least squares estimators. The key is to obtain the
sensitivity coefficients of these estimators to the
noise in the observations. FEED greatly facilitates the
implementation of this approach.
Realizing the local nature of the traditional
sensitivity analysis and its limitations in dealing with
dramatic policy changes, this thesis also introduces
nonlocal sensitivity analysis. The idea is to fully
utilize modern computers' superior ability in
integrating ordinary differential equations, and to
trace the trajectories of the policy variables and their
sensitivity coefficients numerically.
The focus of the thesis is on mathematical and
computational methodology. However, applications are
also viewed of equal importance. Thus, the thesis is
organized around the actual calibration and sensitivity
analysis of gravity models. Three planning problems
(identifying consumers' preferences related to shopping
and traveling in static and dynamic retailing systems,
and forecasting the changes in equilibrium retailing
systems) are examined. Numerical results are provided
using synthetic data.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  2981 </NUMBER>
<ORDER>   AAI9620668 </ORDER>
<TITLE> DESIGNERS AND THEIR TOOLS: COMPUTER SUPPORT FOR DOMAIN CONSTRUCTION  </TITLE>
<AUTHOR> SUMNER, TAMARA R. </AUTHOR>
<YEAR> 1995 </YEAR>
<INSTITUTION> UNIVERSITY OF COLORADO AT BOULDER; 0051 </INSTITUTION>
<DESCRIPTORS> COMPUTER SCIENCE; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> GERHARD FISCHER </ADVISER>
<CLASSIFICATIONS> HUMAN COMPUTER INTERACTION </CLASSIFICATIONS>
<ABSTRACT>
In today's high-technology workforce, many designers
work in dynamic and innovative domains such as user
interface and software design. This thesis considers the
problem of providing these designers with computational
design support tools. It differs from other efforts in
that the emphasis is on understanding and supporting the
evolutionary patterns of change inherent in dynamic
domains. The motivating problem investigated is
flexibility, specifically: How can systems provide
domain-specific support for short-term design activities
yet still be flexible enough to accommodate long-term
evolutionary patterns of change in the domain? Three
empirical studies show how design communities gradually
construct their domain by defining important domain
objects, creating and evolving representations for
viewing these objects, and establishing relationships
between objects and representations. The observed design
process is termed domain construction. Analyses of these
studies are used to characterize the observed domain
construction processes of use, elaboration, and
modification. Design environments based on two
computational models are analyzed in terms of these
domain construction processes. The two computational
models occupy seemingly different ends of the spectrum
from support to flexibility. The Toolbelt model, where
practitioners assemble and evolve collections of generic
software applications, seemingly offers more
flexibility. The Domain-Oriented Design Environment
model, where customized domain-oriented tools are
created for a specific community, seemingly provides
better support but is less flexible. These intuitions
are investigated to better understand which aspects of a
computational model (i.e., underlying data models,
domain models, architectures, and integration services)
help or hinder an environment's overall flexibility. The
results are used to develop recommendations for the next
generation of design support environments.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  2982 </NUMBER>
<ORDER>   AAI9620582 </ORDER>
<TITLE> QUALITY MONITORING AND CONTROL OF THE INJECTION MOLDING PROCESS USING A PATTERN-BASED APPROACH </TITLE>
<AUTHOR> WOLL, SUZANNE LYNN BRADFORD </AUTHOR>
<YEAR> 1995 </YEAR>
<INSTITUTION> THE UNIVERSITY OF CONNECTICUT; 0056 </INSTITUTION>
<DESCRIPTORS> ENGINEERING, CHEMICAL; PLASTICS TECHNOLOGY; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> NIL </ADVISER>
<CLASSIFICATIONS> NEURAL NETWORKS, PROCESS CONTROL </CLASSIFICATIONS>
<ABSTRACT>
Injection molding is a fundamental manufacturing
technology that produces plastic components for a vast
array of consumer product industries. Current industry
demands for high quality, tight tolerance parts require
improved injection molding capabilities. In an effort to
improve the part quality monitoring and control
capabilities, this work applies the use of artificial
neural networks (ANNs) as pattern analysis tools.
Presented in this work are a part quality monitoring
technique, a closed-loop pattern control strategy and a
part quality calibration methodology. Central to each of
these pattern-based developments is the use of a back
propagation network (BPN) to associate cavity pressure
patterns with appropriate parameters. Demonstrations
show that the monitoring technique is superior in
predicting part quality when compared to statistical
techniques commonly practiced in the industry.
Additional demonstrations validate the pattern set point
tracking and disturbance identification abilities of the
pattern control strategy.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  2983 </NUMBER>
<ORDER>   AAI9619957 </ORDER>
<TITLE> APPLICATION OF ASSOCIATIVE MEMORIES FOR BACKGROUND CORRECTION OF SPECTRA  </TITLE>
<AUTHOR> WABUYELE, BUSOLO WA </AUTHOR>
<YEAR> 1995 </YEAR>
<INSTITUTION> OHIO UNIVERSITY; 0167 </INSTITUTION>
<DESCRIPTORS> CHEMISTRY, ANALYTICAL; ENGINEERING, BIOMEDICAL; ENGINEERING, ELECTRONICS AND ELECTRICAL; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> NIL </ADVISER>
<CLASSIFICATIONS> ARTIFICIAL INTELLIGENCE </CLASSIFICATIONS>
<ABSTRACT>
A novel artificial neural network has been devised and
is evaluated for the background correction of single
scan infrared (IR) spectra. An optimal associative
memory (OAM) is an enhanced bidirectional associative
memory (BAM). By factoring the weight matrix, OAMs may
be used with high resolution data on a desktop computer.
IR spectroscopy provides a rigorous and practical
challenge for evaluating background connection. IR
single scan background spectra are stored in the
associative memory. Single scan sample spectra are used
to retrieve the best fitting background scans. The OAM
uses an internal Gram-Schmidt calculation and does not
require orthogonal data. The associative properties of
the OAM allow background scans not stored in the memory
to be modeled. The memories were evaluated with 2 cm$sp0-
1$ resolution IR spectra. Quantitative analyses of 2-
octanone/toluene solutions were used to evaluate the OAM
with regard to accuracy and linearity. In both cases of
univariate and multivariate calibrations, the OAM
corrected spectra furnished better calibration models
than those obtained from conventional IR absorbance
spectra.
Quantitative comparisons of a BAM, a modified BAM and an
OAM neural networks are presented for background
prediction of IR spectra. These memories were evaluated
using 2 cm$sp0-1$ resolution IR spectra. The efficacies
of these methods were quantitatively evaluated using
root mean square prediction errors of 100% transmittance
lines. In all cases, the OAM performed superiorly to the
BAMs. The OAM is a technique that can be applied to any
type of data as long as two conditions are satisfied:
the background spectra and the sample spectra must have
points of intersection and the signal variations in the
sample need to be different from the background
variations.
A fuzzy optimal associative memory (FOAM) has been
devised for background correction of near-IR spectra.
The FOAM improves the prediction of backgrounds using
near-IR spectra of glucose in plasma matrices. The FOAM
is an enhanced OAM that uses a fuzzy function for
encoding the spectra. The FOAM can predict a matching
background spectrum for a near-IR absorbance spectrum
with low glucose absorbances (e.g., 10$sp0-2$-10$sp0-4$
AU), by using second derivative spectra. Glucose
concentrations were predicted from calibration models
furnished by partial least squares (PLS). The FOAM
stored reference spectra obtained from either
water/phosphate buffer or plasma/glucose solutions. Both
of these associative memories were evaluated.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  2984 </NUMBER>
<ORDER>   AAG9705223 </ORDER>
<TITLE> CMAC ADDRESSING TECHNIQUE BASED LEARNING STRUCTURES </TITLE>
<AUTHOR> CHIANG, CHING-TSAN </AUTHOR>
<YEAR> 1995 </YEAR>
<INSTITUTION> UNIVERSITY OF MISSOURI - COLUMBIA; 0133 </INSTITUTION>
<DESCRIPTORS> ENGINEERING, ELECTRONICS AND ELECTRICAL; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> CHUN-SHIN LIN </ADVISER>
<CLASSIFICATIONS> CEREBELLAR MODEL ARTICULATION CONTROLLER, ARTIFICIAL INTELLIGENCE </CLASSIFICATIONS>
<ABSTRACT>
The Cerebellar Model Articulation Controller (CMAC) was
first introduced by J. S. Albus in 1972. Since then very
few further studies have been done until recent years.
The CMAC is one kind of associative memory technique
often used for control learning, mapping implementation
and function approximation. The technique is able to
provide good generalization, guaranteed learning
convergence and fast learning speed. With these
attractive merits, however, because constant values are
stored for quantized states, the derivative of the
modeled function is not preserved. This drawback limits
the applications of the CMAC. In this dissertation, new
techniques are developed to solve the
undifferentiability problem. Two techniques that are
based on the CMAC have been developed. One technique
uses differentiable basis functions to replace the
constant ones originally used in the conventional CMAC.
Another one integrates the locally weighted regression
with the CMAC.
On the first kind of technique, the dissertation starts
with discussions on the CMAC with general basis
functions. Mathematical equations describing the
generalized CMAC have been derived and the proof that
the learning will converge has been given. All proofs in
this part are applicable to the conventional CMAC, which
is a special case of the generalized one. A further
study on the CMAC with the use of one special type of
differentiable basis functions, Gaussian Basis
Functions, has been done. Necessary learning rules have
been derived and simulations have been performed to
evaluate the learning performance. Experimental results
demonstrate the merits of differentiability of the
approximate function and better accuracy.
The second technique called CMAC$sb-$LWR integrates the
locally weighted regression (LWR) technique with CMAC.
The technique uses the CMAC structure to efficiently
store information for local areas. The locally weighted
regression method is adopted to construct a local
regression model when the output for a given input data
point is needed. This technique also shows the
capability of differentiation and, with the regression,
provides better accuracy.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  2985 </NUMBER>
<ORDER>   AAI9619668 </ORDER>
<TITLE> AN AUTOMATED DIAGNOSTICS SYSTEM FOR EDDY CURRENT ANALYSIS USING APPLIED ARTIFICIAL INTELLIGENCE METHODS </TITLE>
<AUTHOR> YAN, WU </AUTHOR>
<YEAR> 1995 </YEAR>
<INSTITUTION> THE UNIVERSITY OF TENNESSEE; 0226 </INSTITUTION>
<DESCRIPTORS> ENGINEERING, NUCLEAR; ENGINEERING, MECHANICAL; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> B. R. UPADHYAYA </ADVISER>
<CLASSIFICATIONS> FUZZY LOGIC, EXPERT SYSTEMS, NEURAL NETWORKS </CLASSIFICATIONS>
<ABSTRACT>
The purpose of this dissertation research is to develop
a diagnostic expert system that integrates database
management methods, digital signal processing,
artificial neural networks, expert system and fuzzy
logic techniques for the automation of steam generator
eddy current test (ECT) data analysis. The following key
tasks were identified and developed for establishing a
robust analysis system: (1) digital eddy current test
data calibration, compression, and representation, (2)
noise compensation, (3) development of robust neural
networks with a low probability of defect
misclassification and defect parameter estimation, (4)
decision making for flaw detection using fuzzy logic,
(5) development of an expert system for database
management, compilation of a trained neural network
library, and a decision module, and (6) performance
evaluation of the integrated approach using eddy current
test data. An automated diagnostics system using NDE
data is needed because of the necessity to process a
large amount of information, and because of the
limitations of human processing capability. Different
forms of eddy current inspection data were acquired from
the EPRI NDE Center and from the Metals and Ceramics
Division of ORNL.
The integrated approach for automating the analysis of
eddy current test data for steam generator tubing
diagnosis is an original contribution of this research.
The successful implementation of the methodology
requires proper data compression, data calibration, data
management, fuzzy logic flaw detection and flaw
parameters estimation. There are no defined approaches
to accomplish this task. The fuzzy flaw detection
system, developed in this research, is the first to
utilize information from multi-frequency eddy current
data for flaw detection. The database management
approach developed in this research, is also a unique
contribution that would help pave the way for commercial
on-line implementation of this nondestructive evaluation
technique. A PC WINDOWS-based expert system called
EDDYAI was developed using Microsoft Visual C++. This
system integrates all the techniques developed in this
research project into a user-friendly expert system for
automated steam generator multi-frequency eddy current
test data analysis.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  2986 </NUMBER>
<ORDER>   AAI9619652 </ORDER>
<TITLE> FUZZY LOGIC AND NEURAL NETWORK BASED ADVANCED CONTROL AND ESTIMATION TECHNIQUES IN POWER ELECTRONICS AND AC DRIVES </TITLE>
<AUTHOR> SIMOES, MARCELO GODOY </AUTHOR>
<YEAR> 1995 </YEAR>
<INSTITUTION> THE UNIVERSITY OF TENNESSEE; 0226 </INSTITUTION>
<DESCRIPTORS> ENGINEERING, ELECTRONICS AND ELECTRICAL; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> BIMAL K. BOSE </ADVISER>
<CLASSIFICATIONS> NIL </CLASSIFICATIONS>
<ABSTRACT>
The dissertation presents, examines and analyzes
advanced control and estimation techniques in power
electronics and ac drives. It constitutes four projects
where such artificial intelligence tools were
extensively used. A variable speed wind generation
system was developed, where three fuzzy logic
controllers were used for efficiency optimization and
for performance enhancement control. The controller FLC-
1 searches the generator speed on-line so that the
aerodynamic efficiency of the wind turbine can be
optimized. A second fuzzy controller, FLC-2, programmed
the machine flux by on-line search so as to optimize the
machine-converter system efficiency. A third fuzzy
controller, FLC-3, performed robust speed control
against turbine oscillatory torque and wind vortex.
Next, a neural network was applied for estimation of
feedback signals in an induction motor drive, which has
some distinct advantages when compared to DSP based
implementation. A feedforward neural network received
the machine terminal signals at the input and calculated
flux, torque and unit vectors at the output, which were
then used in the control of a direct vector-controlled
drive system. The application of fuzzy logic to the
estimation of power electronic waveforms was taken into
consideration for distorted line current waves in a
TRIAC dimmer and in a three-phase diode rectifier
feeding an inverter-machine load. Fuzzy logic estimation
was applied to assess the rms current, fundamental rms
current, displacement factor and power factor. Both the
rule base and relational approaches were used for
estimation of the above parameters. The estimated values
were then compared with the actual values, indicating
good accuracy. Finally, the development of a speed and
flux sensorless vector-controlled induction motor drive
was considered. The stator flux oriented drive started
at zero speed in indirect vector control mode, transited
to direct vector control mode as the speed developed,
and then transited back to indirect vector control at
zero speed. The vector control used stator flux
orientation in both indirect and direct vector control
modes with the stator resistance variation compensated
by measurement of stator temperature. The problem of
integration at low stator frequency was solved by
cascaded low-pass filters with programmable time
constants.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  2987 </NUMBER>
<ORDER>   AAI9619454 </ORDER>
<TITLE> A FRAMEWORK FOR THE ANALYSIS OF SOPHISTICATED CONTROL </TITLE>
<AUTHOR> WHITEHAIR, ROBERT CHARLES </AUTHOR>
<YEAR> 1995 </YEAR>
<INSTITUTION> UNIVERSITY OF MASSACHUSETTS; 0118 </INSTITUTION>
<DESCRIPTORS> COMPUTER SCIENCE; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> VICTOR R. LESSER </ADVISER>
<CLASSIFICATIONS> INTERPRETATION DECISION PROBLEM, UPC FORMALISM </CLASSIFICATIONS>
<ABSTRACT>
This dissertation addresses problems associated with the
lack of design theories for AI problem solving systems.
The principle focus of the work is the introduction and
demonstration of a framework for the analysis of
sophisticated search control architectures applied in
complex problem domains. The thesis associated with this
work is that real-world problem domains and problem
solving architectures can be represented formally and
that these representations can be used to analytically
predict and explain a problem solver's performance.
Further, the implications of this work are that useful
approximations and abstractions can be derived from such
formal representations and used to design sophisticated
control mechanisms. The ultimate objective of this work
is to use these representations as the basis of design
theories for building problem solving architectures and
dynamic control algorithms.
The framework is based on two formalisms, the
Interpretation Decision Problem (IDP), which models both
the structure of a problem domain and the structure of a
problem solving architecture, and the UPC formalism,
which provides a general quantitative model of search
spaces that can be used in the analysis of problem
solving control. Using these models, the problem
structures of disparate domains and the problem solving
architectures constructed to exploit these structures
can be viewed from a unified perspective where control
and problem solving actions can be considered a single
class of problem solving activity. Models built from
this unified perspective offer advantages for
describing, predicting and explaining the behavior of
blackboard-based interpretation systems and for
generalizing a specific problem solving architecture to
other domains. Use of the IDP and UPC formalisms also
supports the synthesis of new, more flexible problem
solving architectures.
This dissertation demonstrates how the framework can be
applied by analyzing a vehicle monitoring interpretation
problem domain and associated problem solving
architectures, including a heuristic, multi-level
blackboard-based system. Definitions, examples, and
experimental results are given for general structures
from interpretation problem domains and blackboard-based
problem solving architectures. Design principles for
general problem solving strategies that exploit the
structures are discussed.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  2988 </NUMBER>
<ORDER>   AAI9619348 </ORDER>
<TITLE> MODELING DEPENDENCE IN PROJECT MANAGEMENT </TITLE>
<AUTHOR> JENZARLI, ALI </AUTHOR>
<YEAR> 1995 </YEAR>
<INSTITUTION> UNIVERSITY OF KANSAS; 0099 </INSTITUTION>
<DESCRIPTORS> OPERATIONS RESEARCH; BUSINESS ADMINISTRATION, MANAGEMENT; STATISTICS </DESCRIPTORS>
<ADVISER> GLENN R. SHAFER; PRAKASH P. SHENOY </ADVISER>
<CLASSIFICATIONS> BELIEF NETWORKS, PERT </CLASSIFICATIONS>
<ABSTRACT>
We develop new methods for explicit modeling of
dependence between activity times in a project. These
methods improve on existing methods, such as PERT and
PERT-based methods, by taking into account the
probabilistic dependencies between duration and
completion times of different activities, and the
different ways a project may be delayed. We take account
of these complications by using recent advances in
artificial intelligence, decision analysis and
statistics, namely belief networks (BNs), influence
diagrams (IDs), mixed Gaussian probability models and
Gibbs sampling (GS), an iterative Markov chain Monte
Carlo method.
We use BNs to model probabilistic dependencies between
duration and completion times of different activities.
We interpret PERT networks as BNs in which nodes
represent completion times and arrows represent
probabilistic dependencies between nodes. This
interpretation allows us to extend the PERT network
model to include other variables that affect duration
and completion times. We call the resulting network PERT
Belief Network (PBN).
When a PBN includes decision variables, we call the
resulting network PERT Influence Diagram (PID). We
extend our PID representation to represent constraints
on decisions. We call the resulting network PERT
Information/Relevance Influence Diagram (PIRID).
We give Monte Carlo algorithms to solve PBNs, PIDs and
PIRIDs, i.e., compute marginal densities and
expectations, and optimize decisions. We use forward
Monte Carlo to solve PBNs without observations; GS to
solve PBNs with observations; and a combination of GS
and stochastic dynamic programming to solve PIDs. We
model duration times using conditional Gaussian
densities.
We give stopping rules for forward Monte Carlo and GS
algorithms. We show how to draw inferences from one long
run of the chain when using GS to solve PBNs with
observations. Moreover, we show how to diagnose and
solve the problem of near-zero probabilities in GS
programs for PBNs and BNs in general.
Our PBN and PID models, and their solution algorithms
can be used to solve not only project management
problems, but also other problems where discrete,
continuous and decision variables exist in a dependence
structure. These may include work-flow, bottlenecks,
quality audits, medical diagnosis, and many risk
assessment problems, e.g., insurance, financial audit,
and loans.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  2989 </NUMBER>
<ORDER>   AAI9619172 </ORDER>
<TITLE> TEMPORAL DYNAMICS OF BIOLOGICAL NEURAL NETWORK MODELS </TITLE>
<AUTHOR> MURPHY, SEAN DIARMUID </AUTHOR>
<YEAR> 1995 </YEAR>
<INSTITUTION> YALE UNIVERSITY; 0265 </INSTITUTION>
<DESCRIPTORS> BIOLOGY, NEUROSCIENCE; ARTIFICIAL INTELLIGENCE; ENGINEERING, BIOMEDICAL </DESCRIPTORS>
<ADVISER> EDWARD W. KAIRISS </ADVISER>
<CLASSIFICATIONS> OSCILLATIONS, CLUSTERING, MEMBRANE DEPOLARIZATION, ARTIFICIAL INTELLIGENCE </CLASSIFICATIONS>
<ABSTRACT>
The nervous system is too complicated to be understood
by inference from physiological and anatomical data
alone. To a large degree, this is because it is unclear
how experimentally isolated details of neural circuitry
interact to give rise to higher-level functions.
Computational modeling is a means of combining low-level
biological details into functional structures that can
be studied quantitatively, thereby allowing the mutual
interactions of physiological and anatomical details to
be experimentally accessible. Due to technological
advancements in computing technology, it has recently
become possible to study the dynamical properties of
networks of model neurons with Hodgkin-Huxley active
membrane characteristics at a scale that approaches
biological realism. This dissertation consists of three
experimental sections that begin to work towards an
understanding of how properties at the single-neuron
level and network level interact to give rise to
characteristics such as oscillations, synchronization,
and spatio-temporal clustering of activity. First, a
method is presented by which complex biological neuron
models can be computationally reduced to potentially
more efficient regression models. Second, a study of the
sensitivity of simple biological neuron models to
fluctuations in synaptic input timing is presented.
Third, the results of a parametric study of how features
of network activity are dependent on intrinsic
connectivity, afferent connectivity, stimulus pattern
structure, and strength of connectivity between
excitatory and inhibitory cell populations is given. The
design and use of the BIONET neural network simulator is
also presented.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  2990 </NUMBER>
<ORDER>   AAI9619143 </ORDER>
<TITLE> MATCHING AND LEARNING STRUCTURAL AND SPATIAL REPRESENTATIONS WITH NEURAL NETWORKS </TITLE>
<AUTHOR> GOLD, STEVEN ALLEN </AUTHOR>
<YEAR> 1995 </YEAR>
<INSTITUTION> YALE UNIVERSITY; 0265 </INSTITUTION>
<DESCRIPTORS> COMPUTER SCIENCE; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> ERIC DANIEL MJOLSNESS </ADVISER>
<CLASSIFICATIONS> COMBINATORIAL OPTIMIZATION, ARTIFICIAL INTELLIGENCE </CLASSIFICATIONS>
<ABSTRACT>
The matching and learning of structural and spatial
representations with Hopfield like recurrent neural
networks is explored, by formulating and minimizing
different energy functions. Building upon recent
techniques from statistical physics, such as
deterministic annealing which helps avoid some local
minima, and the softmax which enforces a one-way
constraint without a penalty term, a new optimization
technique is introduced--the softassign. The softassign
is specifically geared to the types of problems being
examined--matching problems--which often require two-way
(assignment) constraints. It eliminates the need for
penalty terms in these objective functions.
The softassign is applied to three types of problems,
the first of which is the matching of structural
representations--graphs, A new algorithm is introduced
which can match unweighted, weighted and attributed
relational graphs. This algorithm employs a sparse
distance measure between the links of the two graphs.
Experiments on randomly generated graphs, and on graphs
generated from images are presented.
The second problem is the matching of spatial
representations--two sets of feature points located in
two dimensional space. The feature points may be
specified solely by their Cartesian coordinates, or
there may be a feature vector associated with them. It
is assumed the two sets of feature points are related by
an affine transformation. Within Computer Vision this is
known as a pose estimation and correspondence problem. A
new algorithm is introduced and experiments on randomly
generated point sets are run. Experiments on hand-
written characters are presented.
Finally the problem of learning spatial and structural
representations is addressed. A new algorithm for
clustering is introduced, which uses as distance
measures versions of the point matching and graph
matching algorithms. Point set and graph prototypes are
learned in an unsupervised fashion. Experiments on
randomly generated data sets, and data sets generated
from hand-written characters are run.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  2991 </NUMBER>
<ORDER>   AAI9618842 </ORDER>
<TITLE> BOOTSTRAP BASED COOPERATIVE PROCESSES IN COMPUTER VISION </TITLE>
<AUTHOR> CHO, KYUJIN </AUTHOR>
<YEAR> 1995 </YEAR>
<INSTITUTION> RUTGERS THE STATE UNIVERSITY OF NEW JERSEY - NEW BRUNSWICK; 0190 </INSTITUTION>
<DESCRIPTORS> ENGINEERING, ELECTRONICS AND ELECTRICAL; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> PETER MEER </ADVISER>
<CLASSIFICATIONS> EDGE DETECTION, ARTIFICIAL INTELLIGENCE </CLASSIFICATIONS>
<ABSTRACT>
A new approach for executing computer vision tasks is
presented. In real situations the complexity of the
input data and/or computational procedure limits the
possibilities of rigorous modeling, and therefore it is
difficult to design algorithms optimal for a wide
variety of operating conditions. Validating the
assumptions embedded into a computer vision algorithm
for the given input is a necessary condition if robust
techniques are desired.
We propose the use of bootstrap based cooperative
processes for validation. The set of outputs, obtained
by perturbing the input data in the execution of the
task, defines the empirical distribution of the output.
From the distribution an output confidence measure under
the given operating conditions can then be assessed.
Based on these confidence values the task can be
executed using less constraining assumptions about the
data and thus improving the robustness of any algorithm.
The derived confidences also provide tools for
evaluating the performance of the system under realistic
operating conditions.
The proposed approach is motivated by resampling
techniques developed in statistics during the past
decade, especially the bootstrap. The bootstrap method
is a nonparametric estimation technique of the
statistical behavior of an estimate when only a single
sample of the input data is available. We make extensive
use of bootstrap techniques. The methodology of using
cooperative processes is first applied to evaluate and
compare the performance of several edge detection
systems. Confidences are obtained by using the
perturbation of nuisance properties of the input,
properties with no relevance for the output under ideal
conditions. Based on the confidence values, an edgemap
independent of the gradient magnitude is derived, As
another example we show that robust image segmentation
can be achieved based on the consensus information
extracted from the output of several region-adjacency-
graph (RAG) pyramids having a probabilistic component.
The generality of the new technique is discussed and its
applications for other computer vision tasks are
proposed as further research.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  2992 </NUMBER>
<ORDER>   AAI9618834 </ORDER>
<TITLE> STUCTURAL PROPERTIES AND MINIMIZATION OF HORN BOOLEAN FUNCTIONS  </TITLE>
<AUTHOR> CEPEK, ONDREJ </AUTHOR>
<YEAR> 1995 </YEAR>
<INSTITUTION> RUTGERS THE STATE UNIVERSITY OF NEW JERSEY - NEW BRUNSWICK; 0190 </INSTITUTION>
<DESCRIPTORS> OPERATIONS RESEARCH </DESCRIPTORS>
<ADVISER> ENDRE BOROS </ADVISER>
<CLASSIFICATIONS> COMPLEXITY, SATISFIABILITY </CLASSIFICATIONS>
<ABSTRACT>
This dissertation is devoted to the study of two special
subclasses of Boolean functions: the class of Horn
functions and the class of pure Horn functions. Their
importance rests in the fact that various problems which
are intractable for general Boolean functions become
solvable in polynomial time if we restrict ourselves to
(pure) Horn functions. The most prominent among these
problems is the well known satisfiability problem. As a
result of the tractability of (pure) Horn functions,
many real world tasks that can be formulated as Boolean
problems are effectively solvable in those instances
that correspond to (pure) Horn functions. Examples of
such tasks can be found, among others, in the areas of
artificial intelligence and database design.
There are two topics which are in the center of our
attention throughout the dissertation: (i) structural
properties of (pure) Horn functions and (ii) the
complexity of their minimization. By minimization we
mean the following problem. Given a (pure) Horn function
represented by some standard form, find a representation
of the given function which has a minimum possible size.
The Horn minimization is known to be NP-complete.
However, the proofs require functions of very high
degrees which are proportional to the number of
propositional letters in the function. We sharpen the NP-
completeness results to hold even for inputs with
degrees bounded by a low constant. These are the
"negative" complexity results. On the "positive" side we
show how the structural properties of (pure) Horn
functions can be used to transform s given minimization
problem into a problem on a smaller instance. We also
develop a minimization heuristic based on generating the
classes of logically equivalent propositional letters.
Finally, we suggest a simple algorithm which generates
these equivalence classes and prove that the algorithm
achieves the best possible complexity.
The structural properties of (pure) Horn functions that
we study here hinge on the correspondence between (pure)
Horn functions and directed graphs. They provide a tool
for an efficient recognition of certain redundancies in
a given representation and provide a nontrivial lower
bound on the minimum size of a representation of the
given function. We also show that the concept of
resolution used for general Boolean functions obeys
special properties when applied to (pure) Horn
functions. That allows us to state an upper bound on the
size of all "essential" resolvents.
The last topic we treat in this dissertation is the
relationship between the class of 0, $pm$1 perfect
matrices and Horn functions. We prove that those
matrices for which deciding perfectness is nontrivial
correspond to a very special subclass of Horn functions
called quasi-acyclic Horn functions.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  2993 </NUMBER>
<ORDER>   AAI9618690 </ORDER>
<TITLE> DEVELOPMENT OF A SYSTEMATIC APPROACH FOR KNOWLEDGE ACQUISITION AND EXPERIENCE CAPTURE OF VETERAN PRACTITIONERS IN THE HIGHWAY CONSTRUCTION INDUSTRY </TITLE>
<AUTHOR> EPSTEIN, WILLIAM CURTIS </AUTHOR>
<YEAR> 1995 </YEAR>
<INSTITUTION> UNIVERSITY OF FLORIDA; 0070 </INSTITUTION>
<DESCRIPTORS> ENGINEERING, CIVIL; INFORMATION SCIENCE; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> ZOHAR J. HERBSMAN; RALPH D. ELLIS </ADVISER>
<CLASSIFICATIONS> EXPERT SYSTEMS, HYPERTEXT </CLASSIFICATIONS>
<ABSTRACT>
Every company in every industry faces the prospect of
the loss of knowledge and experience through the
departure of key personnel. This predicament created by
the loss of veteran employees is especially acute in the
highway construction industry, where frequently the
experience is either undocumented or poorly documented,
and the knowledge possessed by these people is retained
exclusively as personal property. This dissertation not
only explores the difficulties associated with pursuing
an approach to acquire heretofore undocumented
construction knowledge and expertise, but it also
recognizes the vast amounts of highway construction data
and information that are currently available within the
transportation industry. Any concerted effort attempting
to capture the construction knowledge and expertise of a
large organization, such as a department of
transportation, would be severely remiss in not taking
advantage of this existing base of documented
information.
This research endeavor represents a comprehensive study
of the problems associated with the development of a
systematic approach for capturing the knowledge and
experience of a large organization, and establishing a
computer delivery system for dissemination of this
encoded information. Fundamental to this delivery system
is the creation of a user-friendly computing environment
that will provide an intuitive tool capable of assisting
both veteran and novice practitioners in fashioning more
informed decisions concerning problems that may arise
during normal and abnormal highway construction
operations.
One of the major accomplishments of this research
effort, was the development of an information management
prototype system which was given the name IN REACH
(Intelligent Information Retrieval and Expert Advice for
the Construction of Highways). IN REACH is comprised of
an underlying, fully functionally hypertext network
which is augmented by the integration of some innovative
database management and expert systems strategies. In an
effort to add structure to the inherently unstructured
world of a pure hypertext system, IN REACH utilizes
these integrated strategies to enhance the user's
capability of direct queries to the overall network,
both statically and dynamically.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  2994 </NUMBER>
<ORDER>   AAI9618355 </ORDER>
<TITLE> NEURAL NETWORK TRAINING ALGORITHMS UTILIZING PERIODIC ACTIVATION AND RELAXATION </TITLE>
<AUTHOR> LIU, LI-MIN </AUTHOR>
<YEAR> 1995 </YEAR>
<INSTITUTION> THE UNIVERSITY OF TEXAS AT ARLINGTON; 2502 </INSTITUTION>
<DESCRIPTORS> ENGINEERING, ELECTRONICS AND ELECTRICAL; COMPUTER SCIENCE; REMOTE SENSING; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> MICHAEL T. MANRY </ADVISER>
<CLASSIFICATIONS> PATTERN RECOGNITION, SIGNAL PROCESSING, REMOTE SENSING </CLASSIFICATIONS>
<ABSTRACT>
In this dissertation, neural network fundamentals and
Fourier series theory are reviewed, followed by a
presentation of new design techniques of network
architectures. A new objective function for neural net
classifier design is presented, which has more free
parameters than the classical objective function. An
iterative minimization technique for the objective
function is derived which requires the solution of
multiple sets of numerically ill-conditioned linear
equations. A numerically stable solution to the neural
network design equations, which utilizes the conjugate
gradient algorithm and a relaxation algorithm, is
presented. The design method is applied to networks used
to classify remote sensing and shaping imaginary.
To transfer Fourier series into a neural network, it is
necessary to convert N-dimensional Fourier series into a
convenient form in which each term has a sine and a
cosine. This is a multilayer network with trigonometric
activations and weight sharing. Thresholds in the hidden
layer are not necessary. A series of experiments on the
mapping and classification applications from the new
developed network shows that its performance is close to
that of the multilayer perceptron network, but with a
smaller number of weights. The network training
performance, with the new architecture, is sometimes
better than that of the MLP.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  2995 </NUMBER>
<ORDER>   AAG1381884 </ORDER>
<TITLE> FUNCTIONAL CORROBORATION OF A DIGITAL MULTILAYER NEURAL NETWORK </TITLE>
<AUTHOR> MALIK, QAISER HAMEED </AUTHOR>
<YEAR> 1995 </YEAR>
<INSTITUTION> MICHIGAN STATE UNIVERSITY; 0128 </INSTITUTION>
<DESCRIPTORS> ENGINEERING, ELECTRONICS AND ELECTRICAL; COMPUTER SCIENCE; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> NIL </ADVISER>
<CLASSIFICATIONS> NIL </CLASSIFICATIONS>
<ABSTRACT>
A model of the digital multilayer neural network (DMNN),
has been implemented in software using the C programming
language. The DMNN employs a stochastic nonlinear
function in the backpropagation learning rule. A suite
of test cases is applied to the simulated DMNN and its
performance is analyzed with reference to an ordinary
Artificial Neural Network (ANN) employing a sigmoidal
function. The backpropagation learning algorithm, used
in the DMNN, has been revised in order to accelerate the
convergence process. A modified DMNN has been simulated
based upon the refinements suggested in the
backpropagation algorithm. The modified DMNN has been
found to converge for a wider range of learning rates
$(eta)$ and momentum factors $(alpha).$
Three networks, DMNN, modified DMNN and ANN, are
simulated on an 80486 based Personal Computer (PC). The
learning pattern of each network is determined for the
test cases and their performance is analyzed.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  2996 </NUMBER>
<ORDER>   AAI9618346 </ORDER>
<TITLE> THE ROLE OF DOMAIN KNOWLEDGE IN SUBSTRUCTURE DISCOVERY </TITLE>
<AUTHOR> DJOKO, SURNJANI </AUTHOR>
<YEAR> 1995 </YEAR>
<INSTITUTION> THE UNIVERSITY OF TEXAS AT ARLINGTON; 2502 </INSTITUTION>
<DESCRIPTORS> COMPUTER SCIENCE; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> DIANE J. COOK </ADVISER>
<CLASSIFICATIONS> ENCODING, MACHINE LEARNING </CLASSIFICATIONS>
<ABSTRACT>
Discovering repetitive, interesting, and useful
substructures in a structural database improves the
ability to interpret and compress the data. However,
scientists working with a database in their area of
expertise often search for a predetermined type of
structure, or for structures exhibiting characteristics
specific to the domain. This study presents a method for
guiding the discovery process with several different
types of domain-specific knowledge. In this study, the
SUBDUE discovery system is used to evaluate the benefits
of using domain knowledge. The domain knowledge is
incorporated into Subdue using a minimum description
length principle to guide the discovery process.
Results show that domain-specific knowledge improves the
search for substructures which are useful to the domain,
and leads to greater compression of the data. To
illustrate these benefits, examples and experiments from
the satellite image, computer programming, computer
aided design circuit, Chinese character and artificial
domains are presented. An analysis of computational cost
of the algorithms is also provided.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  2997 </NUMBER>
<ORDER>   AAI9617975 </ORDER>
<TITLE> CONTROL OF A BIOMECHANICAL MODEL OF THE HUMAN POSTURAL MAINTENANCE SYSTEM BY ARTIFICIAL NEURAL NETWORKS </TITLE>
<AUTHOR> STYER, LOUIS DANIEL </AUTHOR>
<YEAR> 1995 </YEAR>
<INSTITUTION> UNIVERSITY OF CALIFORNIA, DAVIS; 0029 </INSTITUTION>
<DESCRIPTORS> ENGINEERING, BIOMEDICAL; ENGINEERING, ELECTRONICS AND ELECTRICAL; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> V. RAO VEMURI </ADVISER>
<CLASSIFICATIONS> LEARNING, MACHINE LEARNING </CLASSIFICATIONS>
<ABSTRACT>
This research is a first step towards understanding the
algorithm by which the human brain analyzes sensory and
cognitive data to choose an appropriate pattern of motor
responses. A mathematical model of the musculoskeletal
system of the human was controlled by an Artificial
Neural Networks (ANNs) control system to simulate the
learning and motor control of perturbed posture. Two
musculoskeletal models, a single-link and a two-link
model were selected for simulation in software.
This research focused on reinforcement learning because
it appears to incorporate the trial and error learning
of an abstract goal that is characteristic of human
learning. Biologically plausible learning mechanisms do
not rely on the existence of a supervisor/teacher. Six
ANN methods that have reinforcement learning
characteristics, three based on the Adaptive Critic (AC)
method and three based on the Direct Search (DS) method,
were used. Of the six, the Adaptive Critic Functional
Link Outerproduct (AC-FLO) method and the adapted
version of Chemotaxis (DS-Chem) introduced here are new.
The AC-FLO and DS-Chem methods were compared with the
other methods using the cartpole system. The AC-FLO
method provided improvements over the other AC methods
by decreasing the amount of a priori information, as
required in the AC-Box method, and increasing the speed
of convergence during learning over the AC-Bkp method.
The AC methods required and the DS methods were enhanced
by including a stochastic neuron in the action
determination unit.
These ANN methods were compared using both the speed of
convergence and the performance of the control law on
the two biomechanical models. DS-Chem is the best ANN
method for further research of human postural control,
due to its rapid convergence and the favorable scaling
requirements. DS-Chem has a probability of successful
learning to control the two-link postural model of
greater than 0.8, AC-FLO greater than 0.75 and all
others less than 0.35. The DS-Chem method could control
the two-link model 80 percent of the time and the AC-FLO
less than 55 percent of the time.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  2998 </NUMBER>
<ORDER>   AAI9617224 </ORDER>
<TITLE> DESIGN AND COMPARISON OF NONLINEAR COMPENSATORS </TITLE>
<AUTHOR> EUN, CHANG-SOO </AUTHOR>
<YEAR> 1995 </YEAR>
<INSTITUTION> THE UNIVERSITY OF TEXAS AT AUSTIN; 0227 </INSTITUTION>
<DESCRIPTORS> ENGINEERING, ELECTRONICS AND ELECTRICAL; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> EDWARD J. POWERS </ADVISER>
<CLASSIFICATIONS> NEURAL NETWORK, VOLTERRA SERIES </CLASSIFICATIONS>
<ABSTRACT>
We consider nonlinear compensator design schemes using
neural networks and Volterra series models for nonlinear
systems with memory. We also investigate the use of the
stochastic gradient method for the identification of a
finite-memory nonlinear system for the purpose of using
the successive component compensation method for
compensating such nonlinear systems. Of special
importance is that we develop a predistorter design
scheme based on indirect learning architecture which was
originally used in system control. The predistorter
design is important since some limitations encountered
when using equalizers can be overcome. We present
predistorter design techniques for a memory-less
nonlinearity preceded by a linear system with memory. In
addition, we systematically compare various nonlinear
compensation methods using the pth-order inverse method
as a reference. For applications, we apply the neural
network method, the Volterra series model approach, and
the successive component compensation method to the
compensation of nonlinear telecommunication channels and
a sample-and-hold circuit of an analog-to-digital
converter used in digital telecommunications. Both
predistorters and equalizers are considered. For the
neural network approach, we use complex-valued time-
delayed multilayer perceptrons for compensator
structures. To process complex-valued signals, we
independently developed a complex error backward
propagation algorithm. To overcome generic neural
network limitations, we develop the direct Volterra
series model compensation approach which utilizes the
recursive least-squared error (RLS) algorithm. For
finite-memory nonlinear systems, we develop an
identification technique using the stochastic gradient
method. Based on the identified finite-memory nonlinear
system, we compensate components of the system one after
another using a linear system inversion technique and a
root-finding algorithm. For predistorters for a memory-
less nonlinearity preceded by a linear system with
memory, we modify the indirect learning algorithm for an
invertible linear system and developed a stochastic
gradient method approach for a non-invertible linear
system. We verify our compensation design algorithms
through experimental communication data. Also, we verify
the identification technique for finite-memory nonlinear
systems utilizing the stochastic gradient method through
the use of spar data from off-shore engineering. The
comparison of the various methods shows that each
approach has its own advantages and limitations. The
specific compensation approach to be utilized should he
selected depending on the nature of the nonlinearity and
the signal statistics.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  2999 </NUMBER>
<ORDER>   AAI9617183 </ORDER>
<TITLE> AUTOMATING THE ALLOCATION OF WATER SUPPLIES IN TEXAS USING AN EXPERT SYSTEM TO CONTROL THE INTERACTION OF A GEOGRAPHIC INFORMATION SYSTEM AND AN LP SOLUTION ALGORITHM </TITLE>
<AUTHOR> BURGIN, JOHN FREDERICK </AUTHOR>
<YEAR> 1995 </YEAR>
<INSTITUTION> THE UNIVERSITY OF TEXAS AT AUSTIN; 0227 </INSTITUTION>
<DESCRIPTORS> ENGINEERING, CIVIL; PHYSICAL GEOGRAPHY; ENGINEERING, SANITARY AND MUNICIPAL; HYDROLOGY; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> DAENE C. MCKINNEY </ADVISER>
<CLASSIFICATIONS> NIL </CLASSIFICATIONS>
<ABSTRACT>
A set of procedures to automate regional water resources
planning was developed by integrating the capabilities
of an expert system, a geographical information system
and an LP solver. Water supply and demand data are
stored in the database of the geographic information
system and used to develop a network of potential
allocation arcs linking all supplies to all demands.
Planning rules derived from the knowledge and experience
of water planning experts are stored in the expert
system and used to modify the network. A linear
programming solution algorithm is then employed to
determine a minimum cost set of flows in the modified
feasible network of allocation alternatives.
The system was evaluated on both hypothetical and
realistic data sets, and the resulting allocations were
demonstrated to be consistent with those produced by
existing methods.
Significant reduction in the time necessary to perform
an allocation analysis was realized by automating the
procedure. In practical applications this can be
translated into the ability to more fully explore the
effects of variations in supply, demand, transport
capacity, and the expert system rules themselves.
The rules, categorized by the scope of their
application, were found to be effective in capturing and
implementing the considerations of expert water
planners.
The most significant advancement to water resources
planning afforded by automating the process devolves
from the implicit necessity that the process be
rigorous. This results in more defensible solutions and
in more realistic comparisons of alternative scenarios.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  3000 </NUMBER>
<ORDER>   AAI9616940 </ORDER>
<TITLE> COMPACT VLSI ARRAY PROCESSORS DESIGN FOR MULTIMEDIA APPLICATIONS  </TITLE>
<AUTHOR> CHANG, ROBERT CHEN-HAO </AUTHOR>
<YEAR> 1995 </YEAR>
<INSTITUTION> UNIVERSITY OF SOUTHERN CALIFORNIA; 0208 </INSTITUTION>
<DESCRIPTORS> ENGINEERING, ELECTRONICS AND ELECTRICAL; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> BING J. SHUE </ADVISER>
<CLASSIFICATIONS> CELLULAR NEURAL NETWORKS </CLASSIFICATIONS>
<ABSTRACT>
With rapid advances of deep-submicron microelectronic
technologies, a high-performance intelligent system with
tens of millions of transistors can be integrated onto a
single chip. The compact, high-computing power systems
become feasible with significant progresses in the
research and development of advanced computing
architecture and array processing. Extensive studies of
artificial and biological neural networks, which have
inherent massively paralleled and distributed signal
processing capabilities, have provided an excellent
means to perform several complex functions in scientific
and engineering applications such as image/pattern
recognition, medical image, computer vision, path
planning, and autonomous robots. Array processors based
on cellular neural networks combine some features of
fully interconnected neural networks with the nearest
neighbor interactions and are especially well suited for
very large-scale integration (VLSI) implementation. A 5
x 5 paralleled array processor chip has been designed
and fabricated by using the 2-$mu m$ CMOS technology
from the MOSIS Service. The prototype chip with
digitally-programmable weights was constructed with many
compact mixed-signal VLSI circuit components which were
designed using the current-mode techniques. The low-
voltage, low-power operation is supported with the
current-mode scheme which scales well with the supply
voltage. Measurement results of the VLSI computing cells
are presented. Experimental results obtained from a
custom-made circuit board are provided to illustrate the
operation of the prototype chip. The software-hardware
codesign methodology is used to implement the high-
performance intelligent microsystem which can be
constructed by the array processor chips and software
program. Neural networks with the hardware annealing
method are very energy-efficient in solving many complex
optimization problems. Demonstration of novel operation
of achieve optimal solution at fast signal processing
using standard IC parts is given. VLSI design of a
variable-gain neuron circuit can be incorporated into
the prototype chip to realize the optimal solution
capability.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  3001 </NUMBER>
<ORDER>   AAI9616454 </ORDER>
<TITLE> REDUCED COMPLEXITY VLSI CIRCUITS FOR RADIAL BASIS FUNCTION NEURAL NETWORKS </TITLE>
<AUTHOR> WATKINS, STEVEN SPENCER </AUTHOR>
<YEAR> 1995 </YEAR>
<INSTITUTION> UNIVERSITY OF CALIFORNIA, SAN DIEGO; 0033 </INSTITUTION>
<DESCRIPTORS> ENGINEERING, ELECTRONICS AND ELECTRICAL; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> PAUL M. CHAU </ADVISER>
<CLASSIFICATIONS> NIL </CLASSIFICATIONS>
<ABSTRACT>
This research explores the creation of efficient neural
network multiprocessors to exploit the parallelism
inherent in neural network topologies, in order to speed
up execution of the networks. It demonstrates that
reduced complexity circuits can be used in place of
standard floating-point processors for some
applications. These circuits provide very large savings
in terms of area and power consumption, while producing
results that are nearly indistinguishable from results
obtained with high-precision floating-point circuits.
The area and power savings allow the creation of very
efficient, cost-effective neural network accelerators.
Both analog and digital circuits were designed and
evaluated. Analog circuits were designed, simulated,
fabricated and tested. An analog Gaussian neuron with
novel width control is presented. Digital circuits were
designed, simulated, implemented with programmable logic
and tested. A new approach for a digital
multiply/accumulate building block is presented; this
circuit scales as O(klogk), where k is the number of
network inputs.
Comparisons are presented detailing the advantages and
disadvantages of both types of circuits, and suggestions
are made concerning when to use one type of circuit over
the other. Two different neurocomputers were constructed
using these circuits. A remote sensing application
executed on the neurocomputers provided better results
than had been previously obtained using either neural
networks or non-neural network statistical methods.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  3002 </NUMBER>
<ORDER>   AAI9616326 </ORDER>
<TITLE> MODELING DYNAMIC SIGNALS WITH NEURAL NETWORKS </TITLE>
<AUTHOR> NGUYEN, MAI HUONG THI </AUTHOR>
<YEAR> 1995 </YEAR>
<INSTITUTION> UNIVERSITY OF CALIFORNIA, SAN DIEGO; 0033 </INSTITUTION>
<DESCRIPTORS> COMPUTER SCIENCE; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> GARRISON W. COTTRELL </ADVISER>
<CLASSIFICATIONS> SPEECH RECOGNITION </CLASSIFICATIONS>
<ABSTRACT>
This dissertation examines the problem of modeling
dynamic signals in a neural network framework. Dynamic
signals are encountered in many important tasks, ranging
from speech recognition to financial prediction to
biological modeling. The application of a neural network
to such tasks requires that the network have dynamic
properties to make it responsive to time-varying
signals. Modeling dynamic signals requires two
components: the ability to recognize sequences, and the
ability to handle temporal variability. Sequence
recognition is necessary because dynamic signals are not
single patterns but sequences of patterns. Addressing
temporal variability is important because in many real-
world applications, inputs do not come in as fixed-rate
sequences, but rather as temporal signals with varying
time scales.
This dissertation presents a neural network model,
called the Tau Network, with properties to address both
sequence recognition and temporal variability. In Tau
Net, sequence recognition is accomplished using a
combination of prediction and recurrence. Temporal
variability is modeled via adaptable time constants:
Adapting the time constants changes the time scale of
the network, enabling it to model variable-rate signals.
Our approach to modeling dynamic signals using Tau Net
is to train the network to become a model of the signal;
that is, the network learns to generate the dynamics of
the signal being modeled through a prediction task. The
processing rate of the network is then adapted to match
the rate of the signal by adjusting the network's time
constant with respect to the prediction error. The
adapted time constant usefully serves as a measure of
temporal variation in the signal. Experimental results
demonstrate Tau Net's ability to model the underlying
time-varying dynamics of several signals, ranging from
coupled sine waves to segments extracted from continuous
speech. These results show that Tau Net is able to track
signals at variable rates by extrapolating to rates not
represented in the training data. Furthermore, the
change in the network's time constant strongly
correlates with the temporal variation in the signal
being modeled.
Speech is chosen as the domain in which to study the
problem of modeling dynamic signals and as the final
test for Tau Net. Speech is an inherently temporal
process with frequent and often substantial temporal
variation. Capturing its dynamic nature has always been
a challenge in speech modeling, and has been a
particularly troublesome issue for neural network
approaches. Thus, much of the work presented in this
dissertation centers around speech, and speech
recognition in particular. It should be clear, however,
that the Tau Network is a general approach for modeling
variable-rate dynamic signals and is applicable in other
domains as well.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  3003 </NUMBER>
<ORDER>   AAI9616318 </ORDER>
<TITLE> DISCOVERING MOTIFS IN DNA AND PROTEIN SEQUENCES: THE APPROXIMATE COMMON SUBSTRING PROBLEM </TITLE>
<AUTHOR> BAILEY, TIMOTHY LAWRENCE </AUTHOR>
<YEAR> 1995 </YEAR>
<INSTITUTION> UNIVERSITY OF CALIFORNIA, SAN DIEGO; 0033 </INSTITUTION>
<DESCRIPTORS> COMPUTER SCIENCE; BIOLOGY, GENERAL; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> CHARLES P. ELKAN </ADVISER>
<CLASSIFICATIONS> MACHINE LEARNING, ARTIFICIAL INTELLIGENCE </CLASSIFICATIONS>
<ABSTRACT>
Discovering patterns called motifs that are repeated in
groups of protein or nucleic acid sequences is an
important and challenging problem in computational
biology. This dissertation formulates the sequence motif
discovery problem as a family of approximate common
substring (ACS) problems and presents an algorithm
(MEME) which solves them. The algorithm is based on
stochastic models of sequences and a Bayesian variant of
the expectation maximization (EM) algorithm.
MEME is unique among published motif discovery methods
in its consistent use of statistically-motivated
techniques to solve a wide variety of motif discovery
problems. MEME motifs characterize membership in a group
of sequences, and may split the group into subfamilies
or reveal repeated subsequences within individual
sequences in the group. The statistical nature of MEME
allows background information from the problem domain to
be translated into a Bayesian prior distribution or into
model constraints, and used to improve the solution. A
novel modification to the EM algorithm allows multiple
motifs to be found, and a novel heuristic function based
on the maximum likelihood ratio test (LRT) performs well
at optimizing the width of motifs. A technique for
mining the dataset for starting points for EM reduces
the problem of local optima.
The results of extensive experiments on over 80
difficult protein and DNA datasets and a case study
conducted in conjunction with a biologist show that MEME
attains its goals. (1) MEME selectively and sensitively
discovers biologically relevant motifs in groups of
related DNA or protein sequences. (2) The motifs shed
light on the structure and functions of different
portions of the molecules represented in the group of
sequences and reveal relationships among them. (3) The
motifs discovered by MEME have high recall, precision,
and receiver operating characteristic (ROC). They
correctly classify new sequences as belonging or not to
the same family as those from which the motif was
discovered. (4) The biological relevance and
classification performance of the motifs found by MEME
is on a par with that of human experts and with that of
other motif-finding algorithms which use more ad hoc
approaches or require more background information than
MEME. The success of MEME at solving the protein and DNA
sequence motif discovery problem makes it likely that we
can solve other ACS problems involving discrete-, real-,
or vector-valued sequences using similar techniques.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  3004 </NUMBER>
<ORDER>   AAI9615977 </ORDER>
<TITLE> AN INDUCTIVE APPROACH TO THE EXTRACTION OF ROADS FROM MULTISPECTRAL SATELLITE IMAGES </TITLE>
<AUTHOR> MARIN, JOHN ANTHONY </AUTHOR>
<YEAR> 1995 </YEAR>
<INSTITUTION> UNIVERSITY OF VIRGINIA; 0246 </INSTITUTION>
<DESCRIPTORS> ENGINEERING, SYSTEM SCIENCE; REMOTE SENSING; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> NIL </ADVISER>
<CLASSIFICATIONS> LEARNING VECTOR QUANTIZATION, NEURAL NETWORKS, IMAGE PROCESSING </CLASSIFICATIONS>
<ABSTRACT>
Extracting roads from satellite images is an important
problem with applications in both the military and
private sectors. Manually extracting roads is a time-
consuming and tedious task, requiring numerous man-hours
to process an image, and is usually limited to single-
dimensional data. This dissertation presents a two-step
inductive method for extracting rural roads in noisy,
multispectral, satellite images. The procedure is
referred to as inductive because the system infers the
general characteristics of a road from a set of training
examples.
In the first step, a neurally inspired classifier,
Learning Vector Quantization (LVQ), is employed to
initially classify image pixels. This first step
includes an original pixel allocation algorithm that
assigns pixels to training matrices and pre-positions a
set of reference vectors. Also, a modification to the
LVQ process is presented that accounts for patterns not
represented by exemplars in the training matrices.
The second step describes a process for tracking roads
in a binary image, such as the output from the LVQ
classification procedure. In the first phase of the
tracking process, a new noise reduction algorithm is
introduced and justified. In the second phase of the
tracking process, segments are traced and selected road
segments are linked using a potential function-guided
best-first search. This technique allows for the
assimilation of supporting information, as evidenced by
the inclusion of data from a Digital Elevation Model.
The system presented in this research differs from
existing systems in that it is based-on the spectral
properties of roads rather than locating edges in an
image, and is specifically designed for multidimensional
data. The system described here, unlike existing
approaches, represents a complete road extraction
procedure that goes from a satellite image to a traced
road. The system was tested on a SPOT satellite image of
Albemarle county, Virginia, and the results are
presented and discussed.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  3005 </NUMBER>
<ORDER>   AAI0576970 </ORDER>
<TITLE> COMPUTATION AND PSYCHOPHYSICS OF SENSORIMOTOR INTEGRATION  </TITLE>
<AUTHOR> GHAHRAMANI, ZOUBIN </AUTHOR>
<YEAR> 1995 </YEAR>
<INSTITUTION> MASSACHUSETTS INSTITUTE OF TECHNOLOGY; 0753 </INSTITUTION>
<DESCRIPTORS> PSYCHOLOGY, EXPERIMENTAL; BIOLOGY, NEUROSCIENCE; COMPUTER SCIENCE; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> MICHAEL I. JORDAN; TOMASO POGGIO </ADVISER>
<CLASSIFICATIONS> CENTRAL NERVOUS SYSTEM, PROPRIOCEPTION </CLASSIFICATIONS>
<ABSTRACT>
All higher organisms are able to integrate information
from multiple sensory modalities and use this
information to select and guide movements. In order to
do this, the central nervous system (CNS) must solve two
problems: (1) Converting information from distinct
sensory representations into a common coordinate system,
and (2) integrating this information in a sensible way.
This dissertation proposes a computational framework,
based on statistics and information theory, to study
these two problems. The framework suggests explicit
models for both the coordinate transformation and
integration problems, which are tested through human
psychophysics.
The experiments in Chapter 2 suggest that: (1) Spatial
information from the visual and auditory systems is
integrated so as to minimize the variance in
localization. (2) When the relation between visual and
auditory space is artificially remapped, the spatial
pattern of auditory adaptation can be predicted from its
localization variance. These studies suggest that
multisensory integration and intersensory adaptation are
closely related through the principle of minimizing
localization variance. This principle is used to model
sensorimotor integration of proprioceptive and motor
signals during arm movements (Chapter 3). The temporal
propagation of errors in estimating the hand's state is
captured by the model, providing support for the
existence of an internal model in the CNS that simulates
the dynamic behavior of the arm.
The coordinate transformation problem is examined in the
visuomotor system, which mediates reaching to visually-
perceived objects (Chapter 4). The pattern of changes
induced by a local remapping of this transformation
suggests a representation based on units with large
functional receptive fields. Finally, the problem of
converting information from disparate sensory
representations into a common coordinate system is
addressed computationally (Chapter 5). An unsupervised
learning algorithm is proposed based on the principle of
maximizing mutual information between two topographic
maps. What results is an algorithm which develops
multiple, mutually-aligned topographic maps based purely
on correlations between the inputs to the different
sensory modalities. (Copies available exclusively from
MIT Libraries, Rm. 14-0551, Cambridge, MA 02139-4307.
Ph. 617-253-5668; Fax 617-253-1690.)
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  3006 </NUMBER>
<ORDER>   AAGMM11595 </ORDER>
<TITLE> LEARNING EXPLAINABLE CONCEPTS IN THE PRESENCE OF A QUALITATIVE MODEL </TITLE>
<AUTHOR> ROUGET, THIERRY </AUTHOR>
<YEAR> 1995 </YEAR>
<INSTITUTION> UNIVERSITY OF OTTAWA (CANADA); 0918 </INSTITUTION>
<DESCRIPTORS> COMPUTER SCIENCE; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> STAN MATWIN </ADVISER>
<CLASSIFICATIONS> NIL </CLASSIFICATIONS>
<ABSTRACT>
This thesis addresses the problem of learning concept
descriptions that are interpretable, or explainable.
Explainability is understood as the ability to justify
the learned concept in terms of the existing background
knowledge. The starting point for the work was an
existing system that would induce only fully explainable
rules. The system performed well when the model used
during induction was complete and correct. In practice,
however, models are likely to be imperfect, i.e.
incomplete and incorrect. We report here a new approach
that achieves explainability with imperfect models. The
basis of the system is the standard inductive search
driven by an accuracy-oriented heuristic, biased towards
rule explainability. The bias is abandoned when there is
heuristic evidence that a significant loss of accuracy
results from constraining the search to explainable
rules only. The users can express their relative
preference for accuracy vs. explainability. Experiments
with the system indicate that, even with a partially
incomplete and/or incorrect model, insisting on
explainability results in only a small loss of accuracy.
We also show how the new approach described can repair a
faulty model using evidence derived from data during
induction.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  3007 </NUMBER>
<ORDER>   AAI0576968 </ORDER>
<TITLE> ADAPTIVE MOTOR CONTROL USING PREDICTIVE NEURAL NETWORKS </TITLE>
<AUTHOR> FUN, WEY </AUTHOR>
<YEAR> 1995 </YEAR>
<INSTITUTION> MASSACHUSETTS INSTITUTE OF TECHNOLOGY; 0753 </INSTITUTION>
<DESCRIPTORS> ENGINEERING, BIOMEDICAL; BIOLOGY, NEUROSCIENCE; BIOPHYSICS, GENERAL; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> MICHAEL I. JORDAN </ADVISER>
<CLASSIFICATIONS> NIL </CLASSIFICATIONS>
<ABSTRACT>
This thesis investigates the applicability of the
forward modeling approach in adaptive motor control. The
forward modeling approach advocates that in order to
achieve effective motor control, the controller must
first be able to predict the outcomes of its actions
with an internal model of the system, which can be used
in the search for the appropriate actions to achieve
particular desired movement goals. In relistic control
problems, however, the acquisition of a perfect internal
dynamical model is not generally feasible. This thesis
shows how an approximate forward model, obtained via a
simple on-line adaptation algorithm and an on-line
action-search process, is able to provide effective
reaching movement control of a simulated three-
dimensional, four-degree-of-freedom arm.
In the course of studying the on-line action search
process, a problem which we refer to as the "control
boundary problem" was identified. This problem was found
to occur frequently and was found to be detrimental to
the gradient-based search method. We developed a novel
technique for solving the problem, referred to as the
"moving-basin approach." The moving basin approach leads
the system to the desired goal by adaptively creating
subgoals. Results are reported that show the improvement
in the action-search process using the moving basin
method.
Once the control boundary problem is solved, the forward
modeling approach is able to provide stable adaptive
control under perturbations of various forms and
magnitudes, including those that could not be handled by
analytical adaptive control methods. Further
investigation also revealed that changes within the
parameters of a forward model can provide information
about the perturbed dynamics. (Copies available
exclusively from MIT Libraries, Rm. 14-0551, Cambridge,
MA 02139-4307. Ph. 617-253-5668; Fax 617-253-1690.)
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  3008 </NUMBER>
<ORDER>   AAINN05774 </ORDER>
<TITLE> IMPROVED PROCESSING AND CLASSIFICATION TECHNIQUES FOR INFANT CRY VOCALIZATIONS </TITLE>
<AUTHOR> PETRONI, MARCO </AUTHOR>
<YEAR> 1995 </YEAR>
<INSTITUTION> MCGILL UNIVERSITY (CANADA); 0781 </INSTITUTION>
<DESCRIPTORS> ENGINEERING, ELECTRONICS AND ELECTRICAL; PSYCHOLOGY, DEVELOPMENTAL; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> ALFRED S. MALOWANY </ADVISER>
<CLASSIFICATIONS> COMMUNICATION, NEURAL NETWORKS </CLASSIFICATIONS>
<ABSTRACT>
Advances in cry research and understanding have been
limited due to the lack of available analysis and
classification methods which can adequately deal with
the particulars of this simple, yet effective,
communication medium. This thesis presents a new
processing and classification methods for infant cry
signals. First, a new method of accurately extracting
the vocal fundamental frequency from cry signals is
proposed. This multi-step crosscorrelation vector-based
method accurately tracks rapid changes in the
fundamental frequency in these utterances, is not
limited to any particular range of pitch values, and
allows a more detailed view of this important parameter
for further analysis. The benefits of this method are
not limited to infant cry vocalizations, however. This
new method can be employed by any application that
requires accurate and detailed pitch extraction, as well
as being suitable for pitch synchronous analysis of a
voiced signal. Then, a novel application of artificial
neural networks is presented: the automatic
classification of anger, fear, and pain cries. A
comparison of five different input data sets derived
from two different parametric representations, applied
to four different neural network architectures is
presented. From the classification rates obtained, the
use of artificial neural networks would seem well suited
to the classification of these types of infant cries and
warrants future investigations. Some future work is
outlined prior to the concluding remarks outlining the
contributions of this dissertation.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  3009 </NUMBER>
<ORDER>   AAINN05766 </ORDER>
<TITLE> A NEW APPROACH TO THE AUTOMATIC ROBOT ACTION PLANNING PROBLEM  </TITLE>
<AUTHOR> NOORHOSSEINI, SEYED MAJID </AUTHOR>
<YEAR> 1995 </YEAR>
<INSTITUTION> MCGILL UNIVERSITY (CANADA); 0781 </INSTITUTION>
<DESCRIPTORS> ENGINEERING, ELECTRONICS AND ELECTRICAL; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> ALFRED MALOWANG </ADVISER>
<CLASSIFICATIONS> INTELLIGENT MACHINES </CLASSIFICATIONS>
<ABSTRACT>
Action planning ability is essential for autonomous
behavior of an intelligent machine. In the robotics
domain, planning occurs at different levels of a robotic
system; this research targets the problem of planning at
the highest level of the hierarchy which is planning a
course of actions to accomplish a task. Planning at this
level is extremely complex due to the many combinatorial
problems that must be solved before a real world plan
can be formulated. Two major approaches have been
adopted by the researchers: domain independent
approaches and application dependent approaches. We
believe that a completely domain independent planner is
not feasible and an application dependent planner is too
restrictive. This research effort focuses on developing
a planning system which combines that advantages of the
two approaches. We have outline a clear boundary between
the domain independent and domain dependent modules of
the planner and developed a framework for proper
interaction of the two. A new representation scheme
which used the inter-relationships of objects to model
the world is proposed. Two classes of non-linear
planning problems, monotone planning problems and non-
monotone planning problems are identified and new
generic algorithms are proposed to solve these problems.
These algorithms, which are based on our new
representation scheme, are sound and complete and embody
a mechanism for incorporation of the domain knowledge in
an algorithmic fashion. Based on these theoretical
developments, a planning system is implemented which
includes an expert system to find the task constraints,
a graphic user interface and a simple workcell simulator
for execution and verification of the generated plan.
The robotic assembly domain is chosen as an application
domain and the planning system is tested on variety of
assembly examples.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  3010 </NUMBER>
<ORDER>   AAINN05078 </ORDER>
<TITLE> DEVELOPMENT OF A HYBRID KNOWLEDGE-BASED SYSTEM FOR CONDITION MONITORING AND DIAGNOSIS OF ROTATING MACHINERY </TITLE>
<AUTHOR> ZHANG, SIYU </AUTHOR>
<YEAR> 1995 </YEAR>
<INSTITUTION> CONCORDIA UNIVERSITY (CANADA); 0228 </INSTITUTION>
<DESCRIPTORS> ENGINEERING, MECHANICAL; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> S. V. HOA; G. D. XISTRIS; R. GANESAN </ADVISER>
<CLASSIFICATIONS> ARTIFICIAL INTELLIGENCE </CLASSIFICATIONS>
<ABSTRACT>
A new approach to hybrid knowledge-based systems (KBSs)
for rotating machinery monitoring and diagnostics is
developed, incorporating the latest developments in AI
techniques and expert systems technology. This approach
employs the vibration signature as the diagnostic
signal, and neural networks are used to perform
numerical processing of diagnostic data to enable
condition identification and classification of fault
patterns, and the quantification of fault or malfunction
development. Neural network solutions to the above two
problems, particularly the solutions using Self-
Organizing Maps (SOM) are sought and obtained. For
trending and quantifying fault development, a method
which employs multiple-index based trend analysis is
proposed and implemented. To address this problem, an
appropriate Self-Organizing Mapping algorithm is
developed from first principles.
A prototype expert system, designated RMD-KBS (Rotating
Machinery Diagnostic Knowledge-Based System), is
designed and fully developed. This is an on-line
diagnostic system in which both the symbolic and
numerical processing are deeply coupled. The "Object-
Oriented Programming (OOP) technique" is employed in
such a way that its computational advantages are
exploited in RMD-KBS. In addition, the RMD-KRS is
designed and developed with the ability to possess a
number of the most desired computational and functional
capabilities of a diagnostic KBS for industrial
applications. In order to validate the RMD-KBS
diagnostic expert system and to assess its performance,
experimental data from a class of real-life industrial
machine systems have been collected. Comparison of the
diagnostic results provided by the RMD-KBS with the
faults known to be present, established the efficiency,
accuracy and superiority of the proposed prototype
system.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  3011 </NUMBER>
<ORDER>   AAI9618406 </ORDER>
<TITLE> FUZZINESS, UTILITY, AND DECISION-MAKING: A SPECIAL APPLICATION TO THE NEWSBOY PROBLEM </TITLE>
<AUTHOR> LI, JING </AUTHOR>
<YEAR> 1995 </YEAR>
<INSTITUTION> OKLAHOMA STATE UNIVERSITY; 0664 </INSTITUTION>
<DESCRIPTORS> BUSINESS ADMINISTRATION, MANAGEMENT; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> HON-SHIANG LAU </ADVISER>
<CLASSIFICATIONS> NIL </CLASSIFICATIONS>
<ABSTRACT>
Scope and method of study. This dissertation examines
the newsboy problem in the fuzzy environment where human
judgment is involved in the process of decision making.
Fuzzy set theory was applied to the single-period
inventory model for dealing with the inherent fuzziness
existing in the subjective measurement of the decision
makers' utilities. The newsboy's utility on profit was
modeled with L-R type fuzzy functions. The computation
of expected fuzzy utility was based on the theory of
sheaf and expectation of fuzzy numbers, the operation
rules of L-R fuzzy numbers and the rule of integration
of L-R fuzzy functions. Liou and Wang's approach was
used to rank the expected fuzzy utilities.
Findings and conclusions. The L-R fuzzy utility function
provides an appropriate approach for handling the
fuzziness existing in the subjective determination of
the decision makers' utilities. The form of the mean
value functions reflects the individuals' attitudes to
risk; the spread functions and the reference functions
effectively account for the fuzziness existing in
measuring the individuals' utilities. The optimal
solutions of the newsboy problem strongly depend on the
forms of the mean value function and the spread
functions. The larger the index of risk aversion of the
mean value function is, the smaller the optimal order
quantity will be. The spread functions are the main
factors that cause the resultant optimal order quantity
to deviate from those derived with the corresponding
classical utility functions. The degree of deviation
also depends on the relationships between the left and
right spread functions; and between the mean value
function and the spread functions. The form of the
utility functions strongly affects the behavior of the
newsboy problems' solutions; ignoring the fuzziness
existing in utilities may lead to inferior solutions.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  3012 </NUMBER>
<ORDER>   AAI9617352 </ORDER>
<TITLE> FAULT DIAGNOSIS AND CONTROL OF A THERMAL POWER PLANT </TITLE>
<AUTHOR> SREEDHAR, RAJIV </AUTHOR>
<YEAR> 1995 </YEAR>
<INSTITUTION> THE UNIVERSITY OF TEXAS AT AUSTIN; 0227 </INSTITUTION>
<DESCRIPTORS> ENGINEERING, MECHANICAL; ENGINEERING, ELECTRONICS AND ELECTRICAL; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> BENITO FERNANDEZ R.; GLENN Y. MASADA </ADVISER>
<CLASSIFICATIONS> NEURAL NETWORKS, ARTIFICIAL INTELLIGENCE </CLASSIFICATIONS>
<ABSTRACT>
The pressing need to improve efficiency, reliability and
safety of power plants has resulted in constant effort
to upgrade plant systems. The operation of a thermal
power plant involves a large throughput of fuel and
energy, thus even a small increase in efficiency can
result in significant savings. The high pressures and
temperatures involved in thermal power plant operation
can result in significant damage to property and loss of
life in the event of a system failure. The analog
control systems which control a majority of the thermal
power plants are constantly being replaced by more
sophisticated digital distributed control systems. The
introduction of modern digital distributed control
systems in thermal power plants has facilitated the
implementation of complex control and online fault
diagnosis algorithms. The design of an online fault
diagnosis system and a multivariable sliding mode
control system for a thermal power plant is presented in
this dissertation. The performance of the fault
diagnosis system and the control system was tested by
simulating faults in a 21$sp0st$ order physically based,
lumped parameter model of a 235 MW gas fired thermal
power plant. The model represents the steady state and
transient characteristics of Clifford B. Jones Unit #2
power plant operated by Southwestern Public Services
Company in Lubbock, Texas.
The fault diagnosis system is based on a neural network
augmented observer and provides robust fault diagnosis
even in presence of modeling errors and unmodeled
dynamics. A novel technique using a sliding mode
observer to characterize the modeling errors and
facilitate the training of the neural network is
presented. The accurate continuous time model of the
system dynamics resulting from this approach is used for
model based fault diagnosis. This model can also be used
for system simulation and control. The online fault
diagnosis system focuses on diagnosing process faults in
the water/steam-side of the thermal power plant. The
faults simulated in the power plant model were
water/steam-side fouling, fire-side fouling, tube leaks,
boiler feedpump failure, and a change in the calorific
value of the fuel. The neural network augmented observer
based fault diagnosis scheme was successful in
diagnosing faults in the water/steam-side of the thermal
power plant.
The existing multiloop PID control system for the
water/steam-side of the power plant is difficult to tune
and provides marginal robustness to system faults. The
PID control system for the water-steam side of the
thermal power plant consists of six loops, controlling
the boiler drum level, main steam pressure, superheat
temperature, reheat temperature (using spray and burner
tilt), and megawatt output. The six PID loops were
replaced by a multivariable sliding mode control system.
The sliding mode control system was easier to tune and
reduced the deviations of the process operating
parameters from the setpoints. The inherent robustness
of the sliding mode controller also provided improved
stability margins and facilitated stable operation in
the presence of system faults.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  3013 </NUMBER>
<ORDER>   AAI9617343 </ORDER>
<TITLE> A SELF-ORGANIZING NEURAL NETWORK MODEL OF THE PRIMARY VISUAL CORTEX </TITLE>
<AUTHOR> SIROSH, JOSEPH </AUTHOR>
<YEAR> 1995 </YEAR>
<INSTITUTION> THE UNIVERSITY OF TEXAS AT AUSTIN; 0227 </INSTITUTION>
<DESCRIPTORS> COMPUTER SCIENCE; BIOLOGY, NEUROSCIENCE; ENGINEERING, BIOMEDICAL; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> RISTO MIIKKULAINEN </ADVISER>
<CLASSIFICATIONS> NIL </CLASSIFICATIONS>
<ABSTRACT>
This work is aimed at modeling and analyzing the
computational processes by which sensory information is
learned and represented in the brain. First, a general
self-organizing neural network architecture that forms
efficient representations of visual inputs is presented.
Two kinds of visual knowledge is stored in the cortical
network: information about the principal feature
dimensions of the visual world (such as line orientation
and ocularity) is stored in the afferent connections,
and correlations between these features in the lateral
connections. During visual processing, the cortical
network filters out these correlations, generating a
redundancy-reduced sparse coding of the visual input.
Through massively parallel computational simulations,
this architecture is shown to give rise to structures
similar to those in the primary visual cortex, such as
(1) receptive fields, (2) topographic maps, (3) ocular
dominance, orientation and size preference columns, and
(4) patterned lateral connections between neurons. The
same computational process is shown to account for many
of the dynamic processes in the visual cortex, such as
reorganization following retinal and cortical lesions,
and perceptual shifts following dynamic receptive field
changes. These results suggest that a single self-
organizing process underlies development, plasticity and
visual functions in the primary visual cortex.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  3014 </NUMBER>
<ORDER>   AAI9615907 </ORDER>
<TITLE> A MODEL-BASED ARCHITECTURE FOR EXPLAINING UNCERTAIN DATA </TITLE>
<AUTHOR> TSAO, JUNGFU </AUTHOR>
<YEAR> 1995 </YEAR>
<INSTITUTION> TEXAS A&M UNIVERSITY; 0803 </INSTITUTION>
<DESCRIPTORS> COMPUTER SCIENCE; ENGINEERING, PETROLEUM; ENGINEERING, MARINE; ARTIFICIAL INTELLIGENCE; ENVIRONMENTAL SCIENCES </DESCRIPTORS>
<ADVISER> JAN D. WOLTER </ADVISER>
<CLASSIFICATIONS> OIL SPILLS, ARTIFICIAL INTELLIGENCE </CLASSIFICATIONS>
<ABSTRACT>
Marine oil spills, such as the one resulting from the
wreckage of the Exxon Valdez in 1989, are a source of
major ecological and economical disruption. When such an
incident occurs, rapid response is of critical
importance to contain the spilled oil, since the actions
taken in the first eight hours of the incident often
determine the success or failure of the response. Thus,
decision makers are often forced to respond to the oil
spills before a clear understanding of the situation can
be obtained. This dissertation contributes to the
development of computational tools to support such
decision-making problems.
An oil spill model is one such tool. The input of the
model consists of the location of oil spill source, the
type and original volume of oil spilled, the
temperature, and the wind and current vectors at each
location for each time step. The model generates the
state of the oil, which is the oil distribution, for
each next time step. Given an initial state of the oil,
we can apply to the model the inputs at different times
iteratively to predict the oil's future state. Data on
the state of the oil and the inputs at different times
is provided by observers, and may have large
uncertainties associated with them. Before decision
makers can use the model to predict the future state of
the oil, they must find inputs that agree with the
observations and cause the model to match the past
behavior of the spill. We wish to automate this problem
solving process.
In this dissertation, a model-based architecture is
proposed to explain uncertain observations in oil spill
tracking. Explanation of uncertain observations for each
time step goes through an iterative process of two
phases. The two phases are implemented by two modules:
error detection and fix generation. The error detection
module looks for inconsistencies between the modeled and
observed oil distributions. The fix generation module
removes the inconsistencies by adjusting the input of
the model in order to match the modeled oil distribution
with the observed oil distribution. When an
inconsistency can not be removed for some time step
alone, the fix generation module backtracks in time such
that the inputs in the previous time steps are
readjusted in order for the inconsistency for that time
step to be removed. Fuzzy logic techniques are employed
to deal with the uncertainty in the observations. The
validity of the architecture is successfully
demonstrated through implementation.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  3015 </NUMBER>
<ORDER>   AAI9615842 </ORDER>
<TITLE> AN INTELLIGENT SYSTEM FOR ACTIVE VIBRATION CONTROL </TITLE>
<AUTHOR> MANCHALA, DANIEL W. </AUTHOR>
<YEAR> 1995 </YEAR>
<INSTITUTION> TEXAS A&M UNIVERSITY; 0803 </INSTITUTION>
<DESCRIPTORS> COMPUTER SCIENCE; ENGINEERING, MECHANICAL; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> DICK B. SIMMONS </ADVISER>
<CLASSIFICATIONS> ROTOR BALANCING, ARTIFICIAL INTELLIGENCE </CLASSIFICATIONS>
<ABSTRACT>
An intelligent system useful for the active vibration
control of rotating machinery is presented through this
research. The intelligent system is built using an
expert system with inexact reasoning and control of the
rotating system is achieved by using feedback and
feedforward control hardware. Diagnostics through data
acquisition is done by using fast Fourier transforms,
time sample analysis, and voltage controlled
oscillators. Such a system could be used in the real-
time detection and correction of several rotordynamic
anomalies like blade loss to an aircraft caught in
battle zones, bird ingestion by airplanes, rotor rub,
bearing cracks, etc.
Jet Engines may experience severe vibration due to the
sudden imbalance caused by blade failure. Active
Vibration Control (AVC) techniques are used to suppress
the sudden increase of vibrations. Identification of the
source of the vibrations via an expert system,
determination of the required phase angles and
amplitudes for the correction forces, and application of
the desired control signals to the piezo electric
actuators are the steps involved to correct this form of
anomaly. Correction forces may exceed the physical
limitations of the actuators, hence results of
"constrained force" quadratic programming, least squares
and multi-point correction algorithms will be compared.
It is demonstrated that simply scaling down the least
squares predicted correction forces to satisfy the
actuator saturation constraints does not necessarily
yield optimal reductions in vibration. Test results for
sudden imbalance and comparison of the computational
time requirements and balancing effectiveness of the
various approaches are shown through this research.
An expert system distinguishes the various rotordynamic
anomalies and issues correction signals to correct these
anomalies. In case of bearing failure, a frequency sweep
test is performed to confirm its presence. A hybrid
analog digital controller is used to change the
stiffness to correct this anomaly. In case of rotor rub,
a direct current displacement is used for correction.
Sudden impact, rotor rub, and blade loss have similar
frequency spectrum responses. The expert system is used
to distinguish among these anomalies. Test results for
diagnosing and correcting these anomalies are shown in
the dissertation.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  3016 </NUMBER>
<ORDER>   AAI9615832 </ORDER>
<TITLE> FUZZY LOGIC BASED INCIDENT DETECTION FOR PAIRED INTERSECTIONS </TITLE>
<AUTHOR> LEE, SIBOK </AUTHOR>
<YEAR> 1995 </YEAR>
<INSTITUTION> TEXAS A&M UNIVERSITY; 0803 </INSTITUTION>
<DESCRIPTORS> ENGINEERING, CIVIL; ARTIFICIAL INTELLIGENCE; TRANSPORTATION </DESCRIPTORS>
<ADVISER> RAYMOND A. KRAMMES </ADVISER>
<CLASSIFICATIONS> NIL </CLASSIFICATIONS>
<ABSTRACT>
This dissertation documents the development of a fuzzy
logic based incident detection model for paired
intersections. Research in incident detection for
intersections and arterials is at a very initial stage.
Existing algorithms are still far from being robust in
dealing with the difficulties related with data
availability and the multi-dimensional nature of the
incident detection problem. The purpose of this study is
to develop a new real-time incident detection model for
urban diamond interchanges. The development of the
algorithm is based on fuzzy logic. The incident
detection model developed through this research is
capable of detecting lane-blocking incidents when their
effects are manifested by certain patterns of
deterioration in traffic conditions and, thereby,
adjustments in signal control strategies are required.
The model overcomes the boundary condition problem
inherent in conventional threshold-based concepts. The
model captures system-wide incident effects utilizing
multiple measures for more accurate and reliable
detection, and serves as a component module of a real-
time traffic adaptive diamond interchange control
system. The model is designed to be readily scalable and
expandable for larger systems of arterial streets. The
incident detection model is illustrated using a sample
case. The prototype incident detection model was applied
to an actual diamond interchange to investigate its
performance. A simulation study was performed to
evaluate the model's performance in terms of detection
rate, false alarm rate, and mean time to detect. The
model's performance was encouraging, and the fuzzy logic
based approach to incident detection is promising.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  3017 </NUMBER>
<ORDER>   AAGMM11565 </ORDER>
<TITLE> THE TEXT ANALYZER: A TOOL FOR KNOWLEDGE ACQUISITION FROM TEXTS </TITLE>
<AUTHOR> KAVANAGH, JUDITH </AUTHOR>
<YEAR> 1995 </YEAR>
<INSTITUTION> UNIVERSITY OF OTTAWA (CANADA); 0918 </INSTITUTION>
<DESCRIPTORS> COMPUTER SCIENCE; INFORMATION SCIENCE; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> DOUGLAS SKUCE </ADVISER>
<CLASSIFICATIONS> NIL </CLASSIFICATIONS>
<ABSTRACT>
The world is being inundated with knowledge at an ever-
increasing rate. As intelligent beings and users of
knowledge, we must find new ways to locate particular
items of information in this huge reservoir of knowledge
or we will soon be overwhelmed with enormous quantities
of documents that no one any longer has time to read.
The vast majority of knowledge is still being stored in
conventional text written in natural language, such as
books and articles, rather than in more "advanced" forms
like knowledge bases. With more and more of these texts
being stored on-line rather than solely in print, an
opportunity exists to make use of the power of the
computer to aid in the location and analysis of
knowledge in on-line texts.
We propose a tool to do this--the Text Analyzer. We have
combined methods from computational linguistics and
artificial intelligence to provide the users of the Text
Analyzer with a variety of options for finding
information in documents, verifying the consistency of
this information, performing word and conceptual
analyses and other operations. Parsing and indexing are
not used in the Text Analyzer. The Text Analyzer can be
connected to CODE4, a knowledge management system, so
that a knowledge base can be constructed as knowledge is
found in the text. We believe this tool will be
especially useful for linguists, knowledge engineers,
and document specialists.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  3018 </NUMBER>
<ORDER>   AAI9615574 </ORDER>
<TITLE> IDENTIFICATION AND CONTROL OF NONLINEAR DYNAMICAL SYSTEMS USING MULTILAYER FEEDFORWARD NEURAL NETWORKS AND AUTOREGRESSIVE MOVING AVERAGE MODELS </TITLE>
<AUTHOR> AL-DUWAISH, HUSSAIN NASER </AUTHOR>
<YEAR> 1995 </YEAR>
<INSTITUTION> COLORADO STATE UNIVERSITY; 0053 </INSTITUTION>
<DESCRIPTORS> ENGINEERING, ELECTRONICS AND ELECTRICAL; ENGINEERING, SYSTEM SCIENCE; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> NIL </ADVISER>
<CLASSIFICATIONS> ARTIFICIAL INTELLIGENCE </CLASSIFICATIONS>
<ABSTRACT>
This research investigated the application of a hybrid
model of multilayer feedforward neural network (MFNN)
and autoregressive moving average (ARMA) linear model in
the identification of dynamical nonlinear systems. The
hybrid model consists of a MFNN in series with an ARMA
model. The MFNN is used to model the nonlinearities in
the process and the ARMA model is to capture the
temporal information associated with the dynamic
process. To estimate the weights of the MFNN and the
parameters of the ARMA model, a recursive identification
algorithm has been developed. Generalization of the
proposed identification method has been done for the
general multi-input multi output (MIMO) systems.
Control of the MFNN/ARMA model can be achieved using the
linear control theory by designing a linear controller
for the ARMA linear model and inserting the inverse of
the nonlinearities modeled by the MFNN in the
appropriate control loop locations. Issues related to
noninvertible nonlinearities has been discussed and a
method has been proposed.
The second part of the research focuses on the
identification and control of linear systems with static
nonlinearities. The systems considered in this research
are: the Hammerstein model, MIMO linear systems with
static input nonlinearities, the Wiener model, MIMO
linear systems with static output nonlinearities, and
the General model. The main contributions in this part
can be summarized in the following points: (1) The
MFNN/ARMA model has been used to identify the
Hammerstein model. (2) The application of the MIMO
MFNN/ARMA identification method to the identification of
MIMO systems with static input nonlinearities. (3) A new
model for the identification of the Wiener system has
been proposed. The proposed model consists of an ARMA
model in series with a MFNN. A two step procedure has
been proposed for the identification of the Wiener
model. (4) A general MIMO model for linear systems with
static output nonlinearities was proposed. A two step
identification procedure has been developed. (5) The
static nonlinearity and the second linear part of the
General model have been identified using the MFNN/ARMA
identification method.
Many simulation examples have been used to study the
convergence and robustness properties of the RLS/BP
algorithm. Real data from laboratory scale processes
have been used to demonstrate the effectiveness of the
proposed identification methods.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  3019 </NUMBER>
<ORDER>   AAI9615419 </ORDER>
<TITLE> INTEGRATED INTELLIGENCES IN A FUZZY SYSTEMS FRAMEWORK </TITLE>
<AUTHOR> PENMETCHA, KRISHNAMRAJU V. </AUTHOR>
<YEAR> 1995 </YEAR>
<INSTITUTION> UNIVERSITY OF ALABAMA AT BIRMINGHAM; 0005 </INSTITUTION>
<DESCRIPTORS> COMPUTER SCIENCE; INFORMATION SCIENCE; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> KEVIN D. REILLY REILLY, KEVIN D. </ADVISER>
<CLASSIFICATIONS> ARTIFICIAL INTELLIGENCE, NEURAL NETWORKS </CLASSIFICATIONS>
<ABSTRACT>
In this dissertation we address the problem area of
intelligent hybrid systems integrating artificial neural
networks, rule-based knowledge, and fuzzy logic
paradigms. Combining such computational paradigms
provides synergistic benefits and potentially expands
the application domain for intelligent systems. Our
initial step is a proposed architecture which provides a
framework for hybrid system integration. We use it to
help identify basic problems in integrating expert
systems and neural nets (NN). The first problem we
address is mapping fuzzy rule-based knowledge, in a
fuzzy expert system (FES), into a neural architecture
that preserves functionality and even enhances it. The
reverse problem, generating fuzzy rules from a trained
neural net is addressed as a second principal problem,
in terms of algorithmically transforming a feedforward
net into a set of fuzzy rules. Test results for these
two problems (FES $to$ NN and NN $to$ FES) show that the
neural networks we generate are able to model a fuzzy
rule-base and, vice versa, that the fuzzy rules
generated by the neural network can perform operations
required of an expert system. Our third and final
problem explicitly incorporates fuzziness (fuzzy signals
and weights) into the neural network portion of the
architecture. Proposed fuzzy neural networks with
backpropagation and/or genetic-based learning system is
used on problems which map a fuzzy or real input to a
fuzzy or real output based on interval arithmetic
operations. Experimental results demonstrating
characteristics of various linear and non-linear
mappings are discussed. Remaining questions within a
hybrid system include matters of integration, use, and
impacts, particularly of fuzziness, on the hybrid
systems architecture itself.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  3020 </NUMBER>
<ORDER>   AAI9615110 </ORDER>
<TITLE> A SEMANTICS OF CONTRAST AND INFORMATION STRUCTURE FOR SPECIFYING INTONATION IN SPOKEN LANGUAGE GENERATION </TITLE>
<AUTHOR> PREVOST, SCOTT ALLAN </AUTHOR>
<YEAR> 1995 </YEAR>
<INSTITUTION> UNIVERSITY OF PENNSYLVANIA; 0175 </INSTITUTION>
<DESCRIPTORS> COMPUTER SCIENCE; LANGUAGE, LINGUISTICS; SPEECH COMMUNICATION; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> MARK STEEDMAN </ADVISER>
<CLASSIFICATIONS> ARTIFICIAL INTELLIGENCE </CLASSIFICATIONS>
<ABSTRACT>
In this dissertation I present a model for the
determination of intonation contours from context and
provide two implemented systems which apply this theory
to the problem of generating spoken language with
appropriate intonation from high-level semantic
representations. The theory and implementations
presented here are based on an information structure
framework that mediates between intonation and
discourse, and encodes the proper level of semantic
information to account for both contextually-bound
accentuation patterns and intonational phrasing. The
structural similarities among these linguistic levels of
representation are the basis for selecting Combinatory
Categorial Grammar (CCG, Steedman 1985, 1990a) as the
model for spoken language production. This model
licenses congruent syntactic, prosodic and information
structural constituents and consequently represents a
simplification over models of prosody developed in
syntactically more traditional frameworks.
The previous mention heuristic, which has been widely
used as a model for determining intonation contours, is
shown to be inadequate for handling a broad range of
examples involving semantic contrasts, which require
pitch accents to be allocated based on their ability to
discriminate among available entities in the discourse
model. To address this problem, I introduce a model that
determines accentual patterns based on sets of
alternative entities in the knowledge base. The
algorithms for building the information structural
representations that encode the semantics of intonation
supply the foundation for two computational
implementations. These implementations demonstrate how
the theoretical model applies to the problem of
producing contextually-appropriate spoken output in a
natural language generation framework and provide a
platform for incrementally testing and refining the
underlying theory.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  3021 </NUMBER>
<ORDER>   AAI9615023 </ORDER>
<TITLE> RADIAL BASIS FUNCTION NETWORKS FOR NONLINEAR SIGNAL PROCESSING  </TITLE>
<AUTHOR> CHA, INHYOK </AUTHOR>
<YEAR> 1995 </YEAR>
<INSTITUTION> UNIVERSITY OF PENNSYLVANIA; 0175 </INSTITUTION>
<DESCRIPTORS> ENGINEERING, ELECTRONICS AND ELECTRICAL; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> NIL </ADVISER>
<CLASSIFICATIONS> NEURAL NETWORKS </CLASSIFICATIONS>
<ABSTRACT>
In many signal processing problems linear techniques
give only sub-optimal results, due to non-linearity in
signal models and systems. Consequently, much research
has been directed in the search for alternative tools
for signal processing. Neural networks, due to their non-
linear capabilities, provide one such alternative.
Recently, a neural net commonly called the radial basis
function network (RBFN) has attracted a lot of research
because it has been found to provide a number of
important advantages over multi-layer sigmoidal
networks. This dissertation deals with two aspects of
the RBFN as a nonlinear signal processing tool.
The first part of the dissertation investigates the RBFN
with respect to its structural characterization and
learning algorithms. After a general introduction of the
RBFN structure and learning algorithms, we present a
gradient-based training algorithm called the Stochastic-
Gradient (SG) algorithm and discuss its characteristics.
Secondly, we discuss extensions of the basic RBFN
structure that enhance the capability of the RBFN. Here,
we focus on the so-called normalized RBFNs. First, we
discuss their functional characteristics. Then, a
normalized RBFN structure based on a mixture-of-Gaussian
probabilistic data model is presented and its aspects as
a signal processing tool are investigated.
The second part of the dissertation deals with
application of the RBFN in signal processing problems.
In Chapter 3, a complex extension of the RBFN is defined
and applied in symbol-by-symbol equalization of complex-
valued communication channels. In Chapter 4, the problem
of interference cancellation is investigated from a
signal estimation viewpoint. There, we discuss a result
which, in summary, says that a class of RBFNs can be
optimal as interference cancelers under a special class
of signal models. Finally, application of the RBFN in a
few other problems, namely, time-series prediction,
blind channel equalization, nonlinear filtering and
image processing, are investigated in Chapter 5. In
these applications, we observe that the RBFN and its
extensions provide superior alternatives to not only the
traditional linear processors but also some of the more
novel techniques based on, for example, multilayer
neural networks.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  3022 </NUMBER>
<ORDER>   AAI9615014 </ORDER>
<TITLE> COGNIAC: A DISCOURSE PROCESSING ENGINE </TITLE>
<AUTHOR> BALDWIN, FREDERICK BRECKENRIDGE </AUTHOR>
<YEAR> 1995 </YEAR>
<INSTITUTION> UNIVERSITY OF PENNSYLVANIA; 0175 </INSTITUTION>
<DESCRIPTORS> COMPUTER SCIENCE; LANGUAGE, LINGUISTICS; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> ARAVIND JOSHI </ADVISER>
<CLASSIFICATIONS> ANAPHORS </CLASSIFICATIONS>
<ABSTRACT>
In spoken and written language, anaphora occurs when one
phrase points to another, where "points to" means that
the two phrases denote the same thing in one's mind, as
in the relationship between GREGOR SAMSA and he in the
following: As GREGOR SAMSA awoke one morning from uneasy
dreams he found himself transformed in his bed into a
gigantic insect. Kafka, The Metamorphosis.(DIAGRAM,
TABLE OR GRAPHIC OMITTED...PLEASE SEE DAI)Much of the
difficulty of developing a computer program to resolve
anaphors amounts to picking the right antecedent when
there are many to choose from.
The dissertation describes an approach that is
particularly suitable for applications that require
large coverage and high accuracy. These results are
achieved by endowing the system with the ability to
notice that it cannot make a good choice in certain
circumstances, coupled with simple and efficient
language technologies to structure the prior discourse.
The significant features of the system, named CogNIAC,
include: (1) CogNIAC classifies anaphors into ones that
it can resolve with high precision and those it cannot
resolve with high precision via a uniqueness based
search mechanism. (2) Automatic recognition of noun
phrases as anaphors. (3) Declarative representation of
salience. (4) CogNIAC is fully implemented in Perl 4.
(5) CogNIAC uses simple language technologies like part-
of-speech tagging, basal noun phrase detection and
finite clause identification to support the anaphora
resolution process. (6) CogNIAC performs quite well
either as a high precision system or as a high recall
system. Performance results are given for a variety of
domains and configurations ranging from narrative texts
to Wall Street Journal articles.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  3023 </NUMBER>
<ORDER>   AAI9614826 </ORDER>
<TITLE> AN ASSISTANT FOR PERCEPTUAL TASKS USING EXEMPLAR-BASED LEARNING </TITLE>
<AUTHOR> REED, DALE FRANKLIN </AUTHOR>
<YEAR> 1995 </YEAR>
<INSTITUTION> NORTHWESTERN UNIVERSITY; 0163 </INSTITUTION>
<DESCRIPTORS> COMPUTER SCIENCE; MUSIC; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> LAWRENCE HENSCHEN </ADVISER>
<CLASSIFICATIONS> TIMBRES, MUSIC, EXPERT SYSTEMS, NEAREST NEIGHBOR, PATTERN RECOGNITION, COMPUTER HUMAN INTERFACE </CLASSIFICATIONS>
<ABSTRACT>
Inductive learning can be used to perform an expert
skill using nearest neighbor pattern recognition. This
is demonstrated through a sound equalization expert
system which learns to proficiently adjust the timbres
(sound qualities) of brightness, darkness, and
smoothness in a context-dependent fashion. This
functions as an intelligent computer interface in the
computer-human interaction (CHI) paradigm where the
computer is used as a tool to sense, process, and act in
helping the user perform a perceptual task. Adjusting
timbres of sound is complicated by the fact that there
are non-linear relationships between equalization
adjustments and perceived sound quality changes. The
developed system is innovative in that it applies the
established nearest-neighbor technique to the new
application area of performing a skillful perceptual
task. This combination has been made possible through
advances in computer memory and processor technology,
making previously intractable problems now feasible. The
developed system shows that the nearest-neighbor context-
dependent equalization is rated 68% higher than the set
linear average equalization and that it is preferred 81%
of the time. Future work is discussed.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  3024 </NUMBER>
<ORDER>   AAI9614806 </ORDER>
<TITLE> THE ROLE OF THE PLANT PROPERTIES IN POINT-TO-POINT ARM MOVEMENTS: A NEURAL NETWORK APPROACH </TITLE>
<AUTHOR> MYERS, JENNIFER DAWN </AUTHOR>
<YEAR> 1995 </YEAR>
<INSTITUTION> NORTHWESTERN UNIVERSITY; 0163 </INSTITUTION>
<DESCRIPTORS> BIOLOGY, NEUROSCIENCE; COMPUTER SCIENCE; ENGINEERING, BIOMEDICAL; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> LINA L. E. MASSONE </ADVISER>
<CLASSIFICATIONS> ARTIFICIAL ARMS, ROBOTICS </CLASSIFICATIONS>
<ABSTRACT>
The central nervous system (CNS) signals the arm to move
the hand to a target by supplying activity to the
neurons which, in turn, innervate the muscles. These
muscles develop force and, through their attachment by
tendons to the skeletal system, impart torques at the
joints of the skeletal system over which the muscles are
attached. The task that the CNS faces--to construct a
time-activation of the neurons which innervate the
muscles in order to move the arm along a desired
trajectory-- is extremely complicated, and yet human
movement has an elegance far beyond the current
abilities of robotic devices. Point-to-point arm
movements exhibit the following kinematic invariances:
the hand tends to follow a smooth, straight path with a
bell-shaped velocity profile. It is a controversial
matter as to what extent these features may be planned
by the central nervous system in its time-varying neural
signals to the muscles, and to what extent they may be,
instead, an emergent property of the plant. The aim of
this dissertation is to examine, with a modeling study,
to what extent the observed kinematic properties of
point-to-point arm movements can be accounted for at the
level of the plant (that is, the controlled device,
rather than the controller). We used the following
methodology: (i) we assembled a neural network-based
model of the human arm, (ii) we analyzed the response of
this model to random input signals, (iii) we studied the
response of the model under various changes to the
model's parameters. We found that the smoothness of the
hand path and the bell-shape of its velocity profile are
emergent properties of the plant. The results of this
research are relevant to the understanding of how the
central nervous system plans and controls arm movements,
as well as to engineering control systems and the design
of artificial arms.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  3025 </NUMBER>
<ORDER>   AAI9614783 </ORDER>
<TITLE> A DUAL-NET APPROACH TO GUIDE THE CHOICE OF CLAUSE IN RESOLUTION  </TITLE>
<AUTHOR> LIAO, SHUMING G. </AUTHOR>
<YEAR> 1995 </YEAR>
<INSTITUTION> NORTHWESTERN UNIVERSITY; 0163 </INSTITUTION>
<DESCRIPTORS> ENGINEERING, ELECTRONICS AND ELECTRICAL; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> NIL </ADVISER>
<CLASSIFICATIONS> NEURAL NETWORKS, AUTOMATED REASONING </CLASSIFICATIONS>
<ABSTRACT>
The research in this thesis has focused on two distinct
areas of artificial intelligence, automated reasoning
and neural networks, and one possible way of utilizing
NN techniques to help guide a resolution-based theorem
prover for a special application.
Regarding automated reasoning, this is the first work to
apply neural net techniques to first-order logic
problems, although we recognize that the carefully
chosen sample problem, jobs puzzles, has no function
symbols and is therefore not fully representative of
first-order theorem-proving problems. We consider the
major theorem-proving contribution to be the overall
methodology of using a dual-net NN for picking the next
clause to use in resolution. We describe the results of
experiments on the jobs puzzle problem in which we
tested both the learning and prediction capability of
the dual-net NN. To what extent this approach could lead
to useful resolution guidance methodologies remains to
be seen. However, it is clearly a totally new approach
to the aspect of strategy in automated reasoning.
On the NN side of the research, we introduced the
concept of multiple NNs looking at different aspects of
the same problem and the concomitant question of
combining the outputs of the several NNs through the
postprocessor to produce a final output. We illustrated
this concept with a dual-net NN applied to the problem
of strategy for a particular automated reasoning
problem. We also developed two sample postprocessors. We
believe the idea of a dual-net or multi-net NN more
closely approximates a certain type of human reasoning
about problems in which categories of the problem help
focus the detailed reasoning about a particular problem
within the application domain. This new architecture
also is the first to explicitly allow for the matching
of specific NN inputs with classified prior experience
by focusing on the relevant SUBSET of the training set
to get a hopefully more accurate output. To this end, we
proposed the notion of "relevance" and showed some ways
in which that notion could be implemented. Finally, in
determining how accurate the INN in a dual network needs
to be, we have proposed a measure called to "order of
precision".
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  3026 </NUMBER>
<ORDER>   AAI9614770 </ORDER>
<TITLE> DAYDREAMING: REINFORCEMENT LEARNING IN A VIRTUAL ENVIRONMENT FOR NEURAL CONTROL </TITLE>
<AUTHOR> JUHN, HEINRICH </AUTHOR>
<YEAR> 1995 </YEAR>
<INSTITUTION> NORTHWESTERN UNIVERSITY; 0163 </INSTITUTION>
<DESCRIPTORS> COMPUTER SCIENCE; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> CHI-HAUR WU </ADVISER>
<CLASSIFICATIONS> NEURAL NETWORKS, MACHINE LEARNING </CLASSIFICATIONS>
<ABSTRACT>
Daydreaming is a common psychological phenomena
experienced by most people: spontaneously recalling or
imagining personal or vicarious experiences in the past
or future. Daydreaming serves several functions in
humans including rehearsal, future planning, and
learning from past experiences. An analogous process can
serve the same function with neural networks by
providing a training framework for learning from
"experience". A neural architecture for control is
presented based on a reinforcement learning paradigm
utilizing a virtual environment provided by a forward
model of the physical environment and a process
analogous to daydreaming in humans. A generic model of a
neural network is described along with the necessary
elements and processes to implement the network as a
black box controller capable of "daydreaming" during
times of idle activity. A partial implementation of the
generic model used to control the simulation of an
insect learning to navigate through an unknown and
dynamic environment is discussed. The implemented system
demonstrated the ability to learn basic navigation of
the environment and to adapt when goal states were
relocated or obstacles introduced.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  3027 </NUMBER>
<ORDER>   AAI9614663 </ORDER>
<TITLE> A FUZZY DISTRIBUTED DECISION-MAKING MODEL AND ITS APPLICATIONS TO DISTRIBUTED COMPUTING SYSTEMS </TITLE>
<AUTHOR> PARK, CHULHYE </AUTHOR>
<YEAR> 1995 </YEAR>
<INSTITUTION> THE UNIVERSITY OF IOWA; 0096 </INSTITUTION>
<DESCRIPTORS> ENGINEERING, ELECTRONICS AND ELECTRICAL; COMPUTER SCIENCE; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> JON G. KUHL </ADVISER>
<CLASSIFICATIONS> FUZZY LOGIC </CLASSIFICATIONS>
<ABSTRACT>
This thesis presents a new distributed decision-making
mechanism called a fuzzy distributed decision-making
model which allows individual decision makers to
efficiently manage state uncertainty in their decision-
making processes and to update their states
asynchronously and flexibly depending on the degree of
state uncertainty. The main idea of the fuzzy model is
that individual nodes may avoid taking unnecessary or
nonproductive actions by accounting for the effects of
state uncertainty upon the utility of their actions.
This fuzzy model, which is based upon the fuzzy set
theory, is characterized by the following three
functions: (i) the estimation of the degree of state
uncertainty from the states of uncertainty sources which
are locally available, (ii) the derivation of the
possibility distribution of the system state from
observations based upon the estimated degree of state
uncertainty, and (iii) the judgment of the values of
decisions based upon the fuzzy expected utility of
decisions. The notion of linguistic variables is used to
model state variables that have imprecise and uncertain
state values and fuzzy control to estimate the degree of
state uncertainty. Possibility theory is employed to
represent the system state with uncertainty. The fuzzy
expected utility of actions is calculated based upon the
possibility distribution of the system state and a
utility function. Another important feature of this
fuzzy model is its novel state-update mechanism which
allows individual decision makers to adjust the
frequency of information exchange dynamically.
To demonstrate the benefits of the fuzzy distributed
decision-making model, this thesis applies the fuzzy
model to distributed load balancing and distributed
system-level diagnosis, by designing a fuzzy distributed
load balancing algorithm and a fuzzy distributed system-
level diagnosis mechanism, and comparing their
performance and overheads against those of existing
distributed decision-making mechanisms through
simulations. It is shown through the simulations that
the fuzzy mechanisms outperform the existing mechanisms
without increasing overheads.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  3028 </NUMBER>
<ORDER>   AAG9703408 </ORDER>
<TITLE> DESIGN AND ANALYSIS OF A CLASS OF RECURRENT NETWORKS USING FEED-FORWARD MAPPING PROPERTIES </TITLE>
<AUTHOR> SHAABAN, KHALED MAMDOUH </AUTHOR>
<YEAR> 1995 </YEAR>
<INSTITUTION> CLEMSON UNIVERSITY; 0050 </INSTITUTION>
<DESCRIPTORS> ENGINEERING, ELECTRONICS AND ELECTRICAL; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> NIL </ADVISER>
<CLASSIFICATIONS> NEURAL NETWORKS, ARTIFICIAL INTELLIGENCE </CLASSIFICATIONS>
<ABSTRACT>
This work considers the development of a modified
version of the Hopfield network which is called Cascade
Recurrent Network (CRN). This network architecture has a
single or multilayer feedforward (FF) structure with
synchronous input-output feedback. System dynamics are
determined by the characteristics of this FF structure;
thus, a study of these characteristics provides useful
tools for system analysis and design. First, a formal
definition of both the mapping operation and
generalization are provided. Using these definitions,
and the classical definition of stability, the mapping-
stability relation is developed in the form of a
correspondence between CRN stability properties and FF
mapping characteristics. On the basis of this stability-
mapping relation, a new synthesis technique is given.
This technique utilizes optimization of FF mapping
generalization as a synthesis procedure for both single
layer (the Hopfield network) and multilayer CRNs. This
optimization is performed using a modified form of the
backpropagation algorithm. The objective function for
the optimization process has two terms, the first is the
total sum of squares of the mapping error, and the
second represents the total sum of squares of the
interconnection weight values. The second term adds a
secondary goal for the optimization process: improving
mapping generalization. The performance of this
algorithm is demonstrated to be equal to or superior
than other recurrent network synthesis procedures.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  3029 </NUMBER>
<ORDER>   AAI9614571 </ORDER>
<TITLE> NON-AXIOMATIC REASONING SYSTEM: EXPLORING THE ESSENCE OF INTELLIGENCE  </TITLE>
<AUTHOR> WANG, PEI </AUTHOR>
<YEAR> 1995 </YEAR>
<INSTITUTION> INDIANA UNIVERSITY; 0093 </INSTITUTION>
<DESCRIPTORS> COMPUTER SCIENCE; PSYCHOLOGY, GENERAL; PHILOSOPHY; ARTIFICIAL INTELLIGENCE; INFORMATION SCIENCE </DESCRIPTORS>
<ADVISER> NIL </ADVISER>
<CLASSIFICATIONS> ARTIFICIAL INTELLIGENCE, INHERITANCE NETWORK, COMMON SENSE, COGNITION </CLASSIFICATIONS>
<ABSTRACT>
Every artificial-intelligence research project needs a
working definition of "intelligence", on which the
deepest goals and assumptions of the research are based.
In the project described in the following chapters,
"intelligence" is defined as the capacity to adapt under
insufficient knowledge and resources. Concretely, an
intelligent system should be finite and open, and should
work in real time.
If these criteria are used in the design of a reasoning
system, the result is NARS, a non-axiomatic reasoning
system.
NARS uses a term-oriented formal language, characterized
by the use of subject-predicate sentences. The language
has an experience-grounded semantics, according to which
the truth value of a judgment is determined by previous
experience, and the meaning of a term is determined by
its relations with other terms. Several different types
of uncertainty, such as randomness, fuzziness, and
ignorance, can be represented in the language in a
single way.
The inference rules of NARS are based on three
inheritance relations between terms. With different
combinations of premises, revision, deduction,
induction, abduction, exemplification, comparison, and
analogy can all be carried out in a uniform format, the
major difference between these types of inference being
that different functions are used to calculate the truth
value of the conclusion from the truth values of the
premises.
Since it has insufficient space-time resources, the
system needs to distribute them among its tasks very
carefully, and to dynamically adjust the distribution as
the situation changes. This leads to a "controlled
concurrency" control mechanism, and a "bag-based" memory
organization.
A recent implementation of the NARS model, with
examples, is discussed. The system has many interesting
properties that are shared by human cognition, but are
absent from conventional computational models of
reasoning.
This research sheds light on several notions in
artificial intelligence and cognitive science, including
symbol-grounding, induction, categorization, logic, and
computation. These are discussed to show the
implications of the new theory of intelligence.
Finally, the major results of the research are
summarized, a preliminary evaluation of the working
definition of intelligence is given, and the limitations
and future extensions of the research are discussed.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  3030 </NUMBER>
<ORDER>   AAI9614548 </ORDER>
<TITLE> INTROSPECTIVE LEARNING FOR CASE-BASED PLANNING </TITLE>
<AUTHOR> FOX, SUSAN EILEEN </AUTHOR>
<YEAR> 1995 </YEAR>
<INSTITUTION> INDIANA UNIVERSITY; 0093 </INSTITUTION>
<DESCRIPTORS> COMPUTER SCIENCE; ARTIFICIAL INTELLIGENCE; INFORMATION SCIENCE </DESCRIPTORS>
<ADVISER> DAVID LEAKE </ADVISER>
<CLASSIFICATIONS> ARTIFICIAL INTELLIGENCE </CLASSIFICATIONS>
<ABSTRACT>
A fundamental problem for artificial intelligence is
creating systems that can operate well in complex and
dynamic domains. In order to perform well in such
domains, artificial intelligence systems must be able to
learn from novel and unexpected situations. There are
many well-researched learning methods for augmenting
domain knowledge, but little attention has been given to
learning how to manipulate that knowledge more
effectively. This research develops a method for
learning about reasoning methods themselves. It proposes
a model for a combined system which can learn new domain
knowledge, but is also able to alter its reasoning
methods when they prove inadequate.
Model-based reasoning is used as the basis of an
"introspective reasoner" that monitors and refines the
reasoning process. In this approach, a model of the
desired performance of an underlying system's reasoning
is compared to the actual performance to detect
discrepancies. A discrepancy indicates a reasoning
failure; the system explains the failure by looking for
other related failures in the model, and repairs the
flaw in the reasoning process which caused the failure.
The framework for this introspective reasoner is general
and can be transferred to different underlying systems.
The ROBBIE (Re-Organization of Behavior By Introspective
Evaluation) system combines a case-based planner with an
introspective component implementing the approach
described above. ROBBIE's implementation provides
insights into the kinds of knowledge and knowledge
representations that are required to model reasoning
processes. Experiments have shown a practical benefit to
introspective reasoning as well; ROBBIE performs much
better when it learns about its reasoning as well as its
domain than when it learns only about its domain.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  3031 </NUMBER>
<ORDER>   AAI9614423 </ORDER>
<TITLE> A PROPOSAL FOR HARDWARE IMPLEMENTATION OF ASSOCIATIVE MEMORIES USING SUPERCONDUCTING ELECTRONICS </TITLE>
<AUTHOR> QIAN, GANG </AUTHOR>
<YEAR> 1995 </YEAR>
<INSTITUTION> UNIVERSITY OF CINCINNATI; 0045 </INSTITUTION>
<DESCRIPTORS> ENGINEERING, ELECTRONICS AND ELECTRICAL; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> NIL </ADVISER>
<CLASSIFICATIONS> IMAGE PROCESSING, SYNAPTIC CIRCUITS, ARTIFICIAL INTELLIGENCE </CLASSIFICATIONS>
<ABSTRACT>
Memory is a fundamental characteristic of any
intelligent information processing system. Neural
associative memories can store patterns and retrieve
them from partial and incomplete stimuli. Most of neural
associative memory paradigms are based on the storage
and retrieval of binary patterns. Furthermore, these
binary associative memories are simulated in software
making applicability in large scale systems impractical.
In this dissertation, we describe a Q-state associative
memory for storage and retrieval of multivalued
patterns. Hardware implementation of such memories are
proposed based on the realization of binary and Q-state
neural cells using dc and radio frequency driven
unbalanced superconducting Wheatstone bridges.
The current-voltage characteristics of these bridges are
calculated while including the effect of thermal noise
as well as the effect of bond disorder in the various
Josephson junctions forming the bridge. We show that the
threshold dc biasing current needed to observe a
transverse voltage across the transverse junction of a
superconducting Wheatstone bridge can be adjusted by
varying the critical current in one or several branches
of the bridge with use of superconducting field effect
transistors (SuFETs). These SuFETs can also be used to
control the intersynaptic weights between the neural
cells. An alternative way to control the synaptic
weights is to use arrays of double junction SQUIDs to
form the various bits of the synapse.
We analyze the performance of Q-state pattern storage
using the Hebbian learning rule and find the latter
unsatisfactory. A new storage and retrieval algorithm
based on the properties of threshold decomposition and
stacking is formulated. The proposed algorithm allows
reliable storage and retrieval of patterns and allows an
increased level of fault tolerance. Hardware
implementation of the proposed Q-state associative
memory is described which makes use of binary and Q-
state neural cells organized in a massively parallel
architecture.
The proposed neural algorithm and implementation for
storing Q-state pattern can be used in the storage and
retrieval of realistic images and for multi-class
pattern classification. Among the advantages of the
implementation are low power consumption, ultra-high-
speed operation, and ultra-high packaging density. The Q-
state associative memory described in this thesis can be
realized with great reproducibility using Selective
Niobium Anodization Process (SNAP) to fabricate a
Niobium/AlO$sb0x$/Niobium shunted superconducting tunnel
junction technology.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  3032 </NUMBER>
<ORDER>   AAI9614422 </ORDER>
<TITLE> ADAPTIVE TRAFFIC CONTROL FOR ISOLATED SIGNALIZED INTERSECTIONS USING NEURAL NETWORKS </TITLE>
<AUTHOR> MUSA, MUHAMMAD </AUTHOR>
<YEAR> 1995 </YEAR>
<INSTITUTION> UNIVERSITY OF CINCINNATI; 0045 </INSTITUTION>
<DESCRIPTORS> ENGINEERING, CIVIL; TRANSPORTATION; COMPUTER SCIENCE; ENGINEERING, SYSTEM SCIENCE; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> NIL </ADVISER>
<CLASSIFICATIONS> ARTIFICIAL INTELLIGENCE </CLASSIFICATIONS>
<ABSTRACT>
In this study, the development of an adaptive traffic
control for signalized intersections is based on two
basic characteristics: (1) use of detectors upstream of
the intersection for early detection of arrivals of
vehicles, and (2) use of advance arrival and real-time
signal timing information as a primary basis to
determine and implement the optimal signal switching
sequence on a real time basis.
A PC-based system is developed. The system consists of
three neural networks and an on-line adaptive traffic
signal control algorithm. The three neural networks are
developed: for predicting: (1) whether an individual
vehicle will stop or not, (2) to predict the amount of
stopped delay for each through or right turning vehicle,
and (3) for predicting the amount of stopped delay for
each left turning vehicle during a protected phase.
These predictions are based on the detection of the
individual vehicles at some distance upstream of the
stop-line. The adaptive control algorithm is based on
minimizing the total amount of stopped delay for the
entire intersection for each cycle.
Additionally, two simulation models were developed: (1)
for evaluating the number of stops and amount of stopped
delay on a cycle-by-cycle basis, and (2) for selecting
the best phase lengths and cycle lengths based on the
least amount of stopped delay for the intersection. The
results of the simulation runs indicated that the
adaptive traffic control is applicable in practice.
The application of neural networks for adaptive traffic
control allows the system to efficiently predict and
adapt to the changing traffic patterns. The application
of the microscopic simulation technique made it possible
to check the applicability of the new adaptive traffic
control algorithm to the entire intersection. During the
course of this research, several advanced signal timing
parameters were identified that were useful in
predicting stops and stopped delay for each vehicle.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  3033 </NUMBER>
<ORDER>   AAI9614413 </ORDER>
<TITLE> TIME-VARYING NEURAL NETWORKS FOR ROBOT TRAJECTORY CONTROL  </TITLE>
<AUTHOR> GOLNAZARIAN, WANEK </AUTHOR>
<YEAR> 1995 </YEAR>
<INSTITUTION> UNIVERSITY OF CINCINNATI; 0045 </INSTITUTION>
<DESCRIPTORS> ENGINEERING, INDUSTRIAL; ENGINEERING, MECHANICAL; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> RICHARD L. SHELL </ADVISER>
<CLASSIFICATIONS> ARTIFICIAL INTELLIGENCE </CLASSIFICATIONS>
<ABSTRACT>
With increasing demands for faster, more accurate and
reliable robots, the field of robotics has faced the
challenges of reducing the required on-line
computational power, calibration time, and engineering
cost when developing new robot controllers. The robot
arm position control is a complex kinematic and dynamic
problem and has received researchers' attention for
quite some time. During the last several years, most
research on robot control has resulted in effective but
computationally expensive algorithms.
The focus of this dissertation is to systematically
design an improved robot controller based on time-
varying neural networks in place of designs using
conventional and adaptive robot controllers. The utility
of the approach was demonstrated by providing results of
the gross motion control of the first two joints of a
SCARA robot (AdeptOne) through simulation. The
robustness of the controller to parameter variations
(noise and mass disturbances) was also effectively
demonstrated along with the ability to maintain tracking
accuracy when faced with new trajectories. Unlike most
other control schemes, learning is done iteratively,
based on observations of input and output relationships
of the system in motion rather than having to specify
the explicit model of the system. The improved
controller based on the temporal ability of the simple
recurrent network structure has provided the time-
varying attribute needed for dealing with real-time
production tasks during implementation.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  3034 </NUMBER>
<ORDER>   AAI9614380 </ORDER>
<TITLE> NEW PARADIGMS FOR FUZZY NEURAL NETWORKS </TITLE>
<AUTHOR> NAVA, PATRICIA ANN </AUTHOR>
<YEAR> 1995 </YEAR>
<INSTITUTION> NEW MEXICO STATE UNIVERSITY; 0143 </INSTITUTION>
<DESCRIPTORS> ENGINEERING, ELECTRONICS AND ELECTRICAL; COMPUTER SCIENCE; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> JAVIN M. TAYLOR </ADVISER>
<CLASSIFICATIONS> SPEECH RECOGNITION </CLASSIFICATIONS>
<ABSTRACT>
Neural network history and fuzzy theory are explored to
create hybrid fuzzy neural networks. The generalized
delta learning rule is derived and used as a basis for
the learning rules used to train these fuzzy networks.
These new models and their learning rules combine the
benefits of both areas. The new models are tested on the
Speaker Independent Vowel Recognition Problem data set--
a particularly difficult classification problem due to
differences in voice frequency and variation in
speakers' pronunciation of the vowels. As the final
quantitative values prove, performance is vastly
improved by incorporating fuzzy theory into the neural
network model.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  3035 </NUMBER>
<ORDER>   AAI9614324 </ORDER>
<TITLE> SYSTEM MODELING VIA NEURAL NETWORK </TITLE>
<AUTHOR> SETOODEHNIA, ALI KORANI </AUTHOR>
<YEAR> 1995 </YEAR>
<INSTITUTION> THE UNIVERSITY OF OKLAHOMA; 0169 </INSTITUTION>
<DESCRIPTORS> ENGINEERING, ELECTRONICS AND ELECTRICAL; MATHEMATICS; COMPUTER SCIENCE; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> NIL </ADVISER>
<CLASSIFICATIONS> FEEDFORWARD MULTILAYER PERCEPTRON, GROUP METHOD DATA HANDLING </CLASSIFICATIONS>
<ABSTRACT>
This research focuses on application of Artificial
Neural Network (ANN) especially for modeling nonlinear
time-series problems, short-term forecasting problems,
chaotic systems, or dynamic control systems. In
particular, this dissertation presents two approaches:
the first is a modification of the connectivity of
supervised Feedforward Multilayer Perceptron (FMP) using
an Auto Regressive Moving Average (ARMA) connection at
each neuron for mapping the dynamic system rather than
FMP which is a static mapping network. In the second
approach, the Self-Organized Group Method Data Handling
(GMDH) has been investigated and a Hypercube Data
partitioning is proposed for training the network
efficiently. And furthermore, the multiple GMDH is
proposed for identifying piecewise continuous function
and it is proved that the multiple GMDH can reach better
accuracy than GMDH. The output model performance
evaluation is established at the end. The mathematical
analysis, convergence behavior, and computer simulations
are presented respectively.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  3036 </NUMBER>
<ORDER>   AAI9614113 </ORDER>
<TITLE> AUTOMATED MALFUNCTION DIAGNOSIS OF SEMICONDUCTOR FABRICATION EQUIPMENT USING A HYBRID NEURAL EXPERT SYSTEM </TITLE>
<AUTHOR> KIM, BYUNGWHAN </AUTHOR>
<YEAR> 1995 </YEAR>
<INSTITUTION> GEORGIA INSTITUTE OF TECHNOLOGY; 0078 </INSTITUTION>
<DESCRIPTORS> ENGINEERING, ELECTRONICS AND ELECTRICAL; ENGINEERING, INDUSTRIAL; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> GARY S. MAY </ADVISER>
<CLASSIFICATIONS> OBJECT ORIENTED </CLASSIFICATIONS>
<ABSTRACT>
Manufacturing integrated circuits (IC's) with increased
density and complexity on larger and larger substrates
requires the stringent control of hundreds, or even
thousands of process variables. Individual IC process
steps are conducted by complex pieces of fabrication
equipment. When unreliable performance causes this
equipment to vary beyond specified limits, overall
product quality is jeopardized. Since process shifts
resulting from faulty equipment can degrade
semiconductor products to an unacceptable level, it is
essential that root causes for the malfunctions be
diagnosed and corrected quickly to prevent the continued
occurrence of expensive misprocessing.
Although in-line measurements and electrical test data
have historically been used to detect process
fluctuations, these methods alone have become inadequate
for rapidly identifying problems in processes with a
narrow range of acceptable performance. However, with
the advent of highly proficient sensors designed to
monitor process conditions in-situ, it has become
feasible to perform such malfunction diagnosis on a real-
time basis. Therefore, methods of equipment diagnosis
which utilizes these capabilities are critical to the
overall success of the semiconductor production process.
This dissertation presents a general methodology for the
automated diagnosis of IC fabrication equipment. The
techniques presented combine the best aspects of
quantitative algorithmic, qualitative experiential, and
neural network approaches. By using neural network-based
modeling techniques in conjunction with statistical
inference methods, evidential belief is generated from
equipment maintenance history, real-time sensor data and
in-line measurements. The cause of failures is inferred
by integrating this belief using Dempster-Shafer
evidential reasoning techniques. This methodology is
applied to the identification of faults in the Plasma
Therm 720/740 Dual Chamber reactive ion etching (RIE)
system.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  3037 </NUMBER>
<ORDER>   AAI9614095 </ORDER>
<TITLE> WAVELET NEURAL NETWORKS FOR EEG MODELING AND CLASSIFICATION </TITLE>
<AUTHOR> ECHAUZ, JAVIER RAMON </AUTHOR>
<YEAR> 1995 </YEAR>
<INSTITUTION> GEORGIA INSTITUTE OF TECHNOLOGY; 0078 </INSTITUTION>
<DESCRIPTORS> ENGINEERING, BIOMEDICAL; ENGINEERING, ELECTRONICS AND ELECTRICAL; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> GEORGE VACHTSEVANOS </ADVISER>
<CLASSIFICATIONS> NIL </CLASSIFICATIONS>
<ABSTRACT>
Wavelet neural networks (WNNs) are introduced as a new
class of elliptic basis function neural networks and
wavelet networks, and are applied to the numerical
modeling and classification of EEGs. The implementation
of the networks is achieved in two possibly cyclical
stages of structure and parameter identification. For
structure identification, two methods are developed: one
generic, based on data clusterings, and one specific,
using wavelet analysis. For parameter identification,
two methods are also implemented: the Levenberg-
Marquardt algorithm and a genetic algorithm of ranking
type.
The problem of model generalization is considered from
both, a crossvalidation and a regularization point of
view. For the latter, a corrected average squared error
(CASE) is derived as a new model selection criterion
that does not rely on assumptions about error
distributions or modeling paradigms.
For EEG modeling, the nonlinear dynamics framework is
employed in the reconstruction of state-spaces via the
embedding scheme. Preprocessing for the resulting state-
vector is introduced in terms of decorrelation and
compression. The naive application of chaos theory to
EEGs is shown to be useful in feature extraction, but
not in corroborating theories about the nature of EEGs.
For the latter, the concept of modeling resolution is
introduced. It is shown that the chaos-in-the-brain
question becomes meaningful only as a function of
modeling resolution.
For EEG classification, a general WNN classification
system is implemented as a cascade of synergistic
feature selection, WNN nonlinear discrimination, and
decision logic. A feature library is described including
raw and model-based features, ranging from traditional
measures to chaotic indicators. Training for maximum-
likelihood classification is shown to be inductively
feasible via a decoder-type WNN classifier adjusted with
nonanalytic methods.
WNNs were found to be ideally suited for problems of EEG
analysis due to the long-duration/low-frequency and
short-duration/high-frequency structure of EEG signals.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  3038 </NUMBER>
<ORDER>   AAI9613948 </ORDER>
<TITLE> REGULATION OF TRANSCRIPTION OF THE BACTERIOPHAGE MU MIDDLE OPERON </TITLE>
<AUTHOR> KAHMEYER-GABBE, MICHELLE LEE </AUTHOR>
<YEAR> 1995 </YEAR>
<INSTITUTION> THE UNIVERSITY OF TENNESSEE; 0226 </INSTITUTION>
<DESCRIPTORS> BIOLOGY, MICROBIOLOGY; BIOLOGY, MOLECULAR </DESCRIPTORS>
<ADVISER> MARTHA M. HOWE </ADVISER>
<CLASSIFICATIONS> NIL </CLASSIFICATIONS>
<ABSTRACT>
A fundamental problem for artificial intelligence is
creating systems that can operate well in complex and
dynamic domains. In order to perform well in such
domains, artificial intelligence systems must be able to
learn from novel and unexpected situations. There are
many well-researched learning methods for augmenting
domain knowledge, but little attention has been given to
learning how to manipulate that knowledge more
effectively. This research develops a method for
learning about reasoning methods themselves. It proposes
a model for a combined system which can learn new domain
knowledge, but is also able to alter its reasoning
methods when they prove inadequate.
Model-based reasoning is used as the basis of an
"introspective reasoner" that monitors and refines the
reasoning process. In this approach, a model of the
desired performance of an underlying system's reasoning
is compared to the actual performance to detect
discrepancies. A discrepancy indicates a reasoning
failure; the system explains the failure by looking for
other related failures in the model, and repairs the
flaw in the reasoning process which caused the failure.
The framework for this introspective reasoner is general
and can be transferred to different underlying systems.
The ROBBIE (Re-Organization of Behavior By Introspective
Evaluation) system combines a case-based planner with an
introspective component implementing the approach
described above. ROBBIE's implementation provides
insights into the kinds of knowledge and knowledge
representations that are required to model reasoning
processes. Experiments have shown a practical benefit to
introspective reasoning as well; ROBBIE performs much
better when it learns about its reasoning as well as its
domain than when it learns only about its domain.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  3039 </NUMBER>
<ORDER>   AAGNN11465 </ORDER>
<TITLE> SYNTHESE DE RESEAUX DE NEURONES ARTIFICIELS POUR RESOUDRE DES PROBLEMES D'OPTIMISATION NP-COMPLETS: APPLICATIONS EN VLSI </TITLE>
<AUTHOR> AOURID, SIDI MOHAMED </AUTHOR>
<YEAR> 1995 </YEAR>
<INSTITUTION> ECOLE POLYTECHNIQUE, MONTREAL (CANADA); 1105 </INSTITUTION>
<DESCRIPTORS> ENGINEERING, ELECTRONICS AND ELECTRICAL; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> BOZENA KAMINSKA </ADVISER>
<CLASSIFICATIONS> FRENCH TEXT, NEURAL NETWORKS, COMBINATORIAL OPTIMIZATION </CLASSIFICATIONS>
<ABSTRACT>
This thesis proposes a mathematical method to synthesise
and analyse a neural architecture for pseudo-boolean
optimization. Results proposed by Hopfield have shown
many drawbacks concerning the stability and the quality
of the solutions. The Hopfield's model can solve only
small problems. This is due to the energy function
defined by Hopfield for his system. This energy has many
local minima which are in most cases irrelevant to the
solution of the original problem. To overcome these
difficulties, a new energy function is developed based
on the equivalence between concave and integer
programming problems. We have also used penalty methods
to transform a constrained problem into an unconstrained
one. The energy function that we have obtained consists
of three terms: the first term is the cost function for
the original problem, the second term is obtained
according to the equivalence between concave and integer
programming and the last term is the violated
constraints. Next, we have shown that our energy
function is continuously differentiable and also a
Lyapunov function which represent an important impact in
neural networks synthesis. This energy is also
associated with two parameters that must be chosen
adequately to guarantee a good solution. We have shown
that the choice of these parameters depends on the
method used to minimize the energy function. In fact, by
using neural networks to minimize its energy, we have
shown that the concavity of the energy function can be
omitted. This allows us to propose an efficient method
to fix the parameters very easily.
In order to ensure the convergence and the stability of
the system, we have drawn two conditions that our system
must satisfy at any moment. These two conditions
rewritten otherwise are equivalent to the Khun-Tucker
optimality conditions. To evaluate the performances of
our network, many linear and quadratique 0-1 problems
under inequalities constraints are tested and good
results are obtained.
Finally, we have solved a static compaction problem for
combinational circuits. This problem consists of, given
a test vectors set with some fault coverage, determining
a subset of test vectors without compromising the fault
coverage. Different methods for this problem are known
to be inefficient and very expensive regarding the
dynamic compaction where the compaction is performed
during test generation phase. To solve this problem, we
have shown first, an equivalence between static
compaction and set covering problem. Then, the
equivalent set covering problem is solved by a neural
network that we have developed. The obtained results
show the advantages of this equivalence for static
compaction and they also show that our network can deal
with large scale problems. (Abstract shortened by UMI.)
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  3040 </NUMBER>
<ORDER>   AAI9613930 </ORDER>
<TITLE> DEMONSTRATION OF AN EXPERT SYSTEM DATA BASE FOR THE SURVEILLANCE OF NUCLEAR WEAPONS AND MISSILE TECHNOLOGY UTILIZING A TACTICAL RAMJET AND MISSILE DESIGN AS A SYSTEMS MODEL </TITLE>
<AUTHOR> MENGES, PAMELA A. </AUTHOR>
<YEAR> 1995 </YEAR>
<INSTITUTION> THE UNION INSTITUTE; 1033 </INSTITUTION>
<DESCRIPTORS> ENGINEERING, AEROSPACE; ENGINEERING, SYSTEM SCIENCE; POLITICAL SCIENCE, INTERNATIONAL LAW AND RELATIONS; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> STANFORD J. SEARL, JR. </ADVISER>
<CLASSIFICATIONS> NIL </CLASSIFICATIONS>
<ABSTRACT>
The objective of this doctoral engineering project was
to provide a proof-of-demonstration that a microcomputer-
based system could act as a "field tool" for the
surveillance of nuclear weapon and missile technology.
The "expert system" data base was developed from data
provided by two systems-based conceptual models. The
first model is a rocket-boosted, boron slurry fueled
ramjet missile. The second model is a lens implosion
nuclear warhead. The missile model is also intended to
provide a concept for a supersonic standoff weapon with
a goal of using half of the components as commercial-off-
the-shelf (COTS) or dual-use products. Both models were
chosen because of their desirability among "potentially
proliferant" nations and encompass both the warhead and
the delivery system. The project computer was based on a
486DX2 microprocessor and the operating system software
was DOS 6.2. The expert system programs were XXXPERT
version 24, a shareware program, and its derivative,
ExpertFiles, developed by the writer to fulfill the
expanded requirements of the project. The two programs
were compared through fifty exercises where key words
were provided for data and file retrieval and cross
referencing. Both programs offer rule-based engines and
were used to integrate specific spreadsheet and DOS
batch files into an expert system data base. ExpertFiles
differed from XXXPERT V24, beyond the extended pattern
matching functions, to allow for experimentation with
user interfaces and inclusion of more sophisticated
subroutines for automatic file retrieval and cross
referencing. The successful demonstration suggests that
microcomputer-based field tools may be effective in
supplementing current and future missions in arms
control, verification, trade interdiction, and peace
keeping.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  3041 </NUMBER>
<ORDER>   AAI9613916 </ORDER>
<TITLE> ARTIFICIAL LANGUAGES/VIRTUAL BRAINS </TITLE>
<AUTHOR> BLACKWELL, ARSHAVIR WILLIAM </AUTHOR>
<YEAR> 1995 </YEAR>
<INSTITUTION> UNIVERSITY OF CALIFORNIA, SAN DIEGO; 0033 </INSTITUTION>
<DESCRIPTORS> PSYCHOLOGY, GENERAL; LANGUAGE, LINGUISTICS; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> ELIZABETH A. BATES; JEFF ELMAN </ADVISER>
<CLASSIFICATIONS> ARTIFICIAL INTELLIGENCE, LANGUAGE ACQUISITION, NEURAL NETWORKS, COMPETITION MODEL </CLASSIFICATIONS>
<ABSTRACT>
Various predictions of the Competition Model, a theory
of on-line language acquisition and processing (Bates
and MacWhinney, 1989) are tested, using the MAL
(Miniature Artificial Language) paradigm with both
humans and multi-layer neural networks.
Humans were tested in a series of different dialects of
an MAL with regular syntactic and morphological rules
which could also be used as cues to the meaning of the
sentence. The variables manipulated included the
frequency of the cue, the reliability of the information
it offered, and the surface form of the cue (i.e., word
order, agreement morphology, or animacy). In some
conditions, subjects' performance followed the
predictions of the Competition Model and profiles seen
in child language acquisition, in that their performance
initially showed sensitivity to those cues which were
more frequent, and then converged later in training upon
those cues which were more reliable. However, this
effect interacted with the form of the cue in that
subjects overall had a more difficult time using
agreement morphology than word order, a finding also
seen in natural language processing.
Neural networks were tested with languages that were
similar in their underlying structure to the MALs used
with humans; some versions of the networks showed the
same effects as predicted and as seen in normals in that
they initially showed sensitivity to those cues which
were more frequent, and then converged later in training
upon those cues which were more reliable. This effect
interacted in an interesting way with the type of
network, in that networks with an additional "hidden"
layer of processing units were closer to the predicted
performance than those with only one layer, even though
the one layer networks were well able to solve the
problem, suggesting an additional constraint on the
types of models that can be used if they are to be
psychologically valid.
Implications for the Competition Model and for further
research with MALs and their relevance to natural
language acquisition are discussed, as well as the
useful parallels between MAL research with humans and
neural network models.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  3042 </NUMBER>
<ORDER>   AAI9613815 </ORDER>
<TITLE> DECISION-THEORETIC REMINDER SYSTEMS THAT LEARN FROM FEEDBACK  </TITLE>
<AUTHOR> WAGNER, MICHAEL MATTHEW </AUTHOR>
<YEAR> 1995 </YEAR>
<INSTITUTION> UNIVERSITY OF PITTSBURGH; 0178 </INSTITUTION>
<DESCRIPTORS> COMPUTER SCIENCE; OPERATIONS RESEARCH; HEALTH SCIENCES, MEDICINE AND SURGERY; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> GREGORY F. COOPER </ADVISER>
<CLASSIFICATIONS> MEDICAL INFORMATICS, MACHINE LEARNING </CLASSIFICATIONS>
<ABSTRACT>
I developed a decision-theoretic model of unsolicited
information retrieval (UIR). The model, called DT-UIR,
extends two existing approaches: a decision-theoretic
model of document retrieval from the field of
information science, and a rule-based reminder system
from medicine.
To implement DT-UIR in a medical context, I defined
document utility as the difference between the value of
information in a document, which was measured by domain-
expert assessment of the expected utility of changes in
patient care plans caused by information, and time cost,
which was measured as the utility of time physician's
spent with the document. I implemented many variants of
the model including ones that assumed negligible time
cost (PRETRIEVE), and ones that assumed linear time cost
(PRETRIEVE-TC). I developed a test collection for system
evaluation by giving documents to physicians who were
formulating management plans for real patient cases.
Using a leave-one-out design, I tested how well each
system predicted the utility of documents in "new"
situations. Using an evaluation metric similar to ROC-
curve analysis, I tested how well each system arranged a
set of documents in order of expert-judged utility. I
compared systems with each other and with a comparable
rule-based reminder system. I tested variants of the DT-
UIR model that varied systematically by type of evidence
used by the system, by the level of discretization of
variables in the system, and by the use of data other
than utility as the basis for retrieval decisions. I
constructed and tested a hybrid reminder system that
used expected utility to order a set of rule-selected
documents.
I found that utility prediction was poor; causes
included limited training data, and limited evidence
from which the retrieval decision was based. The
document orderings of all DT-UIR systems, however, were
substantially better than random, although somewhat less
than ideal. Variants using relevance feedback ordered
documents less well than those using utility feedback.
The orderings and utility of retrieved sets of documents
of the PRETRIEVE-TC system were significantly better
than those of the rule-based system.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  3043 </NUMBER>
<ORDER>   AAI9613810 </ORDER>
<TITLE> SIGNAL AND SYSTEM ANALYSIS IN FUZZY INFORMATION SPACE </TITLE>
<AUTHOR> KOSANOVIC, BOGDAN RADOSLAV </AUTHOR>
<YEAR> 1995 </YEAR>
<INSTITUTION> UNIVERSITY OF PITTSBURGH; 0178 </INSTITUTION>
<DESCRIPTORS> ENGINEERING, ELECTRONICS AND ELECTRICAL; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> LUIS F. CHAPARRO; ROBERT J. SCLABASSI </ADVISER>
<CLASSIFICATIONS> FUZZY SET </CLASSIFICATIONS>
<ABSTRACT>
A general approach to signal and system analysis using
fuzzy set theory is developed. A family of temporal
fuzzy sets is constructed to provide for the
unsupervised quantitative and qualitative analysis of
dynamic motions. The observed process generated by a
physical system is decomposed into several hidden
processes that coexist at the same time but to different
degrees. Each of the identified processes tends to
characterize the corresponding region of attraction that
is modeled by a temporal fuzzy set. The fuzzy
information space is constructed from the activities of
hidden processes, i.e. the membership functions of
temporal fuzzy sets. It is shown that the hidden
processes generalize the notion of hidden Markov
modeling. Through the introduction of dynamic fuzzy
sets, it is suggested that signal analysis can be
performed in fuzzy information space, instead of raw
signal space, because the motivation is to fit the
analysis to the significant aspects of system dynamics
instead of fitting the noise in raw data. An algorithm
for estimation of temporal fuzzy sets is discussed and a
dynamic profile validity functional is proposed that
determines an upper bound for a reasonable number of
hidden processes. The simulation results from a class of
quasi-stationary processes are presented to verify the
applicability of a proposed method. Analysis of
electroencephalographic signals recorded during sleep is
performed to suggest a way the method can be used on
real-world problems. The theoretical extensions
developed in this work are laying the foundations for a
practical approach to analysis of complex systems.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  3044 </NUMBER>
<ORDER>   AAI9613737 </ORDER>
<TITLE> APPLICATION OF NEURAL NETWORKS TO TRANSIENT STABILITY ASSESSMENT AND GENERATOR COHERENCY IDENTIFICATION </TITLE>
<AUTHOR> MUKNAHALLIPATNA, SURESH S. </AUTHOR>
<YEAR> 1995 </YEAR>
<INSTITUTION> UNIVERSITY OF WYOMING; 0264 </INSTITUTION>
<DESCRIPTORS> ENGINEERING, ELECTRONICS AND ELECTRICAL; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> NIL </ADVISER>
<CLASSIFICATIONS> ARTIFICIAL INTELLIGENCE </CLASSIFICATIONS>
<ABSTRACT>
In this dissertation work, neural networks have been
applied to the problem of on-line transient stability
assessment and generator coherency identification.
Transient stability assessment is the process of
identifying the power system state after a disturbance
in a short time.
Three neural networks, namely, the feedforward network
trained using the backpropagation algorithm, the
probabilistic neural network, and the general regression
neural network are used to perform the transient
stability assessment. The number of input features to
these networks is a function of the number of generators
present in a power system. The features chosen contain
information about the traverse of the system state after
a disturbance.
This new approach has been tested on two power systems,
namely, the New England system, and the IEEE 145 Bus
system. The accuracy of the transient stability
assessment by the proposed networks is comparable with
the time domain simulation approach. The accuracy of
assessment for the probabilistic and general regression
neural networks was close to 100%. The networks, after
proper training, are suited for on-line transient
stability assessment.
Two dimension reduction techniques are also used to
reduce the dimension of the input features. The same
level of accuracy in transient stability assessment was
maintained in the new reduced pattern space.
A new approach for the coherency identification of the
generators is proposed. In this approach, instead of the
conventional rotor angle criterion, a new criterion,
consisting of the angular velocities of the generators,
is proposed. The coherency identification is done by
identifying inherent similarities in the input patterns
by using a Kohonen network. This approach is also tested
on the two test systems.
The coherency identification obtained by the proposed
method is compared with time domain simulations. The
identification is found to be accurate in most of the
cases. Also, it is observed that the proposed approach
is able to identify the critical generators, location of
faults, etc., along with the coherency identification.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  3045 </NUMBER>
<ORDER>   AAI9613561 </ORDER>
<TITLE> ROAD FOLLOWING USING NEURAL NETWORKS AND REINFORCEMENT LEARNING  </TITLE>
<AUTHOR> YU, GENING </AUTHOR>
<YEAR> 1995 </YEAR>
<INSTITUTION> WAYNE STATE UNIVERSITY; 0254 </INSTITUTION>
<DESCRIPTORS> COMPUTER SCIENCE; ENGINEERING, ELECTRONICS AND ELECTRICAL; ENGINEERING, AUTOMOTIVE; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> ISHWAR K. SETHI </ADVISER>
<CLASSIFICATIONS> ARTIFICIAL INTELLIGENCE </CLASSIFICATIONS>
<ABSTRACT>
One of the important tasks in Intelligent Vehicle
Highway Systems (IVHS) is to have a system which can
generate steering control signals given one or more
sensory inputs either to assist drivers or to intervene
in the driving task. This particular need is in the
background of the work described in this dissertation
where the aim is to build a road following system that
generates steering control signals based on vision
input. A neural network-based system is proposed to take
advantage of learning ability exhibited by such
networks. Unlike many existing neural network-based
systems that only use the supervised mode of learning,
the proposed system also uses a reinforcement learning
mode to generate steering control outputs. The use of
reinforcement learning eliminates the need for an
external supervisor and at the same time provides the
system with continuous learning ability similar to the
human driving practice.
A simplified version of the proposed road following
system was implemented in a simulated single-lane road
environment. The implemented road following system
consists of a road model categorization system and a
steering control system. A modified self-organizing map
(SOM) neural network learning algorithm is used by the
road model categorization system to categorize the road
shapes and locations. An adaptive heuristic critic (AHC)
reinforcement learning algorithm is used by the steering
control system to provide continuous learning ability.
An integrated algorithm was proposed for the road
following system to learn in simulation and real driving
environments. A three-phase learning algorithm was
developed to integrate the SOM network and the AHC
learning in the simulation driving environment. In real
situations, supervised learning may be used initially
and reinforcement learning can then be applied to keep
the road following system continuously improving. The
simulation experimental results demonstrate the system's
road following performance and continuous learning
capability. The results indicate that it is possible to
build a road following system with continuous learning
capability. Future work will include full-scale
simulation in complex road environments, speed control
and the construction of a real system.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  3046 </NUMBER>
<ORDER>   AAI9613533 </ORDER>
<TITLE> APPLICATIONS OF EVOLUTIONARY CREDIT APPORTIONMENT TO COMPLEX NEURAL ARCHITECTURES </TITLE>
<AUTHOR> SMALZ, ROBERT WAYNE </AUTHOR>
<YEAR> 1995 </YEAR>
<INSTITUTION> WAYNE STATE UNIVERSITY; 0254 </INSTITUTION>
<DESCRIPTORS> COMPUTER SCIENCE; ARTIFICIAL INTELLIGENCE; BIOLOGY, NEUROSCIENCE </DESCRIPTORS>
<ADVISER> MICHAEL CONRAD </ADVISER>
<CLASSIFICATIONS> ARTIFICIAL INTELLIGENCE </CLASSIFICATIONS>
<ABSTRACT>
This dissertation presents diverse ways of applying the
author's previously developed evolutionary credit
apportionment (or ECA) approach to neural learning to
temporal input-output problems primarily and over a
variety of architecture and neuronal assumptions. One
main emphasis is on the application of a modification or
extension to the fitness assignment process to neurons
so as to include multiple fitness values for each neuron
corresponding to different values for a threshold
parameter (or a threshold and ceiling parameter).
Another involves a decomposition of the part of the
algorithm that selects a best network for a long
temporal association sequence into multiple selection
steps over subsequences. These ECA extensions are
evaluated over a range of network architectures
including one consisting of a hierarchy built from
several different network modules. Among the key results
are demonstrations of significant benefits in terms of
average accuracy levels of using both threshold-based
selection and sequence partitioning in conjunction with
all of the recurrent architectures. Similarly, threshold-
based selection alone with the static 6-bit Boolean
multiplexor problem saw, in comparison to the single
fitness value per neuron method, significant positive
effects both on functional accuracy (strongly evident in
increases in the percentage of perfect performances) and
on the average number of generations required to reach
the maximum performance level for each trial. ECA
learning with threshold-based selection over this same
task was also capable of exploiting the neurons with
both a threshold and a ceiling parameter to moderate the
effect on performance (particularly with respect to best
possible accuracy) when the network size was reduced. At
the same time, the recurrent hierarchical network showed
performance gains with respect to both average accuracy
and the required number of generations to reach the same
levels of accuracy in comparison to single level
networks when problem sets consisted of groups of
closely related sequences (some sequences noisy variants
of others). Over similar kinds of temporal association
problems this network hierarchy also worked together
smoothly (no loss in average accuracy or required
learning generations) with a specialized front-end
module that is intended to facilitate a pre-given task
performance assumption regarding rotation invariance.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  3047 </NUMBER>
<ORDER>   AAI9613500 </ORDER>
<TITLE> MODERN APPROACHES TO THE COMPUTATION OF THE PROBABILITY OF TARGET DETECTION IN CLUTTERED ENVIRONMENTS </TITLE>
<AUTHOR> MEITZLER, THOMAS J. </AUTHOR>
<YEAR> 1995 </YEAR>
<INSTITUTION> WAYNE STATE UNIVERSITY; 0254 </INSTITUTION>
<DESCRIPTORS> ENGINEERING, ELECTRONICS AND ELECTRICAL; PSYCHOLOGY, EXPERIMENTAL; PHYSICS, OPTICS; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> HARPREET SINGH </ADVISER>
<CLASSIFICATIONS> COMPUTER VISION, ARTIFICIAL INTELLIGENCE </CLASSIFICATIONS>
<ABSTRACT>
The field of computer vision interacts with fields such
as psychology, vision research, machine vision,
psychophysics, mathematics, physics, and computer
science. The focus of this thesis is new algorithms and
methods for the computation of the probability of
detection (Pd) of a target in a cluttered scene. The
scene can be either a natural visual scene such as one
sees with the naked eye (visual), or, a scene displayed
on a monitor with the help of infrared sensors. The
relative clutter and the temperature difference between
the target and background ($Delta$T) are defined and
then used to calculate a relative signal-to-clutter
ratio (SCR) from which the Pd is calculated for a target
in a cluttered scene. It is shown how this definition
can include many previous definitions of clutter and
($Delta$T). Next, fuzzy and neural-fuzzy techniques are
used to calculate the Pd and it is shown how these
methods can give results that have a good correlation
with experiment. The experimental design for actually
measuring the Pd of a target by observers is described.
Finally, wavelets are applied to the calculation of
clutter and it is shown how this new definition of
clutter based on wavelets can be used to compute the Pd
of a target.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  3048 </NUMBER>
<ORDER>   AAI9613468 </ORDER>
<TITLE> THE DETERMINATION OF TERMINAL RELIABILITY WITH DEPENDENCY INFORMATION IN COMPUTER COMMUNICATION NETWORKS USING ARTIFICIAL NEURAL NETWORKS </TITLE>
<AUTHOR> HACHEM, NABIL ASSAAD </AUTHOR>
<YEAR> 1995 </YEAR>
<INSTITUTION> WAYNE STATE UNIVERSITY; 0254 </INSTITUTION>
<DESCRIPTORS> ENGINEERING, ELECTRONICS AND ELECTRICAL; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> JATINDER S. BEDI </ADVISER>
<CLASSIFICATIONS> NIL </CLASSIFICATIONS>
<ABSTRACT>
The terminal reliability is the probability that a given
source node in the network can communicate with a given
terminal node. The available methods in computing the
terminal reliability assume that all links fail
independently with a fixed value. The classical Boolean
algebra method depends on minimization techniques. The
present algorithms that implement it do not result in
minimized functions, and are impractical for large
networks. An algorithm for minimizing Boolean functions
is developed which handles networks of all types, and
yields minimum functions. Another algorithm is developed
to compute the terminal reliability which includes the
dependent link failures in the network, and yields lower
and upper bounds. Then neural networks are used to
implement the reliability computation utilizing the back
propagation technique. Networks analyses are provided
implementing the algorithms.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  3049 </NUMBER>
<ORDER>   AAI9613436 </ORDER>
<TITLE> DESIGN OF CELLULAR MANUFACTURING SYSTEMS IN A FUZZY ENVIRONMENT  </TITLE>
<AUTHOR> AL-QAHTANY, SALEH AM </AUTHOR>
<YEAR> 1995 </YEAR>
<INSTITUTION> WAYNE STATE UNIVERSITY; 0254 </INSTITUTION>
<DESCRIPTORS> ENGINEERING, INDUSTRIAL; ENGINEERING, SYSTEM SCIENCE; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> NANUA SINGH; JATINDER BEDI </ADVISER>
<CLASSIFICATIONS> GROUPING, ARTIFICIAL INTELLIGENCE </CLASSIFICATIONS>
<ABSTRACT>
Modern manufacturing systems must deliver lower-cost,
better-quality, and minimal-throughput-times products.
One technological innovation used to achieve these goals
is Cellular Manufacturing (CM). One of the major aspects
of cellular manufacturing systems is cell formation
(CF), which consists of identifying part families and
machine groups (cells).
There are two main descriptive procedures for solving
the cell formation problem, sequential grouping and
simultaneous grouping. Most of the previous work done in
the area of cellular manufacturing assumes that
information about processing time and cost, parts
demand, and other data is precise. In reality, this
information is often vague. This uncertainty in the
manufacturing environment has a major impact on cell
design. In order to deal with this inherent uncertainty,
fuzzy logic is employed in this research. In cell
design, the creation of mutually exclusive cells is one
of the most important goals. However, achieving this
goal may lead to higher cost by duplicating machines, or
less utilized system by having under-utilized machine
capacity in each cell.
The objective of this thesis is to use both the
sequential and simultaneous approaches to cell formation
to address the above issues. For the first one, a fuzzy
mathematical programming model is built to design
mutually exclusive cells. In this model, we incorporate
routing flexibility (permitting alternate routes for
each part) in forming the cells. Part families and
machine cells are formed simultaneously, taking into
consideration uncertainty in processing cost processing
time, and in parts demand. For the sequential approach,
we present a new neuro-fuzzy model for designing a
cellular manufacturing system. A three-stage model is
proposed. In the first stage, an integer programming
model is used as an operational allocation model. In the
second stage, a neural network (NN) model is used to
form the machine cells. In the last stage, a fuzzy model
is used to improve the solution and to retrain the
neural network to assign new parts to the existing
system.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  3050 </NUMBER>
<ORDER>   AAGNN11463 </ORDER>
<TITLE> CONTRIBUTION AU DEVELOPPEMENT D'UNE THEORIE DE GENERATION DE MOUVEMENTS SIMPLES ET RAPIDES APPLICATION AU MANUSCRIT </TITLE>
<AUTHOR> ALIMI, M. ADEL </AUTHOR>
<YEAR> 1995 </YEAR>
<INSTITUTION> ECOLE POLYTECHNIQUE, MONTREAL (CANADA); 1105 </INSTITUTION>
<DESCRIPTORS> ENGINEERING, ELECTRONICS AND ELECTRICAL; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> REJEAU PLAMONDON </ADVISER>
<CLASSIFICATIONS> FRENCH TEXT, HANDWRITING, ARTIFICIAL INTELLIGENCE </CLASSIFICATIONS>
<ABSTRACT>
Dans la sphere de l'intelligence artificellie, se trouve
la modelisation de l'ecriture manuscrite, domaine
relativement recent mais dans lequel toutefois, il se
fait de plus en plus activement de la recherche. Cette
these est un sous-ensemble d'un projet plus global du
laboratoire Scribens de l'Ecole Polytechnique de
Montreal traitant du developpement d'une theorie de
generation de l'ecriture manuscrite. L'objectif
principal de notre contribution est de valider la plus
performante des theories et modeles developpes a ce
jour, pour les mouvements rapides simples. Cette
validation va s'appuyer sur les observations a aspect
cinematique et precision rapportees par les chercheurs
oeuvrant dans ce domaine en se basant sur l'ecriture
manuscrite comme outil d'experimentation. La
contribution majeure de ce travail repose sur le
developpement d'une methodologie originale de
comparaison de modeles developpes dans des contextes
differents. Cette methodologie, portant sur divers
aspects de l'analyse de la generation de mouvements, est
divisee en differentes etapes bien structurees a travers
lesquelles une theorie de mouvement basee sur des
fondements solides doit passer avec succes.
Pour atteindre notre objectif, nous avons fait une revue
exhaustive des observations, lois, modeles et theories a
aspect cinematique et precision concernant les
mouvements rapides simples que nous avons tous formules
sous un meme format. Il a donc ete plus aise de les
comparer theoriquement et experimentalement en se basant
sur plusieurs criteres afin d'eviter de biaiser notre
etude comparative de selection.
Cette methode systematique demontre que la theorie de
loi delta-lognormale de Plamondon (1993b,c; 1995a,b)
demeure a ce jour la plus performante et la plus precise
pour predire et expliquer les phenomenes observes. De
plus, ont ete mises au point une serie d'experiences
basees sur l'ecriture manuscrite de traits simples afin
de verifier de facon encore plus precise d'autres
predictions specifiques a cette theorie visant ainsi a
valider et en confirmer sa robustesse.
Avec cette theorie de la loi delta-lognormale, l'on peut
de facon adequate, tenir compte des diverses formes du
profil de vitesse d'un effecteur ainsi que de ses
differentes proprietes en fonction de differentes
conditions experimentales. En utilisant la loi delta-
lognormale de base, toutes les observations cinematques
peuvent etre decrites et les predictions analytiques
concernant la duree de mouvement, le temps d'occurrence
du pic de vitesse, la vitesse maximale, etc. sont
valides. En utilisant une loi quadratique ou son
approximation, la loi de puissance qui derive de la loi
delta-lognormale, toutes les observations a aspect
precision concernant le compromis vitesse-precision
peuvent entre decrites. L'interet majeur de cette
theorie provient du fait qu'elle nous presente une
description unique du systeme neuromusculaire et permet
de l'analyser sous differents points de vue decoulant
des differents protocoles experimentaux.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  3051 </NUMBER>
<ORDER>   AAI9613408 </ORDER>
<TITLE> SYNTHESIS OF TACTICAL PLANS FOR ROBOTIC EXCAVATION </TITLE>
<AUTHOR> SINGH, SANJIV </AUTHOR>
<YEAR> 1995 </YEAR>
<INSTITUTION> CARNEGIE-MELLON UNIVERSITY; 0041 </INSTITUTION>
<DESCRIPTORS> COMPUTER SCIENCE; ENGINEERING, CIVIL; ENGINEERING, MECHANICAL </DESCRIPTORS>
<ADVISER> NIL </ADVISER>
<CLASSIFICATIONS> ACTION SPACE, SOILS </CLASSIFICATIONS>
<ABSTRACT>
This thesis describes an approach to synthesizing plans
for robotic excavators. Excavation tasks range from
loading a pile of soil to cutting a geometrically
described volume of earth--for a trench or foundation
footing. The excavation task can be stated in terms
familiar to researchers in robotics and artificial
intelligence: Transform the world from its current state
to another state. Two important characteristics,
however, distinguish the excavation domain. First, soil
is deformable, and, hence, a complete state-space
description of terrain to be excavated requires a high-
dimensional representation. But, for the state-based
representations that traditional planners use, very
large spaces are simply infeasible. Second, the response
of soil varies immensely, and in general, it is not
possible to analytically describe the mechanics of soil
motion and its interaction with tools. A soil's shear
strength depends not only on its physical and chemical
makeup, but also on factors such as the compaction
experienced in the past. Thus a robotic excavator is
forced to deal with approximate and incomplete models of
its actions and their results.
This research has developed and demonstrated a unified
approach to deal with each of these issues. Instead of
posing the planning problem in state space, this thesis
employs a dual representation called "action space." An
action space is spanned by parameters that abstract the
actions that a robot excavator might perform. This
formulation allows posing an excavation task as a
problem of constrained optimization over the space of
prototypical, one-step excavating plans. To reason about
resistive forces encountered while digging, this work
has developed a method that learns to predict resistive
forces encountered during excavation. The action space
representation allows incorporating goal configuration
and geometric and force constraints within a single
framework. Planning is thus reduced to finding a subset
of plans that meet the constraints and optimize an
appropriate performance measure.
Over 400 experiments on a specially-developed testbed
were conducted to validate the action-space/force-
prediction approach. The testbed robot has a
hydraulically manipulated shovel and sensors that
measure both contact forces and terrain contour. Given a
geometric specification, the current implementation can
excavate a trench to predictable tolerances. Testbed
results reinforce the notion that a force-based model is
essential to successful robotic excavation. These
findings also point to the necessity of a lower-level
control mode that can modify excavation plans based on
the nature of the terrain encountered.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  3052 </NUMBER>
<ORDER>   AAI9613400 </ORDER>
<TITLE> AN INTELLIGENT, PREDICTIVE CONTROL APPROACH TO THE HIGH- SPEED CROSS-COUNTRY AUTONOMOUS NAVIGATION PROBLEM </TITLE>
<AUTHOR> KELLY, ALONZO JAMES </AUTHOR>
<YEAR> 1995 </YEAR>
<INSTITUTION> CARNEGIE-MELLON UNIVERSITY; 0041 </INSTITUTION>
<DESCRIPTORS> COMPUTER SCIENCE; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> NIL </ADVISER>
<CLASSIFICATIONS> ROBOTS, ARTIFICIAL INTELLIGENCE </CLASSIFICATIONS>
<ABSTRACT>
Autonomous robot vehicles promise many ultimate
civilian, military, and space applications. Off-road
autonomous vehicles must engage the world exactly as
they find it without relying on having it engineered to
suit them. For this reason, off-road autonomous
navigation is one of the most difficult automation
challenges. Previous work in the area has been
disappointing from the perspective of the speeds
attained, and the inability of systems to travel long
distances autonomously. Indeed, no system has travelled
an autonomous mile or exceeded 3 m/s speeds. To date, no
off-road system has approached the capabilities needed
to address real applications.
This thesis examines and proposes a solution to the
problem of high speed autonomous navigation of outdoor
vehicles. As a systems-level effort, aspects of
perception, path planning, position estimation, and to a
lesser extent, strategic planning and motion control are
considered. The emphasis of the work has been to assess
the fundamental requirements of the problem, and to
validate the conclusions of this assessment through the
demonstration of an improved ability to achieve a real
cross-country mission on several vehicle testbeds.
Results indicate that cross-country navigation systems
of unprecedented capability are possible if they are
designed to optimally utilize limited computing
resources. A system of unprecedented performance has
been constructed and extensively tested.
The essential argument of the thesis is one of
architecture. An intermediate intelligent predictive
control layer is introduced between the typical high-
level strategic or artificial intelligence layer and the
typical low-level servo control layer. This new layer,
the tactical layer, incorporates some deliberation, and
some environmental mapping as do deliberative AI
planners, yet it also emphasizes the real-time aspects
of the problem as do minimalist reactive architectures.
The contribution of the work is a codified systems
theory that permits future design efforts to benefit
from the experience and a fieldworthy prototype system
that provides a baseline capability for continued
research. Specific results include an analysis of the
complexity of range image perception for autonomous
vehicles and an associated computational image
stabilization algorithm which permits highest vehicle
speeds.
The problem of local autonomous mobility has been
formulated entirely in an optimal control context. In
this context, the concepts of actuation space and hazard
space replace the configuration space that is more
typical of AI planners. The resulting high fidelity
models stabilize coordinated control of a high speed
vehicle for both obstacle avoidance and goal seeking
purposes.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  3053 </NUMBER>
<ORDER>   AAI9613320 </ORDER>
<TITLE> PROCESS MODELLING, OPTIMIZATION AND CONTROL USING ARTIFICIAL NEURAL NETWORKS </TITLE>
<AUTHOR> WANG, XING AN </AUTHOR>
<YEAR> 1995 </YEAR>
<INSTITUTION> UNIVERSITY OF COLORADO AT BOULDER; 0051 </INSTITUTION>
<DESCRIPTORS> ENGINEERING, MECHANICAL; ARTIFICIAL INTELLIGENCE; ENGINEERING, INDUSTRIAL </DESCRIPTORS>
<ADVISER> ROOP L. MAHAJAN </ADVISER>
<CLASSIFICATIONS> MANUFACTURING, ARTIFICIAL INTELLIGENCE, CVD </CLASSIFICATIONS>
<ABSTRACT>
This thesis reports the results of research in modeling,
optimization and run-to-run control of complex
manufacturing processes through the use of artificial
neural networks (ANNs). The test vehicle is the chemical
vapor deposition of silicon in a barrel reactor. Other
manufacturing processes are also included, where
necessary, to elucidate some aspects of the research.
In the introductory chapter, the motivation and
objective of the present study are addressed, and a
framework of the ANN control system is proposed.
Chapter 2 describes the ANN modeling techniques for both
dense data and sparse data. The principle and
configuration of ANNs are briefly illustrated. The
horizontal CVD reactor and boiling curve are chosen as
examples for the dense data case. It is shown that ANNs
can effectively map very nonlinear processes, including
discrete relationships. When a physical model is
available, enough data points generated by the physical
model can be used to train an ANN model. This model
supported by a physical model is referred to as the
physico-neural model and is shown to have good
generalization capability. The barrel CVD reactor is
chosen as an example for the sparse data case. To map
the input-output relationship, ANNs with different
configurations are trained and tested by designed
experimental data. A "simple to complex" approach is
proposed to determine the best net configuration.
Chapter 3 deals with process modeling and optimization
technique. An artificial neural network response surface
methodology (ANNRSM) is proposed for process modeling
and optimization. An ANN model is built by "simple to
complex" approach and is then used in conjunction with a
gradient search scheme to ascertain input settings for
optimal output. The results of using the ANNRSM in
identifying optimum settings in the presence of noise
show the applicability of the technique to noisy data. A
laboratory experimental study based on a mock-up CVD
reactor supports the optimum settings obtained by the
ANNRSM. A comparison between the ANNRSM and regression
RSM shows that the ANNRSM is able to build an accurate
global model and find the optimum using fewer data
especially when the data points are noisy.
Chapter 4 deals with an ANN model based run-to-run
controller. The ANN run-to-run controller is an
integration of the ANN modeling, statistical process
control (SPC), and automatic process control (APC)
techniques. The procedure for design and optimization of
an ANN run-to-run controller is discussed in detail. The
controller model is extracted from the ANN process model
by Taylor expansion and inversion. An EWMA technique is
used to detect the process shift/drift and filter out
the output noise. The control action is determined by
feedback to compensate for the process shift and slow
drift. It is found that a dual controller does a good
job in controlling of a process with either a small or
big shift. A total cost criterion is proposed for
optimizing the run-to-run controller. Simulation
calculations of the total cost are also performed.
Experiments from the laboratory mock-up reactor
demonstrate the effectiveness of the proposed ANN run-to-
run controller.
In the concluding chapter, the major contributions of
this study are highlighted, and future work is proposed.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  3054 </NUMBER>
<ORDER>   AAI9613247 </ORDER>
<TITLE> DIFFERENTIABLE SYMBOL MANIPULATION AND LANGUAGE INDUCTION  </TITLE>
<AUTHOR> DAS, SREERUPA </AUTHOR>
<YEAR> 1995 </YEAR>
<INSTITUTION> UNIVERSITY OF COLORADO AT BOULDER; 0051 </INSTITUTION>
<DESCRIPTORS> COMPUTER SCIENCE; ENGINEERING, GENERAL; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> MICHAEL C. MOZER </ADVISER>
<CLASSIFICATIONS> NEURAL NETWORKS, ARTIFICIAL INTELLIGENCE </CLASSIFICATIONS>
<ABSTRACT>
There is a large class of learning problems that are
inherently discrete. Connectionist models that operate
on continuous weight and activation spaces are not
always appropriate for learning such tasks because their
learning procedures have a propensity to produce
solutions that lack symbolic interpretation. In this
thesis, I demonstrate that it is possible to incorporate
differentiable symbol manipulation (DSM) techniques in a
connectionist system in order to overcome their
nonsymbolic nature. The hypothesis underlying this
methodology is that a connectionist model can benefit
from exploring a subsymbolic solution space even when
the final solutions have symbolic interpretations.
In this thesis, the idea of DSM has been applied to the
domain of Language Induction. Given a finite number of
examples (sentences) from a language, the goal of
language induction is to induce the target language by
identifying structural regularities underlying the
examples. The domain of language induction is strictly
symbolic, having to do with rule identification and
symbol manipulation, and to learn such tasks using
subsymbolic connectionist methods has always been a
challenge.
I explore three connectionist models using DSM. The
first model learns to induce finite state machines
(regular languages) by inducing discrete representations
of the states. It incorporates an adaptive clustering
technique in a standard recurrent connectionist
architecture that quantizes the state space as an
integral part of learning. Simulations show that this
architecture leads to a significant improvement in
generalization performance over earlier connectionist
approaches. In the second model, I describe an
architecture that incorporates DSM for learning symbolic
rewrite rules in a subclass of context-free grammars.
The third model incorporates DSM for learning yet
another subclass of context free languages. In contrast
to the second model, it learns the dynamics of a push
down automaton. Both the second and third models learn
to manipulate symbol strings--a feature that
distinguishes them from prior research on similar tasks.
While DSM has many strengths, I explore several
weaknesses in the current models, most importantly
scaling issues. I conclude by discussing directions of
future research with the aim of achieving a robust
language induction system.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  3055 </NUMBER>
<ORDER>   AAI9613147 </ORDER>
<TITLE> OBJECT SCHEMAS AND PORT-BASED AGENTS FOR ASSIMILATING DISPARATE SENSORY FEEDBACK </TITLE>
<AUTHOR> NELSON, BRADLEY JAMES </AUTHOR>
<YEAR> 1995 </YEAR>
<INSTITUTION> CARNEGIE-MELLON UNIVERSITY; 0041 </INSTITUTION>
<DESCRIPTORS> ENGINEERING, MECHANICAL; COMPUTER SCIENCE; ENGINEERING, ELECTRONICS AND ELECTRICAL; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> PRADEEP K. KHOSLA </ADVISER>
<CLASSIFICATIONS> ROBOTICS, INTELLIGENT SYSTEMS </CLASSIFICATIONS>
<ABSTRACT>
This dissertation proposes and experimentally
demonstrates a framework that assimilates disparate
sensory feedback for the control of intelligent systems.
The domain is sensor-based robotic manipulation within
imprecisely calibrated and dynamically varying
environments. The sensing modalities considered are
force and vision, including a dynamically reconfigurable
vision sensor capable of changing its effective spatial
resolution as a task is executed. A framework for the
control of intelligent systems using disparate sensory
feedback has been developed by approaching this problem
from four distinct research perspectives. First, a solid
grounding in control theory based on the controlled
active vision paradigm provides a foundation for
analyzing the dynamic nature of the task and the
stability of the intelligent system that executes the
task. Second, explicit environment modeling represents
the task dynamically and provides a structure for
reasoning during task execution. Third, sensor modeling
provides an understanding of how the task is perceived
and how disparate sensors should be used during task
execution. Fourth, system complexity is addressed at a
reconfigurable systems level during framework
development in order to create a scalable and extendable
system. These perspectives are combined into a single
interdisciplinary framework. The result is a task-
oriented model-driven approach to assimilating disparate
sensory feedback in which reconfigurable systems issues
are fundamentally considered in the development of the
intelligent sensor-based system framework.
The main components of the framework are object schemas
and port-based agents. An object schema is a dynamic
internal representation of an object in the real world,
i.e. an environment model, augmented by object-sensor
mappings specific to the sensors employed in the system.
By considering the resolvability of the sensors in the
system, an object schema selects the appropriate sensor
to use at any given moment and directs variable sensor
parameters in order to increase resolvability. Port-
based agents are defined as tightly integrated control
loops that perform some action in the real world, such
as sensor reconfiguration or sensor-based object
manipulation, by accepting control directives from
object schemas. A port-based agent uses feedback control
algorithms to ensure that schema-generated control
directives are robustly executed, and that the internal
environment model is a temporally coherent
representation of the real world. Port-based agents also
ensure that object schemas do not command sensor
configurations that result in unstable manipulator
control. Object schemas and port-based agents are
defined in terms of port automata theory by explicitly
defining input and output ports, states, and mappings
for these two system components. This directly addresses
the issue of system reconfigurability by creating well-
defined modular system components that are quickly and
easily added to the system in order to increase system
capabilities. The result is a scalable and extendable
framework for assimilating disparate sensors within a
manipulation domain. (Abstract shortened by UMI.)
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  3056 </NUMBER>
<ORDER>   AAI9612855 </ORDER>
<TITLE> FORMULATION AND ANALYSIS OF INERTIAL NAVIGATION EQUATIONS FOR TERRESTRIAL NAVIGATION SYSTEMS </TITLE>
<AUTHOR> WANG, LUEN-CHENG </AUTHOR>
<YEAR> 1995 </YEAR>
<INSTITUTION> THE PENNSYLVANIA STATE UNIVERSITY; 0176 </INSTITUTION>
<DESCRIPTORS> ENGINEERING, MECHANICAL; ENGINEERING, AUTOMOTIVE; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> KATHRYN W. LILLY </ADVISER>
<CLASSIFICATIONS> NIL </CLASSIFICATIONS>
<ABSTRACT>
The primary objective of this thesis work is to develop
and apply a practical means of precisely determining the
position of fixed guideway systems (moving rail and
rubber-tire vehicles) by sensing and interpreting the
various motions of these vehicles with respect to an
inertial reference frame. For strapdown navigation
systems, the inertial navigation equations (also called
the navigator) play the role of interpreting the input
signals from accelerometer and gyro sensors to predict
the velocity and position of these vehicles.
This work focused on existing navigators and the
development of new navigators to match the goal of low
cost IMU instruments. In total, six navigators were
derived. Specifically, they are the earth-centered
frame, local-level frame, reduced earth-centered frame,
earth-surface frame, tangent and normal frame, and speed
tangent and normal frame navigators. For each of these
navigators, the following issues were also investigated:
the error model for each navigator, navigator
performance, determination and sensitivity of initial
conditions, the error effect of the Earth's angular
rate, and numerical integration methods for attitude
calculation.
From the study of arithmetic operations, we have shown
that a nine-parameter scheme is less effective than a
three-parameter (Euler angles) scheme. The computational
load for the (reduced) earth-centered frame navigator is
slightly less than the local-level frame navigator.
Also, the speed tangent normal frame navigator is the
best navigator among these navigators in terms of the
number of arithmetic operations.
The numerical integration methods provided by SIMULINK
(from Math Work Inc.) show that a fifth order Runge-
Kutta-Fehlberg method is the best among several
numerical integration methods (including a third order
Runge-Kutta-Fehlberg, the Adams, and the Gear methods).
We have also shown that the time step size of 1/75
second is appropriate for terrestrial navigation
systems.
A coarse alignment procedure is introduced in this
thesis, and the sensitivity of initialization is
analyzed. Through the sensitivity of initialization
study, a bounded attitude error formula is presented.
The error propagation for the Earth's angular rate is
also studied. The study has identified a position error
range in terms of velocity, the Earth's angular rate,
and the navigation time when modeling ignores the
Earth's angular rate. This study provides the
information needed for using high-grade sensors in a
navigator which does not model the Earth's angular rate.
The study of stability and performance for each
navigator shows that most of the navigators exhibit
unstable behavior, except the local-level frame
navigator. For the navigators which model the Earth's
angular rate, they still show the Schuler effect in the
error states. We have also compared the position errors
produced from each navigator under the same error
sources. From this investigation, we found that the
speed tangent and normal frame navigator is the best
candidate for terrestrial navigation systems. The
tangent and normal frame navigator and the earth-surface
frame navigator are the next best candidates. However,
if high-grade sensors which measure the Earth's angular
rate are used, then the earth-centered frame and/or the
local-level frame navigator are the best navigators to
be used.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  3057 </NUMBER>
<ORDER>   AAI9612827 </ORDER>
<TITLE> ADAPTIVE NEURAL NETWORK CONTROL WITH INVERSE MODEL: APPLICATION TO THE CONTROL OF TURNING PROCESS </TITLE>
<AUTHOR> SHEEN, DONGMOK </AUTHOR>
<YEAR> 1995 </YEAR>
<INSTITUTION> THE PENNSYLVANIA STATE UNIVERSITY; 0176 </INSTITUTION>
<DESCRIPTORS> ENGINEERING, INDUSTRIAL; ENGINEERING, MECHANICAL; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> SOUNDAR R. TIRUPATIKUMARA </ADVISER>
<CLASSIFICATIONS> ARTIFICIAL INTELLIGENCE </CLASSIFICATIONS>
<ABSTRACT>
This dissertation presents adaptive on-line neural
network control schemes for unknown dynamical processes
and eventually for the control of feed force in turning
process. The research consists of four tasks:
Development of a machining process model, development of
a neural network control structure and adaptation
schemes, machining experiments to collect data for
building a simulation model, and application of proposed
control schemes to turning process.
By studying the process models in the literature, a
turning process model on a CNC lathe is developed. The
proposed model is nonlinear and sampling time is
independent of spindle rpm. The characteristics of noise
and the parameters of cutting dynamics are determined by
the experimental data. To collect cutting force data, a
SAE 6150 steel is turned with 25 sets of machining
conditions on a 20HP LeBlond 1610 lathe.
The proposed adaptive inverse model (AIM) control scheme
has similar structure as the model reference adaptive
controller (MRAC). In AIM control, neural networks are
used as the system identifier and the controller. The
system identifier and the controller are first trained
off-line to be a forward model and an inverse model of
the process respectively. The off-line training is
simultaneously done for the same set of data with
different arrangements. During on-line adaptation, the
system identifier is iteratively used to convert
tracking errors into control errors and to calculate the
current and past tracking errors after changing the
weights of the controller. To be robust to noises, the
controller not only considers the current error but also
looks back to the past to minimize the "would-have-been"
tracking errors since the change in weights of the
controller would have generated different control inputs
in the past, and, in turn, different tracking error.
Two implementations of AIM controllers, using
feedforward networks and using cerebellar model
articulation controllers (CMACs), are applied to control
the feed force in turning along with an MRAC for
comparison. Simulation results show that AIM
controllers, which are designed without structural
information about the dynamics of the process, perform
comparably well with the MRAC. Especially for the
process with severe noise, AIM controller with
feedforward networks outperformed the others.
This research also provides a collective view on neural
networks in on-line process control. Real-time back-
propagation (RTB) and back-propagation through time
(BTT) learning algorithms are presented for multilayer
neural networks with internal time-delays. Convergent
CMAC learning algorithms for on-line process
identification are developed with proofs.
This research is unique in that we can design a control
system without knowing the dynamics of the process. The
proposed control system can outperform other control
techniques since it is based on neural networks, which
are noise-tolerant and can accurately represent
nonlinearity. Application of neural network-based
control schemes to the machining process is also
notable. The parallel structure of neural networks can
make integration easier with other concepts such as tool-
wear monitoring, intelligent control, and supervisory
control.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  3058 </NUMBER>
<ORDER>   AAI9612817 </ORDER>
<TITLE> DISTRIBUTED CONTROL OF AUTOMATED MANUFACTURING SYSTEMS </TITLE>
<AUTHOR> RAMASWAMY, SANJAY ELATHUR </AUTHOR>
<YEAR> 1995 </YEAR>
<INSTITUTION> THE PENNSYLVANIA STATE UNIVERSITY; 0176 </INSTITUTION>
<DESCRIPTORS> ENGINEERING, INDUSTRIAL; OPERATIONS RESEARCH </DESCRIPTORS>
<ADVISER> SANJAY B. JOSHI </ADVISER>
<CLASSIFICATIONS> SCHEDULING </CLASSIFICATIONS>
<ABSTRACT>
In this thesis, a new technique for scheduling and
control of automated manufacturing systems is developed
that integrates the Optimization and the Distributed
Artificial Intelligence approaches. Discrete time
optimization models of the shop scheduling problem are
used to structure and drive an intelligent agent based
scheduler. A two-phase approach to the problem is
presented; the first phase solves a static mathematical
programming formulation of the scheduling problem over a
finite time horizon, and the second phase uses
information from the first phase to structure a real-
time agent based scheduler. Extensions to handle the
occurrence of unplanned events such as machine
breakdowns and entry of new jobs are also considered.
Experimental studies are conducted to compare the
performance of this system with existing approaches. The
contributions of this research are the following:
The technique provides a theoretical basis for
structuring a price-based negotiation framework for
agent based shop floor control systems, assigning
meaningful utility functions to agents, and developing a
mechanism for their interaction. Bounds on the deviation
of agent based systems from theoretical optima, and the
relation of individual agent utilities to the overall
shop goal are quantified. This serves to combine the
advantages of real-time scheduling and disruption
handling with the ability to quantify and compare the
performance of the scheduling system. Finally,
experimental studies are conducted to explore the
performance of the algorithms developed and insights
into the applicability of the technique are provided.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  3059 </NUMBER>
<ORDER>   AAI9608670 </ORDER>
<TITLE> FEATURE SELECTION FOR SEGMENTATION OF MEDICAL IMAGES </TITLE>
<AUTHOR> BAKER, EVA HALLE </AUTHOR>
<YEAR> 1995 </YEAR>
<INSTITUTION> THE UNIVERSITY OF WISCONSIN - MADISON; 0262 </INSTITUTION>
<DESCRIPTORS> HEALTH SCIENCES, RADIOLOGY; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> JAMES A. SORENSEN </ADVISER>
<CLASSIFICATIONS> MRI, ARTIFICIAL INTELLIGENCE, TUMORS </CLASSIFICATIONS>
<ABSTRACT>
Segmentation attempts to divide an image into meaningful
regions, and classifiers are a common segmentation
method. Classifiers require multiple digital images of
the same scene as input. Many types of images are
available; objective selection of images to use as input
to a classifier requires a systematic method to evaluate
the contribution made by each image to answering the
question posed. This study addresses the development of
such a method.
Segmentation questions were posed by identifying pairs
of tissues that must be differentiated to produce a
meaningful segmented image. Each feature was assigned a
figure-of-merit related to its ability to distinguish
each pair, providing a basis for ranking potential input
images. The figure-of-merit was the statistical distance
between two populations, represented by operator-
designated examples of each tissue to be distinguished.
Two different tree searches, forward selection and
backward elimination, were used to rank the images.
Once the images were ranked, subsets were analysed to
predict the outcome of segmentation. The split sample
experiment can predict outcome, and several classifiers
(maximum likelihood, interactive region mapping, and
vector decomposition) were tested this way to evaluate
their performance on specific classification tasks. Such
experiments allow determination of which and how many of
the potential input images are necessary and sufficient
to address the question posed.
The method was illustrated using three practical
examples. The first examined standard screening images
(density-, T2-, and T1-weighted MRI) of ten normal
subjects. It was found that distinguishing among
different types of brain parenchyma required all three
images with approximately equal importance. Grey matter,
white matter, and CSF could be readily distinguished
using these images; however, basal ganglia were not well
distinguished from each other or from grey matter or
white matter. Among these three images, density-weighted
images were most important for distinguishing blood
vessels from brain parenchyma. The statistical distance
predicted the performance of two classifiers, maximum
likelihood and vector decomposition, as measured by the
split sample experiment.
The second example applied the method to images of
nineteen subjects with recurrent gliomas. Seven types of
images were tested for their ability to distinguish live
tumor from necrosis, edema, and normal brain; PET and
contrast-enhanced T1-weighted images were ranked as the
most important. Again, statistical distance predicted
the performance of the maximum likelihood classifier.
The third example applied the method to images of five
subjects with arteriovenous malformations. The goal was
to isolate the AVM nidus from arteries, veins, and
parenchyma. Density-weighted MRI and time-of-flight MRA
were selected as input to segmentation by two-
dimensional interactive region mapping. It was found
that success depended on the disease pattern; the nidus
could be isolated by classifier alone in cases having
the classic pattern of rapid flow in the feeders,
moderate non-turbulent flow in the nidus, and slow flow
in the drainers. However, even an image in which the
classifier merely identified vessels provided useful
additional information for radiosurgery planning. This
example showed that although statistical distance is
probability-based, it predicts the performance of a non-
probabilistic classifier.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  3060 </NUMBER>
<ORDER>   AAI0576906 </ORDER>
<TITLE> INTERPRETIVE INSTRUMENTATION: AN APPLICATION TO REAL TIME AUTOMATIC DETECTION OF MYOCARDIAL ISCHAEMIA USING ELECTROCARDIOGRAPHIC PARAMETERS </TITLE>
<AUTHOR> OATES, JOHN DAVID </AUTHOR>
<YEAR> 1995 </YEAR>
<INSTITUTION> UNIVERSITY OF NEW SOUTH WALES (AUSTRALIA); 0423 </INSTITUTION>
<DESCRIPTORS> ENGINEERING, BIOMEDICAL; ENGINEERING, ELECTRONICS AND ELECTRICAL </DESCRIPTORS>
<ADVISER> NIL </ADVISER>
<CLASSIFICATIONS> NIL </CLASSIFICATIONS>
<ABSTRACT>
The usefulness of the electrocardiogram in the
evaluation of patients potentially suffering from
episodes of myocardial ischaemia has been reduced by two
major problems. The first was the large amount of
tedious work involved for highly paid experts to review
the often large amounts of data associated with lengthy
ECG monitoring sessions. This problem was interpreted as
a need to develop the equipment and algorithms necessary
to implement an ECG machine capable of real time
automated detection of ischaemic episodes. The second
problem is the unreliable nature of the interpretation
techniques currently employed to classify the ECG data.
This problem is related to the first as the more
clinically useful information that can be extracted from
the ECG, the more reliable will be any algorithm
implemented to defect ischaemia.
A versatile and reconfigurable measurement instrument
was developed capable of calculating many parameters
from the ECG in real time. This machine collected three
channels of ECG simultaneously and transformed them into
the corrected Frank lead vectorcardiogram. The
instrument was used to collect ECG data from patients
undergoing Percutaneous Transluminal Coronary
Angioplasty. Episodes of coronary occlusion due to
balloon inflation were recorded with the ECG and
parameters measured from the data. The data from each
test was reviewed by a cardiologist and classified as
corresponding either to an ischaemic or non-ischaemic
episode with a ten second resolution. The classified
data was then used to generate decision tree algorithms
using an artificial intelligence technique called ID3.
The parameterisation of the ECG included parameters
based on the ST segment, which, to date has almost
exclusively been used to indicate episodes of myocardial
ischaemia, and parameters based on the planarity of the
vectorcardiographic QRS loop. Although it has been known
for many years that the QRS loop of normal patients lays
essentially within a single plane this planarity has
never previously been employed to observe the possible
depolarization anomalies associated with myocardial
ischaemia. The normal limits of QRS loop planarity are
established in this project by first defining a
normalized parameter and then calculating its 99%
confidence interval using a large number of QRS loops
from many subjects. The same parameter is then used to
show a reduction in planarity for patients suffering
episodes of myocardial ischaemia.
It is concluded that the automated detection of
myocardial ischaemia using advanced measurement
instrumentation and artificial intelligence is feasible.
Furthermore the value of the ECG for evaluating patients
with episodes of myocardial ischaemia can be enhanced by
including parameters based on the planarity of the QRS
loop in conjunction with ST segment parameters.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  3061 </NUMBER>
<ORDER>   AAG9636709 </ORDER>
<TITLE> A NEURAL CODE FOR FACE REPRESENTATION: FROM V1 RECEPTIVE FIELDS TO IT 'FACE' CELLS </TITLE>
<AUTHOR> FELLOUS, JEAN-MARC </AUTHOR>
<YEAR> 1995 </YEAR>
<INSTITUTION> UNIVERSITY OF SOUTHERN CALIFORNIA; 0208 </INSTITUTION>
<DESCRIPTORS> COMPUTER SCIENCE; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> MICHAEL A. ARBIB </ADVISER>
<CLASSIFICATIONS> OBJECT RECOGNITION, ARTIFICIAL INTELLIGENCE </CLASSIFICATIONS>
<ABSTRACT>
In this dissertation, I present a computer modeling
study of part of the 'what' (or form) visual pathway
(V1, V2/V4, IT/STP). I use an information theoretic
approach to propose ways in which in the responses of V1
simple cells can be combined to yield higher levels of
description of the visual inputs. This method allows for
the derivation of 'shape selective' cells, end-stopped
and 'spot' cells, and provides a partial explanation for
the nature of horizontal connections in V1. I then
derive a neural code on the basis of which I describe
objects such as faces. This code is sparse when applied
to facial features (eyes, noses...) and combinatorial
when applied to the whole face. The behavior of this
code when presented with distorted face images is
compared to neurophysiological findings on 'face-
selective' cells.
In a second part of the study, I show that facial
information such as gender and emotional expression can
be extracted with good accuracy, on the basis of the
configuration of a certain set of facial points. These
points differ depending on which information is to be
extracted, and therefore form different codes for
different aspects of the face (identity, gender,
expression...). Neurophysiological correlates are
presented to support the view that these codes might be
built/maintained by distinct brain structures: IT for
facial identity, STP/Amygdala for facial expression.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  3062 </NUMBER>
<ORDER>   AAI0576902 </ORDER>
<TITLE> THE EVALUATION OF THE APPLICABILITY OF ARTIFICIAL INTELLIGENCE SOFTWARE TO SOLVING PROBLEMS IN ION CHROMATOGRAPHY </TITLE>
<AUTHOR> MULHOLLAND, MARY </AUTHOR>
<YEAR> 1995 </YEAR>
<INSTITUTION> UNIVERSITY OF NEW SOUTH WALES (AUSTRALIA); 0423 </INSTITUTION>
<DESCRIPTORS> CHEMISTRY, ANALYTICAL; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> NIL </ADVISER>
<CLASSIFICATIONS> EXPERT SYSTEMS </CLASSIFICATIONS>
<ABSTRACT>
The initial goal of the work described in this thesis
was to build an expert system (ES) for ion
chromatography (IC). Work began by coding some rules for
the separation mechanism of ion-interaction. The first
rules were programmed using the ES development tool Xi
Plus. The limitations of this tool quickly became clear;
it had no facilities such as frames or other advanced ES
features. Level 5 object was then purchased and a
working system was developed for the ion-interaction
mechanism. During this time knowledge was collected by
interviewing the expert and also by using information in
a previously compiled database of IC methods taken from
the published literature. At this stage it was realised
that the database could be used in a more formal way by
applying algorithms developed for automatic machine
learning and the Ripple down Rules (RDR) ES tool.
Several modifications to both the machine learning
algorithms and RDR were required to make them suitable
for the IC domain. Some of these were carried out by the
author and became a fundamental part of this research,
most notably the development of techniques for the
application of RDR to configuration problems. Several
machine learning algorithms were evaluated and INDUCT
was selected to perform the task of configuring rules
for the IC domain. Throughout this research it became
clear that many fundamental areas needed to be
considered when applying the techniques of AI, these
included philosophy, psychology and neural anatomy.
These issues are discussed throughout this thesis. It
also became one of the goals to establish to what extent
AI can provide for the encapsulation of real scientific
expertise and this is discussed in the conclusions to
this work.
The project resulted in the development of an ES for IC
which has performed successfully over a variety of
validation studies. Over 90% of the methods suggested by
the ES would work well in practice.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  3063 </NUMBER>
<ORDER>   AAI0576848 </ORDER>
<TITLE> A HANDWRITTEN CAPITAL LETTER RECOGNITION SYSTEM INCORPORATING CRITICAL FEATURE PATTERN DETECTORS AND ARTIFICIAL NEURAL NETWORKS  </TITLE>
<AUTHOR> TSIE, TJIEN SEN </AUTHOR>
<YEAR> 1995 </YEAR>
<INSTITUTION> UNIVERSITY OF NEW SOUTH WALES (AUSTRALIA); 0423 </INSTITUTION>
<DESCRIPTORS> COMPUTER SCIENCE; INFORMATION SCIENCE; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> NIL </ADVISER>
<CLASSIFICATIONS> ARTIFICIAL INTELLIGENCE </CLASSIFICATIONS>
<ABSTRACT>
This thesis develops a new type of handwritten capital
letter recognition system based on several biological
facts. Tanaka, et.al., 1991 (ch.l, ref.8), found that
inside the inferotemporal cortex of the Macaque monkey
there exist many complex pattern detectors which detect
important parts of the image of an object and thus it
may be inferred that combinations of the active cells
inside that region of the brain code the shape of
objects. Moreover, Spinelli, et.al., 1972 (ch.2,
ref.44), discovered the importance of basic knowledge
for detecting simple patterns (horizontal, vertical or
oriented bars of light), which were "built" in early
stages of life in the kittens' striate cortex, and that
the lack of these basic pattern detector cells may
impair the adult human visual perception ability,
Gregory, 1977, (ch.2, ref.24). Furthermore, eye movement
experiments conducted by Yarbus, 1967, (ch.2, ref.51),
revealed that the human eye will only stop scanning on
several spots on the image which are considered to
contain important information (critical features) of
that image. All of these concepts directed the
development of the system described in this thesis.
A handwritten capital letter consists of several basic
feature patterns with possibly several different letters
sharing the same features and the combination of those
features forming the shape of a letter. In the
handwritten capital letter recognition system described
in this thesis, Kohonen's LVQ subsystem decomposes a
letter into its feature patterns by scanning its
receptive field over that letter. This mechanism is
based on the combination of the concepts for human eye
movement and complex pattern detectors in the
inferotemporal cortex of the Macaque monkey. The
combination of the features extracted from a letter is
given to a three layer neural network trained with a
modified backpropagation learning algorithm. Thus this
network learns the combination of features in each
letter. Two stages of learning occur in this system,
firstly, the training of Kohonen's LVQ on letter
features providing the system with early basic knowledge
of critical features and secondly, the training of a
three layer neural network with the combinations of
critical features of the letters.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  3064 </NUMBER>
<ORDER>   AAI0576821 </ORDER>
<TITLE> INTERACTIVE REACTIVE SCHEDULING OF AN UNBALANCED PRODUCTION LINE BY HUMAN LEARNING AND MACHINE INDUCTION </TITLE>
<AUTHOR> KIBIRA, DEOGRATIAS </AUTHOR>
<YEAR> 1995 </YEAR>
<INSTITUTION> UNIVERSITY OF NEW SOUTH WALES (AUSTRALIA); 0423 </INSTITUTION>
<DESCRIPTORS> OPERATIONS RESEARCH; ARTIFICIAL INTELLIGENCE; ENGINEERING, INDUSTRIAL </DESCRIPTORS>
<ADVISER> NIL </ADVISER>
<CLASSIFICATIONS> ARTIFICIAL INTELLIGENCE </CLASSIFICATIONS>
<ABSTRACT>
This thesis investigates the construction of an
automated interactive scheduling system for allocating
labour to various workstations in a dynamic production
line environment given start-of-shift buffer stocks,
target buffers and volume throughput. Unlike most
scheduling research which seeks to formulate methods of
finding optimal solutions to different classes of
scheduling problems, thereby increasing the body of
scheduling theory, this research principally uses
techniques already available and investigates an
approach using rule induction for building practical
automated schedulers. This research is based on
experience from a real life telephone manufacturing
plant. However, detailed experiments are performed in a
simulated environment.
Under idealised steady state conditions, a deterministic
scheduler based on flow rates (henceforth called the
"Capacity Allocator") computes optimal labour placement.
Experiments with a simulation model of a real life plant
however, show that the schedules based on deterministic
conditions are not effective in achieving manufacturing
objectives.
Human learned heuristics are shown to schedule the line
better than the capacity allocator. An inductive
inference tool derives a set of rules from human
supplied examples which are subsequently used for
automated rescheduling. The resulting automated
scheduler performs in a manner similar to the human
subject who supplied the training set from which the
rules were induced, and as such, performs better than
the capacity allocator. The rules were derived using
linguistic variables and implementation on a computer is
done using two methods. One setting uses numerical
values which describe the ranges of values of a
linguistic variable while the second method views the
scheduling task as a control problem and uses fuzzy sets
and fuzzy logic which improves rule performance.
This thesis contributes to research in scheduling
unbalanced production lines, which has been relatively
lacking. It also gives insights into using a human
subject to use simulation model of a system to acquire
skills for scheduling and the transfer of these skills,
acquired and conceived in linguistic rules, into an
automated scheduler. The results obtained can inspire
research into the use of this experience to automate
scheduling in different environments and to other
processes found in process control industries.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  3065 </NUMBER>
<ORDER>   AAI0576805 </ORDER>
<TITLE> INTELLIGENT CONTROL TECHNIQUES FOR FEEDBACK CONTROLLER TUNING APPLICATIONS </TITLE>
<AUTHOR> CHAN, KA CHING </AUTHOR>
<YEAR> 1995 </YEAR>
<INSTITUTION> UNIVERSITY OF NEW SOUTH WALES (AUSTRALIA); 0423 </INSTITUTION>
<DESCRIPTORS> ENGINEERING, INDUSTRIAL; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> NIL </ADVISER>
<CLASSIFICATIONS> ARTIFICIAL INTELLIGENCE </CLASSIFICATIONS>
<ABSTRACT>
The investigation of intelligent control techniques and
their applications to the development of intelligent
systems for tuning feedback controllers are presented in
this thesis. The system consists of four main building
blocks, namely, the open-loop process characterisation
module, the control algorithm selection and initial-gain
setting module, the multiple criteria performance
evaluation module, and the intelligent tuning system.
The open-loop process characterisation module is
implemented to identify two parameters: the normalised
dead-time and the normalised process gain, for both
stable and unstable processes. A fast technique is
developed to extract these parameters from open-loop
step responses based on extensive numerical experiments.
According to these parameters, suitable control
algorithms are chosen by the control algorithm selection
and initial-gain setting module. Ziegler-Nichols tuning
rules are then applied to set initial controller gains.
The multiple criteria performance evaluation module is
developed to provide feedback information about the
shapes and sizes of response curves for the intelligent
tuning system to make appropriate gain adjustments. A
multiple criteria model using fuzzy membership functions
is proposed for the measurement and evaluation of
performance of feedback controllers.
Neural networks are employed in the intelligent tuning
system. Tuning knowledge is extracted automatically
through the use of a representative process. The neural
network tuner has been successfully tested using several
processes covering a wide range of process dynamics.
However, due to the disadvantage of neural networks that
it is difficult to incorporate structured linguistic
knowledge, an attempt is made to develop an integrated
neural-fuzzy system. The neural-fuzzy approach has
succeeded in combining human tuning knowledge with the
automatically extracted numerical knowledge, but the
long training time requirement of neural networks
remains as the major bottleneck in the system. A logical
extension is to develop a more efficient learning
algorithm to replace the neural network. Therefore, a
new adaptive algorithm, based on a new concept, called
virtual fuzzy set, is developed.
The virtual fuzzy set concept, which is incorporated
into the adaptive algorithm, provides a more accurate
representation of a fuzzy production rule. The algorithm
is a one-pass build-up procedure and time consuming
iterative training is not required. The proposed method
has been applied to the fuzzy modelling of a difficult
non-linear system. The results showed that the new
algorithm has better performance than previous
approaches. Furthermore, the adaptive algorithm has been
verified by its successful application to feedback
controller tuning.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  3066 </NUMBER>
<ORDER>   AAINN03613 </ORDER>
<TITLE> ACTIVE CHATTER CONTROL TECHNIQUES IN PERIPHERAL MILLING </TITLE>
<AUTHOR> SOLIMAN, ESSAM </AUTHOR>
<YEAR> 1995 </YEAR>
<INSTITUTION> UNIVERSITY OF WATERLOO (CANADA); 1141 </INSTITUTION>
<DESCRIPTORS> ENGINEERING, MECHANICAL; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> F. ISMAIL </ADVISER>
<CLASSIFICATIONS> FUZZY LOGIC CONTROLLERS, MACHINING </CLASSIFICATIONS>
<ABSTRACT>
The research work presented in this thesis tackles
different aspects of the chatter control problem in
peripheral milling. These aspects include chatter
detection, suppression, and avoidance.
A new method for detecting chatter is introduced. The
method is based on using the spindle drive current
signal, an application that has been thought not
possible by researchers in the field due to the limited
bandwidth. Different chatter detection signals are
compared based on their capabilities and sensitivities.
Comparisons include the acceleration, sound, and cutting
force signals, as well as the current signal.
Statistical methods are used for analyzing experimental
data. The current signal was proven to have a high
sensitivity to chatter development. Also, it had the
maximum signal to noise ratio. This makes it a preferred
signal, overall, for chatter detection in industrial
applications.
Two fuzzy logic controllers, proportional and
proportional derivative, are designed to select
combinations of amplitude and frequency of spindle speed
modulation based on a measure of process instability,
the R-value. The implementation aspects of the
controllers are addressed. The performance of the
controllers is compared with that of a bang-bang
controller. The effects of the cutting parameters on the
controllers' performance are investigated using
statistical methods, and discussed using the stability
chart of the milling process. The analysis of variance
of experimental data indicated that the increase in the
immersion adversely affects the controllers' performance
while other cutting parameters have no significant
effect. Also, the interaction of the spindle speed and
the geometry of cut was shown to have a significant
effect on the controllers' performance. By analyzing
experimental data using the stability chart of half
immersion down milling, it was found that the
controllers' performance was dependent on the position
of the operating point with respect to stability lobes.
Experimental data and simulations showed that the delay
time of the control action degraded the controllers'
performance. An advanced interface card is necessary to
solve this problem.
A new method for identifying the locations of stability
lobes is introduced. The method depends on ramping the
spindle speed while observing the pattern of the R-
value. A control system for avoiding chatter in
peripheral milling is developed and implemented. The
system ramps the spindle speed when chatter is detected.
Based on the fluctuations in the R-value, the system
selects a favourable spindle speed at which chatter
ceases or the degree of system instability decreases.
The system was tested under different cutting
conditions. Experimental results showed that this system
is very successful in both avoiding chatter and
alleviating its effects, and reducing the degree of
system instability.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  3067 </NUMBER>
<ORDER>   AAINN03593 </ORDER>
<TITLE> KNOWLEDGE REORGANIZATION IN RULE-BASED SYSTEMS </TITLE>
<AUTHOR> LOPEZ-SUAREZ, ALEJANDRO </AUTHOR>
<YEAR> 1995 </YEAR>
<INSTITUTION> UNIVERSITY OF WATERLOO (CANADA); 1141 </INSTITUTION>
<DESCRIPTORS> COMPUTER SCIENCE; ARTIFICIAL INTELLIGENCE; INFORMATION SCIENCE </DESCRIPTORS>
<ADVISER> M. KAMEL </ADVISER>
<CLASSIFICATIONS> ARTIFICIAL INTELLIGENCE, MACHINE LEARNING </CLASSIFICATIONS>
<ABSTRACT>
This thesis proposes that the dynamic reorganization of
knowledge will improve the operation of an intelligent
system. Knowledge reorganization is defined as the
transformation of existing knowledge to make it more
useful or easily usable. The thesis presents a formal
specification of the knowledge reorganization problem
and an approach to its solution. Reorganization is
investigated in the context of problem solving systems
which use rules to represent knowledge. Reorganization
of knowledge is attained through the application of
deductive learning algorithms and consists of structural
changes performed on selected groups of rules.
The approach for reorganizing knowledge dynamically
satisfies two major objectives: performance improvement
and comprehensibility. The attainment of performance
gains is essential to make knowledge based systems
acceptable in industrial applications. The development
of knowledge bases that are understandable to humans is
an equally important problem for several reasons
including the maintenance of these systems and the
generation of explanations.
The research conducted is an extension of machine
learning techniques that perform deductive learning on
existing knowledge. Specifically, the knowledge
reorganization tools developed utilize Explanation-Based
Learning and Abstraction to transform the structure of
knowledge, and Conceptual Clustering as a restoration
technique. The methodology proposed includes mechanisms
to restructure knowledge to improve its use during
problem solving, algorithms to detect and control
redundancy, and the automatic generation of logical
groups of rules. The effect of knowledge transformations
is evaluated analytically and experimentally.
Experiments are carried out using the DyKOr (Dynamic
Knowledge Reorganization) software developed for this
research and CLIPS, a commercially available rule based
system.
The work presented is directly applicable to expert and
other types of problem solving systems that specify
knowledge through rules of inference and use the
production model of inferential reasoning.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  3068 </NUMBER>
<ORDER>   AAINN03125 </ORDER>
<TITLE> A MULTI-VALUED EPISTEMIC LOGIC </TITLE>
<AUTHOR> SIM, KWANG MONG </AUTHOR>
<YEAR> 1995 </YEAR>
<INSTITUTION> UNIVERSITY OF CALGARY (CANADA); 0026 </INSTITUTION>
<DESCRIPTORS> COMPUTER SCIENCE </DESCRIPTORS>
<ADVISER> MILDRED SHAW </ADVISER>
<CLASSIFICATIONS> LOGICAL OMNISCIENCE, DEGREE OF BELIEF </CLASSIFICATIONS>
<ABSTRACT>
In the last decade there has been a resurgence of work
on epistemic logic in artificial intelligence to
alleviate the problem of logical omniscience. Among them
were the logic of implicit and explicit belief and the
logic of awareness. Although these logics have surface
dissimilarities, a closer examination shows that they
have strong resemblance. In this research, I consider a
multi-valued epistemic logic (MEL) which has a unifying
semantics that subsumes the semantics of several
existing epistemic logics. This formulation is based on
the realization that epistemic notions such as implicit
belief, explicit belief and awareness can be modeled by
restricting the truth assignments of atomic sentences to
subsets of truth values in a bilattice. A bilattice is a
structure that can be viewed as a class of truth values
that can accommodate incomplete and inconsistent
information. In bilattice theory, formulas are ordered
along two dimensions: truth/falsity and
certainty/uncertainty. Subsequently, by adopting a
bilattice interpretation, the issue of representing
degree of belief can also be addressed. Most of the
previously proposed logic for reasoning about knowledge
characterize an agent's knowledge base with the two
absolute notions of total belief and total disbelief.
Unfortunately, restricting to such a dichotomy limits
the expressiveness of these logics. In MEL, beliefs of
agents are associated with a degree of truth and a
degree of certainty. Additionally, this research
investigates the issue of employing a model-theoretic
approach for examining the validity and provability of
sentences in the logic. In particular, it is shown that
the validity and provability of a sentence in MEL can be
checked in a finite number of steps. This rests on the
fact that not only is MEL determined by (or sound and
complete with respect to) a class of models, but it is
also determined by a class of finite models and there is
an algorithm to examine if a sentence is true in these
models. A polynomial time model-checking algorithm for
determining the satisfiability of a sentence at a
particular state in a given model of MEL and for
computing the associated degree of truth and degree of
certainty of the sentence is also presented. In outline,
this dissertation presents a multi-valued epistemic
logic that not only has a sound and complete
axiomatization and is decidable, but also (i) has a
general semantics for representing belief, (ii) provides
a means to represent degree of belief and (iii) adopts a
model-theoretic approach for characterizing belief.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  3069 </NUMBER>
<ORDER>   AAINN03114 </ORDER>
<TITLE> INSTRUCTIBLE AGENTS </TITLE>
<AUTHOR> MAULSBY, DAVID LAWRENCE </AUTHOR>
<YEAR> 1995 </YEAR>
<INSTITUTION> UNIVERSITY OF CALGARY (CANADA); 0026 </INSTITUTION>
<DESCRIPTORS> COMPUTER SCIENCE; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> IAN H. WITTEN </ADVISER>
<CLASSIFICATIONS> MACHINE LEARNING </CLASSIFICATIONS>
<ABSTRACT>
This dissertation explores the design of inference and
interaction methods that would enable end users to teach
a computer the characteristic, discriminating features
of a set of data. The envisaged application is an agent
that learns to select and edit data, or to observe and
maintain relationships between data. Users would teach
by giving examples, hints and partial specifications.
The work described here develops design requirements,
implements inference and interaction techniques, and
gathers empirical data on their usability. The research
method interleaves analysis, implementation and user
testing.
Chapter 1 motivates the research with a detailed worked
example. It defines design goals and functional
requirements, on which previous work in machine learning
and programming by demonstration is assessed, revealing
that no system enables users to teach concepts in a rich
representation by giving both examples and ambiguous
hints.
Chapter 2 presents empirical data on methods of
instruction which users readily adopt to teach a
computer agent. A preliminary, underspecified design is
simulated manually. A diverse group of users
consistently develop similar sets of commands, and learn
the agent's language from its verbal feedback.
Chapter 3 explains the use of dynamic bias to reduce the
complexity of concept learning, and shows how
instructions from a teacher (the user) can direct the
bias. The result is a formal model of instruction based
on classifying examples, hints and rules.
Chapter 4 describes interaction techniques for teaching
and controlling an agent, suitable for use in direct
manipulation and menu-based interfaces. These techniques
are iteratively designed and user tested in prototypes
ranging from slideshows to partial implementations.
Chapter 5 implements the first concept learning system
whose dynamic bias enables it to learn from examples,
ambiguous hints and partial specifications. Using
multiple heuristics, it can choose the most justified
interpretation of hints, and find plausible alternatives
in case instructions are erroneous. When evaluated on
tasks from the study in Chapter 2, the implemented
system rivals the simulated agent's ability to learn
from examples and hints.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  3070 </NUMBER>
<ORDER>   AAI9616119 </ORDER>
<TITLE> A METHODOLOGY AND OPERATIONALIZATION FOR ACQUIRING KNOWLEDGE FROM MULTIPLE EXPERTS </TITLE>
<AUTHOR> MATHIYALAKAN, SATHASIVAM </AUTHOR>
<YEAR> 1995 </YEAR>
<INSTITUTION> UNIVERSITY OF KENTUCKY; 0102 </INSTITUTION>
<DESCRIPTORS> BUSINESS ADMINISTRATION, GENERAL; ARTIFICIAL INTELLIGENCE; PSYCHOLOGY, INDUSTRIAL </DESCRIPTORS>
<ADVISER> JAMES R. MARSDEN </ADVISER>
<CLASSIFICATIONS> EXPERT SYSTEMS </CLASSIFICATIONS>
<ABSTRACT>
When there are multiple experts in an organization, or
when a system development project requires the use of
multiple experts, there is a need to determine the
better group size for knowledge acquisition, as the
group size may affect the quality of knowledge elicited.
The primary theme of this research effort is to
investigate issues relating to the capabilities of
groups of different sizes in developing expert systems
dealing with decision making tasks. Our research
methodology is organized into two stages. In the first
stage subjects act alone and our purpose is to select
candidates for subsequent group sessions. In the second
or group stage, we study the relationships among group
size, decision rules, availability of what-if
capability, change in group membership, performance,
decision time, productivity and satisfaction.
A key feature of our study is the use of market
conditions, that is the use of performance based rewards
along with system usage costs. To achieve our research
objectives we develop programs written in the C
language, one in stand-alone mode for the individual
setting and one in network mode for the group setting.
Prototyping, a system development technique is used to
design the experimental screen, software and to set
experimental parameters. A senior officer from a leading
bank, faculty members and volunteer students provided
significant help during the system development phase.
Our subject pool consists of student subjects and bank
personnel.
There are two major findings in this study, both of
which can serve as recommendations for practitioners.
First, we note that using a market approach subjects are
able to provide a realistic assessment on the nature and
value of the support provided. Second, we find no
dominant group size. We find that each group size that
we examine has its benefits and drawbacks. Finally, we
identify issues that a Knowledge Engineer needs to
consider in selecting a group size for use in rule set
development for building an expert system that provides
decision making support.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  3071 </NUMBER>
<ORDER>   AAI9615865 </ORDER>
<TITLE> COMPARING AN EXPERT SYSTEM VS TRADITIONAL APPROACH TO FORECASTING ITEM DEMAND IN A DISTRIBUTION INVENTORY ENVIRONMENT </TITLE>
<AUTHOR> PEARCE, STEPHEN L. </AUTHOR>
<YEAR> 1995 </YEAR>
<INSTITUTION> TEXAS A&M UNIVERSITY; 0803 </INSTITUTION>
<DESCRIPTORS> BUSINESS ADMINISTRATION, GENERAL; INFORMATION SCIENCE; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> BENITO FLORES </ADVISER>
<CLASSIFICATIONS> NIL </CLASSIFICATIONS>
<ABSTRACT>
This research developed and tested an expert forecasting
system using the C Language Integrated Production System
(CLIPS) expert system shell. CLIPS allows the
representation of expert knowledge as rules and allows
the use of the object-oriented design paradigm. The
testing of the expert system was undertaken under
realistic business conditions using actual item demand
data and an experienced human user. This research
focused on the forecasting of inventory demand by a
company providing a diverse range of industrial products
to selling locations from a regional warehouse.
A central issue explored by this research is whether or
not the expert forecasting system can be used in a
business environment to automatically generate forecasts
for inventory items that will be at least as accurate as
those generated by the forecasting system currently
being used by the company participating in the test. In
this study, none of the differences in forecasting
accuracy among the various forecasting methodologies
used were significant. However, the expert system's
forecasting accuracy was better than that of the test
company's in many comparisons. This may validate the
expert system approach to forecasting.
The expert system is constructed in such a way that the
business user is able to specify that a particular
forecasting method be used for a particular item or to
alter the numerical forecast values generated by the
expert forecasting system. In addition, the business
user was allowed to select a forecasting method and then
alter the numerical forecast values generated by that
method. In this study, user input to the forecasting
process did not create significantly better forecasting
accuracy. However, in many cases in this study, the
user's input resulted in the avoidance of large absolute
forecasting errors and underforecasting.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  3072 </NUMBER>
<ORDER>   AAGNN16259 </ORDER>
<TITLE> POLYMORPHIC COMPUTING PARADIGMS REALIZED FOR A FPD BASED MULTICOMPUTER  </TITLE>
<AUTHOR> ROSENDAHL, GLENN KENTON </AUTHOR>
<YEAR> 1995 </YEAR>
<INSTITUTION> THE UNIVERSITY OF MANITOBA (CANADA); 0303 </INSTITUTION>
<DESCRIPTORS> ENGINEERING, ELECTRONICS AND ELECTRICAL; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> ROBERT MCLEOD </ADVISER>
<CLASSIFICATIONS> PARALLEL PROCESSING, FIELD PROGRAMMABLE DEVICES, ARTIFICIAL NEURAL NETWORK </CLASSIFICATIONS>
<ABSTRACT>
In general, parallel processing has not gained wide
acceptance to date, due to many problems associated with
cost, design effort, and a limited scope of application.
Many of these problems are related to the rigid nature
of hardware architecture, which prevents systems from
conforming to diverse application needs. The present
thesis defines a flexible parallel architecture based on
a large number field programmable devices, which enables
a wider application scope through architectural
flexibility. Several application architectures are
presented, demonstrating control flow, data driven,
demand driven, and hybrid computing paradigms.
A design method for Xilinx 3000 series field
programmable logic arrays is presented. This method is
hierarchical in construction and enables the rapid
prototyping and design of register transfer sequences.
Further, a method for expanding designs beyond chip
boundaries is also presented.
Two neural network applications are discussed and the
Kohonen self-organizing feature map is implemented on
the present architecture. A network of 588 nodes is
executed with network solution times of 2.616ms and
1.368ms per input sample for one and two processors
respectively.
Field programmable devices can be an invaluable resource
to multicomputers and large systems in general. As a
result of this study of large system designs, a number
of practical and interesting issues related to field
programmable devices have been described, including
design practices, testing, and architectural
flexibility.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  3073 </NUMBER>
<ORDER>   AAGNN11061 </ORDER>
<TITLE> INCREMENTAL COMMUNICATION FOR ARTIFICIAL NEURAL NETWORKS </TITLE>
<AUTHOR> GHORBANI, ALI AKBAR </AUTHOR>
<YEAR> 1995 </YEAR>
<INSTITUTION> THE UNIVERSITY OF NEW BRUNSWICK (CANADA); 0823 </INSTITUTION>
<DESCRIPTORS> ENGINEERING, SYSTEM SCIENCE; COMPUTER SCIENCE; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> V. C. BHAVSAR </ADVISER>
<CLASSIFICATIONS> FEEDFORWARD </CLASSIFICATIONS>
<ABSTRACT>
The large number of nodes and interconnections that
comprise an artificial neural network (ANN) makes ANNs
inherently computation and communication intensive. A
new method of inter-neuron communication named the
incremental communication method is proposed to minimize
communication costs. In the incremental communication
method instead of communicating the whole value of a
variable, only the increment or decrement of its
previous value is sent on a communication link. The
variable precision scheme, which can be implemented in
either hardware or software, can further reduce the
complexity of intercommunication and speed up the
computations in massively parallel computers that have
variable precision (e.g., bit, 4-bit nibble, or byte
level) processing capabilities.
Multilayer feedforward neural networks architectures are
used to illustrate the effectiveness of the proposed
communication scheme. A simulator is developed using the
C programming language to implement the standard error
backpropagation learning algorithm as well as some of
its variations. It is shown that for some problems even
4-bit precision in fixed--as well as floating--point
representations is sufficient for the network to
converge. With 8-12 bit precisions almost the same
results are obtained as that with the conventional
communication using 32-bit precision.
A precision assignment strategy is developed to assign
precision to the incremental values as learning
progresses. This scheme is applied to multilayer
perceptrons (MLP) and simulation studies are carried out
on various learning problems. The simulation results
show more than 40% saving in the communication costs
using the variable precision scheme.
Mathematical and statistical models are used to
investigate the effects of limited precision incremental
communication method on the convergence behavior and
performance degradation of MLPs. It is shown that the
nonlinear effect of small perturbation in the
input(s)/output of a node does not enforce instability.
However, when the precision of the incremental values
falls below a certain level, the network fails to
converge.
Many of the methods of parallelizing the process of
learning in the MLP network are found to be extremely
communication intensive. It is shown that the
incremental communication method decreases the cost of
interconnection and intercommunication by an amount
directly proportional to the number of interconnections
and inversely proportional to the precision used.
The incremental communication method is aimed at
reducing the communication complexity of artificial
neural networks by limiting the node's input/output
bandwidth requirements. It is primarily intended to be
incorporated into the continuous neural models. However,
the concept of incremental inter-node communication is
also applicable to many of the current learning
algorithms in which inter-neuron communications are
required. Moreover, it can be used along with the other
limited precision strategies for representation of
variables suggested in the literature. The proposed
method of communication can lead to significant savings
in the intercommunication cost for implementations of
artificial neural networks on parallel computers as well
as the interconnection cost of direct hardware
realizations. (Abstract shortened by UMI.)
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  3074 </NUMBER>
<ORDER>   AAI9615665 </ORDER>
<TITLE> MODELING HEALTH CARE FOR COST CONTAINMENT: A DECISION SUPPORT SYSTEM COMPARING MULTIVARIATE TECHNIQUES AND ARTIFICIAL NEURAL SYSTEMS </TITLE>
<AUTHOR> MORRISON, JOYCE ANN </AUTHOR>
<YEAR> 1995 </YEAR>
<INSTITUTION> THE UNIVERSITY OF MISSISSIPPI; 0131 </INSTITUTION>
<DESCRIPTORS> BUSINESS ADMINISTRATION, MANAGEMENT; HEALTH SCIENCES, HOSPITAL MANAGEMENT; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> JOHN D. JOHNSON </ADVISER>
<CLASSIFICATIONS> NIL </CLASSIFICATIONS>
<ABSTRACT>
This country is currently facing a crisis in health care
due to escalating costs. Curtailing these spiraling
costs has become a focal point for many health care
managers. Previously, there have been few studies on
predicting treatment costs. This is due in part to the
inadequacy of computer technology necessary to isolate,
aggregate, and model large volumes of patient
information. As the price of health care continues to
rise, modern technology must provide answers to
questions that were unasked earlier. Fortunately, the
1990's have brought us the technology to process and
model patient data into useful information that can
become a valuable resource in the business of health
care.
This research focuses on postmenopausal women as a study
group. This group was chosen for two reasons: First, due
to increased life expectancy, women now live over one
third of their life in postmenopausal years, and with
these years comes a myriad of health problems. Secondly,
one proposed solution to this problem is the
prescription of conjugated estrogens, now one of the
most frequently dispensed pharmaceuticals in the United
States. The impact of estrogen replacement therapy on
the reduction of total treatment costs will be measured.
In order to validate the construction of cost models,
this research will examine two very large medical
databases, Mississippi Medicaid and The Prudential
Health. By using the claims data of postmenopausal
women, this study will evaluate data modeling techniques
and propose a decision support tool for health care
managers. Two highly complex and powerful statistical
procedures are proposed as methodologies for this
prediction model: stepwise multivariate regression and
Artificial Neural Systems (ANS). The predictive accuracy
of these two diverse techniques is presented within a
comprehensive, mathematically sound framework.
The results of this research offer a new decision
support instrument for health care managers. Heretofore,
medical science alone has charted pathways to health.
Now information science enables us to use the
retrospective clinical data to both predict and possibly
improve the future through estimating and reducing the
cost of health care.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  3075 </NUMBER>
<ORDER>   AAI9615655 </ORDER>
<TITLE> A COMPARATIVE STUDY OF ARTIFICIAL NEURAL NETWORKS AND MULTINOMIAL LOGIT FOR THE ESTIMATION OF DISCRETE CHOICE </TITLE>
<AUTHOR> FISH, KELLY ESSON </AUTHOR>
<YEAR> 1995 </YEAR>
<INSTITUTION> THE UNIVERSITY OF MISSISSIPPI; 0131 </INSTITUTION>
<DESCRIPTORS> BUSINESS ADMINISTRATION, MARKETING; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> JAMES H. BARNES </ADVISER>
<CLASSIFICATIONS> CHOICE MODELING </CLASSIFICATIONS>
<ABSTRACT>
This research introduces a type of artificial
intelligence computing, neural networks, into choice
modeling. The well-known Guadagni and Little (1983)
model was replicated using scanner-panel coffee data and
multinomial logit processing. The same model and data
were then processed through three different feedforward
neural networks using separate training algorithms--
backpropagation, Logicon projection and, GANNT (Genetic
Adaptive Neural Network Training). A comparison of the
results using hit rates, mean absolute errors and, brand
share tracking with charts was then carried out.
It was concluded that a neural network trained with
backpropagation was slightly more accurate than
multinomial logit in forecasting brand share. Also, the
results indicated that neural networks do not suffer as
severe an extrapolation penalty as logistic regression.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  3076 </NUMBER>
<ORDER>   AAI9615525 </ORDER>
<TITLE> QUALITY IMPROVEMENT IN THE SERVICE SECTOR: AN EXPERT SUPPORT SYSTEM </TITLE>
<AUTHOR> HOPE, BEVERLEY G. </AUTHOR>
<YEAR> 1995 </YEAR>
<INSTITUTION> UNIVERSITY OF HAWAII; 0085 </INSTITUTION>
<DESCRIPTORS> BUSINESS ADMINISTRATION, MANAGEMENT; BUSINESS ADMINISTRATION, MARKETING; INFORMATION SCIENCE; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> ROSEMARY H. WILD </ADVISER>
<CLASSIFICATIONS> ESS </CLASSIFICATIONS>
<ABSTRACT>
Services play a dominant role in post-industrial
economies. The strength of those economies depends upon
the competitiveness of both their manufacturing and
service sectors. In this research we address the
challenge of improving service competitiveness through
data-driven quality improvement systems.
Measuring, monitoring, and controlling service quality
is an elusive task. Members of quality improvement teams
frequently lack a detailed understanding of quality
improvement techniques and data collection requirements.
Some progress has been made toward understanding data
needs in manufacturing industries, but many people
believe that service organizations are different. What
is needed is (a) an improved understanding of service
quality data needs, and (b) a way of supporting workers
in collecting relevant and valid data.
This research used a field study in the banking industry
to develop a model of data needs for service quality
improvement. The model describes the data needs at three
levels of quality planning and implementation uncovered
by our research: strategic, tactical, and operational.
The preliminary model developed in the banking industry
was divided into two sections for validation. The first
section was validated by a series of structured
interviews and a survey of service providers in a broad
range of service industries. The second, more
prescriptive section was validated by a panel of
experts.
The validated model provided the basis for a logical
model which was subsequently implemented as a
demonstration prototype expert support system (ESS). The
ESS uses procedural cuing to guide users through a data-
driven quality improvement process. Emphasis is placed
on problem-focused data needs and selection of
appropriate tools and techniques to analyse data.
Computerized support at the operational level can
provide on-the-job and training to teams charged with
implementing quality improvement projects.
The research provides both theoretical and practical
contributions. These include an improved understanding
of quality-related data needs in service industries, a
strategy for tying data needs to the service quality
improvement process, and demonstration of computerized
support to a new problem domain.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  3077 </NUMBER>
<ORDER>   AAI9614703 </ORDER>
<TITLE> PREDICTING NAVAL AVIATOR FLIGHT TRAINING PERFORMANCE USING MULTIPLE REGRESSION AND AN ARTIFICIAL NEURAL NETWORK </TITLE>
<AUTHOR> GRIFFIN, GLENN RAY </AUTHOR>
<YEAR> 1995 </YEAR>
<INSTITUTION> NOVA SOUTHEASTERN UNIVERSITY; 1191 </INSTITUTION>
<DESCRIPTORS> EDUCATION, EDUCATIONAL PSYCHOLOGY; EDUCATION, PSYCHOLOGY; EDUCATION, TESTS AND MEASUREMENTS; PSYCHOLOGY, EXPERIMENTAL; EDUCATION, VOCATIONAL; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> JOHN KINGSBURY </ADVISER>
<CLASSIFICATIONS> NIL </CLASSIFICATIONS>
<ABSTRACT>
The Navy needs improved methods for assigning naval
aviators (pilots) to fixed-wing and rotary-winged
aircraft. This study evaluated the potential of a series
of single- and multitask tests to account for additional
significant variance in the prediction of flight grade
training performance for a sample of naval aviator
trainees. Subjects were tested on a series of cognitive
and perceptual psychomotor tests. The subjects then
entered the Navy Flight Training Program. Subject's
flight grades were obtained at the end of primary
training. Multiple regression and artificial neural
network procedures were evaluated to determine their
relative efficiency in the prediction of flight grade
training performance.
All single- and multitask test measures evaluated as a
part of this study were significantly related to the
primary training flight grade criterion. Two psychomotor
and one dichotic listening test measures contributed
significant added variance to a multiple regression
equation, beyond that of selection tests $F (5,
428)=27.19, R$ squared =.24, multiple $R=.49, p<.01.$ A
follow-on analysis indicated a split-half validation
correlation coefficient of $r=.38, p<.01$ using multiple
regression and as high as $r=.41, p<.01$ using a neural
network procedure.
No statistically significant differences were found
between the correlation coefficients resulting from the
application of multiple regression and neural network
validation procedures. Both procedures predicted the
flight grade criterion equally well, although the neural
network applications consistently provided slightly
higher correlations between actual and predicted flight
grades.
The results of this study demonstrated that the single-
and multitask measures accounted for added unique
variance beyond that of selection tests in predicting
flight grades. Since later (intermediate and advanced)
flight training assignments are determined by flight
grades earned during the primary portion of training,
these tests could theoretically be used to predict an
individual's flight grade and select aviator applicants
into training pipelines prior to training.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  3078 </NUMBER>
<ORDER>   AAI9614233 </ORDER>
<TITLE> A COMPUTER MODEL OF REACTIVE PLANNING AND IMPLEMENTATION STRATEGY IN PROGRAM-CONSTRAINED DECISION-MAKING </TITLE>
<AUTHOR> SPANGLER, WILLIAM EUGENE </AUTHOR>
<YEAR> 1995 </YEAR>
<INSTITUTION> UNIVERSITY OF PITTSBURGH; 0178 </INSTITUTION>
<DESCRIPTORS> BUSINESS ADMINISTRATION, GENERAL; INFORMATION SCIENCE; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> NIL </ADVISER>
<CLASSIFICATIONS> ARTIFICIAL INTELLIGENCE </CLASSIFICATIONS>
<ABSTRACT>
Although organizational programs are an important
influence on the behavior of decision makers in complex
task environments, their influence is tempered by other
cognitive and situational factors which can lead a
decision maker to deviate from the prescribed directives
of a program. Using empirical data obtained from two
separate domains--Nuclear Power Plant (NPP) operations
and Mergers & Acquisitions (M&A)--this research has
sought to understand and explain the factors that cause
actors to conform to, or deviate from, a prescribed
program. This disertation describes a theory of program-
constrained behavior derived from cognitive task
analysis of observed behavior. The theory explains two
observed aspects of program-constrained behavior: (1)
actions taken during program execution which might be
construed as deviating from the constraints of the
program, and (2) arguments constructed by the decision
maker to justify and defend such actions. The planning
process which produces these behaviors is distinguished
by a dichotomy between the reactive planning required to
achieve, restore or defend desired goals, and the
implementation planning required to execute the reactive
plan while avoiding sanctions imposed by the
organization in response to observed program violations.
Analysis of data describing NPP operator behavior led to
development of an initial conceptual and computational
theory that explained identified instances of deviations
in NPP procedure execution. The initial theory then
served as the basis for a more focused exploration of
behavior related to corporate Mergers and Acquisitions,
where argumentation in defense of program-constrained
actions became the focus. This led to an extension of
the original NPP-derived model, in part to account for
behaviors in M&A, but also to refine the explanatory
capabilities of the model in the NPP domain. Finally,
having begun in the real-time NPP operations
environment, and then having applied lessons learned in
that effort to the construction of an enhanced model of
post-mortem M&A argumentation, this research project
'closed the circle' by extending the model to
incorporate post-mortem argumentation in the original
domain of NPP operations. The result of the research is
a general computational theory capable of explaining and
predicting program-deviating and argumentation behavior
across domains.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  3079 </NUMBER>
<ORDER>   AAI1377757 </ORDER>
<TITLE> A COMPARISON OF NEURAL LEARNING FOR THE WIDROW-HOFF PERCEPTRON AND THE BACK-PROPAGATION NETWORK </TITLE>
<AUTHOR> TOLAND, HOLLY ANNE </AUTHOR>
<YEAR> 1995 </YEAR>
<INSTITUTION> TEXAS WOMAN'S UNIVERSITY; 0925 </INSTITUTION>
<DESCRIPTORS> COMPUTER SCIENCE; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> NIL </ADVISER>
<CLASSIFICATIONS> NIL </CLASSIFICATIONS>
<ABSTRACT>
A comparison of learning capabilities between a single
neuron using the Widrow-Hoff learning rule and a two-
layer back-propagation neural network was completed. The
single, Widrow-Hoff perceptron was programmed by the
author, while the back-propagation network used was the
commercially available product, Neuroshell$sp0rm TM$.
Data used to train both systems was created by drawing
examples and non-examples of capitol letter Es on a 7 x
5 grid. Each grid square represented a pixel to create a
35-element binary input vector. Both systems were
trained on the data and tested using a file composed of
the training sets and 20 additional data sets. Each
program was trained with varying numbers of iterations
to determine the relationship between the number of
training cycles and the accuracy of letter
identification. The perceptron and the back propagation
network both learned the training set in approximately
400 iterations at the optimal learning constants for
both systems. The back propagation network, however,
performed more accurately on the testing data than did
the perceptron.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  3080 </NUMBER>
<ORDER>   AAI1377541 </ORDER>
<TITLE> MULTI-NEURON CHIP DESIGN </TITLE>
<AUTHOR> PATEL, RAJESH B. </AUTHOR>
<YEAR> 1995 </YEAR>
<INSTITUTION> CALIFORNIA STATE UNIVERSITY, LONG BEACH; 6080 </INSTITUTION>
<DESCRIPTORS> ENGINEERING, ELECTRONICS AND ELECTRICAL; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> EDWARD EVANS </ADVISER>
<CLASSIFICATIONS> ARTIFICIAL INTELLIGENCE </CLASSIFICATIONS>
<ABSTRACT>
Recent research in real time image processing, pattern
recognition and speech synthesis by multi-neuron multi-
layered neural networks has pointed out some encouraging
results. In this thesis a multi-neuron multilayered
neural network architecture has been implemented through
VLSI.
The Hebbian learning rule using Hopfield architecture is
implemented by designing a 10 neuron chip. It has on
line learning capability. Large neuron architecture can
be formed by replicating this 10 neuron chip to form a
20, 30, etc., neuron chip.
This chip has been designed and simulated at transistor
level using VLSI tools. This chip uses a common SRAM
memory and an arithmetic logic unit (ALU). The memory
and ALU control system is directly implemented in
hardware to increase the speed.
The logical part of the layout was done with standard
cell procedures using auto routing and compactor
programs. The memory layout was done manually.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  3081 </NUMBER>
<ORDER>   AAI1377538 </ORDER>
<TITLE> A NEURAL NETWORK APPROACH TO ANALYZING FEATURE DEPENDENCY </TITLE>
<AUTHOR> NGUYEN, TOAN CAO </AUTHOR>
<YEAR> 1995 </YEAR>
<INSTITUTION> CALIFORNIA STATE UNIVERSITY, LONG BEACH; 6080 </INSTITUTION>
<DESCRIPTORS> COMPUTER SCIENCE; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> THINH V. NGUYEN </ADVISER>
<CLASSIFICATIONS> NIL </CLASSIFICATIONS>
<ABSTRACT>
This thesis presents a neural network approach to the
analysis of feature dependency. The approach consists of
two main sessions: training and analysis sessions. The
training session is performed by the use of a
multilayered feedforward neural network with generalized
delta learning rule. A training set of patterns is used
to train the network as usual. In the analysis session,
an analysis set of patterns is created by replacing all
values of the suspected dependent feature with zeros.
The process is then carried out in a manner similar to
that of the training session except that those values
obtained for the network weights and thresholds in the
training session are kept constant for those features
that do not belong to the suspected pair of independent
and dependent features. If the analysis process
converges, we can conclude that the suspected dependent
feature is a function of the other independent feature.
This approach is tested using several training sets of
patterns. Each set represents different functional
relationship between the pair of independent and
dependent features. To check the performance of the
trained network for each set, an output-generation
session is performed right after the training session to
ascertain that the network performs as expected before
the procedure can be continued with the analysis
session. The results of the experiments indicate that
the approach works for all the test patterns.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  3082 </NUMBER>
<ORDER>   AAI1377488 </ORDER>
<TITLE> A FUZZY LOGIC-BASED AUTOMOBILE FUEL INJECTION CONTROL SYSTEM </TITLE>
<AUTHOR> LUU, RAYMOND </AUTHOR>
<YEAR> 1995 </YEAR>
<INSTITUTION> CALIFORNIA STATE UNIVERSITY, LONG BEACH; 6080 </INSTITUTION>
<DESCRIPTORS> ENGINEERING, ELECTRONICS AND ELECTRICAL; ENGINEERING, AUTOMOTIVE; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> CHIT-SANG TSANG; MICHAEL SINGH CHELIAN; HENRY YEH </ADVISER>
<CLASSIFICATIONS> NIL </CLASSIFICATIONS>
<ABSTRACT>
In an industry as competitive as automotive
manufacturing, designing an efficient system has become
essential to market competitiveness. Today, consumers
demand automobiles that have higher output power, better
fuel economy, and proficient emission control, but still
stay within their budgets. Satisfying all such
requirements simultaneously from the customers are not
the easy tasks for automotive manufactures because these
requirements are conflicting with each other in every
aspect. Utilizing fuzzy logic control has become a part
of the responses to these demands.
In this thesis, the advantages of fuzzy logic are
discussed over conventional method by means of a
computer simulation based on an automobile fuel
injection control system. The fuzzy-logic control system
not only meets many contradictory demands from the
customers on automobiles but also is preferable over the
conventional control system on flexible engine outputs,
improved fuel economy, purified exhausted gases, and
improved drivability.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  3083 </NUMBER>
<ORDER>   AAI1377065 </ORDER>
<TITLE> GENETIC ALGORITHM TUNING OF A FUZZY LOGIC CONTROLLER FOR A DYNAMIC SYSTEM </TITLE>
<AUTHOR> WANG, LUI </AUTHOR>
<YEAR> 1995 </YEAR>
<INSTITUTION> RICE UNIVERSITY; 0187 </INSTITUTION>
<DESCRIPTORS> ENGINEERING, MECHANICAL; ENGINEERING, ELECTRONICS AND ELECTRICAL; ENGINEERING, AEROSPACE; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> JOHN B. CHEATHAM, JR. </ADVISER>
<CLASSIFICATIONS> NIL </CLASSIFICATIONS>
<ABSTRACT>
This thesis describes the use of the genetic algorithm
to facilitate the design process of a fuzzy logic based
controller. The basic mechanics of both the fuzzy logic
control system and the genetic algorithm are presented
for establishing the foundation of this research. A
detailed design process to integrate the fuzzy logic
controller and the genetic algorithm is disclosed.
Software is developed to simulate the dynamics of a two-
link planar manipulator, and a multiple-link fuzzy logic
control (MLFLC) system is developed to control a non-
linear robotics system. In this work, the genetic
algorithm technique is used to design both the Universe
of Discourse of some of the control variables and also
the shape and location of membership functions. As a
result, the system is able to maintain control with
moderate errors. The most important contribution of this
work is that it demonstrates the effectiveness of using
genetic algorithms to optimize fuzzy logic control
systems.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  3084 </NUMBER>
<ORDER>   AAGC520835 </ORDER>
<TITLE> THE IMPACT OF ARCHITECTURE ON THE PERFORMANCE OF ARTIFICIAL NEURAL NETWORKS </TITLE>
<AUTHOR> BOSTOCK, RICHARD THOMAS JOHN </AUTHOR>
<YEAR> 1995 </YEAR>
<INSTITUTION> ASTON UNIVERSITY (UNITED KINGDOM); 0734 </INSTITUTION>
<DESCRIPTORS> COMPUTER SCIENCE; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> NIL </ADVISER>
<CLASSIFICATIONS> RADIAL BASIS FUNCTION, BUMPTREE </CLASSIFICATIONS>
<ABSTRACT>
A number of researchers have investigated the impact of
network architecture on the performance of artificial
neural networks. Particular attention has been paid to
the impact on the performance of the multi-layer
perceptron of architectural issues, and the use of
various strategies to attain an optimal network
structure. However, there are still perceived
limitations with the multi-layer perceptron and networks
that employ a different architecture to the multi-layer
perceptron have gained in popularity in recent years.
Particularly, networks that implement a more localised
solution, where the solution in one area of the problem
space does not impact, or has a minimal impact, on other
areas of the space. In this study, we discuss the major
architectural issues effecting the performance of a
multi-layer perceptron, before moving on to examine in
detail the performance of a new localised network,
namely the bumptree.
The work presented here examines the impact on the
performance of artificial neural networks of employing
alternative networks to the long established multi-layer
perceptron. In particular, networks that impose a
solution where the impact of each parameter in the final
network architecture has a localised impact on the
problem space being modelled are examined. The
alternatives examined are the radial basis function and
bumptree neural networks, and the impact of
architectural issues on the performance of these
networks is examined. Particular attention is paid to
the bumptree, with new techniques for both developing
the bumptree structure and employing this structure to
classify patterns being examined.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  3085 </NUMBER>
<ORDER>   AAI1376961 </ORDER>
<TITLE> DATAFLOW PROCESSOR FOR BACK PROPAGATION NEURAL NETWORKS: ARCHITECTURE AND PERFORMANCE EVALUATION </TITLE>
<AUTHOR> ABU-MUTLAQ, MAHER HAMDAN KHALIL </AUTHOR>
<YEAR> 1995 </YEAR>
<INSTITUTION> KING FAHD UNIVERSITY OF PETROLEUM AND MINERALS (SAUDI ARABIA); 1088 </INSTITUTION>
<DESCRIPTORS> COMPUTER SCIENCE; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> NIL </ADVISER>
<CLASSIFICATIONS> NIL </CLASSIFICATIONS>
<ABSTRACT>
Real time applications of neural networks demand high
performance systems. Neural networks may be naturally
represented by macro dataflow graphs. Dataflow machines
therefore offer suitable platforms for simulation of
these networks. In this thesis, the hardware
requirements for neural computing are first discussed.
The rationale of dataflow approach to neural computing
is presented. A new neural dataflow processor
architecture based on argument-fetching principles is
proposed. The proposed architectural model is static and
flexible to exploit different levels of parallelism
offered by neural networks through the use of software
pipelining. The architecture is studied by extensive
simulations using some neural network examples with
various parameters. Back propagation and Hopfield
networks are transformed into dataflow graphs in order
to execute on the machine. The simulation shows good
performance results.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  3086 </NUMBER>
<ORDER>   AAIMM04598 </ORDER>
<TITLE> A FUZZY ART MAP NEURAL NETWORK SPEECH RECOGNITION SYSTEM BASED ON FORMANT RATIOS </TITLE>
<AUTHOR> YOUNG, DAVID PETER </AUTHOR>
<YEAR> 1995 </YEAR>
<INSTITUTION> ROYAL MILITARY COLLEGE OF CANADA (CANADA); 1103 </INSTITUTION>
<DESCRIPTORS> COMPUTER SCIENCE; ARTIFICIAL INTELLIGENCE; ENGINEERING, ELECTRONICS AND ELECTRICAL </DESCRIPTORS>
<ADVISER> PAUL ALLARD </ADVISER>
<CLASSIFICATIONS> NIL </CLASSIFICATIONS>
<ABSTRACT>
This thesis investigates the applicability of a Fuzzy
ART (Adaptive Resonance Theory) Map ANN (Artificial
Neural Net) to the task of ASR (Automatic Speech
Recognition).
This thesis provides some basic background information
about ANNs, ART, fuzzy logic, ASR, and formant ratio
theory. It then describes how a Fuzzy ART Map ANN is
implemented as the recognizer component of an ASR system
to learn and identify formant ratio vectors extracted
from spoken phrases. The audio frequency analysis is
limited to a 300 to 3300 Hz bandwidth so that the system
may operate on verbal commands over telephone channels.
The recognition accuracy of this system is then tested
using a database with eight phonetically rich phrases.
The database was recorded by twelve males and two
females over a four month period using a high quality
microphone in a computer room environment. The tests are
repeated using a multi-layer feedforward backpropagation
ANN as the recognizer component to provide a relative
performance benchmark. Finally, the performance of the
Fuzzy ART Map ASR system is tested over the telephone
channel. (Abstract shortened by UMI.)
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  3087 </NUMBER>
<ORDER>   AAIMM04596 </ORDER>
<TITLE> VLSI FAULT MONITORING USING NEURAL NETWORKS </TITLE>
<AUTHOR> WIEMER, DOUGLAS JOSEPH MARTIN </AUTHOR>
<YEAR> 1995 </YEAR>
<INSTITUTION> ROYAL MILITARY COLLEGE OF CANADA (CANADA); 1103 </INSTITUTION>
<DESCRIPTORS> ENGINEERING, ELECTRONICS AND ELECTRICAL; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> COME ROZON </ADVISER>
<CLASSIFICATIONS> NIL </CLASSIFICATIONS>
<ABSTRACT>
The growing complexity and use of automated remote
systems results in a number of difficulties for system
maintenance. For example, satellite systems reside in a
hostile environment where failure for any reason is
difficult to monitor, hard to diagnose and, unless
redundant systems are available, impossible to repair.
Also, in any fault diagnosis situation, the reliability
of the test system must be certain. A novel approach to
real time on-line fault monitoring of VLSI using neural
networks is investigated. The circuit input/output data
is considered as a pattern recognition task to which a
neural network is applied. Extensive use of
generalization is used to prevent the requirement for
exhaustive test pattern generation. As well, a detailed
investigation reveals that the distributed knowledge
within a neural network results in "graceful
degradation" of the tool, given the possibility of
faults within the remote test system itself. Comparisons
are made involving the use of feature vector extraction,
tanh versus sigmoid transfer functions, the delta versus
the normalized-cumulative learning rules, varying the
number of hidden layer nodes and various representations
of the network output.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  3088 </NUMBER>
<ORDER>   AAIMM04592 </ORDER>
<TITLE> IMPROVED CONDITION MONITORING OF THE CH-124 SEAKING HELICOPTER MAIN GEARBOX THROUGH AN ARTIFICIAL INTELLIGENCE APPLICATION </TITLE>
<AUTHOR> SELKIRK, COLIN GREGORY </AUTHOR>
<YEAR> 1995 </YEAR>
<INSTITUTION> ROYAL MILITARY COLLEGE OF CANADA (CANADA); 1103 </INSTITUTION>
<DESCRIPTORS> ENGINEERING, AEROSPACE; ENGINEERING, MECHANICAL; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> PIERRE ROBERGE </ADVISER>
<CLASSIFICATIONS> NIL </CLASSIFICATIONS>
<ABSTRACT>
Maintenance productivity and efficiency play roles of
increasing importance within the management of most of
today's manufacturing and service industries. The costs
and resource requirements associated with maintenance
work have come under tougher scrutiny recently as
organizations look for ways to trim their operating
expenses. Under this pressure, maintenance managers are
always looking for better more efficient ways to achieve
their maintenance goals. The implementation of a
preventive maintenance (PM) program and the use of
effective work allocation and scheduling practice have
proven to be direct results of such efforts. Such is the
case in the maintenance program for Canadian Forces'
(CF's) aircraft, which uses a PM philosophy consisting
of a combination of non-destructive testing (NDT),
condition monitoring (CM), and scheduled and unscheduled
inspections.
One area of research which offers a means to address the
need to increase maintenance efficiency is that of
artificial intelligence (AI). AI techniques presented
herein show how their related strengths have been
utilized to achieve improvements in this, and many other
application domains. The purpose of this work is to
present the development of an expert system (ES) for
helping perform a CM technique (Filter Debris Analysis
(FDA) on the CH-124 Seaking Helicopter within the CF.
The resultant system is the Filter Debris Analysis
Partner FDAP), an ES diagnostic aid for technicians
performing FDA in the field or at the support
laboratories. Each stage of the development process is
addressed, and the potential for improvement in the
performance of CM within the CF is discussed. Besides
increasing objectivity, applying an ES to the FDA
technicians will also shorten the decision time, enable
the collection of analytical experience in a knowledge
base, provide a means to historically trend wear debris
information, and provide a means of correlating results
from other CM techniques. This correlation of knowledge
may be achieved in the future by expanding the system to
include other techniques, such as spectrometric oil
analysis (SOA), ferrography, or vibration analysis (VA).
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  3089 </NUMBER>
<ORDER>   AAIMM04357 </ORDER>
<TITLE> GEOLOGICAL MAPPING FROM MULTI-SOURCE DATA USING NEURAL NETWORKS </TITLE>
<AUTHOR> YANG, GRACE YEN-CHEW </AUTHOR>
<YEAR> 1995 </YEAR>
<INSTITUTION> UNIVERSITY OF CALGARY (CANADA); 0026 </INSTITUTION>
<DESCRIPTORS> GEOTECHNOLOGY; REMOTE SENSING; ARTIFICIAL INTELLIGENCE; PHYSICAL GEOGRAPHY </DESCRIPTORS>
<ADVISER> M. J. COLLINS </ADVISER>
<CLASSIFICATIONS> NIL </CLASSIFICATIONS>
<ABSTRACT>
This study explores and analyzes the detailed operations
of lithologic classification from remote sensing images
and geophysical data using feedforward neural networks.
A set of experiments was designed and performed to test
the dependence of classification accuracy on various
parameters. The variables used in the experiments are
various combinations of input channels, the number of
output classes, the number of hidden nodes, the training
sample sizes, and the training coefficients (i.e. the
momentum factor and the learning rate). The input
channels consist of different types of images generated
from gravity, magnetic, gamma ray spectrometry data and
remote sensing images such as Thematic Mapper, radar and
SPOT.
Through the analysis of classification accuracy with
increased number of iterations, we demonstrated that the
optimal choice of input channels is the most critical
factor in achieving better accuracy result. The
classification accuracy may be maximized by choosing an
optimal combination of input data layers. When training
the network, the size of individual training samples is
more important than the total number of training samples
in obtaining a satisfactory classification. The
classification accuracy is inversely promotional to the
number of output classes in this geological mapping.
Generally speaking, the overall average accuracy of
classification gets better by increasing the number of
iterations to a certain degree, however, at the expense
of some individual classification accuracy.
The variance in the individual classification accuracy
were found to be significant which has lead to some
criterion on the selection of the parameters. For
lithologic mapping, the network should be structured in
accordance with the importance of each individual class.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  3090 </NUMBER>
<ORDER>   AAIMM04354 </ORDER>
<TITLE> MULTIPLE-ANGLE CANOPY DATA INVERSION USING A NEURAL NETWORK APPROACH </TITLE>
<AUTHOR> WANG, DUANE XIANG </AUTHOR>
<YEAR> 1995 </YEAR>
<INSTITUTION> UNIVERSITY OF CALGARY (CANADA); 0026 </INSTITUTION>
<DESCRIPTORS> ENVIRONMENTAL SCIENCES; PHYSICAL GEOGRAPHY; REMOTE SENSING; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> PENG GONG; J. A. R. BLAIS </ADVISER>
<CLASSIFICATIONS> NIL </CLASSIFICATIONS>
<ABSTRACT>
A new inversion approach of the canopy reflectance model
has been developed. A coupled atmosphere-canopy (CAC)
directional canopy model (Liang and Strahler, 1993) is
used to simulate the multiple-angle canopy reflectance
data based on various combinations of canopy biophysical
parameters, such as leaf angle distribution and leaf
area index. The CAC model, however, can only generate
results through numerical iterations and is very
difficult to be used for retrieval of those biophysical
parameters with traditional inversion techniques.
Therefore, a feed-forward neural network is used in the
inversion for the canopy biophysical parameters.
Although special emphasis has been placed on the studies
of the vegetation canopy, the inversion approach was
retrieved some other parameters including the soil
reflectance parameter and atmosphere parameter.
Different numbers of multiple-angle reflectances are
input to the neural networks. Experimentation with 64,
32, 16, 8, 4, 2 and 1 reflectances have been carried out
to find the best configuration of input features for
inversion. Within these seven kinds of input features,
the 32 input features (viewing angles) are the best
choice for retrieval according to the combination
consideration of test error and convergence speed. A
comparison of single parameter inversion and two-
parameter simultaneous inversion has been conducted. The
results show an accuracy at the same level. The test
results show that a normalized test error of 0.01-0.05
or better is achievable for retrieving one parameter at
a time or two parameters simultaneously. Simultaneous
multiple parameter retrieval (i.e., as many as five
parameters) has also been achieved. The accuracies are
in a reasonable range and these results can be used for
subsequent field data retrieval.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  3091 </NUMBER>
<ORDER>   AAIMM04346 </ORDER>
<TITLE> A COMPLEX DOMAIN NEURAL NETWORK BASED DATA EXTRAPOLATION ALGORITHM AND ITS APPLICATIONS IN MRI </TITLE>
<AUTHOR> HUI, YAN </AUTHOR>
<YEAR> 1995 </YEAR>
<INSTITUTION> UNIVERSITY OF CALGARY (CANADA); 0026 </INSTITUTION>
<DESCRIPTORS> ENGINEERING, ELECTRONICS AND ELECTRICAL; ENGINEERING, BIOMEDICAL; HEALTH SCIENCES, RADIOLOGY; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> M. R. SMITH </ADVISER>
<CLASSIFICATIONS> NIL </CLASSIFICATIONS>
<ABSTRACT>
Many applications make use of the discrete Fourier
transform (DFT) during data manipulation. The resolution
in such applications is inversely proportional to the
available data length used during the DFT. Resolution
can be improved by modeling and then extrapolating the
known data set to increase its effective length prior to
the DFT. A new data extrapolating algorithm based on a
complex domain neural network is presented in this
thesis. The complex back-propagation algorithm is
derived based on reported approaches but in a more
general way. Adaptive learning and momentum methods are
extended to this complex algorithm. To illustrate the
performance of the new algorithm, it is applied to two
magnetic resonance imaging (MRI) areas--truncated data
reconstruction and dynamic imaging. Qualitative and
quantitative comparisons with the existing methods
indicate that the proposed algorithm works competitively
well with the TERA method and better than other
approaches.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  3092 </NUMBER>
<ORDER>   AAIMM04333 </ORDER>
<TITLE> ON LEARNING LARGE OUTPUT DOMAIN DECISION TREES </TITLE>
<AUTHOR> WILSON, DAVID KENNETH </AUTHOR>
<YEAR> 1995 </YEAR>
<INSTITUTION> UNIVERSITY OF CALGARY (CANADA); 0026 </INSTITUTION>
<DESCRIPTORS> COMPUTER SCIENCE; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> NADER BSHOUTY </ADVISER>
<CLASSIFICATIONS> NIL </CLASSIFICATIONS>
<ABSTRACT>
One of the biggest open problems in computational
machine learning is whether boolean formulas are
learnable, under the restrictions of the learning model,
in time polynomial in their disjunctive normal form size
and the number of variables that they are defined over.
An obvious strategy towards the solution of this problem
is through the study of the learnability of other
subclasses of boolean formulas to see if they are
learnable under the same criteria.
One such subclass that is exactly learnable using
membership and equivalence queries are boolean decision
trees but this result does not imply the learnability of
decision trees whose output domains are large because a
simple boolean encoding may not suffice. We show how to
exactly learn decision trees when the possible leaf
values form either a bounded lattice, a set of constant
values, or any exactly learnable class of functions over
a distinct variable set.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  3093 </NUMBER>
<ORDER>   AAIMM04153 </ORDER>
<TITLE> AN EXPERT-BASED APPROACH FOR CULTURAL LANDSCAPE ASSESSMENT USING A GEOGRAPHIC INFORMATION SYSTEM AS A TOOL FOR ANALYSIS </TITLE>
<AUTHOR> VINCENT, STEPHEN JOHN </AUTHOR>
<YEAR> 1995 </YEAR>
<INSTITUTION> UNIVERSITY OF GUELPH (CANADA); 0081 </INSTITUTION>
<DESCRIPTORS> GEOGRAPHY; ANTHROPOLOGY, CULTURAL; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> JAMES R. TAYLOR </ADVISER>
<CLASSIFICATIONS> NIL </CLASSIFICATIONS>
<ABSTRACT>
Development pressures and changes to the landscape
necessitate a comprehensive analysis to understand all
the factors that contribute to the meaning and structure
of the landscape. A landscape approach for cultural
landscape assessment was adopted as the fundamental
premise underlying this study, recognizing the entire
landscape has been affected by human activity and has
cultural values. A cultural landscape assessment method
for identifying, recording and analyzing the natural and
cultural resources is proposed in this paper, using an
expert-based approach and a Geographical Information
System (GIS).
The Beaver Valley, located in the townships of Artemesia
and Euphrasia in Southern Ontario, was used to develop
and test the method. Data was collected from existing
maps and a field survey of the study area. The proposed
method provides a spatial description of the cultural
landscape and has been found to be effective for
cultural landscape assessment. The method is discussed
and research directions are recommended.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  3094 </NUMBER>
<ORDER>   AAIMM03968 </ORDER>
<TITLE> LOCALISATION D'UN DIPOLE MAGNETIQUE A L'AIDE D'UN RESEAU DE NEURONES  </TITLE>
<AUTHOR> PARADIS, STEPHANE </AUTHOR>
<YEAR> 1995 </YEAR>
<INSTITUTION> UNIVERSITE LAVAL (CANADA); 0726 </INSTITUTION>
<DESCRIPTORS> ENGINEERING, ELECTRONICS AND ELECTRICAL; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> BRAHIM CHAIB-DRAA; JACQUES BEDARD </ADVISER>
<CLASSIFICATIONS> FRENCH TEXT </CLASSIFICATIONS>
<ABSTRACT>
Les reseaux de neurones ont ete etudies dans le cadre,
du present travail, pour estimer la position d'un dipole
magnetique a partir de quelques valeurs de champ
observees dans l'entourage de ce dernier. La
localisation du dipole est traitee comme une
approximation d'une fonction non-lineaire. Les valeurs
des composantes du champ magnetique du dipole sont
associees, de facon univoque, a sa position par
l'entremise de l'entrai nement d'un reseau de neurones.
Ce dernier permet en plus de generaliser cette
correspondance au traitemnt de donnees pour lequel il
n'a pas ete entrai ne ce qui correspond a effectuer une
interpolation multidimensionnelle. Les differents
modeles etudies ont montre qu'il est possible d'entrai
ner un reseau pour resoudre l'inversion des equations du
champ d'un dipole magnetique lorsque le nombre de
dimensions est inferieur a trois. Differentes approches
ont ete analysees pour reduire la dimension du probleme
et faciliter ainsi sa realisation. Finalement, les
experimentations effectuees sont presentees suivies
d'une discussion des resultats obtenus.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  3095 </NUMBER>
<ORDER>   AAGC520009 </ORDER>
<TITLE> A SOFTWARE ENGINEERING APPROACH TO THE DEVELOPMENT OF FUZZY CONTROL SYSTEMS </TITLE>
<AUTHOR> ISOMURSU, ESA PEKKA </AUTHOR>
<YEAR> 1995 </YEAR>
<INSTITUTION> OULUN YLIOPISTO (FINLAND); 0409 </INSTITUTION>
<DESCRIPTORS> COMPUTER SCIENCE; ARTIFICIAL INTELLIGENCE 2000, FIN-02044  VTT, FINLAND </DESCRIPTORS>
<ADVISER> NIL </ADVISER>
<CLASSIFICATIONS> NIL </CLASSIFICATIONS>
<ABSTRACT>
We examine the development process of fuzzy control
software from the software engineering point of view. We
propose an approach to the development of fuzzy logic
controllers (FLCs) that makes their industrial
exploitation easy and efficient. We base our approach on
the assumption that the development process as well as
its outcome should be intelligible to the human experts
who create or use the FLC.
The proposed approach consists of three views of the FLC
software development process: development model,
development methods and tools, and design parameters.
For each view, methodology is proposed and constructed
that helps the development of FLCs for industrial use.
This methodology includes a detailed model of the FLC
software development process, methods for the tuning of
FLCs, a development tool, and designs of FLCs that make
their structure intelligible.
Using the proposed methodology we have managed to
successfully implement various industrial FLCs. Some of
them are discussed in detail in this thesis.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  3096 </NUMBER>
<ORDER>   AAIMM03861 </ORDER>
<TITLE> ANALYSE ET CONCEPTION D'UN SYSTEME EXPERT D'AIDE A LA GESTION DE PROJET BASE SUR LE RAISONNEMENT PAR CAS </TITLE>
<AUTHOR> DIALLO, OUSMANE </AUTHOR>
<YEAR> 1995 </YEAR>
<INSTITUTION> UNIVERSITE LAVAL (CANADA); 0726 </INSTITUTION>
<DESCRIPTORS> COMPUTER SCIENCE; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> GERARD SIMIAN; NICOLE TOURIGNY </ADVISER>
<CLASSIFICATIONS> FRENCH TEXT </CLASSIFICATIONS>
<ABSTRACT>
La frequence des echecs des projets de developpement,
notamment dans le domaine rural, constitue desormais une
caracteristique en Afrique Sahelienne. Parmi les causes
de ces echecs, on invoque de plus en plus le manque de
systemes efficaces de suivi et d'evaluation permettant
d'utiliser les lecons tirees des experiences passees.
Les gestionnaires se privent ainsi d'une information
disponible et riche. Toutefois celle-ci est profondement
desorganisee. Il est donc imperatif de developper des
systemes d'information au service de projets nouveaux ou
existants, restructurant et diffusant les lecons
apprises.
C'est dans ce but que la composante "Amenagement des
Terroirs" du Centre Sahel de l'Universite Laval a
inscrit dans ses activites la presente recherche visant
a mettre au point un outil d'aide a la gestion et a
l'evaluation des projets agroforestiers au Sahel.
Nous proposons d'utiliser la technologie des systemes a
base de connaissances, pour conceptualiser, emmagasiner
et diffuser les enseignements tires des projets passes
ou existants dans le domaine de l'agroforesterie.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  3097 </NUMBER>
<ORDER>   AAIMM03724 </ORDER>
<TITLE> BENCHMARKING RULE-BASED EXPERT SYSTEM SHELLS </TITLE>
<AUTHOR> BURNS, GERALD DANIEL </AUTHOR>
<YEAR> 1995 </YEAR>
<INSTITUTION> YORK UNIVERSITY (CANADA); 0267 </INSTITUTION>
<DESCRIPTORS> COMPUTER SCIENCE; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> ANESTIS TOPTSIS </ADVISER>
<CLASSIFICATIONS> NIL </CLASSIFICATIONS>
<ABSTRACT>
We present a systematic way to evaluate the performance
of rule based expert system shells. The proposed method
is based on the fundamental architecture of a rule based
expert system shell and, therefore, it is product
independent. Although there have been a few studies that
evaluate the performance of such shells, they all deal
with qualitative features of the shells, such as
platform used, language written, interface design
features, reasoning strategies used (i.e. forward,
backward chaining), and availability of front ends for
knowledge representation. To the best of our knowledge,
there is no study that provides a systematic
quantitative evaluation of the shells. Yet, this may be
of primary interest to knowledge engineers that are
interested in evaluating the raw power of expert system
building tools, i.e. for cases where processing speed is
considered of critical importance (e.g. in real-time
diagnosis systems). The proposed methodology is used to
compare a number of commercially available shells.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  3098 </NUMBER>
<ORDER>   AAIMM03630 </ORDER>
<TITLE> B-SPLINE APPROXIMATION OF AIRFOILS USING ARTIFICIAL NEURAL NETWORKS </TITLE>
<AUTHOR> CHAWLA, BOBBY </AUTHOR>
<YEAR> 1995 </YEAR>
<INSTITUTION> UNIVERSITY OF WATERLOO (CANADA); 1141 </INSTITUTION>
<DESCRIPTORS> ENGINEERING, MECHANICAL; ENGINEERING, AEROSPACE; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> S. BEDI </ADVISER>
<CLASSIFICATIONS> NIL </CLASSIFICATIONS>
<ABSTRACT>
One of the difficult problems in reverse engineering
consists of determining a good functional representation
of a geometric object from a series of data points.
This thesis presents a connectionist network (Artificial
Neural Network) approach to generate a curve from the
data, although the concept can be extended to surfaces.
The proposed connectionist network has an architecture
similar to a Radial Basis Function Network, but uses B-
Spline basis functions as the activation functions. The
proposed network trains much faster than traditional
MultiLayer Perceptron type networks, and it does not
suffer from many of the difficulties commonly related to
connectionist networks.
A solution to the airfoil problem, approximating all
points to the required tolerance of 0.016% of the chord
length, can be achieved within 10 minutes on a
SPARCstation IPX. A time period competitive with other
numerical techniques, but with less overhead.
Using a B-Spline based network has the added advantage
that the B-Spline control points are generated through
this process. B-Spline curves, which are generated from
their control points, are popular in the field of
computer aided geometric design (CAD) and manufacturing
(CAM). Therefore, once the curve data is generated, it
can be easily converted into a form understood by CAD
data exchange systems such as IGES (Initial Graphics
Exchange Specification).
Backpropagation allows the network can exactly reproduce
a curve that had previously been generated from a B-
Spline curve, including the automatic determination of
the original knot vector. By implementing the techniques
of knot-deletion and optimization of knot vectors, the
algorithm automatically produces a good approximation of
part data, without any prior knowledge of its geometry.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  3099 </NUMBER>
<ORDER>   AAIMM03377 </ORDER>
<TITLE> AVAILABILITY AND PERFORMANCE MANAGEMENT IN DISTRIBUTED SYSTEMS </TITLE>
<AUTHOR> STOKES, DAVID KEITH </AUTHOR>
<YEAR> 1995 </YEAR>
<INSTITUTION> THE UNIVERSITY OF WESTERN ONTARIO (CANADA); 0784 </INSTITUTION>
<DESCRIPTORS> COMPUTER SCIENCE; ENGINEERING, SYSTEM SCIENCE; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> MICHAEL BAUER; HANAN LUTFIYYA </ADVISER>
<CLASSIFICATIONS> NIL </CLASSIFICATIONS>
<ABSTRACT>
Managing the availability and performance of a
distributed system involves monitoring the behaviour of
the system, identifying system problems, and correcting
those problems. Each of these tasks requires some
expertise, such as an understanding of the mechanics of
the underlying system components. As the size and
complexity of these systems increases, and the number of
distributed applications executing on these systems
increases, managing the availability performance of a
distributed system becomes more difficult. Little
research has focussed on embedding systems management
expertise into a management application for a
distributed system.
The thesis proposes a knowledge-based management
application for a commercially available distributed
computing environment, that is capable of monitoring the
distributed system, detecting performance and
availability problems, and generating corrective actions
to eliminate the problem.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  3100 </NUMBER>
<ORDER>   AAIMM03207 </ORDER>
<TITLE> EVALUATING ALTERNATIVE APPROACHES TO KNOWLEDGE ACQUISITION FOR AN EXPERT SYSTEM </TITLE>
<AUTHOR> MADAN, MUNISH </AUTHOR>
<YEAR> 1995 </YEAR>
<INSTITUTION> UNIVERSITY OF CALGARY (CANADA); 0026 </INSTITUTION>
<DESCRIPTORS> COMPUTER SCIENCE; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> BRIAN GAINES </ADVISER>
<CLASSIFICATIONS> NIL </CLASSIFICATIONS>
<ABSTRACT>
This research compares knowledge acquisition tools and
techniques, during the development of a sample legal
expert system, dealing with intellectual property laws.
The research requires both the creation of a new legal
expert system architecture, and informal, structured,
formal and computational knowledge acquisition. The
research analyzes the entire knowledge acquisition
process, and offers guidelines and observations that may
help to streamline the development of future knowledge
acquisition tools and techniques. The research is
important since all types of computer based problem
solving require knowledge, and accordingly the
identification of powerful knowledge acquisition
techniques is necessary.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  3101 </NUMBER>
<ORDER>   AAIMM03174 </ORDER>
<TITLE> RV-TOOLS: DEVELOPMENT TOOLS FOR BUILDING REGISTER VECTOR PARSERS </TITLE>
<AUTHOR> ASTELS, DAVID RAYMOND </AUTHOR>
<YEAR> 1995 </YEAR>
<INSTITUTION> UNIVERSITY OF CALGARY (CANADA); 0026 </INSTITUTION>
<DESCRIPTORS> COMPUTER SCIENCE </DESCRIPTORS>
<ADVISER> BRUCE A. MACDONALD </ADVISER>
<CLASSIFICATIONS> NIL </CLASSIFICATIONS>
<ABSTRACT>
Natural language understanding is and always has been an
important area of research and development in artificial
intelligence. Natural language understanding is made up
of several processing stages, including morphological,
lexical, syntactic, semantic, and discourse. The stages
of processing morphology, lexicon, and syntax are
commonly combined and called parsing. For natural
language understanding to be widely useful an efficient
model of language must be used for each stage, and it
must be convenient for a system developer to implement
language processors using the model.
The Register Vector (RV) model of language is an
efficient parsing model, having fixed space complexity
and linear time complexity. RV is a low-level formalism,
which results in its efficiency but also makes it
difficult to build RV parsers.
The work described in this thesis is an attempt to make
it easier to develop RV parsers by providing a set of
interactive tools. These tools allow non-linear,
interactive, incremental browsing/editing of parsers,
immediate error feedback, as well as interactive
debugging.
The system described here has been implemented using
Smalltalk-80 on Sun 3 and SparcStation platforms. This
work is the first to try to develop a convenient,
interactive environment for developing RV parsers.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  3102 </NUMBER>
<ORDER>   AAIMM02476 </ORDER>
<TITLE> RAG EXPERT: SYSTEME EXPERT SUR LES REACTIONS ALCALIS- GRANULATS, CARACTERISATION DES GRANULATS ET PREVENTION DES REACTIONS </TITLE>
<AUTHOR> OUELLET, SERGE </AUTHOR>
<YEAR> 1995 </YEAR>
<INSTITUTION> UNIVERSITE LAVAL (CANADA); 0726 </INSTITUTION>
<DESCRIPTORS> ENGINEERING, MATERIALS SCIENCE; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> MARC-ANDRE BERUBE </ADVISER>
<CLASSIFICATIONS> FRENCH TEXT, ARTIFICIAL INTELLIGENCE </CLASSIFICATIONS>
<ABSTRACT>
RAG Expert est un systeme expert d'aide et de prevention
des problemes relies aux reactions alcalis-granulats
(RAG) dans les betons de ciment. Ce logiciel permet
d'evaluer une formule de beton d'apres le dosage et le
contenu en alcalis des divers constituants (granulats,
ciment, ajouts mineraux, adjuvants et eau) et d'analyser
les resultats de onze essais de RAG qui tiennent compte
des dernieres modifications de l'Association Canadienne
de Normalisation. Les essais consideres sont les
suivants: Esamen petrographique ASTM C 295, Essai
chimique CSA A23.2-26A, Barre de mortier acceleree CSA
A23.2-25A, Prisme de beton CSA A23.2-14A a 310 kg/m$sp3$
de ciment Prisme de beton CSA A23.2-14A a 420
kg/m$sp3$de ciment, Methode chimique ASTM C 289, Methode
chimique modifiee ASTM C 289M Barre de mortier a
l'autoclave UL/MTQ, Prisme de beton CSA A23.2-14A
immerge dans une solution alcaline a 80$spcirc$C et
Prisme de beton CSA A23.2-14A modifie a 365 kg/m$sp3$ de
ciment. D'apres ces essais, le logiciel permet de
caracteriser un echantillon ou une source de granulat
face au probleme de la RAG. RAG Rxpert donne aussi la
possibilite d'analyser la performance physico-mecanique
d'un granulat en tenant compte des dernieres exigences
du Ministere des Transports du Quebec. De plus, RAG
Expert donne acces a une base de donnees ou il est
possible de maintenir et de gerer des resultats d'essais
et d'analyses couvrant les aspects suivants:
caracterisation physico-mecanique, analyse chimique,
examen petrographique en lames minces et caracterisation
du potentiel de RAG. Le systeme expert offre aussi un
systeme d'aide sur les RAG et une vaste gamme de
photographies pour illustrer les differentes facettes du
phenomene des RAG.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  3103 </NUMBER>
<ORDER>   AAIMM01948 </ORDER>
<TITLE> AN INVESTIGATION OF ELABORATIVE AND COHERENCE INFERENCES FROM AN ARTIFICIAL KNOWLEDGE BASE </TITLE>
<AUTHOR> SMITH, SHARON DIANTHY </AUTHOR>
<YEAR> 1995 </YEAR>
<INSTITUTION> UNIVERSITY OF TORONTO (CANADA); 0779 </INSTITUTION>
<DESCRIPTORS> EDUCATION, EDUCATIONAL PSYCHOLOGY; EDUCATION, PSYCHOLOGY; EDUCATION, READING; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> LINDA S. SEIGEL </ADVISER>
<CLASSIFICATIONS> NIL </CLASSIFICATIONS>
<ABSTRACT>
Research has show that prior knowledge plays an
essential role in reading comprehension. An examination
of the research literature on inferencing indicates that
rarely is prior knowledge taken into consideration. The
present study controlled for prior knowledge and
examined children's responses to two types of questions:
causal inference, integration of text information and
prior knowledge that is necessary for text
comprehension; and elaborative inference, unnecessary
for text comprehension but enriches the mental model.
Thirty-one 9 to 11 year old skilled readers were tested
individually. They were first taught an artificial
knowledge base about a make believe world called Gan,
then tested on their comprehension of a 10-passage story
about Gan. Consistent with previous research findings,
in the present study elaborative inferences were more
difficult for children to make than coherence
inferences. The children appeared to only perform the
tasks that were necessary for text comprehension.
Controlling for prior knowledge did not affect this
pattern.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  3104 </NUMBER>
<ORDER>   AAIC484635 </ORDER>
<TITLE> FROM PLANAR PATCHES TO GRASPS: A THREE-DIMENSIONAL ROBOT VISION SYSTEM HANDLING UNMODELED OBJECTS </TITLE>
<AUTHOR> TROBINA, MARJAN </AUTHOR>
<YEAR> 1995 </YEAR>
<INSTITUTION> EIDGENOESSISCHE TECHNISCHE HOCHSCHULE ZUERICH (SWITZERLAND); 0663 </INSTITUTION>
<DESCRIPTORS> ENGINEERING, ELECTRONICS AND ELECTRICAL; ARTIFICIAL INTELLIGENCE ZENTRUM, GLORIASTR. 35  CH-8092, ZURICH, SWITZERLAND KONSTANZ, GERMANY </DESCRIPTORS>
<ADVISER> NIL </ADVISER>
<CLASSIFICATIONS> NIL </CLASSIFICATIONS>
<ABSTRACT>
When robots have to manipulate objects in an autonomous
way, i.e. based on visual sensors, the problem is
usually approached by an object recognition strategy. In
many applications, however, unmodeled objects, that is
objects of which no models are available, have to be
dealt with. Such situations arise frequently in
unstructured environments, or in situations where the
variety of possible objects forbids off-line modeling.
In this thesis, a reliable and robust approach to the
problem of grasping unmodeled 3-D objects from a pile is
presented. The approach adheres to the paradigm of
purposive vision, which says that one should only
extract as much information as it is needed to perform a
certain task, e.g. grasping, while a complete and
precise recovery of the shape of the objects is not
necessary. It is shown that planar patches extracted
from range images contain enough information to find
grasps on complex 3-D scenes.
Due to the 3-D nature of the problem range images were
chosen as input data since they provide a direct 3-D
sampling of object surfaces. The thesis starts with the
introduction of an error model of a range sensor based
on the coded-light approach and discusses the chosen
spatial configuration of three static range sensors. The
developed error model is of general use for range data
processing. A spatial configuration of three range
sensors was chosen which fulfills the requirements of
seeing opposite faces on objects, seeing vertical and
even overhanging faces all around objects, while
allowing the combination of range data from the three
sensors.
The central part of the thesis describes the overall
strategy for finding grasps on unmodeled 3-D objects
arranged in a pile. The system consists of the following
three stages: segmentation of range images into planar
patches, establishing of object hypotheses, and finding
grasps. An existing algorithm for segmentation of range
images into planar patches based on the recover- and-
select paradigm was chosen because of its high
robustness. Modifications of the original algorithm
allow to speed up the segmentation process by a factor
of 20. Further, the developed range sensor error model
has been used to achieve a pose and viewpoint invariant
scene description. It was demonstrated that the planar
patches represent a highly compact scene description
compared to the original amount of data points. The
scene description is very efficiently used for
segmenting scene into objects using geometric relations
between pairs of patches, for finding grasps on the
objects by looking for antipodal planar patches, and for
avoiding collisions.
A complete robot vision system (from sensing to
manipulation) was vertically integrated and its
functioning was demonstrated on over 200 scenes. The
objects were arranged in piles consisting of up to 12
objects. More than 50 different 3-D objects were used in
our experiments, including objects with curved surfaces,
objects with holes, objects with reflecting surfaces,
and objects on which range data were partially missing.
The performance characteristics of the complete system
are given and the possibilities for further speeding up
the complete system in the future are proposed.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  3105 </NUMBER>
<ORDER>   AAIC484623 </ORDER>
<TITLE> FROM TRIANGULAR MESHES TO GRASPS: A THREE-DIMENSIONAL ROBOT VISION SYSTEM HANDLING UNMODELED OBJECTS </TITLE>
<AUTHOR> RUTISHAUSER, MARTIN </AUTHOR>
<YEAR> 1995 </YEAR>
<INSTITUTION> EIDGENOESSISCHE TECHNISCHE HOCHSCHULE ZUERICH (SWITZERLAND); 0663 </INSTITUTION>
<DESCRIPTORS> ENGINEERING, ELECTRONICS AND ELECTRICAL; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> NIL </ADVISER>
<CLASSIFICATIONS> NIL </CLASSIFICATIONS>
<ABSTRACT>
If robots are to manipulate objects in weakly structured
environments, they need to be provided with sensors and
certain reasoning capabilities. Up to now, the
dominating approach is to use databases to store a
priori knowledge about all objects admitted in the
scene. This information is used to recognize the objects
and to determine possible grasping points which enables
an actuator to remove the objects.
In this work, we concentrate on the problem of removing
objects from a heap without having recourse to object
models. This capability is useful in several
applications, e.g., cleaning tasks like removing objects
from floors or working surfaces (where no a priori
knowledge about the objects is available), or exception
handling for "traditional" robot systems (where the a
priori knowledge is not sufficient).
We are relying on geometric information alone, and thus,
the use of range sensors to capture the scene is a
natural choice. The objects are to be grasped by a two-
fingered gripper and therefore the system has to see
opposite patches of the object surface. To ensure this,
we use three fixed range sensors with equal angular
spacing around the scene. Each of the three acquired
data sets is tessellated into triangles, using the
measured data points as vertices. A merge of the
tessellated descriptions is performed in such a way that
a "mutual approximation" is achieved in regions of
overlapping data.
The resulting triangular tessellation of the whole data
set serves as the primary scene representation. This
representation is then segmented, i.e., partitioned into
sets of contiguous triangles which correspond to objects
or object components in the scene. This is done by
cutting the surface at jump discontinuities and places
with high concave curvature. A connected component
labeling completes the final scene representation.
The system then tries to detect grasping opportunities.
Two heuristics guide the selection of a "focus of
action" which consists of a suitable component. A novel
approach is then used to search for grasping
opportunities on this component: all combinations of two
vertices are admitted as possible contact points for the
two-finger gripper. Based on evidence accumulation, a
quality measure is defined for each of these vertex
pairs. A discrete optimization algorithm which is based
on Tabu-Search then tries to find several good grasping
configurations. Additional constraints which are not
part of the objective functions (e.g. impending
collisions) have to be respected. If no pairs are found
due to impending collisions or bad grasping quality
another component is checked.
Finally the robot performs the grasping. Force sensing
allows the correction of inaccuracies of the vision
system and the handling of collisions.
The complete system has been implemented, from range
sensing through scene analysis to the actual grasping by
the robot. Throughout the text, several "real" examples
are presented, showing the performance of each
processing step and of the system as a whole.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  3106 </NUMBER>
<ORDER>   AAGC512807 </ORDER>
<TITLE> CONTRAST SENSITIVITY FOR COMPLEX AND RANDOM GRATINGS </TITLE>
<AUTHOR> UKKONEN, OUTI IRENE </AUTHOR>
<YEAR> 1995 </YEAR>
<INSTITUTION> ASTON UNIVERSITY (UNITED KINGDOM); 0734 </INSTITUTION>
<DESCRIPTORS> COMPUTER SCIENCE; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> NIL </ADVISER>
<CLASSIFICATIONS> COMPUTER VISION </CLASSIFICATIONS>
<ABSTRACT>
This thesis studied the effect of (i) the number of
grating components and (ii) parameter randomisation on
root-mean-square (r.m.s.) contrast sensitivity and
spatial integration.
The effectiveness of spatial integration without
external spatial noise depended on the number of equally
spaced orientation components in the sum of gratings.
The critical area marking the saturation of spatial
integration was found to decrease when the number of
components increased from 1 to 5-6 but increased again
at 8-16 components. The critical area behaved similarly
as a function of the number of grating components when
stimuli consisted of 3, 6, or 16 components with
different orientations and/or phases embedded in spatial
noise. Spatial integration seemed to depend on the
global Fourier structure of the stimulus. Spatial
integration was similar for sums of two vertical cosine
or sine gratings with various Michelson contrasts in
noise. The critical area for a grating sum was found to
be a sum of logarithmic critical areas for the component
gratings weighted by their relative Michelson contrasts.
The human visual system was modelled as a simple image
processor where the visual stimuli is first low-pass
filted by the optical modulation transfer function of
the human eye and secondly high-pass filtered, up to the
spatial cut-off frequency determined by the lowest
neural sampling density, by the neural modulation
transfer function of the visual pathways. The internal
noise is then added before signal interpretation occurs
in the brain. The detection is mediated by a local
spatially windowed matched filter. The model was
extended to include complex stimuli and its
applicability to the data was found to be successful.
The shape of spatial integration function was similar
for non-randomised and randomised simple and complex
gratings. However, orientation and/or phase
randomisation reduced r.m.s. contrast sensitivity by a
factor of $sqrt02$. The effect of parameter
randomisation on spatial integration was modelled under
the assumption that human observers change the observer
strategy from cross-correlation (i.e., a matched filter)
to auto-correlation detection when uncertainty is
introduced to the task. The model described the data
accurately.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  3107 </NUMBER>
<ORDER>   AAIC481366 </ORDER>
<TITLE> ASPECTS OF MODELLING AND CONTROL OF BIOPROCESSES: APPLICATION OF CONVENTIONAL APPROACH AND FUNCTIONAL STATE CONCEPT </TITLE>
<AUTHOR> XIA-CHANG, ZHANG </AUTHOR>
<YEAR> 1995 </YEAR>
<INSTITUTION> TEKNILLINEN KORKEAKOULU (HELSINKI) (FINLAND); 5766 </INSTITUTION>
<DESCRIPTORS> ENGINEERING, CHEMICAL; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> NIL </ADVISER>
<CLASSIFICATIONS> FUZZY LOGIC, KNOWLEDGE-BASED, EXPERT SYSTEM </CLASSIFICATIONS>
<ABSTRACT>
Modelling and control of bioprocesses are the main
subjects in this thesis. Different modelling approaches
are proposed for different purposes in various
bioprocesses. At first, a conventional global model
based on mass balance was constructed for a very complex
mammalian cell culture process.
A new helpful concept of functional state and a multiple
model (local models) approach were used for modelling
fed-batch baker's yeast process for monitoring and
control purposes. The functional states were first
defined according to yeast metabolism. The process was
then described by a set of simple local models. In
different functional states, different local models were
used. On the other hand, the on-line estimation of
functional state and biomass of the process was
discussed for process control purpose. Exhaust gas
analysis gives the possibility of on-line estimation
both of functional states and biomass of the process. As
a consequence, both the functional state concept and the
multiple model approach were applied for fuzzy logic
control of yeast growth process. In the fuzzy logic
control algorithm, the control variables were, either,
the respiratory quotient or the on-line estimated
specific growth rate depending on the current functional
state of the process. A fuzzy factor was calculated on
the basis of a knowledge-based expert system and fuzzy
logic rules. The factor was used to correct an ideal
substrate feed rate. By simulation of the process and
comparison with real experimental data from diskette,
the controller was showed to work effectively and
precisely enough. The results also showed that the yeast
fermentation process can be controlled near its optimal
state.
Finally, a combination of conventional electrical and
biological models was used to simulate a microbial fuel
cell process. A microbial fuel cell is a device for
direct conversion of chemical energy to electrical
energy by using microorganisms as catalysts. The
combined model reveals the relationship between the
process output (electrical current) and metabolic
process conditions.
The results showed that different modelling approaches
are useful for different purposes. Especially, the new
functional state modelling approach proved to be very
useful for monitoring, control, and optimization of
bioprocesses.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  3108 </NUMBER>
<ORDER>   AAIC481014 </ORDER>
<TITLE> FUZZY LOGIC IN CONTROL </TITLE>
<AUTHOR> JAGER, RENE </AUTHOR>
<YEAR> 1995 </YEAR>
<INSTITUTION> TECHNISCHE UNIVERSITEIT TE DELFT (THE NETHERLANDS); 0951 </INSTITUTION>
<DESCRIPTORS> ENGINEERING, SYSTEM SCIENCE; ARTIFICIAL INTELLIGENCE DELFT, THE NETHERLANDS </DESCRIPTORS>
<ADVISER> NIL </ADVISER>
<CLASSIFICATIONS> NIL </CLASSIFICATIONS>
<ABSTRACT>
In the application of fuzzy control, the following
stages can be distinguished: matching of data with rule
premises (includes fuzzification), determination of
degrees of fulfillment for the rules, aggregation of
results of individual rules and defuzzification to
obtain a numerical controller output. Because of
fuzzification and defuzzification, a fuzzy controller
can be regarded as an input-output mapping. Regarding a
fuzzy controller (or model) as such a mapping, it can be
shown that the mapping is characterized by tuples in a
hyperspace and each tuple represents a fuzzy rule. The
fuzzy reasoning performs an interpolation between these
tuples in that hyperspace, resulting in a (nonlinear)
input-output mapping. Based on this idea of
interpolation, it can be shown that many non-trivial
nonlinearities can be introduced by the used operators,
defuzzification method, shape of membership functions of
fuzzy sets and the relations between fuzzy sets on a
universe.
Fuzzy control can be regarded as only a small part of
the much broader framework of approximate reasoning and
possibility theory. A major disadvantage is the lack of
practical applicability due to severe calculational
effort and/or memory requirements to perform the
reasoning according to the theory of approximate
reasoning. An inference break-up can reduce the
inference of a complex rule base to inference of a
number of simple rule bases.
In many cases a fuzzy controller can be simplified to a
look-up table and an interpolation method to provide the
"fuzzy inference". The same idea can be used to simplify
adaptive fuzzy controllers. The self-organizing
controller can be simplified by a look-up table and an
interpolation method where the elements of the look-up
table, representing the (numerical) consequents of the
fuzzy rules, are adapted. The adaptive fuzzy systems
based on gradient-descent optimization can be simplified
to the adaptation of a look-up table of which the
elements and the index vectors, representing the centers
of the fuzzy sets on the input universes, are adapted.
Hence, these simplifications can reduce the fuzzy aspect
of fuzzy control to a user-interfacing concept during
the design stage.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  3109 </NUMBER>
<ORDER>   AAIC481000 </ORDER>
<TITLE> A FRAMEWORK FOR KNOWLEDGE-BASED MAP INTERPRETATION </TITLE>
<AUTHOR> DEN HARTOG, JURGEN EDWIN </AUTHOR>
<YEAR> 1995 </YEAR>
<INSTITUTION> TECHNISCHE UNIVERSITEIT TE DELFT (THE NETHERLANDS); 0951 </INSTITUTION>
<DESCRIPTORS> COMPUTER SCIENCE; ARTIFICIAL INTELLIGENCE; GEOGRAPHY DELFT, THE NETHERLANDS </DESCRIPTORS>
<ADVISER> NIL </ADVISER>
<CLASSIFICATIONS> IMAGE PROCESSING </CLASSIFICATIONS>
<ABSTRACT>
Many public utilities have large stocks of paper maps.
The information in these maps needs to be converted to a
digital object description to meet the requirements of
dedicated databases such as GIS. This thesis
concentrates on the development of automatic techniques
for this conversion using a priori knowledge about the
application and suitable image processing techniques.
Within this study, a framework has been developed for
knowledge-based map interpretation which integrates a
dedicated knowledge representation language, image
processing, and a reasoning mechanism.
Chapters 2 and 3 concentrate on the preprocessing needed
for object recognition. In Chapter 2, a new low-level
representation is proposed as an alternative to the
standard approach of vectorization. The main advantage
of this approach is that, compared to standard
vectorization, the morphological information is
retained.
Chapter 4 focuses on the use of knowledge to guide the
interpretation process by means of contextual reasoning.
The a priori map knowledge consists of the objects which
occur in the maps, their shape, and their
interrelationships. The concept of contextual reasoning
is based on the observation that each object type is
related to other object types. Thus, detection of an
object immediately generates expectations about other
objects in its neighborhood, which are very suitable to
generate new goals for the interpretation process. The
model is extended to detect inconsistencies during
interpretation.
Most inconsistencies are due to a poor global
segmentation. To be able to solve these inconsistencies
automatically, the model is further refined with
knowledge about image processing in Chapter 5. In the
new model, both the cause of the inconsistency (the
global segmentation) and its solution (a new, object-
specific segmentation) can be represented.
In Chapter 6, the applicability of the developed
concepts for aerial image interpretation is explored.
The potential use of contextual reasoning for this
specific domain is illustrated with a case-study.
The main conclusion is that the framework proposed in
this thesis is a promising and flexible approach to map
interpretation. The experimental results indicate that
the framework provides an effective mechanism to guide
the interpretation and the segmentation. Currently, the
TNO Institute of Applied Physics is involved in a
research project, together with two Dutch universities,
to develop an operational semi-automatic conversion
system for a Dutch utility which should become
operational early 1997.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  3110 </NUMBER>
<ORDER>   AAIC480682 </ORDER>
<TITLE> APPLICATION OF IMAGE ANALYSIS TO COAL FLOTATION </TITLE>
<AUTHOR> HARGRAVE, JONATHAN MARK </AUTHOR>
<YEAR> 1995 </YEAR>
<INSTITUTION> UNIVERSITY OF NOTTINGHAM (UNITED KINGDOM); 0616 </INSTITUTION>
<DESCRIPTORS> ENGINEERING, MINING; ARTIFICIAL INTELLIGENCE NOTTINGHAM </DESCRIPTORS>
<ADVISER> NIL </ADVISER>
<CLASSIFICATIONS> NIL </CLASSIFICATIONS>
<ABSTRACT>
Control is a neglected area of coal flotation, with most
coal preparation plants having little or no form of
automatic flotation control. Although some control
systems have been developed these have not been widely
accepted, principally on their high inherent cost.
In flotation plants manual control is carried out by
operators who make decisions based partially on a
subjective visual observation of the froth structure in
a bank. It is well known that the appearance of the
froth changes down a bank of cells and that these are
linked to changes in froth loading and concentrate
quality. It was considered that this manual approach
could be automated, to a degree, by the application of
image processing and artificial intelligence techniques.
By using fairly basic image analysis techniques
information was obtained on the bubble size distribution
and the grey level profile of the various froths. Which
was successfully linked to some of the flotation cells
performance characteristics, firstly on a single small
continuous cell then on a bank of four pilot scale
cells. It was demonstrated that most of the flotation
performance parameters can be predicted from the image
analysis values to within 20%.
Testwork was also conducted at Thoresby coal preparation
plant which indicated that the image analysis procedures
could be successfully applied in an industrial
situation. The image analysis procedure was attempted on
the Jameson cell and also on the flotation column.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  3111 </NUMBER>
<ORDER>   AAIC480672 </ORDER>
<TITLE> APPLICATION OF NEURAL NETWORKS TO MINERAL RESERVE ESTIMATION </TITLE>
<AUTHOR> BURNETT, CHRISTOPHER CHARLES H. </AUTHOR>
<YEAR> 1995 </YEAR>
<INSTITUTION> UNIVERSITY OF NOTTINGHAM (UNITED KINGDOM); 0616 </INSTITUTION>
<DESCRIPTORS> ENGINEERING, MINING; ARTIFICIAL INTELLIGENCE OF NOTTINGHAM </DESCRIPTORS>
<ADVISER> NIL </ADVISER>
<CLASSIFICATIONS> NIL </CLASSIFICATIONS>
<ABSTRACT>
The reserve estimation process is a fundamental part of
any mineral deposit evaluation, and will often determine
the economic viability of extracting the deposit. The
most useful existing reserve estimation techniques are
often complex, subject to restrictive assumptions, and
require a high degree of expert knowledge to be applied
successfully. The recent advances in the field of
artificial neural networks, (ANNs), suggest a new
approach to the reserve estimation problem that
addresses many of the disadvantages of currently used
techniques. ANNs are information processing structures
that can "learn" the solution to a problem through a
process of self adaptation in response to "examples"
from the problem domain. They excel at approximating
complex relationships between variables, and are also
capable of utilising any data as input that can be
expressed in a numerical format.
Work has therefore been undertaken in the AIMS research
unit within the Department of Mineral Resources
Engineering at the University of Nottingham, to
investigate the application of ANNs to reserve
estimation. This thesis examines the suitability of ANNs
for reserve estimation, and describes the design and
evaluation of a neural network based reserve estimation
system, GEMNet, developed by the author.
In its most basic form the reserve estimation problem is
one of interpolation between known data points in order
to estimate values at unknown locations. The problem can
be regarded essentially as a function approximation or
mapping task. The mapping to be approximated is the one
between the mineral grade and a combination of location
and other variables. The GEMNet system uses ANNs to
learn this mapping from known examples of the mapping,
derived from borehole assay data. The technique
developed involves the use of multiple ANNs for
estimation, which also provides a form of reliability
indicator for predictions produced by the system.
The GEMNet system is applied to three reserve estimation
case studies which show it is capable of handling both 2
& 3D data sets, and also that its performance compares
favourably with conventional estimation techniques. Its
main advantages over more conventional techniques are
that it makes fewer assumptions about the form of the
raw data, it requires less in the way of expert
knowledge to produce useful results, and it offers the
possibility of incorporating different data types into
the reserve estimation process.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  3112 </NUMBER>
<ORDER>   AAIC480671 </ORDER>
<TITLE> NOISE HAZARD ASSESSMENT IN SURFACE MINE DESIGN </TITLE>
<AUTHOR> VON BROCKDORFF-AHLEFELDT, CAY GRAF </AUTHOR>
<YEAR> 1995 </YEAR>
<INSTITUTION> UNIVERSITY OF NOTTINGHAM (UNITED KINGDOM); 0616 </INSTITUTION>
<DESCRIPTORS> ENGINEERING, MINING; ARTIFICIAL INTELLIGENCE; ENVIRONMENTAL SCIENCES </DESCRIPTORS>
<ADVISER> NIL </ADVISER>
<CLASSIFICATIONS> NIL </CLASSIFICATIONS>
<ABSTRACT>
Noise problems are a common environmental issue in
surface mining. This Ph.D. thesis highlights the need
for computerised noise modelling and reviews the
development of a decision support system known as Expert
Noise Modelling System (ENMS) for the assessment of
noise levels in the vicinity of U.K. surface coal mines.
Engineering requirements of opencast extraction
techniques, combined with the site specific conditions
are considered in the computer model. These parameters
are used as inputs to a model, in order to analyse the
potential noise levels at residential areas in the
vicinity of the site.
Although there are many factors and variables involved
in the prediction of outdoor noise levels, the use of
British Standards BS 5228 is generally regarded as the
standard procedure for the prediction of noise. This
thesis describes the various attenuation effects on
noise and forms a framework from which a rudimentary
prediction and expert system is derived. ENMS utilises
the data obtained from the prediction package and
compares these results with threshold noise limits and
identifies specific activities which may give
environmental problems.
A novel aspect of ENMS is the use of knowledge-based
expert system technology to provide recommendations for
reductions in noise levels in order to minimise
environmental impact.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  3113 </NUMBER>
<ORDER>   AAIC480597 </ORDER>
<TITLE> DESIGN OF A RECONFIGURABLE NEUROCOMPUTER PERFORMANCE ANALYSIS BY IMPLEMENTATION OF RECURRENT ASSOCIATIVE MEMORIES  </TITLE>
<AUTHOR> UTNE, LISBET </AUTHOR>
<YEAR> 1995 </YEAR>
<INSTITUTION> UNIVERSITETET I TRONDHEIM (NORWAY); 0941 </INSTITUTION>
<DESCRIPTORS> COMPUTER SCIENCE; ARTIFICIAL INTELLIGENCE N-7034 TRONDHEIM-NTH, NORWAY NORWEGIAN INSTITUTE  OF TECHNOLOGY, O.S. BRAGSTADS PLASS 2, N-7034 TRONDHEIM, NORWAY </DESCRIPTORS>
<ADVISER> NIL </ADVISER>
<CLASSIFICATIONS> ARTIFICIAL INTELLIGENCE </CLASSIFICATIONS>
<ABSTRACT>
The main objective has been to design and build a
neurocomputer for experimenting with different system
architectures for simulation of artificial neural
networks (ANNs). RENNS, REconfigurable Neural Network
Server, is a moderately parallel programmable
neurocomputer designed at the Norwegian Institute of
Technology. The RENNS architecture is scaleable, with
processing modules and their attached data streams as
building blocks. Each module consists of one TMS320C30
DSP, memory hierarchy, and a separate communication
subsystem. The modules can be connected through four
bidirectional communication links. Being dynamically
reconfigurable, RENNS can form a range of communication
architectures.
For performance analysis, recurrent associative memories
are implemented and applied on a simple pattern
recognition problem. One of the methods overcomes
limitations of the original Hopfield net but requires
extensive resources of memory and computational
capacity. Various parallelisation and mapping strategies
have been investigated. With an eight-processor
configuration, performance of 40.82 MCPS (Million
Connections Processed per Second) is achieved, a
utilisation of numerical capacity of 5.9 FLOPS/CPS. On
eight processors, speedup of 7.7 compared to the one-
processor case is achieved for large patterns. For small
patterns, communication costs and the sequential part of
the program become more significant, reducing speedup to
5.7. A straight forward parallelisation strategy, with
non-overlapping communication and computation on a one-
dimensional ring, using token-ring protocol, showed to
be most efficient. Attempts to pipeline computations and
communication, and to increase communication bandwidth
by a two-dimensional toroidal mesh, do not lead to
increased performance. Although waiting time for data is
reduced, more complex code and a larger non-
parallelisable part of the program instead reduce the
performance.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  3114 </NUMBER>
<ORDER>   AAIC480355 </ORDER>
<TITLE> FUZZY SUPERVISORY SYSTEMS FOR BIOPROCESS DIAGNOSIS AND CONTROL  </TITLE>
<AUTHOR> SIIMES, TERHI TUULIKKI </AUTHOR>
<YEAR> 1995 </YEAR>
<INSTITUTION> TEKNILLINEN KORKEAKOULU (HELSINKI) (FINLAND); 5766 </INSTITUTION>
<DESCRIPTORS> ENGINEERING, CHEMICAL; AGRICULTURE, FOOD SCIENCE AND TECHNOLOGY; ARTIFICIAL INTELLIGENCE ESPOO, FINLAND </DESCRIPTORS>
<ADVISER> NIL </ADVISER>
<CLASSIFICATIONS> FUZZY LOGIC, YEAST, FERMENTATION </CLASSIFICATIONS>
<ABSTRACT>
It has been shown during recent years that artificial
intelligence (AI) technologies can be successfully
employed in the area of bioprocess modelling and
control. The rapid development of computer hardware has
enhanced the application of AI paradigms and methods to
relatively complicated bioprocess management. The type
and amount of knowledge needed to control a bioprocess
is multidimensional and large, and typically of
heuristic nature. Exact bioprocess models, or often
important numerical information are lacking, favoring
the application of techniques mimicking human reasoning.
The aim of this work was to build easy-to-use
intelligent systems to support the operator, and aid in
bioprocess diagnosis and control by acting as
supervisory control systems and by utilizing heuristic
expert knowledge about the process. For that purpose, an
object-oriented programming environment, Smalltalk/V
Mac, was employed in a Macintosh computer. In the system
developed, fuzzy logic was utilized to handle
uncertainties in process knowledge and measurements.
Example applications during the system development were
provided by lactic acid fermentation and fed-batch
baker's yeast cultivation.
The off-line diagnosing ability of the system was tested
by studying the effects of precultivation conditions in
lactic acid fermentation. The system was improved to
perform online diagnosis and to be able to suggest
possible corrective actions to the operator. Later, the
structure of the system knowledge base was modified to
comprise two levels, one for recognizing the process
functional states, and the other for the diagnosis and
control of each state. The new features of the system
were then tested on baker's yeast fermentations, in the
form both of experimental data from literature, and
process simulations. The cultivation was divided into 5
phases on the basis of fuzzy rules describing yeast
metabolism, and during each phase, the substrate feed
rate was controlled using fuzzy rules.
The system was constructed stepwise with two application
examples in different scales. Programming of new modules
and features was quick and easy through an object-
oriented environment. The resultant system offers a
simple frame to be applied to a new process. The system
functioning was tested in laboratory scale simulations
and discovered to offer enhancements in bioprocess
control.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  3115 </NUMBER>
<ORDER>   AAIC477552 </ORDER>
<TITLE> APPROACHES TO THE FOUR COLOUR THEOREM </TITLE>
<AUTHOR> LOUPEKINE, FEODOR </AUTHOR>
<YEAR> 1995 </YEAR>
<INSTITUTION> OPEN UNIVERSITY (UNITED KINGDOM); 0949 </INSTITUTION>
<DESCRIPTORS> MATHEMATICS </DESCRIPTORS>
<ADVISER> NIL </ADVISER>
<CLASSIFICATIONS> GRAPH THEORY, EDGE COLORING </CLASSIFICATIONS>
<ABSTRACT>
The Four Colour Problem is the most celebrated problem
in graph theory, and its solution this century has been
one of the greatest spurs to graph theory of all time.
Solved only by artificial intelligence, it has been
conjectured by Zhou Shuguo amongst others, that there
may be a solution using only traditional mathematics.
The small groups up to S$sb3$ are applied to different
aspects of the problem, and the present text paves the
way for deciding definitely whether Z. Shoguo's
conjecture is true--or, more likely--false.
After dealing with C$sb2$, the author moves on to
discuss snarks and reveals how his family of snarks was
discovered some 20 years ago. The conjecture of whether
any planar graph is a subgraph of a larger triangular
graph of even order is seen to be equivalent to the four
colour theorem.
Chapters five and six deal with the S$sb3$ results. The
preamble occupying the whole of chapter five is the only
known way of establishing these results on a strong
footing. In chapter six we see that the various S$sb3$
results are all equivalent.
The final chapter deals with the most promising of the
new approaches. It starts with a general approach to
edge colouring graphs with elements of the Klein four-
group and ends up deep in sample theory. On the way we
examine sets of spanning circuits in the so-called
alternate angle labellings, and finally arrive at a
simple conjecture in sample theory that is exactly
equivalent to the four colour theorem.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  3116 </NUMBER>
<ORDER>   AAIC476688 </ORDER>
<TITLE> ALGORITMOS DE VISION ARTIFICIAL Y DE RECONOCIMIENTO DE PATRONES PARA EL ESTUDIO MORFOMETRICO DEL EJE RAQUIDEO HUMANO; ARTIFICIAL VISION AND PATTERN RECOGNITION ALGORITHMS FOR THE MORPHOMETRIC STUDY OF THE HUMAN SPINE </TITLE>
<AUTHOR> INESTA QUEREDA, JOSE MANUEL </AUTHOR>
<YEAR> 1995 </YEAR>
<INSTITUTION> UNIVERSITAT DE VALENCIA (SPAIN); 5871 </INSTITUTION>
<DESCRIPTORS> BIOLOGY, ANATOMY; ARTIFICIAL INTELLIGENCE; HEALTH SCIENCES, PATHOLOGY VALENCIA, C. DE LA NAVE, 2,  E-46003 VALENCIA, SPAIN </DESCRIPTORS>
<ADVISER> NIL </ADVISER>
<CLASSIFICATIONS> ARTIFICIAL INTELLIGENCE </CLASSIFICATIONS>
<ABSTRACT>
Knowledge of the human vertebral morphology is much
better developed from the qualitative point of view than
from the quantitative one. The feasibility of a method
to extract anatomical information from them using image
analysis is discussed. This feature extraction is fully
automatic, so (1) simplicity in data acquisition is
achieved, allowing straight-forward and fast measurement
of a lot of samples; and (2) the subjectivity of the
human observer is avoided. The morphometric database
obtained will be used as a training set to investigate
the possibility of objective identification of vertebral
levels. We have demonstrated the capability to perform
this classification with a small degree of uncertainty.
Artificial neural networks, in particular, (multilayer
perceptron trained with backpropagation) have shown
their capability to perform well in this difficult
pattern recognition task.
Among the contributions in image analysis are: a pseudo-
binarizing method for well contrasted images that allows
the use of grey levels in the edge zones for using
subpixel precision; a non-parametric algorithm for
detecting dominant points with deletion of collinear
points that gives excellent results when the compression
rate and the global error are considered together; the
extended delta rule as an efficient and precise method
to assess moments, which is able to use the subpixel
approach; the use of k-symmetry as a tool for describing
digital contours and for detecting interesting
anatomical landmarks; and an algorithm for objectively
assessing the degree of deformity of pathologic
vertebrae, defining the degree of scoliosis in the axial
plane.
This work could be regarded as a first step towards a
future implementation of this recognition system. To do
it, some improvements should be taken into account: (1)
More robustness in the vertebra positioning in the
scene. (2) The system should be able to deal with
incomplete data (broken or deformed vertebrae). (3) The
size of the training set should be increased to improve
the knowledge about the vertebrae. (4) Features
extracted from other projections could be considered.
(5) A lot of pattern recognition schemes still remain to
be studied comparatively. In this regard, our current
results should be considered as a lower limit to the
recognition rate that could be achieved.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  3117 </NUMBER>
<ORDER>   AAGC512802 </ORDER>
<TITLE> EVOLUTIONARY NEURAL NETWORKS: MODELS AND APPLICATIONS </TITLE>
<AUTHOR> WILLIAMS, VAUGHAN </AUTHOR>
<YEAR> 1995 </YEAR>
<INSTITUTION> ASTON UNIVERSITY (UNITED KINGDOM); 0734 </INSTITUTION>
<DESCRIPTORS> ENGINEERING, ELECTRONICS AND ELECTRICAL; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> NIL </ADVISER>
<CLASSIFICATIONS> GENETIC ALGORITHMS, SCALING </CLASSIFICATIONS>
<ABSTRACT>
The scaling problems which afflict attempts to optimise
neural networks (NNs) with genetic algorithms (GAs) are
discussed. A novel GA-NN hybrid is introduced, based on
the bumptree, a little-used connectionist model. As well
as being computationally efficient, the bumptree is
shown to be more amenable to genetic coding than other
NN models. A hierarchical genetic coding scheme is
developed for the bumptree and shown to have low
redundancy, as well as being complete and closed with
respect to the search space. When applied to optimising
bumptree architectures for classification problems the
GA discovers bumptrees which significantly out-perform
those constructed using a standard algorithm.
The fields of artificial life, control and robotics are
identified as likely application areas for the
evolutionary optimisation of NNs. An artificial life
case-study is presented and discussed. Experiments are
reported which show that the GA-bumptree is able to
learn simulated pole balancing and car parking tasks
using only limited environmental feedback. A simple
modification of the fitness function allows the GA-
bumptree to learn mappings which are multi-modal, such
as robot arm inverse kinematics.
The dynamics of the 'geographic speciation' selection
model used by the GA-bumptree are investigated
empirically and the convergence profile is introduced as
an analytical tool. The relationships between the rate
of genetic convergence and the phenomena of speciation,
genetic drift and punctuated equilibrium are discussed.
The importance of genetic linkage to GA design is
discussed and two new recombination operators are
introduced. The first, linkage mapped crossover (LMX) is
shown to be a generalisation of existing crossover
operators. LMX provides a new framework for
incorporating prior knowledge into GAs. Its adaptive
form, ALMX, is shown to be able to infer linkage
relationships automatically during genetic search.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  3118 </NUMBER>
<ORDER>   AAIC476127 </ORDER>
<TITLE> BIOPROCESS MONITORING WITH HYBRID NEURAL NETWORK/MECHANISTIC MODEL BASED STATE ESTIMATORS; BIOPROCESS MONITORING WITH HYBRID NEURAL NETWORK/MECHANISTIC MODEL BASED STATE ESTIMATORS </TITLE>
<AUTHOR> ZORZETTO, LUIZ FLAVIO MARTINS </AUTHOR>
<YEAR> 1995 </YEAR>
<INSTITUTION> UNIVERSITY OF NOTTINGHAM (UNITED KINGDOM); 0616 </INSTITUTION>
<DESCRIPTORS> ENGINEERING, CHEMICAL; ARTIFICIAL INTELLIGENCE U.K. </DESCRIPTORS>
<ADVISER> NIL </ADVISER>
<CLASSIFICATIONS> NIL </CLASSIFICATIONS>
<ABSTRACT>
The development of efficient monitoring strategies for
industrial bioprocesses has been hindered by two major
obstacles: the lack of reliable key process variable
measurements and the difficulty of defining mechanistic
mathematical equations to describe the relationship
between the specific rate of microbial growth and the
process state variables. In this work, an alternative
strategy is proposed to estimate the non-measurable
bioprocess variables on-line. This strategy makes use of
a hybrid model, that combines the traditional
differential balance equations, describing the dynamics
of the main system components, with Artificial Neural
Networks (ANN), to model the specific rate of growth. A
modified extended Kalman filter, that handles the ANN
intrinsic error together with the process and
measurement disturbances, is developed around the hybrid
model to perform the estimation. The proposed estimation
strategy is also applicable to Chemical Engineering
systems that can be modelled with the same combined set
of balance and rate equations as the bioprocesses. The
performance of the hybrid modelling approach and the
estimation scheme is examined in four case studies: two
bio-systems (a simulated fed-batch production of
Saccharomyces cerevisiae and an experimental batch bio-
oxidation of D-sorbitol to L-sorbose) and two non-
biological systems (a cascade of three process vessels
and a semi-batch chemical reactor, involving two
parallel reactions). In these case studies, the use of
the hybrid model to describe their dynamics presented
very satisfactory results. The employment of ANNs to
model the rate equations proved to be very efficient,
considering the accuracy of their outputs and the
reduced time to select and train a suitable ANN
structure, when compared with the time needed to develop
a traditional mechanistic model. The estimation strategy
that incorporates the hybrid model produced quite
precise values for the non-measured key variables in the
examined systems, representing a very helpful tool for
bioprocess monitoring.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  3119 </NUMBER>
<ORDER>   AAIC476007 </ORDER>
<TITLE> AN INVESTIGATION INTO THE SCOPE FOR THE INTRODUCTION OF A DYNAMIC SCHEDULING CAPABILITY INTO A BATCH PRODUCTION ENVIRONMENT </TITLE>
<AUTHOR> STEINER, SIMON J. </AUTHOR>
<YEAR> 1995 </YEAR>
<INSTITUTION> COVENTRY UNIVERSITY (UNITED KINGDOM); 1201 </INSTITUTION>
<DESCRIPTORS> OPERATIONS RESEARCH; ENGINEERING, INDUSTRIAL; ENGINEERING, SYSTEM SCIENCE </DESCRIPTORS>
<ADVISER> NIL </ADVISER>
<CLASSIFICATIONS> CAM </CLASSIFICATIONS>
<ABSTRACT>
This research programme was established to investigate
the perceived changing circumstances in batch
manufacture, both in terms of the demands placed on the
systems by the market and the expectation for
improvements in system performance by the application of
"new" techniques for control. The principal aim of the
research programme was to investigate and establish a
dynamic scheduling capability, for use in a batch
production type environment for small parts manufacture,
which could subsequently provide on-line control at shop
floor level for line management.
Surveys of industry and visits to industrial
implementations of Computer Aided Production Management
(CAPM) systems were used to investigate the perceived
growing demands for on-line shop floor control. The
changes that have taken place in manufacturing
management as a consequence of implementing new
technologies for advanced systems of manufacture were
identified.
The findings of the research indicated the need for a
'front-end' to the large commercial MRP-based systems,
that could complement JIT, KANBAN, and OPT principles in
order to effect improved control of shop floor
activities. Although a number of commercial systems from
software houses have become available during the
research programme, their current shortcomings are
likely to limit their adoption by industry for some
time.
A modelling package, with a graphical simulation
capability, was developed under this research programme,
as a vehicle for investigating the scope for the
application of dynamic scheduling. The software is able
to model the shop floor environment, and is able to
represent alternative strategies of operation. The model
can simulate the operation of an advanced system of
manufacture as specified by the user, and has the
capability to dynamically re-schedule work according to
revised plans as the work progresses through its
manufacturing sequence.
The simulation capability of the software has enabled a
number of the principles relating to dynamic scheduling
to be appraised, firstly by using test data, and
secondly by using industrial data obtained as part of
establishing collaboration with a manufacturing supplier
of component parts and assemblies to the automotive
industry. Evidence of new knowledge has been
demonstrated by the creation and application of this
simple shop scheduling software, which can distinguish
clearly between the performance results obtained from
using different, short-term scheduling regimes and
rules.
The scope for the introduction of dynamic scheduling
into a batch production environment has been
established, together with the scope for the
implementation of appropriate software that has an
Artificial Intelligence capability for improved
shopfloor control by line management. Resulting from
this, a second PhD programme has been established,
running in parallel with this programme for the past
year, where the aim of the second programme is to
implement an AI-based shop floor control system for the
collaborating industrial company.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  3120 </NUMBER>
<ORDER>   AAI9612503 </ORDER>
<TITLE> LEARNING CONTROL OF A QUADRUPED WALKING MACHINE USING CEREBELLAR MODEL ARTICULATION CONTROLLER NEURAL NETWORKS </TITLE>
<AUTHOR> LIN, YI </AUTHOR>
<YEAR> 1995 </YEAR>
<INSTITUTION> UNIVERSITY OF ILLINOIS AT CHICAGO; 0799 </INSTITUTION>
<DESCRIPTORS> ENGINEERING, MECHANICAL; APPLIED MECHANICS; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> NIL </ADVISER>
<CLASSIFICATIONS> ARTIFICIAL INTELLIGENCE </CLASSIFICATIONS>
<ABSTRACT>
This work aims to explore the power of learning and
speed of one type of the artificial neural networks,
namely the Cerebellar Model Articulation Controller
(CMAC). The capabilities and limitations of CMAC are
investigated and compared with other types of neural
networks. Then, a CMAC-based learning algorithm is
applied to the kinematic control of a walking machine.
The stability of the CMAC-based control scheme is also
studied and a mathematical proof of the asymptotical
stability for the regulation control is derived. The
developed algorithm is then extended to control both the
position and force of a two degrees-of-freedom leg
walking on soft terrain. It is demonstrated that the
CMAC-based learning system performs better than the mere
feedback control in terms of speed and accuracy.
Furthermore, the CMAC-based hybrid force/position
control is applied to control a quadruped walking
machine walking on a flat and soft terrain. Finally, the
proposed walking control are simulated using a self-
developed animation software package. The entire
learning control process was accomplished on a PC/AT
personal computer with a CMAC board.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  3121 </NUMBER>
<ORDER>   AAI9612210 </ORDER>
<TITLE> NEURAL EXCITATION, TRAINING, AND CONTROL OF BIOROBOTIC SYSTEMS  </TITLE>
<AUTHOR> KIM, JAYWOO </AUTHOR>
<YEAR> 1995 </YEAR>
<INSTITUTION> THE OHIO STATE UNIVERSITY; 0168 </INSTITUTION>
<DESCRIPTORS> ENGINEERING, BIOMEDICAL; ENGINEERING, ELECTRONICS AND ELECTRICAL; ENGINEERING, MECHANICAL; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> HOOSHANG HEMAMI </ADVISER>
<CLASSIFICATIONS> NEURAL NETWORKS, ROBOTICS </CLASSIFICATIONS>
<ABSTRACT>
The problems of voluntary movement and trajectory
tracking control of a three-dimensional model of the
human upper torso and head is considered in this
dissertation. The torso and the head are modeled as two
rigid bodies connected at one point, and the Newton-
Euler method is used to derive the nonlinear
differential equations that govern the motion of the
system. The two-link system is driven by six pairs of
muscle-like actuators that possess physiologically
inspired alpha- and gamma-like inputs, and spindle- and
Golgi tendon organ-like outputs. These outputs are
utilized as reflex feedback for stability and stiffness
control in a long loop feedback for the purpose of
estimating the state of the system (somesthesis) and as
part of the input to the controller. Ideal delays of
different duration, proportional to the distance of the
actuators from the controller, are included in the
feedforward and feedback paths of the system to emulate
such delays encountered in physiological systems.
A possible neural structure and a learning scheme for
motor control are also investigated in this
dissertation. A dynamic neural network is the basic
building block of five neural networks involved in
trajectory generation, system state estimation, delay
compensation, and generation of two command signals to
each actuator. The learning strategy is tested on both a
sagittal one-link arm and the three-dimensional human
upper torso and head model. The dynamical neural
networks are trained to learn effective control of the
desired maneuvers of the system. The feasibility of the
controller is demonstrated by computer simulation of the
successful execution of a point-to-point movement and
rhythmic maneuvers and adaptation to an unexpected load
change.
This work is a step in the direction of understanding
the workings and, possibly, the structure of the central
nervous system in living systems. It demonstrates the
capabilities of neural circuits in controlling highly
nonlinear systems with multi-delays in their feedforward
and feedback paths. The ultimate long-range goal of this
research is towards understanding the working of the
central nervous system in controlling movement. It is an
interdisciplinary effort relying on mechanics,
biomechanics, neuroscience, system theory, physiology
and anatomy, and its short-range relevance to
rehabilitation must be noted.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  3122 </NUMBER>
<ORDER>   AAI9612102 </ORDER>
<TITLE> GENETIC SELECTION AND NEURAL MODELING FOR DESIGNING PATTERN CLASSIFIERS  </TITLE>
<AUTHOR> VRIESENGA, MARK RICHARD </AUTHOR>
<YEAR> 1995 </YEAR>
<INSTITUTION> UNIVERSITY OF CALIFORNIA, IRVINE; 0030 </INSTITUTION>
<DESCRIPTORS> ENGINEERING, ELECTRONICS AND ELECTRICAL; COMPUTER SCIENCE; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> JACK SKLANSKY </ADVISER>
<CLASSIFICATIONS> ARTIFICIAL INTELLIGENCE </CLASSIFICATIONS>
<ABSTRACT>
We show how genetic algorithms and neural modeling
provide powerful new tools for the design of trainable
pattern classifiers--including neural classifiers--based
on statistical decision theory and cluster analysis. We
describe two major uses of genetic algorithms for
designing linear and piecewise linear classifiers: (a)
the selection of features from an initially large set,
and (b) the global optimization of these classifiers,
thereby avoiding local performance maxima. Neural
modeling involves the replacement of step decision
functions by differentiable decision functions. By
applying neural modeling to genetically designed
piecewise linear classifiers, we obtain globally
optimized neural classifiers in which the number of
neurons strike a good balance between classification
accuracy and generalizing ability. We describe
applications of these techniques to an adaptive detector
of abnormal tissue in mammograms and a detector of
straight lines and edges in noisy aerial images.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  3123 </NUMBER>
<ORDER>   AAI9612071 </ORDER>
<TITLE> CASCADE ERROR PROJECTION: AN EFFICIENT HARDWARE LEARNING ALGORITHM  </TITLE>
<AUTHOR> DUONG, TUAN ANH </AUTHOR>
<YEAR> 1995 </YEAR>
<INSTITUTION> UNIVERSITY OF CALIFORNIA, IRVINE; 0030 </INSTITUTION>
<DESCRIPTORS> ENGINEERING, ELECTRONICS AND ELECTRICAL; ARTIFICIAL INTELLIGENCE; COMPUTER SCIENCE </DESCRIPTORS>
<ADVISER> ALLEN R. STUBBERUD </ADVISER>
<CLASSIFICATIONS> BACK PROPAGATION, NEURAL NETWORKS, LEARNING, ARTIFICIAL INTELLIGENCE </CLASSIFICATIONS>
<ABSTRACT>
In this dissertation, a novel learning methodology for
neural networks entitled "Cascade Back Propagation"
(CBP) is proposed and analyzed. This learning technique
overcomes the difficulties in implementing the Back
propagation (BP) learning algorithm in hardware.
Simulations demonstrate that from a hardware
implementation view point, as few as 5 bits weight
quantization are required for CBP in sharp contrast to
the 8-16 bits weight quantization required for BP and
Cascade Correlation (CC) hardware implementation. A
minor drawback of this proposed approach is that the
network converges slowly. To address this training time
issue, the Cascade Error Projection (CEP) technique is
introduced.
In the CEP learning algorithm, the mathematical analysis
demonstrates the existence of a weight sub-space such
that the network converges in Liapunov's sense when
weight sets are cascaded into the network. This analysis
not only confirms the convergence of the network using
the CEP learning algorithm, but it also helps to
understand the depth and subtleties of the CC. Moreover,
for a discrete weight space, the theoretical analysis
presents the capability of learning with limited weight
quantization as well. In the CEP, hidden units are added
only one at a time, while a pool of candidate hidden
units is used in CC. In addition, a part of the weight
set is trained by the one layer perceptron learning
algorithm, and the other part of the weight set is
obtained by deterministic calculation. This results in a
network which is easy and reliable to implement in
hardware. As a benchmark to validate the theory,
simulations show that with 3 to 4 bit weight
quantization, the network is able to learn 5- to 8-bit
parity problems. The results demonstrate that the CEP
follows the analytic prediction limits between the
continuous weight and limited weight quantization space.
Finally, the comparisons among CC, CBP, and CEP were
performed through a common 6-bit parity benchmark
problem and showed that CEP is more efficient to
implement in hardware due to its simplicity; is cheaper
to build; and is robust in both the convergence and
mathematical senses. As a real world application, this
algorithm is being proposed to be implemented in
hardware for a 3-D on-chip learning network.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  3124 </NUMBER>
<ORDER>   AAI9611871 </ORDER>
<TITLE> THE INTEGRATION OF ARTIFICIAL NEURAL NETWORKS AND GEOGRAPHIC INFORMATION SYSTEMS FOR ENGINEERING GEOLOGICAL MAPPING </TITLE>
<AUTHOR> EASSON, GREGORY LEE </AUTHOR>
<YEAR> 1995 </YEAR>
<INSTITUTION> UNIVERSITY OF MISSOURI - ROLLA; 0135 </INSTITUTION>
<DESCRIPTORS> GEOTECHNOLOGY; REMOTE SENSING; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> DAVID J. BARR </ADVISER>
<CLASSIFICATIONS> NIL </CLASSIFICATIONS>
<ABSTRACT>
This research investigates the utility of Artificial
Neural Network (ANN) technology in producing Engineering
Geological Maps. Specifically, a preliminary map
describing the stability for sanitary landfill use was
created. To accomplish this, three technologies were
combined: ANNs, Geographic Information Systems (GISs),
and engineering geological mapping techniques.
ANNs are computer programs designed to model the human
brain and its ability to learn tasks. GIS are computer
systems that store, analyze, and display mapped features
and related information. Engineering geological mapping
classifies the surficial materials and bedrock geology
according to their suitability for engineered
construction or modification. Engineering geology relies
on basic geologic, hydrologic, and topographic data.
This data is created, stored and displayed in the GIS,
which is also used to format the data into the single-
column vector needed by the ANN. Within the ANN, a
sequence of training and testing was undertaken to
create a tool that can be used to create preliminary
maps of engineering geology themes. This is additional
information for the engineering geologist to use in the
investigation of a specific area. It is a tool that can
reduce the level of effort, and thus the ultimate cost,
of the engineering geological map.
This research shows that ANN technology is appropriate
for creating preliminary engineering geological maps.
The trained ANN correctly estimated the suitability for
sanitary landfill use in 93% of the area being
investigated.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  3125 </NUMBER>
<ORDER>   AAI9611862 </ORDER>
<TITLE> A SYNERGISTIC PARADIGM FOR INTELLIGENT MULTIVARIATE DATA CLASSIFICATION  </TITLE>
<AUTHOR> GABER, MOHAMED TAREK </AUTHOR>
<YEAR> 1995 </YEAR>
<INSTITUTION> UNIVERSITY OF MISSOURI - ROLLA; 0135 </INSTITUTION>
<DESCRIPTORS> ENGINEERING, INDUSTRIAL; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> COLIN O. BENJAMIN </ADVISER>
<CLASSIFICATIONS> MACHINE LEARNING, NEURAL NETWORKS </CLASSIFICATIONS>
<ABSTRACT>
The main objective of this study is to develop an
intelligent data classification model that integrates
techniques from Statistical, Neural Networks, Machine
Learning and Knowledge Based Expert Systems approaches.
The goal of such synergy is to overcome the limitations
of the various approaches and improve data
classification results. The model suggested stems from
an information systems view of data classification and
is designed as a foundation for an intelligent decision
support system that can assist decision makers
especially in a data intensive management environment.
The model is developed and tested through several
phases. First a conceptual framework representing the
synergistic approach is built. Second a methodology for
developing the system is designed. Third the model is
developed. The model uses the results of a logistic
regression classifier to feed a Neural Network
(Backpropagation) and a Machine Learning Algorithm
(ID3). Results from these two classifiers are then
integrated and interpreted using a Knowledge Based
System. Finally the model is evaluated comparing its
efficiency to that of other classifiers. The efficiency
is measured by classification accuracy (the percentage
of correct classifications on new cases) and reliability
(the variance of classification results on test
samples). The model is evaluated using samples from
actual customer's data collected by a national service
company.
Results have shown that this approach can significantly
improve the accuracy and reliability of classification
while also providing interpretation to the results. To
extend its results to other domains, further testing
using different data is recommended. This study
contributes to the ongoing research in improving data
classification and provides a structured methodology for
implementing the suggested model.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  3126 </NUMBER>
<ORDER>   AAI9611859 </ORDER>
<TITLE> AN INTELLIGENT GDSS FOR MULTIPLE CRITERIA EVALUATION OF AGILE MANUFACTURING SYSTEM DESIGNS </TITLE>
<AUTHOR> MONPLAISIR, LESLIE FELIX </AUTHOR>
<YEAR> 1995 </YEAR>
<INSTITUTION> UNIVERSITY OF MISSOURI - ROLLA; 0135 </INSTITUTION>
<DESCRIPTORS> ENGINEERING, INDUSTRIAL; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> COLIN O. BENJAMIN; CATHERINE A. RIORDAN </ADVISER>
<CLASSIFICATIONS> GROUP DECISION SUPPORT SYSTEM, NEURAL NETWORKS </CLASSIFICATIONS>
<ABSTRACT>
A comprehensive evaluation by engineering design teams
of alternative configurations for cellular manufacturing
systems to meet the goals of agile production involves
consideration of several flexibility criteria. Group
Decision Support Systems (GDSS) can provide an efficient
decision-making environment for multi-disciplinary teams
faced with the challenge of evaluating agile production
systems. In this research, the development and
evaluation of two GDSS prototypes to aid the systematic
evaluation of agile manufacturing systems are described
and tested. The GDSS facilitate consideration of the
large number of flexibility and agility criteria
associated with the evaluation of agile systems. The
first GDSS prototype supports the following functions:
(1) anonymous inputs, (2) parallel processing of
information, (3) group memory, (4) electronic
brainstorming, (5) idea organization, (6) multiple
criteria decision making, and (7) consensus building.
The second GDSS prototype adopts MCDM enhancements for
incorporation into the group decision-making framework.
The enhancements consist of traditional
cardinal/ordinal/outranking algorithms, neural network
counter-propagation model for preference aggregation,
and graphics capability to enhance the user interface.
An industrial case study involving the evaluation of
alternative design configurations of a CMS for agile
manufacturing was used for laboratory testing with
twelve multi-disciplinary student teams. The results
indicate that both GDSS prototypes provided effective
support for the teams. However, the enhanced GDSS
outperformed the basic level one GDSS in: (1) decision
quality, (2) users' satisfaction and agreement with the
final group decision, (3) consensus attained by the
group, and (4) the degree of consensus after each
iteration of brainstorming, categorization and voting.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  3127 </NUMBER>
<ORDER>   AAGC512322 </ORDER>
<TITLE> ARTIFICIAL INTELLIGENCE APPLIED TO MMIC LAYOUT </TITLE>
<AUTHOR> ROBINSON, JAYNE HELEN </AUTHOR>
<YEAR> 1995 </YEAR>
<INSTITUTION> QUEEN'S UNIVERSITY OF BELFAST (NORTHERN IRELAND); 0725 </INSTITUTION>
<DESCRIPTORS> ENGINEERING, ELECTRONICS AND ELECTRICAL; ARTIFICIAL INTELLIGENCE LIBRARY, CHLORINE GARDENS,  BELFAST BT9 5AG, NORTHERN IRELAND </DESCRIPTORS>
<ADVISER> NIL </ADVISER>
<CLASSIFICATIONS> INTEGRATED CIRCUITS </CLASSIFICATIONS>
<ABSTRACT>
This thesis presents the development of a novel system,
GALA, which uses artificial intelligence to aid in the
layout of Monolithic Microwave Integrated Circuits
(MMICs). This is an area of MMIC design which is under-
represented both in the literature and traditional
Computer-Aided-Design (CAD) but which is crucial to the
successful production of a working circuit. GALA
(Gallium Arsenide Layout Assistant) has been developed
in Prolog using the blackboard architecture as a model.
The difficulties associated with laying out a MMIC are
presented and the selection of the blackboard
architecture as the framework on which GALA has been
based is reviewed. The constituent parts of the
blackboard architecture are described with emphasis on
their application to the task of layout. Their
development is discussed in depth and illustrated using
examples taken from typical amplifier designs.
GALA contains links to commercially available software
packages and is the third project undertaken within the
High Frequency Research Group at Queen's to aid in the
design of a MMIC amplifier. This has resulted in a novel
design framework known as MADE (MMIC Automated Design
Environment). Each system contained within MADE tackles
a different part of the design cycle and uses artificial
intelligence techniques to harness expertise garnered
from foundries, literature and human experts. The
integration of GALA with the relevant elements of MADE
is described and the manner in which information about
circuit components is generated, manipulated to produce
connections and then translated into a form that is
understood by a commercially available analysis tool is
discussed and demonstrated. The thesis concludes by
presenting a discussion on the future of microwave CAD
and the applicability of artificial intelligence
techniques to the new generation of design tools.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  3128 </NUMBER>
<ORDER>   AAI9611797 </ORDER>
<TITLE> ADAPTIVE APPROXIMATION AND OPTIMIZATION OF TRANSFORM FUNCTIONS  </TITLE>
<AUTHOR> GOLDEN, JAMES BROWN, III </AUTHOR>
<YEAR> 1995 </YEAR>
<INSTITUTION> VANDERBILT UNIVERSITY; 0242 </INSTITUTION>
<DESCRIPTORS> ENGINEERING, MECHANICAL; BIOLOGY, GENETICS; COMPUTER SCIENCE; ARTIFICIAL INTELLIGENCE; BIOLOGY, MOLECULAR </DESCRIPTORS>
<ADVISER> C. TIBBETTS; E. GARCIA </ADVISER>
<CLASSIFICATIONS> GENETIC ALGORITHMS, DNA SEQUENCING, NEURAL NETWORKS </CLASSIFICATIONS>
<ABSTRACT>
Engineers are often faced with the challenge of modeling
signals from analytical instruments. An inductive
approach is often employed based upon development of a
mathematical model for the dependence of function
outputs upon function inputs. A presumptive functional
model, based on desired behavior, constrains the
categories of functions that can be estimated.
This dissertation presents an application of adaptive
programming methods to processing signals from
analytical instruments. This deductive approach
facilitates development of applications free of the
constraints suggested for an inductive approach above.
This research applies flat neural networks as adaptive
signal processing transform functions for automated DNA
sequence determination. Adaptive optimization of this
approach is explored using genetic algorithms for the
design of architecture and connection matrices of
problem specific neural networks. Biological control
elements and local gene organization are investigated as
enhancements of genetic search and optimization.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  3129 </NUMBER>
<ORDER>   AAI9611757 </ORDER>
<TITLE> MESH-BASED NEURAL ARCHITECTURES </TITLE>
<AUTHOR> AYOUBI, RAFIC A. </AUTHOR>
<YEAR> 1995 </YEAR>
<INSTITUTION> UNIVERSITY OF SOUTHWESTERN LOUISIANA; 0233 </INSTITUTION>
<DESCRIPTORS> ENGINEERING, ELECTRONICS AND ELECTRICAL; COMPUTER SCIENCE; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> MAGDY A. BAYOUMI </ADVISER>
<CLASSIFICATIONS> PARALLEL PROCESSING, NEURAL NETWORKS, MASSIVELY PARALLEL, PLANAR ARCHITECTURES </CLASSIFICATIONS>
<ABSTRACT>
The past decade has seen explosive growth in studies of
neural networks. One of the main motivations for this
increased attention is the availability of parallel
computers, which allow ANN investigators to simulate and
test their ideas in ways not available before. The
objectives of our research are twofold: first, to
develop algorithmic mapping techniques to implement ANNs
on massively parallel planar architectures, namely torus
and mesh machines; and second, to ensure that the
developed algorithms maintain an acceptable performance
in case of nodes or links malfunction. The multi-layer
perceptron (MLP) networks are selected to model the ANN
under investigation. The developed algorithms are
extended to cover the general case, in which there is no
limit (theoretically) on the number of neurons in a
layer. Practically, the number of neurons in a layer can
only be increased to the capacity of the local memory of
each processor. Our study is then oriented towards fault
tolerant neural networks. First, it is shown that the
MLP network is not fault tolerant, as was first thought
by many researchers. This result led to further research
into techniques to embed fault tolerance into such a
neural network. Our approach to achieve a better fault
tolerant system is realized at two different levels. At
the abstract level, we propose a new technique that
shows, through theoretical and experimental results, a
superior performance, compared to other techniques
proposed in the literature. The new mapping techniques
are exploited to embed fault tolerance at the
implementation level, yet yielding a better system. That
latter point is demonstrated in the case of torus and
ring architectures, where a highly fault tolerant system
was achieved with little extra hardware. Simulations of
the standard back-error propagation algorithm, as well
as fault tolerant model, are performed on the MasPar MP-
1, and a comparison of results is furnished.
The proposed algorithm is proved to be superior to other
algorithms implemented on planar architectures known in
the literature. In fact, it is comparable in performance
to other algorithms implemented on hypercube-based
machines with O(log N) time, where N is the size of the
largest layer. In summary, the proposed algorithms are
more cost-effective than others mapped on either planar
architecture or hypercube-based machines, considering
the high connectivity required by the latter.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  3130 </NUMBER>
<ORDER>   AAI9611688 </ORDER>
<TITLE> FAULT DETECTION AND ISOLATION BASED ON LINEAR MODELS AND NEURAL NETWORK MODELS </TITLE>
<AUTHOR> LIU, BINFAN </AUTHOR>
<YEAR> 1995 </YEAR>
<INSTITUTION> ARIZONA STATE UNIVERSITY; 0010 </INSTITUTION>
<DESCRIPTORS> ENGINEERING, ELECTRONICS AND ELECTRICAL; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> NIL </ADVISER>
<CLASSIFICATIONS> ARTIFICIAL INTELLIGENCE </CLASSIFICATIONS>
<ABSTRACT>
This research is concerned with detecting and isolating
multiple faults in dynamic systems by model-based
approaches.
A new full state observer design method is developed to
isolate simultaneous multiple faults for linear time-
invariant systems. The method can isolate m simultaneous
component and actuator faults with m output measurements
under zero initial error of state estimation. Asymptotic
fault isolation results can also be obtained using the
same observer design if the number of invariant
eigenvalues is $(n-m),$ and if they are stable, where n
represents the system order, m is the number of faults
in the systems. In both cases m can be up to the system
order n.
In nonlinear cases, a framework for fault detection is
proposed based on existing results of neural network
approximation properties. A recurrent neural network
comprised of two static feedforward networks is used to
model a class of nonlinear dynamic systems. The model is
then used as a nominal model for fault detection. An
algorithm is provided to train these two static
networks.
Approximation error bounds using neural networks are
also considered in this research. From the view point of
best approximation theory, an upper bound of the
approximation error is obtained for a Gaussian network
with centers located on a regular mesh.
Some applications and examples are given to demonstrate
the results obtained in the research, in particular
using fault isolation filters.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  3131 </NUMBER>
<ORDER>   AAI9611591 </ORDER>
<TITLE> ADAPTIVE INTELLIGENT TRAFFIC MANAGEMENT IN ATM NETWORKS </TITLE>
<AUTHOR> LIU, YAO-CHING </AUTHOR>
<YEAR> 1995 </YEAR>
<INSTITUTION> UNIVERSITY OF MIAMI; 0125 </INSTITUTION>
<DESCRIPTORS> COMPUTER SCIENCE; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> CHRISTOS DOULIGERIS </ADVISER>
<CLASSIFICATIONS> NEURAL NETWORKS, FUZZY LOGIC, SCHEDULING </CLASSIFICATIONS>
<ABSTRACT>
Asynchronous Transfer Mode (ATM) networks support a wide
range of multimedia traffic (e.g. data, voice and
video). Unlike traditional teletraffic, many of the
current and emerging services have poorly understood
traffic parameters and user behaviors. These networks
must be self-managing and self-healing, while being able
to maintain their quality of service (QOS), and deal
with congestion.
Computational intelligence paradigms such as neural
networks and fuzzy logic have the ability to learn from
experience and to predict future behaviors. In some
cases these learning rules are explicit, but in other
cases the learning algorithms are implicit in a more
general structure such as a neural network. In
particular, neural networks and fuzzy logic have been
shown to have properties that can help in managing
congestion in networks.
In this thesis, neural networks and fuzzy logic are
applied to the feedback congestion control mechanisms
using different traffic models. The integration of both
techniques to a neural-network-based fuzzy logic system
is also presented. A traditional prediction mechanism
using Kalman filter algorithm is also proposed by
defining a traffic model. The results are compared with
the static feedback congestion controllers and their
superiority is shown.
Dynamic priority control mechanisms are then proposed.
These proposed mechanisms have better performance than
traditional mechanisms to meet the QOS requirements of
different traffic classes. A fuzzy threshold concept is
also applied in these proposed mechanisms. It is shown
that the fuzzy logic can optimize the traffic scheduling
and reduce the cell loss rate and queueing delays.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  3132 </NUMBER>
<ORDER>   AAI9611523 </ORDER>
<TITLE> VLSI SYSTEMS FOR ANALOG AND HAMMING PARALLEL COMPUTATION </TITLE>
<AUTHOR> PEDRONI, VOLNEI ANTONIO </AUTHOR>
<YEAR> 1995 </YEAR>
<INSTITUTION> CALIFORNIA INSTITUTE OF TECHNOLOGY; 0037 </INSTITUTION>
<DESCRIPTORS> ENGINEERING, ELECTRONICS AND ELECTRICAL; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> NIL </ADVISER>
<CLASSIFICATIONS> SIGNAL PROCESSING, NEURAL NETWORKS </CLASSIFICATIONS>
<ABSTRACT>
This thesis explores the vast field of physically
implementing parallel-computing algorithms. In this
research, we introduce a series of new circuit
architectures and new technology applications, which
implement multidimensional functions that are at the
heart of many parallel signal processing systems, e.g.,
neural and Hamming networks, vector quantizers, and
median filters. The functions are realized using low-
cost, low-power, high-density technologies (CMOS and
CCD), fully compatible with current industrial
processes. The systems are either analog or hybrid,
allowing lower time and/or storage complexities in many
types of applications when compared to fully-digital
systems. Special emphasis is placed on circuit modeling,
with the purpose of thoroughly understanding the
potentialities--and limitations--of each alternative.
The models are verified experimentally on most
occasions. As a consequence, the results presented in
this dissertation are expected not only to provide new
technological alternatives, but also new means of
evaluating the technologies themselves.
Chapter 1 presents an introductory discussion on
parallel systems. It has three main purposes. One is to
describe some of the parallel functions whose
implementations we are interested in. Another is to
present a graphical discussion on how certain
multidimensional systems work, which is probably the
best way of describing--and appreciating--systems of
this kind. And finally to describe basic guidelines
concerning this research.
Chapter 2 discusses a function that is inherent to most
analog parallel processors, the winner-take-all
function. The reason for it to be developed first is
that this function is part of many other function
realizations. A global discussion is presented, which
provides an overview on the potentialities of most
implementations available in CMOS technology, followed
by high-resolution alternatives. The use of this
function to implement other functions and systems is
also illustrated.
Chapter 3 presents a detailed discussion on charge-
coupled device (CCD) technology and its applications to
parallel signal processing systems. This technology,
compatible with conventional double-poly CMOS, is of
interest due to its low power consumption and very high
integration density, allowing the construction of very
efficient vector-matrix multipliers and Hamming
networks. To overcome its main limitation (i.e., charge-
transfer inefficiency), a locally-controlled
architecture is introduced. Several chips and extensive
measurements are shown, with the purpose of concretely
evaluating the performance of this technology when
performing signal processing tasks.
Finally, Chapter 4 describes further research on CMOS
cells that compute distance-based functions. These
circuits allow the construction of LMS and other
distance-based parallel processors, and provide
additional valuable means of further examining the use
of MOS technology for analog computation. Once again
experimental results are presented and the systems are
illustrated through vector quantizers, Hamming networks,
vector multipliers, and median filters. The chapter also
provides further applications of the winner-take-all
function to the construction of more complex functions.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  3133 </NUMBER>
<ORDER>   AAI9611294 </ORDER>
<TITLE> BUILDING A KNOWLEDGE BASED SIMULATION OPTIMIZATION SYSTEM WITH DISCOVERY LEARNING </TITLE>
<AUTHOR> SIOCHI, FERNANDO CARVALHO </AUTHOR>
<YEAR> 1995 </YEAR>
<INSTITUTION> VIRGINIA POLYTECHNIC INSTITUTE AND STATE UNIVERSITY; 0247 </INSTITUTION>
<DESCRIPTORS> OPERATIONS RESEARCH; COMPUTER SCIENCE; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> LOREN P. REES </ADVISER>
<CLASSIFICATIONS> EXPERT SYSTEMS </CLASSIFICATIONS>
<ABSTRACT>
Simulation optimization is a developing research area
whereby a set of input conditions is sought that produce
a desirable output (or outputs) to a simulation model.
Although many approaches to simulation optimization have
been developed, the research area is by no means mature.
This research makes three contributions in the area of
simulation optimization. The first is fundamental in
that it examines simulation outputs, called "response
surfaces," and notes their behavior. In particular both
point and region estimates are studied for different
response surfaces: Conclusions are developed that
indicate when and where simulation-optimization
techniques such as Response Surface Methodology should
be applied.
The second contribution provides assistance in selecting
a region to begin a simulation-optimization search. The
new method is based upon the artificial intelligence
based approach best-first search. Two examples of the
method are given.
The final contribution of this research expands upon the
ideas by Crouch for building a "Learner" to improve
heuristics in simulation over time. The particular case
of parameter-modification learning is developed and
illustrated by example.
The dissertation concludes with limitations and
suggestions for future work.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  3134 </NUMBER>
<ORDER>   AAI9611126 </ORDER>
<TITLE> APPLICATION OF MODIFIED FUZZY AHP METHOD TO ANALYZE BOLTING SEQUENCE OF STRUCTURAL JOINTS </TITLE>
<AUTHOR> LEE, ANMIN RICK </AUTHOR>
<YEAR> 1995 </YEAR>
<INSTITUTION> LEHIGH UNIVERSITY; 0105 </INSTITUTION>
<DESCRIPTORS> ENGINEERING, INDUSTRIAL; ENGINEERING, CIVIL; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> G. TONKAY </ADVISER>
<CLASSIFICATIONS> ANALYTIC HEIRARCHY PROCESS </CLASSIFICATIONS>
<ABSTRACT>
Bolt-tightening procedures are investigated in this
research. The random behavior of bolts in loosening
torque is analyzed through a multiple criteria
environment. The multiple criteria decision making
(MCDM) method incorporates many factors which may affect
the performance of jointed connections in loosening
torque. The factorial design method is used to examine
all the judging criteria with bolt-tightening
procedures. The data collected includes the percentage
of bolts loosened and the magnitude of torque loss from
the preset level. From the analysis of all judging
factors, some sources of variation may have conflicts
with each other. Multiple criteria are considered in the
whole analysis to determine a goal instead of judging
from a single criteria in order to resolve the conflict.
Butt splice connections are utilized for the bolt-
tightening procedures. The effects of four different
tightening patterns (row, column, off-center, random), 2
physical plate setups (rectangular, staggered), and 2
torque levels (80 ft-lb, 100 ft-lb) are studied. With
each different combination, the number of bolts relaxed
and the magnitude of torque loss are measured using the
calibrated torque method.
A series of pulling tests is carried out in order to
find the maximum frictional force in each combination.
The frictional force is directly related to the factors
described above. This test criteria is combined with
other criteria which may affect the performance of
jointed connections.
In the MCDM environment, different units of information
are generated for the multi-level, multi-criteria goal.
The modified fuzzy Analytic Hierarchy Process (AHP)
method provides a useful analysis in dealing with
vagueness in comparison within and between criteria. The
analysis for bolt-tightening procedures with the
modified fuzzy AHP method proves to be effective in
choosing from many sources of tightening techniques.
This model can also help examine structures which are
composed of many similar jointed connections.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  3135 </NUMBER>
<ORDER>   AAI9611087 </ORDER>
<TITLE> A NEURAL NETWORK MODEL OF SHORT-TERM DYNAMICS OF HUMAN DISPARITY VERGENCE SYSTEM </TITLE>
<AUTHOR> PATEL, SAUMIL SURENDRA </AUTHOR>
<YEAR> 1995 </YEAR>
<INSTITUTION> UNIVERSITY OF HOUSTON; 0087 </INSTITUTION>
<DESCRIPTORS> ENGINEERING, ELECTRONICS AND ELECTRICAL; HEALTH SCIENCES, OPHTHALMOLOGY; BIOLOGY, NEUROSCIENCE; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> NIL </ADVISER>
<CLASSIFICATIONS> EYE MOVEMENTS, NEURAL NETWORKS </CLASSIFICATIONS>
<ABSTRACT>
A neural network model for the human vergence system is
presented and its predictions are compared qualitatively
and quantitatively with a large variety of horizontal
disparity vergence data. The model consists of seven
functional stages, namely (i) target selection and
generation of a normalized retinotopic activity, (ii)
computation of instantaneous disparity and generation of
a disparity map, (iii) conversion of the disparity into
a velocity signal for each eye, (iv) push-pull
integration of velocity to generate a position signal
for each eye, (v) conversion of the position signal to
motoneuron/plant activity, (vi) gating of velocity
overdrive signal to the motoneuron/plant system, and
finally (vii) discharge path for position cells. Where
possible, the firing pattern of the neurons in the model
has been compared to actual cellular recordings reported
in the literature. Closed-loop symmetric step, staircase
and sinusoidal disparity vergence data were collected
from three subjects and a single set of model parameters
was obtained to quantitatively match the data of one of
the subjects. The simulated closed and open loop
symmetric step, sinusoidal, pulse, staircase, square and
ramp wave responses closely resemble experimental
results either recorded in our laboratory or reported in
the literature. A simplified static model based on the
principles of the dynamic model is also presented. This
static model is used to explain the nonlinear
relationship between vergence demand and fixation
disparity. This work provides insights into neural
correlates underlying the dynamics and statics of
vergence eye movements.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  3136 </NUMBER>
<ORDER>   AAI9611083 </ORDER>
<TITLE> DEVELOPMENT OF A NEURAL NETWORK MODEL AND A FUZZY EXPERT SYSTEM: APPLICATION TO MANAGERIAL DECISION-MAKING </TITLE>
<AUTHOR> GUPTA, VIPUL KUMAR </AUTHOR>
<YEAR> 1995 </YEAR>
<INSTITUTION> UNIVERSITY OF HOUSTON; 0087 </INSTITUTION>
<DESCRIPTORS> ENGINEERING, INDUSTRIAL; COMPUTER SCIENCE; OPERATIONS RESEARCH; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> NIL </ADVISER>
<CLASSIFICATIONS> NIL </CLASSIFICATIONS>
<ABSTRACT>
In this research, a Fuzzy Expert System and a neural
network have been designed, developed, and validated to
facilitate construction modularization decision making
which is defined as a method of constructing small
modules of a facility at a fabrication shop and/or
manufacturing plant, and installing them later at the
final project site.
Modularization decision-making model available from
previous research was modified to develop a new detailed
decision-making model comprising 43 decision variables.
Using data from 60 previously completed projects, a
neural network based on the Learning Vector Quantization
(LVQ) algorithm was trained. The trained neural network
was tested on a hold-out test data set of size 24, and
class ed the projects with a 79.2% accuracy. However,
the neural network approach posed the difficulty in
inspecting the content of the knowledge base and in
creating a user-friendly interface. Keeping these
difficulties in mind, a new distributed fuzzy-reasoning-
based architecture was developed and implemented in the
design and programming of a Fuzzy Expert System for
MOdularization REcommendation (FESMORE). The FESMORE
system includes the following modules: (1) Plant
Location Module, (2) Labor Related Module, (3)
Organizational Issues Module, (4) Plant Characteristics
Module, (5) Project Risks Module, (6) Environmental
Issues Module, and (7) Modularization Decision-making
Module. A user interface in Microsoft$sbcircler$ Visual
Basic was also developed to facilitate the usage of the
system.
Validation techniques utilized to test the FESMORE
system included performance evaluation on 24 test cases,
user interface evaluation, usefulness evaluation, and
usability analysis. The overall usability function value
for the system was 0.74, which is recognized as good. On
24 test cases, the FESMORE system accuracy was 83.3%.
These results show that the FESMORE system outperformed
the LVQ neural network. The decision support systems
developed in this dissertation can be used by a project
planning team in the pre-project planning stage to
evaluate various sites in terms of extent of
modularization that can be used for construction. The
FESMORE or the LVQ neural network will also help a
project team prepare conceptual scopes and estimates
based on economically optimum degree of modularization,
thereby minimizing the total construction cost.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  3137 </NUMBER>
<ORDER>   AAGC507780 </ORDER>
<TITLE> MAPPING BAYESIAN NETWORKS TO STOCHASTIC NEURAL NETWORKS: A FOUNDATION FOR HYBRID BAYESIAN-NEURAL SYSTEMS </TITLE>
<AUTHOR> MYLLYMAKI, PETRI JUKKA </AUTHOR>
<YEAR> 1995 </YEAR>
<INSTITUTION> HELSINGIN YLIOPISTO (FINLAND); 0592 </INSTITUTION>
<DESCRIPTORS> COMPUTER SCIENCE; ARTIFICIAL INTELLIGENCE P.O. BOX 26,  FIN-00014, HELSINKI, FINLAND </DESCRIPTORS>
<ADVISER> NIL </ADVISER>
<CLASSIFICATIONS> NIL </CLASSIFICATIONS>
<ABSTRACT>
In this work, we are interested in the problem of
finding maximum a posteriori probability (MAP) value
assignments for a set of discrete attributes, given the
constraint that some of the attributes are permanently
fixed to some values a priori. For building a system
capable of this type of uncertain reasoning in practice,
we need first to construct an accurate abstract
representation of the problem domain, and then to
establish an efficient search mechanism for finding MAP
configurations within the constructed model. We propose
a hybrid Bayesian network-neural network system for
solving these two subtasks. The Bayesian network
component can be used for constructing a compact, high-
level representation for the problem domain probability
distribution quickly and reliably, assuming that
suitable expert knowledge is available. The neural
network component provides then a computationally
efficient, massively parallel platform for searching the
model state space. The main application areas for these
kinds of systems include configuration and design
problems, medical diagnosing and pattern recognition.
For implementing a hybrid Bayesian-neural system as
suggested above, we present here methods for mapping a
given Bayesian network to a stochastic neural network
architecture, in the sense that the resulting neural
network updating process provably converges to a state
which can be projected to a MAP state on the probability
distribution corresponding to the original Bayesian
network. From the neural network point of view, these
mappings can be seen as a method for incorporating high-
level, probabilistic a priori information directly into
neural networks, without recourse to a time-consuming
and unreliable learning process. From the Bayesian
network point of view, the mappings offer a massively
parallel implementation of simulated annealing where all
the variables can be updated at the same time. Our
empirical simulations suggest that this type of
massively parallel simulated annealing outperforms the
traditional sequential Gibbs sampling/simulated
annealing process, provided that suitable hardware is
available.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  3138 </NUMBER>
<ORDER>   AAI9611023 </ORDER>
<TITLE> TOWARD A PARADIGM FOR VALIDATING DECISION-MAKING IN MAN- IN-THE-LOOP SIMULATIONS </TITLE>
<AUTHOR> HOPKINSON, WILLIAM CHARLES </AUTHOR>
<YEAR> 1995 </YEAR>
<INSTITUTION> UNIVERSITY OF CENTRAL FLORIDA; 0705 </INSTITUTION>
<DESCRIPTORS> ENGINEERING, INDUSTRIAL; OPERATIONS RESEARCH; COMPUTER SCIENCE; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> NIL </ADVISER>
<CLASSIFICATIONS> ARTIFICIAL INTELLIGENCE </CLASSIFICATIONS>
<ABSTRACT>
Simulations, as a tool to answer various questions in
both commercial and military areas, have proliferated in
the past decade. They are no longer just used by the
"computer expert" or "operations research specialist"
but rather by novice, non-simulation experts needing
answers to critical questions within time constraints.
Man in the loop simulations are a class of computer
models which are typically used for training students in
command type of decisions. Man in the loop simulations
are distinguished by the decision making process being
controlled dynamically by the trainee.
Quality control of computer simulations is controlled
through verification and validation throughout the life
cycle of the model. Verification is the process that
determines that the model and simulation functions as it
was originally conceived, specified, and designed.
Validation is the process that addresses the credibility
of the model and simulation in its depiction of the
modeled world. In the simulation and modeling community,
there are a lack of tools for the modeler to use to
assist in the verification and validation process. The
objective of this research is to develop a methodology
which allows the user to validate the decisions of the
man in the loop dynamically in real time.
This research explores the use of automated tools that
can operationally validate the decisions of the student
during real time. Case-based reasoning is explored as a
modeling paradigm for incorporating a validation
mechanism for a man-in-the-loop simulation. The approach
taken by this research is to reduce the model users risk
(type II error) by reducing the number of invalid
solutions. This method holds the potential to greatly
increase the model users confidence in the results of a
training exercise. A proof of principle demonstration
has been developed that operationally validates the
decisions made by a military commander in a high
resolution simulation. This demonstration establishes
the ability of an artificial intelligence system to
operate in real time and assist in the validation
process.
The contribution to the body of knowledge is primarily
in the development of a generic methodology for
validating the operational decisions for a man in the
loop simulation. Secondary contributions have been made
in the areas of artificial intelligence and modeling of
the command and control process.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  3139 </NUMBER>
<ORDER>   AAI9611020 </ORDER>
<TITLE> A KBES TO ANALYZE THE ENVIRONMENTAL IMPACT OF PROPOSED HIGHWAY DESIGN ALTERNATIVES </TITLE>
<AUTHOR> FIGUEIREDO, WELLINGTON CORREIA </AUTHOR>
<YEAR> 1995 </YEAR>
<INSTITUTION> UNIVERSITY OF CENTRAL FLORIDA; 0705 </INSTITUTION>
<DESCRIPTORS> ENGINEERING, CIVIL; ARTIFICIAL INTELLIGENCE; ENVIRONMENTAL SCIENCES; TRANSPORTATION </DESCRIPTORS>
<ADVISER> NIL </ADVISER>
<CLASSIFICATIONS> ARTIFICIAL INTELLIGENCE, EXPERT SYSTEMS </CLASSIFICATIONS>
<ABSTRACT>
This study addresses the application of a knowledge
based expert system as a tool for selecting the best
alternative for a proposed highway alignment from
multiple alternatives based on environmental features.
The automated environmental evaluation aid method uses
Expert Systems to complete the approach of automation,
performing the integration functions.
Noise Prediction and Air Quality analyses for the
attributes noise and air are performed in detail, and
other environmental attributes are generalized.
The VP-Expert shell, version 3.10, was the tool used to
build the expert system prototype. The prototype was
tested with real design cases and it was verified that
the system is able to develop an acceptable selection
among several alignment alternatives for a new
expressway section.
The main feature of the evaluation is the utilization of
the Analytic Hierarchy Process (AHP) with the following
environmental attributes: noise pollution, air
pollution, water (surface water and wetlands) affected,
endangered species habitat disruption, wildlife habitat
disruption, and displacement of houses by the future ROW
(right of way) of the new facility. AHP, a
multicriterion's decision making process created by
Thomas Saaty in 1972, is used as a decision making
methodology to select the best alternative.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  3140 </NUMBER>
<ORDER>   AAI9610932 </ORDER>
<TITLE> DIAGNOSTIC MODELS BASED ON PROJECTION </TITLE>
<AUTHOR> CARREIRA, DANIEL JOSEPH, III </AUTHOR>
<YEAR> 1995 </YEAR>
<INSTITUTION> FLORIDA INSTITUTE OF TECHNOLOGY; 0473 </INSTITUTION>
<DESCRIPTORS> COMPUTER SCIENCE; ENGINEERING, SYSTEM SCIENCE; ENGINEERING, AEROSPACE; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> ROBERT MORRIS </ADVISER>
<CLASSIFICATIONS> AUTOMATED SYSTEMS </CLASSIFICATIONS>
<ABSTRACT>
In developing diagnostic models of a system the designer
of automated systems is constrained by the tension
between making the model as simple as possible and
fulfilling the requirements of the diagnostic task.
Unfortunately, it is often impossible to meet these
constraints with a single model. This is because: (1)
the diagnostic task is complex, so a model which is best
in one instance might not be in another; and (2) a
complex system may exhibit diverse behavior modes, each
requiring a different model of diagnosis. To address
these issues researchers in AI have begun to focus on
using multiple representations and allowing the
diagnostic system to select the best for each context.
This dissertation defines a new theory for creating and
selecting from a set of models. This theory refines an
idea proposed in (Struss-91) by focusing on one
relationship involving the effects of simplifying models
by considering subsets of behavioral aspects. We also
show how this modified theory generalizes to concepts
proposed in other research and how this theory can be
used to explain the cognitive processes of experts
performing diagnosis.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  3141 </NUMBER>
<ORDER>   AAI9610927 </ORDER>
<TITLE> USING RECURSIVE ALLEN TEMPORAL ALGEBRA AND TEMPORAL DEPENDENT INTERVAL CALCULUS IN SMART SCHEDULING </TITLE>
<AUTHOR> MCDUFFIE, ERNEST LEROY </AUTHOR>
<YEAR> 1995 </YEAR>
<INSTITUTION> FLORIDA INSTITUTE OF TECHNOLOGY; 0473 </INSTITUTION>
<DESCRIPTORS> COMPUTER SCIENCE; MATHEMATICS; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> MORDECHAY SCHNEIDER </ADVISER>
<CLASSIFICATIONS> NIL </CLASSIFICATIONS>
<ABSTRACT>
The objective of this research was to lay a solid
mathematical foundation and to demonstrate the utility
of the Smart Scheduling concept. The results are
presented in the form of complete definitions for two
newly developed conceptual tools. These two concepts,
Recursive Allen Temporal Algebra (RATA) and Temporal
Dependent Interval Calculus (TDIC), have their roots
planted firmly in the field of Artificial Intelligence
(AI). A number of sub-domains in that field such as,
Expert Systems, Temporal Reasoning, Automatic
Scheduling, and Fuzzy Logic, are of primary interest for
the development and implementation of these concepts. In
addition to the definitions a functional implementation,
the Smart Scheduler Program (SSP), is used to
demonstrate the utility of the tools in a flexible
manufacturing environment. The concept of Smart
Scheduling combines the mathematical description of RATA
and TDIC with a number of technical improvement to the
original SSP implementation to produce a unique and
powerful new tool for real world scheduling problems.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  3142 </NUMBER>
<ORDER>   AAI9610917 </ORDER>
<TITLE> FULL ENVELOPE CONTROL OF NONLINEAR PLANTS WITH PARAMETER UNCERTAINTY BY FUZZY CONTROLLER SCHEDULING </TITLE>
<AUTHOR> KOBYLARZ, THOMAS JOHN </AUTHOR>
<YEAR> 1995 </YEAR>
<INSTITUTION> AIR FORCE INSTITUTE OF TECHNOLOGY; 0002 </INSTITUTION>
<DESCRIPTORS> ENGINEERING, SYSTEM SCIENCE; ENGINEERING, AEROSPACE; ENGINEERING, ELECTRONICS AND ELECTRICAL; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> MEIR PACHTER </ADVISER>
<CLASSIFICATIONS> NIL </CLASSIFICATIONS>
<ABSTRACT>
A full envelope controller synthesis technique is
developed for multiple-input single-output (MISO)
nonlinear systems with structured parameter uncertainty.
The technique maximizes the controller's valid region of
operation, while guaranteeing pre-specified transient
performance. The resulting controller does not require
on-line adaptation, estimation, prediction or model
identification. Fuzzy Logic (FL) is used to smoothly
schedule independently designed point controllers over
the operational envelope and parameter space of the
system's model. These point controllers are synthesized
using techniques chosen by the designer, thus allowing
an unprecedented amount of design freedom. By using
established control theory for the point controllers,
the resulting nonlinear dynamic controller is able to
handle the dynamics of complex systems which can not
otherwise be addressed by Fuzzy Logic Control. An
analytical solution for parameters describing the
membership functions allows the optimization to yield
the location of point designs: both quantifying the
controller's coverage, and eliminating the need of
extensive hand tuning of these parameters. The net
result is a decrease in the number of point designs
required. Geometric primitives used in the solution all
have multi-dimensional interpretations (convex hull,
ellipsoid, Voronoi/Delaunay diagrams) which allow for
scheduling on n-dimensions, including uncertainty due to
nonlinearities and parameter variation. Since many
multiple-input multiple-output (MIMO) controller design
techniques are accomplished by solving several MISO
problems, this work bridges the gap to full envelope
control of MIMO nonlinear systems with parameter
variation.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  3143 </NUMBER>
<ORDER>   AAI9610837 </ORDER>
<TITLE> PROBABILISTIC COUNTERFACTUALS: SEMANTICS, COMPUTATION, AND APPLICATIONS  </TITLE>
<AUTHOR> BALKE, ALEXANDER ABRAHAM </AUTHOR>
<YEAR> 1995 </YEAR>
<INSTITUTION> UNIVERSITY OF CALIFORNIA, LOS ANGELES; 0031 </INSTITUTION>
<DESCRIPTORS> COMPUTER SCIENCE; STATISTICS; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> JUDEA PEARL </ADVISER>
<CLASSIFICATIONS> CONDITIONAL STATEMENTS, CAUSAL MODELLING, TREATMENT EFFECTS, STATISTICS IN LAW, ARTIFICIAL INTELLIGENCE </CLASSIFICATIONS>
<ABSTRACT>
Counterfactual conditionals of the form "If A were true,
then C" are commonly used to express generic, law-like
relationships. This dissertation provides formal
semantics for interpreting such conditionals, as well as
computational methods for answering queries of the form
"Find the probability of C if A were true, given that A
is in fact false." Here, generic knowledge is
represented as a network of causal relationships among
variables of interest, while specific occurrences are
represented as instantiations of those variables. The
counterfactual antecedent A is interpreted as a local,
hypothetical change induced by forces external to the
system. Counterfactual probabilities are computed using
standard evidence propagation in two loosely coupled
Bayesian networks--one corresponding to the factual
world, the other to the counterfactual--where the
probabilities are defined over the causal mechanisms
governing the domain. When such probabilities are not
available, we develop methods for computing either
bounds on the counterfactual probabilities or
qualitative beliefs, i.e., order-of-magnitude
abstractions of standard probabilities.
We then demonstrate the usefulness of our formulation in
application areas where counterfactual reasoning is
essential but considered difficult, if not impossible,
to compute. First, we examine experimental studies in
which subjects do not comply perfectly with treatment
assignment, thus violating the tenets of randomized
experimentation. We show that it is possible in such
studies to derive informative bounds on treatment
efficacy, tighter than any yet reported in the
statistical or the epidemiological literature. Next, we
address the problem of determining legal responsibility
(e.g., whether the defendant is liable for the
plaintiff's injuries). Although counterfactual
assertions in this domain cannot be evaluated using
conventional statistical analysis, under our formalism
they can be assigned meaningful probability intervals.
In the areas of econometrics and the social sciences,
the formalism allows coherent evaluation of policies
involving the control of variables that, prior to
enacting a given policy, were influenced by other
variables in the system. Finally, in the area of
artificial intelligence, the formulation provides a
computational model for interpreting counterfactual
utterances, answering counterfactual queries, and
evaluating actions and plans.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  3144 </NUMBER>
<ORDER>   AAI9610471 </ORDER>
<TITLE> MODULARIZED AND BOOLEAN NEURAL NETWORKS FOR IMAGE PROCESSING  </TITLE>
<AUTHOR> CHANG, LIANG-WEN B. </AUTHOR>
<YEAR> 1995 </YEAR>
<INSTITUTION> UNIVERSITY OF DELAWARE; 0060 </INSTITUTION>
<DESCRIPTORS> ENGINEERING, ELECTRONICS AND ELECTRICAL; COMPUTER SCIENCE; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> DANIEL L. CHESTER; ALI S. KHAYRALLAH </ADVISER>
<CLASSIFICATIONS> SIGNAL PROCESSING </CLASSIFICATIONS>
<ABSTRACT>
In this dissertation, two types of neural networks are
introduced and analyzed. The modularized neural networks
are continuous weighted neural networks, and MIN/MAX
Boolean neural networks are discrete (binary) weighted
neural networks. In addition, one optimization method,
the genetic annealing algorithm, is devised to improve
the supervised learning of neural networks.
A modularized neural network (MNN) is introduced to
combat signal distortion and noise reduction. The MNN is
compared with a non-modularized neural network when
trained to compute functions such as rank ordering and
median type operators. Based on the result, the MNN
containing fixed-weight and trainable modules can be
efficiently trained to filter noisy signals. The
partitioning of the input space of the MNN is determined
by an analysis of rank order information and/or relative
magnitude information in windowed observed data. The
relation between the rule for partitioning input
patterns and the probabilistic characteristics of the
signal and noise is discussed. The modularized neural
networks are tested on stationary Markov processes with
various types of noise, nonstationary signal waveforms
with additive noise, and images with additive noise.
A MIN/MAX Boolean neural network is constructed by
minterms and maxterms of Boolean functions. The
algebraic structure of Minimum and Maximum operators is
discussed. Almost all nonlinear, selective filters can
be expressed by MIN/MAX Boolean neural networks. There
is a subset of MIN/MAX Boolean neural networks,
constrained Boolean neural networks, which reduces the
complexity of MIN/MAX Boolean neural networks by
excluding outliers from window inputs. The MIN/MAX
Boolean neural networks are tested on stationary Markov
sequences with various noise, nonstationary multi-tone
signals with various noise, and images with additive
noise. Both modularized neural networks and MIN/MAX
Boolean neural networks are compared with other linear
and nonlinear filters structurally.
A new optimization method, genetic annealing algorithm,
which unifies a genetic algorithm and a simulated
annealing algorithm is developed to globally search for
the weights of neural networks. The method is obtained
by observing the similarity of natural evolution and
material evolution. The process of simulated annealing
serves as a single mutation among population. The
mathematical expression of the genetic annealing
algorithm is discussed and the five standard test bed
functions are tested. Simulations show that the
algorithm gives promising results. Practically, the
genetic annealing algorithm is used to optimize the
discrete (binary) weights of MIN/MAX Boolean neural
networks. The application aspect of the algorithm is
also investigated.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  3145 </NUMBER>
<ORDER>   AAI9610464 </ORDER>
<TITLE> APPLICATIONS OF ANNS IN TRANSPORTATION ENGINEERING: DEVELOPMENT OF A NEURAL TRAFFIC SIGNAL CONTROL SYSTEM </TITLE>
<AUTHOR> HUA, JIUYI </AUTHOR>
<YEAR> 1995 </YEAR>
<INSTITUTION> UNIVERSITY OF DELAWARE; 0060 </INSTITUTION>
<DESCRIPTORS> ENGINEERING, CIVIL; TRANSPORTATION; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> ARDESHIR FAGHRI </ADVISER>
<CLASSIFICATIONS> NEURAL NETWORKS </CLASSIFICATIONS>
<ABSTRACT>
Artificial neural networks are one of the recently
explored advanced technologies which show promise in the
area of transportation engineering. However, in contrast
to the availability of a large number of successful
application demonstrations, it is hard to find studies
in the literature that provide systematic examinations
of the-state-of-the-art, the application domains, and
the applicability of artificial neural networks to
transportation problems. On the other hand, some unseen
artificial neural networks development has been
motivated by transportation engineering objectives.
Therefore, this document presents examinations of
artificial neural network applications in transportation
engineering as well as the development of a neural
network paradigm for the purpose of roadway traffic
signal control for isolated intersections.
The characteristics, properties, and application domains
of artificial neural networks and their relationship to
neural science and other artificial intelligence
techniques, such as expert systems, are reviewed. The
review attempts to project the application domains of
artificial neural networks in a general sense. Then,
through a literature study, the state-of-the-art in
application of artificial neural networks to
transportation problems is described. Through
examinations of numerous applications, the
applicability, justifications, advantages and
limitations of artificial neural networks for
transportation problems are summarized as well.
The next generation of roadway transportation systems
will be formed of so-called intelligent transportation
systems. It is anticipated that the software component
of such intelligent transportation systems will rely on
multiple advanced technologies, including artificial
neural networks. This document also provides an
assessment of the application potential of artificial
neural networks to intelligent transportation systems.
To better demonstrate the use of artificial neural
networks in solving different types of transportation
problems, a number of real-world applications are
presented in detail. These applications, which utilize
existing artificial neural network techniques, cover
several aspects of transportation engineering, including
demand study, facilities maintenance, planning and
management.
Artificial neural networks are still under development.
New advantages, from which transportation engineering
can choose, are expected to be revealed as the
development progresses. This dissertation dedicates a
large amount of attention to the creation of an
operation-time weights changing neural network paradigm
for creating a traffic signal control system for an
isolated intersection. This system focuses on adaptive,
"human-thinking-like," and self-organizing performance.
Thorough validation of the control mechanism is
included.
Finally, this document summarizes the application
domains and applicability, advantages and limitations of
artificial neural networks in transportation
engineering; presents an evaluation of the neural signal
control system; and provides recommendations for future
studies in this area.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  3146 </NUMBER>
<ORDER>   AAI9610286 </ORDER>
<TITLE> AN ANALYSIS OF THE EFFECTS OF DIFFERENT REPRESENTATION SCHEMES ON GENETIC ALGORITHMS </TITLE>
<AUTHOR> CHUNG, WEON SAM </AUTHOR>
<YEAR> 1995 </YEAR>
<INSTITUTION> UNIVERSITY OF SOUTH FLORIDA; 0206 </INSTITUTION>
<DESCRIPTORS> COMPUTER SCIENCE; BIOLOGY, GENETICS; ENGINEERING, ELECTRONICS AND ELECTRICAL; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> RAFAEL A. PEREZ </ADVISER>
<CLASSIFICATIONS> ARTIFICIAL INTELLIGENCE </CLASSIFICATIONS>
<ABSTRACT>
Two types of representation schemes have been employed
for genetic algorithms (GAs). One is problem-dependent
and high-level representation such as symbols, integers,
etc. The other is problem-independent and low-level
representation such as binary representation. Contrary
to the schema model, which is based on the similarities
among strings, recommending binary representation, the
application of GAs has been expanded to a broader range
of problems by the usage of problem-dependent and high-
level representation scheme.
On the representation scheme of a GA, there are two
significant issues: How can a GA using problem-dependent
and high-level representation behave? Between the two
different representation schemes, which representation
scheme is better?
Our purpose in this dissertation is to construct new
theoretical guidelines based on a Markov chain for a GA
using problem-dependent and high-level representation as
well as problem-independent and low-level
representation. First, the schema model is rigorously
tested using different representation schemes. These
tests lead to the important result that Holland's schema
concept is insufficient to provide strong theoretical
foundations of a GA. Consequently, novel Markov chain
models are proposed for problem-dependent and high-level
representation, as well as problem-independent and low-
level representation. The transition matrix of each
Markov chain is the composition of three intermediate
transition matrices for proportionate selection with
generation insertion, one-point crossover, and binary or
boundary mutation.
Based on the newly proposed Markov chain models, the
stochastic search behavior of a GA is presented,
regardless of the representation scheme used. A GA
converges to a population consisting of optimal strings
as the number of generations increases. If the mutation
operator is not employed, the convergence population
depends on a given initial population. Otherwise, the
convergence population is independent of the initial
population.
The effects of different representation schemes on a GA
are compared in terms of four comparison criteria based
on the newly proposed Markov chain model: state fitness
evaluation time, fully meaningful state ratio, diversity
pressure, and convergence pressure. According to these
criteria, we show that problem-dependent and high-level
representation is better than problem-independent and
low-level representation, except for a special case when
the mutation operator is not used.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  3147 </NUMBER>
<ORDER>   AAI9609865 </ORDER>
<TITLE> EFFICIENT LEARNING FROM FAULTY DATA </TITLE>
<AUTHOR> DECATUR, SCOTT EVAN </AUTHOR>
<YEAR> 1995 </YEAR>
<INSTITUTION> HARVARD UNIVERSITY; 0084 </INSTITUTION>
<DESCRIPTORS> COMPUTER SCIENCE; MATHEMATICS; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> LESLIE G. VALIANT </ADVISER>
<CLASSIFICATIONS> LEARNING SYSTEMS, ARTIFICIAL INTELLIGENCE </CLASSIFICATIONS>
<ABSTRACT>
Learning systems are often provided with imperfect or
noisy data. Therefore, researchers have formalized
various models of learning with noisy data, and have
attempted to delineate the boundaries of learnability in
these models. In this thesis, we describe a general
framework for the construction of efficient learning
algorithms in noise tolerant variants of Valiant's PAC
learning model. By applying this framework, we also
obtain many new results for specific learning problems
in various settings with faulty data.
The central tool used in this thesis is the
specification of learning algorithms in Kearns'
Statistical Query (SQ) learning model, in which
statistics, as opposed to labelled examples, are
requested by the learner. These SQ learning algorithms
are then converted into PAC algorithms which tolerate
various types of faulty data.
We develop this framework in three major parts: (1) We
design automatic compilations of SQ algorithms into PAC
algorithms which tolerate various types of data errors.
These results include improvements to Kearns
classification noise compilation, and the first such
compilations for malicious errors, attribute noise and
new classes of "hybrid" noise composed of multiple noise
types. (2) We prove nearly tight bounds on the required
complexity of SQ algorithms. The upper bounds are based
on a constructive technique which allows one to achieve
this complexity even when it is not initially achieved
by a given SQ algorithm. (3) We define and employ an
improved model of SQ learning which yields noise
tolerant PAC algorithms that are more efficient than
those derived from standard SQ algorithms. Together,
these results provide a unified and intuitive framework
for noise tolerant learning that allows the algorithm
designer to achieve efficient, and often optimal, fault
tolerant learning.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  3148 </NUMBER>
<ORDER>   AAGC507542 </ORDER>
<TITLE> SCENE VERIFICATION USING AN IMAGING MODEL IN THREE- DIMENSIONAL COMPUTER VISION </TITLE>
<AUTHOR> HANAJI' K, MILAN </AUTHOR>
<YEAR> 1995 </YEAR>
<INSTITUTION> TECHNISCHE UNIVERSITEIT EINDHOVEN (THE NETHERLANDS); 0426 </INSTITUTION>
<DESCRIPTORS> COMPUTER SCIENCE; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> NIL </ADVISER>
<CLASSIFICATIONS> MACHINE VISION </CLASSIFICATIONS>
<ABSTRACT>
A technique for the verification of scene descriptions
is presented which employs an imaging model, i.e. a
model describing the scene illumination and the image
formation processes. It is assumed that the scene
description to be verified has been created by a
computer vision system. This verification problem
involves the estimation of unknown scene parameters, and
a decision-making problem based on the original acquired
image and the synthetic image created with the imaging
model.
The image of a scene projected onto an image plane is
the result of an interaction of light with objects in
the scene and a camera image plane. Discussed are
surface reflectance models, a camera model, and three
techniques for the computation of the global
illumination, ray tracing, radiosity and stochastic ray
tracing. An imaging model consisting of stochastic ray-
tracing and the Torrance-Sparrow surface reflectance
model is considered.
When using the imaging model, knowledge of surface
reflectance parameters and parameters of the light
sources is essential. A maximum-likelihood technique for
the estimation of the unknown parameters is proposed and
elaborated on.
For the verification of a scene description, a decision
procedure consisting of the difference between the
camera image and the synthetic image (an image created
using the imaging model), the linear filtering of the
result of the difference by a North filter, and the
subsequent thresholding of the filtered image is
proposed. For the special case of a simple hypothesis
and a simple alternative this procedure is a most
powerful test in the Neyman-Pearson sense. The
verification of the scene description is a decision
problem with a simple hypothesis and a composite
alternative. A method for the determination of suitable
filter coefficients in the decision procedure is given.
Finally, some methods for the improvement of the scene
description are discussed. The application of the
technique is demonstrated in a number of experiments
reported throughout the thesis, showing the feasibility
of the proposed verification method.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  3149 </NUMBER>
<ORDER>   AAI9609755 </ORDER>
<TITLE> SOME ASPECTS OF GENERALIZATION IN FEED-FORWARD ARTIFICIAL NEURAL NETWORKS </TITLE>
<AUTHOR> REED, RUSSELL DERYL </AUTHOR>
<YEAR> 1995 </YEAR>
<INSTITUTION> UNIVERSITY OF WASHINGTON; 0250 </INSTITUTION>
<DESCRIPTORS> ENGINEERING, ELECTRONICS AND ELECTRICAL; COMPUTER SCIENCE; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> R. J. MARKS II </ADVISER>
<CLASSIFICATIONS> NIL </CLASSIFICATIONS>
<ABSTRACT>
One of the interesting properties of artificial neural
networks is that they 'learn' from examples. Since a
complex system trained on a few samples may overfit the
data, an important question is how well the system
generalizes from the samples to the underlying rule
behind the data. This dissertation reviews some factors
affecting generalization, methods for predicting and
estimating generalization ability, and heuristics that
have been proposed as ways to improve generalization in
neural networks. Two techniques are considered in more
detail: training with noisy inputs (jitter) and pruning.
A relationship between training with jitter,
convolutional smoothing of the target, regularization,
gain scaling, and weight decay is shown. Concepts are
illustrated by simulations on a number of simple
examples.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  3150 </NUMBER>
<ORDER>   AAI9609675 </ORDER>
<TITLE> HIGH PERFORMANCE ELECTRIC DRIVE SYSTEMS USING FUZZY CONTROL  </TITLE>
<AUTHOR> HUANG, TONY CHUN-HUNG </AUTHOR>
<YEAR> 1995 </YEAR>
<INSTITUTION> UNIVERSITY OF WASHINGTON; 0250 </INSTITUTION>
<DESCRIPTORS> ENGINEERING, ELECTRONICS AND ELECTRICAL; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> MOHAMED A. EL-SHARKAWI </ADVISER>
<CLASSIFICATIONS> ARTIFICIAL INTELLIGENCE </CLASSIFICATIONS>
<ABSTRACT>
An electric drive system is considered high performance
when the variable under control, such as rotor position
or shaft speed, can be made to follow a pre-selected
track at all times. A track or trajectory is a desired
time history of the particular controlled variable. This
type of high performance drive system is essential in
applications such as robotics, actuation and guided
manipulation where precise movements are required.
Fuzzy control has many advantages over conventional
control. Fuzzy control does not use mathematical model
and therefore is less sensitive to system parameter
changes. Design objectives that are difficult to express
mathematically can be easily incorporated in a fuzzy
controller by linguistic rules. In addition, its
implementation is simple and straight forward. In this
research, fuzzy control is applied to both the dc and
induction drive systems.
An extension to fuzzy control, Multi-Layer Fuzzy Control
(MLFC), is developed. The MLFC has two layers. The first
layer is the execution layer which is made up of small
subcontrollers. The second layer is the supervisor layer
which fuzzily combines the execution layer
subcontrollers to achieve the system objectives. The
MLFC topology is applied to speed regulation, efficiency
maximization, speed and position tracking of induction
motors.
A test setup is designed and built for the performance
verification of the controllers. The MLFC based
induction motor drive applications are tested in the
laboratory. It is found that the MLFC based position
tracking controller can satisfactorily track a
trajectory of a few turns even with a 20% load. The test
results show that the MLFC topology is effective and it
is presented in this report.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  3151 </NUMBER>
<ORDER>   AAI9609624 </ORDER>
<TITLE> SOLVING INVERSE PROBLEMS USING BAYESIAN MODELING TO INCORPORATE INFORMATION SOURCES </TITLE>
<AUTHOR> DAVIS, DANIEL THOMAS </AUTHOR>
<YEAR> 1995 </YEAR>
<INSTITUTION> UNIVERSITY OF WASHINGTON; 0250 </INSTITUTION>
<DESCRIPTORS> ENGINEERING, ELECTRONICS AND ELECTRICAL; GEOPHYSICS; ARTIFICIAL INTELLIGENCE; REMOTE SENSING </DESCRIPTORS>
<ADVISER> JENQ-NENG HWANG </ADVISER>
<CLASSIFICATIONS> NIL </CLASSIFICATIONS>
<ABSTRACT>
Inverse problems have been considered unmanageable
because they are often ill-posed, i.e., the statement of
the problem does not thoroughly constrain the solution
space. We take advantage of this lack of information by
adding additional informative constraints to the problem
solution using Bayesian methodology. Bayesian modeling
gains much of its power from its ability to isolate and
incorporate causal models as conditional probabilities.
As causal models are accurately represented by forward
models, we convert implicit functional models into data
driven forward models represented by neural networks, to
be used as engines in a Bayesian modeling setting. The
forward model merges the information from an analytic
model of estimated accuracy and a limited number of
ground truth information, which are true samples of the
function under study. We apply these methods to
satellite remote sensing problems, as they afford
numerous opportunities for inclusion of ground truth
information, prior probabilities, noise distributions,
and other informative constraints.
In particular, this dissertation elaborates an indepth
Bayesian analysis of inverse problems, including novel
aspects such as ground truth incorporation and the use
of embedded neural networks. The model ground truth
incorporation is accomplished through a novel kernel
technique, where the analysis of the new technique
proves as fruitful as the technique itself. Finally,
these methods are validated in simulation, and applied
to a real world problem of inverse geophysical parameter
retrieval for Africa using satellite data.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  3152 </NUMBER>
<ORDER>   AAI9609610 </ORDER>
<TITLE> ACTIVE CONTOUR MODELS FOR DISTINCT FEATURE TRACKING AND LIPREADING </TITLE>
<AUTHOR> CHIOU, GREG I. </AUTHOR>
<YEAR> 1995 </YEAR>
<INSTITUTION> UNIVERSITY OF WASHINGTON; 0250 </INSTITUTION>
<DESCRIPTORS> ENGINEERING, ELECTRONICS AND ELECTRICAL; COMPUTER SCIENCE; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> JENQ-NENG HWANG </ADVISER>
<CLASSIFICATIONS> NIL </CLASSIFICATIONS>
<ABSTRACT>
This dissertation presents two frameworks: (1) contour
extraction using snakes, neural networks, and the Gibbs
sampler, (2) lipreading using snakes, principal
component analysis, and hidden Markov models. Three
versions of active contour models (also knows as the
"Snakes") were designed, implemented, and used in the
frameworks.
The first framework uses NND-SNAKE (incorporating a
neural network classifier) to extract contours in a
deterministic manner or NNS-SNAKE (incorporating a
neural network classifier and the Gibbs sampler) to
extract contours in a stochastic manner. Successful
application of the framework using NND-SNAKE and NNS-
SNAKE on magnetic resonance (MR) images is presented.
The second framework uses Active Star Model (another
modified version of active contour model) with principal
component analysis (PCA) and hidden Markov models
(HMM's) for lipreading. The lipreading system uses the
framework to perform color motion video recognition
without acoustic data. The active star model and PCA are
used to extract two sets of visual features from every
frame (image) in color video sequences. The active star
algorithm looks for contour features in the geometric
space, while PCA seeks principal components in the
eigenspace. An HMM recognizer is used to train and
recognize a sequence of the combined visual features.
With the visual information alone, we were able to
achieve 94% recognition accuracy for 10 isolated words
of a single speaker without any special marker or
lipstick.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  3153 </NUMBER>
<ORDER>   AAI9609599 </ORDER>
<TITLE> A HYBRID SYSTEM WITH SYMBOLIC AI AND STATISTICAL METHODS FOR SPEECH RECOGNITION </TITLE>
<AUTHOR> SAVAGE-CARMONA, JESUS </AUTHOR>
<YEAR> 1995 </YEAR>
<INSTITUTION> UNIVERSITY OF WASHINGTON; 0250 </INSTITUTION>
<DESCRIPTORS> ENGINEERING, ELECTRONICS AND ELECTRICAL; COMPUTER SCIENCE; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> ALISTAIR HOLDEN </ADVISER>
<CLASSIFICATIONS> ARTIFICIAL INTELLIGENCE </CLASSIFICATIONS>
<ABSTRACT>
We applied a combination of artificial intelligence (AI)
techniques with digital signal processing and
statistical methods to enhance speech recognition. We
implemented a hybrid system which used a rule-based
expert system to create Conceptual Dependency (CD)
representations of the spoken input. Conceptual
Dependencies are used for natural language understanding
of written text, but until now have not been applied to
speech recognition. Our hybrid system used a three-step
process. First, we implemented continuous speech
recognition using a keyword spotting system, based on
Hidden Markov Models. Then, the recognized keywords were
used to search for the CD representation. Finally, the
gaps in the CD representation were used as contextual
cues for reinterpreting the speech input and so increase
the speech recognition accuracy.
We also implemented a sentence speech recognition system
based on Multi-Section Vector Quantization, CD
representations, and context. The recognized sentences
were used to create CD representations, which were then
combined with contextual knowledge to reinterpret the
speech input and increase the recognition accuracy. The
context was represented using Scripts, which describe
possible sequences of events that an actor or entity may
perform under certain conditions. Using context
representation reduced the speech recognition errors in
our application by 31%.
The application chosen was software agent navigation
through a virtual environment via vocal commands. The
software agent was represented by a Virtual Robot
(VIRBOT) and the environment was the representation of a
simple house. There were a number of objects in the
house and the VIRBOT could be directed to them and could
plan a series of actions to achieve a goal. The VIRBOT
understood commands such as "Robot, give the newspaper
to the father," "Robot, where is the tool box?," "Robot,
bring it," etc. Feedback was provided by synthesized
speech announcing the movements of the VIRBOT; for
example the robot says "I found the newspaper," when it
finds it. Another type of feedback was provided visually
to the user, who could see the VIRBOT as it moved. This
application may be used to develop and test simulated
Robot behaviors, before construction and programming of
a real Robot.
This work used the best current methods for speech
recognition, and integrated them with semantic
representations (CD's) and contextual representations
(scripts.) It has been shown that meaning and context
can improve speech recognition accuracy considerably, in
a real time environment.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  3154 </NUMBER>
<ORDER>   AAI9608998 </ORDER>
<TITLE> DYNAMICS AND ALGORITHMS FOR STOCHASTIC SEARCH </TITLE>
<AUTHOR> ORR, GENEVIEVE BETH </AUTHOR>
<YEAR> 1995 </YEAR>
<INSTITUTION> OREGON GRADUATE INSTITUTE OF SCIENCE & TECHNOLOGY; 0284 </INSTITUTION>
<DESCRIPTORS> COMPUTER SCIENCE; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> TODD LEEN </ADVISER>
<CLASSIFICATIONS> MACHINE LEARNING, NEURAL NETWORKS </CLASSIFICATIONS>
<ABSTRACT>
In this thesis we develop a mathematical formulation for
the learning dynamics of stochastic or on-line learning
algorithms in neural networks. We use this formulation
to (1) model the time evolution of the weight space
densities during learning, (2) predict convergence
regimes with and without momentum, and (3) develop a new
efficient algorithm with few adjustable parameters which
we call adaptive momentum.
In stochastic learning, the weights are updated at each
iteration based on a single exemplar randomly chosen
from the training set. Treating the learning dynamics as
a Markov process, we show that the weight space
probability density P(w,t) can be cast as a Kramers-
Moyal series$$0partial P(w,t)overpartial t = Lsb0KM
P(w,t)eqno(0.1)cr$$where $Lsb0KM$ is an infinite-order
linear differential operator, the terms of which involve
powers of the learning rate $mu.$ We present several
approaches for truncating this series so that
approximate solutions can be obtained. One approach is
the small noise expansion where the weights are modeled
as a sum of a deterministic and noise component.
However, in order to provide more accurate solutions, we
also develop a perturbation expansion in $mu.$ We
demonstrate the technique on equilibrium weight-space
densities.
Unlike batch learning, stochastic updates are noisy but
fast to compute. The speed-up can be dramatic if
training sets are highly redundant, and the noise can
decrease the likelihood of becoming trapped in poor
local minima. However, acceleration techniques based on
estimating the local curvature of the cost surface can
not be implemented stochastically because the estimates
of second order effects are much too noisy. Disregarding
such effects can greatly hinder learning in problems
where the condition number of the hessian is large. A
matrix of learning rates (the inverse hessian) that
scales the stepsize according to the curvature along the
different eigendirections of the hessian is needed. We
propose adaptive momentum as a solution. It results in
an effective learning rate matrix that approximates the
inverse hessian. No explicit calculation of the hessian
or its inverse is required. This algorithm is only $0cal
O(n)$ in both space and time, where n is the dimension
of the weight vector.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  3155 </NUMBER>
<ORDER>   AAI0576742 </ORDER>
<TITLE> PERCEIVING AND RECOGNIZING THREE-DIMENSIONAL FORMS </TITLE>
<AUTHOR> SINHA, PAWAN </AUTHOR>
<YEAR> 1995 </YEAR>
<INSTITUTION> MASSACHUSETTS INSTITUTE OF TECHNOLOGY; 0753 </INSTITUTION>
<DESCRIPTORS> COMPUTER SCIENCE; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> TOMASO POGGIO </ADVISER>
<CLASSIFICATIONS> SHAPE RECOVERY, IMAGE RECOGNITION, VOLUME RECOGNITION </CLASSIFICATIONS>
<ABSTRACT>
When presented with a single two-dimensional picture of
a three-dimensional object, the human visual system is
often able to: (1) interpret the 2D projection as a 3D
shape, and (2) recognize the 3D object that produced the
2D image. How these twin tasks of perception and
recognition are accomplished remains one of the most
debated questions in the field of vision.
This thesis examines this question in a few domains,
both computationally and experimentally, and arrives at
the following conclusions: (1) It is possible to account
for human 3D shape recovery performance in constrained
domains by positing the existence of a few biases
towards specific kinds of shapes. (2) In a general
setting, the perception of 3D shapes involves learning
and is likely to be mediated by recognition processes.
This conclusion runs counter to the traditional notion
of a perception to recognition processing hierarchy. (3)
The processes subserving the recognition of 3D shapes
may use highly viewpoint-dependent internal
representations for at least some classes of objects.
(4) The memory requirements of view-dependent
representation schemes can be greatly reduced by the use
of quasi-invariants comprising sets of qualitative
measurements. (Copies available exclusively from MIT
Libraries, Rm. 14-0551, Cambridge, MA 02139-4307. Ph.
617-253-5668; Fax 617-253-1690.)
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  3156 </NUMBER>
<ORDER>   AAINN02753 </ORDER>
<TITLE> VLSI-COMPATIBLE IMPLEMENTATIONS FOR ARTIFICIAL NEURAL NETWORKS </TITLE>
<AUTHOR> FAKHRAIE, SIED MEHDI </AUTHOR>
<YEAR> 1995 </YEAR>
<INSTITUTION> UNIVERSITY OF TORONTO (CANADA); 0779 </INSTITUTION>
<DESCRIPTORS> ENGINEERING, ELECTRONICS AND ELECTRICAL; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> J. M. XU; K. C. SMITH </ADVISER>
<CLASSIFICATIONS> MOS </CLASSIFICATIONS>
<ABSTRACT>
In the work presented in this thesis, design,
simulation, and implementation of VLSI-compatible
artificial neural networks have been explored. As a
result, a new class of MOS-compatible artificial neural
networks (ANNs) has been developed.
First, based on a general model for an artificial neural
network with localized storage of parameters, we have
employed a quadratic relation, with constraints similar
to those found in practical MOS devices, to implement
synapses in a feedforward neural network. A software
simulator has been developed through which to consider
the activity constraints of such synapses. With this
simulator, through extensive simulations, we have
identified and fully examined several architectural-
level designs which provide greater flexibility and
optimal utilization of simple MOS-compatible synapses in
network applications. Our theoretical investigation
includes analysis, low-level and high-level simulation,
as well as a geometrical interpretation of this new
class of networks.
Our research at a device-level has led to the design of
a MOS device with an externally-controllable threshold
voltage, called a Synapse-MOS device, for use as a
synapse in ANNs.
One of the developed architectures, called the
Switchable-Sign-Synapse Architecture (SSSA), has been
selected for full-custom VLSI design and implementation.
Basic blocks have been separately designed, and
individually and collectively tested through several
chip-fabrication cycles. For the first time, these
networks provide the option of discriminating-function
selection as well as adaptation of weights.
Finally, in a second development inspired by the promise
of a fully-quadratic synapse in various applications, we
have designed, fabricated, and tested a special network
having fully-quadratic synapses. While, otherwise, our
major attention has been directed towards the solution
of feedforward pattern-recognition problems, the
applicability of this particular architecture to general
function-approximation problems and real-time hardware
for unsupervised competitive learning has been shown.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  3157 </NUMBER>
<ORDER>   AAINN02743 </ORDER>
<TITLE> A UNIFIED AND EXTENDED FRAMEWORK FOR OPERATOR SELECTION IN GENERALIZED MODUS PONENS TYPE FUZZY REASONING </TITLE>
<AUTHOR> DEMIRLI, KUDRET </AUTHOR>
<YEAR> 1995 </YEAR>
<INSTITUTION> UNIVERSITY OF TORONTO (CANADA); 0779 </INSTITUTION>
<DESCRIPTORS> ENGINEERING, INDUSTRIAL; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> I. B. TURKSEN </ADVISER>
<CLASSIFICATIONS> EXPERT SYSTEMS </CLASSIFICATIONS>
<ABSTRACT>
This thesis deals with issues related to fuzzy expert
systems, in general, and implication functions and the
inference known as Generalized Modus Ponens (GMP), in
particular.
A unified framework to the generation of implications is
adopted and based on the properties of the unified
framework, two new implication functions are generated.
Existing results about the relationship between the
conjunctions and implications are reviewed and extended.
A general and unified framework is provided for the
identification of appropriate operators (implication
functions and composition operators) in GMP. It is shown
that there are implication functions and composition
operators, other than the extreme solutions, which
produce conclusions in GMP in accordance with the
identified desirable properties of inference. The set of
such operators are characterized and a broader set of
composition operators are identified in order to be used
with a given implication function. Conversely, a broader
set of implication functions are identified in order to
be used with a given composition operator. This analysis
is extended from the implications under the unified
framework to general implications.
Based on the analysis of the properties of implications,
results regarding the rule decomposition principle are
extended and operation decomposition principle is
proposed. These principles lead to two efficient
implementations of GMP with multi-antecedent rules.
These are called inference with rule decomposition and
inference with operation decomposition. The selection of
a t-norm operator in the multi antecedent case is also
investigated in conjunction with rule and operation
decomposition principles.
Inference with rule and operation decomposition
procedures are considered and inference with operation
decomposition procedure is successfully applied to
implement a navigation algorithm for an autonomous
mobile robot in real time. A new heuristic method is
also suggested to combine the outcome of individual
rules.
In summary, a broader set and variety of composition
operators and implication functions are incorporated
into GMP. With the efficient implementations,
computational complexity of GMP is reduced from an
exponential function to a polynomial function of the
number of antecedent variables. Finally, some of the
theoretical findings of this thesis are successfully
applied in the solution of a practical problem.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  3158 </NUMBER>
<ORDER>   AAGC506611 </ORDER>
<TITLE> SYSTEME INTEGRE DE CONCEPTION DES BOITES DE TRANSMISSION PAR ENGRENAGES; INTEGRATED SYSTEM FOR GEARBOX DESIGN </TITLE>
<AUTHOR> MEHDI, KAMEL </AUTHOR>
<YEAR> 1995 </YEAR>
<INSTITUTION> INSTITUT NATIONAL DES SCIENCES APPLIQUEES DE LYON (FRANCE); 5285 </INSTITUTION>
<DESCRIPTORS> ENGINEERING, MECHANICAL; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> NIL </ADVISER>
<CLASSIFICATIONS> EXPERT SYSTEM </CLASSIFICATIONS>
<ABSTRACT>
Le processus de conception d'un produit mecanique
regroupe generalement differentes activites. Chaque
activite est generalement modelisee par un programme qui
execute des procedures appelees a partir des methodes
definies dans differentes classes d'objets. De meme,
differentes activites manipulent les memes objets sans
aucune interaction entre eux. Cependant, une simple
modification des attributs d'un objet peut impliquer des
modifications sur les attributs des autres objets
manipules par d'autres activites. Dans la these, nous
presentons un systeme integre de conception des boi tes
de transmission par engrenages. Dans ce systeme, nous
presentons une approche qui permet de cooperer des
differentes activites de conception des boi tes de
transmission. Cette approche est basee sur une
representation orientee objets des differents composants
mecaniques de la boi te. Cette representation permet la
construction d'une bibliotheque de composants commune
pour toutes les activites de conception. La
compatibilite du systeme est maintenue grace a la
definition de differentes relations de parente entre les
objets, des contraintes et des regles de conception,
ainsi que des methodes. Cette bibliotheque communique
entre un module de traitement des donnees, un module de
base des donnees, et l'utilisateur a travers une
interface homme-machine.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  3159 </NUMBER>
<ORDER>   AAINN02599 </ORDER>
<TITLE> ADAPTIVE NEUROCONTROL AND ITS APPLICATION TO ROBOTS </TITLE>
<AUTHOR> LIANG, FENG </AUTHOR>
<YEAR> 1995 </YEAR>
<INSTITUTION> MCMASTER UNIVERSITY (CANADA); 0197 </INSTITUTION>
<DESCRIPTORS> ENGINEERING, ELECTRONICS AND ELECTRICAL; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> H. A. ELMARAGHY </ADVISER>
<CLASSIFICATIONS> FLEXIBLE JOINTS, NEURAL NETWORKS </CLASSIFICATIONS>
<ABSTRACT>
This thesis is devoted to investigating adaptive
neurocontrol of nonlinear systems with uncertain or
unknown dynamic models. Novel theoretical synthesis and
analysis of neurocontrol systems have been conducted,
and applied to the control of flexible joint robots with
experimental tests. The contributions of this thesis
fall into the following three areas: (1) neural
networks, (2) adaptive neurocontrol and (3) control of
flexible joint robots.
The aim of my research in the neural network area is to
search for fast and global convergent learning
algorithms with reduced computation burden. The
localized neural networks with competitive lateral
inhibitory cells were introduced. The developed extended
Kalman filtering algorithm with UD factorization can
make the localized polynomial networks and localized pi-
sigma networks possess fast learning convergence and
less computation. The multi-step localized adaptive
learning algorithm was derived for RBF networks which
leads to about 10 fold improvement in the speed of
learning convergence. New neural network models of
nonlinear systems were introduced to facilitate
neurocontroller design.
In the adaptive neurocontrol area, theoretical issues of
the existing backprop-based adaptive neurocontrol
schemes were first clarified. Then new direct and
indirect adaptive neurocontrol schemes, with better
performance, were proposed. It is noticed that the
system stability of many existing neurocontrol schemes
cannot be proved. In addition, few stability-based
adaptive neurocontrol schemes are available and can only
be applied to feedback linearizable nonlinear systems.
The thesis provides two major contributions to the
stability-based adaptive neurocontrol approach. The
first contribution is extending the classical self-
tuning control methodologies for linear systems to the
self-tuning neurocontrol of nonlinear systems by using
localized neural networks. This extension greatly
enriches the neurocontrol algorithms with guaranteed
system stability. The second contribution is proposing
the variable index control approach, which is of great
significance in the control field, and applying it to
derive new stable robust adaptive neurocontrol schemes.
Those new schemes possess inherent robustness to system
model uncertainty, which is not required to satisfy any
matching condition. They do not impose any growth
condition and infinite differentiability assumption on
the system nonlinearity. They can also be applied to
nonlinear systems which are not feedback-linearizable.
As applications and extensions of the above theory,
three different robust adaptive neurocontrol schemes for
general flexible joint robots were derived with proven
system stability. All three schemes are able to
incorporate a priori information about the robot
dynamics into the neurocontroller design to simplify the
neural network design. No acceleration and jerk signals
are required in these control laws. Moreover, arbitrary
joint stiffness is allowed in the control algorithms.
To demonstrate the feasibility of the proposed learning
algorithms and adaptive neurocontrol schemes, intensive
computer simulations were conducted based on different
nonlinear systems and functions. Different types of
adaptive tracking problems and regulation problems were
considered. Furthermore, the proposed adaptive
neurocontrol schemes were experimentally tested using an
existing experimental flexible joint robot. Both the
simulation and experimental results confirm the
practicability of the proposed schemes.
The thesis concludes that the neurocontrol approach,
along with the development of neural computers and large
scale parallel distributed processors, is capable of
solving the complex control problem of nonlinear systems
with uncertain or unknown dynamic models.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  3160 </NUMBER>
<ORDER>   AAI9612258 </ORDER>
<TITLE> HYBRID NEURAL NETWORKS AND NETWORK DESIGN </TITLE>
<AUTHOR> PATTERSON, RAYMOND A. </AUTHOR>
<YEAR> 1995 </YEAR>
<INSTITUTION> THE OHIO STATE UNIVERSITY; 0168 </INSTITUTION>
<DESCRIPTORS> BUSINESS ADMINISTRATION, GENERAL; COMPUTER SCIENCE; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> HASAN PIRKUL </ADVISER>
<CLASSIFICATIONS> TELECOMMUNICATIONS </CLASSIFICATIONS>
<ABSTRACT>
The major contribution of this dissertation is to design
and demonstrate the effectiveness of neural networks
hybridized with problem specific meta-knowledge to solve
combinatorial optimization problems. Heuristic
procedures are incorporated into the neural network
topological design. The learning rules implemented
within the neural network adjust the cost weights to
improve on the initial heuristic results obtained by the
neural network. The viability of the neural network
implementation is shown by solving the Capacitated
Minimum Spanning Tree (CMST) and the Tree-Star
telecommunications network topology design problems.
This dissertation also modifies the Hopfield neural
network topology to solve the Traveling Salesperson
Problem and the CMST problem. Computational results for
the Hopfield implementation of the CMST, both in terms
of computational time and quality of solution, are not
as good as the results for the hybrid neural network
techniques originated in this dissertation.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  3161 </NUMBER>
<ORDER>   AAI9611675 </ORDER>
<TITLE> THE CONSTRUCTION OF AN AT-RISK INDEX AND ITS EFFECT UPON FUNDING OF ARIZONA SCHOOL DISTRICTS </TITLE>
<AUTHOR> JORAANSTAD, MARK H. </AUTHOR>
<YEAR> 1995 </YEAR>
<INSTITUTION> ARIZONA STATE UNIVERSITY; 0010 </INSTITUTION>
<DESCRIPTORS> EDUCATION, FINANCE; EDUCATION, ADMINISTRATION </DESCRIPTORS>
<ADVISER> NIL </ADVISER>
<CLASSIFICATIONS> NIL </CLASSIFICATIONS>
<ABSTRACT>
The purpose of the study was to probe at-risk
identification criteria and to attempt to project
expenditures based upon those criteria by constructing
an at-risk index, using that index in a hypothetical
funding formula, and determining the redistributive
effect on state funding of Arizona school districts.
Research revealed that measure and prediction of at-
riskness was most precisely accomplished through use of
multiple variables reflecting home, school, and
community domains. The study commenced with the
selection of indicators, from a pool of Arizona school
district and U.S. Census Bureau data, that were
predictive of at-riskness and supported by the
literature and research. Seven variables survived the
selection process: special education students, Limited
English Proficiency students, students with low ITBS
scores, householder income, number of children in
poverty, student ethnicity, and parental education
level.
These variables, for 208 school districts, were
processed by an artificial intelligence neural network.
That Kohonen analysis, adept at pattern recognition,
classified the 208 districts into eleven categories
which were used in the development of an at-risk index,
a whole number between 1.0 and 1.25 for each Arizona
school district. The two variables most influential in
determining the Kohonen categories were ethnicity and
low ITBS scores. The resulting index was then compared
to current Arizona funding. Virtually all school
districts increased their weighted student count
considerably less under the at-risk index. Though
limitations were reached when indicators were too
disparate, neural network processing proved feasible and
useful for analysis of multiple indicators.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  3162 </NUMBER>
<ORDER>   AAI9611671 </ORDER>
<TITLE> THE EFFECT OF EXPERT SYSTEM EXPLANATORY FACILITIES ON KNOWLEDGE ACQUISITION AND REPRESENTATION </TITLE>
<AUTHOR> INGRAHAM, LAURA R. </AUTHOR>
<YEAR> 1995 </YEAR>
<INSTITUTION> ARIZONA STATE UNIVERSITY; 0010 </INSTITUTION>
<DESCRIPTORS> BUSINESS ADMINISTRATION, ACCOUNTING; INFORMATION SCIENCE; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> NIL </ADVISER>
<CLASSIFICATIONS> NIL </CLASSIFICATIONS>
<ABSTRACT>
The accounting literature has produced a simple model of
the acquisition of expertise in which the determinants
of performance are knowledge, ability, environment, and
motivation. The acquisition of knowledge, in turn, is a
function of an individual's ability, motivation,
environment, and experience. This model further assumes
that, in the accounting domain, motivation can be held
constant and environment is only of import when the
nature of the task determines the relations of knowledge
and ability to performance. Thus, according to the
model, it is an individual's experiences and ability
that have the greatest impact on the acquisition of
accounting knowledge in the accounting domain.
Experience includes task related encounters which
provided opportunities for learning. Such encounters
include one's exposure to expert systems. This research
focuses on examining the differential effect of
alternative levels of explanations provided by an expert
system's explanatory facility on subjects' mental
representations of information. The results suggest that
it is possible to systematically guide the acquisition
and formulation of expert knowledge structures through
the use of the explanatory facility of an expert system
and that the amount of explanation provided by the
explanatory facility is a key factor in successful
acquisition. However, the subject of user interaction
remains unsettled. These results, therefore, provide
useful training and system design implications, as well
as directions for future research.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  3163 </NUMBER>
<ORDER>   AAI9609284 </ORDER>
<TITLE> ARTIFICIAL NEURAL NETWORKS FOR SYSTEM MODELING, MONITORING AND CONTROL  </TITLE>
<AUTHOR> ESSAWY, MAGDI ABDEL-AZIM </AUTHOR>
<YEAR> 1995 </YEAR>
<INSTITUTION> THE UNIVERSITY OF TENNESSEE; 0226 </INSTITUTION>
<DESCRIPTORS> ENGINEERING, NUCLEAR; ARTIFICIAL INTELLIGENCE; ENGINEERING, ELECTRONICS AND ELECTRICAL </DESCRIPTORS>
<ADVISER> ROBERT E. UHRIG </ADVISER>
<CLASSIFICATIONS> DYNAMIC SYSTEM IMITATOR </CLASSIFICATIONS>
<ABSTRACT>
This dissertation introduces a new dynamic network
architecture called the Dynamic System Imitator (DSI).
It is especially designed to mimic the behavior of a
wide range of dynamic systems. It is also designed such
that its basic building neurons have a good
approximation of the known functional organization of
the human brain neuron. The DSI is a three layer
network, with neurons in the hidden layer fully
connected to every other neuron in the hidden and output
layers and also to itself. Time delays are simulated in
the network, using simple integrators at certain
positions. Those time delays and feedback connections
are very important to the dynamic behavior of the
network. The DSI is a dynamic deterministic neural
system that is designed to have enough flexibility to be
arranged to have similar behavior to a wide class of
other real deterministic systems. Two different training
algorithms have been designed to train the DSI. One is
based on a one-dimensional minimization. The other is
based on a multi-dimensional minimization. The
characteristics of both algorithms have been discussed.
The feasibility of using the DSI to model linear and
nonlinear systems has been studied. It has been adopted
for check valve monitoring application in which the DSI
was used to model a very complicated nonlinear
relationship between two different vibration signals
measured by accelerometers mounted on two different
positions of the check valve. A control strategy using
the DSI was developed. This control strategy, was
applied to control the chaotic behavior of the Lorenz
system. This application showed very interesting results
that demonstrated the ability of the DSI for dynamic
system control.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  3164 </NUMBER>
<ORDER>   AAI9609268 </ORDER>
<TITLE> AUTOMATIC SENSOR PLACEMENT FOR VOLUMETRIC OBJECT CHARACTERIZATION  </TITLE>
<AUTHOR> ROUI-ABIDI, BESMA A. </AUTHOR>
<YEAR> 1995 </YEAR>
<INSTITUTION> THE UNIVERSITY OF TENNESSEE; 0226 </INSTITUTION>
<DESCRIPTORS> ENGINEERING, ELECTRONICS AND ELECTRICAL; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> R. C. GONZALEZ; D. W. BOULDIN </ADVISER>
<CLASSIFICATIONS> ACTIVE SENSING </CLASSIFICATIONS>
<ABSTRACT>
Active sensing is the process of exploring the
environment using multiple views of a scene captured by
sensors from different points in space under different
sensor settings. Active sensing can be used for the
modeling of unknown objects or the recognition of
objects in a scene. Applications of active sensing are
numerous and can be found in the medical field, in
archeology, in the movie and advertisement industry, in
manufacturing, and in the environmental industry.
In this work, the focus is on the use of a single vision
sensor (camera) to perform the volumetric modeling of an
unknown object in an entirely autonomous fashion. The
camera moves to acquire the necessary information in two
ways: (a) viewing closely each local feature of interest
using 2-D data; and (b) acquiring global information
about the environment via 3-D sensor locations and
orientations. An iterative 2-D optimization process is
developed and the enhanced image at each step is
projected along the corresponding viewing direction. The
new projection is intersected with previously obtained
projections for volume reconstruction. During the global
exploration of the scene, the current image as well as
previous images are used to maximize the information in
terms of shape irregularity as well as contrast
variations. The scene on the borders of occlusion
(contours) is modeled by partitioning the contour images
and evaluating an entropy-based objective functional on
each contour segment. This functional is optimized to
determine the best next view, which is recovered by
computing the pose of the camera. A criterion based on
the minimization of the difference between consecutive
volume updates is set for termination of the exploration
procedure. These steps are integrated into the design of
an off-line Autonomous Model Construction System AMCS,
based on data-driven active sensing. The system operates
autonomously with no human intervention and with no
prior knowledge about the object.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  3165 </NUMBER>
<ORDER>   AAI9609004 </ORDER>
<TITLE> A NEURAL NETWORK BASED ANESTHESIA ALARM SYSTEM </TITLE>
<AUTHOR> FARRELL, ROBERT MICHAEL </AUTHOR>
<YEAR> 1995 </YEAR>
<INSTITUTION> THE UNIVERSITY OF UTAH; 0240 </INSTITUTION>
<DESCRIPTORS> ENGINEERING, BIOMEDICAL; HEALTH SCIENCES, MEDICINE AND SURGERY; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> NIL </ADVISER>
<CLASSIFICATIONS> NIL </CLASSIFICATIONS>
<ABSTRACT>
Conventional anesthesia monitors use threshold alarms
that merely announce to the anesthesiologist that a
given parameter has fallen below or risen above some
preset threshold. These alarms give no indication as to
the cause of the threshold violation. This dissertation
describes an alarm system that monitors three patient
waveforms (CO$sb2$, expiratory flow, and airway
pressure) and uses a neural network classifier to
determine which, if any, of 21 breathing circuit faults
exist in the anesthesia breathing circuit.
Neural network training data was collected by
ventilating a lung simulator. When tested on simulator
data withheld from network training, the best version of
the alarm system correctly identified 80.5% of 1008
fault events and had a false positive rate of 2.6%. A
version tested clinically had a false positive rate of
5.2% and correctly identified four of 17 fault events
observed.
The use of principal component analysis to compute a
transform matrix that resulted in a smaller neural
network input vector whose elements were uncorrelated
was explored in one version of the alarm system. The
principal component transform was useful because a
smaller neural network could be trained in less time.
The alarm system that made use of the principal
component transform performed similarly to the alarm
system that did not. It was concluded that the principal
component transform added a layer of complexity to the
system that did not improve performance.
By integrating information available from the monitoring
equipment, the neural network based alarm system was
able to make more intelligent decisions about the
breathing circuit than conventional monitors are
currently capable of doing.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  3166 </NUMBER>
<ORDER>   AAI9608945 </ORDER>
<TITLE> CORDOC: A HYBRID AI APPROACH TO ECG INTERPRETATION </TITLE>
<AUTHOR> KUPPURAJ, RAVI NARAYAN </AUTHOR>
<YEAR> 1995 </YEAR>
<INSTITUTION> LOUISIANA TECH UNIVERSITY; 0109 </INSTITUTION>
<DESCRIPTORS> ENGINEERING, BIOMEDICAL; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> NIL </ADVISER>
<CLASSIFICATIONS> NEURAL NETWORKS </CLASSIFICATIONS>
<ABSTRACT>
The hypothesis of this dissertation is the addition of
the qualitative information about the subject would
improve the overall recognition efficiency of a NN ECG
classification system as compared to the NN system
without utilizing this additional information. This
philosophy was implemented in the design and development
of CORDOC, an ECG arrhythmia classification system for
classifying 15 types of ECG rhythms, including normal
sinus rhythm. CORDOC utilized both the non-symbolic ECG
time domain data, as well as available symbolic,
qualitative information about the subject. CORDOC
essentially consists of a neural network module to
process the ECG data and a rule-based module to process
the qualitative information. The overall recognition
efficiency was 70.33 percent and 75 percent for the
neural network module alone and the complete of CORDOC
respectively. The average Specificity was 97.88 percent
and 98.17 percent for the NN module alone and for the
complete of CORDOC respectively. The average Positive
Predictivity was 72.18 percent and 76.67 percent for the
neural network module alone and CORDOC respectively.
The rule-based module overruled the NN module's
classification for 18 of the test cases. This means, for
282 of the 300 cases, the rule-based module either
agreed with the NN classification or did not have
sufficient information to overrule the NN
classification. Fourteen of these overrules resulted in
a correct classification of the case, while the
remaining four overrules still resulted in incorrect
classifications. The overall sensitivity improved by
6.64 percent, and the Positive Predictivity improved by
6.22 percent over the NN module's classification. The
number of errors were reduced by 15.9 percent for the
complete CORDOC over the NN module alone.
When the number of classes were abstracted to 10
categories by grouping together the PVC related rhythms
and the tachy-rhythms, the overall recognition
efficiency of CORDOC was 82.2 percent. On further
abstraction by grouping premature atrial contractions
with atrial fibrillation cases, a recognition efficiency
of 84.2 percent was seen for nine rhythm categories.
Thus the addition of rule-based system resulted in
improved overall efficiency and the average Specificity
over the NN module for classifying the 15 rhythms. The
approach of integrating neural networks and rule-based
system provides a very viable solution for ECG diagnosis
in particular and medical diagnostic systems in general.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  3167 </NUMBER>
<ORDER>   AAI9608942 </ORDER>
<TITLE> F3MCNN: FUZZY MINIMUM MEAN MAXIMUM CLUSTERING NEURAL NETWORK  </TITLE>
<AUTHOR> WU, LIANG-TSAN </AUTHOR>
<YEAR> 1995 </YEAR>
<INSTITUTION> OKLAHOMA STATE UNIVERSITY; 0664 </INSTITUTION>
<DESCRIPTORS> COMPUTER SCIENCE; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> HUIZHU LU </ADVISER>
<CLASSIFICATIONS> PATTERN CLUSTERING </CLASSIFICATIONS>
<ABSTRACT>
Scope and method of study. In this study, the author
developed a real-time pattern clustering system called
the fuzzy minimum mean maximum clustering neural network
(F3MCNN). It can represent and manipulate inexact, fuzzy
cluster information. The F3MCNN model is a synergetic
combination of a modified adaptive resonance theory
(ART) neural network with the fuzzy set theory. It has
the self-organization property and adaptive learning
ability of the ART. The system architecture of F3MCNN
consists of two subsystems: the attentional subsystem
and the selection control subsystem. It utilizes both
the learned concept and the statistical characteristics
of clusters to classify patterns. Its clustering
algorithm contains two phases: fuzzy hyper-box
clustering and fuzzy statistical clustering. The fuzzy
statistical clustering process is used to solve the
problem of full membership ambiguity in fuzzy hyper-box
clustering. Fisher's iris data was used in the
experiment to compare the F3MCNN clustering results with
two similar models.
Findings and conclusions. The 91.3%-97.3% accuracy rates
are shown in the iris data experimental results by using
the proposed model. The F3MCNN model has the following
advantages: (1) it can handle real-world dynamic and
inexact pattern clustering problems, (2) it has human-
like accumulative learning ability, (3) it is a fast and
self-adjust pattern clustering technique and can achieve
cluster stability in just one pass of patterns, (4) it
requires no time-consuming work for hyper-box overlap
checking and contraction, and (5) it is free from the
problem of ambiguous full membership.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  3168 </NUMBER>
<ORDER>   AAI9608889 </ORDER>
<TITLE> INTERVAL-VALUED APPROXIMATE INFERENCE USING FUZZY RELATIONAL TECHNIQUES  </TITLE>
<AUTHOR> YEW, KOK MENG </AUTHOR>
<YEAR> 1995 </YEAR>
<INSTITUTION> THE FLORIDA STATE UNIVERSITY; 0071 </INSTITUTION>
<DESCRIPTORS> COMPUTER SCIENCE; INFORMATION SCIENCE; HEALTH SCIENCES, GENERAL; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> LADISLAV KOHOUT </ADVISER>
<CLASSIFICATIONS> EXPERT SYSTEMS </CLASSIFICATIONS>
<ABSTRACT>
Inference techniques had traditionally been based on
modus ponens, modus tollens, syllogism and
contraposition. In this dissertation, we look at
inference based on subset containment, supported by the
power set theory and mathematical relations. Two
distinct groups of relational products definitions were
compared here, the triangle relational products of
Bandler and Kohout (called BK-products in the
literature) and their B- and K- modifications suggested
by DeBates and Kerre. The type of inference studied here
belongs to a category called interval-valued inference
as opposed to point-based inference and is based on the
"Checklist Paradigm" of Bandler and Kohout.
One crucial factor in using the relational products is
the choice of the connectives. T-norms and t-conorms had
been used for the AND and OR connective in one of the
relational product definitions as opposed to the
traditional MAX and MIN counterpart. However, there are
an infinite number of t-norms and t-conorms that could
be used and it is difficult to know which is the most
suitable.
To avoid this situation, interval-valued approximate
inference templates were abstracted from these
relational products definitions. These templates were
instantiated using a meta theory called the checklist
paradigm in which the bounds of logical connectives can
be found, giving rise to interval-valued approximate
fuzzy relational inference structures. The class of
upper and lower bounds of the connectives provide the
intervals of the computation.
A simulator was built using the activity structures
methodology to evaluate these fuzzy relational inference
structures in a complete medical domain dealing with
multiple context. The conceptual structure of the
complete domain was based on the structures of a medical
knowledge base system, CLINAID. The simulation was
performed using fuzzy input data, crisp input data,
computation with and without paradox in three different
scenarios: body systems identification, disease
diagnosis (deterministic) and disease diagnosis
(stochastic).
We defined inference bands for the inference structures
and introduced new performance metrics to measure the
inference structures that we had instantiated from the
templates. The performance of the inference structures
based on these metrics were reported.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  3169 </NUMBER>
<ORDER>   AAGC505659 </ORDER>
<TITLE> A STATISTICAL EXPERT SYSTEM PROTOTYPE: AN APPLICATION OF KNOWLEDGE ENGINEERING TO MANAGEMENT OF CONFOUNDING FACTORS  </TITLE>
<AUTHOR> LAMMI, SEPPO </AUTHOR>
<YEAR> 1995 </YEAR>
<INSTITUTION> KUOPION YLIOPISTO (FINLAND); 5754 </INSTITUTION>
<DESCRIPTORS> COMPUTER SCIENCE; ARTIFICIAL INTELLIGENCE FINLAND </DESCRIPTORS>
<ADVISER> NIL </ADVISER>
<CLASSIFICATIONS> MEDICAL INFORMATICS </CLASSIFICATIONS>
<ABSTRACT>
Statistical expert systems are applications of knowledge
engineering and artificial intelligence technology.
During recent years an increasing number of such systems
have been constructed. These systems are usually aimed
to be competent statistical advisors and guides in some
predefined area of statistics, for instance in
regression analysis. A statistical expert system may
also be an intelligent front-end software added on to an
existing statistical package.
In medicine, where the unexperimental study type is a
common practice, sampled data sets often contain
properties that make the association at interest between
an independent variable (suspected cause) and a
dependent variable (response) spurious. In this work two
kinds of variables that may distort the associations
have been considered. If the data set contains a
variable that has two properties: it is statistically
associated with the independent variable and it is (in
some sense) a cause of the dependent variable, it may
act as a confounding factor in the association
considerations. To reach a correct conclusion, the
confounding factor must be managed, usually by means of
suitable statistical analyses. A data set may contain
several confounding factors, of which each one alone or
even two or more together can confound the associations.
An effect modifier is another variable that may distort
the association between the independent and the
dependent variable. To be an effect modifier, a variable
must be a cause for the dependent variable.
In this work, a statistical expert system prototype has
been constructed for the identification and management
of both confounding factors and effect modifiers. The
system uses statistical multivariate models in the
identification phase and it is applicable to cohort and
case-control studies. The expert system also proposes a
suitable statistical analysis to the management of
confounding factors and effect modifiers. The expert
system has been constructed with an object-oriented
expert system tool, called LEVEL5 Object$rm sp0TM.$
Knowledge representation is based on methods
encapsulated in objects, rules and demons. The
statistical calculations needed by the expert system are
carried out by SPSS/PC+$rm sp0TM$ statistical software
package.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  3170 </NUMBER>
<ORDER>   AAI9608657 </ORDER>
<TITLE> TECHNIQUES FOR OPTIMIZING NEURAL NETWORKS FOR MEDICAL APPLICATIONS  </TITLE>
<AUTHOR> NARUS, SCOTT PATRICK </AUTHOR>
<YEAR> 1995 </YEAR>
<INSTITUTION> THE UNIVERSITY OF UTAH; 0240 </INSTITUTION>
<DESCRIPTORS> ENGINEERING, BIOMEDICAL; COMPUTER SCIENCE; HEALTH SCIENCES, GENERAL; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> NIL </ADVISER>
<CLASSIFICATIONS> DATA NORMALIZATION, HIERARCHICAL NETWORKS </CLASSIFICATIONS>
<ABSTRACT>
The overwhelming amount and diversity of clinical data
that may be collected from patients have necessitated
the development and use of sophisticated processing
methods in order to make the data useful in medical
applications. Artificial neural networks (ANNs) are one
such method that has found growing success in the
medical field. In the past, techniques for optimizing
neural networks have focused almost completely on ANN
training algorithms and architectures in order to
improve performance on specific applications. However, a
more data-centric view of optimization may prove more
valuable in making ANNs useful to a wider community of
medical researchers.
Four specific characteristics of medical data processing
are addressed: (1) large numbers of classes into which
we wish to categorize data; (2) nonuniform distribution
of classes; (3) features from input data with non-
Gaussian distributions and widely variable ranges; (4)
large, complex data sets from which it is difficult to
choose appropriate data for model development. These
characteristics present potential problems for ANN
development. It is proposed that these problems may be
overcome by using new data normalization techniques,
implementing hierarchical networks, and using distance
metrics to choose the most useful training patterns.
These proposals should be generalizable to many medical
applications because they focus on solutions to data
problems and not specific applications.
The specific proposals are applied to two practical
medical applications: blood pressure determination and
classification of breathing circuit faults. The
proposals are compared with standard ANN training
techniques. For each of the proposals, there was a
significant increase in training performance, or network
classification capability, or both. It is concluded that
the proposals should be generalizable to other medical
applications and that a data-centric view of
optimization is valuable to ANN development in medical
applications.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  3171 </NUMBER>
<ORDER>   AAI9608472 </ORDER>
<TITLE> A NOVEL FAULT LOCATION TECHNIQUE FOR INTERCONNECTED ELECTRICAL CIRCUITS USING ARTIFICIAL NEURAL NETWORKS </TITLE>
<AUTHOR> WANG, NIEN-CHUNG </AUTHOR>
<YEAR> 1995 </YEAR>
<INSTITUTION> RENSSELAER POLYTECHNIC INSTITUTE; 0185 </INSTITUTION>
<DESCRIPTORS> ENGINEERING, ELECTRONICS AND ELECTRICAL; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> MIETEK T. GLINKOWSKI </ADVISER>
<CLASSIFICATIONS> PATTERN RECOGNITION </CLASSIFICATIONS>
<ABSTRACT>
Locating a fault in power networks is important for both
system protection and maintenance purposes. On-line
fault location techniques in networks that involve
interconnected lines or cables and multi-terminal
sources, continue receiving great attention over the
years. However, many of the efforts have limited success
in providing simple and practical solutions. This thesis
postulates that simultaneous measurements of voltages
and currents at various circuit points during the fault
contain the information about the fault location.
Therefore, the fault location problem can be viewed in a
reverse problem context, and the fault location
technique can be formulated as pattern recognition
system. The thesis develops a new fault location
technique that: (1) takes advantage of an artificial
neural network (ANN) with fast and good pattern
classification features, and (2) utilizes modern
protective relaying hardware with the capability of
simultaneously recording and transmitting the fault
event data. To interpret the ANN operating results, a
new 3-D display is developed to provide an interface
between the ANN and the power network operating
personnel. In the application part of the thesis, first,
bench-mark studies on a two-terminal transmission line
and two types (tree-and grid-type) of multi-terminal
underground distribution networks are carried out, which
involve five major tasks: (1) generate the fault data of
balanced faults at discrete points of the circuit, (2)
select ANN training data and the corresponding ANN
architecture, (3) train and test the ANN, (4) perform
sensitivity analysis, and (5) monitor adaptation of the
trained ANN to the actual fault data. Next, the thesis
studies the applicability of the new technique for
locating Single-Line-to-Ground faults in medium voltage
underground feeders integrated with the low voltage
networks. The ANN training and testing data are
generated by the ElectroMagnetics Transient Program. The
results indicate that the new technique is economically
viable, reliable, safe, fast, flexible and intelligent.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  3172 </NUMBER>
<ORDER>   AAI9608207 </ORDER>
<TITLE> EXPLORATION OF NEURAL CONTROLLERS FOR AUTOMATIC GENERATION CONTROL  </TITLE>
<AUTHOR> KANETKAR, JITENDRA SHRIRAM </AUTHOR>
<YEAR> 1995 </YEAR>
<INSTITUTION> NEW MEXICO STATE UNIVERSITY; 0143 </INSTITUTION>
<DESCRIPTORS> ENGINEERING, ELECTRONICS AND ELECTRICAL; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> SATISH J. RANADE </ADVISER>
<CLASSIFICATIONS> ENERGY MANAGEMENT, ARTIFICIAL INTELLIGENCE </CLASSIFICATIONS>
<ABSTRACT>
Automatic Generation Control (AGC) is the cardinal
function associated with Energy Management Systems (EMS)
for electric power systems, which controls the
generating units to serve the utility's obligation to
meet its load. This has traditionally been achieved by
maintaining net interchange and scheduled frequency
while keeping in perspective an overall objective of
optimizing resources. This dissertation explores the use
of Artificial Neural Networks (ANN) in the area of
Automatic Generation Control. The design of
neurocontrollers to effect improvements in Automatic
Generation Control is examined. The dissertation studies
different neurocontrollers and portrays their behaviour
by simulating the long term dynamics associated with
AGC. The simulations are performed in
MATLAB$spcircler$/SIMULINK$spcircler$ with AGC modeled
as a two-area system with detailed nonlinear models of a
Combustion Turbine plant, a Fossil Fuel plant, and a
Hydroelectric plant.
A novel application of the concept of direct control
using neural networks is put forth as a method which can
be used to modify the present AGC systems to effect
improvements. Three types of neurocontrollers for direct
control were implemented. Two were studied in detail--
one based on the dynamic backpropagation neural network,
and the other based on the static backpropagation. In
order to facilitate the training of neurocontrollers for
on-line processes wherein the neurocontroller output map
be constrained, this dissertation formulates the use of
reduced gradient in the normal backpropagation
algorithm. The dissertation shows that neurocontrollers
can be trained on-line for different objective functions
associated with AGC. Further, it is shown that the
neural network based controller can improve upon the
desirable performance criteria for AGC; namely, the unit
movement index. This is important from a utility's
perspective since it can reduce the wear and tear
(governor motors and turbine valves) costs associated
with excessive unit movement. The dissertation shows
comparative evaluations with the pros and cons of
different controllers including the conventional Area
Control Error (ACE) controller.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  3173 </NUMBER>
<ORDER>   AAI9608201 </ORDER>
<TITLE> SITEX: THE SAND INFLOW TREATMENT EXPERT </TITLE>
<AUTHOR> KANJ, MAZEN YOUSEF </AUTHOR>
<YEAR> 1995 </YEAR>
<INSTITUTION> THE UNIVERSITY OF OKLAHOMA; 0169 </INSTITUTION>
<DESCRIPTORS> ENGINEERING, PETROLEUM; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> NIL </ADVISER>
<CLASSIFICATIONS> WELLBORE </CLASSIFICATIONS>
<ABSTRACT>
Sand production or concern over the possibility of
sanding is a major problem due to its adverse effects on
thousands of oil and gas fields throughout the world.
Billions of dollars are spent each year on attempts to
predict and control sand influx and/or repair wells and
equipment damaged by sand. Sand inflow into the well
during production leads to casing abrasion and failure,
formation damage and distortion, and frequent sand
removal and cleaning.
The sand control process has a major influence on the
type of the well completion design and it influences the
guidelines for the completion process. In addition, many
wells are currently being produced below their potential
in order to restrict sand influx or erosion, and/or as a
result of poorly designed or installed sand control
methods. Evidently, the sand prediction and control
problem is exceedingly complex and suggests the use of
heuristics and the appropriateness of the expert systems
technology.
$rm Ssbsp0I0starTsb0EX$ (pronounced sitech and stands
for Sand Inflow Treatment EXpert) is an automated sand
control consultant and expert system that helps in
predicting sand production into the wellbore and assists
in selecting and designing the sand remedial treatments
and control methods. $rm Ssbsp0I0starTsb0EX$ is "grown",
using progressive approximations, rather than
constructed. The system is created based on an easy
upgrade, easy expand format and in conjunction with a
highly generic Graphical User Interface (GUI).
$rm Ssbsp0I0starTsb0EX$ modularity gives the end-user
greater flexibility to tentatively access and evaluate
different scenarios and the knowledge engineer the
ability to expand and upgrade the knowledge base at a
later stage. The system is composed of four primary
modules, these are: (1) sanding assessment, (2) control-
method selection/classification, (3) gravel-packing
gravel selection, and (4) sand-exclusion screens
selection/classification. Modularization was a natural
consequence of the nature of the problem domain of sand-
control.
$rm Ssbsp0I0starTsb0EX$ recommendations on sanding
assessment are formulated in a unified manner and using
only simple, but reliable, drilling, logging, coring,
core analysis and well testing data. This process is
based on analogy to infer threshold values and to set
ranges (boundaries) for various factors of assessment.
The control method selection module of $rm
Ssbsp0I0starTsb0EX$ starts by evaluating and grading the
suitability of each of ten commonly known and up-to-date
techniques of sand control, then moves on to classify
them and to recommend the appropriate as well as
affordable one(s).
$rm Ssbsp0I0starTsb0EX$ modularity also involves the
design and selection of two important elements of
mechanical sand-exclusion techniques: (1) the gravel-
packing gravel and (2) the screen or gauged liner. The
gravel design and selection module uses a standalone
database, containing a list of standard gravel sizes and
their characteristics, that can be edited and updated
without affecting the system or needing to change any of
the system's codes. The screen selection-process starts
by determining the type of the completion job that is
being performed and then makes use of various
completion, stimulation and well production data to
classify the different screen types and to recommend the
proper one(s).
$rm Ssbsp0I0starTsb0EX$ is equipped with a generic GUI,
in the sense that the GUI can be connected to any other
expert system, built using the N scEXPERT O
scBJECT$sp0rm TM$ shell, with only very little
modifications. The generic attribute of the GUI makes
this system a valuable and unique example in the eye of
any expert system developer.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  3174 </NUMBER>
<ORDER>   AAI9608192 </ORDER>
<TITLE> INTELLIGENT METHODS FOR THE DESIGN, ANALYSIS AND CONTROL OF METAL FORMING PROCESSES </TITLE>
<AUTHOR> ANBAJAGANE, RATHINAVEL </AUTHOR>
<YEAR> 1995 </YEAR>
<INSTITUTION> OHIO UNIVERSITY; 0167 </INSTITUTION>
<DESCRIPTORS> ENGINEERING, MECHANICAL; ENGINEERING, MATERIALS SCIENCE; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> JAY S. GUNASEKERA </ADVISER>
<CLASSIFICATIONS> HOT ROLLING </CLASSIFICATIONS>
<ABSTRACT>
Manufacturing practices are generally established by
trial and error technique. This process is not only
cumbersome but expensive as well. At the same time,
computer time to conduct numerical simulations has also
become a cost effective factor in the competitive
manufacturing environment. The outcome of the process
design, that is, optimal solution, is dependent on a
number factors including the knowledge and experience of
the designer. Artificial Intelligence (AI) tools such
Expert Systems (ES), Artificial Neural Networks (ANN)
and Case-Based Reasoning (CBR) use this idea of expert
knowledge to achieve a workable, economical and optimum
solution to the given problem in a faster manner. The
time factor has become all the more important due to
increased competition, greater demand, and stringent
standards in industry.
The primary objective of this research is to develop a
methodology and software that will use the AI techniques
for the automated design and analysis of various metal
forming processes, and an intelligent methodology for
the real-time control of a hot rolling processes. An
intelligent hybrid system, a combination of ES, ANN and
CBR, was used to develop the software for the
intelligent design and analysis of metal forming
process. This software envisages the implementation by
coalescing Computer-Aided Engineering (CAE), Computer-
Aided Design (CAD), Material Science theory, Design
theory, Optimal Process Control, and AI techniques to
achieve a robust and workable system. The required near-
net shape is given in a CAD system as an input. The
objective is to recommend a metal forming process
suitable for forming this shape from a given preform and
carry out the analysis and finally develop a process
planning report to help in the shop floor for producing
this part.
The intelligent design and analysis software was
developed to run under the Microsoft Windows$spcircler$
environment using AutoCAD$spcircler$ for windows as the
CAD system. NeuroShell$spcircler$, a neural network
shell, CBR Express$spcircler$, a windows based case-
based reasoning tool, and AutoLISP, VisualBasic and C++
programming languages were used to develop the feature
extraction, data generation, design, analysis, reasoning
and report generation modules of the software.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  3175 </NUMBER>
<ORDER>   AAI9607932 </ORDER>
<TITLE> ANALYSIS AND DESIGN OF CELLULAR MANUFACTURING SYSTEMS: MACHINE-PART CELL FORMATION AND OPERATION ALLOCATION </TITLE>
<AUTHOR> YANG, ZIYONG </AUTHOR>
<YEAR> 1995 </YEAR>
<INSTITUTION> CASE WESTERN RESERVE UNIVERSITY; 0042 </INSTITUTION>
<DESCRIPTORS> ENGINEERING, SYSTEM SCIENCE; ARTIFICIAL INTELLIGENCE; ENGINEERING, INDUSTRIAL </DESCRIPTORS>
<ADVISER> BEHNAM MALAKOOTI </ADVISER>
<CLASSIFICATIONS> INTERACTIVE CLUSTERING, NEURAL NETWORKS </CLASSIFICATIONS>
<ABSTRACT>
This dissertation addresses the machine-part cell
formation and operation allocation problem in cellular
manufacturing system design from the following aspects:
(1) machine-part cell formation based on the 0-1
incidence matrix; (2) machine-part cell formation and
part processing plan selection with minimal inter-cell
part flow under consideration of several practical
issues; (3) selection of the best cell structure when
there do not exist mutually independent cells.
(1) Based on the 0-1 incidence matrix representation of
the machine-part relationship, a neural network-based
clustering approach is developed to cluster the
incidence matrix into diagonal blocks where each block
is a machine-part cell. The clustering system is
independent of the initial incidence matrix and gives
clear final clustering results that specify the machines
and parts in each cell. In terms of percentage of
exceptional elements, machine utilization rate, and
grouping efficiency, the developed approach provides
better results compared to several existing methods.
(2) The trend in cellular manufacturing system design is
to take more practical issues into consideration. A
comprehensive machine-part cell formation approach is
developed with considerations of part processing
sequence, part production volume, machine capacities and
alternative part processing plans. The developed
approach solves two problems: the selection of part
processing plans and the formation of machine-part
cells. An iterative procedure for the nonlinear
mathematical programming model is introduced to solve
the individual problems one at a time, with one problem
using the solution of the previous problem as inputs,
until a set of plans and machine-part cells are obtained
with minimal inter-cell part flow. The convergence of
the approach is investigated. In the computational point
of view, this approach can handle large size problems.
(3) For most practical problems, there does not exist
mutually independent machine-part cells. The most often
used means to decrease or eliminate the inter-cell part
flow is to duplicate bottleneck machines. A multiple
criteria decision making framework is proposed to
investigate the alternative choices. The non-dominated
alternatives (cell structures) are generated and the
best cell structure is obtained to minimize number of
duplicate machines, to minimize number of exceptional
elements, and to maximize machine utilization rate. The
relationship among criteria is also investigated.
In the last part of this dissertation, an interactive
approach is developed to cluster discrete MCDM
alternatives. The set of alternatives is clustered into
mutually exclusive groups based upon the natural
features among alternatives, the ideal alternatives set
up by the Decision Maker, and the Decision Maker's
preference information. Alternatives in the same group
have certain common features. Clustering of alternatives
decreases the set of alternatives, decreases the number
of criteria, and provides a basis for further evaluation
of alternatives. Application to machine-part cell
formation problem is discussed.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  3176 </NUMBER>
<ORDER>   AAI9607921 </ORDER>
<TITLE> USING COMMON-SENSE KNOWLEDGE FOR COMPUTER MENU PLANNING </TITLE>
<AUTHOR> KOVACIC, KATHY JEANNE </AUTHOR>
<YEAR> 1995 </YEAR>
<INSTITUTION> CASE WESTERN RESERVE UNIVERSITY; 0042 </INSTITUTION>
<DESCRIPTORS> COMPUTER SCIENCE; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> LEON STERLING </ADVISER>
<CLASSIFICATIONS> EXPERT SYSTEMS </CLASSIFICATIONS>
<ABSTRACT>
Menu planning is a complex problem requiring both expert
and common-sense knowledge. The common-sense aspect is
the description of what a menu should look like, and how
substitutions can or should be made. A framework for
representing this information is presented; the
structure contains separate layers for foods, dishes,
meals, and menus, and means for relating the layers to
one another. Implementations of this framework are
presented, with results and analysis. A vocabulary for
common sense in menu planning is proposed.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  3177 </NUMBER>
<ORDER>   AAI9607888 </ORDER>
<TITLE> NOVEL NONLINEAR HYBRID FILTERS FOR IMAGE ENHANCEMENT </TITLE>
<AUTHOR> PENG, SHAOMIN </AUTHOR>
<YEAR> 1995 </YEAR>
<INSTITUTION> UNIVERSITY OF MINNESOTA; 0130 </INSTITUTION>
<DESCRIPTORS> PHYSICS, ELECTRONICS AND ELECTRICITY; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> NIL </ADVISER>
<CLASSIFICATIONS> NOISE, FUZZY FILTER </CLASSIFICATIONS>
<ABSTRACT>
Image noise removal and enhancement are important
subjects in image processing. Nonlinear techniques for
image enhancement and noise reduction challenge the
linear techniques by improving image quality while
removing noise. The purpose of this thesis is devoted to
systematically unifying theory and techniques for mixed
noise removal and image enhancement, and to developing
new techniques for removing large amounts of mixed
Gaussian and impulsive noise while preserving image
details. In this thesis, we introduce three new hybrid
filters which combine linear and nonlinear filters to
produce new hybrid filters capable of removing large
amounts of mixed noise. To efficiently use the ambiguous
information in an image, both fuzzy set concepts and
fuzzy logic operating rules are utilized in the filter
design techniques. The three new filters include the
single level trained fuzzy filter (SLTF), the multi-
level adaptive fuzzy filter (MLAF), and the decision
directed window adaptive hybrid filter (DDWAH).
The SLTF filter is designed to remove large amounts of
mixed noise by combining an impulse filter with a fuzzy
filter. The efficiency of the SLTF filter in removing
large amounts of mixed noise while preserving image
edges is demonstrated. The MLAF filter is an adaptive
SLTF filter which uses the local variance of image gray
scales to adapt the weights used in the linear portion
of the filter to local image statistics. The MLAF filter
provides improved visual performance compared to the
SLTF filter. The adaptive DDWAH filter uses local
statistics to adapt the window size of the filter to
local statistics. This approach prevents distortion of
small objects in the image, and removes noise more
effectively than non-adaptive filters. The experimental
results clearly show the improved noise removal
performance and good edge preservation properties.
Theoretical analysis verifies the measured results.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  3178 </NUMBER>
<ORDER>   AAI9607809 </ORDER>
<TITLE> A NEURAL NETWORK METHODOLOGY TO SOLVE ROBOTIC MANIPULATOR'S INVERSE KINEMATIC AND INVERSE DYNAMIC PROBLEMS </TITLE>
<AUTHOR> PAN, SAN-YIH </AUTHOR>
<YEAR> 1995 </YEAR>
<INSTITUTION> UNIVERSITY OF MARYLAND COLLEGE PARK; 0117 </INSTITUTION>
<DESCRIPTORS> ENGINEERING, MECHANICAL; ENGINEERING, ELECTRONICS AND ELECTRICAL; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> JACKSON C. S. YANG </ADVISER>
<CLASSIFICATIONS> NIL </CLASSIFICATIONS>
<ABSTRACT>
In the first part of this dissertation, a neural network
methodology FAFM (fast, accurate, feature-mapping
network) is developed to solve robotic manipulator's
inverse kinematic problem. It uses the Kohonen feature
map as the first learning step to classify the input
space. In the second learning step, an error-correction
rule and a fuzzy system are combined to learn the
inverse kinematic relationship.
In the second part, a FAN network (fast, accurate
network) which has a time dependent sequential learning
characteristic is developed to learn a robotic
manipulator's inverse dynamic problem and to study the
path tracking. The FAN network is created from the FAFM
network. It doesn't need the first learning step.
In the third part, a theoretical analysis for the FAFM
and the FAN networks is presented. We apply the Stone-
Weierstrass theorem to justify the existence of
approximating functions, i.e., the mapping functions for
the input space and the output space. The uniqueness of
the best approximations is verified. A mathematical
derivation of the learning rule is also included. The
intuitive convergence characteristic is obtained by
logical reasoning. Some properties of the matrix
computations and Cauchy-Schwartz inequality are used to
derive the convergence characteristic of the learning
rule and its convergence rate.
In the final part, an inverse kinematic simulation and
experiment were tested on a PUMA 560 robot to
demonstrate and validate the performance of the FAFM
network. In the experiment, a theodolite was used to
measure the actual world space coordinates of the end-
effector. To show the performance of the FAN network, a
specific sequential example of an inverse kinematics and
an example of the trajectory learning and the path fine-
tuning were also performed on a PUMA 560 robot.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  3179 </NUMBER>
<ORDER>   AAI9607752 </ORDER>
<TITLE> NONLINEAR PROCESS ANALYSIS AND MODELING: INTEGRATING STATISTICAL TECHNIQUES AND NEURAL NETWORKS </TITLE>
<AUTHOR> DONG, DONG </AUTHOR>
<YEAR> 1995 </YEAR>
<INSTITUTION> UNIVERSITY OF MARYLAND COLLEGE PARK; 0117 </INSTITUTION>
<DESCRIPTORS> ENGINEERING, CHEMICAL; ENGINEERING, SYSTEM SCIENCE; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> THOMAS J. MCAVOY </ADVISER>
<CLASSIFICATIONS> NIL </CLASSIFICATIONS>
<ABSTRACT>
It has been demonstrated by many industrial applications
that neural net-works are promising in solving complex
engineering problems. However, like many other new
techniques, neural network technology is not a universal
tool without any shortcoming. In fact, there are a
number of problems that occur in neural network
applications and the theory of neural networks does not
yet have answers for all of them. Fortunately, it has
also been demonstrated that by means of integrating
neural networks with statistical techniques some of the
problems can be solved. Thus, developing integrated
methods which can be applied to model, monitor, and
optimize industrial processes is a major goal of the
dissertation.
Based on principal curve algorithm and neural networks,
a nonlinear principal component analysis (NLPCA) method
has been proposed. NLPCA can be applied to the same
problems as PCA: data reduction, sensor validation,
process monitoring, etc. Because of NLPCA's ability to
describe nonlinear data more efficiently than PCA, it
can enhance the performance of these tasks. Applying the
NLPCA method in continuous process monitoring has been
discussed. The results of case studies show that the
NLPCA monitoring approach has many advantages over
existing approaches. Based on the idea of Multi-way PCA,
NLPCA has been successfully used in batch tracking. By
projecting the data of a batch process down to a low
dimensional space defined by nonlinear principal
components, the batch can be easily monitored by
tracking its progress in this low dimensional space. The
application results show that the NLPCA batch tracking
is simple and powerful. Using NLPCA in autoassociative
neural networks is also discussed. Applying the
autoassociative neural networks in sensor data analysis
is presented.
Neural Net Partial Least Squares (NNPLS) method is
further extended in the dissertation. A Neural Net Multi-
way PLS method is proposed to model batch processes and
batch-to-batch optimization using an NNMPLS model scheme
is presented. Several advantages have been achieved by
proposed batch optimization approach. First, a first-
principal model and on-line state measurements are not
needed. Second, the method can deal with plant-model
mismatch. Third, the computation time in optimization is
significantly less than that using a method based on a
first-principle model. Finally NLPCA and NNPLS are also
used together to solve an industrial soft sensor
problem, and excellent results are achieved.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  3180 </NUMBER>
<ORDER>   AAG9717823 </ORDER>
<TITLE> SUPPRESSIVE SPECIALIZATION: IMPLICATIONS FOR GENERALIZATION AND INTERFERENCE IN CONNECTIONIST NETWORKS </TITLE>
<AUTHOR> FRANKLIN, ALAN LYNN </AUTHOR>
<YEAR> 1995 </YEAR>
<INSTITUTION> UNIVERSITY OF WASHINGTON; 0250 </INSTITUTION>
<DESCRIPTORS> PSYCHOLOGY, COGNITIVE; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> EARL HUNT </ADVISER>
<CLASSIFICATIONS> ARTIFICIAL INTELLIGENCE </CLASSIFICATIONS>
<ABSTRACT>
Three experiments were conducted to investigate the
relationship between generalization and interference in
connectionist networks. Specific modifications to the
traditional error-back propagation learning algorithm
are proposed to mitigate the interference that results
from introducing new knowledge into previously trained
networks. Data collected from 29 human subjects was
compared to networks using the traditional algorithms
and networks using the modified algorithm. The results
indicate substantial improvements in connectionist
network performance, in both tolerance to interference
and improved generalization, can result from simple
modifications to the learning algorithm that acknowledge
previously acquired knowledge. Furthermore, these
improvements result in connectionist network
performances that more closely resemble the behaviors of
human subjects when faced with similar tasks.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  3181 </NUMBER>
<ORDER>   AAG1380692 </ORDER>
<TITLE> AN INCREMENTAL LEARNING AND CLASSIFICATION SYSTEM FOR JOB OPENINGS </TITLE>
<AUTHOR> YAO, CHIH-CHUNG </AUTHOR>
<YEAR> 1995 </YEAR>
<INSTITUTION> UTAH STATE UNIVERSITY; 0241 </INSTITUTION>
<DESCRIPTORS> COMPUTER SCIENCE; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> JIANPING ZHANG </ADVISER>
<CLASSIFICATIONS> NIL </CLASSIFICATIONS>
<ABSTRACT>
Automating the classification of a job-opening database
is challenging because (1) it involves a large number of
classes and features; (2) many classes and features are
not known during classification; (3) the description of
some classes may be changed once in a while; (4) it is
desired that the system be able to provide an
uncertainty value for each classification result; and
(5) the job descriptions that are used as a basis for
classification often contain noisy data.
Applying machine learning techniques to this kind of
task is considered to be the best solution, because
through incremental learning techniques, the system can
generate and modify its classification rules from time
to time. Nevertheless, most popular machine learning
algorithms can process only data with fixed structure
and concepts.
The job-opening database cannot have a fixed structure,
because each job opening is composed of an unpredictable
number of terms. So, we need to define a database with a
dynamic structure, wherein the number of attributes and
concepts may increase boundlessly when more data are
added.
We designed and implemented a simple, but novel,
incremental learning algorithm, called VOTE, that
addresses the above-noted problems. (Abstract shortened
by UMI.)
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  3182 </NUMBER>
<ORDER>   AAI9607738 </ORDER>
<TITLE> STRUCTURAL AND RELIABILITY ANALYSES OF SHIPS WITH FUZZY AND RANDOM VARIABLES </TITLE>
<AUTHOR> CHAO, RU-JEN </AUTHOR>
<YEAR> 1995 </YEAR>
<INSTITUTION> UNIVERSITY OF MARYLAND COLLEGE PARK; 0117 </INSTITUTION>
<DESCRIPTORS> ENGINEERING, MARINE; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> BILAL M. AYYUB </ADVISER>
<CLASSIFICATIONS> HULL-GIRDER BENDING, FUZZY-RANDOM PDF </CLASSIFICATIONS>
<ABSTRACT>
The reliability analysis of existing structures requires
engineers to model two types of uncertainty, cognitive
and noncognitive types. The objective of this study is
to reexamine structural analysis and reliability
assessment methods by considering the cognitive and
noncognitive uncertainties.
The noncognitive uncertainty of a variable can be
described by a probability mass or density function (PMF
or PDF). Moment or simulation methods can be used for
structural reliability analysis. A methodology based on
the ultimate strength assessment module for hull-girder
bending of ships was developed using the advanced second
moment (ASM) method and simulation with variance
reduction techniques. This methodology demonstrates the
structural reliability assessment of hull-girder bending
by considering its strength parameters as random
variables in a non-closed performance function using ASM
and simulation methods. The methodology can also be
applied to closed-form performance functions. It is also
suitable for developing the structural strength and
loads for hull-girder bending as individual modules.
The cognitive uncertainty of a variable can be described
by a membership function as used in defining fuzzy sets.
Two approaches that are based on the displacement method
for structural analysis are proposed: (1) fuzzy
arithmetic approach, and (2) permutations approach. The
first approach only obtains approximate solutions. The
second approach produces the exact solution but requires
more computing time. The behavior of fundamental
structural systems was investigated, and the results
based on the second approach showed that if the modulus
of elasticity is a triangular fuzzy number, the member
forces can be either fuzzy numbers or crisp values
depending on the structural system type. Modified fuzzy
division and subtraction were also proposed for solving
simultaneous equations using fuzzy arithmetic.
The combined effect of both cognitive and noncognitive
uncertainties for a variable in structural and
reliability analyses was modeled using a proposed fuzzy-
random PDF. The variable is assumed to have a fuzzy mean
and a non-fuzzy standard deviation. The fuzzy-random PDF
is defined as the marginal density function of the
multiplication of its normalized membership function and
its random distribution. Relationships for the means and
variances among the fuzzy-random distribution,
normalized membership function, and random distribution
were developed. Moments method and discrete method were
proposed for dealing with the fuzzy-random PDF.
Reliability analysis that accounts for both types of
uncertainties showed that the permutations method
provides upper and lower bounds on reliability
estimates, whereas the fuzzy-random PDF approach
provides an average estimate.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  3183 </NUMBER>
<ORDER>   AAI9607634 </ORDER>
<TITLE> LEARNING A ROBUST RULE SET </TITLE>
<AUTHOR> LEE, YONGWON </AUTHOR>
<YEAR> 1995 </YEAR>
<INSTITUTION> UNIVERSITY OF PITTSBURGH; 0178 </INSTITUTION>
<DESCRIPTORS> COMPUTER SCIENCE; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> NIL </ADVISER>
<CLASSIFICATIONS> TRAINING DATA </CLASSIFICATIONS>
<ABSTRACT>
In concept learning, a learned concept definition is
usually evaluated by its simplicity and classification
accuracy on test data. While the importance of
classification accuracy and simplicity is not in doubt,
there are other aspects of a concept definition which
should be emphasized. This dissertation studies one such
aspect, robustness, which means an ability to withstand
errors and noise in training and test data and to
perform on future cases as well as it does on training
data.
In particular, we want to improve the robustness of a
concept definition in three ways: (1) avoiding
overfitting training data, (2) maximizing global
goodness of a concept definition by fully utilizing
local goodness of pieces of knowledge, and (3) providing
stable performance when there are errors and
perturbations in the measurements of future cases. The
three aspects of robustness are investigated empirically
with a number of learning problems and the RL induction
program.
First, a concept definition overfits training data
because it is overly specific. The main effect is that
while performing well on training data, a concept
definition is not generalized to new cases and performs
poorly. While the previous studies focused on the
relationship between complexity and accuracy on test
data, and ignored the performance on training data, our
study explores the relationship between performance on
training and test data, setting aside the complexity.
This allows us to measure the degree of overfitting.
Second, for a disjunctive set of rules, there are many
methods of using it globally in making predictions for
new case. Thus, depending on the method selected, a rule
set may exhibit different degrees of gloBal goodness. We
studied the possibility of selecting an appropriate
method of applying a rule set such that better measures
of global goodness can be obtained. Finally, we examined
how to learn a concept definition whose performance
would be less brittle with respect to measurement errors
in new cases.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  3184 </NUMBER>
<ORDER>   AAI9607516 </ORDER>
<TITLE> EXPERT SYSTEMS FOR MANAGEMENT OF URINIARY INCONTINENCE IN WOMEN  </TITLE>
<AUTHOR> GORMAN, RUTH IRENE HICKEY </AUTHOR>
<YEAR> 1995 </YEAR>
<INSTITUTION> UNIVERSITY OF FLORIDA; 0070 </INSTITUTION>
<DESCRIPTORS> HEALTH SCIENCES, NURSING; EDUCATION, HEALTH; INFORMATION SCIENCE; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> MOLLY DOUGHERTY </ADVISER>
<CLASSIFICATIONS> HYPERTEXT </CLASSIFICATIONS>
<ABSTRACT>
The purpose of this nursing informatics and outcomes
research study was to determine the effectiveness of a
personal computer-based expert system for disseminating
knowledge to ambulatory women health care consumers with
urinary incontinence for informed decision making.
Clinical knowledge from Agency for Health Care Policy
and Research (AHCPR) patient guidelines for urinary
incontinence and research literature for behavioral
treatments provided the knowledge base for the expert
system.
A quasi-experimental design with two experimental groups
and one control group was utilized. Subjects in the
experimental groups received information from an expert
system with handout or the AHCPR patient guideline
booklet with handout. The control group viewed a general
health video. The dependent variables for the study were
voiding frequency, urinary incontinence episodes,
protective pad changes, and impact on life measures. The
dependent variables were measured three times in the
study: (a) two weeks prior to the intervention, (b) two
weeks post-intervention, and (c) four to six weeks post-
intervention. Sixty women, with a mean age of 55 years,
were randomly assigned to one of the three groups.
Multivariate repeated measures analysis of variance
indicated a significant decrease in reported mean
urinary incontinence episodes over time for the expert
system and booklet groups compared to the control group
F(4,106) = 2.8614, p =.0269. As part of the repeated
measures of analysis, contrasts indicated a significant
difference between mean urinary incontinence episodes
for pre-intervention and first post-intervention,
F(1,54) = 8.84, p = (.0044).
Multivariate repeated measures analysis of variance
indicated a significant change within subjects over time
in mean number of protective pad changes, F(2,53) =
6.0022, p =.0045, and mean Incontinence Impact on Life
Scores, F(2,52) = 4.5498, p =.0151. Mean voiding
frequency, protective pad changes, and Incontinence
Impact on Life measures were not statistically
significant between groups.
Study results suggest the use of an expert system as one
effective communication means for disseminating clinical
information in an advisory capacity to ambulatory women
with urinary incontinence. This study contributes to an
evolving body of knowledge in which the role of the
consumer in health care decision making is enabled
through the use of computer technology.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  3185 </NUMBER>
<ORDER>   AAI9607465 </ORDER>
<TITLE> A REAL-TIME EXPERT SYSTEM FOR CITRUS MICROIRRIGATION MANAGEMENT </TITLE>
<AUTHOR> XIN, JIANNONG </AUTHOR>
<YEAR> 1995 </YEAR>
<INSTITUTION> UNIVERSITY OF FLORIDA; 0070 </INSTITUTION>
<DESCRIPTORS> ENGINEERING, AGRICULTURAL; AGRICULTURE, AGRONOMY; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> FEDRO S. ZAZUETA </ADVISER>
<CLASSIFICATIONS> NIL </CLASSIFICATIONS>
<ABSTRACT>
Elaborate techniques are commonplace in modern farm
management and microirrigation scheduling for citrus.
Water management practices involve complex decisions and
daily operations that are affected by water and nutrient
requirements of the trees, temporal distribution of
rainfall, and extreme weather conditions. A computer-
based system (CIMS) was developed using a real-time
expert system (RTES) and conventional control techniques
to assist citrus microirrigation, cold protection, and
fertigation management. The system integrates water
management technologies into an effective control
technique that can be used as a tool by farm managers.
CIMS combines the RTES, conventional control, and
irrigation management tools into a single system to help
the decision-making of irrigators. On-site soil moisture
sensors and an automated weather station provide data to
the system. CIMS activates or deactivates the control
devices of an irrigation system based upon its knowledge
base. The expert system operates continuously to select
an irrigation strategy and to schedule the application
of irrigation, fertigation, and cold protection. Data
uncertainty management approaches were used to validate
the sensor readings. Conventional control routines were
also developed so that irrigation and fertigation could
be applied according to user defined schedules with
control flexibility and few hardware requirements. A
simulation model of the crop root zone was developed to
estimate crop water requirements to help the user to
define irrigation schedules. A short-term prognosis of
an irrigation requirement can be generated from the
simulation. Database and farm management utilities were
also included in the system to assist the decision-
making of farm managers. Both laboratory and field tests
showed that the integrated system worked as expected as
a management tool for irrigation, fertigation, and cold
protection. The system is highly automated and has the
potential to improve microirrigation management, to
achieve water and energy savings, and to prevent water
pollution due to improper fertigation management.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  3186 </NUMBER>
<ORDER>   AAI9607371 </ORDER>
<TITLE> AUTOMATED PRELIMINARY DESIGN USING ARTIFICIAL NEURAL NETWORKS  </TITLE>
<AUTHOR> GARCELON, JOHN HERRICK </AUTHOR>
<YEAR> 1995 </YEAR>
<INSTITUTION> UNIVERSITY OF FLORIDA; 0070 </INSTITUTION>
<DESCRIPTORS> APPLIED MECHANICS; ENGINEERING, GENERAL; ENGINEERING, CIVIL; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> GALE E. NEVILL, JR. </ADVISER>
<CLASSIFICATIONS> STRUCTURAL TOPOLOGIES </CLASSIFICATIONS>
<ABSTRACT>
This dissertation investigates the applicability of
artificial neural network systems to preliminary
engineering design tasks. Synthesizing new, possibly
innovative designs by exploring the development of
structural topologies and determining their possible
behaviors are two steps of preliminary design where this
research concentrates. These two areas of preliminary
structural design have proven difficult for design
researchers. Using the neural network approach toward
these tasks is feasible, but issues such as representing
design problems in neural networks, collecting good
design examples, and measuring network performance are
still unresolved.
This research begins by examining philosophies of
design, which provides a basis for later discussions. In
particular, the influence of design automation and
computational models of design processes on the science
of design are considered.
Next, this work provides an introduction to artificial
neural networks. Two classes of neural models,
constraint satisfaction and supervised learning models,
are examined in depth. The constraint satisfaction model
is later used for development of a system for
qualitative evaluation of preliminary designs.
Supervised learning models provide the cornerstone for
development of a model that uses induction in an attempt
to learn from design examples, generalize results, and
generate preliminary structural designs.
A major bottleneck in developing most knowledge based
systems is acquiring and representing requisite
knowledge. Supervised learning models of connectionism
have the potential to alleviate this obstacle. The
second neural network system discussed and demonstrated
is a hybrid back propagation model. This system can
learn from examples of previous designs and is able to
generate new designs.
In addition to design issues, the discussion of
connectionist models includes details of the different
models, their performance, attributes, integrity, and
shortcomings. The results of this research are an
initial investigation into connectionism as applied to
design. Both connectionism and the theory of design are
relatively young in terms of formal research when
compared to traditional areas of engineering and
science. This work contributes to the maturing effort
and identifies promising areas for further research.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  3187 </NUMBER>
<ORDER>   AAI9607355 </ORDER>
<TITLE> ANALYSIS OF HIGHWAY BRIDGES USING COMPUTER-ASSISTED MODELING, NEURAL NETWORKS, AND DATA COMPRESSION TECHNIQUES </TITLE>
<AUTHOR> CONSOLAZIO, GARY RAPH </AUTHOR>
<YEAR> 1995 </YEAR>
<INSTITUTION> UNIVERSITY OF FLORIDA; 0070 </INSTITUTION>
<DESCRIPTORS> ENGINEERING, CIVIL; COMPUTER SCIENCE; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> MARC I. HOIT </ADVISER>
<CLASSIFICATIONS> NIL </CLASSIFICATIONS>
<ABSTRACT>
By making use of modern computing facilities, it is now
possible to routinely apply finite element analysis
(FEA) techniques to the analysis of complex structural
systems. While these techniques may be successfully
applied to the area of highway bridge analysis, there
arise certain considerations specific to bridge analysis
that must be addressed.
To properly analyze bridge systems for rating purposes,
it is necessary to model each distinct structural stage
of construction. Also, due to the nature of moving
vehicular loading, the modeling of such loads is complex
and cumbersome. To address these issues, computer
assisted modeling software has been developed that
allows an engineer to easily model both the construction
stages of a bridge and complex vehicular loading
conditions.
Using the modeling software an engineer can create
large, refined FEA models that otherwise would have
required prohibitively large quantities of time to
prepare manually. However, as the size of these models
increases so does the demand on the computing facilities
used to perform the analysis. This is especially true in
regard to temporary storage requirements and required
execution time.
To address these issues a real time lossless data
compression strategy suitable for FEA software has been
developed, implemented, and tested. The use of this data
compression strategy has resulted in dramatically
reduced storage requirements and, in many cases, also a
significant reduction in the analysis execution time.
The latter result can be attributed to the reduced
quantity of physical data transfer which must be
performed during the analysis.
In a further attempt to reduce the analysis execution
time, a neural network has been employed to create a
domain specific equation solver. The chosen domain is
that of two-span flat-slab bridges. A neural network has
been trained to predict displacement patterns for these
bridges under various loading conditions. Subsequently,
a preconditioned conjugate gradient equation solver was
constructed using the neural network both to seed the
solution vector and to act as a preconditioner. Results
are promising but further network training is needed to
fully realize the potential of the application.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  3188 </NUMBER>
<ORDER>   AAI9606937 </ORDER>
<TITLE> REFLECTANCE ANALYSIS FOR IMAGE UNDERSTANDING </TITLE>
<AUTHOR> OREN, MICHAEL </AUTHOR>
<YEAR> 1995 </YEAR>
<INSTITUTION> COLUMBIA UNIVERSITY; 0054 </INSTITUTION>
<DESCRIPTORS> COMPUTER SCIENCE; ARTIFICIAL INTELLIGENCE; REMOTE SENSING </DESCRIPTORS>
<ADVISER> SHREE K. NAYAR </ADVISER>
<CLASSIFICATIONS> COMPUTER VISION, RENDERING </CLASSIFICATIONS>
<ABSTRACT>
In this thesis, we study the two primary reflectance
components--diffuse and specular reflectance--and their
roles in image understanding. In particular, we explore
accurate physical modeling of reflectance and
development of scene recovery techniques.
One of the most widely used models for diffuse
reflection is the Lambertian model which predicts that
surface brightness is independent of viewing direction.
However, it is shown that the Lambertian model can be a
very inaccurate approximation for rough surfaces. A
comprehensive model is developed that predicts
reflectance from rough diffuse surfaces. The model
accounts for complex geometric and radiometric phenomena
including masking, shadowing, and inter-reflections
between points on the surface. Experiments have been
conducted on real samples, such as plaster, clay, sand,
and cloth, which demonstrate significant deviation from
Lambertian behavior. The reflectance measurements
obtained are in strong agreement with the reflectance
predicted by the proposed model. The implications of the
model for machine vision and graphics are discussed.
A theoretical framework is introduced for the perception
of specular surface geometry. When an observer moves in
three-dimensional space, real scene features, such as
surface markings, remain stationary with respect to the
surfaces they belong to. In contrast, a virtual feature,
which is the specular reflection of a real feature,
travels on the surface. Based on the notion of caustics,
a novel feature classification algorithm is developed.
Next, using support functions of curves, a closed-form
relation is derived between the image trajectory of a
virtual feature and the geometry of the specular surface
it travels on. It is shown that in the 2D case where
camera motion and the surface profile are coplanar, the
profile is uniquely recovered by tracking just two
unknown virtual features. Finally, these results are
generalized to the case of arbitrary 3D surface profiles
that are traveled by virtual features when camera motion
is not confined to a plane. An algorithm is developed
that uniquely recovers 3D surface profiles using a
single virtual feature tracked from the occluding
boundary of the object. All theoretical derivations and
proposed algorithms are substantiated by experiments.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  3189 </NUMBER>
<ORDER>   AAI9606483 </ORDER>
<TITLE> A SIMULATION SUBSTRATE FOR REAL-TIME PLANNING </TITLE>
<AUTHOR> ANDERSON, SCOTT DECATUR </AUTHOR>
<YEAR> 1995 </YEAR>
<INSTITUTION> UNIVERSITY OF MASSACHUSETTS; 0118 </INSTITUTION>
<DESCRIPTORS> COMPUTER SCIENCE; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> PAUL R. COHEN </ADVISER>
<CLASSIFICATIONS> TCL </CLASSIFICATIONS>
<ABSTRACT>
Real-time planning is, generally speaking, problem-
solving under time-pressure. In order to test and
evaluate real-time planners, scientists need to have
environments that pose problems to be solved. This
dissertation describes a substrate, called M$sc0rm ESS,$
for building environments and real-time planners.
M$sc0rm ESS$ relies on a second system, TCL, to replace
CPU time as a way to measure the amount of thinking done
by a real-time agent.
The key issue with real-time planning simulators is that
some of the simulation processes represent real-world
events and other-processes represent thinking or
planning that occurs while the real-world elements do.
Therefore, there needs to be a correspondence between
real-world events and thinking processes. Most current
simulators make the correspondence by measuring the CPU
time of the thinking process, which means that every bit
of thinking is "on the clock," but which also results in
measurement error and portability troubles.
M$sc0rm ESS$ incorporates TCL, a programming language
for agents. TCL is very nearly Common Lisp, augmented by
functions for interacting with the rest of the
simulation. The thinking time for each primitive in TCL
is determined by a platform-independent function. Thus,
an agent's every thought is on the clock but in a
platform-independent way. The functions representing
thinking time are stored in a database that is
inspectable by the agent, so that the agent can be aware
of its own thinking time and can use that time for
planning. The functions can model the duration of the
agent's thinking at either the fine-grained level of
Common Lisp primitives or at higher levels of
abstraction, in which the duration model of a primitive
is independent of the implementation of the primitive.
The fine-grained representation is important for
researchers interested in the timing properties of
particular algorithms, while the abstract representation
is important for those modeling other implementations of
the algorithms (such as parallel hardware), those
modeling different kinds of systems (such as cognitive
scientists modeling brain function), or those modeling
more global properties, such as the interaction of the
durations of various activities.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  3190 </NUMBER>
<ORDER>   AAI9606456 </ORDER>
<TITLE> INTELLIGENT CONTROL BASED ON FUZZY LOGIC AND CONSTRAINT PROCESSING </TITLE>
<AUTHOR> TYAN, CHING-YU </AUTHOR>
<YEAR> 1995 </YEAR>
<INSTITUTION> DUKE UNIVERSITY; 0066 </INSTITUTION>
<DESCRIPTORS> ENGINEERING, ELECTRONICS AND ELECTRICAL; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> PAUL P. WANG </ADVISER>
<CLASSIFICATIONS> NIL </CLASSIFICATIONS>
<ABSTRACT>
This thesis presents a design framework for intelligent
control based on fuzzy logic and constraint processing.
Although, to date, many fuzzy logic control systems have
been implemented in rule-based languages, we expect that
eventually these languages will be supplanted by
constraint-based languages.
Despite the successes which have flowed from the
applications of rule-based fuzzy logic control systems,
this paradigm offers only a small part of the expressive
competence of the first-order predicate calculus (FOPC).
In addition, because constraints represent the
requirements that the artifact being designed must
satisfy, the design can be viewed as exploring
alternatives in a solution space bounded by these
constraints. In consequence, constraints are suitable to
the task of modelling the controller in a dynamic
control system so that the output is governed to a
desired state as specified by the constraints. We study
the theoretical aspects of fuzzy constraint processing
and investigate the potential application of fuzzy
constraint network theory to control technology. We
found our hypothesis that fuzzy constraint network
constitute a suitable platform for the design and
implementation of both simple single agent and complex
multiple agent control systems.
In this thesis, the concept of "fuzzy constraints" in
problem solving is introduced and some basic definitions
of fuzzy constraint processing in a constraint network
and its semantic modeling are addressed. Then a fuzzy
local propagation inference mechanism for reasoning
about imprecise information applying the filter
operation in a network of constraints is proposed.
Moreover, we advance the concurrent fuzzy logic
controller (FLC) to a new type of controller, the fuzzy
constraint-based controller (FCC), using a more general
predicate calculus and full first-order logic knowledge
representation and making use of the idea of fuzzy
constraint processing to model practical dynamic control
systems. In addition, we expand the Single Agent FCC as
a benchmark for the implementation of Multiple Agent FCC
(MAFCC) for more complex systems. MAFCC in the system is
interactive, with human agent adaptively modifies the
constraints in the network subject to the outside
environment and different control objectives. The
utility of MAFCC system is illustrated by a complex
hydraulic control application.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  3191 </NUMBER>
<ORDER>   AAI9606354 </ORDER>
<TITLE> EVALUATIONS OF NEURAL NETWORK CONTROL IN GRINDING MILL CIRCUITS </TITLE>
<AUTHOR> CHO, CHONG SANG </AUTHOR>
<YEAR> 1995 </YEAR>
<INSTITUTION> UNIVERSITY OF IDAHO; 0089 </INSTITUTION>
<DESCRIPTORS> ENGINEERING, METALLURGY; ARTIFICIAL INTELLIGENCE; OPERATIONS RESEARCH </DESCRIPTORS>
<ADVISER> KEITH A. PRISBREY </ADVISER>
<CLASSIFICATIONS> NIL </CLASSIFICATIONS>
<ABSTRACT>
Raising costs have shifted the emphasis of industrial
plant operating polices from that of processing as much
feed as possible to one of minimizing energy consumed
per unit weight of metal produced. With the vast
tonnages of raw grade materials being refined,
comminution circuits for improving the control of this
operation become attractive. The complexity of the
grinding mill circuits results from feed disturbances
such as frequently changing ore hardness and feed ore
size distribution. The objective of improved control
strategies is the optimal operation of mineral plants
that reduces energy consumption, enhances throughput,
and optimizes specific output.
In spite of advanced control technologies, there have
been practical difficulties in applying these
technologies to industrial processes because of the lack
of adequate theoretical models. In the industrial
process, the major disturbances in grinding mill
circuits are variations in feed ore hardness, variations
in feed ore size distribution, and variations in tonnage
to be processed. The process is more susceptible to
variations of feed ore hardness the other two.
The initial work shows the use of artificial neural
networks for industrial mineral processing applications.
The applications studied are industrial data and
inferential model based grinding mill circuits. The
focus then shifts to dynamic grinding mill circuits with
optimal control (state space based control with LQG),
model predictive control, and artificial neural network
control. They are to demonstrate the breadth of
applicability of the proposed system identification
technique. A new method of control with artificial
neural networks is related to incorporate process
knowledge to the recurrent and back-propagation models.
Artificial neural networks are investigated in this
research as a means of filling the need for new,
accurate, multivariable, and nonlinear models. A novel
method for a general nonlinear model predictive control
scheme is laid out. The control strategies are in three
areas. First, a dynamic model and on-line measurements
are used to build a prediction of future output behavior
expressed in terms of current and future manipulated
input changes. Second, optimization is performed to find
a sequence of input changes that minimizes a chosen
measure of the output derivation from their respective
plant values while satisfying all the given constraints.
Third, the quality of prediction may improve as more
measurements are collected, only the first of the
calculated input sequence is implemented and the whole
optimization is repeated at the next sampling time.
Another important contribution is the incorporation of
population balance model.
Finally, the new method of control with artificial
neural networks where simplicity and speed are two
attractive features of the control scheme, make it a
promising method for solving mineral industrial control
problems.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  3192 </NUMBER>
<ORDER>   AAG1380689 </ORDER>
<TITLE> DISCRETIZING CONTINUOUS NEURAL NETWORKS USING A POLARIZATION LEARNING RULE </TITLE>
<AUTHOR> WANG, LIFENG </AUTHOR>
<YEAR> 1995 </YEAR>
<INSTITUTION> UTAH STATE UNIVERSITY; 0241 </INSTITUTION>
<DESCRIPTORS> COMPUTER SCIENCE; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> HENG-DA CHENG </ADVISER>
<CLASSIFICATIONS> NIL </CLASSIFICATIONS>
<ABSTRACT>
Neural networks using continuous activation functions
develop internal representations in a continuous space,
which is not desirable for certain applications dealing
only with discrete values. A common problem faced by
researchers is: unstable, infinite internal
representations (states) are developed in a continuous
space while finite, discrete states are desired. This
problem is especially important in the application of
grammatical inference using neural networks, which is
based on the assumption that during training, clusters,
representing the states of a Finite State Automaton
(FSA), will form in the state neuron activation space.
Since these clusters are in a continuous space, when
long test strings are presented, originally separate
clusters may drift, begin to merge, and eventually
become indistinguishable. When this happens, the test
string is misclassified. Existing approaches use various
clustering techniques and/or discretization methods,
which are not built in the training procedure seamlessly
and therefore suffer from various disadvantages.
This thesis presents a polarization learning rule, which
assumes the existence of a force pulling the activation
value of a neuron to the two poles of its activation
function. The polarization learning rule can be combined
with traditional error back-propagation learning without
compromising the theoretical foundation of the gradient
descent algorithm. The polarization learning rule can
also be applied to the second-order recurrent network to
solve the grammatical inference problem. By using the
polarization learning rule, no clustering algorithms are
needed after training because the state neuron
activations are already in an isolated, discrete space.
Extraction of a FSA from a trained network becomes a
straightforward procedure. For the Tomita grammars
studied in this thesis, the FSAs constructed from the
trained networks are, in most cases, the ideal FSAs of
the target grammars. This result is superior to the ones
using existing approaches.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  3193 </NUMBER>
<ORDER>   AAI9606277 </ORDER>
<TITLE> A CONCEPTUAL MODEL AND PROTOTYPE OF AN ADAPTIVE PRODUCTION CONTROL SYSTEM  </TITLE>
<AUTHOR> OTTAWAY, THOMAS ALLEN </AUTHOR>
<YEAR> 1995 </YEAR>
<INSTITUTION> TEXAS TECH UNIVERSITY; 0230 </INSTITUTION>
<DESCRIPTORS> ENGINEERING, SYSTEM SCIENCE; ENGINEERING, INDUSTRIAL; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> JAMES R. BURNS </ADVISER>
<CLASSIFICATIONS> AUTOMATED MANUFACTURING, COORDINATION STRUCTURE </CLASSIFICATIONS>
<ABSTRACT>
The rapidly increasing complexity of production
automation has prompted considerable interest in the
application of artificial intelligence (AI) to the
various components, e.g., controllers, machines,
workstations, cells, etc., that compose production
systems. As the intelligence of these components
increases, each component becomes capable of making
decisions that affect the overall performance of the
system. The integration and coordination of autonomous
decision-making components are fundamental research
issues in the design of intelligent production systems.
A critical factor affecting the integration and
coordination of autonomous decision-making components is
the coordination structure. Coordination structure
refers to the pattern of decision-making and
communication among a set of autonomous decision-making
components. Current intelligent production systems
research focuses on centralized versus decentralized
coordination structures. The centralized coordination
structures most often advocated are based on a
functional hierarchy. The decentralized coordination
structures are modeled after an economic marketplace.
Centralized and decentralized coordination structures
represent opposite ends of the continuum of coordination
structures. By focusing on opposite ends of the
continuum, researchers ignore the myriad of coordination
structures that lie between these extremes. This
dissertation presents a conceptual model and prototype
of an adaptive production control system capable of
traversing the continuum between centralized and
decentralized coordination structures.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  3194 </NUMBER>
<ORDER>   AAI9606276 </ORDER>
<TITLE> AN EMPIRICAL STUDY ON THE KNOWLEDGE ACQUISITION PROCESS FOR EXPERT SYSTEMS </TITLE>
<AUTHOR> KIRIS, ESIN OZAR </AUTHOR>
<YEAR> 1995 </YEAR>
<INSTITUTION> TEXAS TECH UNIVERSITY; 0230 </INSTITUTION>
<DESCRIPTORS> ENGINEERING, INDUSTRIAL; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> MICA R. ENDSLEY </ADVISER>
<CLASSIFICATIONS> NIL </CLASSIFICATIONS>
<ABSTRACT>
Expert systems, a form of artificial intelligence, are
computer programs that enhance the problem-solving and
decision-making performances of users. The power of
these systems is mostly dependent on the knowledge that
is extracted from the experts. This process of
extracting expertise is called knowledge acquisition.
The objective of the research was to determine how the
knowledge source (domain expert), task features
(domain), knowledge engineer (expert system developer)
and knowledge acquisition technique affect the effort
needed to develop a knowledge base, the time spent to
develop a knowledge base and the quality of the elicited
knowledge base. Nine librarians, six pilots (experts)
and nine graduate university students (knowledge
engineers) served as subjects in this study. Two types
of domains were investigated: (1) an aircraft flight
maneuver task and (2) a librarian material selection
task. In the experiment, each person serving as an
expert participated in the study using all three
techniques: (1) interview, (2) verbal protocol and (3)
concept mapping with three different knowledge
engineers. Results of ANOVAs showed a significant effect
of task type only for the completeness measurement and
not for all other measurements. In addition, results of
ANOVAs showed that the quality of the knowledge base was
more dependent on the knowledge engineer's personal
characteristics and performance than a selected
knowledge acquisition technique. However, the time spent
on both knowledge elicitation and knowledge analysis is
dependent on the knowledge acquisition technique. The
verbal protocol technique shortened the time spent on
knowledge elicitation, whereas the concept mapping
technique shortened the time spent on analysis. From the
point of a knowledge engineer, it could be concluded
that the concept mapping technique is the most efficient
and requires the least effort spent. On the other hand,
domain experts were split, with the librarians viewing
the concept mapping technique as the most efficient and
the pilots viewing the verbal protocol technique as the
most efficient technique. Although there were not any
quality or time differences using the different
techniques, the concept mapping technique is recommended
based on this study, as compared to both the interview
and verbal protocol techniques as a means of reducing
the knowledge engineer's workload.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  3195 </NUMBER>
<ORDER>   AAI9606167 </ORDER>
<TITLE> ADAPTIVE IMPEDANCE CONTROL </TITLE>
<AUTHOR> LOVE, LONNIE JOE </AUTHOR>
<YEAR> 1995 </YEAR>
<INSTITUTION> GEORGIA INSTITUTE OF TECHNOLOGY; 0078 </INSTITUTION>
<DESCRIPTORS> ENGINEERING, MECHANICAL; ENGINEERING, ELECTRONICS AND ELECTRICAL; ARTIFICIAL INTELLIGENCE; COMPUTER SCIENCE </DESCRIPTORS>
<ADVISER> WAYNE BOOK </ADVISER>
<CLASSIFICATIONS> ROBOTICS, TELEFACTORS, ENVIRONMENT ESTIMATION, CONTACT STABILITY, VIRTUAL REALITY </CLASSIFICATIONS>
<ABSTRACT>
The objective of this research is to establish a method
of controlling a robot that operates in an unstructured
environment. This requires three fundamental objectives.
First, the robot must be capable of constrained, as well
as unconstrained manipulation. Second, the robot must be
capable of learning not only where obstacles are in its
workspace, but the characteristics of those obstacles as
well. Finally, the robot must be capable of learning the
characteristic of its environment without explicitly
modifying its task definition.
To achieve these goals, a new approach to robotic
environment estimation is described. First, a
discretized model of a robot's workspace provides for
spatial and temporal variations in the environment. This
operates in concert with a multiple input, multiple
output recursive estimation algorithm. As the robot
maneuvers about its workspace, measured tip force and
position information provide the estimation routine
states necessary for the identification of environment
impedance. The updated parameters of the estimated
environment impedance are stored in the robot's position
dependent discretized workspace. As the robot learns the
characteristics of its environment, the target impedance
of the robot's controller adapts to this estimate based
upon a specified performance criterion. The author
describes five different methods to extract the
estimated environment information and adapt the target
impedance of the robot. Three techniques provide
predictive behavior that enables adaptation prior to
contact with the environment. This reduces the magnitude
of contact forces generated during impact. In addition,
two techniques provide robust initialization that ensure
stability when operating in uncertain environments.
Finally, the methods developed for robotic tasks are
extended to a novel teleoperation platform. A new
approach to force reflecting teleoperation of long reach
flexible robots is described. The environment estimation
method is employed for the estimation of a remote
environment manipulated by a slave robot. The target
impedance of the master robot, coupled to a human,
adapts to variations in the remote environment. This
ensures safe telemanipulation in hazardous or uncertain
environments. Furthermore, the adaptive impedance
controller is augmented with virtual fixtures to provide
teleoperated obstacle avoidance.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  3196 </NUMBER>
<ORDER>   AAI9538013 </ORDER>
<TITLE> LEARNING FROM INSTRUCTION AND EXPERIENCE: METHODS FOR INCORPORATING PROCEDURAL DOMAIN THEORIES INTO KNOWLEDGE- BASED NEURAL NETWORKS  </TITLE>
<AUTHOR> MACLIN, RICHARD FRANK </AUTHOR>
<YEAR> 1995 </YEAR>
<INSTITUTION> THE UNIVERSITY OF WISCONSIN - MADISON; 0262 </INSTITUTION>
<DESCRIPTORS> COMPUTER SCIENCE; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> JUDE WILLIAM SHAVLIK </ADVISER>
<CLASSIFICATIONS> MACHINE LEARNING </CLASSIFICATIONS>
<ABSTRACT>
This thesis defines and evaluates two systems that allow
a teacher to provide instructions to a machine learner.
My systems, FS scKBANN and scRATLE, expand the language
that a teacher may use to provide advice to the learner.
In particular, my techniques allow a teacher to give
partially correct instructions about procedural tasks--
tasks that are solved as sequences of steps. FS scKBANN
and scRATLE allow a computer to learn both from
instruction and from experience. Experiments with these
systems on several testbeds demonstrate that they
produce learners that successfully use and refine the
instructions they are given.
In my initial approach, FS scKBANN, the teacher provides
instructions as a set of propositional rules organized
around one or more finite-state automata (FSAs). FS
scKBANN maps the knowledge in the rules and FSAs into a
recurrent neural network. I used FS scKBANN to refine
the Chou-Fasman algorithm, a method for solving the
secondary-structure prediction problem, a difficult task
in molecular biology. FS scKBANN produces a refined
algorithm that outperforms the original (non-learning)
Chou-Fasman algorithm, as well as a standard neural-
network approach.
My second system, scRATLE, allows a teacher to
communicate advice, using statements in a simple
programming language, to a connectionist, reinforcement-
learning agent. The teacher indicates conditions of the
environment and actions the agent should take under
those conditions. scRATLE allows the teacher to give
advice continuously by translating the teacher's
statements into additions to the agent's neural network.
The scRATLE language also includes novel (to the theory-
refinement literature) features such as multi-step plans
and looping constructs. In experiments with scRATLE on
two simulated testbeds involving multiple agents, I
demonstrate that a scRATLE agent receiving advice
outperforms both an agent that does not receive advice
and an agent that receives instruction, but does not
refine it.
My methods provide an appealing approach for learning
from both instruction and experience in procedural
tasks. This work widens the "information pipeline"
between humans and machine learners, without requiring
that the human provide absolutely correct information to
the learner.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  3197 </NUMBER>
<ORDER>   AAI0576636 </ORDER>
<TITLE> PROGRESSIVE LEARNING AND ITS APPLICATION TO ROBOTIC ASSEMBLY </TITLE>
<AUTHOR> YANG, BOO-HO </AUTHOR>
<YEAR> 1995 </YEAR>
<INSTITUTION> MASSACHUSETTS INSTITUTE OF TECHNOLOGY; 0753 </INSTITUTION>
<DESCRIPTORS> ENGINEERING, MECHANICAL; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> HARUHIKO ASADA </ADVISER>
<CLASSIFICATIONS> NIL </CLASSIFICATIONS>
<ABSTRACT>
Human learning is by far more effective than machine
learning in many ways. Humans use a curriculum, an
organized set of materials to be learned in a particular
sequence. Inspired by this human learning, we have
developed a new method of machine learning by designing
a series of input tasks, referred to as "curriculum," so
that machine learning can be performed smoothly, quickly
and stably without incurring fatal mistakes. The new
method, termed "Progressive Learning," uses scheduled
excitation inputs that allow the system to learn quasi-
static, slow modes in the beginning, followed by the
learning of faster modes. We first present a theory of
progressive learning by formulating a gradient based,
model reference adaptive control problem. It is well
known that in a model reference adaptive control system
an excitation at a high frequency causes instability to
the system when the relative order of the plant is high
and the SPR (strictly positive real) condition is not
met. To derive a stability analysis for progressive
learning, we apply a method of averaging analysis to
describe the behavior of the adaptive system in the
frequency domain. Based on this analysis, we prove that
the stable convergence of control parameters is
guaranteed if the system is excited gradually through
the reference input in accordance to the progress of the
adaptation. A numerical example is provided to verify
the above analysis. The concept of progressive learning
is next applied to robotic assembly to explore the
possibility of progressive learning. A high speed
insertion task is used as an example, where an impedance
control law is learned with the excitation scheduling
method. In this method, learning starts with a slow,
quasi-static motion and goes to a fast, dynamic motion.
During the learning process, the stiffness of the
impedance controller are learned first, followed by the
damping terms and finally by the inertial terms.
Consequently, this progressive learning method enables
the learning of high-speed dynamic control laws without
instability and fatal damage due to high speed
collisions. The mechanism of progressive learning is
also discussed in detail and verified through simulation
experiments.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  3198 </NUMBER>
<ORDER>   AAINN01437 </ORDER>
<TITLE> HANDWRITTEN NUMERAL RECOGNITION WITH NEURAL NETWORKS AND FUZZY FUSION </TITLE>
<AUTHOR> CAO, JUN </AUTHOR>
<YEAR> 1995 </YEAR>
<INSTITUTION> UNIVERSITY OF WINDSOR (CANADA); 0115 </INSTITUTION>
<DESCRIPTORS> COMPUTER SCIENCE; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> M. SHRIDHAR; M. AHMADI </ADVISER>
<CLASSIFICATIONS> NIL </CLASSIFICATIONS>
<ABSTRACT>
The principal goal of this dissertation is to present
several techniques for improving the performance of the
handwritten numeral recognition system. There were two
major tasks in this work. The first was to develop
neural network approaches for improving the performance
of classification. The second was to develop efficient
fusion techniques for combining different classifiers.
Apart from these major tasks, several feature extraction
methods have been modified and some new features have
been developed.
By using a principal component analysis, a Bayes
incremental learning neural network has been developed.
This network is able to learn the data clusters as well
as discriminants at a high speed.
A multistage neural network architecture has been
developed based on decomposition and localization
strategy where different neural networks are used in
different stages to perform different classification
tasks.
An evidence fusion technique based on the notion of
fuzzy integral is utilized to combine classifiers. An
algorithm for the dynamic assignment of source relevance
is developed. By using the performance of each
classifier on each class as well as the confusion
information among classes, this algorithm effectively
removes the discord error cases generated by individual
classifiers.
Experiments on handwritten numeral recognition are
described. They show that multistage neural networks can
generate a high recognition rate. These experiments also
show that very low error rates with low rejection rates
can be achieved by fusing several low performance
classifiers.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  3199 </NUMBER>
<ORDER>   AAINN01436 </ORDER>
<TITLE> FUZZY INFERENCE NETWORKS FOR PATTERN RECOGNITION </TITLE>
<AUTHOR> CAI, YALING </AUTHOR>
<YEAR> 1995 </YEAR>
<INSTITUTION> UNIVERSITY OF WINDSOR (CANADA); 0115 </INSTITUTION>
<DESCRIPTORS> ENGINEERING, ELECTRONICS AND ELECTRICAL; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> H. K. KWAN </ADVISER>
<CLASSIFICATIONS> NEURAL NETWORKS </CLASSIFICATIONS>
<ABSTRACT>
This dissertation presents a study of fuzzy inference
networks for pattern recognition problems. In this
research, fuzzy neurons are defined and five types of
fuzzy neurons are introduced. Three fuzzy inference
models for pattern recognition systems, min-max
inference model, min-sum inference model, and min-
competitive inference model, are developed. Fuzzy
inference networks based on the inference models and
their learning algorithms are presented. The proposed
fuzzy inference networks can learn fuzzy inference rules
directly from training data. Two of the proposed fuzzy
inference networks, Min-Max Fuzzy Inference Network and
Min-Sum Fuzzy Inference Network, are applied to pattern
classification problems. These two networks can learn
the membership functions of all the classes and find out
the soft and hard partitions according to the membership
values. Another two fuzzy inference networks based on a
min-competitive inference method are developed for
invariant pattern recognition systems. These two Min-
Competitive Fuzzy Inference Networks have been
constructed for 2-D visual pattern recognition problems
and have been tested with letter patterns with black and
white pixel values. The learning speed of the proposed
fuzzy inference networks is very fast. The structures of
the proposed fuzzy inference networks are simple and
they perform well when used in pattern classification
and pattern recognition problems.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  3200 </NUMBER>
<ORDER>   AAINN00653 </ORDER>
<TITLE> TECHNIQUES IN POTENTIAL-BASED PATH PLANNING </TITLE>
<AUTHOR> MASOUD, AHMAD A. </AUTHOR>
<YEAR> 1995 </YEAR>
<INSTITUTION> QUEEN'S UNIVERSITY AT KINGSTON (CANADA); 0283 </INSTITUTION>
<DESCRIPTORS> ENGINEERING, ELECTRONICS AND ELECTRICAL; TRANSPORTATION; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> NIL </ADVISER>
<CLASSIFICATIONS> AUTONOMOUS NAVIGATION </CLASSIFICATIONS>
<ABSTRACT>
This thesis examines the ability of an agent to move
from one point to another, or in a more abstract sense,
its ability, once presented with a situation, to affect
its immediate environment with a sequence of actions
that is carefully designed so that the reaction of the
environment carries it to the goal. An approach, based
on artificial potential fields, is investigated for
generating such a capability. This approach is in turn
used as a framework to generate different navigation
techniques, each of which is geared towards a certain
application. It is shown that the potential approach
provides an efficient means for building path planners
that, among other things, can be easily integrated in an
autonomous navigation system.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  3201 </NUMBER>
<ORDER>   AAI1376896 </ORDER>
<TITLE> OBJECT RECOGNITION BY GENETIC ALGORITHM </TITLE>
<AUTHOR> LI, JIANHUA </AUTHOR>
<YEAR> 1995 </YEAR>
<INSTITUTION> FLORIDA ATLANTIC UNIVERSITY; 0119 </INSTITUTION>
<DESCRIPTORS> ENGINEERING, ELECTRONICS AND ELECTRICAL; ENGINEERING, MECHANICAL; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> CHINGPING HAN; HANQI ZHUANG </ADVISER>
<CLASSIFICATIONS> NIL </CLASSIFICATIONS>
<ABSTRACT>
Vision systems have been widely used for parts
inspection in electronics assembly lines. In order to
improve the overall performance of a visual inspection
system, it is important to employ an efficient object
recognition algorithm.
In this thesis work, a genetic algorithm based
correlation algorithm is designed for the task of visual
electronic parts inspection. The proposed procedure is
composed of two stages. In the first stage, a genetic
algorithm is devised to find a sufficient number of
candidate image windows. For each candidate window, the
correlation is performed between the sampled template
and the image pattern inside the window. In the second
stage, local searches are conducted in the neighborhood
of these candidate windows. Among all the searched
locations, the one that has a highest correlation value
with the given template is selected as the best matched
location. To apply the genetic algorithm technique, a
number of important issues, such as selection of a
fitness function, design of a coding scheme, and tuning
of genetic parameters are addressed in the thesis.
Experimental studies have confirmed that the proposed GA-
based correlation method is much more effective in terms
of accuracy and speed in locating the desired object,
compared with the existing Monte-Carlo random search
method.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  3202 </NUMBER>
<ORDER>   AAI1376852 </ORDER>
<TITLE> TRAINING THE NEURAL NETWORK USING FAST ADAPTIVE BACKPROPAGATION ALGORITHM WITH CORRUPTED TRAINING SET </TITLE>
<AUTHOR> GAUTAM, SANJEEV SINGH </AUTHOR>
<YEAR> 1995 </YEAR>
<INSTITUTION> TEXAS A&M UNIVERSITY-KINGSVILLE; 1187 </INSTITUTION>
<DESCRIPTORS> COMPUTER SCIENCE; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> CHUNG S. LEUNG </ADVISER>
<CLASSIFICATIONS> NIL </CLASSIFICATIONS>
<ABSTRACT>
In pattern recognition, there is a major drawback in
using neural networks under supervised learning. If the
test pattern is not identical with one of the trained
patterns in the training set, the outcome is
unpredictable. Thus a perfect classification of ideal
input vectors and a reasonably accurate classification
of noise vectors are both required. In order to create a
network that can handle noisy vectors, it has to be
trained with both ideal and noisy vectors. In this
research, a feed forward network is trained with an
adaptive fast backpropagation algorithm to recognize
noisy patterns with high accuracy. It eliminates the
painstaking and time consuming process of finding the
optimum learning rate and the selection of a perfect
training set.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  3203 </NUMBER>
<ORDER>   AAG1380638 </ORDER>
<TITLE> PREDICTION OF ARCHEOLOGICAL SITES BY ARTIFICIAL NEURAL NETWORKS </TITLE>
<AUTHOR> DESAI, RUTVIK HARSHAD </AUTHOR>
<YEAR> 1995 </YEAR>
<INSTITUTION> UTAH STATE UNIVERSITY; 0241 </INSTITUTION>
<DESCRIPTORS> COMPUTER SCIENCE; ANTHROPOLOGY, ARCHAEOLOGY; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> DONALD COOLEY </ADVISER>
<CLASSIFICATIONS> NIL </CLASSIFICATIONS>
<ABSTRACT>
Archeological sites are a valuable source of information
about our past. Numerous locations containing
archeological artifacts like remains or pottery, houses,
villages, etc. have been found in the country. To a
large extent, the process of finding such locations is a
trial-and-error affair. This work attempts to identify
the attributes or features of the landscape where
archeological sites have been found, and use them to
predict the probability of finding archeological
information at a given location. Biologically inspired
computational paradigms known as artificial neural
networks (ANNs) have been used for this purpose.
Geographic and mathematically extracted features of the
landscape are input into an ANN, which attempts to find
a relationship between values of features for a
particular location and existence or nonexistence of
archeological information at that location. To select
the features that are relevant to finding this
relationship, a stochastic optimization method known as
simulated annealing (SA) is utilized. SA searches the
space of various feature subsets to find the optimum
subset of features, where the evaluation of a feature
subset is provided by a nearest-neighbor classifier.
Results indicate that ANNs can be successfully applied
to predict the locations of archeological sites, with a
reasonable degree of accuracy. Feature selection does
not significantly improve the accuracy of prediction,
although it enables the neural network to be more
consistent in its predictions and to use less training
time.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  3204 </NUMBER>
<ORDER>   AAI1376847 </ORDER>
<TITLE> THE CONFOUNDING OF BACKPROPAGATION NEURAL NETWORKS IN CHEMICAL ENGINEERING APPLICATIONS </TITLE>
<AUTHOR> DOPPELT, ALAN ELLIOT </AUTHOR>
<YEAR> 1995 </YEAR>
<INSTITUTION> TEXAS A&M UNIVERSITY-KINGSVILLE; 1187 </INSTITUTION>
<DESCRIPTORS> ENGINEERING, CHEMICAL; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> WILLIAM HEENAN </ADVISER>
<CLASSIFICATIONS> NIL </CLASSIFICATIONS>
<ABSTRACT>
Process units are being modeled in industry by
artificial neural networks. These programs do not
require a knowledge of first principles or process
dynamics. Many attempts to use neural networks for
modeling have been unsuccessful due to confounding. This
thesis is an attempt to quantify the reasons for
confounding by determining the signal to noise ratio
that could be tolerated by the net for a given
sensitivity and determining what accuracy and what
percent of time a gross error could be tolerated by the
net for a given sensitivity.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  3205 </NUMBER>
<ORDER>   AAI1376650 </ORDER>
<TITLE> STOCK MARKET VALUATION THE NEURAL NETWORK WAY </TITLE>
<AUTHOR> ZHUO, JIAYIN </AUTHOR>
<YEAR> 1995 </YEAR>
<INSTITUTION> UNIVERSITY OF NEVADA, RENO; 0139 </INSTITUTION>
<DESCRIPTORS> COMPUTER SCIENCE; ARTIFICIAL INTELLIGENCE; ECONOMICS, FINANCE </DESCRIPTORS>
<ADVISER> CARL G. LOONEY </ADVISER>
<CLASSIFICATIONS> NIL </CLASSIFICATIONS>
<ABSTRACT>
We present a new method on market timing series,
inspired by the neural network (NN), an Artificial
Intelligence method. The neural network imitates the
brain's learning mechanism, teaches itself the
relationship between input and output, and performs
complex inductive reasoning. Our goal is to use NN to
allocate investment funds between stocks and money
market securities. We exhibit the method in the context
of multivariate time series prediction on financial data
from the New York Stock Exchange. We use the cubic
random strategy method to search weights in a 4 layer
network and learn rules in large data samples. The
variation, incidentally, is significantly large due to
different network conditions (such as architecture and
initial weights). We also use the cross-validation
method to determine quality and reliability of a neural
network predictor. We demonstrate this on a strictly
held-out test set that includes the 1987 stock market
crash. The total prediction results are quite successful
and satisfactory.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  3206 </NUMBER>
<ORDER>   AAI1376539 </ORDER>
<TITLE> FAULT TOLERANT CHARACTERISTICS OF ARTIFICIAL NEURAL NETWORK ELECTRONIC HARDWARE </TITLE>
<AUTHOR> ZEE, FRANK C. </AUTHOR>
<YEAR> 1995 </YEAR>
<INSTITUTION> UNIVERSITY OF SOUTHERN CALIFORNIA; 0208 </INSTITUTION>
<DESCRIPTORS> ENGINEERING, BIOMEDICAL; ENGINEERING, ELECTRONICS AND ELECTRICAL; PHYSICS, RADIATION; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> THEODORE BERGER </ADVISER>
<CLASSIFICATIONS> NIL </CLASSIFICATIONS>
<ABSTRACT>
The fault tolerant characteristics of analog-VLSI
artificial neural network (with 32 neurons and 532
synapses) chips are studied by exposing them to high
energy electrons, high energy protons, and gamma
ionizing radiations under biased and unbiased
conditions. The biased chips became nonfunctional after
receiving a cumulative dose of less than 20 krads, while
the unbiased chips only started to show degradation with
a cumulative dose of over 100 krads. As the total
radiation dose increased, all the components
demonstrated graceful degradation. The analog sigmoidal
function of the neuron became steeper (increase in
gain), current leakage from the synapses progressively
shifted the sigmoidal curve, and the digital memory of
the synapses and the memory addressing circuits began to
gradually fail. From these radiation experiments, we can
learn how to modify certain designs of the neural
network electronic hardware without using radiation-
hardening techniques to increase its reliability and
fault tolerance.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  3207 </NUMBER>
<ORDER>   AAI1376509 </ORDER>
<TITLE> CROSS-CORRELATION METHODS FOR QUANTIFICATION OF NONLINEAR INPUT-OUTPUT TRANSFORMATIONS OF NEURAL SYSTEMS USING A POISSON RANDOM TEST INPUT </TITLE>
<AUTHOR> SCARINGE, WILLIAM ANTHONY </AUTHOR>
<YEAR> 1995 </YEAR>
<INSTITUTION> UNIVERSITY OF SOUTHERN CALIFORNIA; 0208 </INSTITUTION>
<DESCRIPTORS> ENGINEERING, BIOMEDICAL; COMPUTER SCIENCE; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> TED BERGER </ADVISER>
<CLASSIFICATIONS> NIL </CLASSIFICATIONS>
<ABSTRACT>
We show that input-output cross-correlation can identify
the nonlinear input-output transformation of a system by
estimating the kernels of the Discrete Volterra Series
(DVS). The DVS kernels have a simple interpretation and
provide a useful characterization of the system
nonlinearities. We present two complementary methods for
computing the DVS kernels. The first method uses the
formula for the Discrete Poisson Orthogonal Series
(DPOS) kernels. We derive the DPOS by orthogonalizing
the DVS for the Poisson Random Event Sequence (PRES)
test input. Although we show that the DPOS kernels
contain components involving all the DVS kernels, we
also show that we can isolate a single DVS kernel if at
least one of three conditions is satisfied. The second
method is a general method that involves solving a set
of simultaneous linear equations to isolate each DVS
kernel from other system nonlinearities. We use
simulations to demonstrate our theoretical results.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  3208 </NUMBER>
<ORDER>   AAI1376380 </ORDER>
<TITLE> THE DESIGN AND IMPLEMENTATION OF AN INTELLIGENT INTERFACE AND ENVIRONMENT FOR A REENGINEERING DECISION SUPPORT FRAMEWORK </TITLE>
<AUTHOR> DUNN, JEFFREY WAYNE </AUTHOR>
<YEAR> 1995 </YEAR>
<INSTITUTION> UNIVERSITY OF LOUISVILLE; 0110 </INSTITUTION>
<DESCRIPTORS> COMPUTER SCIENCE; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> NIL </ADVISER>
<CLASSIFICATIONS> NIL </CLASSIFICATIONS>
<ABSTRACT>
This thesis describes the design and implementation of a
decision support framework for a computer based
reengineering facility. The application and
implementation is named Emulation Simulation Maintenance
Facility (ESMF) as it is intended to support the tasks
of emulation, simulation and maintenance in
reengineering. The software uses a blackboard type
architecture to organize information and knowledge
sources used to develop prototypes. The goal of ESMF is
to intelligently guide the user through a rapid
prototyping process of redefining complex systems. The
complex systems evaluated are broken down into
manageable component modules. These component modules
are then configured into a modular testbed to represent
the complex system. The modular testbed is used by ESMF
to represent the platform for simulation and emulation
set-up. This facility also provides the user with
varying degrees of intelligent assistance throughout the
design and evaluation phases of system rapid
prototyping. Intelligent assistance is provided by a
CLIPS based expert system.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  3209 </NUMBER>
<ORDER>   AAI1376360 </ORDER>
<TITLE> LOW POWER ANALOG CHIPS FOR THE COMPUTATION OF THE MAXIMAL PRINCIPAL COMPONENT </TITLE>
<AUTHOR> VEDULA, SHANTI SWARUP </AUTHOR>
<YEAR> 1995 </YEAR>
<INSTITUTION> MICHIGAN STATE UNIVERSITY; 0128 </INSTITUTION>
<DESCRIPTORS> ENGINEERING, ELECTRONICS AND ELECTRICAL; COMPUTER SCIENCE; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> NIL </ADVISER>
<CLASSIFICATIONS> NIL </CLASSIFICATIONS>
<ABSTRACT>
The eigenvector projection method, also called the
principal component analysis (PCA) approach, is a
popular linear projection algorithm used in unsupervised
processing. This method involves computation of
covariance matrix of the input patterns, its eigenvalues
and eigenvectors. A number of neural network models have
been proposed which compute the eigenvectors directly
without computing the covariance matrix and the
eigenvalues. The neural network 'learns' on its own,
based on the input patterns presented, and after
'learning', the parameters (weights) of the network
specify the eigenvectors. This work focuses on the
implementation of a compact, modular, low power,
subthreshold analog VLSI circuit for computing the
maximal principal component based on a new analog VLSI
non-linear model. The model uses MOS elements and
differential pairs operating in the subthreshold regime
of MOS operation. The model for computing the principal
component has been simulated (using MATLAB and PSpice)
and implemented up to six dimensions on tiny prototype
chips fabricated via the MOSIS service.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  3210 </NUMBER>
<ORDER>   AAI1376097 </ORDER>
<TITLE> A HYBRID ROAD IDENTIFICATION SYSTEM USING IMAGE PROCESSING TECHNIQUE AND BACK-PROPAGATION NEURAL NETWORKS </TITLE>
<AUTHOR> KO, KUO-TU </AUTHOR>
<YEAR> 1995 </YEAR>
<INSTITUTION> MISSISSIPPI STATE UNIVERSITY; 0132 </INSTITUTION>
<DESCRIPTORS> COMPUTER SCIENCE; REMOTE SENSING; TRANSPORTATION; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> GENE BOGGESS </ADVISER>
<CLASSIFICATIONS> NIL </CLASSIFICATIONS>
<ABSTRACT>
Road identification of remotely sensed satellite images
has been used for many different purposes, e.g.,
military planning, map publishing, census, etc. In this
paper, a method which combines traditional image
processing techniques with backpropagation neural
networks to detect roads in a Landsat TM satellite image
is presented.
The Landsat image is first processed to extract all the
line features which are road candidates, then the
supervised neural network is employed to determine
whether a candidate road pixel is really a road pixel or
not according to its spectral characteristics.
Furthermore, some postprocessing steps are taken to
refine the result. The resultant image showed that this
hybrid identification system performs better than using
only image processing techniques or only neural network
techniques.
If a particular kind of road (i.e., interstate, urban
area road, bridge, etc.) is of interest, then a
specialist neural network road detector can be
constructed; this is also discussed briefly in this
paper.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  3211 </NUMBER>
<ORDER>   AAIMM99759 </ORDER>
<TITLE> NEURAL NETWORK AND LINEAR PREDICTION FOR UNDERWATER SIGNAL ESTIMATION </TITLE>
<AUTHOR> LI, JIAN </AUTHOR>
<YEAR> 1995 </YEAR>
<INSTITUTION> TECHNICAL UNIVERSITY OF NOVA SCOTIA (CANADA); 0300 </INSTITUTION>
<DESCRIPTORS> ENGINEERING, ELECTRONICS AND ELECTRICAL; ENGINEERING, HYDRAULIC; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> M. EL-HAWARY </ADVISER>
<CLASSIFICATIONS> NIL </CLASSIFICATIONS>
<ABSTRACT>
This thesis proposes an artificial neural network
approach to filter additive noise in the time-domain. A
back-propagation algorithm is applied and a delta
learning rule is employed to update the weights during
the training. Signal estimation is tested by a feed-
forward neural network after training. The test signals
consist of a sinusoid with different levels of white
noise in order to evaluate the overall performance of
the network. In addition, the performance of the neural
network is compared with that of an AR filter.
Preliminary test results show acceptable performance.
The application of the ANN to underwater target tracking
is reported. The neural tracker is trained using ideal
data and tested for three different levels of noisy data
sets. The performance of the neural tracker is very
significant. Noise levels are highly reduced by the
neural tracker. Also, it is very efficient in real-time
tracking since only simple computations are involved
with computationally intensive training done off-line.
Finally, conclusions and ideas for future work are
given. The main point being considered is to enable a
neural filter or tracker to achieve a better
performance.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  3212 </NUMBER>
<ORDER>   AAIMM99182 </ORDER>
<TITLE> A SYMBOLIC ASSOCIATIVE MEMORY MODEL </TITLE>
<AUTHOR> ASTLE, MARY JOYCE </AUTHOR>
<YEAR> 1995 </YEAR>
<INSTITUTION> THE UNIVERSITY OF WESTERN ONTARIO (CANADA); 0784 </INSTITUTION>
<DESCRIPTORS> COMPUTER SCIENCE; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> CHARLES LING </ADVISER>
<CLASSIFICATIONS> NIL </CLASSIFICATIONS>
<ABSTRACT>
Artificial intelligence simulates human mental faculties
with the hope of understanding and utilizing the
powerful methodology of the brain. Current theory in
neurobiology suggests an associative PDP (parallel
distributed processing) model for simulating human
memory. PDP models designed specifically to store and
recall a set of patterns are called auto-associators.
Auto-associator models are traditionally created with
neural networks which allow only numeric values,
requiring patterns to be encoded and decoded. This
thesis presents a Symbolic Associative Memory Model
(SAMM) composed of a set of interconnected decision
trees constructed with Quinlan's scC4.5 inductive
inference algorithm and processed in parallel. SAMM is
tested with several different pattern sets for
correctness, accuracy, capacity, stability and speed.
Freed from the restrictions of neural networks, SAMM
enables the symbolic representation of patterns,
improving ease of use as well as providing full-
capacity, reliability, greater stability and faster
recall speed.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  3213 </NUMBER>
<ORDER>   AAG1380614 </ORDER>
<TITLE> TRANSIENT STABILITY ASSESSMENT USING ARTIFICIAL NEURAL NETWORKS </TITLE>
<AUTHOR> AL-SHAMS, ABDUL-AZIZ MOHAMMED </AUTHOR>
<YEAR> 1995 </YEAR>
<INSTITUTION> KING FAHD UNIVERSITY OF PETROLEUM AND MINERALS (SAUDI ARABIA); 1088 </INSTITUTION>
<DESCRIPTORS> ENGINEERING, ELECTRONICS AND ELECTRICAL; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> NIL </ADVISER>
<CLASSIFICATIONS> NIL </CLASSIFICATIONS>
<ABSTRACT>
This thesis presents a study of the feasibility of using
Artificial Neural Networks for Transient Stability
Assessment of power systems. In this research,
Artificial Neural Networks have been developed to
synthesize the complex mappings that carry the power
system's operating variables and faults locations into
the Critical Fault Clearing Times. Training of the
Artificial Neural Networks has been achieved through the
method of backpropagation. The Critical Fault Clearing
Time values are obtained by the Extended Equal Area
Criterion method and are used for training. In this
work, an attempt was made to avoid the restrictions on
load and topology variations. The results obtained are
in general agreement with those reported recently by
other researchers.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  3214 </NUMBER>
<ORDER>   AAIMM02061 </ORDER>
<TITLE> A MOBILE ROBOT THAT LEARNS TO ESTIMATE ITS POSITION FROM A STREAM OF SONAR MEASUREMENTS </TITLE>
<AUTHOR> OORE, SAGEEV </AUTHOR>
<YEAR> 1995 </YEAR>
<INSTITUTION> UNIVERSITY OF TORONTO (CANADA); 0779 </INSTITUTION>
<DESCRIPTORS> COMPUTER SCIENCE; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> GEOFFREY HINTON </ADVISER>
<CLASSIFICATIONS> NIL </CLASSIFICATIONS>
<ABSTRACT>
Consider a robot with noisy motion sensors and noisy
sonar sensors. By combining the sensory measurements
within a Bayesian framework, we can use the motion
information to provide a consistency constraint over the
position estimates through time, yielding filtered
probability distributions over position which are better
than the distributions that can be achieved by either
sonar or motion sensing alone.
We assume the robot starts with an inaccurate sonar
model of its environment that maps from a position to a
probability distribution over sonar measurements. This
model is implemented by a neural net using radial basis
functions. The filtered probability distributions over
position obtained by combining the inaccurate sonar
model with the noisy motion can then be used to improve
the sonar model. On simulated sonar data, this process
converges to an accurate sonar model of the environment
even when the initial model is random and the robot is
only told its initial position.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  3215 </NUMBER>
<ORDER>   AAIMM01914 </ORDER>
<TITLE> NEURAL NETWORK BASED INCIPIENT FAULT DETECTION OF INDUCTION MOTORS </TITLE>
<AUTHOR> ROKONUZZAMAN, MOHD </AUTHOR>
<YEAR> 1995 </YEAR>
<INSTITUTION> MEMORIAL UNIVERSITY OF NEWFOUNDLAND (CANADA); 0306 </INSTITUTION>
<DESCRIPTORS> ENGINEERING, MECHANICAL; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> M. A. RAHMAN </ADVISER>
<CLASSIFICATIONS> NIL </CLASSIFICATIONS>
<ABSTRACT>
An incipient fault detection scheme of induction motors
through the recognition of frequency spectra of the
stator current has been developed in this thesis. It is
based on the adaptive resonance theory of neural
networks. This fault diagnosis scheme is not only
capable of detecting a fault but also can report if it
cannot identify a particular fault so that necessary
preventive steps can be taken to update the underlying
neural network to adapt to this undetected fault.
Moreover, it can update itself to cope with this dynamic
situation retaining already acquired knowledge without
the need of retraining with the old patterns.
A laboratory experimental set-up using a digital signal
processing (DSP) technique has been employed to collect
the frequency spectra of the stator current at different
fault conditions. A wound-rotor induction motor has been
used as the test motor to create different types of
faults making unbalance in the stator and rotor
circuits. A 24-bit high speed DSP board has been used
with a personal computer to develop a real-time
interactive software to collect the spectra. A driver
for the HP-plotter has also been developed to directly
plot the frequency spectra of the stator current.
Adaptive resonance theory (ART) based network is a
recent addition to the neural network family. A new
software has been successfully developed and implemented
in the laboratory experiment using ART neural network.
Its performances in training, recalling and dynamic
updating have been studied with a set of example
patterns. The incipient faults of a 3-phase wound rotor
induction motor have been successfully diagonized by
this neural network.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  3216 </NUMBER>
<ORDER>   AAIMM01668 </ORDER>
<TITLE> APPLICATION OF ARTIFICIAL INTELLIGENCE TO IMPROVE PULP MILL OPERATIONS  </TITLE>
<AUTHOR> ZURCHER, ULRICH JAMES </AUTHOR>
<YEAR> 1995 </YEAR>
<INSTITUTION> UNIVERSITY OF ALBERTA (CANADA); 0351 </INSTITUTION>
<DESCRIPTORS> ENGINEERING, INDUSTRIAL; ARTIFICIAL INTELLIGENCE; BUSINESS ADMINISTRATION, MANAGEMENT; AGRICULTURE, WOOD TECHNOLOGY </DESCRIPTORS>
<ADVISER> M. RAO </ADVISER>
<CLASSIFICATIONS> ALBERTA </CLASSIFICATIONS>
<ABSTRACT>
For most of the last forty years Artificial Intelligence
(AI) has been confined to academic study. In the past
decade, however, it has experienced an explosive growth
in industry. So pervasive has been its recent growth
that it prompted Tom Peters, world-renowned industry
watcher, to espouse "that any senior manager in any
business of almost any size who isn't at least learning
about artificial intelligence (AI), and sticking a
tentative toe or two into AI's waters, is simply out of
step, dangerously so."$sp1$
AI encompasses a varied array of technologies including
virtual reality, speech recognition, natural language,
intelligent robotics, expert systems and neural
networks. The research covered by this thesis involves
learning. about the expert systems and neural network
technologies, theories and tools, and then applying this
knowledge to solve appropriate problems within the
Weyerhaeuser pulp mill operations at Grande Prairie,
Alberta.
Applying new technology, however involves more than
simply finding an elegant solution to a problem. There
is a human side to technology implementation that most
also be managed in order for any new technology to be
effectively deployed and maintained. The knowledge
gained in this area is discussed in this thesis.
ftn$sp1$Allen, Mary Kay and Helferich, Omar Keith,
Putting Expert Systems to Work in Logistics, Council of
Logistics Management, Oak Brook, IL, 1990, p. 158.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  3217 </NUMBER>
<ORDER>   AAIMM01603 </ORDER>
<TITLE> A KNOWLEDGE REPRESENTATION ARCHITECTURE FOR EXPERT PROCESS MONITORING SYSTEMS: APPLIED TO A PULP BLEACHING PROCESS </TITLE>
<AUTHOR> ERLENBACH, SAMUEL WYATT </AUTHOR>
<YEAR> 1995 </YEAR>
<INSTITUTION> UNIVERSITY OF ALBERTA (CANADA); 0351 </INSTITUTION>
<DESCRIPTORS> ENGINEERING, CHEMICAL; ENGINEERING, SYSTEM SCIENCE; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> MING RAO </ADVISER>
<CLASSIFICATIONS> NIL </CLASSIFICATIONS>
<ABSTRACT>
This thesis proposes a new knowledge representation
architecture for process monitoring expert systems. The
architecture is based on the object oriented paradigm as
a structure to represent world knowledge. The thesis
proposes several new perspectives for the paradigm and
its application. Several natural forms of experience are
interwoven into the structure of the architecture.
Experience is applied in a predictive manner. The
architecture encompasses the conceptual and physical
systems of a world through embedding of
interrelationship knowledge into component objects.
Associative linking of memory is included in the
architecture as a basis for intricate pathways for
mental exploration. Human thought processes are
replicated through the decoupling of thinking and
information knowledge. The architecture provides a
structure to capture and execute knowledge and thinking
behaviours for process monitoring activities. A
prototype based on the proposed knowledge representation
architecture was successfully implemented on a pulp
bleaching process of a Kraft pulp mill.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  3218 </NUMBER>
<ORDER>   AAIMM01220 </ORDER>
<TITLE> CONCEPT HIERARCHIES FOR ATTRIBUTE-ORIENTED KNOWLEDGE DISCOVERY </TITLE>
<AUTHOR> FUDGER, DAVID RAYMOND </AUTHOR>
<YEAR> 1995 </YEAR>
<INSTITUTION> THE UNIVERSITY OF REGINA (CANADA); 0148 </INSTITUTION>
<DESCRIPTORS> COMPUTER SCIENCE; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> H. HAMILTON; N. CERCONE </ADVISER>
<CLASSIFICATIONS> NIL </CLASSIFICATIONS>
<ABSTRACT>
The DBLEARN software system performs knowledge discovery
within the attribute-oriented induction learning
paradigm. Concept hierarchies provide a major portion of
the bias information for DBLEARN. In this thesis, the
design, construction, use and effectiveness of concept
hierarchies are identified.
Heuristic measures are defined to estimate the amount
and quality of information in a given concept hierarchy.
To attain a level of validity, extracts of large
commercial databases are used for the experiments. Four
measures of concept hierarchy effectiveness are proposed
and evaluated. A measure of "interestingness" for
quantifying the amount of discovered data is also
presented.
The heuristic measures are based on syntactic
characteristics of the concept hierarchies. The measure
of interestingness is based on the quantity and quality
of results obtained from a run of DBLEARN with a
particular concept hierarchy. Our findings show a
consistent correlation between the heuristic measures
for the concept hierarchies and the level of
interestingness of the output. There were found to be
positive and negative characteristics of concept
hierarchies used with DBLEARN.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  3219 </NUMBER>
<ORDER>   AAIMM00416 </ORDER>
<TITLE> FIELD SURVEY AND EXPERT SYSTEM ANALYSIS OF OPERATIONAL DEFICIENCIES AT PRIVATE AND PUBLICLY-OWNED WASTEWATER TREATMENT FACILITIES IN NEW BRUNSWICK </TITLE>
<AUTHOR> PAGE, IAN CHRISTOPHER </AUTHOR>
<YEAR> 1995 </YEAR>
<INSTITUTION> THE UNIVERSITY OF NEW BRUNSWICK (CANADA); 0823 </INSTITUTION>
<DESCRIPTORS> ENGINEERING, SANITARY AND MUNICIPAL; ENGINEERING, CIVIL; ENVIRONMENTAL SCIENCES; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> K. C. LIN </ADVISER>
<CLASSIFICATIONS> NIL </CLASSIFICATIONS>
<ABSTRACT>
New Brunswick has nearly 200 small private and publicly-
owned wastewater treatment facilities scattered
throughout the province, and more of these small systems
are being constructed each year. These facilities
service a wide range of developments, including federal
and provincial parks, industrial plants, subdivisions,
mobile home parks, hospitals and schools. The majority
of these facilities are owned and operated by
individuals who have little or no formal training or
experience in the wastewater treatment field. The owners
of these small facilities are often constrained by
limited finances for the design, operation and
maintenance of the treatment system. Though these small
systems are essentially scaled-down versions of large
treatment plants, their operational characteristics can
be quite unique.
Small private and publicly-owned wastewater treatment
plants have long been a source of pollution in New
Brunswick because of poor treatment performance. An
extensive survey of these systems was conducted to
determine why these systems have not been effective.
Each site was inspected and evaluated for treatment
efficiency and performance. Both summer and winter
inspections were performed to determine the performance
of these systems under a wide variety of environmental
conditions. Common operational deficiencies were
recorded, reasons for the deficiencies were investigated
and remediation alternatives were developed. The survey
revealed that poor operational procedures and lack of
regular maintenance were the sources of most system
deficiencies. The operators' lack of formal training in
the operation of a wastewater treatment plant was the
chief factor in the failure of many of these systems to
meet effluent requirements.
As a potential solution to these problems, the data
gathered during these inspections were combined with
proven remedial measures and troubleshooting options to
create the knowledge base for a prototype expert system.
A prototype expert system, called TEXWASTE, was then
created using an expert system development shell. The
system is capable of diagnosing potential causes for
poor treatment performance at small wastewater treatment
plants and providing remedial options for the system
user. Based on the user's input, a wide variety of
troubleshooting scenarios can be explored. Using the
shell package, future process developments can also be
added to the system's knowledge base to increase the
scope and application of the system.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  3220 </NUMBER>
<ORDER>   AAIC464005 </ORDER>
<TITLE> CONJECTURES: AN INQUIRY CONCERNING THE LOGIC OF INDUCTION </TITLE>
<AUTHOR> FLACK, PIETER ADRIAAN </AUTHOR>
<YEAR> 1995 </YEAR>
<INSTITUTION> KATHOLIEKE UNIVERSITEIT BRABANT (THE NETHERLANDS); 0687 </INSTITUTION>
<DESCRIPTORS> COMPUTER SCIENCE; ARTIFICIAL INTELLIGENCE; PHILOSOPHY </DESCRIPTORS>
<ADVISER> NIL </ADVISER>
<CLASSIFICATIONS> DATABASES </CLASSIFICATIONS>
<ABSTRACT>
This thesis deals with induction: deriving general rules
from specific cases. As a form of reasoning induction is
frequently applied, for example when generalising
observed facts and situations in daily life, but also
for drawing up experimental scientific theories.
Furthermore, induction is nowadays being applied in
computer systems that learn from examples.
Conclusions reached by induction may turn out to be
wrong, and the justification of inductive conclusions is
a notorious philosophical problem. There is, however,
another problem: a general theory as to which inductive
conjectures are refuted by the observed instances, and
which are still possible, does not exist. This problem
of 'conjectural reasoning' forms the subject of this
thesis. Starting from earlier work in philosophy,
computer science and logic, an attempt has been made to
reduce the problem to manageable proportions, and to
suggest the beginnings of a solution.
The principal result of this attempt is twofold. First
of all, it is claimed that the logic of induction is not
essentially different from, for example, deductive
logic, as long as we are prepared to broaden the usual
conception of logic somewhat. This frees the way for the
application of a recently developed description method--
put forward by Kraus, Lehmann & Magidor to aid the
analysis of reasoning with general rules and exceptions--
to inductive reasoning. The second result of this thesis
is a distinction between and logical characterisation of
two different forms of induction: explanatory induction,
which aims at explaining observed cases, and
confirmatory induction, where the inductive conjectures
are confirmed by the observations, however without
explaining the latter. It is shown that this distinction
can be traced back to philosophical work of Peirce and
Hempel, making furthermore use of recent work in the
field of artificial intelligence.
Finally, the theory developed in the thesis is applied
to the problem of inducing integrity constraints in
databases, aimed at making explicit the structure that
is implicitly present in the data. The constraints thus
discovered can be used, with some help of the user, to
reorganise the data in a more meaningful and less
redundant way.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  3221 </NUMBER>
<ORDER>   AAIC463372 </ORDER>
<TITLE> A CONSTRUCTIVE LEARNING ALGORITHM BASED ON BACK- PROPAGATION  </TITLE>
<AUTHOR> LOWTON, ANDREW DAVID </AUTHOR>
<YEAR> 1995 </YEAR>
<INSTITUTION> ASTON UNIVERSITY (UNITED KINGDOM); 0734 </INSTITUTION>
<DESCRIPTORS> COMPUTER SCIENCE; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> NIL </ADVISER>
<CLASSIFICATIONS> NEURAL NETWORKS, GENERALISATION </CLASSIFICATIONS>
<ABSTRACT>
There has been a resurgence of interest in the neural
networks field in recent years, provoked in part by the
discovery of the properties of multi-layer networks.
This interest has in turn raised questions about the
possibility of making neural network behaviour more
adaptive by automating some of the processes involved.
Prior to these particular questions, the process of
determining the parameters and network architecture
required to solve a given problem had been a time
consuming activity. A number of researchers have
attempted to address these issues by automating these
processes, concentrating in particular on the dynamic
selection of an appropriate network architecture.
The work presented here specifically explores the area
of automatic architecture selection; it focuses upon the
design and implementation of a dynamic algorithm based
on the Back-Propagation learning algorithm. The
algorithm constructs a single hidden layer as the
learning process proceeds using individual pattern error
as the basis of unit insertion. This algorithm is
applied to several problems of differing type and
complexity and is found to produce near minimal
architectures that are shown to have a high level of
generalisation ability.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  3222 </NUMBER>
<ORDER>   AAIC463364 </ORDER>
<TITLE> THE DEVELOPMENT OF AN EXPERT SYSTEM FOR THE IDENTIFICATION OF ANODIC COATING PROCESS DEFECTS AS A CONTRIBUTION TO THE DISSEMINATION OF ANODIZING TECHNOLOGY </TITLE>
<AUTHOR> BRACE, ARTHUR WILLIAM </AUTHOR>
<YEAR> 1995 </YEAR>
<INSTITUTION> ASTON UNIVERSITY (UNITED KINGDOM); 0734 </INSTITUTION>
<DESCRIPTORS> ENGINEERING, INDUSTRIAL; ARTIFICIAL INTELLIGENCE; COMPUTER SCIENCE; BUSINESS ADMINISTRATION, GENERAL </DESCRIPTORS>
<ADVISER> NIL </ADVISER>
<CLASSIFICATIONS> HYPERTEXT </CLASSIFICATIONS>
<ABSTRACT>
Initially this thesis examines the various mechanisms by
which technology is acquired within anodizing plants. In
so doing the history of the evolution of anodizing
technology is recorded, with particular reference to the
growth of major markets and to the contribution of the
marketing efforts of the aluminium industry. The
business economics of various types of anodizing plants
are analyzed. Consideration is also given to the impact
of developments in anodizing technology on production
economics and market growth. The economic costs
associated with work rejected for process defects are
considered.
Recent changes in the industry have created conditions
whereby information technology has a potentially
important role to play in retaining existing knowledge.
One such contribution is exemplified by the expert
system which has been developed for the identification
of anodizing process defects. Instead of using a "rule-
based" expert system, a commercial neural networks
program has been adapted for the task. The advantages of
neural networks over 'rule-based' systems is that they
are better suited to production problems, since the
actual conditions prevailing when the defect was
produced are often not known with certainty.
In using the expert system, the user first identifies
the process stage at which the defect probably occurred
and is then directed to a file enabling the actual
defects to be identified. After making this
identification, the user can consult a database which
gives a more detailed description of the defect, advises
on remedial action and provides a bibliography of papers
relating to the defect. The database uses a proprietary
hypertext program, which also provides rapid cross-
referencing to similar types of defect. Additionally, a
graphics file can be accessed which (where appropriate)
will display a graphic of the defect on screen.
A total of 117 defects are included, together with 221
literature references, supplemented by 48 cross-
reference hyperlinks. The main text of the thesis
contains 179 literature references.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  3223 </NUMBER>
<ORDER>   AAIC447614 </ORDER>
<TITLE> LITTLE LINGUISTIC CREATURES: CLOSED SYSTEMS OF SOLVABLE NEURAL NETWORKS FOR INTEGRATED LINGUISTIC ANALYSIS </TITLE>
<AUTHOR> DROSSAERS, MARC FREDERIC JOOST </AUTHOR>
<YEAR> 1995 </YEAR>
<INSTITUTION> UNIVERSITEIT TWENTE (THE NETHERLANDS); 0237 </INSTITUTION>
<DESCRIPTORS> COMPUTER SCIENCE; LANGUAGE, LINGUISTICS; ARTIFICIAL INTELLIGENCE THE NETHERLANDS </DESCRIPTORS>
<ADVISER> NIL </ADVISER>
<CLASSIFICATIONS> NIL </CLASSIFICATIONS>
<ABSTRACT>
This thesis answers the question for a theory on self-
organizing neural networks which, if properly organized
in systems, can be used for integrated linguistic
analysis, where 'integrated' refers to, among others,
syntactic, semantic and pragmatic aspects.
The approach to answering the question is based on the
ideas of the neural-biologists Maturana and Varela. It
is directed at machines that unsupervisedly acquire the
subjective knowledge required for the use of language.
The thesis presents a class of neural networks that: (1)
are models of bi-layer modules of the nervous system,
these modules can be considered its basic functional
unit; (2) come to perform a task by unsupervised
learning; (3) are computationally equivalent to finite-
state acceptors; and (4) can be combined into systems of
networks, just as the bi-layer modules are combined into
the nervous system.
The thesis presents and analyzes: (1) the neural-network
acceptor, a neural network which is computationally
equivalent to a finite-state acceptor: the abstract
machine that is computationally just strong enough for
natural language processing tasks; (2) the noisy-network
acceptor, a variant which incorporates the stochastic
nature of biological neurons in firing action
potentials; and (3) the parallel-network acceptor, a
simplified variant with improved computational
efficiency. The analyses are based on the statistical
mechanics analyses of the Hopfield model.
The networks learn to perform functions by means of two
learning processes. One modifies the synapses within
layers, and one modifies the synapses between layers. In
the case of systems of network acceptors, only the
peripheral layers are given examples to learn from; in a
system learning proceeds from the periphery inward.
The functional correctness of systems can be checked by
first order predicate logic. Because it can be
determined a priori how individual networks and the
learning processes will behave, it can also be
determined a priori how systems of network acceptors
will behave.
Since it is in general not known how the brain
implements language processing tasks it is necessary,
and very interesting, to construct experimental systems
of network acceptors for natural language processing:
little linguistic creatures.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  3224 </NUMBER>
<ORDER>   AAG1380458 </ORDER>
<TITLE> MORPHOLOGICAL DIAGNOSES WITH THE USE OF AN EXPERT SYSTEM IN THE DOMAIN OF LYMPH NODE PATHOLOGY </TITLE>
<AUTHOR> CLARKE, KENNETH GERRARD </AUTHOR>
<YEAR> 1995 </YEAR>
<INSTITUTION> UNIVERSITY OF SOUTHERN CALIFORNIA; 0208 </INSTITUTION>
<DESCRIPTORS> HEALTH SCIENCES, PATHOLOGY; BIOLOGY, BIOSTATISTICS; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> STANLEY P. AZEN </ADVISER>
<CLASSIFICATIONS> NIL </CLASSIFICATIONS>
<ABSTRACT>
Background: Pathfinder, an expert system that assists
pathologists with the diagnosis of lymph node pathology,
includes 76 diseases and 91 morphologic distinctions.
Pathfinder provides a differential diagnosis given a set
of observations, and suggests additional features that
are likely to narrow the differential diagnosis.
Purpose: To evaluate the diagnostic accuracy of
Pathfinder.
Methods: 29 slides and 19 pathologists were used to
evaluate Pathfinder in a crossover design. For each
test, the proportion of correct diagnoses was compared
between those using Pathfinder versus standard methods.
Results: Test 1 showed no statistically significant
difference in the proportion of correct diagnoses, while
in Test 2, Pathfinder had a significantly greater
proportion of correct diagnoses than the standard
method.
Conclusions: While sensitive to feature recognition
skills, Pathfinder is a valuable educational tool for
the lymph node domain.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  3225 </NUMBER>
<ORDER>   AAIC446782 </ORDER>
<TITLE> AUTOMATIC PATTERN RECOGNITION AND LEARNING FOR INFORMATION SYSTEMS  </TITLE>
<AUTHOR> BRUCKNER, JORG </AUTHOR>
<YEAR> 1995 </YEAR>
<INSTITUTION> UNIVERSITY OF SUSSEX (UNITED KINGDOM); 0545 </INSTITUTION>
<DESCRIPTORS> COMPUTER SCIENCE; ENGINEERING, ELECTRONICS AND ELECTRICAL; REMOTE SENSING; ARTIFICIAL INTELLIGENCE BRIGHTON, BN1 9RH SUSSEX,  ENGLAND </DESCRIPTORS>
<ADVISER> NIL </ADVISER>
<CLASSIFICATIONS> IMAGE PROCESSING </CLASSIFICATIONS>
<ABSTRACT>
Space science information systems involve accessing vast
databases. There is a need for an automatic process by
which properties of the whole data set can be
assimilated and presented to the user. This work
describes the building blocks of a prototype information
system allowing automatic data pre-processing and
analysis. The corresponding software was developed in C
on a Sun workstation under UNIX/Xwindows.
Examined are geophysical, sonar radar, solar X-ray,
electrical motor deterioration and financial data. All
of them contain different phenomena, or patterns, which
can be recognised and learned by the developed
prototype.
For geophysical and solar X-ray data, image objects are
segmented by a novel image pre-processing method.
Statistical measurements obtain feature extraction and
yield a set of feature vectors which describe the
objects. Feature vectors for the electrical motor and
financial time series data are gained by time-dependant
telescoping.
The feature vectors are classified in quasi real-time by
the unsupervised neural network classifiers CALM and
fuzzy ART and the supervised neural network classifier
fuzzy ARTMAP. The classifiers offer qualities like fast
learning, generalising, ability to continuously adapt to
changes in the input data and the possibility of
modularisation. Various neural network configurations
and architectures are developed and explored in detail
to assess their useability for the examined
classification problems. Higher order geophysical
phenomena are classified by a hierarchical neural
network structure, utilising contextual information
between geophysical image objects.
Neural network optimisation and feature space reduction
by feature transformation are used to enhance the
classification abilities of the system. Feature
selection and neural network optimisation are considered
together, using the classification accuracy to guide
exhaustive and genetic algorithm searches for suitable
feature subsets and neural network parameters.
The introduced image pre-processing method is also used
for object-oriented image data compression. Conventional
cosine transform compression is compared with a novel
object-oriented compression method.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  3226 </NUMBER>
<ORDER>   AAIC446568 </ORDER>
<TITLE> ARTIFICIAL NEURAL NETWORKS FOR MODELLING AND CONTROL OF NONLINEAR SYSTEMS  </TITLE>
<AUTHOR> SUYKENS, JOHAN A. K. </AUTHOR>
<YEAR> 1995 </YEAR>
<INSTITUTION> KATHOLIEKE UNIVERSITEIT LEUVEN (BELGIUM); 5605 </INSTITUTION>
<DESCRIPTORS> ENGINEERING, ELECTRONICS AND ELECTRICAL; ARTIFICIAL INTELLIGENCE CAMPUSBIBLIOTHEEKDIENST,  CELESTIJNENLAAN 300 A, B-3001 LEUVEN (HEVERLEE), BELGIUM </DESCRIPTORS>
<ADVISER> NIL </ADVISER>
<CLASSIFICATIONS> ROBUST CONTROL </CLASSIFICATIONS>
<ABSTRACT>
Properties that make artificial neural networks
attractive for application to modelling and control of
nonlinear systems are the fact that neural nets are
universal approximators, have a parallel network
structure and their weights can be learned from a set of
examples. However, dynamical systems that contain neural
network architectures are highly nonlinear and as a
result are difficult to analyse. The aim of this thesis
is to study the use of neural networks in a system
theoretical context. Novel and existing network
architectures and learning algorithms for modelling and
control are discussed. The main contributions of the
thesis are in nonlinear system identification, neural
optimal control, top-down model based neural control
design and stability analysis of neural control systems.
$rm NLsb0it q$ theory is introduced as an extension
towards modern robust control theory, in order to
analyse and synthesize nonlinear systems that contain
linear together with static nonlinear operators that
satisfy a sector condition, such as neural state space
control systems. It turns out that $rm NLsb0it q$ theory
is unifying with respect to many problems arising in
neural networks, systems and control. Examples show that
complex nonlinear systems can be modelled and controlled
within $rm NLsb0it q$ theory, including mastering chaos.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  3227 </NUMBER>
<ORDER>   AAIC444959 </ORDER>
<TITLE> MODEL-BASED AND OPERATOR-ASSISTED COMPUTER VISION IN ROV TELEOPERATION  </TITLE>
<AUTHOR> VOLDEN, RUNE </AUTHOR>
<YEAR> 1995 </YEAR>
<INSTITUTION> NORGES TEKNISKE HOGSKOLE (NORWAY); 5714 </INSTITUTION>
<DESCRIPTORS> COMPUTER SCIENCE; ARTIFICIAL INTELLIGENCE N-7034 TRONDHEIM-NTH, NORWAY UNIVERSITET, N-7034  TRONDHEIM, NORWAY </DESCRIPTORS>
<ADVISER> NIL </ADVISER>
<CLASSIFICATIONS> REMOTELY OPERATED VEHICLE, ROBOTICS, IMAGE PROCESSING </CLASSIFICATIONS>
<ABSTRACT>
This thesis proposes an operator assisted computer
vision system for use in modelbased teleoperation of a
Remotely Operated Vehicle (ROV) in six Degrees of
Freedom. The system uses a single camera and is feature
based. Its purposes are to obtain the camera position
and orientation (camera-pose) from known geometric
objects or known control points and to obtain new
geometric objects in the environment. The system has
included and analyzed the features: Point, corner, line
and ellipse. Matching between model and image feature is
done by projecting a wireframe model of the proposed
object onto the image, so that the operator easily can
verify the spatial correspondence. The vision task is
separated, such that the operator is recognizing the
object, while the computer provides features, pose
calculations and proposed wire-frame models for the
operator.
Camera modeling and camera calibration are covered,
where a new method of obtaining camera-pose from few
control points with a recursive least-square method is
proposed. A chapter is presenting a method of obtaining
three-dimensional coordinates from single two-
dimensional images. If the three-dimensional coordinates
are corners of planar objects, the operator can identify
the objects and name the corners, so that the object
pose is obtained. For regular objects like polyhedron
and pyramid, additional constraints like length of the
object axes and orthogonality between the axes provide
information, which is used in a proposed algorithm for
better object-pose estimate. The robustness ofthe three-
dimensional corner estimates with respect to errors in
camera-pose parameters is analyzed. The thesis also
covers backprojection of ellipse in image-plane to
cylinder and sphere using Projective Geometry. The
feature extraction and especially ellipse extraction
through least-squares method is proposed. A general
discussion on pose extraction is also presented.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  3228 </NUMBER>
<ORDER>   AAIC444662 </ORDER>
<TITLE> SELF-ORGANIZING ARTIFICIAL NEURAL NETWORKS IN DYNAMIC SYSTEMS MODELING AND CONTROL </TITLE>
<AUTHOR> HYOTYNIEMI, HEIKKI JAAKKO </AUTHOR>
<YEAR> 1995 </YEAR>
<INSTITUTION> TEKNILLINEN KORKEAKOULU (HELSINKI) (FINLAND); 5766 </INSTITUTION>
<DESCRIPTORS> ENGINEERING, SYSTEM SCIENCE; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> NIL </ADVISER>
<CLASSIFICATIONS> NIL </CLASSIFICATIONS>
<ABSTRACT>
This thesis discusses the potential of self-organizing
networks applied to the modeling and control of dynamic
systems. A general framework is created for self-
organizing networks applications that is especially
suited to control engineering. Apart from the
traditional time-domain features, linear operators can
be mapped in the network. Efficient algorithms are
derived for adapting the parameters in the self-
organizing net. These algorithms are motivated as
solutions to well-founded optimization problems. Two
prototypical approaches to realizing controllers based
on the neural network representations are presented with
simple application examples. The theoretical problems of
combining self-organizing networks with dynamic systems
are discussed extensively.
The algorithms that are derived for self-organization
are not limited only to control engineering
applications. On the other hand, the theoretical
analyses of dynamic systems are not limited to neural
networks applications--for example, the identification
algorithms and the results achieved on the systems
identifiability are applicable to the general parameter
estimation tasks.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  3229 </NUMBER>
<ORDER>   AAI9606267 </ORDER>
<TITLE> SEPARATION PROCESS SYNTHESIS: A KNOWLEDGE-BASED SYSTEM USING SPREADSHEET MACROS </TITLE>
<AUTHOR> MUNDKUR, SIDDHARTH DINESH </AUTHOR>
<YEAR> 1995 </YEAR>
<INSTITUTION> UNIVERSITY OF LOUISVILLE; 0110 </INSTITUTION>
<DESCRIPTORS> ENGINEERING, CHEMICAL; COMPUTER SCIENCE; OPERATIONS RESEARCH; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> DEAN O. HARPER </ADVISER>
<CLASSIFICATIONS> NIL </CLASSIFICATIONS>
<ABSTRACT>
A task-oriented approach to the syntheses of flowsheets
separating multicomponent mixtures, and the selection of
the appropriate unit operation(s) has been developed.
Built in the environment of spreadsheet macros, PROSHEET
(PROcess design spreadSHEET) was designed, based on a
combination of heuristic and algorithmic approaches. The
expert system is rule-based with the design knowledge
organized into a query with system hierarchy, by
dividing the main separation problem into subproblems.
The subproblems were of two types, (a) split definition,
and (b) unit operation selection. Heuristics helped in
this subdivision. Each subproblem contains a series of
ordered heuristics based on process characteristics and
component properties.
PROSHEET has been designed to handle vapor-liquid, gas,
and non-volatile solute/solvent separations. The
knowledge base is governed by rules which are forward-
chained, while the inference engine is governed by rules
which are distracted chained, i.e., a combination of
forward and backward chaining. Algorithms are used to
calculate physical properties from a supporting database
and make unit operation calculations.
The separation sequences recommended and the flowsheets
developed for sample problems were compared to those
found in commercial designs and process synthesis
literature. The sequences recommended conformed to
commercial designs and PROSHEET at times suggested
considering alternative unit operations for a particular
split. Although not considered a high-level programming
language, spreadsheet macros clearly emulate a rule-
based approach used by high-level languages, and the
spreadsheet environment itself is very versatile for
developing numerous other expert systems.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  3230 </NUMBER>
<ORDER>   AAI9606125 </ORDER>
<TITLE> VISION-GUIDED ROBOT MOTION PLANNING AND CONTROL </TITLE>
<AUTHOR> YU, ZHENYU </AUTHOR>
<YEAR> 1995 </YEAR>
<INSTITUTION> WASHINGTON UNIVERSITY; 0252 </INSTITUTION>
<DESCRIPTORS> ENGINEERING, ELECTRONICS AND ELECTRICAL; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> B. K. GHOSH </ADVISER>
<CLASSIFICATIONS> COMPUTER VISION </CLASSIFICATIONS>
<ABSTRACT>
This dissertation discusses the problem of robot motion
planning and control when computer vision is employed as
a primary sensor. It focuses on general planning and
control problems for robot in a manufacturing workcell.
A typical task for a robot manipulator in a
manufacturing environment is to track and grasp a part
on a conveyor. Another task is for the manipulator to go
from one place to another without running into
previously unknown obstacles. The three critical phases
involved in solving such a problem are sensing with
computer vision as a primary sensor, robot motion
planning based on sensory data and robot motion control
for the execution of planned motion. Two strategies are
introduced to combine the measurements of computer
vision and a positional sensor such as an encoder. One
is called spatial sensor fusion. It combines static
relative position and orientation information obtained
by computer vision with measurements of an encoder
sensor to estimate absolute position and orientation of
a part. The other is called temporal sensor fusion. It
relies upon measurements from an encoder to bring up to
date delayed absolute position and orientation
information obtained by generic vision algorithms. The
goal of these strategies is to reduce the amount of
computation associated with vision algorithm. A vision
algorithm based on the geometry of the trajectory of a
feature point undergoing circular motion is introduced.
This technique constructs a series of camera rotations
to rotate the camera such that the rotated camera looks
straight down at a two dimensional scene. The
corresponding image transformation maps an image into
one that is as if taken by a camera looking straight
down. Relative position and orientation of a part with
respect to its conveyor in the resultant image are
reflected without distortion and hence easy to compute.
This algorithm is aimed at solving another problem
related to computer vision, that is, the tendency of
vision algorithm to rely upon the knowledge of camera
position and orientation. An analytical planning scheme,
parallel tracking, is introduced for robot to track a
moving target. This scheme is designed to solve the
problem of tracking with large initial positional
disparity and bounded control. It adds an artificial
term to the position of a target to obtain a desired
position for robot. This artificial term is initially
set to be the positional error between the robot and the
target. It is planned to gradually reduce to zero with
existing bounded control. Collision avoidance is another
important problem in robot motion planning and control.
A new concept of safety for a robot moving along a
prespecified path is introduced. Based on the new safety
criteria, two safe motion planning schemes are derived.
These plans modify a prespecified motion profile or
generate a time optimal motion profile all by themselves
as the positions of obstacles around the path are
detected during on-line operation. It guarantees the
safety of a robot at the cost of possibly slower moving
speed. Simulation and experimental results are
presented. They demonstrate the validity and
effectiveness of the new sensing scheme based on sensor
fusion, the novel vision algorithm based on the geometry
of a projected circular trajectory, the analytical
tracking scheme with added error term, and the collision
avoidance motion planning scheme based on the new safety
criteria.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  3231 </NUMBER>
<ORDER>   AAI9606098 </ORDER>
<TITLE> PREFERENCE ACQUISITION THROUGH RECONCILIATION OF INCONSISTENCIES  </TITLE>
<AUTHOR> JAIN, NILESH LAXMICHAND </AUTHOR>
<YEAR> 1995 </YEAR>
<INSTITUTION> WASHINGTON UNIVERSITY; 0252 </INSTITUTION>
<DESCRIPTORS> OPERATIONS RESEARCH; COMPUTER SCIENCE; HEALTH SCIENCES, RADIOLOGY; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> MICHAEL G. KAHN </ADVISER>
<CLASSIFICATIONS> KNOWLEDGE BASED EXPERT SYSTEMS, PREFERENCE BASED DECISION THEORETIC SYSTEMS, RADIATION ONCOLOGY </CLASSIFICATIONS>
<ABSTRACT>
Intelligent computer-based systems can be broadly
divided into two categories--knowledge-based expert
systems and preference-based decision-theoretic systems.
The quality of their performance depends on their
underlying knowledge bases and preference models
respectively. Difficulties in acquiring these models
make knowledge and preference acquisition a major focus
of current research in artificial intelligence and
decision theory.
This dissertation focuses on decision problems which
require decision makers to make trade-offs among
multiple conflicting objectives in selecting among
available decision alternatives. Multiattribute utility
theory provides a framework to specify trade-off
preferences of the decision makers and to use these
preferences in selecting the optimal decision.
Traditional decision-theoretic preference-acquisition
techniques are difficult to implement and rarely elicit
the true preferences of the decision maker. This
dissertation describes a new preference-acquisition
technique for eliciting trade-off preferences of
decision makers.
This dissertation makes two key contributions. First, it
describes ACQUIRE--a new preference-acquisition
technique--for decision-theoretic systems which evaluate
competing decision alternatives and select the best
decision alternative while fulfilling multiple
conflicting objectives. ACQUIRE is based on reconciling
inconsistencies between the preference model and the
decision maker, similar to knowledge maintenance for
knowledge-based systems. If the decision recommended by
the preference model does not agree with the decision
maker, she modifies the preference model interactively
until the inconsistency is reconciled.
ACQUIRE is used to elicit the preferences of radiation
oncologists for the objective evaluation of competing
radiation treatment plans. The evaluation of radiation
treatment plans requires radiation oncologists to make
trade-offs between high radiation doses required for
tumor eradication and low radiation doses required to
prevent damage to healthy tissues. The second
contribution of the dissertation is the development of a
decision-theoretic system for evaluating competing
radiation treatment plans for a patient undergoing
radiotherapy. Multiattribute utility theory is used to
construct the decision model. A decision-support system
with an interactive graphical user interface is
developed to implement ACQUIRE and the decision model.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  3232 </NUMBER>
<ORDER>   AAI9605957 </ORDER>
<TITLE> RADAR TARGET DISCRIMINATION USING NEURAL NETWORK </TITLE>
<AUTHOR> TSAI, CHANG-YING </AUTHOR>
<YEAR> 1995 </YEAR>
<INSTITUTION> MICHIGAN STATE UNIVERSITY; 0128 </INSTITUTION>
<DESCRIPTORS> ENGINEERING, ELECTRONICS AND ELECTRICAL; COMPUTER SCIENCE; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> KUN-MU CHEN </ADVISER>
<CLASSIFICATIONS> NIL </CLASSIFICATIONS>
<ABSTRACT>
This study uses several different memory-based neural
networks to discriminate radar targets based on their
early-time, aspect-dependent response, and demonstrates
that target discrimination can be accomplished in a high-
noise environment with great reliability. The difficulty
of locating the beginning response point in practice
prompts the use of FFT frequency spectrum magnitudes as
aspect process patterns since a time shift is implicated
in the phase of the spectrum. The effects of analog data
and bipolar data with different quantization levels on
network performances are investigated. Especially
promising is the Recurrent Correlation Accumulation
Adaptive Memory-Generalized Inverse (RCAAM-GI) cascade
neural network. This network uses a dynamic memory
structure to accumulate the converging information and
has a stability criterion to allow us to define the
final stable state. It can be considered as a real-time
adaptive learning network with contamination
observability and flexible decision strategy. From the
simulation results, the network demonstrates computation
space efficiency, and high noise tolerance.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  3233 </NUMBER>
<ORDER>   AAI9605851 </ORDER>
<TITLE> A PARALLEL ALGORITHM FOR ULTRASONIC MATERIAL CHARACTERIZATION  </TITLE>
<AUTHOR> CHOU, CHIPAI </AUTHOR>
<YEAR> 1995 </YEAR>
<INSTITUTION> MICHIGAN STATE UNIVERSITY; 0128 </INSTITUTION>
<DESCRIPTORS> ENGINEERING, ELECTRONICS AND ELECTRICAL; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> BONG HO </ADVISER>
<CLASSIFICATIONS> NEURAL NETWORK </CLASSIFICATIONS>
<ABSTRACT>
Attenuation coefficient has been considered to be an
important feature in material characterization. However,
estimation of an attenuation coefficient in material,
especially in biological tissues, is still a difficult
task. Unlike conventional approaches, the proposed
approach extracts several features from the return
echoes, then applies a clustering technique to the
extracted features. A modified Hopfield neural network,
called the maximum neural network, is adopted to process
the extracted data set. The advantages and convergence
property of the maximum neural network are discussed in
this dissertation. Due to the inherent parallelism in
the maximum neural network, material characterization
using parallel processing becomes possible. Both
synthetic data sets and a data set taken from a human
sample are used to demonstrate the capability of the
proposed system. Some results were obtained from the
proposed scheme which could be achieved by the
traditional methods.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  3234 </NUMBER>
<ORDER>   AAI9605764 </ORDER>
<TITLE> EXPERT SYSTEM AND HYPERMEDIA METHODS FOR THE INCLUSION OF ERGONOMICS INTO CONCURRENT DESIGN PROCESSES </TITLE>
<AUTHOR> BUDNICK, PETER MATTHEW </AUTHOR>
<YEAR> 1995 </YEAR>
<INSTITUTION> THE UNIVERSITY OF UTAH; 0240 </INSTITUTION>
<DESCRIPTORS> ENGINEERING, INDUSTRIAL; HEALTH SCIENCES, OCCUPATIONAL HEALTH AND THERAPY; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> NIL </ADVISER>
<CLASSIFICATIONS> NIL </CLASSIFICATIONS>
<ABSTRACT>
Engineers engaged in the design of products, components,
and manufacturing processes often have difficulty
accessing or incorporating ergonomic concepts and data
into their designs. Although numerous ergonomic
information sources are available, they appear to
nonexpert engineers to be scattered and difficult to
interpret and apply. Attempts have been made to compile
ergonomic information into concise and easily accessible
formats, but none are widely accepted in industry.
Many industrial organizations have adopted or are
pursuing product life cycle methods that expedite the in-
house design through marketing activities. Such
techniques are commonly referred to as "concurrent
design," "design for manufacturing (DFM)," "simultaneous
engineering," or any number of names. These programs
necessitate cooperation between traditionally separate
engineering concerns and demand timely availability and
access to many types of information, including
ergonomics. Computer aided design platforms that provide
a common computing environment accessible to a variety
of in-house concerns are being implemented by many
organizations. Such systems may immediately reflect
changes made by one individual to all others accessing
the system. Some systems act as an apprentice or
assistant to the engineer by making pertenent
information available at appropriate times as the design
proceeds.
This dissertation describes the conceptual structure of
a concurrent design system that acts as a proactive
assistant with ergonomic expertise. Two versions of the
prototype system utilizing rulebased expert system and
hypermedia artificial intelligence methods are
presented. The first is referred to as "Concurrent
Design Engineering for the Ergonomics of Production
Systems," or CDEEPS, now obsolete, is a prototype
consisting of a "Design Editor," a "Task Editor," and a
"Process Diagnostician."
The second system, referred to as the "Process
Diagnostician," operates within a World Wide Web
application called "ErgoWeb," a hypermedia ergonomics
knowledge delivery system. The prototype Process
Diagnostician is designed to analyze assembly tasks
described in Methods-Time Measurement 1 (MTM1) only. The
prototype expert system predicts both the time to
complete tasks and a general ergonomic concern level
(high, medium, low) for each.
This dissertation reviews the history of ergonomics,
describes the role of ergonomics in concurrent design,
briefly discusses expert systems and hypermedia, but
focuses primarily on ErgoWeb and the Process
Diagnostician.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  3235 </NUMBER>
<ORDER>   AAGMM10888 </ORDER>
<TITLE> THE ROLE OF THE ELEMENTARY PERCEIVER AND MEMORIZER </TITLE>
<AUTHOR> RADVAR-ZANGANEH, SIASB </AUTHOR>
<YEAR> 1995 </YEAR>
<INSTITUTION> CONCORDIA UNIVERSITY (CANADA); 0228 </INSTITUTION>
<DESCRIPTORS> COMPUTER SCIENCE; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> C. Y. SUEN </ADVISER>
<CLASSIFICATIONS> EPAM) IN OPTICAL CHARACTER RECOGNITION (OCR </CLASSIFICATIONS>
<ABSTRACT>
Elementary Perceiver And Memorizer (EPAM) is one of the
few existing general models of human perception. It has
been successful in simulating and describing many human
cognition phenomena. In this thesis, the role of EPAM is
studied in terms of an OCR machine. The model is
described in some detail. Its strengths and shortcomings
have been pointed out. Some suggestions are provided for
its shortcomings. Two of the suggestions are implemented
and tested in this thesis. In EPAM, objects of any
complexity level could be described. In this experiment
the primitive objects of the EPAM model are defined as
characters, and words of the English language are
defined as the upper bound on the complexity of the
objects. In this way the model is tested under: (1) One
level of object complexity. (2) A large base of objects
with a variable length feature set. As such, to test the
modification's effect on the behaviour of the model,
EPAM is used as a postprocess to a character
segmentation and recognition subsystem. The experiment
is tested with 30 fonts of different typefaces with
sizes ranging between 7 points to 12 points. For the
segmentation subsystem a line, word, and character
segmenter is provided. A Feature extraction methodology
and a recognition model are also provided for the
character recognition subsystem. EPAM is trained with
23692 words and tested with the results of the character
testing font set.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  3236 </NUMBER>
<ORDER>   AAI9605737 </ORDER>
<TITLE> UNIPED LOCOMOTION TRAINING </TITLE>
<AUTHOR> LI, LIQUN ANDREW </AUTHOR>
<YEAR> 1995 </YEAR>
<INSTITUTION> LAMAR UNIVERSITY - BEAUMONT; 0424 </INSTITUTION>
<DESCRIPTORS> ENGINEERING, MECHANICAL; COMPUTER SCIENCE; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> NIL </ADVISER>
<CLASSIFICATIONS> NEURAL NETWORK, MACHINE LEARNING </CLASSIFICATIONS>
<ABSTRACT>
The author investigated the use of artificial neural
networks to control the jumping behavior of a three-link
uniped robot. It is believed that the biped locomotion
control problem is an increment of the uniped locomotion
control. Study of legged locomotion dynamics shows that
a hierarchical controller is required to control the
behavior of a legged robot. A structured control
strategy is suggested which includes navigator, motion
planner, biped coordinator and uniped controllers. A
three-link uniped robot simulation was developed to be
used as the plant. Neurocontrollers were trained both on-
line and off-line. In the case of on-line training, a
reinforcement learning technique was used to train the
neurocontroller to make the robot jump to a specified
height. After several hundred iterations of training,
the plant output achieved an accuracy of 7.4%. However,
when jump distance and body angular momentum were also
included in the control objectives, training time became
impractically long. In the case of off-line training, a
three-layered backpropagation (BP) network was first
used with three inputs, three outputs and 15 to 40
hidden nodes. Pre-generated data were presented to the
network with a learning rate as low as 0.003 in order to
reach convergence. The low learning rate required for
convergence resulted in a very slow training process
that took weeks to learn 460 examples. After training,
the neurocontroller's performance was rather poor.
Afterward, the BP network was replaced by a Cerebellar
Model Articulation Controller (CMAC) network. Subsequent
experiments described in this document show that the
CMAC network is more suitable to solving uniped
locomotion control problems in terms of both learning
efficiency and performance.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  3237 </NUMBER>
<ORDER>   AAI9605659 </ORDER>
<TITLE> AGGREGATION IN FUZZY SYSTEMS AND SIMULATION OF NEURAL NETWORKS  </TITLE>
<AUTHOR> RYBALOV, ALEXANDER </AUTHOR>
<YEAR> 1995 </YEAR>
<INSTITUTION> CITY UNIVERSITY OF NEW YORK; 0046 </INSTITUTION>
<DESCRIPTORS> COMPUTER SCIENCE; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> JERRY WAXMAN </ADVISER>
<CLASSIFICATIONS> ARTIFICIAL INTELLIGENCE </CLASSIFICATIONS>
<ABSTRACT>
The central idea in artificial intelligence research has
been that of finding adequate representations to model
human thought. To this end, research has been focused on
fuzzy logic. In this thesis a new kind of fuzzy logic
operators--uni-norm operators--has been introduced,
which can model more faithfully such logical connectives
as conjunction and disjunction. Subsequently their
properties have been investigated and the general
representability was established.
Another type of aggregation in fuzzy systems arise in
attempts to model the way in which humans process
information. Such types of aggregation--full
reinforcement aggregation and self identity operators--
are introduced, and their application in fuzzy systems
is investigated.
Information fusion deals with the problem of combining
knowledge from different information fusion deals with
the problem of combining knowledge from different
sources to obtain so called fused value. This work
introduces the notion of a penalty function as a method
for obtaining the fused value. A number of different
penalty functions are investigated, and their
applications are considered.
Fuzzy systems possess advantages in comparison with
neural networks. In particular they consist of rules
humans can understand, whereas neural networks are
represented as impenetrable mass of weights. Putting
neural networks in a form more amenable to human
reasoning is a large step in understanding their work.
The thesis shows how to represent neural networks
through fuzzy systems.
Fuzzy systems are built by experts, whereas neural
networks learn from examples. Enabling fuzzy systems
also learn from examples greatly enhance their
possibilities. In this work techniques used in building
of neural networks--backpropagation method--is applied
to fuzzy systems, so latter would be more consistent
with both experts and examples.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  3238 </NUMBER>
<ORDER>   AAI9605536 </ORDER>
<TITLE> MODULARIZING BACKPROPAGATION NEURAL NETWORKS FOR MULTISOURCE SPATIAL DATA MODELING AND CLASSIFICATION </TITLE>
<AUTHOR> WANG, YEQIAO </AUTHOR>
<YEAR> 1995 </YEAR>
<INSTITUTION> THE UNIVERSITY OF CONNECTICUT; 0056 </INSTITUTION>
<DESCRIPTORS> PHYSICAL GEOGRAPHY; AGRICULTURE, FORESTRY AND WILDLIFE; REMOTE SENSING; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> NIL </ADVISER>
<CLASSIFICATIONS> LEARNING VECTOR QUANTIZATION, LAND COVER CLASSIFICATION </CLASSIFICATIONS>
<ABSTRACT>
Applications of artificial neural networks (ANN) in
remote sensing and multisource spatial data
classification have been frequently reported in the past
several years. In the previous research, backpropagation
ANN (BPANN) has commonly been applied. This popularity
primarily revolves around the ability of backpropagation
paradigm to learn complicated multidimensional mapping.
Other ANN paradigms, however, are seldom applied and
reported. Technically, the demand of development of
efficient ANN architectures for handling multisource
spatial data still remains. In multisource spatial data
land cover classification, while more information can be
supplied by those data, noise, redundancy and confusion
may also be introduced. If artificial neural network
paradigms with modular functions or competition
mechanisms can be developed, the information process for
each data source will be decomposed, and the
contribution of each data set will be separately
evaluated. Therefore, the advantages from each data
source will be discovered and efficiently employed to
perform the classification. To reach this goal, other
architectures of neural network paradigms, such as
modular artificial neural network (MANN) and learning
vector quantization (LVQ) network, are alternatives
requiring further investigation.
In this research, three network paradigms of BPANN,
MANN, and LVQ were developed and evaluated in
multisource spatial data land cover classifications.
Traditional maximum likelihood classification (MLC) was
also compared in classification performance. Multisource
spatial data in different combinations were classified
by the three ANN paradigms, respectively. Comparable
land cover classification results were achieved by BPANN
and MLC. Both MANN and LVQ networks achieved better
classification results than MLC. It is concluded that
all three artificial neural network paradigms can be
applied in high dimensional multispectral,
multitemporal, multisource spatial data classification.
With a modular design and competition mechanism, the
MANN and LVQ networks performed well and are the
reliable alternatives in multisource spatial data land
cover classification.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  3239 </NUMBER>
<ORDER>   AAI9605367 </ORDER>
<TITLE> INTELLIGENT SIMULATION CODE GENERATOR: A RELATIONAL DATABASE MANAGEMENT APPROACH </TITLE>
<AUTHOR> MALHOTRA, RASHMI </AUTHOR>
<YEAR> 1995 </YEAR>
<INSTITUTION> THE UNIVERSITY OF ALABAMA; 0004 </INSTITUTION>
<DESCRIPTORS> OPERATIONS RESEARCH; COMPUTER SCIENCE; BUSINESS ADMINISTRATION, MANAGEMENT; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> JOSEPH M. MELLICHAMP </ADVISER>
<CLASSIFICATIONS> OBJECT ORIENTED </CLASSIFICATIONS>
<ABSTRACT>
Many researchers have employed artificial intelligence
(AI) and expert systems (ES) to assist the simulation
scientist and simulation user. However, many regard AI-
based system as an expensive and somewhat inefficient
solution. These systems suffer from two inherent
problems: combinatorial explosion and extensive memory
usage. Object-oriented paradigm is a fast-growing
technique that has many advantages over conventional
knowledge-based techniques. Some of these are
extendibility, reusability, reduced code size, and the
process world view. Moreover, objects in an object-
oriented environment have one-to-one correspondence with
entities in a database management systems (DBMS). A DBMS
is an ideal tool which adds a new dimension to AI-
oriented simulation, the much-needed data handling
capabilities. Thus, utilizing AI, simulation, and
databases as a triplet provides a novel way of creating
an integrated simulation environment that combines best
of all fields.
This study utilizes these research findings to develop a
software tool that acts as a buffer, front-end between
the user and a simulation language. The software accepts
user requirements via a natural language interface and
develops a simulation model complying with the syntax
and semantics of the target simulation language.
Moreover, the generator not only generates code, but
also performs model management. The modelbase management
software maintains a systems dictionary that enables the
user to refer to all models developed so far.
Furthermore, a user can also modify these systems. The
dBASE IV package was used to develop the simulation
interface and modelbase management software; the C++
object-oriented language was utilized to develop the
knowledge-engineering software; and SIMAN was used as
the target simulation language.
The ISCG has two main advantages over simulation
languages and application-focused packages: an easy-to-
use simulation software and an extremely flexible user
interface that at any time can be extended to a larger
domain. Moreover, the ISCG provides us with a new
approach to modeling, i.e., an information-based
approach that is "user-centered," not just a "user-
friendly" approach. The ISCG offers data independence,
system independence, simulation-specific transparency,
and target language neutrality. The separation of
systems description, model definition, and model
execution enables the user to concentrate on the
modeling aspects of simulation rather than on the
details of writing computer code. The modelbase
management software "conserves" effort by storing model
descriptions in a long-term fashion. The modification
module further promotes model reusability by allowing
user to modify already constructed systems that are
otherwise treated as "throw away" items. The ISCG is
also able to overcome the limitations of an application-
specific software. The object-oriented software allows a
system designer to add new methods/routines that are
pertinent to a new domain of applications. Similarly, by
changing the target-simulation-language-specific
routines, the designer can use another target simulation
language or develop his/her own shell.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  3240 </NUMBER>
<ORDER>   AAI9604977 </ORDER>
<TITLE> NONLINEAR EQUALIZATION FOR DIGITAL RECORDING CHANNELS </TITLE>
<AUTHOR> NAIR, SAPTHOTHARAN KRISHNAN </AUTHOR>
<YEAR> 1995 </YEAR>
<INSTITUTION> UNIVERSITY OF MINNESOTA; 0130 </INSTITUTION>
<DESCRIPTORS> ENGINEERING, ELECTRONICS AND ELECTRICAL; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> JAY MOON </ADVISER>
<CLASSIFICATIONS> DECISION FEEDBACK, NEURAL NETWORK </CLASSIFICATIONS>
<ABSTRACT>
In the first part of the thesis, a model for digital
magnetic recording on thin-film media is developed. The
performances of several detector/run-length-limited code
combinations are compared under different user
densities, media noise, offtrack interference and
channel mismatch conditions using this model with a
magneto-resistive (MR) head response. The detection
algorithms considered for this simulation study include
the partial response maximum likelihood (PRML)
detectors, decision feedback equalizer (DFE) and fixed-
delay tree search with decision feedback (FDTS/DF)
detector.
Next, nonlinear equalizers based on a multilayer
perceptron (MLP) neural network are proposed as a
replacement for the conventional linear equalizers for
improved data detection performance in the presence of
nonlinear channel distortions. offtrack interference and
media noise. The MLP equalizers are designed by training
using a novel criterion to reduce the probability of
detection error. We first evaluate the effects of
various types of channel impairments on the nonlinear
MLP equalizers using the channel simulator.
Subsequently, we test their performance on an
experimental set-up consisting of a thin-film disk and
an MR head. Timing and gain control are also developed
for the MLP equalizers. Hardware-efficient architectures
for VLSI implementation are also proposed. We
demonstrate that the MLP equalizers and their simplified
versions have superior performance in comparison with
the conventional linear equalizers in a realistic
recording channel.
Finally, we present methods to systematically design and
evaluate a feed-forward neural network detector from the
knowledge of the characteristics of the nonlinear
channel. The superiority of the nonlinear schemes are
demonstrated by theoretical computation.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  3241 </NUMBER>
<ORDER>   AAI9604853 </ORDER>
<TITLE> ULTRASONIC NEURAL NETWORKS FOR AGRICULTURAL MACHINERY POSITION SENSING  </TITLE>
<AUTHOR> ZHENG, DAHUA </AUTHOR>
<YEAR> 1995 </YEAR>
<INSTITUTION> NORTH CAROLINA STATE UNIVERSITY; 0155 </INSTITUTION>
<DESCRIPTORS> ENGINEERING, AGRICULTURAL; ENGINEERING, INDUSTRIAL; ENGINEERING, ELECTRONICS AND ELECTRICAL; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> ROGER P. ROHRBACH </ADVISER>
<CLASSIFICATIONS> AUTOMATION </CLASSIFICATIONS>
<ABSTRACT>
The purpose of the research has been to develop an
automatic position control system for agricultural
machinery. This research was conducted to prototype a
multisensor ultrasonic ranging system for automatic
position control of blueberry bush pruning. In this
study, multiple ultrasonic transducers in conjunction
with neural networks were used to provide a positional
reference signal that could be used for automatic
machine control.
An experimental apparatus was designed and implemented.
This apparatus consists of six Polaroid ultrasonic
transducers. The elapsed times between the initial
transmissions of chirps and the returning echoes were
used to estimate the shape of targets. Neural network
models, which represent a mapping function of the time
intervals and blueberry bush pruning control center
(BBPCC), were trained and used to compute the BBPCC of
blueberry bushes. A modular design method was developed
to speed up the training phase of a neural network. This
method reduced the neural network training time by more
than 50%. Artificial designed targets and real "dead"
blueberry samples were used to determine the accuracy of
the system.
Results reveal that the blueberry bush pruning control
center can be experimentally determined to within an
error range of $pm0.8$ inches. In real bush testing, it
was observed that outstretched branches which are
parallel or nearly parallel to the system centerline
reflect no echoes to the transducers. In these cases,
the system gives a positional reference which is closer
to our human observation for the pruning control center.
The outstretched branches which are parallel or nearly
parallel to the system centerline will be cut off during
the first pruning.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  3242 </NUMBER>
<ORDER>   AAI9604776 </ORDER>
<TITLE> A FUZZY DECISION SUPPORT SYSTEM: APPLICATION TO PETROLEUM EXPLORATION </TITLE>
<AUTHOR> LI, LI-HUA </AUTHOR>
<YEAR> 1995 </YEAR>
<INSTITUTION> THE UNIVERSITY OF ALABAMA; 0004 </INSTITUTION>
<DESCRIPTORS> COMPUTER SCIENCE; ENGINEERING, PETROLEUM; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> HUI-CHUAN CHEN </ADVISER>
<CLASSIFICATIONS> NIL </CLASSIFICATIONS>
<ABSTRACT>
This dissertation presents a new approach for handling
decision-making problems when (1) the information
obtained is fuzzy, (2) no voluminous statistical data
are available, and (3) the decision process relies on
expert's knowledge. The proposed approach is based on
fuzzy multicriteria decision-making paradigm and is
designed to assist managerial and strategic level
decision making in an organization.
Three scenarios in the decision-making paradigm are
studied: (1) single decision maker with multiple
criteria, (2) single decision maker with higher-order
criteria, and (3) multiple decision makers with multiple
criteria. These studies employ fuzzy sets to handle
incomplete and uncertain information. The decision
reasoning is carried out using fuzzy logic. The
framework to model a decision-making problem is first
presented. The relationship among the criteria, not
considered in the traditional decision-making theory, is
studied and represented by using if-then rules and
higher-order structures. The if-then rules are utilized
to describe the criteria relationship as well as to
represent expert's knowledge, whereas higher-order
structures are used to distinguish prioritized criterion
and important criterion.
It is noted that one of the primary issues in group
decision making is the consensus technique. This
research proposes a new aggregating technique that maps
the confidence value or belief value to a consensus
space to obtain a consensus degree of the concerned
criterion. The consensus term for each criterion is
thereby generated by utilizing the Dempster's Rule of
Combination. The overall decision outcome yields a
linguistic solution and a corresponding conformity
degree.
Based on the proposed model and techniques, a fuzzy
decision support system, XPROS, is constructed to
demonstrate the applicability and the reliability of the
approach. The input and the output of this system can be
linguistic terms, real numbers, or unknown data. Several
real-world test cases are used to manifest the
performance of the system.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  3243 </NUMBER>
<ORDER>   AAI9604731 </ORDER>
<TITLE> UNSUPERVISED CATEGORIZATION OF SEQUENTIAL DATA </TITLE>
<AUTHOR> GIBBONS, THOMAS EUGENE </AUTHOR>
<YEAR> 1995 </YEAR>
<INSTITUTION> NORTH DAKOTA STATE UNIVERSITY OF AGRICULTURE AND APPLIED SCIENCE; 0157 </INSTITUTION>
<DESCRIPTORS> COMPUTER SCIENCE; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> PAUL JUELL </ADVISER>
<CLASSIFICATIONS> LANGUAGE PROCESSING </CLASSIFICATIONS>
<ABSTRACT>
This dissertation developed a neural network model for
processing sequential patterns. This model is able to
recognize commonly occurring patterns in sequential data
using unsupervised learning. This is done by adding time
delay connections to a modular neural network
architecture which uses unsupervised learning. The
original architecture is CALM: Categorization And
Learning Module.
The addition of time delay connections allows
construction of networks using both the time delay
paradigm as seen in time delay networks and the
recurrent paradigm as seen in simple recurrent networks.
The basic network structure used is a self-organizing
time delay queue which is formed by connecting a series
of modules together using time delay connections. High-
level modules connected to a number of queue modules
recognize common patterns in the sequential data. The
network relies on unsupervised learning to develop
encodings both within the queue and in the high level
modules.
Simulations demonstrated the architecture's ability to
handle simple language processing problems. This
included recognizing common fourgrams in a continuous
stream of characters and recognizing words in a
continuous stream of phonemes. The network architecture
was also able to fill in missing symbols in an input
sequence generated by a small grammar. All of these
simulations were conducted using unsupervised learning.
These simulations demonstrated the potential of
unsupervised learning in conjunction with the time delay
paradigm for processing sequential patterns.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  3244 </NUMBER>
<ORDER>   AAI9604729 </ORDER>
<TITLE> TRANSFER OF KNOWLEDGE ACQUISITION SKILLS USING HYPERMEDIA: AN EXAMINATION OF LEARNER CHARACTERISTICS AND THEIR INFLUENCE </TITLE>
<AUTHOR> BLAND, KAREN ELAINE </AUTHOR>
<YEAR> 1995 </YEAR>
<INSTITUTION> THE GEORGE WASHINGTON UNIVERSITY; 0075 </INSTITUTION>
<DESCRIPTORS> COMPUTER SCIENCE; EDUCATION, TECHNOLOGY; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> JAY LIEBOWITZ </ADVISER>
<CLASSIFICATIONS> NIL </CLASSIFICATIONS>
<ABSTRACT>
The main objective of this study was to examine the
efficacy of hypermedia as a means for transferring skill
knowledge in the area of knowledge-based systems
development. The focus of this study was not on the
effectiveness of hypermedia in transferring skill
knowledge; rather, it was to explore the processes that
result in efficacy. Thus, the study examined why
knowledge transfer did or did not occur; what processes
and learner attributes contributed to adequate transfer;
how students learn using hypermedia; and the
relationship between this learning process and learner
characteristics.
The study method was a multiple case study design using
a multifaceted data collection plan to provide for both
method and instrument triangulation. A hypermedia system
called the Knowledge Acquisition Research and Teaching
Tool (KARTT) was provided to five graduate students
enrolled in one knowledge-based system development
course and two graduate students enrolled in an
independent research course in the Department of
Management Science at the George Washington University.
Each of these cases was examined over the course of
seventeen weeks.
Study findings suggest distinct relationships among
motivational factors, learning strategies, and learning
outcomes. Analysis revealed a relationship between
learner cognitive style and modeling abilities. The
findings also provided insight into the relationship
between navigational patterns and student learning
intentions.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  3245 </NUMBER>
<ORDER>   AAI9604670 </ORDER>
<TITLE> COMPETITIVE RECURRENT NEURAL NETWORK MODEL FOR CLUSTERING OF MULTISPECTRAL DATA </TITLE>
<AUTHOR> AMARTUR, SUNDAR C. </AUTHOR>
<YEAR> 1995 </YEAR>
<INSTITUTION> CASE WESTERN RESERVE UNIVERSITY; 0042 </INSTITUTION>
<DESCRIPTORS> ENGINEERING, ELECTRONICS AND ELECTRICAL; COMPUTER SCIENCE; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> YOSHIYASU TAKEFUJI </ADVISER>
<CLASSIFICATIONS> MEDICAL INFORMATICS, DATA COMPRESSION, IMAGE PROCESSING </CLASSIFICATIONS>
<ABSTRACT>
Clustering and categorization constitute two important
elements in the field of numerical taxonomy of data and
find application in many engineering problems. In this
thesis we have introduced a constraint satisfying neuron
model for clustering of multi-spectral data. The
proposed method overcomes some of the problems
encountered with the Hopfield network. We have also
compared this method with another neuron model known as
the normalized mean field annealing or Potts neuron
which also has the implicit property of satisfying the
problem constraints. A detailed convergence analysis of
the proposed model is given. The method was tested with
a benchmark data, three sets of multi-dimensional
magnetic resonance images, and a set of remotely sensed
satellite images. An analysis of the performance of this
method with maps representing the classification results
are also presented. From the results we conclude that
the proposed method is fast and provides accurate
clustering of multi-dimensional data.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  3246 </NUMBER>
<ORDER>   AAG1379856 </ORDER>
<TITLE> AN EXPERT SYSTEM FOR THE DIAGNOSIS AND TREATMENT OF ANEMIA </TITLE>
<AUTHOR> KANTHETI, SUSMITHA </AUTHOR>
<YEAR> 1995 </YEAR>
<INSTITUTION> UNIVERSITY OF LOUISVILLE; 0110 </INSTITUTION>
<DESCRIPTORS> COMPUTER SCIENCE; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> A. H. DESOKY; R. K. RAGADE </ADVISER>
<CLASSIFICATIONS> NIL </CLASSIFICATIONS>
<ABSTRACT>
The potential for use of expert systems in the clinical
laboratory as a diagnostic tool or as a decision support
system is enormous. The diagnosis of anemia is a common
clinical problem that lends itself to expert system
analysis. Based on the Complete Blood Count (CBC) report
and other follow-up tests the expert system classifies
the anemic state of the patient as Iron Deficiency
Anemia, Thalassemia, Anemia of Chronic Diseases,
Hemolytic Anemia, Megaloblastic Anemia or other
disorder.
The expert system developed is a sub-system (the second
phase) of the "HEMATOLOGIST" application, the goal of
which is to provide diagnosis for all hematologic
diseases and/or disorders. The expert system is a rule-
based system and is implemented in C Language Integrated
Production System (CLIPS). The user interface of
Hematologist application, developed using C$sp0++$, is
modified to incorporate the expert system for diagnosis
of anemia. The application is designed to be interactive
in that the user is prompted to enter the test results
and is provided with expert comments, explanations,
probabilistic information, and information about tests
and diseases.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  3247 </NUMBER>
<ORDER>   AAI9604665 </ORDER>
<TITLE> EXPLORATION AND SPATIAL LEARNING IN DYNAMIC ENVIRONMENTS </TITLE>
<AUTHOR> YAMAUCHI, BRIAN MASAO </AUTHOR>
<YEAR> 1995 </YEAR>
<INSTITUTION> CASE WESTERN RESERVE UNIVERSITY; 0042 </INSTITUTION>
<DESCRIPTORS> COMPUTER SCIENCE; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> RANDALL BEER </ADVISER>
<CLASSIFICATIONS> ROBOTICS, MACHINE LEARNING </CLASSIFICATIONS>
<ABSTRACT>
Mobile robots have the potential to be useful in a wide
variety of domains, from delivering packages in office
buildings to driving vehicles on highways to performing
reconnaissance on battlefields. If mobile robots are to
live up to their potential, they need to be able to deal
with the changes that may occur in these environments,
whether those changes consist of people walking about or
bridges being washed away. This dissertation presents
techniques developed for exploration, learning, and
navigation in dynamic environments. Adaptive place
networks, topological/metric maps incorporating variable-
confidence adjacency links, are introduced as a means
for dealing with topological changes. ELDEN is an
integrated system that combines adaptive place networks
with a reactive, behavior-based controller for dealing
with transient changes and a relocalization system for
correcting dead reckoning error. ELDEN has been
implemented on a real mobile robot and has been able to
explore and navigate successfully in a dynamic, real-
world environment. Strategies for directing exploration
are also presented, along with quantitative simulation
experiments measuring the performance of these
strategies.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  3248 </NUMBER>
<ORDER>   AAI9604652 </ORDER>
<TITLE> MULTISENSORY OBJECT RECOGNITION AND TRACKING FOR ROBOTIC APPLICATIONS  </TITLE>
<AUTHOR> OLSSON, LARS JONAS </AUTHOR>
<YEAR> 1995 </YEAR>
<INSTITUTION> CASE WESTERN RESERVE UNIVERSITY; 0042 </INSTITUTION>
<DESCRIPTORS> ENGINEERING, ELECTRONICS AND ELECTRICAL; COMPUTER SCIENCE; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> SHELDON GRUBER </ADVISER>
<CLASSIFICATIONS> COMPUTER VISION </CLASSIFICATIONS>
<ABSTRACT>
A vision system which uses 3D sensory information as
well as image intensity as input data for object
recognition algorithms is a major component of a mobile
robot guidance system. The vision system uses a special
3D range-finder that generates registered intensity and
range images. From these images the fold, jump, and
reflectivity edges in the scene are detected. The
different edge types are fused into one edge image,
forming the base for an edge-based segmentation
technique. The resulting segments in the scene are then
grouped into object regions, each likely to come from
the same object. Hypotheses for objects are formed for
each object region based on constraints on surface
features and constraints between surfaces. Each
hypothesized object's location and orientation is
estimated and the hypotheses are verified. The
verification is aided by an accurate simulator of the
real range-finder. The simulator, using ray-tracing
techniques, provides the range and intensity images that
would be generated by the real range-finder. This
verification can be done using only the sensed data.
Furthermore, the simulator can be incorporated in an
object tracking system necessary for a mobile robot. The
initial hypotheses are updated as the robot moves
through the environment, and the simulator can be used
to generate the expected scene from each new mobile
robot position. This simulated data can also be used to
segment the real range-finder data in a model-driven
manner and to select areas of the scene for selective
scanning and processing.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  3249 </NUMBER>
<ORDER>   AAI9604483 </ORDER>
<TITLE> SOME APPLICATIONS OF NON CLAUSAL DEDUCTION </TITLE>
<AUTHOR> RAMESH, ANAVAI G. </AUTHOR>
<YEAR> 1995 </YEAR>
<INSTITUTION> STATE UNIVERSITY OF NEW YORK AT ALBANY; 0668 </INSTITUTION>
<DESCRIPTORS> COMPUTER SCIENCE; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> NIL </ADVISER>
<CLASSIFICATIONS> MINIMAL DIAGNOSES, AUTOMATED REASONING, PRIME IMPLICANTS </CLASSIFICATIONS>
<ABSTRACT>
In this thesis it is shown that by using negation normal
form for representing propositional formulas, rather
than clause forms such as conjunctive and disjunctive
normal forms, reasoning systems that are more efficient
for many classes of formulas can be built. This is due
the fact that the process of converting arbitrary
propositional formulas into clause forms is an expensive
computational task.
Algorithms for two related problems in artificial
intelligence, namely computing prime implicates and
implicants, and computing minimal diagnoses are
developed and implemented. These algorithms use negation
normal form for representing proportional formulas.
These algorithms are based on dissolution, an inference
rule for negation normal form. Through theoretical and
experimental analysis it is shown that these algorithms
are superior to many clause-based algorithms.
Anti-links are defined and certain operations based on
them are introduced. By performing these operations,
many non-prime implicants/implicates and many non-
minimal diagnoses can be eliminated without doing
expensive subsumption checks. Experimental results
showing significant improvements obtained by using these
operations are also given.
An algorithm for computing prime implicants and
implicates of multiple-valued logics is also developed.
This algorithm is based on signed dissolution, an
inference rule for multiple-valued logics.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  3250 </NUMBER>
<ORDER>   AAI9604340 </ORDER>
<TITLE> INTEGRATION OF AN EXPERT SYSTEM AND DYNAMIC PROGRAMMING APPROACH TO OPTIMIZE LOG BREAKDOWN USING THREE- DIMENSIONAL LOG AND INTERNAL DEFECT SHAPE INFORMATION </TITLE>
<AUTHOR> ZENG, YIMIN </AUTHOR>
<YEAR> 1995 </YEAR>
<INSTITUTION> OREGON STATE UNIVERSITY; 0172 </INSTITUTION>
<DESCRIPTORS> AGRICULTURE, WOOD TECHNOLOGY; ENGINEERING, INDUSTRIAL; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> NIL </ADVISER>
<CLASSIFICATIONS> NIL </CLASSIFICATIONS>
<ABSTRACT>
A computer program, SAW3DG, was developed to optimize
log breakdown using 3-dimensional log and internal
defect shapes. The program was based on SAW3D, a log
breakdown optimization program considering only 3-
dimensional log shape. SAW3D was modified to include
internal log defects in 3-dimensional representation and
integrated with SLGRADER, an expert system for softwood
lumber grading, resulting in a system that is able to
optimize log breakdown based on lumber grade.
SAW3DG allows live, cant, around, and multi-thickness
sawing methods. The system uses a polygonal cross-
section model to represent the log and its internal
defects. It consists of four basic components: headrig
optimization, edging optimization, trimming
optimization, and lumber grading. The headrig
optimization component begins the log breakdown process
by mathematically rotating and skewing the log into a
position and then uses a programming (DP) algorithm to
find the optimum sawing pattern. The profile of each
piece cut from the log along with its defect information
is then passed to the edging optimization component
where the piece is optimally positioned and then edged
using another DP algorithm. Information about the
untrimmed lumber and its defects is sent to the trimming
optimization component where the sizes of each finished
piece of lumber and defects exposed on its four faces
are finally determined. This information is then sent to
the lumber grading component to determine the lumber
grade. Lumber value is determined by its grade and size
and used by a third DP algorithm to decide the optimum
trimming pattern. Solutions are provided both in text
and graphic formats. Twelve computer generated logs of
various sizes and in ellipsoid, horn-down, and S-twisted
shapes with a number of internal defect types and
distributions were used to evaluate SAW3DG. Results
indicated that SAW3DG provided better solutions than
those models that consider only the true external log
shape or that treat the log as a defect free truncated
cone. In addition, effects of log rotation and skewing
operations, flitch/cant pitch, and different sawing
methods on SAW3DG solutions were also studied.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  3251 </NUMBER>
<ORDER>   AAI9604309 </ORDER>
<TITLE> AN AGENT-BASED COCKPIT TASK MANAGEMENT SYSTEM: A TASK- ORIENTED PILOT-VEHICLE INTERFACE </TITLE>
<AUTHOR> KIM, JOONG NAM </AUTHOR>
<YEAR> 1995 </YEAR>
<INSTITUTION> OREGON STATE UNIVERSITY; 0172 </INSTITUTION>
<DESCRIPTORS> ENGINEERING, INDUSTRIAL; COMPUTER SCIENCE; PSYCHOLOGY, BEHAVIORAL </DESCRIPTORS>
<ADVISER> NIL </ADVISER>
<CLASSIFICATIONS> AIRCRAFT SAFETY </CLASSIFICATIONS>
<ABSTRACT>
Aircraft safety has long been a big issue to the public
as well as to the aviation community. Though aircraft
systems today are very reliable and air travel is
extremely safe, air accidents still occur with
disastrous results and enormous loss of life and
property. A disturbing fact is about two-thirds of all
aircraft accidents are attributable partly to pilot
errors.
In today's highly automated aircraft, the role of the
pilot has changed from an airplane controller to a
system manager. As a system manager in a cockpit,
today's pilot is in charge of a management-level
activity called cockpit task management (CTM). In
earlier studies of 470 ASRS (Aviation Safety Reporting
System) reports, CTM errors were found in almost 50
percent of the incidents. The primary objective of this
research was to reduce CTM-related pilot errors. A
prototype pilot-vehicle interface (PVI) called the
cockpit task management system (CTMS) was developed and
its effectiveness in improving CTM performance was
evaluated.
The concepts and methods of object-oriented design (OOD)
and distributed artificial intelligence (DAI) were
employed in developing the CTMS. The components of the
CTMS were implemented as software units called agents:
aircraft subsystems were represented by system agents,
and pilot tasks by task agents. After the CTMS was
implemented, it was integrated into a PC-based flight
simulator to perform an experiment to evaluate its
effectiveness.
Eight volunteer subjects were used to collect
performance data in the flight simulator. In order to
compare subject performance between flying with the CTMS
and without the CTMS, each subject flew two data-
collection scenarios in the simulator: one with the
CTMS, the other without it. The results of the
experiment indicated that a statistically significant
improvement was observed when the subjects flew with the
assistance of the CTMS.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  3252 </NUMBER>
<ORDER>   AAI9604165 </ORDER>
<TITLE> ATTENTION MODULATED ASSOCIATED COMPUTING AND CONTENT- ASSOCIATED SEARCH IN IMAGE ARCHIVE </TITLE>
<AUTHOR> KHAN, MUHAMMAD JAVED IQBAL </AUTHOR>
<YEAR> 1995 </YEAR>
<INSTITUTION> UNIVERSITY OF HAWAII; 0085 </INSTITUTION>
<DESCRIPTORS> COMPUTER SCIENCE; ENGINEERING, ELECTRONICS AND ELECTRICAL; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> DAVID Y. Y. YUN </ADVISER>
<CLASSIFICATIONS> NIL </CLASSIFICATIONS>
<ABSTRACT>
Principal result (AAM). This dissertation presents an
Artificial Associative Memory (AAM) which can learn
pattern-associations and retrieve them with changeable
attention. The attention refers to the fact that the
user can specify any subset of the elements in the
example query pattern and expect the memory to confine
its match within the specified field of attention.
Existing AAMs lack such flexibility and perform match
based on unchangeable unary attention over all the
elements of the query pattern.
Corollary 1 (dynamic attention). Unlike the existing
AAMs, in this new associative memory user can
dynamically vary the field of attention during each
query. Within the specified field of attention, it
performs statistically robust matching.
Corollary 2 (robustness). This attentive AAM can
retrieve information from very small cue. Conventional
AAMs require the effective cue in the query pattern to
be large (approximately 50% of the query frame) and
statistically dominant.
Corollary 3 (MNC feedback). It also has the unique
ability to generate a feedback (called MNC) on the
quality of match corresponding to the retrieved pattern.
Approach. In contrast to the conventional AAM, the
proposed approach is based on (i) a new representation
of information, which includes confidence, instead of
only measurement (ii) mapping of measurements on the
surface of a hypersphere, instead of on a linear
interval, and (iii) a new rule of synaptic efficacy
based on trigonometric averaging, rather than a
statistical sum. The memory is called multidimensional
holographic attentive memory (MHAC) because of its
multidimensional complex numeric representation and mode
of computation.
Application. As an application of this attentive memory
an automatic direct content-based search mechanism has
been developed for querying into image database (IDB).
For an IDB of p images of n pixels, it improves the cost
of direct content based search from O(np) to O(n.logp).
It can also use a fuzzy logic based query and inference
formalism. This mechanism avoids the problem of
representation insufficiency and inaccuracy of
intermediate model encoding and can help in
supplementing existing content based IDB query
mechanisms.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  3253 </NUMBER>
<ORDER>   AAI9604002 </ORDER>
<TITLE> FRAMEWORK FOR THE DESIGN, DEVELOPMENT, AND IMPLEMENTATION OF THE AUTOMATED FACTORY </TITLE>
<AUTHOR> GEORGE, LALJI JACOB </AUTHOR>
<YEAR> 1995 </YEAR>
<INSTITUTION> THE UNIVERSITY OF TEXAS AT ARLINGTON; 2502 </INSTITUTION>
<DESCRIPTORS> ENGINEERING, INDUSTRIAL </DESCRIPTORS>
<ADVISER> G. T. STEVENS, JR. </ADVISER>
<CLASSIFICATIONS> ROBOTICS, SAFETY ISSUES, COMMUNICATION </CLASSIFICATIONS>
<ABSTRACT>
This dissertation provides guidelines for the
development of automated factories. These guidelines
involve the following functions: (1) Planning (2)
Financial Justification (3) Personnel Issues (4)
Organization Issues (5) Computer Communication (6) Robot
and Material Handling Requirements (7) Design for
Manufacturability (8) Safety Issues (9) Artificial
Intelligence and Expert Systems (10) Other Issues.
All of these functions are discussed in general. A
detail discussion of functions 1, 2 and 9 is presented
and applied to two actual case studies.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  3254 </NUMBER>
<ORDER>   AAI9603998 </ORDER>
<TITLE> APPLICATION OF FUZZY DECISION-MAKING IN THE FACILITIES LAYOUT PROCESS </TITLE>
<AUTHOR> DWEIRI, FIKRI T. A. </AUTHOR>
<YEAR> 1995 </YEAR>
<INSTITUTION> THE UNIVERSITY OF TEXAS AT ARLINGTON; 2502 </INSTITUTION>
<DESCRIPTORS> ENGINEERING, INDUSTRIAL; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> F. A. MEIER </ADVISER>
<CLASSIFICATIONS> NIL </CLASSIFICATIONS>
<ABSTRACT>
This dissertation establishes a vigorous methodology,
based on the fuzzy set theory, to improve the facilities
layout process that has occupied scholars and
practitioners for more than four decades. Fuzzy set
theory is an appropriate tool which uses the natural
language that humans use to control complex systems such
as facilities planning. The closeness rating between
departments in a plant depends on qualitative and
quantitative factors. Some of these factors may have
greater effect on the designer's decisions of such
ratings. Thus, the pairwise comparison of the analytical
hierarchy process, which ensures the consistency of the
designers decisions when assigning the importance of one
factor over another, is used to find the weights of
these factors. FUZZY, a computer program developed based
on the fuzzy decision-making system (FDMS) is used to
generate the activity relationship charts. These charts
are used by FZYCRLP, a modified version of CORELAP, to
develop the layouts. FELAP, another program based on
FDMS is used to evaluate the layouts. The new evaluation
method uses the distances and the relationships between
departments to score the layout. The scoring system,
which ranges from zero to ten (ten is the best possible
score), can be used to evaluate and compare any layout
regardless of the number of the departments and their
size.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  3255 </NUMBER>
<ORDER>   AAI9603984 </ORDER>
<TITLE> DECOMPOSITION ABSTRACTION IN PARALLEL RULE LANGAUGES </TITLE>
<AUTHOR> WU, SHIOW-YANG </AUTHOR>
<YEAR> 1995 </YEAR>
<INSTITUTION> THE UNIVERSITY OF TEXAS AT AUSTIN; 0227 </INSTITUTION>
<DESCRIPTORS> COMPUTER SCIENCE </DESCRIPTORS>
<ADVISER> JAMES C. BROWNE; DANIEL P. MINANKER </ADVISER>
<CLASSIFICATIONS> NIL </CLASSIFICATIONS>
<ABSTRACT>
As the applications of production systems expand from
traditional artificial intelligence domains into the
data intensive and real-time arenas, program complexity
and the volume of data also increase dramatically. Over
a decade of efforts to exploit this opportunity, the
previous approaches of employing parallel match and/or
syntactic based multiple-rule-firing have failed to
raise the performance to a satisfactory level. Based on
the observations made in a pilot study, we found that by
incorporating application semantics, it is possible to
achieve a much higher level of concurrency than what can
be achieved by traditional techniques. This dissertation
presents a new approach called decomposition abstraction
that aims at the exploration of application parallelism
in production systems.
Decomposition abstraction is the process of organizing
and specifying parallel decomposition strategies. We
propose a general object-based framework and present the
formal semantics of a set of decomposition abstraction
mechanisms that are applicable to any rule language. A
semantic-based dependency analysis technique that
uncovers hidden concurrency based on a new notion of
functional dependency successfully derives parallelism
that is very difficult, if not impossible, to discover
by traditional syntactic analysis techniques.
The effectiveness of our approach is validated both by
simulation and implementation on Sequent Symmetry
multiprocessor. The performance results demonstrate the
potential of the decomposition abstraction approach to
achieve linear and scalable speedup.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  3256 </NUMBER>
<ORDER>   AAI9603866 </ORDER>
<TITLE> AUTOMATION IN COMPUTER-AIDED DESIGN:  A KNOWLEDGE-BASED SYSTEM FOR GRAPHICS ORIENTED TASKS </TITLE>
<AUTHOR> HUANG, CHIA-CHUAN ROCKSON </AUTHOR>
<YEAR> 1995 </YEAR>
<INSTITUTION> THE UNIVERSITY OF TEXAS AT AUSTIN; 0227 </INSTITUTION>
<DESCRIPTORS> ENGINEERING, MECHANICAL; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> DAVOR JURICIC </ADVISER>
<CLASSIFICATIONS> NIL </CLASSIFICATIONS>
<ABSTRACT>
The present advances in Artificial Intelligence and the
new techniques in building knowledge-based systems
promise to become a substitute for the designer
successfully in those decisions that are based on the
designer's experience, his or her knowledge of the
design rules and practices, and the specific set of
design data. This dissertation explores, develops, and
demonstrates the methodology that can be used for
automating graphics oriented tasks, e.g. the design
processes that involve interaction with geometric models
and their features. A typical task of this kind,
dimensioning of a multiview drawing, is considered in
more detail. A simple class of objects was used to
illustrate the methods involved.
The problems in implementing such a system are
identified, and the solutions are indicated.
Commercially available CAD packages and Expert System
shells were evaluated and compared with the custom made
basic system. A new mechanism was developed to formalize
the rules of the graphics oriented design tasks by
introducing parameters called geometric key-words.
Geometric features were identified for a specific
graphics oriented task. Algorithms were developed to
extract the geometric features from some simple examples
that were generated from two primitives. A decision tree
method with modular design of the knowledge base was
devised. It simplifies the automation of graphics
oriented tasks and makes the knowledge base easy to
modify when the rules change. Implementation of an
inference engine based on limited native developmental
software was pioneered. It demonstrated that an existing
CAD system can be used and the intelligence components
added to it without an excessive software writing
effort. Several new techniques had to be developed to
overcome the limitation of the native developmental
software. The results delivered from the inference
engine were incorporated back into the geometric model
to generate the final solution.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  3257 </NUMBER>
<ORDER>   AAG1379697 </ORDER>
<TITLE> DEVELOPING A COMPUTER PROGRAM IN AN ARTIFICIAL INTELLIGENCE LANGUAGE FOR PAVEMENT DESIGN INCLUDING MATERIAL AND COST ESTIMATION </TITLE>
<AUTHOR> BASHIR, MUHAMMAD </AUTHOR>
<YEAR> 1995 </YEAR>
<INSTITUTION> MICHIGAN STATE UNIVERSITY; 0128 </INSTITUTION>
<DESCRIPTORS> COMPUTER SCIENCE; ENGINEERING, CIVIL </DESCRIPTORS>
<ADVISER> CARL V. PAGE </ADVISER>
<CLASSIFICATIONS> NIL </CLASSIFICATIONS>
<ABSTRACT>
A computer program named BASHROAD has been developed in
List Programming (LISP) Language for designing different
layers of flexible pavement, using the AASHTO (American
Association of State, Highway, and Transportation
Officials) procedure for flexible pavement thickness
design, and for calculation of material quantities
required and the cost of materials and road section.
This system consists of a production rule system
(containing a structure to store the rules, a production
rule memory, a production rule handler etc.), a set of
production rules stored in the production rule memory,
and a set of functions. The functions are used for
obtaining input data from the user and to check its
validity. The production rules are designed to calculate
and display important results on the screen including
values of certain design parameters/variables, different
layer thickness of the road, material quantities
required for its construction, material cost and the
cost per lane mile and for entire road section.
The program has been tested by using different data and
gives accurate results. Overall working of this system
is also elaborated with the help of some examples.
This system is designed in order to become a part of an
anticipated expert system, using Artificial
Intelligence, in the future. The ultimate aim of this
expert system would be to find the best suitable
alignment on the digital map and design a road between
any two places such that maximum job can be done just by
using this expert system.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  3258 </NUMBER>
<ORDER>   AAI9603724 </ORDER>
<TITLE> A CELL-TO-CELL MAPPING BASED ANALYSIS AND DESIGN OF FUZZY DYNAMIC SYSTEMS AND ITS APPLICATIONS </TITLE>
<AUTHOR> PU, BING </AUTHOR>
<YEAR> 1995 </YEAR>
<INSTITUTION> THE UNIVERSITY OF ARIZONA; 0009 </INSTITUTION>
<DESCRIPTORS> ENGINEERING, SYSTEM SCIENCE; ENGINEERING, INDUSTRIAL; ENGINEERING, ELECTRONICS AND ELECTRICAL; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> FEI-YUE WANG </ADVISER>
<CLASSIFICATIONS> ROBOTICS </CLASSIFICATIONS>
<ABSTRACT>
Systematic design and analysis of fuzzy dynamic systems
has been a problem which attracted much attention from
researchers in recent years. In this dissertation, we
propose a methodology for analysis and design of fuzzy
dynamic systems. First, we introduce a new way to treat
fuzzy sets: fuzzy sets as points in fuzzy state space.
We investigate the relationship between membership
functions and their corresponding fuzzy set points in
fuzzy state space. We then examine the formulation and
stability issues of fuzzy dynamic systems based on the
geometric structure of fuzzy state space, resulting in
the generalization and extension of classical stability
definitions to fuzzy dynamic systems. We also introduce
cellular structure to fuzzy state space, allowing a
discrete cell-to-cell mapping method to be developed to
approximate a fuzzy dynamic system model. This method
leads to an efficient global behavior analysis algorithm
based on a simple cell-to-cell mapping search. Finally,
we outline the cellmapping-based search algorithm for
fuzzy optimal control design and demonstrate its
validity and advantages by applying it to time-optimal
trajectory generation for coordinated manipulator
systems with uncertain parameters.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  3259 </NUMBER>
<ORDER>   AAI9603662 </ORDER>
<TITLE> REAL-TIME TASKS SCHEDULING USING ARTIFICIAL NEURAL NETWORKS </TITLE>
<AUTHOR> TAN, TZU-CHIN </AUTHOR>
<YEAR> 1995 </YEAR>
<INSTITUTION> STATE UNIVERSITY OF NEW YORK AT BUFFALO; 0656 </INSTITUTION>
<DESCRIPTORS> ENGINEERING, ELECTRONICS AND ELECTRICAL; COMPUTER SCIENCE; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> TEIN-HSIANG LIN </ADVISER>
<CLASSIFICATIONS> NIL </CLASSIFICATIONS>
<ABSTRACT>
Task scheduling is perhaps the most important issue in
the design of a real-time system. An optimal schedule
can greatly reduce the resource requirement without
violating any real-time objective. However, the usual
dilemma is whether to bear the computational overhead
needed to pursue this optimized schedule when scheduling
real-time tasks. Traditional scheduling algorithms use
simple priority-based scheduling policy to arbitrate
among the tasks. Depending upon the priority assigned to
a task, the delay between its ready time and its
completion time (i.e. the task response time) could vary
substantially from the current iteration to the next.
The task inter-completion times under either the fixed
priority based (Rate-Monotonic) or the dynamic priority
based (Earlier-Deadline-First) algorithms are highly
sporadic, especially for tasks with lower priority or
longer period. The randomness in inter-completion
intervals stems from uneven load distribution of a set
of tasks with different periods.
The objective of this dissertation is to develop a
method to achieve periodic completions for single or
multiple tasks in fixed priority or dynamic priority
based real-time system. The scheduling environment
starts from uni-processor system and is later
generalized to a multi-processor system. The proposed
solution will be a combination of a classic scheduling
algorithm and an artificial neural network (ANN) which
approximate the proper scheduling function assists the
classic scheduler to achieve the optimized result.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  3260 </NUMBER>
<ORDER>   AAI9603508 </ORDER>
<TITLE> METHODOLOGIES FOR ESTIMATING EMISSION RATES OF HAZARDOUS GASES FROM SINGLE POINT SOURCES </TITLE>
<AUTHOR> REGE, MAHESH ANANT </AUTHOR>
<YEAR> 1995 </YEAR>
<INSTITUTION> TEXAS TECH UNIVERSITY; 0230 </INSTITUTION>
<DESCRIPTORS> ENGINEERING, CHEMICAL; ENVIRONMENTAL SCIENCES; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> RICHARD W. TOCK </ADVISER>
<CLASSIFICATIONS> ATMOSPHERIC DISPERSION </CLASSIFICATIONS>
<ABSTRACT>
In the present study, a monitoring facility for
hazardous gases was set up at Texas Tech University's
Wind Engineering Research Field Site. The major
objective of this study was to use the downwind
experimental data acquired at the field site to develop
a methodology for estimating point source emissions
rates. Experiments were carried out by releasing
controlled quantities of hydrogen sulfide (H$sb3$S) and
ammonia (NH$sb3$) in the fields adjoining the field
site. The downwind concentration of gases released
during the studies was measured using a Single Point
Monitor. The meteorological tower at the site was used
to record meteorological data such as wind speed and
direction, ambient temperature and relative humidity.
An empirical correction to the Pasquill-Gifford model
was determined which conservatively estimated emission
rates. The estimation of atmospheric stability was
studied using various methods published in literature.
Terrain specific parameters such as friction velocity
and surface roughness were determined. This approach was
validated only for direct downwind sampling and neutral
atmospheric stability. The dispersion parameters in the
Gaussian model were then modified using experimental
data.
Finally, a novel method based on the use of artificial
neural networks was also developed to model gaseous
atmospheric dispersion. This approach offers significant
potential because it does not require the accurate
determination of the numerous variables which
traditional models require. However, the neural network
must be trained over the span of variables of interest.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  3261 </NUMBER>
<ORDER>   AAI9603435 </ORDER>
<TITLE> IMPLEMENTATION OF ARTIFICIAL NEURAL NETWORKS FOR FEATURE EXTRACTION AND CLASSIFICATION OF CHROMOSOMES </TITLE>
<AUTHOR> KWON, HEBOONG </AUTHOR>
<YEAR> 1995 </YEAR>
<INSTITUTION> FLORIDA INSTITUTE OF TECHNOLOGY; 0473 </INSTITUTION>
<DESCRIPTORS> ENGINEERING, ELECTRONICS AND ELECTRICAL; BIOLOGY, MOLECULAR; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> MICHAEL H. THURSBY </ADVISER>
<CLASSIFICATIONS> NIL </CLASSIFICATIONS>
<ABSTRACT>
This dissertation presents a new approach to feature
extraction and classification of human chromosomes by
using Self-Organizing Map (SOM) and predictive Adaptive
Resonance Theory (ART) neural networks in each stage.
The chromosome images used for this dissertation are
from the Copenhagen data base. The SOM neural network
developed by Kohonen is motivated by the functionality
of the brain that self-organizes learned information. A
SOM network approximates input distributions without
prior knowledge by the ordering process of neurons
resulting from interaction of neighboring neurons during
the learning process. This property of the SOM led to
the investigation of network suitability for the
extraction of salient features inherent in chromosome
images such as length, centromere location, and band
structure. Statistical analysis has been made on the
feature sets extracted. The Euclidean Distance Map (EDM)
method, which works on a binary image encoding pixels
with the distance value from the nearest boundary point,
is used with the SOM for the centromere detection and
primarily used for the orientation finding of an object.
For the classification experiment, the predictive ART
network is considered.
Applying cluster-based mapping neural networks like
fuzzy LAPART, the adaptivity of network is easily
obtained with the freedom of clustering within classes
and supervision for mismatch correction through the
match tracking rule. For a classification experiment of
chromosomes, SPART (Simplified Predictive ART) network,
simplified version of fuzzy LAPART, is designed. An
attempt to give weighting function to the feature sets
is also made to improve the result through a better
exploitation of the feature sets. The classification
experiment, using a combination of features and weighted
feature sets, is performed. The resulting classification
rate using those features from the SOM shows promising
results and suggests a future direction. This system was
tested with 8,106 chromosome set and classified 93%
correctly.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  3262 </NUMBER>
<ORDER>   AAI9603411 </ORDER>
<TITLE> APPLICATION OF NEURAL NETWORKS IN APPROXIMATING ROBOT KINEMATICS </TITLE>
<AUTHOR> HUNG, YU-CHUNG </AUTHOR>
<YEAR> 1995 </YEAR>
<INSTITUTION> UNIVERSITY OF MISSOURI - ROLLA; 0135 </INSTITUTION>
<DESCRIPTORS> ENGINEERING, INDUSTRIAL; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> HENRY WIEBE </ADVISER>
<CLASSIFICATIONS> NIL </CLASSIFICATIONS>
<ABSTRACT>
Due to the increasing variety, complexity and accuracy
requirements of modern products, controlling a robot
manipulator in a production line has become more
difficult. Although Denavit and Hartenberg developed a 4
x 4 homogeneous transformation matrix to describe robot
kinematics relationships in 1955, the end users do not
have access to robot kinematics models, and certain
structure-manipulator parameter equations have no
equations have no unique solution or are difficult to
solve in robot kinematics when the robot has complex
structure or multiple degree of freedom.
An alternative approach for developing robot manipulator
models is to use the concepts of neural networks to
approximate the robot kinematics. This study has applied
backpropagation augmented with a Taguchi's orthogonal
array to develop a more efficient method for
approximating the robot kinematics.
Simulations were conducted on the Jumbo Drilling robot
using the Connected Network of Adaptive Processor System
(CNAPS) system. Simulation results show the following
contributions: (1) Convenience for the end users, (2)
time saving in training backpropagation networks, (3)
solution guarantee for robot kinematics equations, (4)
providing the best working area for system designers.
However, this research also shows that using orthogonal
arrays for data collection can reduce the amount of data
collection to map robot kinematics, although some
accuracy is lost with solving the inverse kinematics.
Finally, further research is recommended in order to
compensate the loss of accuracy.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  3263 </NUMBER>
<ORDER>   AAI9603359 </ORDER>
<TITLE> APPLICATIONS OF ARTIFICIAL INTELLIGENCE IN CONFORMATIONAL ANALYSIS  </TITLE>
<AUTHOR> WALTERS, WILLIAM PATRICK </AUTHOR>
<YEAR> 1995 </YEAR>
<INSTITUTION> THE UNIVERSITY OF ARIZONA; 0009 </INSTITUTION>
<DESCRIPTORS> CHEMISTRY, ORGANIC; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> DANIEL P. DOLATA </ADVISER>
<CLASSIFICATIONS> MACHINE LEARNING </CLASSIFICATIONS>
<ABSTRACT>
Conformational analysis provides a means of
understanding a wide variety of chemical interactions.
However, the complexity of the potential energy
hypersurface for large molecules has restricted the use
of conformational search in molecular modeling. The
model building, or template joining, method employed by
the WIZARD program is capable of overcoming many of the
shortcomings of commonly used conformational search
programs. While WIZARD has been shown to be widely
applicable, the program still possesses a few
limitations. This dissertation describes work done to
overcome these limitations.
When WIZARD is used to perform a conformational search
on large, flexible molecules, the number of fragment
combinations becomes very large and the conformational
search can be extremely time consuming. Section I of
this dissertation presents WIZARD III, a new version of
the WIZARD program which is capable of applying a number
of different search strategies to the conformational
analysis problem. By employing search techniques such as
genetic algorithms and simulated annealing, WIZARD III
is capable of performing extremely rapid conformational
analysis on large systems.
Any program which performs molecular modeling based on
an internal knowledge base will be only as good as the
axioms it possesses. It would be desirable to create a
program which is capable of integrating new knowledge
with minimal interaction from the user. Section II of
this thesis presents the MOUSE program, which utilizes
inductive machine learning to derive new rules of
conformational analysis. These new rules can be used to
augment WIZARD's knowledge base and improve its ability
to predict conformations.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  3264 </NUMBER>
<ORDER>   AAI9603125 </ORDER>
<TITLE> PLANNING IN AN IMPERFECT WORLD USING PREVIOUS EXPERIENCES </TITLE>
<AUTHOR> CHIU, JEN-LUNG </AUTHOR>
<YEAR> 1995 </YEAR>
<INSTITUTION> NEW YORK UNIVERSITY; 0146 </INSTITUTION>
<DESCRIPTORS> COMPUTER SCIENCE; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> ERNEST S. DAVIS </ADVISER>
<CLASSIFICATIONS> NIL </CLASSIFICATIONS>
<ABSTRACT>
This thesis studies the problem of planning and problem
solving in an unpredictable environment by adapting
previous experiences. We construct a single agent
planning system CADDY and operate it in a simple golf
world testbed. The study of CADDY combines the studies
of probabilistic, spatial, and temporal reasoning,
adapting and reusing plans, and the tradeoff between
gains and costs based on various considerations.
The CADDY planning system operates in an uncertain and
unpredictable environment. Despite limited perception,
incomplete knowledge, and imperfect motion control,
CADDY achieves its goal efficiently by finding a plan
that is already known to work well in a similar
situation and applying repair heuristics to improve it.
The capability of adapting experiences makes CADDY a
planning system with learning capability.
In this thesis, we discuss the structure of the CADDY
planning system and the results of experimental tests of
CADDY when we applied to a simulated golf world. We
compare CADDY with several other research projects on
probabilistic planners and planners which utilizes
experiences. We also discuss how CADDY can be
characterized in terms of theoretical work on plan
feasibility. Finally, we point out possible directions
of system extension and generalizations of the idea
learned from CADDY to other problem domains. Currently
CADDY is not directly applied to real-world problems,
but it shows an interesting and promising direction of
study. By combining the techniques of probabilistic
reasoning, planning, and learning, the performance of
planning on real-world domains can be improved
dramatically.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  3265 </NUMBER>
<ORDER>   AAI9602946 </ORDER>
<TITLE> ZEROTH-ORDER SHAPE OPTIMIZATION UTILIZING A LEARNING CLASSIFIER SYSTEM </TITLE>
<AUTHOR> RICHARDS, ROBERT A. </AUTHOR>
<YEAR> 1995 </YEAR>
<INSTITUTION> STANFORD UNIVERSITY; 0212 </INSTITUTION>
<DESCRIPTORS> ENGINEERING, MECHANICAL; COMPUTER SCIENCE; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> SHERI D. SHEPPARD </ADVISER>
<CLASSIFICATIONS> NIL </CLASSIFICATIONS>
<ABSTRACT>
A methodology to perform generalized zeroth-order two-
and three-dimensional shape optimization utilizing a
learning classifier system is developed and applied. To
this end, the applicability of machine learning to
mechanical engineering is investigated. Specifically,
the methodology has the objective of determining the
optimal boundary to minimize mass while satisfying
constraints on stress and geometry.
Even with the enormous advances in shape optimization no
method has proven to be satisfactory across the broad
spectrum of optimization problems facing the modern
engineer. The methodology developed in this dissertation
is based upon a classifier system (CS) and exploits the
CS's adaptability and generality. It thereby overcomes
many of the limitations of today's conventional shape
optimization techniques. A CS learns rules, postulated
as if-then statements, in order to improve its
performance in an arbitrary environment, (which for this
investigation consists of stress and mass information
from components). From this input, and from a population
of initially randomly generated rules, the classifier
system is expected to learn to make the appropriate
component shape modifications to reach a minimum mass
design while satisfying all stress constraints. The CS
learns by utilizing the design improvement success or
failure feedback.
After a review of mechanical engineering shape
optimization methods, an explanatory presentation of CSs
and their underlying genetic algorithm (GA) describes
how classifier systems learn from feedback and the GA.
With this foundation set, the coupling of the shape
optimization domain with the classifier system proceeds
to form, the Shape oPtimization via Hypothesizing
Inductive classifier system compleX (SPHINcsX). The
complex learns shape optimization by its application to
a suite of sizing optimization problems.
The most tangible artifact of this research is the
successful development of the zeroth-order shape
optimization complex. The complex proved adept at
solving both two- and three-dimensional shape
optimization problems. The research also provides a
demonstrative example of the power and flexibility of
machine learning in general and CSs in particular--how
they may be leveraged as tools for mechanical
engineering design, and insights into their proper
application.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  3266 </NUMBER>
<ORDER>   AAI9602129 </ORDER>
<TITLE> FRAGMENT ASSEMBLY IN THE AUTOMATED MOLECULAR INVENTION SYSTEM: INVENTON  </TITLE>
<AUTHOR> PITMAN, MIKE CRENSHAW </AUTHOR>
<YEAR> 1995 </YEAR>
<INSTITUTION> UNIVERSITY OF CALIFORNIA, SANTA CRUZ; 0036 </INSTITUTION>
<DESCRIPTORS> CHEMISTRY, ORGANIC; COMPUTER SCIENCE; ENGINEERING, MATERIALS SCIENCE; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> NIL </ADVISER>
<CLASSIFICATIONS> MORPHINE MIMICS, NANOTUBES, HIV PROTEASE INHIBITORS, IMMUNE DEFICIENCY </CLASSIFICATIONS>
<ABSTRACT>
Our central hypothesis is that computers, when properly
programmed, can be more creative than chemists at
inventing molecular structures. The INVENTON project is
being developed to this end. The INVENTON paradigm
places the role of creativity in the hands of the
computer. The chemist describes the design problem by
specifying objectives and constraints. INVENTON analyzes
the problem and determines its own course of action.
INVENTON carries itself through that course to the
invention of a population of molecular structures. The
chemist can then analyze the results. INVENTON works
unsupervised, and we therefore refer to it as an
automated molecular invention system.
The present work describes the development of INVENTON's
first method of molecular invention, FASM. FASM is a
fragment assembly based method that utilizes a small
library of fragments and principles of stable molecular
structure to assemble fragments into larger, more
complex structures. It works in a strictly goal-directed
fashion, assembling fragments in a stepwise manner until
all objectives and criteria are met. The methodology is
applied to three unrelated problems: morphine mimics,
self-assembling nanotubes, and HIV protease inhibitors.
FASM is found to be a very successful molecular
invention methodology. A key to the creativity and
productivity of the method is due to internal knowledge
of stable organic structure, which allows it to resolve
temporal problems on the fly that would have otherwise
lead to tactical failure. The results of the problems
investigated herein demonstrate true creativity in
molecular structure. Several structures were submitted
for patent. Morphine was reinvented.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  3267 </NUMBER>
<ORDER>   AAI9601984 </ORDER>
<TITLE> EXPERT SYSTEM APPLICATION TO SWITCHING PROCEDURES FOR ELECTRIC UTILITIES </TITLE>
<AUTHOR> SCHULZ, NOEL NUNNALLY </AUTHOR>
<YEAR> 1995 </YEAR>
<INSTITUTION> UNIVERSITY OF MINNESOTA; 0130 </INSTITUTION>
<DESCRIPTORS> ENGINEERING, ELECTRONICS AND ELECTRICAL; COMPUTER SCIENCE; ENERGY; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> BRUCE F. WOLLENBERG </ADVISER>
<CLASSIFICATIONS> NIL </CLASSIFICATIONS>
<ABSTRACT>
Operation of a power utility requires that planned
switching be done within substations. This switching
involves opening circuit breakers and line switches to
isolate and ground equipment disconnecting it from the
power grid and allowing safe conditions for work crews.
Due to the interconnections within the power system,
many possible switching sequences exist that could be
executed to isolate the equipment. However an acceptable
sequence must provide for the transfer of loads and the
adherence of safety rules. This project has created an
expert system that generates an exhaustive list of
possible switching sequences and then subjects the list
to a series of tests to evaluate each sequence's
validity, optimality and safety. The expert system can
be a resource for power personnel to help prevent human
errors that can cause loss of life, loss of load or
damage to equipment.
The heuristics necessary for the expert system were
determined with the cooperation of several power
utilities. Issues addressed are safety, transfer of
load, minimal risk to the stability of the system,
protection schemes and human factors. The switching
steps are determined through the use of topology
analysis and heuristic search. Searching for the optimal
switching sequence involves using criteria such as the
number of and risk factor of switching operations, the
load margins and the relative stability maintained for
contingencies. The output of the expert system was
reviewed by experienced personnel to insure its
correctness and optimality.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  3268 </NUMBER>
<ORDER>   AAGMM08737 </ORDER>
<TITLE> K9: AN AGENT WITH A RULE-BASED EXPERT SYSTEM </TITLE>
<AUTHOR> CROFT, JEFFREY WAYNE </AUTHOR>
<YEAR> 1995 </YEAR>
<INSTITUTION> DALHOUSIE UNIVERSITY (CANADA); 0328 </INSTITUTION>
<DESCRIPTORS> COMPUTER SCIENCE; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> NIL </ADVISER>
<CLASSIFICATIONS> NIL </CLASSIFICATIONS>
<ABSTRACT>
As technology continues to progress, information is
becoming a commodity. Because of the wealth of
information now available to the average person through
a variety of media, access to relevant and time-critical
data is becoming increasingly difficult. It is natural
to use the technology which created the problem to offer
a solution.
An agent is a computer tool which filters information or
performs routine tasks with little or no manual
intervention. K9 is a personal computer agent which
possesses knowledge about the Internet. It allows the
user to take advantage of local and remote computer
facilities without the need for underlying
comprehension.
K9 has two distinct components: a graphical user
interface and a rule-based expert system. The expert
system is intended to be general-purpose, but K9 is
distinctive in that it uses the expert system to
implement specific agent functionality. In this way,
utility is maximized, while futility is minimized.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  3269 </NUMBER>
<ORDER>   AAI9601967 </ORDER>
<TITLE> A NEURO-COMPUTATIONAL MOBILE ROBOT ARCHITECTURE FOR MAPPING LOCALIZATION AND NAVIGATION </TITLE>
<AUTHOR> MORELLAS, VASSILIOS </AUTHOR>
<YEAR> 1995 </YEAR>
<INSTITUTION> UNIVERSITY OF MINNESOTA; 0130 </INSTITUTION>
<DESCRIPTORS> ENGINEERING, MECHANICAL; ENGINEERING, ELECTRONICS AND ELECTRICAL; ARTIFICIAL INTELLIGENCE; REMOTE SENSING </DESCRIPTORS>
<ADVISER> MAX DONATH </ADVISER>
<CLASSIFICATIONS> NIL </CLASSIFICATIONS>
<ABSTRACT>
This dissertation has focused on the development of a
mobile robot architecture, which allows robots to
behaviorally mimic naturally intelligent systems. The
specific problem which is addressed is robot navigation
in unknown, unstructured and dynamically changing
environments. Our approach assumes no a priori
information: the robot perceives the environment solely
by sensing its environment as it moves.
The body of the thesis consists of three major parts:
(1) Development of a procedure which allows a robot to
develop local maps of different working environments in
real time, by processing incoming range data, (2)
Formation of view invariant representations (landmark
representations) and (3) Fuzzy classification of the
landmark representations. Formation of these maps is
obtained through the use of a Self-Organizing Mapping
(SOM) neural network. These maps represent a robot's own
local view of its surrounding environment and represent
discretized representations of the continuous world
space. View invariant representations are extracted by
processing SOMs using a logarithmic scaling procedure
which is motivated by physiological observations.
Finally, classification of landmark representations is
obtained through an Adaptive Resonance Theory (ART),
self-organizing neural network which incorporates fuzzy
learning. Classification of view invariant
representations is used to solve the problem of robot
localization. The methodology was tested and
demonstrated by using an actual mobile robot.
Overall, this research integrates ideas from two
different approaches which dominate the field of mobile
robotics: (i) Artificial Intelligence (AI) and (ii)
behavior-based robotics. Our results enhance the
behavior-based paradigm by introducing behaviors which
are biologically inspired. This last element allows us
to integrate the previous two approaches, by showing
that symbolic and non-symbolic structures which are
developed by the robotic agents themselves can coexist
in the same architecture allowing robots to be
adaptable, autonomous and intelligent.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  3270 </NUMBER>
<ORDER>   AAI9601818 </ORDER>
<TITLE> HUMAN COGNITION AND THE EXPERT SYSTEMS INTERFACE MENTAL MODELS AND EXPLANATION FACILITIES </TITLE>
<AUTHOR> AFZAL, AMIR </AUTHOR>
<YEAR> 1995 </YEAR>
<INSTITUTION> THE GEORGE WASHINGTON UNIVERSITY; 0075 </INSTITUTION>
<DESCRIPTORS> COMPUTER SCIENCE; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> MICHAEL LEE DONNELL </ADVISER>
<CLASSIFICATIONS> NIL </CLASSIFICATIONS>
<ABSTRACT>
Expert systems have been used to automate complex
decision processes, enabling a human problem-solver to
use them as an aid in making decisions. Often, these
decision would not have been possible in the time
available. The purpose of this research was to
investigate human cognition and the expert system
interface, exploring two key variables affecting
user/expert system interaction: (1) User Mental Models
and (2) the nature of the expert system Inference
Explanations. This research explored the reasoning,
problem solving and decision making processes of both
expert systems and human decision makers. The research
empirically established the variables affecting
user/expert system interaction and contributed to the
development of the theoretical relationship between
human cognition and the use of intelligent machines.
The experimental testbed consisted of an expert system
interface program that operated on a personal computer
(PC). The testbed was an event-driven program that
allowed for both textual and graphic explanation of
expert system decisions. To create different mental
models of the expert system's inference logic, the
expert system was taught in different ways to different
subject groups, using text-only, graphic-only or text-
graphic models. All subjects completed
explanation/training in only one mental model condition,
but interacted with each type of explanation mode to
solve the problems.
The testbed also recorded all subject interactions with
the expert system. For each problem, the keystrokes and
the way subjects traversed the inference tree were
captured in data files. These files were used to plot
the Problem Behavior Graphs (PBG) which described the
subject's path through the problem space for each
problem. In addition, before-task and after-task
questionnaires were completed by subjects.
The evaluation of data and questionnaires showed: (1) A
better mental model increased user/expert system
performance. Mental models improved as the conceptual
model shifted from text-based to graphic-based to
multimedia-based. (2) Multimedia (text-graphic)
explanations lead to higher performance than textual
explanation.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  3271 </NUMBER>
<ORDER>   AAI9539224 </ORDER>
<TITLE> SNACK FOOD FRYING PROCESS INPUT-OUTPUT MODELING AND CONTROL THROUGH ARTIFICIAL NEURAL NETWORKS </TITLE>
<AUTHOR> HUANG, YANBO </AUTHOR>
<YEAR> 1995 </YEAR>
<INSTITUTION> TEXAS A&M UNIVERSITY; 0803 </INSTITUTION>
<DESCRIPTORS> AGRICULTURE, FOOD SCIENCE AND TECHNOLOGY; ENGINEERING, SYSTEM SCIENCE; ENGINEERING, INDUSTRIAL; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> A. DALE WHITTAKER </ADVISER>
<CLASSIFICATIONS> NIL </CLASSIFICATIONS>
<ABSTRACT>
Automatic control can avoid the overreaction of human
operators and ensure the consistency of the product
quality. The snack food frying process is a complex
process with nonlinearity, multivariate interactions,
and a long time-lag. The input-output modeling strategy
of system identification is taken to utilize artificial
neural networks to deal with these characteristics of
the process.
A type of multilayer feedforward network with direct
linear connections between input and output layers is
introduced to evaluate the relative contributions of
linear and nonlinear components in the process dynamics.
Evaluation and analysis of this network along with the
regular multilayer feedforward network on the process
input-output data lead to the conclusion that neural
networks can characterize the process well. Further, a
procedure for neural process model identification is
established and applied to identify SISO and MIMO neural
process models based on the cross-validation of training
and testing data with the neural model complexity. For
the purpose of control, neural process one-step-ahead
and multiple-step-ahead predictors are established. The
neural process multiple-step-ahead predictions are
performed through the external recurrent neural network
which is trained by the algorithm of backpropagation
through time. Based on the neural process one-step-ahead
prediction model, a design algorithm of an internal
model controller is developed with iterative inverses at
each sampling instant using a modified version of
Newton's method and gradient descent method. The
simulated internal model process controllers are tuned
using a procedure established with three integral error
objective functions. Based on the neural process
multiple-step-ahead prediction model, a design algorithm
of a predictive controller is developed with the on-line
optimization using an approximate conjugate direction
method which is free from gradient and one-dimensional
search calculations. The simulated predictive process
control actions depend only on the calculations of the
different values of the designated objective function.
This research is a comprehensive treatment in neural
network process modeling and control in food processing
engineering. The developed methodology is capable of
handling problems in modeling and control for the given
process. The outcome of this research is expected to
extend to other similar processes in biological product
processing.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  3272 </NUMBER>
<ORDER>   AAI9539214 </ORDER>
<TITLE> PROCESS CONTROL, OPTIMIZATION, AND MODELING OF CHEMICAL SYSTEMS USING GENETIC ALGORITHMS AND NEURAL NETWORKS </TITLE>
<AUTHOR> HANAGANDI, VIJAYKUMAR </AUTHOR>
<YEAR> 1995 </YEAR>
<INSTITUTION> TEXAS A&M UNIVERSITY; 0803 </INSTITUTION>
<DESCRIPTORS> ENGINEERING, CHEMICAL; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> MICHAEL NIKOLAOU </ADVISER>
<CLASSIFICATIONS> NIL </CLASSIFICATIONS>
<ABSTRACT>
Genetic Algorithms (GAs) are emerging as powerful
alternatives to traditional optimization methods which
are too restrictive and CPU intensive. The first part of
this thesis is aimed at studying the use of GAs to solve
optimization and search problems in chemical
engineering. The simple genetic algorithm is modified by
use of a clustering algorithm to identify and dissolve
clusters so that premature convergence is prevented
while searching for global optimum. A modification of
the genetic search procedure to incorporate qualitative
objective functions is also proposed. This helps the
optimization of controllers when the figure of merit is
hard to express by mathematical expressions. The ability
of a GA to conveniently solve a mixed integer nonlinear
programming (MINLP) problem is exploited to solve
controller synthesis and design problems. A hierarchical
decomposition of the controller design problem is
proposed which helps us to formulate the controller
design problem as an MINLP problem which can be
conveniently solved by a GA.
In the second part of this thesis, the use of recurrent
neural networks in process control of nonlinear systems
is investigated. An integrated methodology is presented,
for the modeling and controller design of nonlinear
dynamical systems. An RNN is trained using plant input-
output data and is used as an observer in the design of
an exact-linearizing controller. The controller uses the
states of the RNN and measurement of plant states is not
required. The methodology was tested on both SISO and
MIMO systems and shown to perform better than a linear,
optimally tuned controller.
In the third part of this thesis, the effects of system
nonlinearity on feedback controller design are studied.
Nonlinearities can be usefully quantified by the 2-norm
for various ranges of process inputs and this knowledge
can be used to explain why and when linear controllers
are adequate. We demonstrate that a nonlinear system may
or may not necessitate the use of a nonlinear model for
control purposes. Given the significant effort required
to design and maintain nonlinear controllers a
quantitative analysis of the need for such an approach
would be a worthwhile task to complete before nonlinear
control is attempted.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  3273 </NUMBER>
<ORDER>   AAINN99856 </ORDER>
<TITLE> HYPERGRAPH REPRESENTATION FOR STRUCTURAL PATTERN RECOGNITION  </TITLE>
<AUTHOR> YANG, FENG </AUTHOR>
<YEAR> 1995 </YEAR>
<INSTITUTION> UNIVERSITY OF WATERLOO (CANADA); 1141 </INSTITUTION>
<DESCRIPTORS> ENGINEERING, SYSTEM SCIENCE; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> A. K. C. WONG </ADVISER>
<CLASSIFICATIONS> MACHINE VISION </CLASSIFICATIONS>
<ABSTRACT>
This thesis develops a new framework for structural
pattern recognition. First, a hypergraph-based theory is
developed to provide a foundation for studying
representation and recognition algorithms. Then, a
representation scheme is proposed for describing
structural pattern recognition problems. In order to
achieve recognition efficiency, the representation
emphasizes representing how to recognize a pattern,
instead of what a pattern is. It can be used effectively
and flexibly for capturing common recognition
strategies. The representation can also deal with noise
and uncertainty. In addition, the thesis develops a few
effective recognition algorithms that can make use of
the recognition knowledge and automatically select
different recognition strategies. The proposed framework
is successfully applied to both low level and high level
recognition tasks in machine vision.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  3274 </NUMBER>
<ORDER>   AAINN99838 </ORDER>
<TITLE> A MIXED-MODE VLSI IMPLEMENTATION OF ARTIFICIAL NEURAL NETWORKS FOR CHARACTER RECOGNITION </TITLE>
<AUTHOR> REHAN, SAMEH EBRAHIM </AUTHOR>
<YEAR> 1995 </YEAR>
<INSTITUTION> UNIVERSITY OF WATERLOO (CANADA); 1141 </INSTITUTION>
<DESCRIPTORS> ENGINEERING, ELECTRONICS AND ELECTRICAL; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> M. I. ELMASRY; J. HANSON </ADVISER>
<CLASSIFICATIONS> NIL </CLASSIFICATIONS>
<ABSTRACT>
Dedicated VLSI circuits, which provide a compact
implementation and a fast processing of artificial
neural networks (ANNs), can release the full power of
ANNs.
In this thesis, a combined top-down bottom-up VLSI
design methodology is proposed for implementing ANN
chips that can be used for character recognition. An XOR
ANN chip is implemented and tested to demonstrate the
main steps of the proposed VLSI design methodology. A
new incremental-learning procedure, which demonstrates
more tolerance towards input noise than the standard
procedure, is introduced.
A mixed-mode switched-resistor (SR) VLSI implementation
of ANNs is presented. A chip containing a novel
programmable SR synapse as well as a simple CMOS analog
neuron is designed, fabricated, and tested. An extended
MLP model architecture is proposed to solve multi-
character recognition problems. A parallelogram VLSI
architecture is developed to implement the ANN circuit
of the extended MLP. A complete multi-chip multi-
character ANN recognition system is proposed.
ANN model, behavioral, and circuit simulations are
performed for three prototype multi-layer perceptron
(MLP) model architectures. The first MLP solves the XOR
problem, the second MLP works as a two-character
recognizer, and the third MLP is designed as a multi-
chip three-character ANN recognition system.
This research demonstrates the feasibility of an SR CMOS
VLSI implementation of ANNs for character recognition.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  3275 </NUMBER>
<ORDER>   AAINN99834 </ORDER>
<TITLE> NEUROCOMPUTATIONAL APPROACHES TO MODELLING THE GENERATION AND CONTROL OF HUMAN LOCOMOTION </TITLE>
<AUTHOR> PRENTICE, STEPHEN DONALD </AUTHOR>
<YEAR> 1995 </YEAR>
<INSTITUTION> UNIVERSITY OF WATERLOO (CANADA); 1141 </INSTITUTION>
<DESCRIPTORS> BIOLOGY, NEUROSCIENCE; HEALTH SCIENCES, PHYSICAL THERAPY; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> A. E. PATLA </ADVISER>
<CLASSIFICATIONS> NEURAL NETWORKS, CENTRAL PATTERN GENERATOR, GAIT MODIFICATION </CLASSIFICATIONS>
<ABSTRACT>
This thesis investigated the utility of a
neurocomputational approach of modelling the locomotor
control system. Artificial neural network (ANN) models
capture some of the powerful features of biological
processing that more traditional modelling methods
cannot and are a logical choice for modelling the
control of locomotion. Two approaches to modelling were
adopted to address some basic motor control issues from
different perspectives. The strategy of the first
approach was to represent some of the control mechanisms
that have been suggested from neurophysiological
studies. The principle of Central Pattern Generators
(CPG) has been proposed as the basis for locomotor
control. Two ANN models were used to represent the
timing and information storage abilities of a CPG for
human locomotion. A timing network was created to
produce simple oscillations with a frequency that was
based on the level of tonic input representing
supraspinal activation. A shaping network was developed
to produce the complex muscle activations from the
simple oscillatory signals which represent the
fundamental locomotor rhythm. The muscle activations
predicted by this model contained the primary features
of those signals recorded from a single subject during
different walking velocities. The second approach
assumed that the nervous system plans movements on a
kinematic level and that this information could be used
to approximate the complex inputs to the locomotor
control system. An ANN model was developed which
transformed the limb kinematics into the appropriate
muscle activation time histories. This model was
developed using data from a wide spectrum of walking
conditions which included steady state walking, steps
over obstacles and various gait modifications (changes
in: cadence, step length, step width). This network was
successful in producing muscle activations which
exhibited the same magnitude and phasing as those
measured experimentally for the various walking
conditions. It is anticipated that the different
modelling approaches proposed will not only lead to a
better fundamental understanding of the locomotor
control system but also assist practical applications of
locomotor control such as the restoration of gait in
paralysed patients through functional electrical
stimulation. Improvement in these modelling techniques
will naturally follow as empirical studies gain more
information regarding how the nervous system utilizes
and codes sensory and supraspinal inputs necessary to
produce safe and adaptable walking patterns.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  3276 </NUMBER>
<ORDER>   AAINN99812 </ORDER>
<TITLE> A SUPERVISORY INTELLIGENT ROBOT CONTROL SYSTEM FOR A RELATIVE POSE-BASED STRATEGY </TITLE>
<AUTHOR> JANABI-SHARIFI, FARROKH </AUTHOR>
<YEAR> 1995 </YEAR>
<INSTITUTION> UNIVERSITY OF WATERLOO (CANADA); 1141 </INSTITUTION>
<DESCRIPTORS> ENGINEERING, ELECTRONICS AND ELECTRICAL; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> W. J. WILSON </ADVISER>
<CLASSIFICATIONS> END POINT SENSING </CLASSIFICATIONS>
<ABSTRACT>
The use of direct end point sensing/control methods can
make the current robotic systems more flexible. However,
robust operation of such robotic systems requires
intelligence integration into the end point control. The
main objective of this thesis is to provide advanced
intelligent supervisory aids to the direct end point
control at the execution level. Therefore a global
system architecture is designed and the architecture and
functions of its Supervisory Level are given in detail.
The design and implementation of the key supervisory
modules comprise the focus of the rest of this thesis.
These modules include: motion trajectory planner; grasp
planner; and automatic feature selector, which address
the major supervisory issues.
The proposed motion trajectory planner has the
capability of real-time trajectory generation and deals
effectively with local minima and kinematic
singularities. Within motion trajectory planning scheme,
novel local and global path planning methods are
proposed. The automatic grasp planner (AGP) is CAD-based
and integrates sensory constraints into (motion) grasp
planning. The grasp and motion trajectory planners are
also capable of generating end-point trajectories
relative to the task object. Automatic feature selection
is an important original contribution of this thesis.
Feature selection constraints, indices and the
algorithms for the calculation of indices are presented.
A feature selection strategy is proposed and the
implementation of a CAD-based automatic feature and
window selector (AFS) is achieved. Finally 3D motion,
grasp, and feature selection simulators are designed and
used for the simulation of the individual modules. The
simulations demonstrate the usefulness and the
effectiveness of the proposed supervisory control
system, in particular for the realization of the tasks
related to relative pose based visual servoing.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  3277 </NUMBER>
<ORDER>   AAINN99767 </ORDER>
<TITLE> UNDERWATER SIGNAL MODELING FOR SUBSURFACE CLASSIFICATION USING COMPUTATIONAL INTELLIGENCE </TITLE>
<AUTHOR> SETAYESHI, SAEED </AUTHOR>
<YEAR> 1995 </YEAR>
<INSTITUTION> TECHNICAL UNIVERSITY OF NOVA SCOTIA (CANADA); 0300 </INSTITUTION>
<DESCRIPTORS> ENGINEERING, ELECTRONICS AND ELECTRICAL; ARTIFICIAL INTELLIGENCE; PHYSICS, ACOUSTICS </DESCRIPTORS>
<ADVISER> M. E. EL-HAWARY; F. EL-HAWARY </ADVISER>
<CLASSIFICATIONS> NIL </CLASSIFICATIONS>
<ABSTRACT>
In the thesis a method for underwater layered media
(UWLM) modeling is proposed, and a simple nonlinear
structure for implementation of this model based on the
behaviour of its characteristics and the propagation of
the acoustic signal in the media accounting for
attenuation effects is designed. The model that responds
to the acoustic input is employed to test the artificial
intelligence classifiers ability.
Neural network models, the basic principles of the back-
propagation algorithm, and the Hopfield model of
associative memories are reviewed, and they are employed
to use min-max amplitude ranges of a reflected signal of
UWLM based on attenuation effects, to define the classes
of the synthetic data, detect its peak features and
estimate parameters of the media.
It has been found that there is a correlation between
the number of layers in the media and the optimum number
of nodes in the hidden layer of the neural networks. The
integration of the result of the neural networks that
classify and detect underwater layered media acoustic
signals based on attenuation effects to prove the
correspondence between the peak points and decay values
has introduced a powerful tool for UWLM identification.
The methods appear to have applications in replacing
original system, for parameter estimation and output
prediction in system identification by the proposed
networks. The results of computerized simulation of the
UWLM modeling in conjunction with the proposed neural
networks training process are given.
Fuzzy sets is an idea that allows representing and
manipulating inexact concepts, fuzzy min-max pattern
classification method, and the learning and recalling
algorithms for fuzzy neural networks implementation is
explained in this thesis. A fuzzy neural network that
uses peak amplitude ranges to define classes is proposed
and evaluated for UWLM pattern recognition. It is
demonstrated to be able to classify the layered media
data sets, and can distinguish between the peak points
for identification purposes.
Fuzzifying the extracted data set through a nonlinear
extended sigmoid type function causes an associative
memory property in the proposed networks. It has been
found that the response of the fuzzy relation rule based
network to grade of membership of fuzzified data set is
much more convincing than the case of working with crisp
or nonfuzzified data. Naturally, because of associative
memory properties of the networks, substituting mono a
connection instead of dual connections may reduce the
networks size, computation time and number of features.
The model has been tested by a real data set from
southern California sediments that were provided by the
Naval Research Laboratory. It has responded well to
identification of the sediments of the data set.
Neural networks have shown great promise in several
areas and its synergism with the fuzzy concept appears
to have a wide range of applications in data
classification for oil and natural gas explorations. The
results suggest that the application of fuzzy neural
networks in pattern recognition will enable automatic
classification of the marine data collections for
layered media identification. (Abstract shortened by
UMI.)
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  3278 </NUMBER>
<ORDER>   AAINN99298 </ORDER>
<TITLE> AUTOMATED ANALYSIS OF NUCLEAR MEDICINE IMAGES: TOWARDS ARTIFICIAL INTELLIGENCE SYSTEMS </TITLE>
<AUTHOR> SLOMKA, PIOTR JAN </AUTHOR>
<YEAR> 1995 </YEAR>
<INSTITUTION> THE UNIVERSITY OF WESTERN ONTARIO (CANADA); 0784 </INSTITUTION>
<DESCRIPTORS> HEALTH SCIENCES, RADIOLOGY; BIOPHYSICS, MEDICAL </DESCRIPTORS>
<ADVISER> TREVOR CRADDUCK </ADVISER>
<CLASSIFICATIONS> IMAGE ANALYSIS, FEATURE EXTRACTION, MYOCARDIAL PERFUSION </CLASSIFICATIONS>
<ABSTRACT>
Automated methods for the analysis of nuclear medicine
images could provide an objective diagnosis, and means
to transfer sophisticated expertise to less experienced
centres. The goal of this study was to develop software
methods for the automated analysis of (a) Quality
Control (QC) images, and (b) myocardial perfusion
tomography images.
The system for the automated analysis of QC images was
based on feature extraction algorithms, which provided
input to a higher level diagnostic expert system.
Several features characterizing QC images were defined.
Rule-based and object-oriented expert systems were
created to guide personnel in QC procedures, detect
gamma camera faults, and suggest corrective actions. An
object-oriented representation of knowledge allowed a
natural representation and classification of image
features, artefacts, and other concepts used in this
knowledge domain. The feature extraction algorithms
combined with a prototype expert system could perform
diagnosis of gamma camera faults and QC procedure errors
on a limited set of examples.
Computer-aided analysis of myocardial perfusion images
was accomplished by creating three-dimensional (3-D)
reference templates, to which patient's images could be
automatically aligned using image registration
algorithms. The templates included a normal distribution
of activity and perfusion maps corresponding to specific
coronary arteries. The quantification was done by a 3-D
region-growing procedure that outlined perfusion defects
in test-patients based on differences from the normal
templates. Alignment and quantification methods of
myocardial perfusion images were successfully tested on
a group of 168 angiographically correlated patients.
Perfusion defects were characterized in terms of numeric
parameters, thus avoiding subjective visual assessment.
The location of defects relative to the expected
hypoperfusion sites was also established.
Analytical and artificial intelligence software methods
can be used for automated interpretation of QC and
cardiac images. Object-oriented methods are suitable for
encoding the knowledge required for computer-aided
analysis of QC images. A comprehensive and fully
automated analysis of cardiac perfusion images is
possible by comparison of patient data to 3-D reference
models.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  3279 </NUMBER>
<ORDER>   AAGMM08619 </ORDER>
<TITLE> STATISTICAL AND KNOWLEDGE-BASED APPROACHES FOR SENSE DISAMBIGUATION IN INFORMATION RETRIEVAL </TITLE>
<AUTHOR> LIU, YONG </AUTHOR>
<YEAR> 1995 </YEAR>
<INSTITUTION> UNIVERSITY OF GUELPH (CANADA); 0081 </INSTITUTION>
<DESCRIPTORS> INFORMATION SCIENCE; COMPUTER SCIENCE; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> FEI SONG; MARY MCLEISH </ADVISER>
<CLASSIFICATIONS> NIL </CLASSIFICATIONS>
<ABSTRACT>
Information retrieval (IR) is concerned with automated
representation and accessing of information. Although
some existing IR systems have been shown to be as
effective as most of the manual methods, further
improvement would require the disambiguation of word
senses, since a word with multiple meanings may cause
irrelevant documents to be retrieved and different words
with the same meaning may cause relevant documents from
being retrieved.
Our contribution is to propose a new framework for IR
based on sense disambiguation using statistical and
knowledge-based approaches. We use an on-line dictionary
to convert a word into a set of senses, which are then
disambiguated through the methods of collocations, co-
occurrences, marker passing, and prior probabilities. We
further conduct experiments of these methods on a
standard test collection. Our results indicate that
there exist effective methods that can largely reduce
the number of word senses without increasing much the
rate of mistakes.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  3280 </NUMBER>
<ORDER>   AAI9604678 </ORDER>
<TITLE> KNOWLEDGE-MAPPING AMERICAN COLD WAR IDEOLOGICAL AND SITUATIONAL INFORMATION: THE EPISTEMICAL CONTENT OF UNITED STATES FOREIGN POLICY STATEMENTS IN NSC-68, IRAN 1953, AND THE DOMINICAN REPUBLIC 1965 </TITLE>
<AUTHOR> HENNESSY, DAVID JAMES </AUTHOR>
<YEAR> 1995 </YEAR>
<INSTITUTION> STATE UNIVERSITY OF NEW YORK AT ALBANY; 0668 </INSTITUTION>
<DESCRIPTORS> POLITICAL SCIENCE, INTERNATIONAL LAW AND RELATIONS; POLITICAL SCIENCE, GENERAL; HISTORY, UNITED STATES; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> NIL </ADVISER>
<CLASSIFICATIONS> NIL </CLASSIFICATIONS>
<ABSTRACT>
The Political Science community's failure to predict, or
even consider a relatively peaceful end of the Cold War
has resurrected interest in ideological influence on
American Foreign Policy. This raises questions about
'epistemical communities' and their effect on the
creation, maintenance, and downfall of political
consensus. This dissertation finds research on
'epistemical communities' is best suited for application
in historical case studies because of lack of access to
the bureaucratic process, political actors, and
government held information in present day
circumstances. However, analysts do have access to the
'epistemical content' of government released information
at their immediate disposal. This data may be
qualitatively analyzed for both explicit content and
implicit meaning.
This dissertation employs a theoretical dichotomy
between ideological and situational information with an
artificial intelligence methodology, called 'knowledge
mapping,' used in expert system construction. The
methodology is based on a decision tree-like rendering
of presidential administration material into a hierarchy
of independent and dependent textual nodes similar to
semantical grammar networks. Like those who construct
expert systems, political scientists are concerned with
fully modeling experts' analytical reasoning
(transparency) and the logical steps in their problem
solving regimen (completeness). Employment of a feedback
mechanism assists in this process. Unlike expert systems
participants, political operatives are not considered
accessible collaborators, but non-cooperative subjects
seeking to build a critical audience mass of supporters
on single issue decisions by manipulating target group
ideological predispositions. The utilization of
government secrecy and executive privilege assist a
presidential administration in implementing its favored
policy while limiting the range of debate over
alternative foreign policy options.
The theory and methodology are tested in three Cold War
case studies over the period 1950 to 1965. Primary and
secondary sources over are used to construct a
historical context for each case study, followed by a
methodological rendering of official textual material.
In an evaluation section feedback questions are
generated about the combination of ideological and
situational material to question the extent of 'expert'
transparency and completeness. In the conclusion is an
assessment of this research framework's applicability to
contemporary analysis of the American foreign policy
decisionmaking process.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  3281 </NUMBER>
<ORDER>   AAI9604450 </ORDER>
<TITLE> A COMPARISON OF PROCEDURE-ORIENTED AND OBJECT-ORIENTED PROGRAMMING PARADIGMS FOR DEVELOPMENT AND MAINTENANCE OF ACCOUNTING APPLICATIONS </TITLE>
<AUTHOR> MCKINLEY, BRIAN D. </AUTHOR>
<YEAR> 1995 </YEAR>
<INSTITUTION> KENT STATE UNIVERSITY; 0101 </INSTITUTION>
<DESCRIPTORS> BUSINESS ADMINISTRATION, ACCOUNTING </DESCRIPTORS>
<ADVISER> RAY G. STEPHENS </ADVISER>
<CLASSIFICATIONS> NIL </CLASSIFICATIONS>
<ABSTRACT>
Today's information age and decreasing response times
for business reaction in dealing with customers,
suppliers, and competitors mandate the use of
computerized information. Software development and
maintenance of accounting and other business
applications is very costly. In the late 1980's object-
oriented (OO) computing, or the object oriented
paradigm, started to become popular. To date, only a
limited amount of research has been directed to the
application of the OO paradigm for accounting
information systems.
This study applies OO concepts to the development and
maintenance of accounting information systems. Empirical
evidence is sought to demonstrate whether the OO
paradigm will provide the same benefits to accounting
information systems that it has in other fields such as
computer aided manufacturing, robotics, expert systems,
and artificial intelligence.
This study is a comparison of the applicability of the
use of procedure-oriented (PO) and object-oriented (OO)
programming paradigms for the development and
maintenance of accounting applications. Within this
study, a number of accounting applications were
developed and subsequently modified using both PO and OO
programming techniques. The results indicate that, while
the traditional PO programming paradigm is applicable to
the development and maintenance of accounting
information systems, significant benefits result from
the application of the OO paradigm.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  3282 </NUMBER>
<ORDER>   AAI9603374 </ORDER>
<TITLE> KNOWLEDGE DISCOVERY IN DATABASES WITH JOINT DECISION OUTCOMES: A DECISION-TREE INDUCTION APPROACH </TITLE>
<AUTHOR> CHANG, NAMSIK </AUTHOR>
<YEAR> 1995 </YEAR>
<INSTITUTION> THE UNIVERSITY OF ARIZONA; 0009 </INSTITUTION>
<DESCRIPTORS> INFORMATION SCIENCE; BUSINESS ADMINISTRATION, MANAGEMENT; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> OLIVIA R. LIU SHENG </ADVISER>
<CLASSIFICATIONS> NIL </CLASSIFICATIONS>
<ABSTRACT>
Inductive symbolic learning algorithms have been used
successfully over the years to build knowledge-based
systems. One of these, a decision-tree induction
algorithm, has formed the central component in several
commercial packages because of its particular
efficiency, simplicity, and popularity. However, the
decision-tree induction algorithms developed thus far
are limited to domains where each decision instance's
outcome belongs to only a single decision outcome class.
Their goal is merely to specify the properties necessary
to distinguish instances pertaining to different
decision outcome classes. These algorithms are not
readily applicable to many challenging new types of
applications in which decision instances have outcomes
belonging to more than one decision outcome class (i.e.,
joint decision outcomes). Furthermore, when applied to
domains with a single decision outcome, these algorithms
become less efficient as the number of the pre-defined
outcome classes increases. The objective of this
dissertation is to modify previous decision-tree
induction techniques in order to apply them to
applications with joint decision outcomes.
We propose a new decision-tree induction approach called
the Multi-Decision-Tree Induction (MDTI) approach. Data
was collected for a patient image retrieval application
where more than one prior radiological examination would
be retrieved based on characteristics of the current
examination and patient status. We present empirical
comparisons of the MDTI approach with the
Backpropagation network algorithm and the traditional
knowledge-engineer-driven knowledge acquisition
approach, using the same set of cases. These comparisons
are made in terms of recall rate, precision rate,
average number of prior examinations suggested, and
understandability of the acquired knowledge. The results
show that the MDTI approach outperforms the
Backpropagation network algorithms and is comparable to
the traditional approach in all performance measures
considered, while requiring much less learning time than
either approach.
To gain analytical and empirical insights into MDTI, we
have compared this approach with the two best known
symbolic learning algorithms (i.e., ID3 and AQ) using
data domains with a single decision outcome. It has been
found analytically that rules generated by the MDTI
approach are more general and supported by more
instances in the training set. Four empirical
experiments have supported the findings.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  3283 </NUMBER>
<ORDER>   AAI9602957 </ORDER>
<TITLE> AMBIGUITY IN LANGUAGE LEARNING: COMPUTATIONAL AND COGNITIVE MODELS  </TITLE>
<AUTHOR> SCHUTZE, HINRICH </AUTHOR>
<YEAR> 1995 </YEAR>
<INSTITUTION> STANFORD UNIVERSITY; 0212 </INSTITUTION>
<DESCRIPTORS> LANGUAGE, LINGUISTICS; COMPUTER SCIENCE; PSYCHOLOGY, GENERAL; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> MARTIN KAY; TOM WASOW </ADVISER>
<CLASSIFICATIONS> COGNITION </CLASSIFICATIONS>
<ABSTRACT>
This dissertation is concerned with how ambiguity and
ambiguity resolution are learned, that is, with the
acquisition of the different representations of
ambiguous linguistic forms and the knowledge necessary
for selecting among them in context. Despite much
separate research on acquisition and ambiguity, there is
little work on how successful acquisition is possible
for ambiguous forms.
The dissertation presents three models of ambiguity
acquisition. In TAGSPACE, a model of syntactic
categorization, unsupervised classification groups
tokens into syntactic categories according to
distributional similarity. An evaluation on the Brown
corpus demonstrates successful acquisition of the major
syntactic categories of English. In WORDSPACE, a model
of semantic categorization, semantic categories are
induced by unsupervised classification of associational
representations of contexts. The model achieves high
accuracy when evaluated on a set of ambiguous words in a
New York Times corpus. The third acquisition problem
addressed is subcategorization. A connectionist model
predicts subcategorization frames from lexicosemantic
representations. The model learns to form internal verb
representations depending on context (i.e. disambiguate)
and to generalize the subcategorization behavior of 178
English verbs in the Dative Alternation class.
Ambiguity is important for theories of linguistic
representation. Disambiguation is difficult with
symbolic representations since all-or-none criteria like
grammaticality or soundness eliminate few readings. In
contrast, disambiguation in both TAGSPACE and WORDSPACE
relies crucially on proximity relations that can only be
modeled by gradient representations. In
subcategorization learning, gradience solves the
transition problem, the question of how the child makes
the gradual transition from a state with little
knowledge to adult performance.
Ambiguity is also relevant for linguistic innateness.
Innate categories do not explain learnability without an
account of how they are grounded in perception. The
grounding problem is hard for ambiguous forms with their
many possible groundings. It is shown here that--
contrary to much skepticism in contemporary linguistic
theories--analogy, induction, distribution and
association are powerful sources of information and can,
in concert with general cognitive innate knowledge, but
without language-specific innate knowledge, learn
important properties of language that are thought to be
innate by many.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  3284 </NUMBER>
<ORDER>   AAI9602893 </ORDER>
<TITLE> ANTHROPOLOGY INSIDE AND OUTSIDE THE LOOKING-GLASS WORLDS OF ARTIFICIAL LIFE </TITLE>
<AUTHOR> HELMREICH, STEFAN GORDON </AUTHOR>
<YEAR> 1995 </YEAR>
<INSTITUTION> STANFORD UNIVERSITY; 0212 </INSTITUTION>
<DESCRIPTORS> ANTHROPOLOGY, CULTURAL; BIOLOGY, GENERAL; ARTIFICIAL INTELLIGENCE; COMPUTER SCIENCE; HISTORY OF SCIENCE; PHILOSOPHY </DESCRIPTORS>
<ADVISER> CAROL DELANEY </ADVISER>
<CLASSIFICATIONS> COMPLEXITY, EVOLUTION </CLASSIFICATIONS>
<ABSTRACT>
This dissertation reports on anthropological fieldwork
conducted at the Santa Fe Institute for the Sciences of
Complexity, in Santa Fe, New Mexico, among researchers
working in the nascent discipline of Artificial Life.
Researchers in this field--a multidisciplinary set of
mostly biologists, computer scientists, and physicists--
attempt to capture in computer simulations the formal
properties and evolutionary trajectories of organisms,
populations, and ecosystems. Artificial Life researchers
claim that "life" is a property of the formal
organization of matter, and they maintain that this
makes sensible the attempt to model life in a computer.
Some have found this claim so compelling that they
maintain that alterative, real, artificial life forms
can exist in the computer, and some hope that the
creation of computer life forms will expand biology's
purview to include not just life-as-we-know-it, but also
life-as-it-could-be. This dissertation provides an
ethnographic account of how Artificial Life scientists'
computational models of "possible biologies" are
inflected by their cultural conceptions and lived
understandings of gender, kinship, sexuality, race,
economy, nation, and cosmology. It follows work in the
cultural study of scientific practice and in
constructivist, feminist, and anti-racist philosophies
of science. Drawing on ethnographic interviews and
observations, as well as close studies of a few
Artificial Life computer simulations, the thesis locates
Artificial Life science as a culturally specific
enterprise which, at many moments, resonates with and is
informed by the values and practices of white middle-
class Judeo-Christian U.S. American and European
heterosexual culture. It situates changing concepts of
"nature" and "life" in Artificial Life as diagnostic of
the ways dominant Euro-American notions of "life,"
"nature," and "culture" may be reproduced, recombined,
and reconfigured in the near future.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  3285 </NUMBER>
<ORDER>   AAI1375943 </ORDER>
<TITLE> A FUZZY AND NEURAL NETWORK APPROACH FOR BREAST CANCER DIAGNOSIS </TITLE>
<AUTHOR> CHEN, CHANG-HSIU </AUTHOR>
<YEAR> 1995 </YEAR>
<INSTITUTION> UTAH STATE UNIVERSITY; 0241 </INSTITUTION>
<DESCRIPTORS> COMPUTER SCIENCE; ENGINEERING, BIOMEDICAL; ARTIFICIAL INTELLIGENCE; HEALTH SCIENCES, MEDICINE AND SURGERY </DESCRIPTORS>
<ADVISER> HENG-DA CHENG </ADVISER>
<CLASSIFICATIONS> NIL </CLASSIFICATIONS>
<ABSTRACT>
This thesis deals with an automatic grading system for
breast cancer via digitized biopsy images. A
computerized procedure using a new texture-analysis
technique for the disease risk evaluation is proposed.
Fuzzy set theory is applied for parenchymal texture
analyzing. A multilayer perceptron neural network using
a back-propagation algorithm is also adopted to classify
the experimental images into three risk groups. Finally,
a resultful comparison of breast cancer diagnosis
between the physicians' judgment and the computerized
evaluation is performed.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  3286 </NUMBER>
<ORDER>   AAI1375664 </ORDER>
<TITLE> A SATELLITE POWER SYSTEM DIAGNOSTIC TOOL USING A FUZZY SIMILARITY MEASURE </TITLE>
<AUTHOR> RITTER, GEORGE HARRISON </AUTHOR>
<YEAR> 1995 </YEAR>
<INSTITUTION> UNIVERSITY OF ALABAMA IN HUNTSVILLE; 0278 </INSTITUTION>
<DESCRIPTORS> ENGINEERING, INDUSTRIAL; COMPUTER SCIENCE; ENGINEERING, SYSTEM SCIENCE; ARTIFICIAL INTELLIGENCE; ENGINEERING, AEROSPACE </DESCRIPTORS>
<ADVISER> LESLIE D. INTERRANTE </ADVISER>
<CLASSIFICATIONS> NIL </CLASSIFICATIONS>
<ABSTRACT>
The purpose of this study is to apply the concepts of
fuzzy set theory to a knowledged-based production system
reasoning task that involves the diagnosis of a
satellite battery power system to achieve a result
(diagnosis) that has a level of "similarity" to a known
failure. A discussion of the important domain
characteristics of the battery power system domain is
presented. An Expert System model is developed using
Fuzzy CLIPS provided by The National Research Council,
Canada. The model implementation is compared to the
diagnosis of a domain expert for a selected set of
simulated input conditions. The results of this
comparison show that fuzzy sets and fuzzy inferencing
techniques provide for a valid and intuitive problem
solution using linguistic constructs for the diagnosis
of failures for this type of system.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  3287 </NUMBER>
<ORDER>   AAI1375648 </ORDER>
<TITLE> AN INTELLIGENT STRATEGY DISCRIMINATOR FOR AN AUTOMATED GUIDED VEHICLE SYSTEM </TITLE>
<AUTHOR> LATHON, RUBY DANYELLE </AUTHOR>
<YEAR> 1995 </YEAR>
<INSTITUTION> UNIVERSITY OF ALABAMA IN HUNTSVILLE; 0278 </INSTITUTION>
<DESCRIPTORS> ENGINEERING, INDUSTRIAL; OPERATIONS RESEARCH; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> LESLIE D. INTERRANTE </ADVISER>
<CLASSIFICATIONS> NIL </CLASSIFICATIONS>
<ABSTRACT>
The thrust of much simulation and artificial
intelligence work is similar: to provide a computer-
based model which aids decision-making. Both employ
representations to model some aspect of an uncertain
world, with the model being formed as a piece of
software. The goal of this study was to develop a method
by which automated material handling systems can become
more responsive to dynamic shop floor changes. This
objective was met by developing a rule-based system
which utilizes both artificial intelligence techniques
and statistical output analysis techniques to
effectively compile and evaluate multiple response
values of multiple systems.
This technique was applied to a manufacturing domain in
which nine simulation models of a large-scale
manufacturing plant, each with a different dispatching
strategy, were used to study the details of a highly
automated material handling system. A detailed
sensitivity analysis was employed to investigate the
results of exercising the models and to tie Automated
Guided Vehicle (AGV) dispatching strategies to
particular shop floor scenarios. The representation
language used to implement the model was Common LISP
(List Processing), which was run on an Apple Macintosh
II Computer with the MCL compiler and environment.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  3288 </NUMBER>
<ORDER>   AAI1375633 </ORDER>
<TITLE> NEURAL NETWORKS IN ECONOMIC FORECASTING: A STUDY OF STOCKS IN S&P 500 INDEX, FROM 1983 TO 1991 </TITLE>
<AUTHOR> D'SOUZA, EDMUND JOSEPH </AUTHOR>
<YEAR> 1995 </YEAR>
<INSTITUTION> UNIVERSITY OF LOUISVILLE; 0110 </INSTITUTION>
<DESCRIPTORS> COMPUTER SCIENCE; ECONOMICS, FINANCE; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> AHMEDH DESOKY </ADVISER>
<CLASSIFICATIONS> NIL </CLASSIFICATIONS>
<ABSTRACT>
The S&P 500 (Standard and Poor's 500) is one of the most
exhaustively studied stock indices. This thesis
investigates the use of neural networks as a tool for
forecasting the return of assets and takes the
"fundamental analysis" approach to tackle this problem.
Historic data for stocks in S&P 500 Index for the years
1983 through 1991 were obtained from COMPUSTAT data
files, and the corresponding returns were obtained from
CRSP (Center for Research in Security Prices) data
files.
Three different neural networks--backpropagation,
Learning Vector Quantization (LVQ) and Radial Basis
Function (RBF)--with different internal architecture's
were used. The input data which was used for training
the network, was preprocessed in several different ways.
The results demonstrated that neural networks can be
used as an effective tool in forecasting, and they
outperform results obtained by pure chance. Changing
network architecture will change forecast results, but
overall the forecasting ability seems to be similar.
Transforming the input data will affect the forecast of
that network. There may be ways of transforming the
input data to improve the forecasting accuracy. Also,
returns for the forecast year when calibrated
differently (ex. moving from three to four or five
outputs) could enhance the forecasting ability of the
networks.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  3289 </NUMBER>
<ORDER>   AAI1375581 </ORDER>
<TITLE> NEOCOGNITRON: APPLICATION TO THE HANDWRITTEN HINDI NUMERALS </TITLE>
<AUTHOR> BAIK, TAMBI MOHAMMAD SHARIEF </AUTHOR>
<YEAR> 1995 </YEAR>
<INSTITUTION> KING FAHD UNIVERSITY OF PETROLEUM AND MINERALS (SAUDI ARABIA); 1088 </INSTITUTION>
<DESCRIPTORS> COMPUTER SCIENCE; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> NIL </ADVISER>
<CLASSIFICATIONS> NIL </CLASSIFICATIONS>
<ABSTRACT>
Character recognition is a very important application in
the field of computer vision. The Neocognitron is a
multilayered neural network, originally designed by
Fukushima, that has the capability of pattern
recognition. Performance of the Neocognitron is not
affected by translation, scaling, or deformation of the
patterns. The objective of this thesis is to design the
Neocognitron to recognize the handwritten Hindi
numerals. A proper training set was designed that
consisted of features to be recognized at every layer.
In addition, detailed analyses were carried out to
decide on proper parameter assignments. A recognition
rate of 95% was achieved with a 5% error rate compared
to a 16% error rate reported by Fukushima. The designed
Neocognitron maintains excellent performance under noisy
environment. At 3 SNR, the Neocognitron maintains a
recognition rate of not less than 85%.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  3290 </NUMBER>
<ORDER>   AAGC539787 </ORDER>
<TITLE> ASSESSMENT AND SELF-ASSESSMENT OF TOTAL QUALITY MANAGEMENT IN ORGANISATIONS USING KNOWLEDGE-BASED TECHNIQUES </TITLE>
<AUTHOR> DOHERTY, WILLIAM </AUTHOR>
<YEAR> 1995 </YEAR>
<INSTITUTION> QUEEN'S UNIVERSITY OF BELFAST (NORTHERN IRELAND); 0725 </INSTITUTION>
<DESCRIPTORS> BUSINESS ADMINISTRATION, MANAGEMENT; ENGINEERING, INDUSTRIAL; ARTIFICIAL INTELLIGENCE BELFAST </DESCRIPTORS>
<ADVISER> NIL </ADVISER>
<CLASSIFICATIONS> NIL </CLASSIFICATIONS>
<ABSTRACT>
Total Quality Management (TQM) has been advanced as an
essential approach for improving organisational
performance, and enhancing competitiveness.
In spite of several claims of successful Total Quality
initiatives, many organisations implementing TQM have
reported disappointment with the results which they have
achieved. Some have used these apparent high failure
rates to dismiss TQM as a whole.
In this thesis it is argued that much of the discussion
of TQM success or failure is inappropriate. Most
research findings have been based on cross-sectional,
one-off, surveys, yet adequate research of this question
needs to be longitudinal in design. Moreover, some have
been quick to condemn TQM as an inadequate philosophy on
the basis of high reported failure rates. Indications
from various studies are however, that high failure
rates are by no means universal, and, the evidence
suggests that lack of success, rather than being due to
any inherent flaw in the TQM concept itself, arises more
from management failure to understand and implement it
properly.
From this there is a clear need to evaluate, or assess,
TQM practices, as a key part of the ongoing TQM
implementation strategy. This thesis examined a novel
approach to this assessment problem, proposing and
rigorously evaluating the use of a computer Knowledge
Based System (KBS). KBS offer the potential to
encapsulate in useable form, knowledge from various
sources within the TQM field, for the dynamic solution
of the assessment problem. In addition this KBS predicts
the likely outcome of TQM initiatives, given
descriptions of key organisational practices relative to
TQM implementation.
This KBS was applied to data from a sample of 113
organisations located in N. Ireland, to make predictions
on the likely success of their implementations. These
organisations were re-contacted two years later to
calculate the predictive accuracy of the knowledge based
approach, and hence enable conclusions on its
suitability as a strategic support tool for senior
managers. This study also permitted insights into TQM
practices, and how these related to the eventual success
or failure of TQM implementations, particularly for
Smaller organisations.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  3291 </NUMBER>
<ORDER>   AAGMM08490 </ORDER>
<TITLE> MARITIME RADAR TARGET DETECTION USING NEURAL NETWORKS </TITLE>
<AUTHOR> ZHU, ALMIN </AUTHOR>
<YEAR> 1995 </YEAR>
<INSTITUTION> THE UNIVERSITY OF REGINA (CANADA); 0148 </INSTITUTION>
<DESCRIPTORS> ENGINEERING, ELECTRONICS AND ELECTRICAL; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> R. MASON </ADVISER>
<CLASSIFICATIONS> NIL </CLASSIFICATIONS>
<ABSTRACT>
This thesis presents a neural network based approach to
target detection maritime radar images with sea and land
clutter scattering. Two neural network based detection
systems are presented. One is based on Back-Propagation
(BP) networks and the other on a combination of
Principal Component Analysis (PCA) and BP networks. A
PCA network is trained to extract the eigenvectors of
the covariance matrix of the sweep difference data.
These eigenvectors can be used as a new compact basis
for representing the data patterns. The BP networks are
trained to establish the internal representations of the
target and clutter patterns. Once trained, they can then
be used as target classifiers. The outputs of the two BP
networks have three components representing the
likelihood of a potential target being (a) target, (b)
sea clutter, or (c) land clutter. The PCA and BP
networks have a multislab structure where each slab is
used for a different variation range of sea clutter
echoes. A post-processing stage performs a winner-takes-
all classification and a merging of target points. The
target point merging takes place along the auzimuth
direction and reduces the number of multiple detections
for a single target. Experimental results show that
using a 6-slab 31-9-3 BP network can provide an overall
detection rate of 95.3% with lower false-alarm rates
than the conventional mean-level Constant False-Alarm
Rate (CFAR) detector. Combining a 6-slab 31-31 PCA
network (implemented using Oja's stochastic gradient
ascent algorithm) with a 6-slab 31-9-3 BP network
provides the same overall target detection rate with a
reduced false-alarm rate. Using different sizes of PCA
and BP networks, the detection results show that by
using PCA methods to compact data patterns, a small
number of data components can be used for pattern
classification while suffering a very small loss in
detection rate. (Abstract shortened by UMI.)
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  3292 </NUMBER>
<ORDER>   AAI1375532 </ORDER>
<TITLE> A NOVEL ALGORITHM FOR QUICK CONVERGENCE OF FEEDFORWARD NEURAL NETWORK </TITLE>
<AUTHOR> MOCHERLA, SASHIBHUSHAN V. L. </AUTHOR>
<YEAR> 1995 </YEAR>
<INSTITUTION> UNIVERSITY OF NEVADA, RENO; 0139 </INSTITUTION>
<DESCRIPTORS> COMPUTER SCIENCE; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> CARL LOONEY </ADVISER>
<CLASSIFICATIONS> NIL </CLASSIFICATIONS>
<ABSTRACT>
We review the methods and techniques for training
feedforward neural networks, accelerate the convergence,
minimize the sum squared error (SSE) and verify the
training. The main aim of this thesis was to remove the
sigmoidal function on the outer layer of a feedforward
neural network to accelerate the learning process. By
this method, the sum squared error is also reduced.
By implementing this new algorithm, the convergence of
feedforward neural networks was accelerated and the sum
squared error was also reduced.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  3293 </NUMBER>
<ORDER>   AAI1375524 </ORDER>
<TITLE> SPEEDING UP CONVERGENCE IN BACKPROPOGATION USING ADAPTIVE LEARNING RATES  </TITLE>
<AUTHOR> HALLETT, JOYCE KATHERINE </AUTHOR>
<YEAR> 1995 </YEAR>
<INSTITUTION> UNIVERSITY OF NEVADA, RENO; 0139 </INSTITUTION>
<DESCRIPTORS> COMPUTER SCIENCE; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> CARL LOONEY </ADVISER>
<CLASSIFICATIONS> NEURAL NETWORKS </CLASSIFICATIONS>
<ABSTRACT>
The speed of convergence for a back propagation neural
network can be improved using adaptive learning rates.
Such improvements are implemented in Version 1.16 of
NevProp, a general purpose backpropagation program
written in C. NevProp is a variant of Scott Fahlman's
Quickprop with the added options of two methods of
updating weights, and the C index and cross entropy
measures of error. Enhancements are made to the program
using various adaptive learning rates, both local and
global, to quicken the search for a suitable weight set
that produces minimum error. Results show that by
methodically changing learning rates before each weight
update there is an improvement over using constant
learning rates. This suggests that while inputs have
different measures of importance and weights reflecting
this importance change throughout training, so must the
amounts by which these weights change. Results show that
an adaptive learning rate speeds up the convergence to a
minimum in a feedforward backpropagation neural network.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  3294 </NUMBER>
<ORDER>   AAI1375310 </ORDER>
<TITLE> A NEURAL NETWORK APPROACH TO FEEDBACK LINEARIZATION </TITLE>
<AUTHOR> AL-SAHLI, KHALED A. S. </AUTHOR>
<YEAR> 1995 </YEAR>
<INSTITUTION> KING FAHD UNIVERSITY OF PETROLEUM AND MINERALS (SAUDI ARABIA); 1088 </INSTITUTION>
<DESCRIPTORS> ENGINEERING, ELECTRONICS AND ELECTRICAL; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> NIL </ADVISER>
<CLASSIFICATIONS> NIL </CLASSIFICATIONS>
<ABSTRACT>
Several methods are available for the design and
analysis of nonlinear control systems. However, each
method is best applicable to a special class of
nonlinear systems. The Feedback linearization scheme is
a powerful method, because it is based on exact
cancellation of nonlinearities. This method is, however,
only applicable to systems which are feedback
linearizable. It also has a number of limitations. In
recent years, there has been a considerable interest in
the field of artificial neural networks and its
applications in many areas. One of the application areas
is in adaptive control systems. In this thesis, the
conventional backpropagation algorithm is modified in
such a way that nonlinear systems can be controlled
directly. In this work, a multilayer neural network is
used to perform input-state feedback linearization thus
alleviating its drawbacks for a large class of nonlinear
systems, adaptive and in an on-line manner. A simulation
study supports this claim.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  3295 </NUMBER>
<ORDER>   AAI1375188 </ORDER>
<TITLE> ARTIFICIAL NEURAL NETWORK PREDICTION OF ALLUVIAL RIVER GEOMETRY </TITLE>
<AUTHOR> HOFFMAN, DAVID CARL </AUTHOR>
<YEAR> 1995 </YEAR>
<INSTITUTION> FLORIDA ATLANTIC UNIVERSITY; 0119 </INSTITUTION>
<DESCRIPTORS> ENGINEERING, HYDRAULIC; ENGINEERING, CIVIL; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> PANAGIOTIS D. SCARLATOS </ADVISER>
<CLASSIFICATIONS> NIL </CLASSIFICATIONS>
<ABSTRACT>
An artificial neural network is used to predict the
stable geometry of alluvial rivers. This knowledge is
useful for the design of new channels or modification of
natural rivers.
Given inputs of river discharge, slope and mean particle
size, an artificial neural network is trained to predict
the corresponding stable channel width and depth. The
network is trained using data from several alluvial
canals and rivers. Various factors including training
set size and composition, number of hidden layer nodes,
activation function type, and data scaling method are
analyzed as variables affecting network performance.
These factors are studied to determine impacts on
network accuracy and generalizing ability.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  3296 </NUMBER>
<ORDER>   AAI1375119 </ORDER>
<TITLE> ASSOCIATIVE MEMORY NEURAL NETWORKS FOR ERROR CORRECTION OF LINEAR BLOCK CODES </TITLE>
<AUTHOR> SAYANI, MOHAMMED ASIF </AUTHOR>
<YEAR> 1995 </YEAR>
<INSTITUTION> KING FAHD UNIVERSITY OF PETROLEUM AND MINERALS (SAUDI ARABIA); 1088 </INSTITUTION>
<DESCRIPTORS> ENGINEERING, ELECTRONICS AND ELECTRICAL; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> NIL </ADVISER>
<CLASSIFICATIONS> NIL </CLASSIFICATIONS>
<ABSTRACT>
Associative memory neural networks are used for error
correction of linear block codes. The implementation of
decoder based on neural networks does not require any
special characteristics of codes (i.e., Linearity,
cyclic nature etc.) and can decode many different types
of codes such as repetition, Hamming, BCH, RS, and other
codes. The concept of Hopfield model has been applied
for error correction of linear block codes defined over
GF(q) fields. All the codewords of length n are
considered as stable states which are used to construct
the weight matrix as defined in the Hopfield model. All
the other possible words of length n are the unstable
states. For a linear (n, k) code, the number of stable
states are 2$sp0k$ and the possible number of unstable
states (patterns) are 2$sp0n-2sp0k$. The decoder would
either map the unstable state to one of the stable
states or indicates that an error has occurred. The
error correction capability is the same as that of
classical decoding methods, that is, only limited by the
minimum distance constraints. Error correction is
applied for the codes having single and multiple error
correction capability.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  3297 </NUMBER>
<ORDER>   AAIMM99103 </ORDER>
<TITLE> FUZZY LOGIC CONTROL OF HYDRAULIC ROBOTS WITH FLOW- DEADBAND NONLINEARITIES </TITLE>
<AUTHOR> CORBET, TODD </AUTHOR>
<YEAR> 1995 </YEAR>
<INSTITUTION> THE UNIVERSITY OF MANITOBA (CANADA); 0303 </INSTITUTION>
<DESCRIPTORS> ENGINEERING, MECHANICAL; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> N. SEPEHRI </ADVISER>
<CLASSIFICATIONS> NIL </CLASSIFICATIONS>
<ABSTRACT>
Application of a fuzzy logic controller to a class of
hydraulically actuated industrial robots is investigated
in this thesis. A simple, yet effective, set of
membership functions and rules are developed to meet the
control requirements of such robots. The proposed PD-
type fuzzy controller is first examined through
simulation of a two-link hydraulic robot. The robot has
the same hydraulic configuration as many existing
industrial manipulators. It is shown that the controller
exhibits positive aspects which cannot be easily
achieved by conventional control techniques, such as a
PD controller. These aspects include a short rise-time
and a well maintained dampened response.
The fuzzy controller is then utilized on an instrumented
Unimate MK-II robot which has been retrofitted as a
research robot. An off-line routine based on the simplex
method is applied to find the best performing control
gains for different links. This is accomplished by
minimizing the summation of errors over step input
responses. The controller, although effective, is shown
to produce steady-state errors. The steady-state error
in a step input response is mainly due to the hydraulic
valve deadband in which the control action is not
effective. The steady-stat position error in a ramp
input response is shown to be due to both valve deadband
and the nature of the PD-type fuzzy controller.
In order to eliminate the steady-state errors,
conceptually simple methods are developed and applied in
parallel with the PD-type fuzzy controller. In
particular, two methods are proposed. In the first
method, a control term proportional to the integral of
error is calculated and added to the output from the
main controller. In the second method, the control
measure of the steady-state error obtained from the PD-
type fuzzy controller is used as an offset. Both actions
are activated only in a region of fuzzy zero velocity
error.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  3298 </NUMBER>
<ORDER>   AAIMM98757 </ORDER>
<TITLE> DEVELOPPEMENT D'UN PROTOTYPE DE SYSTEME EXPERT POUR L'AIDE AU DIAGNOSTIC STRATEGIQUE D'ENTREPRISE </TITLE>
<AUTHOR> CARRIER, JEAN-PIERRE </AUTHOR>
<YEAR> 1995 </YEAR>
<INSTITUTION> UNIVERSITE DE SHERBROOKE (CANADA); 0512 </INSTITUTION>
<DESCRIPTORS> BUSINESS ADMINISTRATION, MANAGEMENT; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> ANDRE THEORET </ADVISER>
<CLASSIFICATIONS> FRENCH TEXT </CLASSIFICATIONS>
<ABSTRACT>
Cette recherche demontre la faisabilite du developpement
d'un systeme expert pour l'aide au diagnostic
strategique d'entreprise, selon une perspective macro-
economique. Ce developpement repose sur l'utilisation de
methodes eprouvees, et permet d'illustrer le cheminement
employe.
Ce memoire comporte une revue de la litterature qui est
divisee en deux volets. En un premier temps, nous avons
defini le diagnostic strategique d'entreprise, analyse
les modeles conceptuels dans le domaine et etudie les
outils existants. Le second volet dresse un bref
historique de l'origine des systemes experts, analyse
leur evolution, les methodes le developpement et les
avantages et inconvenients lies a leur utilisation.
Le developpement du systeme expert a ete rendu possible
grace a la participation de deux specialistes en
diagnostic strategique. Apres avoir choisi un modele
conceptuel pertinent au domaine, nous avons procede, a
l'aide d'entrevues et d'analyses de cas biens connus des
specialistes, au developpement du systeme expert
proprement dit. Divers criteres de validation ont ete
retenus et sont clairement specifies dans le chapitre
sur la methodologie.
Les resultats temoignent de l'utilite de cet outil
d'aide et de sa fiabilite apres validation aupres des
deux specialistes. Il peut expliciter davantage le
diagnostic d'entreprise, offrir un support utile pour
cette etape, souvent negligee, contribuer a
l'amelioration du processus global de formulation
strategique et permettre au specialiste de tenir compte
de son incertitude. De plus, cet instrument pourrait
avoir une utilite comme outil pedagogique. Ce memoire
ouvre la porte a diverses recherches futures. Notamment,
la validation du prototype aupres d'un plus grand nombre
de cas et d'experts, le developpement d'un prototype
dans une perspective micro-economique, ainsi que
l'evaluation empirique et le raffinement du modele de
Miller et Theoret. (Abstract shortened by UMI.)
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  3299 </NUMBER>
<ORDER>   AAIMM98627 </ORDER>
<TITLE> DEVELOPING A KNOWLEDGE-BASED DECISION AID: THE CASE OF CASE ADOPTION </TITLE>
<AUTHOR> PHILLIPS, ROWLAND RENNISON O'CONNOR </AUTHOR>
<YEAR> 1995 </YEAR>
<INSTITUTION> CARLETON UNIVERSITY (CANADA); 0040 </INSTITUTION>
<DESCRIPTORS> BUSINESS ADMINISTRATION, MANAGEMENT; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> UMA KUMAR; VINAD KUMAR </ADVISER>
<CLASSIFICATIONS> NIL </CLASSIFICATIONS>
<ABSTRACT>
This research examines the CASE adoption decision
process. A prototype of a knowledge based tool is
developed to assist the adoption process.
The knowledge base is created through a combination of
literature search and semi structured face-to-face
interviews with individuals responsible for the adoption
decision at organizations that have adopted CASE. These
individuals serve as domain experts$sp1$. The successful
creation of the knowledge base, and the subsequent
hybrid tool demonstrate that unstructured decision
making, in general, and the CASE adoption decision,
specifically, may be aided by a knowledge based
approach. ftn$sp1$A domain expert provides expertise
which the knowledge engineer captures in a knowledge
base.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  3300 </NUMBER>
<ORDER>   AAIMM98596 </ORDER>
<TITLE> TRAINING AND DESIGN OF VLSI NEURAL NETWORKS </TITLE>
<AUTHOR> CHAMBERLAIN, GEORGE </AUTHOR>
<YEAR> 1995 </YEAR>
<INSTITUTION> CARLETON UNIVERSITY (CANADA); 0040 </INSTITUTION>
<DESCRIPTORS> ENGINEERING, ELECTRONICS AND ELECTRICAL; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> T. KWASNIESKI </ADVISER>
<CLASSIFICATIONS> NIL </CLASSIFICATIONS>
<ABSTRACT>
An examination of different hardware technology options
for the implementation of artificial neural networks
(ANNs) finds that CMOS integrated circuit technology
using analog circuit techniques is best suited for the
development of large ANNs. Numerous implementation
schemes from the literature are examined and, based on
the results, a new architecture is selected which
incorporates floating gate differential pair-based
synapses, a current-to-voltage converter-based soma, and
a transconductance amplifier-based activation function.
Since there is close coupling between the ANN hardware
and the training algorithm, both the backpropagation and
the cascade-correlation training algorithms are examined
for their suitability to the training of VLSI-
implemented ANNs. It is found that the dynamically-
generated network architecture and reduced precision
requirements of cascade-correlation render it better
suited to the training of VLSI-implemented ANNs, though
still deficient in the modelling of non-ideal synapses.
A modified cascade-correlation algorithm is proposed,
and its ability to overcome this deficiency is shown.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  3301 </NUMBER>
<ORDER>   AAI9603496 </ORDER>
<TITLE> THE STATE-SAMPLED CONTROLLER:  TRAINABLE-NETWORK CONTROL USING TRADITIONAL DESIGN AND ANALYSIS PRINCIPLES WITH AN APPLICATION TO SMALL-SATELLITE ATTITUDE CONTROL </TITLE>
<AUTHOR> SMITH, JAY LAMONT </AUTHOR>
<YEAR> 1995 </YEAR>
<INSTITUTION> UTAH STATE UNIVERSITY; 0241 </INSTITUTION>
<DESCRIPTORS> ENGINEERING, ELECTRONICS AND ELECTRICAL; ENGINEERING, AEROSPACE; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> ROBERT W. GUNDERSON </ADVISER>
<CLASSIFICATIONS> NEURAL NETWORKS </CLASSIFICATIONS>
<ABSTRACT>
The State-Sampled Network is a trainable network capable
of implementing complex control functions using low cost
computers. It is similar to the CMAC network developed
by James Albus in 1975, but is based on digital image
processing techniques and multidimensional Fourier
transforms of control functions. All linear and a wide
variety of nonlinear control laws can be shown to be
band-limited, thus supporting Albus' premise of smooth
control functions. The result is ideal spatial sampling
of control functions, thereby reducing the number of
network weights.
Training of the State-Sampled Controller, which is a
State-Sampled Network used as a controller, can be
achieved by supervised learning, parallel controller
imitation and optimization, mathematical sampling, and
sequential quadratic programming to yield a one-step-
ahead optimal controller. Training goals can be
mathematically determined by quadratic cost functions.
Training is typically faster than CMAC, can be performed
in real time, and requires substantially less memory.
Software simulation and hardware tests illustrate design
methods and characteristics of the State-Sampled
Controller. Controllers for inverted and cantilevered
pendulums and a three-axis attitude controller for a
small satellite are offered as design examples.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  3302 </NUMBER>
<ORDER>   AAGMM08489 </ORDER>
<TITLE> AUTOMATIC LEARNING OF ENGLISH PRONUNCIATION RULES </TITLE>
<AUTHOR> ZHANG, JIAN </AUTHOR>
<YEAR> 1995 </YEAR>
<INSTITUTION> THE UNIVERSITY OF REGINA (CANADA); 0148 </INSTITUTION>
<DESCRIPTORS> COMPUTER SCIENCE; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> H. HAMILTON </ADVISER>
<CLASSIFICATIONS> NIL </CLASSIFICATIONS>
<ABSTRACT>
English has the richest vocabulary of all languages in
the world. Unfortunately, the English orthography is not
systematic: the writing system does not precisely
reflect its pronunciation.
In this thesis, a machine-learning approach to
abstracting a complete set of English pronunciation
rules, including exceptions, from a computer readable
pronouncing dictionary is introduced. It is called,
Learning English Pronunciation (LEP). This thesis claims
six original contributions: (1) the LEP technique for
automatic learning of English pronunciation rules; (2)
the concept of serial correspondence; (3) the definition
of a silent morphophoneme and its symbol (-); (4) the
discovery that the cumulative frequencies of the
graphemes and sounds follows the Bradford-Zipf
distribution; (5) the $Asb0p$ test for evaluating a text-
to-IPA system; (6) run time for learning individual
graphemes.
Three major parts of the LEP system have been
implemented and tested. A complete set of pronunciation
rules with exceptions for one-syllable words is
produced. The testing results show a 97% learning
accuracy at the word level and 99% at the grapheme level
for one-syllable words. The best performance accuracy is
95.40% at the word level and 98.72% at the grapheme
level, with rules learned from 90% of the input grapheme
examples and tested on the unseen 10% of the input
grapheme examples. Rules learned from one-syllable words
are tested on multi-syllable words and the result shows
that at least 40% of the pronunciation features of the
multi-syllable words cannot be captured by one-syllable
word pronunciation rules.
With the Iterative Version Space Algorithm (IVSA), LEP
expands and contracts the learning space automatically
according to the complexity of the learning examples.
The IVSA algorithm has good noise immunity so that the
noise in the input examples is properly handled without
disturbing the learning process. (Abstract shortened by
UMI.)
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  3303 </NUMBER>
<ORDER>   AAI9603495 </ORDER>
<TITLE> DESIGN OF SELF-TUNING CONTROLLERS FOR PROCESSES HAVING MULTIPLE UNKNOWN TIME-VARYING DELAYS </TITLE>
<AUTHOR> ROJAS-MORENO, ARTURO </AUTHOR>
<YEAR> 1995 </YEAR>
<INSTITUTION> UTAH STATE UNIVERSITY; 0241 </INSTITUTION>
<DESCRIPTORS> ENGINEERING, ELECTRONICS AND ELECTRICAL; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> ROBERT W. GUNDERSON </ADVISER>
<CLASSIFICATIONS> NIL </CLASSIFICATIONS>
<ABSTRACT>
An adaptive control system must be able to retain
certain stability properties in the presence of modeling
errors and a wide class of disturbances. In view of
these properties, a large amount of research is being
performed in that field. However, no significant
research is currently being developed in the issue of
adaptive controllers for multiple-input-multiple-output
(MIMO) processes having multiple unknown time-varying
delays. The purpose of this dissertation is to bridge
this gap by designing self-tuning controllers for such
processes.
MIMO time-delay processes may be accurately represented
by high-order difference-differential equations, where
the presence of delay terms complicates the analytical
aspects of control design and makes good control more
difficult to achieve. However, using a new modeling
approach, based on high-order process models, it is
possible to derive a simple delay-free model capable of
capturing significant features of the actual process. In
such a model, the effect of time delays on the process
can be modeled employing a small number of low-order
rational approximations. The resulting delay-free model
can be transformed into minimal multiple-input-single-
output (MISO) representations, which decrease the number
of model parameters. Such representations are also
required in order to apply single-input-single-output
(SISO) parameter estimation methods and delay-free MIMO
control algorithms.
This dissertation develops two new design approaches for
discrete multi-variable self-tuning controllers, which
are able to stabilize MIMO time-delay processes. Such
approaches assume that all process states, disturbances,
and parameters are unknown. Therefore, on-line
procedures to estimate states and disturbances will be
developed. Process model parameters will be estimated
using two enhanced recursive extended least squares
(RELS) methods: the normalized RELS (NRELS) method and
the improved RELS (IRELS) method.
The first design approach will be called a weak self-
tuning controller (WSTC). It combines the delay-free
MISO state-space description, the NRELS method, and the
extended minimum variance state-space controller
(EMVSSC). A WSTC is able to control open-loop stable
processes (which may also be nonminimum-phase and may
possess multiple unknown time-varying delays) operating
in the presence of colored noise sequences.
The second design approach will be called a strong self-
tuning controller (SSTC). It combines the IRELS method,
the delay-free MISO state-space representation, and a
control algorithm. This control algorithm combines the
stochastic part of an EMVSSC with a proportional-
integral linear-quadratic state-space feedback
controller (PI-LQSSFC). The SSTC is able to control open-
loop stable processes and a certain class of open-loop
unstable processes operating in the presence of a wide
class of disturbances. Such processes may also be
nonminimum-phase and may exhibit multiple unknown time-
varying delays.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  3304 </NUMBER>
<ORDER>   AAI9602374 </ORDER>
<TITLE> LEARNING TO TRANSLATE: A PSYCHOLINGUISTIC APPROACH TO THE INDUCTION OF GRAMMARS AND TRANSFER FUNCTIONS </TITLE>
<AUTHOR> JUOLA, PATRICK </AUTHOR>
<YEAR> 1995 </YEAR>
<INSTITUTION> UNIVERSITY OF COLORADO AT BOULDER; 0051 </INSTITUTION>
<DESCRIPTORS> COMPUTER SCIENCE; LANGUAGE, LINGUISTICS; PSYCHOLOGY, GENERAL; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> JAMES A. MARTIN </ADVISER>
<CLASSIFICATIONS> NIL </CLASSIFICATIONS>
<ABSTRACT>
Human language is one of the most intricate and complex
systems with which scientists have tried to work. Many
projects have foundered on the complexity of natural
language and the difficulties of describing, in a
principled way, its regularities and its idiosyncracies.
Mathematical formalisms capable of describing its
generality have proven infeasible to learn.
Machine translation, translating automatically from one
(natural) language to another, is in an even deeper
hole, because of the difficulties of dealing with two
sets of idiosyncracies simultaneously. In theory, all
the information that a translator needs can be obtained
from a set of already translated text--but it has proven
very difficult and time consuming to write programs that
are capable of working with this sort of information,
and the most successful systems use naive and
linguistically implausible formulations that are almost
impossible to understand, modify, or use.
Linguistic typologists and psycholinguists have
identified many constraints on the form and processing
of human languages. By incorporating these constraints
into a language learning system, it is possible to build
a system that learns to translate (infers functions and
grammars for machine translation) from an aligned
bilingual corpus of sentences using understandable,
symbolic linguistic principles and representations. This
work focuses on one particular constraint, the Marker
Hypothesis, which is shown to be powerful,
understandable, and computationally accessible.
This hypothesis has been incorporated into a family of
systems that infer such transfer functions using
standard multivariate optimization techniques. These
systems have been tested on a variety of language pairs
and corpora, demonstrating the language and corpus
independence of this approach. Furthermore, the design
principles are in theory independent of any particular
inference technique or grammatical representation and
reflect only the constraints of the Marker Hypothesis
and similar psycholinguistic principles.
Because of the symbolic nature of this approach, the
transfer functions learned are easy for non-
mathematicians to use and modify. It is equally easy to
apply other sources of linguistic information to help
speed and direct the learning task. This can make the
task of developing machine translation systems much
simpler and represents a significant improvement over
the current state of the art.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  3305 </NUMBER>
<ORDER>   AAI9602260 </ORDER>
<TITLE> DESIGNING AND PARTITIONING ADAPTIVE STEP SIZE NEURAL NETWORKS, AND NEURAL NETWORK HIDDEN CONSTRAINTS </TITLE>
<AUTHOR> CHRIST, JOHN FURY </AUTHOR>
<YEAR> 1995 </YEAR>
<INSTITUTION> CLEMSON UNIVERSITY; 0050 </INSTITUTION>
<DESCRIPTORS> COMPUTER SCIENCE; ENGINEERING, ELECTRONICS AND ELECTRICAL; BIOLOGY, NEUROSCIENCE; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> EDWARD W. PAGE, III </ADVISER>
<CLASSIFICATIONS> NIL </CLASSIFICATIONS>
<ABSTRACT>
Several barriers prohibit the use of neural networks as
a general purpose method for solving difficult
computational problems. This research addresses the
barriers--scalability, parallel partitioning, and hidden
constraints. It includes the analysis of three classes
of neural network solutions to optimization problems.
These classes are overlapping subsets of problems that
can be solved by Hopfield neural networks.
The first class is amenable to a design rule that
partitions the network across parallel processors in a
way that not only parallelizes the computation but
reduces communication between processors. The benefits
of this partitioning methodology are its applicability
to a large class of problems and a reduction in
algorithmic complexity.
The second class is amenable to an update function that
corresponds to a Hopfield neural network enhanced by an
adaptive step size in the simulation. This model gives
superior results as compared to Hopfield networks and
Greedy algorithms over two orders of magnitude in
network size.
The third class exhibits sub-optimal performance due to
artificial limitation of the solution space by hidden
constraints. A method for determining whether or not
hidden constraints may exist is presented.
A neural representation of the weapon-to-target
assignment problem exemplifies all three classes of
neural networks. The theoretical implications are
explored and are supported by the compilation of network
simulations over two orders of magnitude in network
size.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  3306 </NUMBER>
<ORDER>   AAI9602210 </ORDER>
<TITLE> ON AUGMENTING AN EXPERT SYSTEM WITH NEURAL NETWORKS USING CERTAINTY FACTORS </TITLE>
<AUTHOR> MITCHELL, ROGER VAN </AUTHOR>
<YEAR> 1995 </YEAR>
<INSTITUTION> THE UNION INSTITUTE; 1033 </INSTITUTION>
<DESCRIPTORS> COMPUTER SCIENCE; ENGINEERING, NUCLEAR; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> NIL </ADVISER>
<CLASSIFICATIONS> NIL </CLASSIFICATIONS>
<ABSTRACT>
This study addresses the application of neural networks
and expert systems to assess accident scenarios at
nuclear power plants. It also demonstrates a unique way
to combine neural networks and expert systems into a
hybrid system for analyzing nuclear plant transients.
Hybrid expert systems are developed based on the
backpropagation neural network and a newly developed
analog associative memory neural network. The neural
networks observe deviations from expected patterns in
the input data and calculate certainty factors based on
these deviations. The calculated certainty factors are
used to mark the data going to the expert system as
good, suspect, or invalid where appropriate.
The hybrid expert systems are compared with a
conventional expert system for diagnosing simulated
nuclear plant transients. The transients are repeated
with sensor failures having the most impact to the
proper diagnosis of the event. The hybrid expert system
based on the analog associative memory is the only
system that did not misdiagnose an event due to a failed
instrument.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  3307 </NUMBER>
<ORDER>   AAI9602043 </ORDER>
<TITLE> A NEURAL NETWORK BASED APPROACH FOR SOLVING THE GENERALIZED CELL FORMATION PROBLEM </TITLE>
<AUTHOR> EL-BAWAB, NASER FAYEZ </AUTHOR>
<YEAR> 1995 </YEAR>
<INSTITUTION> WICHITA STATE UNIVERSITY; 0260 </INSTITUTION>
<DESCRIPTORS> ENGINEERING, INDUSTRIAL; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> ABU S. M. MASUD </ADVISER>
<CLASSIFICATIONS> MACHINE DUPLICATION, INTELLIGENT MANUFACTURING </CLASSIFICATIONS>
<ABSTRACT>
The fundamental problem addressed in implementing
cellular manufacturing is how to form the machine cells.
This Cell Formation (CF) problem is concerned with
grouping parts with similar design features or
manufacturing routings into families as well as grouping
the corresponding machines into cells. In addition to
the design features or routing information, other
production related information (such as, the part type
production volume, unit operation time, and routing
sequence) is taken into consideration in the generalized
CF problem. An approach that employs Artificial Neural
Network as a pattern classifier has been proposed for
solving the generalized CF problem. Moreover, a
procedure for solving the multi-attribute machine
duplication subproblem has also been proposed. The
proposed cell formation approach has been verified and,
then, compared with some existing approaches by solving
problems from the literature as well as those created
for this study. In addition, a new quantitative measure
to indicate the goodness of the grouping solutions has
been proposed. The new measure has been used to evaluate
and compare solutions from the proposed approach and
from Gupta and Seifoddini Similarity Coefficient
approach.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  3308 </NUMBER>
<ORDER>   AAI9601808 </ORDER>
<TITLE> ARCHITECTURE FOR A VISION SYSTEM THAT LEARNS FROM GRAPHICAL EXPERT DATA  </TITLE>
<AUTHOR> BHASIN, SANJAY </AUTHOR>
<YEAR> 1995 </YEAR>
<INSTITUTION> DREXEL UNIVERSITY; 0065 </INSTITUTION>
<DESCRIPTORS> ENGINEERING, ELECTRONICS AND ELECTRICAL; COMPUTER SCIENCE; ENGINEERING, BIOMEDICAL; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> OLEH JOHN TRETIAK </ADVISER>
<CLASSIFICATIONS> MACHINE LEARNING </CLASSIFICATIONS>
<ABSTRACT>
The objective of this research is to formulate an
architecture for learning to perform visual tasks with
training information in the form of graphical input.
Input to the computer is a set of images and expert
delineations of these images. The architecture then
finds the best parameters for matching the computer's
output with that of the experts.
Implicit in this architecture is the need for the
computer to evaluate the quality or accuracy of a
delineation by comparing it with the expert's finding.
This research proposes a methodology for constructing an
evaluation measure through a process in which experts
are asked to evaluate the quality of a collection of
imperfect outlines. These quality judgments, along with
the imperfect and correct delineations, are used to
construct the evaluation measure.
Experiments are presented to validate the proposed
process of constructing evaluation measures. The
effectiveness of the learning architecture is
demonstrated by finding parameters for optimal
delineation of a set of images used in neuroscience
research.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  3309 </NUMBER>
<ORDER>   AAI9601760 </ORDER>
<TITLE> OPTIMIZATION OF ENTROPY WITH NEURAL NETWORKS </TITLE>
<AUTHOR> SCHRAUDOLPH, NICOL NORBERT </AUTHOR>
<YEAR> 1995 </YEAR>
<INSTITUTION> UNIVERSITY OF CALIFORNIA, SAN DIEGO; 0033 </INSTITUTION>
<DESCRIPTORS> COMPUTER SCIENCE; STATISTICS; BIOLOGY, NEUROSCIENCE; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> TERRENCE J. SEJNOWSKI; RICHARD K. BELEW </ADVISER>
<CLASSIFICATIONS> HEBBIAN LEARNING </CLASSIFICATIONS>
<ABSTRACT>
The goal of unsupervised learning algorithms is to
discover concise yet informative representations of
large data sets; the minimum description length
principle and exploratory projection pursuit are two
representative attempts to formalize this notion. When
implemented with neural networks, both suggest the
minimization of entropy at the network's output as an
objective for unsupervised learning.
The empirical computation of entropy or its derivative
with respect to parameters of a neural network
unfortunately requires explicit knowledge of the local
data density; this information is typically not
available when learning from data samples. This
dissertation discusses and applies three methods for
making density information accessible in a neural
network: parametric modelling, probabilistic networks,
and nonparametric estimation.
By imposing their own structure on the data, parametric
density models implement impoverished but tractable
forms of entropy such as the log-variance. We have used
this method to improve the adaptive dynamics of an anti-
Hebbian learning rule which has proven successful in
extracting disparity from random stereograms.
In probabilistic networks, node activities are
interpreted as the defining parameters of a stochastic
process. The entropy of the process can then be
calculated from its parameters, and hence optimized. The
popular logistic activation function defines a binomial
process in this manner; by optimizing the information
gain of this process we derive a novel nonlinear Hebbian
learning algorithm.
The nonparametric technique of Parzen window or kernel
density estimation leads us to an entropy optimization
algorithm in which the network adapts in response to the
distance between pairs of data samples. We discuss
distinct implementations for data-limited or memory-
limited operation, and describe a maximum likelihood
approach to setting the kernel shape, the regularizer
for this technique. This method has been applied with
great success to the problem of pose alignment in
computer vision.
These experiments demonstrate a range of techniques that
allow neural networks to learn concise representations
of empirical data by minimizing its entropy. We have
found that simple gradient descent in various entropy-
based objective functions can lead to novel and useful
algorithms for unsupervised neural network learning.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  3310 </NUMBER>
<ORDER>   AAI9601692 </ORDER>
<TITLE> ON-LINE CHARACTER RECOGNITION OF HANDPRINTED CHINESE CHARACTERS USING FUZZY MEASURING AND STRUCTURAL ANALYSIS </TITLE>
<AUTHOR> YEH, SONG-SHEN </AUTHOR>
<YEAR> 1995 </YEAR>
<INSTITUTION> OKLAHOMA STATE UNIVERSITY; 0664 </INSTITUTION>
<DESCRIPTORS> COMPUTER SCIENCE; ENGINEERING, INDUSTRIAL; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> HUIZHU LU </ADVISER>
<CLASSIFICATIONS> NIL </CLASSIFICATIONS>
<ABSTRACT>
Scope and method of study. The purpose of this study is
to develop a prototype on-line handprinted Chinese
character recognition system. A new approach to
recognize the most frequently used Chinese characters
(5,401 categories) is proposed. This new approach
includes character representation, primitive stroke
extraction, and fuzzy similarity measure from a physical
input to the templates in the database. An initial
template database is created for the experiments. At the
end of the study, the performance of the system is
tested based on the 18,000 samples collected from 20
writers. Initial template database and the database
after trained are used in the experiments for computing
recognition rates, respectively.
Findings and conclusions. Conventional schemes of stroke
representation require detailed description of the
selected features in order to portrait the
characteristics of a stroke. This usually requires a
large database file to store the entire Chinese
character set. By quantifying selected local features,
the proposed representation scheme requires less storage
space than the conventional approach for storing similar
amount of features. This results in less physical bytes
to represent each character. Moreover, the time for
retrieving a large and contiguous amount of information
from the secondary storage is reduced. However,
quantification of features causes slight ambiguity
between characters. In the first stage of experiments,
2% of the samples are ambiguous (i.e., out of the first
fifteen candidates list) and the recognition rate is 81%
on the average. In the second stage of experiments, the
recognition rate is improved with selective training
from those characters that were not recognized as the
first candidate in the first time around. The ambiguity
among characters is reduced to 0.4% and the recognition
rate is increased to 94.8%. Overall, the average
computation time spent in the recognition process is
0.94 seconds/character for 133 reference characters and
1.1 seconds/characters for 163 reference characters.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  3311 </NUMBER>
<ORDER>   AAI9601557 </ORDER>
<TITLE> SENSOR-BASED PLANNING AND CONTROL FOR A QUADRUPED WALKING ROBOT  </TITLE>
<AUTHOR> PACK, DANIEL JUNGHO </AUTHOR>
<YEAR> 1995 </YEAR>
<INSTITUTION> PURDUE UNIVERSITY; 0183 </INSTITUTION>
<DESCRIPTORS> ENGINEERING, ELECTRONICS AND ELECTRICAL; APPLIED MECHANICS; COMPUTER SCIENCE; ARTIFICIAL INTELLIGENCE; REMOTE SENSING </DESCRIPTORS>
<ADVISER> AVINASH KAK </ADVISER>
<CLASSIFICATIONS> GAIT CONTROL </CLASSIFICATIONS>
<ABSTRACT>
An "intelligent" system must be able to sense, plan, and
control. It has become increasingly evident that only
when these capabilities work together a system can
successfully accomplish non-trivial tasks. In this
thesis, we discuss issues that are related to such
systems in the context of a vision-based quadruped
walking robot system that we have designed and
developed.
The progress made so far in the design of legged robots
has dealt mostly with the issues of leg coordination,
gait control, stability, incorporation of various types
of sensors, etc. This progress has resulted in the
demonstration of rudimentary robotic walking
capabilities in various labs around the world. The more
stable of these robots have multiple legs, four or more,
and some can even climb stairs. But what is missing in
most of these robots is some perception-based high-level
control that would permit a robot to operate
intelligently. Equipping a robot with perception-based
control is not merely a matter of adding to the robot
yet another module; the high-level control must be
tightly integrated with the low-level control needed for
locomotion and stability. For our high-level control, a
model-based method to recognize a staircase using a
single 2D image of a 3D scene is studied. The staircase
recognition is achieved by obtaining the pose of a
camera coordinate frame which aligns model edges with
image edges. The method contains the matching, the pose
estimation, and the refinement procedures. We propose a
new matching scheme to reduce the complexity of
correspondence search between model and image features.
This is accomplished by grouping edges with certain
geometric characteristics together. The refinement
process uses all matched features to tightly fit the
model edges with camera image edges. The resulting
recognition is used to guide the robot to climb stairs.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  3312 </NUMBER>
<ORDER>   AAI9601147 </ORDER>
<TITLE> A FUZZY RULE-BASED APPROACH TO THE ANALYSIS OF DECISION PROCESS AND ITS APPLICATION </TITLE>
<AUTHOR> CHOWDHURY, ERIK </AUTHOR>
<YEAR> 1995 </YEAR>
<INSTITUTION> NEW MEXICO STATE UNIVERSITY; 0143 </INSTITUTION>
<DESCRIPTORS> ENGINEERING, ELECTRONICS AND ELECTRICAL; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> LONNIE C. LUDEMAN </ADVISER>
<CLASSIFICATIONS> PATTERN RECOGNITION </CLASSIFICATIONS>
<ABSTRACT>
The basic problem addressed is that of developing an
algorithm for a general purpose pattern recognition or
decision making system with a classifier that derives
from a set of fuzzy linguistic rules based on expert
knowledge and/or experience. In order to translate the
fuzzy linguistic rules for the design of a fuzzy
classifier, various ways for modeling the basic sentence
connectives "and," "or" and "not" and the conditional
"if... then..." are investigated within the context of
fuzzy set theory.
The general purpose pattern recognition or decision
making system consists of five major units: pre-
processor, fuzzifier, rule base, computation unit and
decision maker. Each of these major blocks are discussed
in detail.
Finally, the experimental results concerning the problem
of computer-assisted electrocardiogram (ECG)
interpretation for positive identification of cardiac
arrhythmias and the problem of computer vision system
for identity verification are given that demonstrate the
operation and performance of the proposed general
purpose pattern recognition or decision making system.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  3313 </NUMBER>
<ORDER>   AAGMM08484 </ORDER>
<TITLE> ENERGY FUNCTIONS AND HAMILTONIANS IN NEURAL NETWORK THEORY </TITLE>
<AUTHOR> TOKARUK, WAYNE ALLAN </AUTHOR>
<YEAR> 1995 </YEAR>
<INSTITUTION> THE UNIVERSITY OF REGINA (CANADA); 0148 </INSTITUTION>
<DESCRIPTORS> COMPUTER SCIENCE; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> G. PAPINI </ADVISER>
<CLASSIFICATIONS> NIL </CLASSIFICATIONS>
<ABSTRACT>
After an introduction to the language and fundamental
concepts of neural network theory, the two main
approaches to the application of physical theory to
neural network problems are presented. Proceeding from
an energy function for the network, the statistical
approach is demonstrated in detail using the example of
the Hopfield model implementing an associated memory.
The dynamical approach is illustrated using the example
of the classical neural network Hamiltonians due to
Ramacher. Finally, the dynamical approach is extended to
the quantum realm by the development of a quantum neural
network model governed by a wave equation. Based upon a
solution for the wavefunction in a restricted case, this
new model shows promise despite computational
difficulties.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  3314 </NUMBER>
<ORDER>   AAI9600861 </ORDER>
<TITLE> IDENTIFICATION OF NONLINEAR SYSTEMS USING ARTIFICIAL NEURAL NETWORKS WITH ELECTROMECHANICAL APPLICATIONS </TITLE>
<AUTHOR> RUCHTI, TIMOTY LEWIS </AUTHOR>
<YEAR> 1995 </YEAR>
<INSTITUTION> MARQUETTE UNIVERSITY; 0116 </INSTITUTION>
<DESCRIPTORS> ENGINEERING, ELECTRONICS AND ELECTRICAL; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> RONALD H. BROWN </ADVISER>
<CLASSIFICATIONS> NIL </CLASSIFICATIONS>
<ABSTRACT>
The focus of this work is on the development and
utilization of artificial neural networks (ANNs) for the
purpose of providing improved identification of plants
exhibiting significant nonlinearity and uncertainty. The
approach is to integrate ANNs into parallel-series
identification structures as general mappings capable of
representing the unknown portion of a plant. The problem
is then divided between the realization of suitable
identification structures and the development of
adequate learning algorithms.
The contributions of this research are as follows.
First, advanced learning algorithms are explored for the
purpose of parameterizing ANN identification structures.
A consequence of this investigation is the development
of an original ANN training algorithm that exhibits
superior identification in three specific applications
when compared to four other previously reported
techniques.
The ANN framework is improved through the development of
a novel method of exploiting a priori information about
a given plant through the realization of a new class of
ANN layers. The methods are used to identify the static
torque curves of a switched reluctance motor and are
demonstrated through four different examples involving
the identification of nonlinear plants.
Finally, an on-line parallel-series identification model
is proposed that utilizes ANNs and the methods developed
in earlier chapters to identify a SRM and its load
characteristics. The model is demonstrated through
simulation experiments involving a short calibration
period comprised of a point-to-point move.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  3315 </NUMBER>
<ORDER>   AAI9600818 </ORDER>
<TITLE> AN INVESTIGATION OF ARTIFICIAL NEURAL NETWORKS FOR SENSORY INTEGRATION AND DECISION MAKING IN ROBOT SAFETY SYSTEMS </TITLE>
<AUTHOR> ZURADA, JOZEF MACIEJ </AUTHOR>
<YEAR> 1995 </YEAR>
<INSTITUTION> UNIVERSITY OF LOUISVILLE; 0110 </INSTITUTION>
<DESCRIPTORS> COMPUTER SCIENCE; ENGINEERING, INDUSTRIAL; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> NIL </ADVISER>
<CLASSIFICATIONS> NIL </CLASSIFICATIONS>
<ABSTRACT>
This dissertation presents a new approach for real-time
robot safety based on artificial neural networks. This
approach includes a neural network detection unit and a
neural network decision unit, implemented at an
intermediate and high level of sensory processing,
respectively. The work also proposes a new,
computationally efficient methodology for sensory fusion
at the intermediate level in the dynamic environment.
The neural network detection unit is used to combine
basic probability mass functions encoded in certainty
grids (local maps) into one final map of the environment
containing potential collision zones. The neural network
is used to implement the Dempster-Shafer combination
rule to alleviate the potential computational complexity
of the theory. It is trained by the Dempster-Shafer
teacher. The detection unit is tested for two, three,
and four sensor case. Although the neural network
produces approximate results, they are very close to the
true results.
This dissertation also describes the development and
implementation of the neural network decision unit--a
classifier, which accepts on input the map with
potential collision zones (produced by the detection
unit), the robot's velocity and robot's steering angle.
The detection unit produces one of the following safety
decisions: 'move as intended', 'slow down', and
'emergency stop' that can be passed to the robot control
unit. These decisions are based on the concepts of the
virtual force field and the scalar product of two
vectors, i.e., the virtual force vector produced by an
obstacle which repels the robot from an obstacle, and
the robot's velocity vector. The decision unit is
trained by a human expert who heuristically determines
thresholds for safety decisions.
The neural network detection unit and neural network
decision unit have been implemented and tested by
simulation, both separately and as an integrated unit.
This integrated neural safety system gives a real-time
response and integrates observations from sensors in an
efficient manner. The response time of the integrated
system measured on 90 MHz, P5 microprocessor is less
than 11 ms, and the correctness of safety decisions is
93%.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  3316 </NUMBER>
<ORDER>   AAI9600492 </ORDER>
<TITLE> FORECASTING FREEWAY TRAFFIC FLOW FOR INTELLIGENT TRANSPORTATION SYSTEMS APPLICATION </TITLE>
<AUTHOR> SMITH, BRIAN LEE </AUTHOR>
<YEAR> 1995 </YEAR>
<INSTITUTION> UNIVERSITY OF VIRGINIA; 0246 </INSTITUTION>
<DESCRIPTORS> ENGINEERING, CIVIL; ENGINEERING, SYSTEM SCIENCE; TRANSPORTATION; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> MICHAEL J. DEMETSKY </ADVISER>
<CLASSIFICATIONS> NIL </CLASSIFICATIONS>
<ABSTRACT>
The capability to forecast traffic volume in an
operational setting has been identified as a critical
need for intelligent transportation systems (ITS). In
particular, traffic volume forecasts will directly
support proactive traffic control and accurate travel
time estimation. However, previous attempts to develop
traffic volume forecasting models have met with limited
success.
This research effort focused on developing traffic
volume forecasting models for two sites on the Capital
Beltway in Northern Virginia. Four models were developed
and tested for the single interval forecasting problem,
which is defined as estimating traffic flow 15 minutes
into the future. The four models were: historical
average, time-series, neural network, and nonparametric
regression. The nonparametric regression model
significantly outperformed the others.
Based on its success on the single interval forecasting
problem, the nonparametric regression approach was used
to develop and test a model for the multiple interval
forecasting problem. This problem is defined as
estimating traffic flow for a series of time periods
into the future, in 15 minute intervals. The
nonparametric regression model was found to perform well
in this application. In general, the model was portable,
accurate, and easy to deploy in a field environment.
Finally, an ITS system architecture was developed to
take full advantage of the forecasting capability. The
architecture illustrates the potential for significantly
improved ITS services with enhanced analysis components,
such as traffic volume forecasting.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  3317 </NUMBER>
<ORDER>   AAI9600331 </ORDER>
<TITLE> MODULAR NEURAL NETWORK ARCHITECTURE FOR DETECTION OF OPERATIONAL PROBLEMS ON URBAN ARTERIALS  </TITLE>
<AUTHOR> KHAN, SAROSH ISLAM </AUTHOR>
<YEAR> 1995 </YEAR>
<INSTITUTION> UNIVERSITY OF CALIFORNIA, IRVINE; 0030 </INSTITUTION>
<DESCRIPTORS> ENGINEERING, CIVIL; ARTIFICIAL INTELLIGENCE; TRANSPORTATION </DESCRIPTORS>
<ADVISER> STEPHEN G. RITCHIE </ADVISER>
<CLASSIFICATIONS> INTELLIGENT TRANSPORTATION SYSTEMS, SIGNAL TIMING, FREEWAYS </CLASSIFICATIONS>
<ABSTRACT>
A major concern in Advanced Transportation Management
Systems (ATMS), one of the principal thrusts of the
national program on Intelligent Transportation Systems
(ITS), is providing decision support to effectively
detect, verify and develop response strategies for
incidents that disrupt the flow of traffic. A key
element of providing such support is automating the
process of detecting operational problems on large area
networks. Successful detection of operational problems
in their early stages is vital for formulating response
strategies such as modifying surface street signal
timing plans and activating or updating traveler
information systems, including changeable message signs,
in-vehicle navigation systems and highway advisory
radio, altering emergency services, amongst others.
Reliable surface street incident detection is also
necessary for the development of integrated freeway-
arterial control systems.
Incident detection has been the subject of research for
the past two decades. But the focus has been on
detecting capacity reducing non-recurring congestion on
freeways. Only recently has attention begun to focus on
developing a methodology for surface street networks.
The main focus of this research was to develop a
methodology to detect different types of operational
problems relevant to the operations of surface street
networks.
In this research, a modular architecture of neural
network has been proposed to develop a comprehensive
system to detect different types of operational
problems, based on detector data from an urban traffic
control system. The modularity of the classifier
proposed decomposed the task of detecting different
types of problems and produced an overall system of
models that individually outperformed a single multi-
layer feed-forward neural network model for lane-
blocking incidents, special event conditions and
detector malfunction, and also a statistically-based
discriminant function model. The neural network-based
models and the statistical models were developed and
tested with simulated and field data from two test study
areas in Anaheim and Los Angeles, California, USA. The
higher detection rates and lower false alarm rates of
the modular neural network model compared to other
techniques demonstrated its potential of detecting
different types of traffic operational problems on urban
arterials.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  3318 </NUMBER>
<ORDER>   AAI9600204 </ORDER>
<TITLE> AUTOMATED VISUAL INSPECTION AND CLASSIFICATION BY NEURAL NETWORKS IN MANUFACTURING </TITLE>
<AUTHOR> KIM, TAIOUN </AUTHOR>
<YEAR> 1995 </YEAR>
<INSTITUTION> THE PENNSYLVANIA STATE UNIVERSITY; 0176 </INSTITUTION>
<DESCRIPTORS> ENGINEERING, INDUSTRIAL; ENGINEERING, ELECTRONICS AND ELECTRICAL; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> SOUNDAR R. T. KUMARA </ADVISER>
<CLASSIFICATIONS> SUPERVISED LEARNING </CLASSIFICATIONS>
<ABSTRACT>
Automated inspection of industrial parts is a problem of
considerable importance for the assurance of product
quality in most manufacturing fields. The automated
visual inspection problem involves two main areas: input
image representation and identification of the
represented features. Although considerable research has
been accomplished with regard to these areas, the
applications are limited to their own specific domain in
most cases.
This research presents schemes for automated visual
inspection for boundary and surface defects and
classification using neural networks. For boundary
representation, contour radius and polygonal
approximation are discussed and implemented using a male
screw image. A more efficient method for representing
circular boundaries is proposed utilizing a novel
curvature and circular fitting algorithm. For surface
image representation with complicated features, a new
method utilizing line segments is proposed. For the
classification schemes, three types of neural network
modeling are established. First, multi-layer perceptron
is discussed for pattern matching-type and defect
classification-type problems. Second, a Hopfield network
is modeled to be used for continuous types variables by
minimizing energy function. Third, how a Kohonen's
feature map can be used for classification problems is
addressed.
Extensive experiments were conducted on two types of
visual inspection problems. Castings were adopted for
the boundary defects and parts from powder injection
molding were used for the surface defects. The
classification results of neural networks are compared
with those of traditional pattern classifiers: linear
discriminant analysis and C-means algorithm. In all
cases tested, classification results of neural networks
show higher recognition of defective features than those
of traditional pattern classifiers.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  3319 </NUMBER>
<ORDER>   AAI9544920 </ORDER>
<TITLE> RECOGNITION OF VOLUMETRIC ARTICULATED OBJECTS USING SUPERQUADRIC-BASED GEONS </TITLE>
<AUTHOR> JEAN-LAURENT, PIERRE </AUTHOR>
<YEAR> 1995 </YEAR>
<INSTITUTION> SYRACUSE UNIVERSITY; 0659 </INSTITUTION>
<DESCRIPTORS> ENGINEERING, ELECTRONICS AND ELECTRICAL; REMOTE SENSING; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> NIL </ADVISER>
<CLASSIFICATIONS> PATTERN RECOGNITION, COMPUTER VISION, ATTRIBUTED RELATED GRAPH </CLASSIFICATIONS>
<ABSTRACT>
Articulated bodies constitute a large class of objects
that we encounter in our daily life as well as in
industry. In this thesis, we present an integrated
approach to the recognition of volumetric articulated
objects from single view range data. Our method
integrates the qualitative aspects of human vision with
the quantitative ones required for accurate computer
matching. The objects have joints which may be fixed,
prismatic or revolute, and they are assumed to be made
of parts belonging to one of twelve classes of geons
representable by deformed superquadrics. Four major
modules make up our recognition systems: a part
segmenter, a geon classifier-indexer, an attributed
related graph (ARG) matcher, and a verification module.
This dissertation concentrates on the design and
implementation of the geon classifier and the ARG
matcher. A technique for classifying superquadrics as
geons based following the work of Raja and Jain on this
subject is derived. The recovered geons serve as indices
to possible object candidates. This set is further
reduced, ideally to a single candidate, by the ARG
module which selects the most likely interpretation of
the input data by minimizing an appropriate cost
matching function which takes as constraints to be
satisfied not only the individual parts that make up the
observed data, but also their interrelation at common
joints, may these be fixed, prismatic or rotary. The
procedure is tested on synthetic range images.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  3320 </NUMBER>
<ORDER>   AAI9544644 </ORDER>
<TITLE> A COMPUTERIZED LEARNING ENVIRONMENT FOR EXPLORING LEARNING STRATEGIES WITH IMMUNOHEMATOLOGY STUDENTS </TITLE>
<AUTHOR> MILLER, THOMAS E. </AUTHOR>
<YEAR> 1995 </YEAR>
<INSTITUTION> THE OHIO STATE UNIVERSITY; 0168 </INSTITUTION>
<DESCRIPTORS> ENGINEERING, INDUSTRIAL; COMPUTER SCIENCE; EDUCATION, PSYCHOLOGY; HEALTH SCIENCES, EDUCATION; EDUCATION, TECHNOLOGY; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> PHILIP J. SMITH </ADVISER>
<CLASSIFICATIONS> TUTORING, BLOOD BANKING </CLASSIFICATIONS>
<ABSTRACT>
A distinguishing characteristic of expert performance in
problem solving is the early formation of hypotheses.
These hypotheses guide further data collection and
prevent the experts from committing certain types of
errors which novices are more prone to making. Early
hypothesis formation by experts has been observed in
several diverse domains, such as in the interpretation
of x-rays by radiologists, in the diagnosis of problems
in nuclear power plants, and in the identification of
antibodies by immunohematologists.
The major focus of this dissertation was on evaluating
the impact of teaching early hypothesis formation to
novices within a computerized learning environment. This
computerized tutoring system, called the Transfusion
Medicine Tutor (TMT), was designed to take problem-
solving strategies culled from experts and deliver them
to students as they try to solve actual problems. This
dissertation also examines how students adapt to
computer based training systems and specifically, what
learning strategies students select to learn from the
tutoring system.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  3321 </NUMBER>
<ORDER>   AAI9544073 </ORDER>
<TITLE> COMPREHENSIVE ASSESSMENT OF REAL-TIME KNOWLEDGE BASED SYSTEMS: DEVELOPMENT AND EVALUATION OF THE SHIPBOARD PILOTING EXPERT SYSTEM </TITLE>
<AUTHOR> SANBORN, STEPHEN DUANE </AUTHOR>
<YEAR> 1995 </YEAR>
<INSTITUTION> RENSSELAER POLYTECHNIC INSTITUTE; 0185 </INSTITUTION>
<DESCRIPTORS> ENGINEERING, SYSTEM SCIENCE; COMPUTER SCIENCE; INFORMATION SCIENCE; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> MARTHA R. GRABOWSKI </ADVISER>
<CLASSIFICATIONS> SPES </CLASSIFICATIONS>
<ABSTRACT>
The study of information systems has grown over the past
two decades to include decision support systems (DSS),
group decision support systems (GDSS), and knowledge
based systems (KBS) and expert systems (ES). These
systems were initially conceived as standalone
information technology. With the evolution of large
scale and distributed systems, however, many of these
standalone applications have become embedded software
elements in much larger systems, occasioning a host of
attendant design, development, deployment, and
evaluation hurdles.
This research focuses on the evaluation challenges
associated with intelligent software systems which are
embedded in larger host systems. In this research, the
embedded intelligent system under study is the Shipboard
Piloting Expert System (SPES), a knowledge-based system
which represents expert knowledge of ship's pilots in
Prince William Sound, Alaska, makes real-time collision
and stranding assessments, and makes recommendations to
ship's captains, mates on watch, and pilots about
appropriate vessel and bridge watch team conduct. This
knowledge-based system is embedded within a host group
decision support system, an integrated bridge system
(IBS) currently in use aboard commercial tankships.
This research proposes a comprehensive approach to
evaluation of knowledge based decision aids in
operational environments, and applies it to the SPES.
What is notable about this research is not so much that
an embedded intelligent piloting system was built, where
none existed before; nor that the system was deployed
for a two year period in a challenging and demanding
operational environment--a tank ship's bridge; nor that
the system was evaluated using multiple measures in both
an operational environment and a laboratory setting. The
contribution of this research lies in: (1) the
development of a robust, multiple measure evaluation
methodology for knowledge based systems, both embedded
and standalone, (2) the empirical demonstration of the
requirement for an integrative assessment of the
findings produced with the comprehensive evaluation
methodology, and, (3) the demonstration of positive
impact of KBS and GDSS technology in a complex, large
scale interdependent system, using the comprehensive
evaluation methodology.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  3322 </NUMBER>
<ORDER>   AAI9544068 </ORDER>
<TITLE> SYMBOLIC INFORMATION IN RECURRENT NEURAL NETWORKS: ISSUES OF REPRESENTATION AND TRAINING </TITLE>
<AUTHOR> OMLIN, CHRISTIAN W. P. </AUTHOR>
<YEAR> 1995 </YEAR>
<INSTITUTION> RENSSELAER POLYTECHNIC INSTITUTE; 0185 </INSTITUTION>
<DESCRIPTORS> COMPUTER SCIENCE; ENGINEERING, ELECTRONICS AND ELECTRICAL; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> C. L. GILES </ADVISER>
<CLASSIFICATIONS> DETERMINISTIC FINITE STATE AUTOMATA </CLASSIFICATIONS>
<ABSTRACT>
In recent years, there has been a renewed interest in
artificial neural networks. The discovery of new
learning algorithms has made them promising tools in
diverse applications such as pattern recognition, signal
processing, knowledge acquisition for expert systems,
prediction of protein structures, and dynamical system
modeling. Recurrent neural networks which are able to
store state information over indefinite time spans are
particularly well-suited for modeling dynamical systems
such a stock markets, speech, and physical systems.
In this thesis, we examine how symbolic knowledge is
represented in recurrent networks trained to recognize
regular languages. We demonstrate methods for inserting
and extracting the learned languages in the form of
deterministic finite-state automata (DFAs). We focus our
attention on the quality of the extracted grammatical
rules and on how partial prior knowledge can be
effectively utilized to improve training performance. We
prove that DFAs can be naturally embedded in a special
recurrent network architecture with higher order weights
such that the finite-state encoding remains stable
indefinitely. We investigate means for constructing
neural DFAs which are tolerant to faults in their
internal structure.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  3323 </NUMBER>
<ORDER>   AAI9544053 </ORDER>
<TITLE> A HYPER-RESHAPING INTERPRETATION OF NEURAL NETWORK TRAINING WITH APPLICATIONS IN APPROXIMATING GEOMETRICAL MAPPINGS  </TITLE>
<AUTHOR> LEE, HAUHUA </AUTHOR>
<YEAR> 1995 </YEAR>
<INSTITUTION> RENSSELAER POLYTECHNIC INSTITUTE; 0185 </INSTITUTION>
<DESCRIPTORS> ENGINEERING, MECHANICAL; COMPUTER SCIENCE; STATISTICS; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> PRABHAT HAJELA </ADVISER>
<CLASSIFICATIONS> MULTILAYER FEEDFORWARD NETWORKS </CLASSIFICATIONS>
<ABSTRACT>
Fundamental issues in using multilayer feedforward
networks (MFN) for the training of complex mappings,
such as those involving geometrical shapes, were
addressed from the standpoint of mapping nonlinearity.
Approximation of geometrical mappings is an important
and challenging task. An example of applications is
quick estimations of numerical results that would
otherwise require the use of CPU-intensive analysis
programs. Such mappings often involve high mapping
dimensions, high mapping nonlinearity, and may require a
high degree of approximation accuracy. All these factors
mandate appropriate formulation of training samples.
This research showed that a sound criterion for sample
formulation is to reduce the mapping nonlinearity of
mapping samples.
The hyper-reshaping interpretation of MFN was first
presented as the basis of the present research. By
thinking of training samples as the input and output
states of a multidimensional training object, MFN is
shown to be a mechanism that successively hyper-reshapes
such an imaginary object from its input state to its
desired output state via one or several intermediate
states, which correspond to the hidden layers of MFN.
This interpretation shed light on several important
questions about MFN, such as how MFN achieves
generalization and how an activation function affects
the MFN performance. Moreover, it led to the
quantitative mapping non-linearity indicators,
distribution angle $alpha$ and distribution gradient
$beta$, which gauge mapping nonlinearity based on the
spatial characteristics of training samples.
The nonlinearity indicators were also extended to the
salience analysis technique, through which one can
decompose a large mapping, identify redundant or
stubborn samples, and improve the reliability of the
cross-validation training algorithm. As for the
formulation of geometrical samples, Fourier descriptors
and FPF descriptors (and variations) were used in this
research. Numerical experiments included three mapping
models: mapping from arbitrary planar shapes to
geometrical properties, mapping from blade throat
designs to turbine efficiencies, and mapping from 2D
blade shapes to the Mach number distribution along blade
surface. In these experiments, various ways of
formulating mapping samples were explored and analyzed
with their mapping nonlinearities. It showed that
mappings with lower nonlinearity tend to have better
trainability.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  3324 </NUMBER>
<ORDER>   AAGMM08298 </ORDER>
<TITLE> DEVELOPMENT OF KNOWLEDGE-BASED MICROCOMPUTER APPLICATIONS TO ASSIST IN THE SELECTION OF SOIL AND GROUNDWATER REMEDIATION TECHNIQUES AT PETROLEUM CONTAMINATED SITES </TITLE>
<AUTHOR> ROSE, PETER ANDREW </AUTHOR>
<YEAR> 1995 </YEAR>
<INSTITUTION> TECHNICAL UNIVERSITY OF NOVA SCOTIA (CANADA); 0300 </INSTITUTION>
<DESCRIPTORS> ENGINEERING, CIVIL; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> HANS VAZIRI </ADVISER>
<CLASSIFICATIONS> NIL </CLASSIFICATIONS>
<ABSTRACT>
This thesis provides a discussion of two original
microcomputer-based expert systems developed to act as a
learning tool for selecting soil and groundwater
remediation techniques at petroleum contaminated sites.
The SOIL REMEX and H2O REMEX computer programs receive
inputs of site and contaminant information from the
program user through a series of interactive windows. A
rule-based decision making process uses this information
to provide a suggestion of the most applicable or
appropriate site remediation technique for any given
site based on the program inputs provided. The programs
provide a detailed discussion of each of the remedial
techniques which may be suggested, including general
information, advantages, disadvantages, costs and
references. Both programs were developed using the
KnowledgPro$spcopyright$ Windows development environment
and operate in a Microsoft Windows$spcopyright$ 3.1
environment. The programs make use of a graphical
interface and a series of screen objects such as
buttons, edit boxes, hypertext and hypergraphics to
expedite the recovery of information from the user.
As a test of the effectiveness of the programs they are
applied to six actual petroleum contaminated sites where
remediation programs were designed and implemented by
"experts". The results of the program test application
are discussed and suggestions for further study
presented. (Abstract shortened by UMI.)
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  3325 </NUMBER>
<ORDER>   AAI9543939 </ORDER>
<TITLE> KNOWLEDGE BASED MACHINE VISION SYSTEM FOR OUTDOOR PLANT IDENTIFICATION </TITLE>
<AUTHOR> TIAN, LEI </AUTHOR>
<YEAR> 1995 </YEAR>
<INSTITUTION> UNIVERSITY OF CALIFORNIA, DAVIS; 0029 </INSTITUTION>
<DESCRIPTORS> ENGINEERING, AGRICULTURAL; ENGINEERING, AUTOMOTIVE; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> NIL </ADVISER>
<CLASSIFICATIONS> NIL </CLASSIFICATIONS>
<ABSTRACT>
Identification of individual crop plants in the field
and locating their exact position is one of the last
untouched areas of automated farming. Aimed at solving
this "untouchable" problem, this dissertation explored
the theory, implementation, and real-time application of
machine vision for automatic outdoor detection of
individual field plants.
This research describes the need for a reliable outdoor
field plant detection and location system in
horticultural operations. After reviewing the current
state of development in agricultural robotics, machine
vision systems, and related areas, a color machine
vision sensing system for an outdoor field robot was
developed and evaluated.
All research findings were conducted on juvenile
processing tomato plants (Lycopersicon esculentum) using
video images collected in vivo under normal California
commercial farming conditions.
The scope of this research included: (1) the study of
commercial field operations and properties of outdoor
field plants (crop plants and weeds) to select a
suitable view for object sensing, and to find the best
natural plant growth stage (or timing) for
identification, (2) the development of outdoor real-time
video image acquisition and image preprocessing methods,
(3) the development of a robust color segmentation
algorithm for outdoor image processing, and (4) the
formulation of a special pattern recognition algorithm
for plant identification, plant location determination
and/or operation decision making. Three major topics
were studied attentively: (1) Outdoor imaging
conditions. Sunlight, uniform illumination, shadow
problems, optional lighting sources, diffusers, and
filtering were studied in the real-time field
environment. The effects of travel speed, equipment
vibration, and the position of the camera relative to
farm machinery components were investigated. (2) Image
segmentation. A robust, environmentally adaptive
segmentation algorithm has been developed. Major outdoor
imaging problems such as different light source
temperatures, changes in light source position, and
shadowing of the field of view were studied. A partially
supervised learning procedure was applied in the
construction of an adaptive classifier. (3) Plant
identification. Semantic leaf-shape features, position,
and orientation data were used to determine the position
of the whole plant and the location where the stem
enters the soil.
Based on the processing results of more than 270 frames
of real-time images from six different outdoor fields,
the algorithms developed could find and identify between
61 to 82 percent of all the individual crop plants
studied. The results of the prototype system showed that
a machine vision system could be developed for outdoor,
real-time field operation using current machine vision
technology. The number of computationally intensive
procedures could be reduced by careful design of the
machine vision system to provide high quality raw
outdoor images.
This dissertation is composed of five chapters and more
than 60 figures which show the image processing and
pattern recognition procedures evaluated.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  3326 </NUMBER>
<ORDER>   AAI9543663 </ORDER>
<TITLE> NICHING METHODS FOR GENETIC ALGORITHMS </TITLE>
<AUTHOR> MAHFOUD, SAMIR W. </AUTHOR>
<YEAR> 1995 </YEAR>
<INSTITUTION> UNIVERSITY OF ILLINOIS AT URBANA-CHAMPAIGN; 0090 </INSTITUTION>
<DESCRIPTORS> COMPUTER SCIENCE; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> DAVID E. GOLDBERG </ADVISER>
<CLASSIFICATIONS> CROWDING </CLASSIFICATIONS>
<ABSTRACT>
Niching methods extend genetic algorithms to domains
that require the location and maintenance of multiple
solutions. Such domains include classification and
machine learning, multimodal function optimization,
multiobjective function optimization, and simulation of
complex and adaptive systems.
This study presents a comprehensive treatment of niching
methods and the related topic of population diversity.
Its purpose is to analyze existing niching methods and
to design improved niching methods. To achieve this
purpose, it first develops a general framework for the
modelling of niching methods, and then applies this
framework to construct models of individual niching
methods, specifically crowding and sharing methods.
Using a constructed model of crowding, this study
determines why crowding methods over the last two
decades have not made effective niching methods. A
series of tests and design modifications results in the
development of a highly effective form of crowding,
called deterministic crowding. Further analysis of
deterministic crowding focuses upon the distribution of
population elements among niches, that arises from the
combination of crossover and replacement selection.
Interactions among niches are isolated and explained.
The concept of crossover hillclimbing is introduced.
Using constructed models of fitness sharing, this study
derives lower bounds on the population size required to
maintain, with probability $gamma$, a fixed number of
desired niches. It also derives expressions for the
expected time to disappearance of a desired niche, and
relates disappearance time to population size. Models
are presented of sharing under selection, and sharing
under both selection and crossover. Some models assume
that all niches are equivalent with respect to fitness.
Others allow niches to differ with respect to fitness.
Focusing on the differences between parallel and
sequential niching methods, this study compares and
further examines four niching methods--crowding,
sharing, sequential niching, and parallel hillclimbing.
The four niching methods undergo rigorous testing on
optimization and classification problems of increasing
difficulty; a new niching-based technique is introduced
that extends genetic algorithms to classification
problems.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  3327 </NUMBER>
<ORDER>   AAI9543034 </ORDER>
<TITLE> SOFTWARE FAULT TOLERANCE FOR CONTROL APPLICATIONS: A NEW METHODOLOGY </TITLE>
<AUTHOR> STEPHAN, JENNIFER MARIE </AUTHOR>
<YEAR> 1995 </YEAR>
<INSTITUTION> CARNEGIE-MELLON UNIVERSITY; 0041 </INSTITUTION>
<DESCRIPTORS> ENGINEERING, ELECTRONICS AND ELECTRICAL; COMPUTER SCIENCE; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> MARC BODSON </ADVISER>
<CLASSIFICATIONS> NIL </CLASSIFICATIONS>
<ABSTRACT>
The impressive capabilities of modern computers have
enabled the implementation of highly sophisticated
intelligent control methods even in relatively modest
applications. However, the risk of software errors and
the potential of failures due to unanticipated
algorithmic behavior and modes of operation may
increasingly exclude the use of such technologies in
applications where timing or safety is critical. The
work of this thesis aims to ensure that high-performance
intelligent control will be achievable together with
high reliability. To reach this goal, a new technique
for software fault-tolerance is developed. The technique
is based on a redundancy of the controller software with
a complementary reliable/high-performance structure that
exploits a significant disparity between the two
systems. In this construct, a complex high-performance
controller with uncertain reliability is monitored by a
reliable controller. The reliable controller is
responsible for maintaining the safety of the system by
detecting failures of the complex controller and
recovering from such failures when they occur. These
tasks are not straightforward, especially when
considering systems with limits on the control inputs
and state variables. To this end, recoverability for
input and state constrained systems is a focus of the
thesis. The properties of recoverable sets and their
boundaries are investigated and methods for calculating
recoverable sets are developed. The concepts of
recoverable sets are applied for reliable control system
design. The ideas of the thesis are illustrated in two
experimental testbeds, the classic ball and beam and
inverted pendulum systems.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  3328 </NUMBER>
<ORDER>   AAI9543021 </ORDER>
<TITLE> THE HARMONIC SIEVE: A NOVEL APPLICATION OF FOURIER ANALYSIS TO MACHINE LEARNING THEORY AND PRACTICE </TITLE>
<AUTHOR> JACKSON, JEFFREY CHARLES </AUTHOR>
<YEAR> 1995 </YEAR>
<INSTITUTION> CARNEGIE-MELLON UNIVERSITY; 0041 </INSTITUTION>
<DESCRIPTORS> COMPUTER SCIENCE; MATHEMATICS; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> MERRICK FURST </ADVISER>
<CLASSIFICATIONS> NIL </CLASSIFICATIONS>
<ABSTRACT>
This thesis presents new positive results--both
theoretical and empirical--in machine learning. The
primary learning-theoretic contribution is the Harmonic
Sieve, the first efficient algorithm for learning the
well-studied class of Disjunctive Normal Form (DNF)
expressions (learning is accomplished within the
Probably Approximately Correct model with respect to the
uniform distribution using membership queries). Of
particular interest is the novel use of Fourier methods
within the algorithm. Specifically, all prior Fourier-
based learning algorithms focused on finding large
Fourier coefficients of the function to be learned (the
target). The Harmonic Sieve departs from this paradigm;
it instead learns by finding large coefficients of
certain functions other than the target. The robustness
of this new Fourier technique is illustrated by applying
it to prove learnability of noisy DNF expressions, of a
circuit class that is even more expressive than DNF, and
of an interesting class of geometric concepts.
Empirically, the thesis demonstrates the significant
practical potential of a classification-learning
algorithm closely related to the Harmonic Sieve. The
Boosting-based Perceptron (BBP) learning algorithm
produces classifiers that are nonlinear perceptrons
(weighted thresholds over higher-order features). On
several previously-studied machine learning benchmarks,
the BBP algorithm produces classifiers that achieve
accuracies essentially equivalent to or even better than
the best previously-reported classifiers. Additionally,
the perceptrons produced by the BBP algorithm tend to be
relatively intelligible, an important feature in many
machine learning applications. In a related vein, BBP
and the Harmonic Sieve are applied successfully to the
problem of rule extraction, that is, the problem of
approximating an unintelligible classifier by a more
intelligible function.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  3329 </NUMBER>
<ORDER>   AAINN99082 </ORDER>
<TITLE> CONSTRAINT-DIRECTED IMPROVISATION FOR EVERYDAY ACTIVITIES  </TITLE>
<AUTHOR> ANDERSON, JOHN ERIC </AUTHOR>
<YEAR> 1995 </YEAR>
<INSTITUTION> THE UNIVERSITY OF MANITOBA (CANADA); 0303 </INSTITUTION>
<DESCRIPTORS> COMPUTER SCIENCE; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> MARK EVANS </ADVISER>
<CLASSIFICATIONS> ARTIFICIAL INTELLIGENCE, PLANNING </CLASSIFICATIONS>
<ABSTRACT>
Existing approaches to planning in Artificial
Intelligence (such as Universal and Classical Planning)
are designed for very specific types of activities, and
are largely inapplicable to areas outside their narrow
ranges. In particular, everyday activities that are
simple for humans, such as making a meal or getting from
place to place, require long-term goal-directed and
timely responses that are far beyond the bounds of these
traditional approaches. This dissertation examines the
nature of the everyday activities and develops a
computational architecture for an agent able to
participate in such activities.
An analysis of everyday activities shows them to be
difficult tasks made artificially simple through
extensive activity-specific knowledge possessed by the
agent performing them. I argue that existing approaches
are unsuitable to everyday activity because they rely
too heavily on compiled knowledge and fail to adequately
apply the background knowledge from which these
compilations were originally made. To address everyday
activities, I present a theory of improvisation, a new
approach that views the problem as satisficing
intelligent control: providing resource-bounded
responses to the environment in light of the agent's
previous experience and its current and future
intentions for activity. This process is based on the
use of both heavily compiled routines the agent is
accustomed to following, and an extensive collection of
background knowledge used to apply those routines
flexibly. The agent can rely on its routines in
normative situations or when time is too scarce to spend
examining the reasons behind its routines, and can
conversely rely more heavily on background knowledge as
situations become less normative. This allows the agent
to take advantage of regularities in its environment and
respond flexibly in less familiar situations.
I then present an architecture embodying the
improvisational approach based on the use of constraint-
directed reasoning. This methodology provides a flexible
control mechanism that allows the agent to respond as
dynamically as necessary for the circumstances in which
it finds itself. Implemented examples of improvised
behaviour are also shown, using a simulation tool
developed in conjunction with this research.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  3330 </NUMBER>
<ORDER>   AAI9601890 </ORDER>
<TITLE> SELECTING SUPERIOR SECURITIES: USING DISCRIMINANT ANALYSIS AND NEURAL NETWORKS TO DIFFERENTIATE BETWEEN 'WINNER' AND 'LOSER' STOCKS </TITLE>
<AUTHOR> LONGO, JOHN MICHAEL </AUTHOR>
<YEAR> 1995 </YEAR>
<INSTITUTION> RUTGERS THE STATE UNIVERSITY OF NEW JERSEY - NEWARK; 0461 </INSTITUTION>
<DESCRIPTORS> ECONOMICS, FINANCE; BUSINESS ADMINISTRATION, MANAGEMENT; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> MICHAEL S. LONG </ADVISER>
<CLASSIFICATIONS> NIL </CLASSIFICATIONS>
<ABSTRACT>
This study looked at the fundamental and technical
differences between the greatest stock market winners
and losers and used the differences between the two
groups to predict future winners and losers. The neural
networks used for forecasting were shown to be highly
effective, while the models based on discriminant
analysis were ineffective.
The best neural network, Neural Network 1, produced a
'Winner' ('Loser') portfolio that had an annual compound
return of 31.2% (5.89%) versus a return of 18.36% for
the market. A number of additional tests were performed
to examine the robustness of the models. In all cases
the Neural Network 1 performed at highly significant
levels. One test examined the number of predicted
winners (losers) versus the actual number of winners
(losers). The results of both neural nets were
significant at well over the 99.99% level. Other tests
looked at risk adjusted returns. For example, the
'Winner' ('Loser') portfolio for Neural Net 1 realized
annual cumulative abnormal returns of +24.75% ($-$4.7%).
A neural net was also developed for stock market timing
applications. The net was constructed to predict whether
the upcoming month's return on the S&P 500 was positive
or negative. The neural net predicted with approximately
73% accuracy the upcoming direction of the market. The
naive strategy of buy and hold would have been correct
only approximately 58% of the time.
Since the market timing net proved to be successful,
this study also combined it with the first security
selection net to form a total portfolio management
system. Combining both nets resulted in the best
performance, relative to any other portfolio examined in
this paper. This 'Combination' portfolio had a compound
return over an 18 year period of approximately 42.1%,
versus 18.36% for the market. The results of this
combination portfolio compare favorably with some of the
greatest investors in stock market history.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  3331 </NUMBER>
<ORDER>   AAI9601148 </ORDER>
<TITLE> PERCEPTIONS OF TECHNOLOGY DIRECTORS AS TO THE IMPORTANCE OF SPECIFIC KNOWLEDGE AND SKILL REQUIREMENTS </TITLE>
<AUTHOR> DELFIN, ANNE PERNER </AUTHOR>
<YEAR> 1995 </YEAR>
<INSTITUTION> NEW MEXICO STATE UNIVERSITY; 0143 </INSTITUTION>
<DESCRIPTORS> EDUCATION, ADMINISTRATION; EDUCATION, TECHNOLOGY </DESCRIPTORS>
<ADVISER> MARIA LUISA GONZALEZ </ADVISER>
<CLASSIFICATIONS> NIL </CLASSIFICATIONS>
<ABSTRACT>
Use of computer technology has been experiencing
tremendous growth in the public schools, for both
instructional and administrative purposes, since the
beginning of the 1980s. This technology is complex and
many school districts have hired individuals, hereafter
referred to as technology directors, to oversee their
technology programs. This study investigated technology
directors' perceptions of the skill and knowledge
requirements necessary for their positions.
A survey instrument developed by the Boston SIM Laison
Committee (Trauth et al., 1993) to study skill and
knowledge requirements for information systems
professionals was utilized. This study attempted to
identify skill and knowledge requirements technology
directors perceived to be important currently and in
three years, and to compare these results with the
Boston SIM survey results.
The population consisted of technology directors in
public schools with enrollments over 15,000. The sample
size was 165, and the respondent rate was 75%. A profile
of the respondents indicated a myriad of job titles; 95%
were administrators; 12% reported directly to the
superintendent, and 58% to an assistant, associate, or
deputy superintendent; and 25% were responsible for
instructional technology only, 24% for administrative
technology only, and 50% for both.
Interpersonal and managerial skills components were
rated high, with all having means over 4.0 on a 5 point
scale. Technical skills related to microcomputer
operating systems, systems integration, distributed
processing, and communications received high ratings.
Skills associated with traditional technological
functions (i.e., operating systems for mainframe and
minicomputers, assembly languages, and third generation
languages) received low ratings. Some of the more recent
trends (i.e., fourth generation languages, expert
systems/artificial intelligence, etc.) also received low
ratings.
When comparing the results of the public school
technology director study and the results of the Boston
SIM study, there was agreement as to whether items were
statistically significant or not on 82% of the items.
However, when comparing actual mean ratings between the
two studies, there were significant differences between
the values on 83% of the items.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  3332 </NUMBER>
<ORDER>   AAI9600109 </ORDER>
<TITLE> PREDICTING ENGINEERING TECHNOLOGY STUDENT SUCCESS USING STATISTICAL SUCCESS PROBABILITIES AND MULTIVALUED-LOGIC SUCCESS POSSIBILITIES </TITLE>
<AUTHOR> WALKER, GLEN DALE </AUTHOR>
<YEAR> 1995 </YEAR>
<INSTITUTION> EAST TEXAS STATE UNIVERSITY; 0103 </INSTITUTION>
<DESCRIPTORS> EDUCATION, COMMUNITY COLLEGE; EDUCATION, MATHEMATICS; EDUCATION, TESTS AND MEASUREMENTS; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> JAMES W. TUNNELL </ADVISER>
<CLASSIFICATIONS> FUZZY LOGIC </CLASSIFICATIONS>
<ABSTRACT>
Purpose of the study. The major purpose of this study
was to determine if success possibilities for
Engineering Technology Program (ETP) students could be
predicted using a multivalued or fuzzy-logic system of
analysis. This determination was made by comparing the
results of a standard statistical study of the success
probabilities with the fuzzy-logic success
possibilities.
Procedure. The sample was comprised of 53 second-year
students and graduates of the ETP of the Dallas County
Community College District. A questionnaire was utilized
as the means for data acquisition. Analysis of Variance
was used to test the major prediction and five
hypotheses. The.05 level of significance was used as the
point of rejection.
Findings. Five research hypotheses were investigated in
this study. Each hypothesis was tested using ANOVA to
determine if there was a statistically significant
difference in the variables tested. The findings are
indicated as follows: (1) There were no significant
differences, using standard statistical analysis, in the
prediction of ETP student GPAs from college entrance
exam, CEE, or high school GPA scores when compared to
the actual GPAs of graduates. (2) There were no
significant differences, using fuzzy-logic analysis, in
the prediction of ETP student GPAs from CEE or high
school GPA scores when compared to the actual GPAs of
graduates. (3) There were no significant differences,
using either multivalued-logic analysis or standard
statistical analysis, in the prediction of ETP student
GPAs from a weighted value of ethnicity, age, and
employment (EAE) record when compared to the actual GPAs
of graduates.
Conclusions. The study resulted in the following
conclusions, which could be applied to the study of
other groups with respondents similar to those who
participated in this study: (1) ETP student success was
predicted from CEE scores or high school GPAs using
either standard statistical probability analysis or
multivalued-logic possibility analysis. (2) ETP student
success was predicted from a weighted value for EAE
record using either standard statistical probability
analysis or fuzzy-logic possibility analysis. (3) Fuzzy-
logic possibility analysis should be investigated more
fully as a means of including motivational factors and
inferential effects in educational research.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  3333 </NUMBER>
<ORDER>   AAI9544319 </ORDER>
<TITLE> A FUZZY RELATIONAL APPROACH TO COGNITIVE STRUCTURES OF AN URBAN KNOWLEDGE-BASED SYSTEM </TITLE>
<AUTHOR> JOO, YOUNGDO </AUTHOR>
<YEAR> 1995 </YEAR>
<INSTITUTION> THE FLORIDA STATE UNIVERSITY; 0071 </INSTITUTION>
<DESCRIPTORS> COMPUTER SCIENCE; PSYCHOLOGY, GENERAL; URBAN AND REGIONAL PLANNING; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> WYLLIS BANDLER </ADVISER>
<CLASSIFICATIONS> FUZZY LOGIC </CLASSIFICATIONS>
<ABSTRACT>
The development of computer-based modeling systems has
allowed the operationalization of cognitive science
issues. Artificial intelligence, the emulation of high-
level human capability on the computer, has led to
incorporation of systems that model human behavior.
Human cognition has become one of the most interested
research areas. An approach to handle human cognition by
means of personal construct systems is presented in this
dissertation.
The dissertation describes a methodology well-suited for
designing of a non-traditional knowledge-based system to
evaluate personal cognition derived in urban planning as
an application field. The research investigates how to
elicit and represent cognitive knowledges obtained from
individual urbanites through the application of fuzzy
relational theory to personal construct theory and
repertory grid techniques.
Crucial to this research is to formalize and process the
psychological cognition of the urbanites who interact
with an urban environment in order to offer useful
advice on urban problem. What is needed is a technique
to analyze cognitive structures called Hasse diagrams
which are instantiations of these perceptive knowledges
of human being. This requires a theory of similarity to
deal with underlying problems; identification of
individual cognitive structures, comparison of
structures and investigation of a group of structures.
Unlike standard approaches to similarity based on the
statistical techniques, the method presented employs a
fuzzy relational approach which centers on the fuzzy set
theory and fuzzy logic, to cover issues of similarity
and dissimilarity.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  3334 </NUMBER>
<ORDER>   AAI9544302 </ORDER>
<TITLE> INTELLIGENT CONTROL SYSTEM DESIGN </TITLE>
<AUTHOR> SHAH, BIPIN MAVJI </AUTHOR>
<YEAR> 1995 </YEAR>
<INSTITUTION> THE UNIVERSITY OF TENNESSEE; 0226 </INSTITUTION>
<DESCRIPTORS> ENGINEERING, SYSTEM SCIENCE; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> NIL </ADVISER>
<CLASSIFICATIONS> NIL </CLASSIFICATIONS>
<ABSTRACT>
Process control is implemented at various levels in the
manufacturing process industries. At the micro level it
deals with implementing safety interlocks, tuning
controllers, positioning actuators, etc. At the
textitmacro level it deals with plant wide optimization
and control, supervisory control and scheduling. The
micro level implementation of process control uses
programmable logic controllers (PLC) and distributed
control systems (DCS). The macro level implementation
uses workstations and main frame computers with
communication networks that talk to the controllers at
the micro level. Closed analytic representation is
unavailable at the macro level, and sometimes at the
micro level. Artificial Intelligence plays an important
role in implementing process control at the micro and
macro level. This research looks at implementing
Intelligent Control on an instrumented shell and tube
heat exchanger in the Unit Operations laboratory. The
heat exchanger is controlled by an industrial controller
(PLC) and an operator interface. System Cultivation
tools are developed to monitor and classify process
variable trends. These shallow reasoning tools help
determine if a process is at steady state, under
transition or oscillating. Information from these tools
is used by a expert system to provide intelligent
supervisory control and intelligent system
identification. A framework has been developed to
provide an easy way to implement new control strategies
and system identification techniques which when combined
with the intelligent features of the controller provide
a versatile and fail safe controller.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  3335 </NUMBER>
<ORDER>   AAGMM08288 </ORDER>
<TITLE> SPEAKER INDEPENDENT ISOLATED DIGITS RECOGNITION USING ARTIFICAL NEURAL NETWORKS </TITLE>
<AUTHOR> ZHANG, BAOQUAN </AUTHOR>
<YEAR> 1995 </YEAR>
<INSTITUTION> TECHNICAL UNIVERSITY OF NOVA SCOTIA (CANADA); 0300 </INSTITUTION>
<DESCRIPTORS> ENGINEERING, ELECTRONICS AND ELECTRICAL; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> W. J. PHILLIPS; W. ROBERTSON </ADVISER>
<CLASSIFICATIONS> NIL </CLASSIFICATIONS>
<ABSTRACT>
In this thesis, a neural network based speaker
independent isolated digits recognizer (digits 0 to 9
and the utterance of "oh") is proposed and implemented.
Emphasis is placed on the method of pre-processing the
raw speech signals to get accurate neural network input
patterns and on the choice of a suitable neural network
architecture.
The time marks that divide a digit into sub-acoustic
words are used during pre-processing in order to get
accurate neural network input patterns. It is shown in
this thesis that the time alignment algorithm that takes
time marks into account gives better of recognition
rates than the algorithm that does not use time marks.
An unique set of features of 18 critical-band energies
are also introduced in this thesis. This set of features
is relatively easy to get from the raw speech signals
and is found to be effective when forming the neural
network input patterns. A two-layer feed-forward neural
network that uses the Back Propagation (BP) training
algorithm is used as the pattern matcher. A discussion
on the choice of suitable network sizes is presented.
The proposed system is trained by 22 speakers (22
utterances of each speaker) from four cities
(Philadelphia, Pittsburg, Rochester and Boston) in the
United States of America and tested by 21 speakers that
are different from training ones. The overall
recognition results are 85.1%.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  3336 </NUMBER>
<ORDER>   AAI9543274 </ORDER>
<TITLE> AN EVALUATION OF BACKPROPAGATION NEURAL NETWORK MODELING AS AN ALTERNATIVE METHODOLOGY FOR CRITERION VALIDATION OF EMPLOYEE SELECTION TESTING </TITLE>
<AUTHOR> SCARBOROUGH, DAVID JAMES </AUTHOR>
<YEAR> 1995 </YEAR>
<INSTITUTION> UNIVERSITY OF NORTH TEXAS; 0158 </INSTITUTION>
<DESCRIPTORS> PSYCHOLOGY, INDUSTRIAL; BUSINESS ADMINISTRATION, MANAGEMENT; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> NIL </ADVISER>
<CLASSIFICATIONS> NIL </CLASSIFICATIONS>
<ABSTRACT>
Employee selection research identifies and makes use of
associations between individual differences, such as
those measured by psychological testing, and individual
differences in job performance. Artificial neural
networks are computer simulations of biological nerve
systems that can be used to model unspecified
relationships between sets of numbers.
Thirty-five neural networks were trained to estimate
normalized annual revenue produced by telephone sales
agents based on personality and biographic predictors
using concurrent validation data (N = 1085). Accuracy of
the neural estimates was compared to OLS regression and
a proprietary nonlinear model used by the participating
company to select agents.
Criterion estimates of both models were used to classify
employees as hire/reject using high and mid-cutoff score
values. Model classifications were compared to
classifications based on actual revenue production to
determine model accuracy as defined by percentage of
independent sample cases classified hire/reject
correctly. Obtained differences were tested for
significance using the McNemar procedure.
The networks were significantly more accurate than the
OLS regression model. No significant differences were
found between the networks and the nonlinear model at p
=.01. In forty-two of seventy comparisons, small scale
variance favored the nonlinear model.
Neural validation strategies in employee selection
represent a promising development in the field of
organizational psychology with both scientific and
economic consequences. Research opportunities stemming
from the transfer of neural network technology to the
field of organizational psychology are rich and largely
unexplored.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  3337 </NUMBER>
<ORDER>   AAI9543207 </ORDER>
<TITLE> PRACTICAL CURSIVE SCRIPT RECOGNITION </TITLE>
<AUTHOR> CARROLL, JOHNNY GLEN </AUTHOR>
<YEAR> 1995 </YEAR>
<INSTITUTION> UNIVERSITY OF NORTH TEXAS; 0158 </INSTITUTION>
<DESCRIPTORS> COMPUTER SCIENCE; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> NIL </ADVISER>
<CLASSIFICATIONS> PATTERN RECOGNITION, IMAGE PROCESSING </CLASSIFICATIONS>
<ABSTRACT>
This research focused on the off-line cursive script
recognition application. The problem is very large and
difficult and there is much room for improvement in
every aspect of the problem. Many different aspects of
this problem were explored in pursuit of solutions to
create a more practical and usable off-line cursive
script recognizer than is currently available.
The scope of the project involved a complete solution to
most aspects of the problem. Preprocessing was refined
via a new thinning algorithm and a new Finite Induction
(FI) based vectorization algorithm. Feature extraction
was performed by extracting features from the
singularity graph of the line drawing instead of the
line drawing itself. The feature graph was designed to
provide a very expressive, flexible, and efficient data
structure so all existing features of a singularity
graph can be easily scanned and associated locally. A
new and powerful FI based character extraction mechanism
was created and studied. Character extraction, word
segmentation, and word classification were performed
iteratively in light of the context of the lexicon using
split n-gram indices to assist in word classification
and search space reduction. The use of heuristics was
employed and studied in the recognition of punctuation.
Also, an adaptable system was designed so that the
system could adapt to individual handwriting styles of
experiment participants.
Another focus of this dissertation involved exploring
how the pattern recognition technology known as Finite
Induction could be employed in pursuit of applications
of this nature. FI was a major contributor in two of the
phases. FI technology was adapted for use and
successfully employed in the line segmentation process
and in the character extraction process.
An experiment was conducted which demonstrated that with
reasonable training of the system and reasonable
restrictions placed upon the writer of the cursive
script, successful hand written cursive script
recognition is feasible and usable systems are within
reach.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  3338 </NUMBER>
<ORDER>   AAGMM08271 </ORDER>
<TITLE> GENETIC ALGORITHMS FOR ACTIVE CONTOUR OPTIMIZATION IN COMPUTER VISION </TITLE>
<AUTHOR> MACEACHERN, LEONARD ALEXANDER </AUTHOR>
<YEAR> 1995 </YEAR>
<INSTITUTION> TECHNICAL UNIVERSITY OF NOVA SCOTIA (CANADA); 0300 </INSTITUTION>
<DESCRIPTORS> ENGINEERING, ELECTRONICS AND ELECTRICAL; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> PETER GREGSON </ADVISER>
<CLASSIFICATIONS> NIL </CLASSIFICATIONS>
<ABSTRACT>
This thesis presents an overview of "natural
computation" methods with special consideration given to
a class of Evolutionary Algorithms known as Genetic
Algorithms (GA).
In particular, genetic algorithms are applied to the
solution of computer vision processing tool known as the
"active contour", or "snake".
A brief outline of active contours (snakes) is given,
and previous methods of solving the underlying energy
minimization problem are discussed. The concept of
"snake state" is introduced via a 5-tuple formulation,
and the process of snake state transition from initial
state to final state is detailed. A case is made for a
multi-stage snake energy minimization procedure based on
the generational optimization process of the genetic
algorithm.
A coherent, extensible framework is devised for solving
the snake minimization problem by a genetic algorithmic
approach. A possible algorithm implementation of a snake
solution method based upon this framework is presented,
and the resulting algorithmic complexity is of order
$O(nlambda G)$, where n is the number of control points
for the snake, $lambda$ is the number of individuals per
generation, and G is the number of generations
considered. The new algorithm exhibits several key
features: a low order of complexity, the ability to
handle arbitrary constraints, operation in discrete
space, avoidance of higher-order derivatives, possible
parallel computation, low/fixed storage requirements,
the ability to handle large search spaces comfortably,
and the ability to escape local minima and to handle non-
convex search spaces.
A software implementation of the new algorithm is
presented, and several examples of image contours
located using the genetic algorithm snake are given.
Finally, a comparison between the results obtained from
a brute force technique and the genetic algorithm is
discussed. (Abstract shortened by UMI.)
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  3339 </NUMBER>
<ORDER>   AAI9540874 </ORDER>
<TITLE> NUCLEAR PLANT DIAGNOSTICS USING NEURAL NETWORKS WITH DYNAMIC INPUT SELECTION </TITLE>
<AUTHOR> BASU, ANUJIT </AUTHOR>
<YEAR> 1995 </YEAR>
<INSTITUTION> IOWA STATE UNIVERSITY; 0097 </INSTITUTION>
<DESCRIPTORS> ENGINEERING, NUCLEAR; ARTIFICIAL INTELLIGENCE; ENGINEERING, ELECTRONICS AND ELECTRICAL </DESCRIPTORS>
<ADVISER> ERIC B. BARTLETT </ADVISER>
<CLASSIFICATIONS> NIL </CLASSIFICATIONS>
<ABSTRACT>
The work presented in this dissertation explores the
design and development of a large scale nuclear power
plant (NPP) fault diagnostic system based on artificial
neural networks (ANNs). The viability of detecting a
large number of transients in a NPP using ANNs is
demonstrated. A new adviser design is subsequently
presented where the diagnostic task is divided into
component parts, and each part is solved by an
individual ANN. This new design allows the expansion of
the diagnostic capabilities of an existing adviser by
modifying the existing ANNs and adding new ANNs to the
adviser.
This dissertation also presents an architecture
optimization scheme called the dynamic input selection
(DIS) scheme. DIS analyzes the training data for any
problem and ranks the available input variables in order
of their importance to the input-output relationship.
Training is initiated with the most important input and
one hidden node. As the network training progresses,
input and hidden nodes are added as required until the
networks have learned the problem. Any hidden or input
nodes that were added during training but are
unnecessary for subsequent recall are now removed from
the network. The DIS scheme can be applied to any ANN
learning paradigm.
The DIS scheme is used to train the ANNs that form the
NPP fault diagnostic adviser. DIS completely eliminates
any guesswork related to architecture selection, thus
decreasing the time taken to train each ANN. Each ANN
uses only a small subset of the available input
variables that is required to solve its particular task.
This reduction in the dimensionality of the problem
leads to a drastic reduction in training time.
Data used in this work was collected during the
simulation of transients on the operator training
simulator at Duane Arnold Energy Center, a boiling water
reactor nuclear power plant. An adviser was developed to
detect and classify 30 distinct transients based on the
simulation of 47 scenarios at different severities. This
adviser was then expanded to detect and classify a total
of 36 transients based on the simulation of 58 transient
scenarios. The noise tolerant characteristics of the
adviser are demonstrated.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  3340 </NUMBER>
<ORDER>   AAI9540819 </ORDER>
<TITLE> CHIRON: PLANNING IN AN OPEN-TEXTURED DOMAIN </TITLE>
<AUTHOR> SANDERS, KATHRYN ELIZABETH </AUTHOR>
<YEAR> 1995 </YEAR>
<INSTITUTION> BROWN UNIVERSITY; 0024 </INSTITUTION>
<DESCRIPTORS> COMPUTER SCIENCE; ARTIFICIAL INTELLIGENCE; LAW </DESCRIPTORS>
<ADVISER> THOMAS L. DEAN </ADVISER>
<CLASSIFICATIONS> INCOME TAX LAW </CLASSIFICATIONS>
<ABSTRACT>
Most work in artificial intelligence and law has
concentrated on modelling the type of reasoning done by
trial lawyers. In fact, most lawyers' work involves
planning--for example, wills and trusts, real estate
deals, and business mergers and acquisitions. Certain
planning issues, such as the use of underspecified, or
"open-textured" rules, are illustrated especially
clearly in this domain.
In this thesis, I set forth the characteristic features
of planning n law, place it in the context of past
artificial intelligence work in both law and planning,
and describe scCHIRON, a system that I have developed
implementing my theory of open-textured planning in the
domain of personal income tax law.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  3341 </NUMBER>
<ORDER>   AAI9540781 </ORDER>
<TITLE> PREDICTING REAL-TIME PLANNER PERFORMANCE BY DOMAIN CHARACTERIZATION </TITLE>
<AUTHOR> KIRMAN, JOHN ALAN </AUTHOR>
<YEAR> 1995 </YEAR>
<INSTITUTION> BROWN UNIVERSITY; 0024 </INSTITUTION>
<DESCRIPTORS> COMPUTER SCIENCE; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> NIL </ADVISER>
<CLASSIFICATIONS> NIL </CLASSIFICATIONS>
<ABSTRACT>
There is a large class of problems that involve real-
time planning and execution in stochastic domains.
Classical solutions either ignore the random element
while planning and then modify the plan to deal with
failures, or compute the best action to perform in any
circumstance. These solutions are often either too
brittle or too expensive computationally. I present an
approach that interleaves planning and execution and
reduces the set of circumstances that need to be
considered at a given time. In previous work with other
researchers I have shown that this approach is practical
for some stochastic problems, but left open the question
of which problems the approach can be applied to
effectively. I present a classification of real-time
stochastic decision problems that allows the prediction
of the performance of this planning system (and others)
without resorting to exhaustive empirical performance
estimation. For a number of such planning problems, I
present results showing the correlation between the
predicted performance and the actual performance as
estimated empirically.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  3342 </NUMBER>
<ORDER>   AAI9540737 </ORDER>
<TITLE> LEARNING PROBABILISTIC GRAMMARS FOR LANGUAGE MODELING </TITLE>
<AUTHOR> CARROLL, GLENN </AUTHOR>
<YEAR> 1995 </YEAR>
<INSTITUTION> BROWN UNIVERSITY; 0024 </INSTITUTION>
<DESCRIPTORS> COMPUTER SCIENCE; LANGUAGE, LINGUISTICS; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> NIL </ADVISER>
<CLASSIFICATIONS> MACHINE LEARNING, SPEECH RECOGNITION </CLASSIFICATIONS>
<ABSTRACT>
A language model defines a probability distribution over
the strings of a language. Such models are most commonly
used in speech recognition to assist in disambiguating
words that are phonetically similar but semantically
distinct. Traditional language models have been
statistically sophisticated but linguistically naive.
While they have been very successful, the upper limits
on their performance have been apparent since their
inception. We present a scheme for learning
probabilistic context-free grammars (PCFGs) for use in
linguistically better motivated models. While PCFGs are
powerful enough to address the limitations of previous
models, this increased power makes them more difficult
to learn. We overcome this by using linguistic knowledge
and heuristics, both as constraints and as bias for the
learner. Our approach is experimental, with the emphasis
on developing a practical system. We present the design
of our system, experimental evaluation of various
learning methods used in it, and results showing that
the learned grammars outperform traditional language
models evaluated over the same data.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  3343 </NUMBER>
<ORDER>   AAI9540736 </ORDER>
<TITLE> REAL-TIME OPTICAL FLOW </TITLE>
<AUTHOR> CAMUS, THEODORE ARMAND </AUTHOR>
<YEAR> 1995 </YEAR>
<INSTITUTION> BROWN UNIVERSITY; 0024 </INSTITUTION>
<DESCRIPTORS> COMPUTER SCIENCE; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> HEINRICH BULTHOFF; THOMAS DEAN </ADVISER>
<CLASSIFICATIONS> COMPUTER VISION, ROBOTICS, VISUAL MOTION DETECTION </CLASSIFICATIONS>
<ABSTRACT>
Currently two major limitations to applying vision in
real tasks are robustness in real-world, uncontrolled
environments, and the computational resources required
for real-time, operation. In particular, many current
robotic visual motion detection algorithms (optical
flow) are not suited for practical applications such as
segmentation and structure-from-motion because they
either require highly specialized hardware or up to
several minutes on a scientific workstation. In
addition, many such algorithms depend on the computation
of first and in some cases higher numerical derivatives,
which are notoriously sensitive to noise. In fact the
current trend in optical flow research is to stress
accuracy under ideal conditions and not to consider
computational resource requirements or resistance to
noise, which are essential for real-time robotics. As a
result robotic vision researchers are frustrated by an
inability to obtain reliable optical flow estimates in
real-world conditions, and practical applications for
optical flow algorithms remain scarce. Algorithms based
on the correlation of image patches have been shown to
be robust in practice but are in general infeasible due
to their computational complexity. This thesis describes
a space-time tradeoff to this algorithm which converts a
quadratic-time algorithm into a linear-time one, as well
as a method for dealing with the resulting problem of
temporal aliasing. One limitation of this algorithm is
that it does not give truly real-valued image velocity
measurements. Therefore, it is not obvious that it can
be used for a wide range of robotics vision tasks. One
particular application for optical flow is time-to-
collision: based on the equations for the expansion of
the optical flow field it is possible to compute the
number of frames remaining before contact with an
observed object. Although the individual motion
measurements of this algorithm are of limited precision,
they can be combined in such a manner as to produce
remarkably accurate time-to-contact measurements, which
can be produced at real-time rates.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  3344 </NUMBER>
<ORDER>   AAI9540675 </ORDER>
<TITLE> MISC: A MASSIVELY PARALLEL ARCHITECTURE FOR ASSOCIATIVE- BASED ARTIFICIAL INTELLIGENCE </TITLE>
<AUTHOR> ROBERTS, JAMES D. </AUTHOR>
<YEAR> 1995 </YEAR>
<INSTITUTION> UNIVERSITY OF CALIFORNIA, SANTA CRUZ; 0036 </INSTITUTION>
<DESCRIPTORS> COMPUTER SCIENCE; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> NIL </ADVISER>
<CLASSIFICATIONS> NEURAL NETWORK, SEMANTIC NETWORK, GRAPH </CLASSIFICATIONS>
<ABSTRACT>
Parallel architectures are required to provide the
computational power for future artificial intelligence
research and applications. Massively parallel processing
is emerging as an important alternative to prior
approaches to parallel AI. Unfortunately, contemporary
general-purpose machines are optimized for numeric codes
while application-specific machines do not fully address
the wide variety of algorithms needed by large-scale
knowledge processing. This dissertation investigates
overcoming these limitations through associative content-
based processing of complex dynamic data objects,
focusing on retrieval from large knowledge bases.
Analysis of algorithm-architecture-technology
interactions is the foundation of the MISC architecture
development. To accomplish this, we develop an
associative pseudocode, new parallel algorithms, and an
enhanced design tool. The SEGUL pseudocode features
nested multisets, allowing the expression of knowledge
processing algorithms in a machine-independent manner
for subsequent characterization. Three algorithms serve
as the focus of the analysis: an associative memory
neural network, a semantic network, and a graph
knowledge-base. Suspense, the early analysis tool,
projects speed and cost measures for architectural
alternatives. Functional-level simulation combined with
early analysis of a hypothetical implementation provide
cost-performance projections for evaluating the
resulting architecture.
The MISC system architecture is comprised of multiple
small data-parallel arrays, as the number of processors
required by any one of the algorithms scales sublinearly
with respect to the knowledge base size. The array
processors feature a general-purpose core and additional
functional units to improve content-based knowledge
processing. Each processor also has high bandwidth
access to a large off-chip memory, and inter-processor
communication is by a wide-link extended mesh network.
Analysis shows that advanced packaging is a cost-
effective means of achieving the required high
connectivity. Simulation of the MISC architecture for
the suite of three algorithms indicates more than a
factor of ten improvement in both speed and cost-
performance over a massively parallel architecture
tailored for numeric codes.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  3345 </NUMBER>
<ORDER>   AAI9540659 </ORDER>
<TITLE> ACTIVE IMAGE REGISTRATION AND RECOGNITION </TITLE>
<AUTHOR> WANG, MAO </AUTHOR>
<YEAR> 1995 </YEAR>
<INSTITUTION> UNIVERSITY OF KENTUCKY; 0102 </INSTITUTION>
<DESCRIPTORS> ENGINEERING, ELECTRONICS AND ELECTRICAL; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> BRUCE WALCOTT; LARRY HASSEBROOK </ADVISER>
<CLASSIFICATIONS> FEATURE MATCHING, ACTIVE CONTOUR </CLASSIFICATIONS>
<ABSTRACT>
Image feature matching is the key to image registration
and recognition. In this dissertation, an active image
feature matching technique is developed, which
incorporates both local and global information in the
matching process to achieve a global optimal goodness-of-
match. In addition, since this technique is contour-
based, it is particularly useful in situations of
multisensor images where images have different gray
level characteristics but contours representing region
boundaries are preserved. First, an optimal active
contour (snake) is used to reduce the 2D object of
interest to a 1D contour feature string. This snake has
the capability to extract accurate information about an
object's corners that contains significant discriminant
information. High performance is achieved by dividing
the energy optimization process into multiple stages.
The first stage was designed to optimize the convergence
speed in order to allow the snake to quickly approach
the optimal state. The second stage was devoted to snake
refinement and to the local optimization of energy
thereby driving the snake to the quasi-optimal state.
The third stage uses the Bellman optimality principle to
fine tune the snake to the global optimal state. This
three-stage scheme optimized both performance and speed
of the snake. After the objects to be matched were
reduced to two feature vector strings, dynamic feature
matching (DFM) was used to match these strings. DFM
matched the two feature strings in a global optimal way
by using both the Bellman optimality principle as well
as a back-propagation neural network. Also, a hidden
Markov model for dynamic feature matching was derived.
This model shows that the dynamic feature matching is
optimal in the sense of maximum likelihood. An active
image registration system was then introduced using
active feature matching to obtain a partial disparity
map from which a full disparity map was estimated using
regularization. This system is tested on a sequence of
MR functional brain images. Results show that the brain
activation map obtained from registered images was
significantly improved when compared to nonregistered
images. Finally, an active image recognition system is
implemented based on active feature matching. This
system is applied to aircraft images and results
indicate that the active recognition system has superior
distortion tolerance over the correlation based system.
It maintains good performance over a wide range of
distortion. This tolerance to distortion is due to its
"active" nature. In other words, to some extent, it
mimicks human vision by dynamically adjusting the
matching path so that the differences due to perspective
distortion was minimized.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  3346 </NUMBER>
<ORDER>   AAI9540084 </ORDER>
<TITLE> SYSTEM IDENTIFICATION USING WAVEARX NEURAL NETWORK </TITLE>
<AUTHOR> CHEN, JUNGHUI </AUTHOR>
<YEAR> 1995 </YEAR>
<INSTITUTION> THE UNIVERSITY OF TENNESSEE; 0226 </INSTITUTION>
<DESCRIPTORS> ENGINEERING, CHEMICAL; COMPUTER SCIENCE; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> DUANE D. BURNS </ADVISER>
<CLASSIFICATIONS> NIL </CLASSIFICATIONS>
<ABSTRACT>
The WaveARX neural network is an innovative system
identification algorithm. Its development is motivated
by the needs of improving the traditional artificial
neural network, such as providing guidelines for the
structure determination and speeding up training. Also,
few identification techniques are available for
distinguishing linear from nonlinear characteristics of
a process. Therefore, these are the problems to be
addressed in this research.
The WaveARX network, a new ANN architecture, is
proposed. It evolves from the three layer feedforward
neural network and allows both on-line and off-line
process applications. The WaveARX network structure,
including the number of neurons, initial values of the
network parameters and parameter update, is determined
by multiresolution analysis of wavelet transforms (MRA),
classical Gram-Schmidt algorithm (CGS) and the two-stage
optimization scheme. Besides, a traditional linear
model, AutoRegressive eXternal input model (ARX), is
constructed in parallel with the three layer network.
The combinational network not only improves the
approximation performance of ANN but also isolates and
quantifies linear and nonlinear contributions to a
process.
The WaveARX network extended to on-line applications is
called the adaptive WaveARX network. With a rectangular
window moving at each sampling time, MRA and CGS are
used to determine when and where a new neuron should be
generated and/or an old one should be removed. By these
training procedures, the network structure is flexible,
so the number and location of neurons as well as
parameters can be adjusted according to the changes of
the process behavior.
A total of eight off-line and on-line simulation
examples are presented for testing the capability of the
WaveARX network. Their results suggest that the WaveARX
network with less neurons and training time has a
better, or at least similar, approximation ability as
some widely used linear, nonlinear or neural network
techniques. The major contributions of the WaveARX
network are: (1) improving the accuracy of ANN for
system identification, (2) isolating and quantifying
linearity and nonlinearity of a process, (3) achieving
an effective approximation with less training time and
faster convergence, and (4) producing adaptable network
structure so the model can be responsive to the changing
process behavior.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  3347 </NUMBER>
<ORDER>   AAI9539737 </ORDER>
<TITLE> NEURAL NETWORK MODELS FOR THE WIRE BONDING PROCESS </TITLE>
<AUTHOR> SUN, XIAOYUN </AUTHOR>
<YEAR> 1995 </YEAR>
<INSTITUTION> UNIVERSITY OF MARYLAND COLLEGE PARK; 0117 </INSTITUTION>
<DESCRIPTORS> OPERATIONS RESEARCH; STATISTICS; COMPUTER SCIENCE; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> BRUCE L. GOLDEN </ADVISER>
<CLASSIFICATIONS> MICROCIRCUITS </CLASSIFICATIONS>
<ABSTRACT>
The wire bonding process is a crucial step in
manufacturing microcircuits. It uses ultrasonic power to
weld a very thin gold wire to areas on a substrate.
Currently, wire bonds are screened for quality by visual
inspection and a non-destructive pull-strength test.
Both screening methods are costly and time-consuming but
not highly reliable. So far no adequate mathematical and
physical models exist that predict wire bond quality.
The relationship between wire bond quality and
ultrasonic measurements has never been well understood.
In this dissertation, we apply artificial neural network
methods to model the relationship between wire bond
quality and ultrasonic data recorded during the
manufacturing of wire bonds. Specifically, our models
are able to: (1) predict a wire bond's pull-strength
value and (2) classify wire bonds as good or defective.
For data preprocessing and model comparison purposes,
several statistical techniques including multiple linear
regression and multivariate discriminant analysis are
used. We also develop several new enhancements to the
backpropagation learning rule. These enhancements have
been implemented and have proven to be effective.
The results of our modeling efforts reveal that neural
networks are useful and cost-effective tools for a
quality inspection system. On test data sets our neural
network models are able to correctly predict bad wire
bonds about 96.8% of the time, and correctly classify
wire bonds about 96.6% of the time on average. In this
problem setting, our neural network models outperform
regression models and three different discriminant
analysis models. Our enhanced algorithm outperforms
commercial software which is based upon standard
backpropagation learning rule.
Chapter 2 provides background on the wire bonding
problem. Chapter 3 is devoted to a literature review
from both theoretical and empirical points of view. Our
research methodology is presented in Chapter 4. Chapter
5 describes our neural network enhancements and related
experiments that we perform to judge a model's
effectiveness. Chapter 6 reports the models and results
of predicting a wire bond's pull-strength value. Chapter
7 presents the models and results for classifying wire
bonds and a cost-benefit analysis. Chapter 8 gives our
conclusions and points to future research.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  3348 </NUMBER>
<ORDER>   AAGMM07974 </ORDER>
<TITLE> FAST IMAGE SEGMENTATION USING STEREO VISION </TITLE>
<AUTHOR> EZZATI, MAJID </AUTHOR>
<YEAR> 1995 </YEAR>
<INSTITUTION> MCGILL UNIVERSITY (CANADA); 0781 </INSTITUTION>
<DESCRIPTORS> ENGINEERING, ELECTRONICS AND ELECTRICAL; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> M. D. LEVINE </ADVISER>
<CLASSIFICATIONS> MACHINE VISION </CLASSIFICATIONS>
<ABSTRACT>
Binocular stereopsis is a biologically motivated
approach that uses two slightly different views of a
scene to extract information about its three-dimensional
properties. The two underlying principles of our
approach to stereo vision are local computation of
binocular disparities and the use of the resulting
disparity map for image segmentation.
The cepstrum is used to provide an estimation of
binocular disparity between corresponding regions of the
stereo image pair. We study the cepstrum and its
properties, and suggest improvements to the initial
disparity estimation stage. Next a modified median
filtering scheme is employed for the refinement of the
initial disparities using neighbourhood information. The
overall disparity map is used for image segmentation
based on distance.
Local estimation of initial disparities provides two
fundamental advantages for real-time systems: the
possibility of increased computational efficiency
through parallel implementation and a fixed running time
that is independent of image properties. Furthermore,
using stereopsis for figure-ground segmentation rather
than surface reconstruction eliminates the need for
camera calibration which is essential for methods based
on exact depth calculation. Therefore, the approach is
well-suited to active vision systems in which the
cameras are in constant motion.
We provide evidence for the plausibility of the
disparity estimation algorithm and the properties of the
overall disparity map in the context of biological
stereopsis. The algorithm is implemented on a network of
TMS320C40 processors to obtain a processing time of one
second for a 128-pixel $times$ 128-pixel image frame.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  3349 </NUMBER>
<ORDER>   AAI9539585 </ORDER>
<TITLE> VISUAL PATTERN RECOGNITION USING NEURAL NETWORKS </TITLE>
<AUTHOR> MOH, JENLONG </AUTHOR>
<YEAR> 1995 </YEAR>
<INSTITUTION> NEW JERSEY INSTITUTE OF TECHNOLOGY; 0152 </INSTITUTION>
<DESCRIPTORS> COMPUTER SCIENCE; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> FRANK Y. SHIH </ADVISER>
<CLASSIFICATIONS> IMAGE RECOGNITION </CLASSIFICATIONS>
<ABSTRACT>
Neural networks have been widely studied in a number of
fields, such as neural architectures, neurobiology,
statistics of neural network and pattern classification.
In the field of pattern classification, neural network
models are applied on numerous applications, for
instance, character recognition, speech recognition, and
object recognition. Among these, character recognition
is commonly used to illustrate the feature and
classification characteristics of neural networks.
In this dissertation, the theoretical foundations of
artificial neural networks are first reviewed and
existing neural models are studied. The Adaptive
Resonance Theory (ART) model is improved to achieve more
reasonable classification results. Experiments in
applying the improved model to image enhancement and
printed character recognition are discussed and
analyzed. We also study the theoretical foundation of
Neocognitron in terms of feature extraction, convergence
in training, and shift invariance.
We investigate the use of multilayered perceptrons with
recurrent connections as the general purpose modules for
image operations in parallel architectures. The networks
are trained to carry out classification rules in image
transformation. The training patterns can be derived
from user-defined transformations or from loading the
pair of a sample image and its target image when the
prior knowledge of transformations is unknown.
Applications of our model include image smoothing,
enhancement, edge detection, noise removal,
morphological operations, image filtering, etc. With a
number of stages stacked up together we are able to
apply a series of operations on the image. That is, by
providing various sets of training patterns the system
can adapt itself to the concatenated transformation. We
also discuss and experiment in applying existing neural
models, such as multilayered perception, to realize
morphological operations and other commonly used imaging
operations.
Some new neural architectures and training algorithms
for the implementation of morphological operations are
designed and analyzed. The algorithms are proven correct
and efficient. The proposed morphological neural
architectures are applied to construct the feature
extraction module of a personal handwritten character
recognition system. The system was trained and tested
with scanned image of handwritten characters. The
feasibility and efficiency are discussed along with the
experimental results.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  3350 </NUMBER>
<ORDER>   AAI9539579 </ORDER>
<TITLE> DOCUMENT PREPROCESSING AND FUZZY UNSUPERVISED CHARACTER CLASSIFICATION </TITLE>
<AUTHOR> CHEN, SHY-SHYAN </AUTHOR>
<YEAR> 1995 </YEAR>
<INSTITUTION> NEW JERSEY INSTITUTE OF TECHNOLOGY; 0152 </INSTITUTION>
<DESCRIPTORS> COMPUTER SCIENCE; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> PETER A. NG; FRANK Y. SHIH </ADVISER>
<CLASSIFICATIONS> NIL </CLASSIFICATIONS>
<ABSTRACT>
This dissertation presents document preprocessing and
fuzzy unsupervised character classification for
automatically reading daily-received office documents
that have complex layout structures, such as multiple
columns and mixed-mode contents of texts, graphics and
half-tone pictures. First, the block segmentation
algorithm is performed based on a simple two-step run-
length smoothing to decompose a document into single-
mode blocks. Next, the block classification is performed
based on the clustering rules to classify each block
into one of the types such as text, horizontal or
vertical lines, graphics, and pictures. The mean white-
to-black transition is shown as an invariance for
textual blocks, and is useful for block discrimination.
A fuzzy model for unsupervised character classification
is designed to improve the robustness, correctness, and
speed of the character recognition system. The
classification procedures are divided into two stages.
The first stage separates the characters into seven
typographical categories based on word structures of a
text line. The second stage uses pattern matching to
classify the characters in each category into a set of
fuzzy prototypes based on a nonlinear weighted
similarity function. A fuzzy model of unsupervised
character classification, which is more natural in the
representation of prototypes for character matching, is
defined and the weighted fuzzy similarity measure is
explored. The characteristics of the fuzzy model we
discussed and used in speeding up the classification
process.
After classification, the character recognition
procedure is simply applied on the limited versions of
the fuzzy prototypes. To avoid information loss and
extra distortion, an topography-based approach is
proposed to apply directly on the fuzzy prototypes to
extract the skeletons. First, a convolution by a bell-
shaped function is performed to obtain a smooth surface.
Second, the ridge points are extracted by rule-based
topographic analysis of the structure. Third, a
membership function is assigned to ridge points with
values indicating the degrees of membership with respect
to the skeleton of an object. Finally, the significant
ridge points are linked to form strokes of skeleton, and
the clues of eigenvalue variation are used to deal with
degradation and preserve connectivity. Experimental
results show that our algorithm can reduce the
deformation of junction points and correctly extract the
whole skeleton although a character is broken into
pieces. For some characters merged together, the
breaking candidates can be easily located by searching
for the saddle points. A pruning algorithm is then
applied on each breaking position. At last, a multiple
context confirmation can be applied to increase the
reliability of breaking hypotheses.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  3351 </NUMBER>
<ORDER>   AAI9538279 </ORDER>
<TITLE> ON-LINE RADIAL BASIS FUNCTION NETWORK CENTER ADAPTATION FOR NONLINEAR ADAPTIVE IDENTIFICATION AND CONTROL </TITLE>
<AUTHOR> CHAN, ALISTAIR KEATING </AUTHOR>
<YEAR> 1995 </YEAR>
<INSTITUTION> UNIVERSITY OF CINCINNATI; 0045 </INSTITUTION>
<DESCRIPTORS> ENGINEERING, AEROSPACE; ENGINEERING, ELECTRONICS AND ELECTRICAL; ENGINEERING, SYSTEM SCIENCE; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> GEORGES A. BECUS </ADVISER>
<CLASSIFICATIONS> NEURAL NETWORKS </CLASSIFICATIONS>
<ABSTRACT>
Nonlinear adaptive identification and control are
difficult to solve problems which are now being solved
by the application of neural networks. Neural networks
provide a solid framework for attacking these problems
as they are described by adjustable parameters which are
readily adaptable on-line and they are universal
function approximators. Radial basis function networks
have been shown to be functional in these systems
especially when one attempts to consider the analytical
proof of stability. Most algorithms developed for radial
basis function networks for these applications consider
only on-line adaptation of the output layer weights
alone. This dissertation describes and demonstrates two
novel algorithms which adapt the radial basis function
center parameters as well as the output layer weights on-
line. The first algorithm simply translates the
initially chosen center lattice within the network input
space. This algorithm is also shown to be equivalent to
a recurrent radial basis function network. Using this
algorithm results in faster learning of the output layer
weights. The second algorithm described is a discrete-
time algorithm that moves the centers to new locations
within the network input space. Use of this algorithm
reduces the amount of required a priori information
about the functions to be approximated. Heuristic and
analytical stability results are provided along with
simulation examples which show the potential for these
algorithms.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  3352 </NUMBER>
<ORDER>   AAI9537146 </ORDER>
<TITLE> AN ANYTIME APPROACH TO CONNECTIONIST THEORY REFINEMENT: REFINING THE TOPOLOGIES OF KNOWLEDGE-BASED NEURAL NETWORKS </TITLE>
<AUTHOR> OPITZ, DAVID WILLIAM </AUTHOR>
<YEAR> 1995 </YEAR>
<INSTITUTION> THE UNIVERSITY OF WISCONSIN - MADISON; 0262 </INSTITUTION>
<DESCRIPTORS> COMPUTER SCIENCE; STATISTICS; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> JUDE WILLIAM SHAVLIK </ADVISER>
<CLASSIFICATIONS> NIL </CLASSIFICATIONS>
<ABSTRACT>
Many scientific and industrial problems can be better
understood by learning from samples of the task at hand.
For this reason, the machine learning and statistics
communities devote considerable research effort on
generating inductive-learning algorithms that try to
learn the true "concept" of a task from a set of its
examples. Often times, however, one has additional
resources readily available, but largely unused, that
can improve the concept that these learning algorithms
generate. These resources include available computer
cycles, as well as prior knowledge describing what is
currently known about the domain. Effective utilization
of available computer time is important since for most
domains an expert is willing to wait for weeks, or even
months, if a learning system can produce an improved
concept. Using prior knowledge is important since it can
contain information not present in the current set of
training examples.
In this thesis, I present three "anytime" approaches to
connectionist theory refinement. Briefly, these
approaches start by translating a set of rules
describing what is currently known about the domain into
a neural network, thus generating a knowledge-based
neural network (KNN). My approaches then utilize
available computer time to improve this KNN by
continually refining its weights and topology. My first
method, TopGen, searches for good "local" refinements to
the KNN topology. It does this by adding nodes to the
KNN in a manner analogous to symbolically adding rules
and conjuncts to an incorrect rule base. My next
approach, R scEGENT, uses genetic algorithms to find
better "global" changes to this topology. R scEGENT
proceeds by using (a) the domain-specific rules to help
create the initial population of KNNs and (b) crossover
and mutation operators specifically designed for KNNs.
My final algorithm, A scDDEMUP, searches for an
"ensemble" of KNNs that work together to produce an
effective composite prediction. A scDDEMUP works by
using genetic algorithms to continually create new
networks, keeping the set of networks that are as
accurate as possible while disagreeing with each other
as much as possible. Empirical results show that these
algorithms successfully achieve each of their respective
goals.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  3353 </NUMBER>
<ORDER>   AAI9535078 </ORDER>
<TITLE> ANALYSIS OF IMPEDANCE AND INDUCTANCE VENTILATION SENSORS AND FUZZY LOGIC FOR ECG QRS DETECTION </TITLE>
<AUTHOR> COHEN, KEVIN P. </AUTHOR>
<YEAR> 1995 </YEAR>
<INSTITUTION> THE UNIVERSITY OF WISCONSIN - MADISON; 0262 </INSTITUTION>
<DESCRIPTORS> ENGINEERING, BIOMEDICAL; ENGINEERING, ELECTRONICS AND ELECTRICAL; ARTIFICIAL INTELLIGENCE; BIOLOGY, PHYSIOLOGY </DESCRIPTORS>
<ADVISER> JOHN G. WEBSTER </ADVISER>
<CLASSIFICATIONS> IMPEDANCE PLETHYSMOGRAPHY </CLASSIFICATIONS>
<ABSTRACT>
The long-term goal of this research is to develop
improved apnea monitors. This includes a primary measure
of ventilation and a secondary physiological indicator
not related to ventilation, the electrocardiogram (ECG).
Magnetic coupling due to the mutual inductance between
chest and abdominal bands modulates the desired
oscillation frequencies in a respiratory inductance
plethysmograph (RIP). When modulation is excessive,
frequency locking occurs and RIP cannot make independent
measures of ribcage (rc) and abdominal (abd) area. We
have performed simulations which show that, as the rc
and abd band oscillator frequencies are sufficiently
separated, we decrease modulation and avoid frequency
locking.
We compared the relative performance of RIP and
impedance plethysmography (IP) on adults and on infants
during natural breathing, motion, apnea and airway
obstruction. On adults no individual sensor or
combination of sensors was more accurate than RIP
calibrated during an isovolume maneuver. During natural
breathing and artifacts that did not involve arm
movement, no other individual sensor measured tidal
volume more accurately than IP(rc). During arm
movements, no other individual sensor was more accurate
than RIP(abd). On infants, no other individual sensors
resulted in lower bias (mean error) or limits of
agreement (bias $pm$ 2SD of errors) than IP(rc). IP(rc)
measurements of tidal volume during quiet breathing of
10.0 ml had a mean bias of 0.8 ml, with limits of
agreement from $-$5.6 to 7.2 ml. During motion,
spontaneous apnea and airway obstruction, the IP(rc)
bias increased to 7.6 $pm$ 8.4, 4.8 $pm$ 4.2, and 7.6
$pm$ 4.2 ml (mean $pm$ 2SD), respectively. The
combination of RIP(abd) and RIP(rc) was not
significantly more accurate than IP(rc). IP(rc)
measurements obtained at 35 kHz and 185 kHz appeared
similar, and IP(abd) measurements were the most
unreliable.
We developed an algorithm to detect QRS complexes from
the ECG using a fuzzy neural network. Overall, for the
entire MIT/BIH database our algorithm reduced the total
number of combined false-positive and false-negative
detections from 588 to 370 compared to our most accurate
existing algorithm.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  3354 </NUMBER>
<ORDER>   AAINN98365 </ORDER>
<TITLE> DEVELOPMENT OF A KNOWLEDGE-BASED HIERARCHICAL CONTROL STRUCTURE FOR PROCESS AUTOMATION </TITLE>
<AUTHOR> WICKRAMARACHCHI, NALIN KUMARA </AUTHOR>
<YEAR> 1995 </YEAR>
<INSTITUTION> THE UNIVERSITY OF BRITISH COLUMBIA (CANADA); 2500 </INSTITUTION>
<DESCRIPTORS> ENGINEERING, MECHANICAL; ENGINEERING, SYSTEM SCIENCE; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> C. W. DE SILVA </ADVISER>
<CLASSIFICATIONS> FUZZY LOGIC </CLASSIFICATIONS>
<ABSTRACT>
Fuzzy logic is applicable in representation and
processing of knowledge in some types of knowledge-based
control. The technique is particularly useful when the
plant that is to be controlled is complex, incompletely
known, and difficult to model either analytically or
experimentally, but when a knowledge base is available
in the form of if-then rules containing fuzzy
descriptors. The standard practice of applying fuzzy
logic in control systems is to replace a conventional
direct controller with a rulebase and an inference
mechanism that is based on fuzzy set theory. Thus, in
the standard fuzzy logic control, the knowledge-based
controller is located in the low-level control loop
itself.
In the present research, a significantly different
approach to standard fuzzy logic control, one that is
particularly useful in process automation, is
considered. The knowledge-based control system developed
in this research has a hierarchical architecture, where
knowledge-based decision making that depends on fuzzy
logic, is employed for high-level functions like process
monitoring, tuning, and supervisory control, leaving the
low-level direct control to conventional controllers. It
is argued that since fuzzy logic is primarily a method
of artificial intelligence, the proper place for such a
tool would be the upper levels of a hierarchy rather
than in low-level direct control, where the fastest and
most high-resolution data processing take place.
A general model for a hierarchical fuzzy system is
introduced, which uses transitional and combinational
operators. Some characteristics of these operators are
explored. Hierarchical fuzzy systems are shown to be
characterized by several heuristic features such as
information resolution, fuzziness of information, and
the required data processing intelligence. Some
preliminary relationships between these parameters are
explored.
It is argued that fish processing is one application
where the knowledge-based hierarchical control system
that is developed in this research, is appropriate. The
rationale for this choice is given. As the application
testbed of the developed technology, an automated
workcell for fish processing that has been developed in
the Industrial Automation Laboratory is employed. An on-
line system is implemented for monitoring and tuning of
the workcell, which incorporates computer vision,
knowledge based tuning, servomotor operation, and
conveyor control. The attractiveness of employing fuzzy
logic in the context of a data processing hierarchy is
illustrated, by means of a case study of application,
where large quantities of low-level information that is
generated by various sensors are abstracted through the
use of fuzzy-logic based processing. The resulting
information that has a lower resolution but more
amenable to knowledge-based decision making, permits one
to perform more intelligent data processing at a reduced
computational burden, and by making use of available
experience and expertise on the particular process
plant.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  3355 </NUMBER>
<ORDER>   AAI9544296 </ORDER>
<TITLE> HYBRID SYSTEMS FOR ROBUSTNESS AND PERSPICUITY: SYMBOLIC RULE INDUCTION COMBINED WITH A NEURAL NET OR A STATISTICAL MODEL </TITLE>
<AUTHOR> GIM, GWANGYONG </AUTHOR>
<YEAR> 1995 </YEAR>
<INSTITUTION> GEORGIA STATE UNIVERSITY; 0079 </INSTITUTION>
<DESCRIPTORS> BUSINESS ADMINISTRATION, GENERAL; BUSINESS ADMINISTRATION, ACCOUNTING; OPERATIONS RESEARCH; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> THOMAS WHALEN </ADVISER>
<CLASSIFICATIONS> NIL </CLASSIFICATIONS>
<ABSTRACT>
The purpose of this research was to investigate (a) the
feasibility of hybrid models combining the perspicuity
of symbolic rule induction with the robustness of the
neural network or statistical models and (b) the
modifiability of hybrid and nonhybrid models by experts.
$theta$, the area under the receiver operating
characteristics (ROC) curve, was used as a measure of
classification performance.
Each hybrid model was generated by applying ID3 to the
training sample cases but with a criterion variable
based on the categorized output of the LOGIT or neural
network(NN). LOGIT output is an estimate of the
probability that a firm will go bankrupt, while NN is
best viewed as the membership grade of a case in the
fuzzy set of cases at risk for bankruptcy. These
continuous numerical outputs were converted into a
consistent set of ordinal risk categories based on
optimal criterion, which showed the highest $theta$ in
the training set. Overall, the performance of the hybrid
models was roughly equal to that of the corresponding
nonhybrid models; thus, the gain in perspicuity was
achieved at no significant cost in accuracy. In
addition, all hybrid models had higher prediction
accuracy than nonhybrid ID3. These results suggested
that the method of hybrid model is appropriate in
classifying bankruptcy risk.
An experiment was used to test the modifiability of
hybrid and nonhybrid models. Experts, matched for their
degree of expertise, independently modified each set of
If-Then rules generated from nonhybrid ID3, hybrid model
with neural network, and hybrid model with LOGIT. There
was no significant evidence of a main effect of human
modification, but there was a significant interaction
effect of human modification and type of (non)hybrid
models. Therefore, the effect of human modification is
unpredictable without specifying the source of the rules
the human is modifying. In conclusion, the prediction
accuracy of hybrid model with NN was increased after
experts' modification, while the prediction accuracy of
hybrid model with LOGIT was decreased after experts'
modification. The prediction accuracy of nonhybrid ID3
was not changed after experts' modification.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  3356 </NUMBER>
<ORDER>   AAI9543026 </ORDER>
<TITLE> USING A COGNITIVE ARCHITECTURE TO DESIGN INSTRUCTIONS </TITLE>
<AUTHOR> MERTZ, JOSEPH S., JR. </AUTHOR>
<YEAR> 1995 </YEAR>
<INSTITUTION> CARNEGIE-MELLON UNIVERSITY; 0041 </INSTITUTION>
<DESCRIPTORS> EDUCATION, TECHNOLOGY; COMPUTER SCIENCE; EDUCATION, PSYCHOLOGY; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> JILL H. LARKIN </ADVISER>
<CLASSIFICATIONS> OCCUPATIONAL TRAINING </CLASSIFICATIONS>
<ABSTRACT>
In this thesis, I describe a cognitive engineering
approach to designing instruction for occupational
training. One problem with existing training programs is
that expertise is difficult to teach, particularly when
it requires learning to use problem solving and learning
as part of the job. Furthermore, when the expertise is
mental ability, experts often cannot articulate what
they know. Recent interdisciplinary work between
psychology and computer science has created tools that
enable an applied science approach to education and
training. A cognitive architecture is one such tool; it
is a broad theory of human cognition, based on a wide
range of experimental data, that is implemented as a
computer application. It provides a theoretical
framework for engineering cognitive models to solve
practical problems that concern learning and problem-
solving. Soar is one example of a cognitive
architecture. The research reported in this thesis
demonstrates how the Soar cognitive architecture can be
used in an applied science, or cognitive engineering,
approach to training.
This thesis includes three major research contributions.
The first is a theory of how to learn more when
performing repeated actions by putting obstacles in your
way to force learning. The theory is derived from a Soar
model that explains how experts use learning to their
advantage when performing repeated actions.
The second contribution is a theory of how people can
learn from direct instruction. Soar has no innate
mechanism for taking the instructions it sees and
transforming them into behavior. Rather, learning
happens when impasses are hit, and new knowledge is
needed to continue. This suggests that deliberate
learning can only be done indirectly, by reasoning in
ways that take advantage of how the mind naturally
learns.
The third contribution is a method for designing
instruction using a simulated-student. A simulated-
student is a cognitive model that can be used to do
formative evaluation of instruction. To accomplish this,
it has prerequisite skill in a subject, and the ability
to learn from instructions. Lessons are developed by
iteratively drafting and testing instructions on the
simulated student. In this thesis, instruction is
designed for training circuit board assemblers.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  3357 </NUMBER>
<ORDER>   AAI9541882 </ORDER>
<TITLE> NONLINEAR TIME SERIES FORECASTING WITH NEURAL NETWORKS </TITLE>
<AUTHOR> RHEE, MAXWELL JOO </AUTHOR>
<YEAR> 1995 </YEAR>
<INSTITUTION> UNIVERSITY OF CALIFORNIA, LOS ANGELES; 0031 </INSTITUTION>
<DESCRIPTORS> ECONOMICS, FINANCE; STATISTICS; COMPUTER SCIENCE; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> MASANAO AOKI </ADVISER>
<CLASSIFICATIONS> STOCK MARKET, DEUTSCHMARK FUTURES </CLASSIFICATIONS>
<ABSTRACT>
Composed of two empirical studies, this dissertation
investigates the effectiveness and utility of neural
networks in accurately forecasting the short-term
behavior of a variety financial time series.
The first study employs a recurrent neural network as a
nonlinear function approximator to forecast the out-of-
sample return on two stock market indices: the Dow Jones
Industrial Average and Standard and Poor's 500 Composite
Index. The use of an extensive, multivariate information
set and a global stochastic maximization algorithm
distinguishes this study from prior work. The data set
investigated encompasses daily observations from 1970
through 1993, with the following forecast exercise
undertaken. For a variety of model sizes, the network
task is to approximate the weekly, monthly or quarterly
conditional mean return. These forecasts are conditioned
on a daily information set containing a number of index-
specific and market-wide variables, term structure and
corporate bond yields, and calendar variables. Network
performance is evaluated by out-of-sample normalized
mean-squared error, sample statistics describing the
joint distribution of forecasted and actual returns, and
tests for market-timing ability and nonlinear
independence. A further performance evaluation concerns
the construction of trading portfolios with transaction
costs. Bootstrapping techniques are also applied to
construct surrogate distributions of the out-of-sample
statistics. Finally, impulse-response and input ranking
analysis are addressed to characterize the network
solutions. It is found that neural networks perform more
than adequately when compared with a benchmark linear
model, and that is possible to generate large risk-
adjusted returns over and above simple buy-and-hold
strategies.
The second study again using this nonlinear model
concentrates on accurately forecasting daily high and
low Deutschmark futures prices. Results are presented
for a number of model estimations which employ eight
years of in-sample data to forecast two years of out-of-
sample data. Two experiments are conducted: (1) a data
shuffling exercise to determine the sensitivity of
network performance with respect to partitioning of data
into in-sample and out-of-sample data sets; and (2) a
Monte Carlo analysis of network performance with respect
to variation in parameter search initialization.
Generally, evidence is found of substantial ability to
conditionally forecast both market direction and
magnitude.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  3358 </NUMBER>
<ORDER>   AAI9541127 </ORDER>
<TITLE> THE LEARN, EXPLORE, AND PRACTICE </TITLE>
<AUTHOR> LINTON, FRANKLYN N., JR. </AUTHOR>
<YEAR> 1995 </YEAR>
<INSTITUTION> UNIVERSITY OF MASSACHUSETTS; 0118 </INSTITUTION>
<DESCRIPTORS> EDUCATION, ADULT AND CONTINUING; EDUCATION, CURRICULUM AND INSTRUCTION; EDUCATION, TECHNOLOGY </DESCRIPTORS>
<ADVISER> KLAUS SCHULTZ </ADVISER>
<CLASSIFICATIONS> LEAP </CLASSIFICATIONS>
<ABSTRACT>
Intelligent Tutoring Systems (ITS) can provide
individualized instruction in problem-solving skills, a
kind of instruction that until recently only humans
could perform. While ITS have been an active area of
research for nearly twenty-five years and researchers
have convincingly demonstrated that ITS can instruct in
various ways, few ITS are in actual use and their
potential benefit to learners is unrealized.
This research is predicated on the notion that ITS
research has three closely related but distinct foci:
artificial intelligence research in tutoring,
instructional research in tutoring, and research on
practical tutoring; and on the notion that investigation
and evaluation in the latter two areas has been lacking.
With respect to instructional research in tutoring, this
work examines the extent to which conventional
instructional design theory can usefully inform the
design of intelligent tutors, the means of incorporating
instructional methods into an intelligent tutor, and the
range of instructional skills necessary in a practical
intelligent tutor. It examines how ITSs push
instructional design theory in the area of computational
instructional design and presents a new instructional
method: Focused Practice. Evaluation of tutoring skills
focused on trainees' usage of the tutor and the
resulting learning, and on measuring the extent to which
the tutor was capable of individualizing instruction.
With respect to research on practical tutoring, this
work examines the extent to which it is feasible to
simulate a work environment, represent the expertise of
a non-formal domain, construct a large knowledge base,
build a functional student model, supply a shell and
authoring tools, incorporate a variety of instructional
skills, instructional activities, and instructional
materials into a cohesive tutoring package that
integrates well into a training program; and gain
support from the variety of stakeholders affected by the
tutor. Evaluation of practicality focused on trainees'
and instructors' affective responses toward the tutor,
their perceptions of usability and instructional value;
and on other stakeholders' (instructional designers,
managers from research, production and training)
perceptions of value.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  3359 </NUMBER>
<ORDER>   AAGMM07719 </ORDER>
<TITLE> A TIME-MULTIPLEXED FPGA ARCHITECTURE FOR LOGIC EMULATION </TITLE>
<AUTHOR> JONES, DAVID EDGAR </AUTHOR>
<YEAR> 1995 </YEAR>
<INSTITUTION> UNIVERSITY OF TORONTO (CANADA); 0779 </INSTITUTION>
<DESCRIPTORS> ENGINEERING, ELECTRONICS AND ELECTRICAL; COMPUTER SCIENCE; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> D. M. LEWIS </ADVISER>
<CLASSIFICATIONS> NIL </CLASSIFICATIONS>
<ABSTRACT>
This thesis describes VEGA, a special-purpose logic
emulation processor and associated software, designed to
achieve maximum usable logic block density per unit
silicon area and fast mapping. Logic blocks are
represented by instructions stored in on-chip memories.
A circuit is emulated by sequentially executing the
instructions that describe it. Three independent
execution units and a two-level memory hierarchy offer
high emulation performance.
FPGA-based logic emulators are capacity-limited by the
low gate density on FPGAs and typically achieve no more
than 25% logic block utilization due to I/O
restrictions. Using similar technology, VEGA achieves a
fourfold improvement in raw density as compared to a
Xilinx XC4010 FPGA. Furthermore, since VEGA achieves 89%
logic block utilization on average, the effective
density is roughly fourteen times that of a logic
emulator based on the XC4010.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  3360 </NUMBER>
<ORDER>   AAI9540707 </ORDER>
<TITLE> KNOWLEDGE ACQUISITION FOR FUZZY KNOWLEDGE BASE DEVELOPMENT IN SURFACE MOUNT PWB ASSEMBLY </TITLE>
<AUTHOR> WU, CHIEN-HSING </AUTHOR>
<YEAR> 1995 </YEAR>
<INSTITUTION> STATE UNIVERSITY OF NEW YORK AT BINGHAMTON; 0792 </INSTITUTION>
<DESCRIPTORS> ENGINEERING, INDUSTRIAL; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> NIL </ADVISER>
<CLASSIFICATIONS> EXPERT SYSTEMS </CLASSIFICATIONS>
<ABSTRACT>
The development of knowledge-based expert systems
requires the understanding and regulation of several
complex tasks. The key to the successful application
knowledge-based expert systems lies in understanding how
the various components affect the system's overall
performance. Effectively understanding the
interrelationships among components of an expert system
and the role that each component plays is important. The
knowledge base in the expert system serves as a
storehouse of knowledge primitives including the basic
facts, domain theories, production rules, and heuristics
available to the system. An expert system cannot be a
valuable domain problem solver if the knowledge base
does not contain the required quantitive and qualitive
knowledge. A problem often cited in the implementation
of knowledge-based expert systems is the knowledge
acquisition bottleneck. Consequently, the elicitation of
knowledge from knowledge sources becomes important. It
is a time consuming component of the expert system
development life-cycle. Therefore, the design and
development of a prototype Knowledge Acquisition (KA)
facility (or KA tool) to overcome this problem will
definitely help facilitate the development of knowledge-
based expert systems.
The forms in which knowledge is elicited from a human
expert may not always match the forms in which it is
used by a knowledge-based expert system. The selection
of a knowledge representation technique to represent
different types of human knowledge depends on the
analysis of knowledge sources. Consequently, designing a
functional KA facility to extract domain knowledge from
knowledge sources, transforming the knowledge gained
into the system's knowledge, refining the generated
knowledge, validating and verifying the refined
knowledge, and storing the validated and verified
knowledge into a format compatible to the system's
knowledge base structure is a complicated task.
Information available to solving domain problems can be
subjective and/or objective. Ambiguous results always
exist in the subjective and objective decision. Reducing
the degree of uncertainty in the decision making process
helps to enhance accuracy and efficiency. Fuzzy set
theory and fuzzy logic are used in this research to help
overcome this problem.
The knowledge that an expert system needs in order to
perform a task should be defined in such a way that
computer program can represent and adequately use that
knowledge. The complex process of knowledge acquisition
needs to be well identified to interpret and formalize
the activities in developing a knowledge acquisition
facility. Consequently, techniques that need to be
developed to facilitate the knowledge acquisition
process becomes important. The types (or levels) of
knowledge have to be clarified because they determine
the techniques being used in knowledge acquisition.
A prototype knowledge acquisition system for fuzzy
knowledge base development was designed and developed in
this research. This tool assists in the acquisition of
domain knowledge and in the generation of domain
knowledge bases. The surface mount PWB assembly arena
was a focus of this research. The prototype system
serves as a knowledge base generator with the ability to
collect knowledge and data, represent intermediate
knowledge and data, and store knowledge and data. To
attain the stated research objectives, this research
employed the principles of designing knowledge based
systems, knowledge acquisition mechanisms, methods and
techniques of knowledge acquisition, and fuzzy set
theory and fuzzy logic.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  3361 </NUMBER>
<ORDER>   AAI9540383 </ORDER>
<TITLE> IMPROVED ACCURACY OF RBF NEURAL NETWORKS THROUGH THE IMPLEMENTATION OF CERTAINTY FACTORS </TITLE>
<AUTHOR> WEDDING, DONALD K., II </AUTHOR>
<YEAR> 1995 </YEAR>
<INSTITUTION> THE UNIVERSITY OF TOLEDO; 0232 </INSTITUTION>
<DESCRIPTORS> ENGINEERING, ELECTRONICS AND ELECTRICAL; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> NIL </ADVISER>
<CLASSIFICATIONS> RADIAL BASIS FUNCTION, RELIABILITY MEASURE </CLASSIFICATIONS>
<ABSTRACT>
A new method is proposed for using Radial Basis Function
(RBF) neural networks to generate a reliability measure
along with a network's normal output. This new method,
the certainty factor, will generate a value which
approaches 1.0 when the input data is similar to the
data on which the RBF network is trained and will
approach 0.0 for input data that is unfamiliar to the
network. When output with low certainty factors are
discarded, the accuracy of the remaining output
increases.
The research proposed in this paper will be to compare
the new certainty factor approach with an established
technique, Parzen windows. Advantages and disadvantages
of each approach are discussed. Both methods will then
be implemented into RBF networks, and the results of
using each method compared.
Both certainty factors and Parzen windows were found to
improve the accuracy of RBF networks to the same extent,
but conditions are shown to exist where Parzen windows
give meaningless results. Certainty factors are shown to
always yield meaningful results even in conditions
hostile to Parzen windows. Results indicate that the
certainty factor approach is a better choice for a
reliability measure. Further results demonstrate that
analyzing the learning data set at different cutoff
levels can result in a good estimate of the optimal
certainty factor threshold for an RBF network.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  3362 </NUMBER>
<ORDER>   AAI9539989 </ORDER>
<TITLE> A FRAMEWORK FOR DEVELOPING AND EVALUATING HOUGH-LIKE OBJECT RECOGNITION METHODS </TITLE>
<AUTHOR> CHANG, JIYOUNG </AUTHOR>
<YEAR> 1995 </YEAR>
<INSTITUTION> INDIANA UNIVERSITY; 0093 </INSTITUTION>
<DESCRIPTORS> COMPUTER SCIENCE; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> ANDREW J. HANSON </ADVISER>
<CLASSIFICATIONS> COMPUTER VISION, SIGNAL DETECTION </CLASSIFICATIONS>
<ABSTRACT>
Humans have the ability to identify shapes that have
been rotated, scaled, and even partially occluded;
emulating this capability is a classic problem of
computer vision. This dissertation examines a particular
class of computer algorithms for solving such problems,
and studies the mechanisms by which we may evaluate
their performance.
In particular, this thesis studies the class of object
recognition methods based on the Hough transform,
develops a new variant of the method that is especially
adapted to handling rotated and scaled objects, and
formulates evaluation tools for quantifying the
performance of these methods.
The performance analysis presented is based on viewing
the Hough class of methods in the context of signal
detection theory. This approach deals in particular with
two measures: the probability of correctly detecting an
existing signal and the probability of a false alarm. In
the Hough transform class of methods, we obtain
appropriate measures for these quantities and use them
to evaluate and compare the methods that we have
studied.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  3363 </NUMBER>
<ORDER>   AAI9538954 </ORDER>
<TITLE> FLOWS SUSPENDING ITERATIVE ALGORITHMS </TITLE>
<AUTHOR> KOSOWSKY, JEFFREY JOSEPH </AUTHOR>
<YEAR> 1995 </YEAR>
<INSTITUTION> HARVARD UNIVERSITY; 0084 </INSTITUTION>
<DESCRIPTORS> APPLIED MECHANICS; MATHEMATICS; OPERATIONS RESEARCH; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> ROGER W. BROCKETT </ADVISER>
<CLASSIFICATIONS> INTERIOR POINT, NEURAL NETWORKS, TEMPERATURE TRACKING, SINKHORN'S METHOD </CLASSIFICATIONS>
<ABSTRACT>
In the past decade, there has been an explosion of
interest in interior point methods and analog techniques
such as neural networks. In this thesis, we focus upon
the assignment problem and construct several provably
convergent, interrelated iterative and continuous flows
for finding the optimal assignment.
We begin by using statistical physics techniques to
motivate the derivation of a general effective energy
function for suspending combinatorial problems. This
effective energy form may be compared with standard
barrier function approaches to non-linear programming.
For the special case of the assignment problem, the
optimal solution can always be recovered from a minimum
of the effective energy and rigorous convergence bounds
can be proved. Interestingly, in the zero temperature
limit, extremized versions of the effective energy
function reduce to standard formulations of the primal
and dual linear programming problems.
A number of different iterative and continuous
algorithms may be used to minimize the effective energy
and solve the assignment problem, including steepest
descent and a temperature tracking method. Sinkhorn's
classical iterative matrix algorithm for finding doubly
stochastic matrix is shown to be equivalent to
minimizing the effective energy. Moreover, our effective
energy results may be used to derive a generalized
version of Sinkhorn's method and to construct candidate
continuous suspensions.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  3364 </NUMBER>
<ORDER>   AAI9538863 </ORDER>
<TITLE> AN EVALUATION OF THE GENETIC ALGORITHM AS A COMPUTATIONAL TOOL IN PROTEIN NMR </TITLE>
<AUTHOR> BEESON, NICHOLAS WELBORN </AUTHOR>
<YEAR> 1995 </YEAR>
<INSTITUTION> HARVARD UNIVERSITY; 0084 </INSTITUTION>
<DESCRIPTORS> BIOPHYSICS, GENERAL; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> NIL </ADVISER>
<CLASSIFICATIONS> NIL </CLASSIFICATIONS>
<ABSTRACT>
During the last decade many of the techniques of
artificial intelligence have been reduced to practice.
These techniques can be of benefit in the solution of
complex problems in the sciences that have resisted
computerized solutions using other programming
techniques. The characteristics these problems will have
if they can be solved with artificial intelligence are
discussed and a list of identifying criteria is given.
This list is then used to identify several potentially
solvable problems. One artificial intelligence
technique, the genetic algorithm, is then applied to one
of these problems, protein NMR. The genetic algorithm
successfully finds chemical shifts, line widths, and
volumes of NOE peaks, demonstrating that the criteria
work and that artificial intelligence can be of benefit
to protein NMR.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  3365 </NUMBER>
<ORDER>   AAI9538846 </ORDER>
<TITLE> ASSESSING GENERALIZATION OF FEEDFORWARD NEURAL NETWORKS </TITLE>
<AUTHOR> TURMON, MICHAEL J. </AUTHOR>
<YEAR> 1995 </YEAR>
<INSTITUTION> CORNELL UNIVERSITY; 0058 </INSTITUTION>
<DESCRIPTORS> ENGINEERING, ELECTRONICS AND ELECTRICAL; COMPUTER SCIENCE; BIOLOGY, NEUROSCIENCE; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> NIL </ADVISER>
<CLASSIFICATIONS> NIL </CLASSIFICATIONS>
<ABSTRACT>
We address the question of how many training samples are
required to ensure that the performance of a neural
network of given complexity on its training data matches
that obtained when fresh data is applied to the network.
This desirable property may be termed 'reliable
generalization.' Well-known results of Vapnik give
conditions on the number of training samples sufficient
for reliable generalization, but these are higher by
orders of magnitude than practice indicates; other
results in the mathematical literature involve unknown
constants and are useless for our purposes.
We seek to narrow the gap between theory and practice by
transforming the problem into one of determining the
distribution of the supremum of a Gaussian random field
in the space of weight vectors. This is addressed first
by application of a tool recently proposed by D. Aldous
called the Poisson clumping heuristic, and then by
related probabilistic techniques. The idea underlying
all the results is that mismatches between training set
error and true error occur not for an isolated network
but for a group or 'clump' of similar networks. In a few
ideal situations--perceptrons learning halfspaces,
machines learning axis-parallel rectangles, and networks
with smoothly varying outputs--the clump size can be
derived and asymptotically precise sample size estimates
can be found via the heuristic.
In more practical situations, when formal knowledge of
the data distribution is unavailable, the size of this
group of equivalent networks can be related to the
original neural network problem via a function of a
correlation coefficient. Networks having prediction
error correlated with that of a given network are said
to be within the 'correlation volume' of the latter.
Means of computing the correlation volume based on
estimating such correlation coefficients using the
training data are proposed and discussed. Two simulation
studies are performed. In the cases we have examined,
informative estimates of the sample size needed for
reliable generalization are produced by the new method.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  3366 </NUMBER>
<ORDER>   AAI9538581 </ORDER>
<TITLE> PERSPECTIVES OF PATTERN RECOGNITION IN HANDWRITTEN CHARACTER RECOGNITION  </TITLE>
<AUTHOR> JAMEEL, AKHTAR </AUTHOR>
<YEAR> 1995 </YEAR>
<INSTITUTION> TULANE UNIVERSITY; 0235 </INSTITUTION>
<DESCRIPTORS> COMPUTER SCIENCE; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> CRIS KOUTSOUGERAS </ADVISER>
<CLASSIFICATIONS> NEURAL NETWORKS </CLASSIFICATIONS>
<ABSTRACT>
Handwritten Character Recognition is a long-standing
problem among computer scientists. It promises several
benefits to the user friendliness of modern computers.
Several classical pattern recognition methods such as
template matching, Fourier transformation, geometric
moments and scene analysis which have proven to be
effective in several domains have not yielded consistent
or reliable results for handwritten character
recognition.
Currently, neural networks are considered as the
underlying computing mechanism for a robust approach to
the problem of handwritten character recognition. This
thesis presents various perspectives on pattern
recognition techniques for handwritten character
recognition using many different forms of neural
networks. Six different hypotheses were investigated.
It is well known that many neural methods are overly
specific to the training prototypes, a characteristic
which is not suitable for the handwritten character
recognition. A new neural network, called the polynomial
network designed for more generalized classification is
introduced. Apart from being more suitable this network
performs classification of handwritten characters faster
than standard backpropagation methods. Finally, this
work presents a comprehensive collection of experimental
evidence supporting claims for high character
recognition abilities of Kohonen's learning vector
quantization network, recurrent neural network, and the
newly proposed polynomial neural network.
A body of theoretical and empirical results gathered
during this work provides an insight to methodologies
that may be the basis of future handwritten character
recognition systems. In a broader sense the significance
of this research extends to the general area of pattern
recognition.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  3367 </NUMBER>
<ORDER>   AAI9538577 </ORDER>
<TITLE> AN APPROACH FOR THE DEFINITION, REPRESENTATION AND QUERYING OF BINARY TOPOLOGICAL AND DIRECTIONAL RELATIONSHIPS BETWEEN TWO-DIMENSIONAL OBJECTS  </TITLE>
<AUTHOR> COBB, MARIA ANNETTE </AUTHOR>
<YEAR> 1995 </YEAR>
<INSTITUTION> TULANE UNIVERSITY; 0235 </INSTITUTION>
<DESCRIPTORS> COMPUTER SCIENCE; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> FREDERICK PETRY </ADVISER>
<CLASSIFICATIONS> FUZZY QUERY </CLASSIFICATIONS>
<ABSTRACT>
An approach is developed in which sets of binary
topological and directional relationships for spatial
features is constructed based on definitions obtained
from extending Allen's temporal relations (1) to the
spatial domain. These relationships are then modeled by
an abstract graph representation that preserves the
topological and directional information associated with
a pair of objects. Data structures are developed that,
along with quantitative information stored with the
graph, facilitate retrieval of fuzzy topological and
directional information. A low-level query framework,
including a BNF and fuzzy query processing strategies,
is then presented. It is shown how this framework can be
incorporated into existing high-level spatial query
languages in order to provide access to the data
modeling capabilities of the approach developed here.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  3368 </NUMBER>
<ORDER>   AAI9538363 </ORDER>
<TITLE> NONLINEAR ADAPTIVE FILTERING:  THE GENETIC ALGORITHM APPROACH  </TITLE>
<AUTHOR> OSTROWSKI, TOMASZ </AUTHOR>
<YEAR> 1995 </YEAR>
<INSTITUTION> POLITECHNIKA WARSZAWSKA (POLAND); 1227 </INSTITUTION>
<DESCRIPTORS> ENGINEERING, ELECTRONICS AND ELECTRICAL; COMPUTER SCIENCE; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> JERZY WOZNICKI </ADVISER>
<CLASSIFICATIONS> NEURAL NETWORKS, HYPERSURFACE SMOOTHING </CLASSIFICATIONS>
<ABSTRACT>
This thesis reports an adaptive method of suboptimal
nonlinear filter design exploiting the genetic
algorithms and neural networks.
There is the strong interest in nonlinear adaptive
filtering because the closed form solutions for optimal
nonlinear filters are difficult to find and the
computational burden of known numerical methods grows
exponentially with the filter window size, e.g., the
search for optimal stack filter under the mean absolute
error criterion via linear programming. The
effectiveness of adaptive algorithms is strongly
dependent on the shape of hypersurface obtained by
evaluating the optimization criterion in the parameter
space. For the reason of the singularities of admissible
criterion value hypersurface, e.g., discontinuities and
flat hypersurface areas where gradient equals zero, many
optimization methods, e.g., recursive differential
require the hypersurface regularization. This approach
inevitably introduces the possibility of error caused by
criterion hypersurface smoothing. Moreover, the
application of the majority of iterative optimization
methods to the smoothed hypersurface does not guarantee
the discovery of globally optimal solution but only the
locally optimal one.
To overcome the above drawbacks the nonlinear adaptive
filtering has been formulated in terms of genetic
algorithms and the general form of the filtering quality
criterion has been proposed.
The genetic algorithms have been developed to search for
the suboptimal nonlinear nonrecursive smoothers
including the minimal filters, i.e., the filters
suboptimal under the filtering quality criterion whose
implementation is computationally most efficient.
The modified tournament selection in the overlapping
population, nonlinear fitness scaling, evolutionary
algorithm to search for the minimal weighted order
statistic filters and dedicated crossover for the
recombination of multilayer neural networks have been
proposed.
Subsequently for the broad class of nonlinear filters,
so called neural filters, the results obtained using the
genetic algorithm technique have been compared with the
results given by known differential recursive neural
filtering algorithms. The results of the genetic
algorithm based method are not worse than given by the
recursive adaptive algorithms for the generally defined
neural filters. In the case of the additional complexity
of criterion value hypersurface for the special neural
filter subclasses, e.g., the weighted order statistic
filters, the results given by the genetic algorithm
approach are substantially better. Moreover, the genetic
algorithm method enables the search for suboptimal
minimal filters.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  3369 </NUMBER>
<ORDER>   AAI9538203 </ORDER>
<TITLE> INTERACTIONS OF A USER MENTAL MODEL WITH AN EXPERT SYSTEM AND AN EXPLANATION FACILITY </TITLE>
<AUTHOR> WANG, DAVID KAILI </AUTHOR>
<YEAR> 1995 </YEAR>
<INSTITUTION> THE GEORGE WASHINGTON UNIVERSITY; 0075 </INSTITUTION>
<DESCRIPTORS> COMPUTER SCIENCE; INFORMATION SCIENCE; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> MICHAEL LEE DONNELL </ADVISER>
<CLASSIFICATIONS> NIL </CLASSIFICATIONS>
<ABSTRACT>
The focus of this research is to evaluate several
proposed user mental model hypotheses. User interactions
with an explanation facility which is comprised of an
intelligent help desk system (essentially an expert
system) are observed and evaluated. To bring some
structure to this complex process, a fundamental,
analogical reasoning model for the user mental model is
presented. The goal of this basic research is not to
provide a widely accepted, clear cut explanation of user
mental models, but, rather, to perform basic research
that delves into specific areas of the user mental
model, namely, to demonstrate the interaction of the
user mental model with either a text-based or a GUI-
based expert system explanation facility. The testbed is
a software application similar to a typical intelligent
help desk, in essence, an expert system.
The author proposes a novel explanation facility system
with three levels of design, namely, novice,
intermediate, and advanced expert explanation
facilities. These three levels will allow for better
programmability with reduced coding under the object-
oriented programming paradigm.
The empirical research application software development
is divided into two parts. Part I involves the design
and implementation of a Human Information Processing
(HIP) Software Program and is mainly utilized to
facilitate the calculation (tabulation) and isolation of
the forty questions gathered from an HIP survey. These
forty questions categorize the users' cognitive
abilities into left, integrated, and right hemisphere.
Left hemispheric thinkers have logical or verbal
cognitive thinking ability. Right hemispheric thinkers
have artistic or visual cognitive ability. Integrated
hemispheric thinkers have the traits from both cognitive
thinking abilities.
Part II involves the design and implementation of an
expert explanation (intelligent help desk) application
software testbed centered on the "Computer System
Hardware/Software diagnosis System" developed under the
Kappa-PC environment. This application software program
is capable of giving explanations and storing subjects'
responses. The Kappa-PC environment by Intellicorp is a
robust software development tool box that runs under the
Microsoft Windows environment. The application software
program developed can be considered an expert
explanation facility or an intelligent help desk system,
since features from both categories are present.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  3370 </NUMBER>
<ORDER>   AAGMM07212 </ORDER>
<TITLE> FORMULATION DE LA FRAGMENTATION DES DONNEES EN TERMES D'ALGORITHMES GENETIQUES ET DE SYSTEMES EXPERTS POUR L'OPTIMISATION DE L'OPERATION DE JOINTURE PARALLELE </TITLE>
<AUTHOR> PETRETTA, DAVID </AUTHOR>
<YEAR> 1995 </YEAR>
<INSTITUTION> UNIVERSITE LAVAL (CANADA); 0726 </INSTITUTION>
<DESCRIPTORS> ENGINEERING, ELECTRONICS AND ELECTRICAL; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> NADIR BELKHITER </ADVISER>
<CLASSIFICATIONS> FRENCH TEXT </CLASSIFICATIONS>
<ABSTRACT>
Nous proposons d'utiliser les algorithmes genetiques et
les systemes experts comme outils pour la resolution du
probleme de la fragmentation des donnees dans les
S.G.B.D. paralleles. En effet, ces approches permettent
de resoudre des problemes pour lesquels aucun algorithme
conventionnel ne peut-etre concu, ce qui est le cas du
probleme de la fragmentation des donnees. Nous etudions
dans un premier temps les heuristiques utilisees pour la
resolution des problemes de la fragmentation horizontale
et verticale. Par la suite, nous proposons une
formulation de ces problemes en termes d'algorithmes
genetiques et de systemes experts. Plus
particulierement, nous nous attardons a l'optimisation
des operations de jointure paralelle par la
fragmentation efficace des donnees.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  3371 </NUMBER>
<ORDER>   AAI9538156 </ORDER>
<TITLE> A HIERARCHICAL FUSION NEURAL NETWORK FOR HANDWRITTEN CHARACTER RECOGNITION </TITLE>
<AUTHOR> ZHOU, JIAN </AUTHOR>
<YEAR> 1995 </YEAR>
<INSTITUTION> STATE UNIVERSITY OF NEW YORK AT BUFFALO; 0656 </INSTITUTION>
<DESCRIPTORS> ENGINEERING, ELECTRONICS AND ELECTRICAL; COMPUTER SCIENCE; ENGINEERING, BIOMEDICAL; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> RAJ S. ACHARYA </ADVISER>
<CLASSIFICATIONS> TEXT RECOGNITION </CLASSIFICATIONS>
<ABSTRACT>
Research in text recognition has long been focused on
the recognition of handwritten characters. Because of
large variation involved in human handwriting and noise
corrupted, the machine recognition of general
handwritten characters presents a number of challenges.
Despite the success of some recognition systems in
constrained domains, problems that involve distortions,
major variations, omissions and unconstrained domain
remain difficult. In this dissertation, we have proposed
a novel neural network architecture alone with new
feature representations for use in the recognition of
handwritten characters.
In applying ANN to pattern recognition problems, the
first consideration is the feature representation.
Unfortunately, no satisfactory representation exists for
handwriting signals, and finding such a representation
is still an open research problem. In the approaches
proposed here, based on empirical evidence, we have
carefully selected two feature sets, global structure
and local orientation feature sets. The processes of the
global feature extraction with mathematical morphology
based method and the local orientation feature
extraction with gradient computation based method are
thoroughly explored in this study. The proposed
recognition network is a hierarchical fusion network and
function more close to human visual system. Within this
new approach, independent decisions by two high
performance classifiers, a fully connected feedforward
multi-layer perceptron which is feeded with local
orientation based feature vector and the module based
neural network which is feeded with global structural
and moment feature vector, are fused by a higher level
module based multi-layer feedforward neural network.
We have designed a new system for handwritten character
recognition. The success of the proposed recognition
system is demonstrated by means of experiments using
real-world data--NIST data set. Finally, the comparative
advantages and significant improvements of the proposed
recognition system to the traditional feedforward
perceptron approaches are discussed.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  3372 </NUMBER>
<ORDER>   AAI9538153 </ORDER>
<TITLE> MULTIRESOLUTION OBJECT RECOGNITION USING NEURAL NETWORKS </TITLE>
<AUTHOR> YOUNG, SUSAN SHIQIONG </AUTHOR>
<YEAR> 1995 </YEAR>
<INSTITUTION> STATE UNIVERSITY OF NEW YORK AT BUFFALO; 0656 </INSTITUTION>
<DESCRIPTORS> ENGINEERING, ELECTRONICS AND ELECTRICAL; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> PETER D. SCOTT </ADVISER>
<CLASSIFICATIONS> HOPFIELD NETWORK </CLASSIFICATIONS>
<ABSTRACT>
This dissertation presents a study of multiresolution
object recognition methods that are based on neural
network technique. The traditional multiresolution top-
down matching approach in shape classification which
employs image pyramid analysis is described. The problem
associated with top-down matching strategy is addressed
which is that an early stage mistake in the low
resolution will propagate into each subsequent higher
resolution level and will cause a final mismatch. An
approach of multiresolution concurrent matching using
multi-layer Hopfield neural network is proposed. The
proposed network consists of several cascaded single
layer Hopfield networks, each encoding object features
at a distinct resolution, with bidirectional
interconnections linking adjacent layers. The inter-
layer feedback feature of the proposed algorithm
reinforces the usual intra-layer matching processing in
the conventional single layer Hopfield network in order
to compute the most consistent model-object match across
several resolution levels. Extension of the multi-layer
Hopfield nets to foveal image which is obtained by non-
uniform sampling technique for object recognition is
also discussed. A top-down algorithm employing a polygon
data structure, the available subset of the image
pyramid, is introduced and shown to be effective in a 2D
shape classification experimental environment.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  3373 </NUMBER>
<ORDER>   AAI9538097 </ORDER>
<TITLE> A THEORY OF CLASSIFIER COMBINATION: THE NEURAL NETWORK APPROACH </TITLE>
<AUTHOR> LEE, DAR-SHYANG </AUTHOR>
<YEAR> 1995 </YEAR>
<INSTITUTION> STATE UNIVERSITY OF NEW YORK AT BUFFALO; 0656 </INSTITUTION>
<DESCRIPTORS> COMPUTER SCIENCE; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> SARGUR N. SRIHARI </ADVISER>
<CLASSIFICATIONS> NIL </CLASSIFICATIONS>
<ABSTRACT>
There is a trend in recent OCR development to improve
system performance by combining recognition results of
several complementary algorithms. This thesis examines
the classifier combination problem under strict
separation of the classifier and combinator design. None
other than the fact that every classifier has the same
input and output specification is assumed about the
training, design or implementation of the classifiers. A
general theory of combination should possess the
following properties. It must be able to combine any
type of classifiers regardless of the level of
information contents in the outputs. In addition, a
general combinator must be able to combine any mixture
of classifier types and utilize all information
available. Since classifier independence is difficult to
achieve and to detect, it is essential for a combinator
to handle correlated classifiers robustly. Although the
performance of a robust (against correlation) combinator
can be improved by adding classifiers indiscriminantly,
it is generally of interest to achieve comparable
performance with the minimum number of classifiers.
Therefore, the combinator should have the ability to
eliminate redundant classifiers. Furthermore, it is
desirable to have a complexity control mechanism for the
combinator. In the past, simplifications come from
assumptions and constraints imposed by the system
designers. In the general theory, there should be a
mechanism to reduce solution complexity by exercising
non-classifier-specific constraints. Finally, a
combinator should capture classifier/image dependencies.
Nearly all combination methods have ignored the fact
that classifier performances (and outputs) depend on
various image characteristics, and this dependency is
manifested in classifier output patterns in relation to
input images. Capturing the dependency improves the
theoretical error bound of the combinator. This thesis
defines a framework to separate the combinator design
from classifier specific details. Then we present a
combination theory based on the neural network approach
that possesses all the properties mentioned above.
Moreover, in facing these issues, we discover several
interesting findings involving the concept of classifier
bootstrapping, the definition for classifier
independence and dynamic classifier selection.
Experimental results on handwritten digits recognition
verify our theory and findings.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  3374 </NUMBER>
<ORDER>   AAI9538050 </ORDER>
<TITLE> NONPARAMETRIC ERROR ESTIMATION METHODS FOR EVALUATING AND VALIDATING ARTIFICIAL NEURAL NETWORK PREDICTION MODELS </TITLE>
<AUTHOR> TWOMEY, JANET MARIE </AUTHOR>
<YEAR> 1995 </YEAR>
<INSTITUTION> UNIVERSITY OF PITTSBURGH; 0178 </INSTITUTION>
<DESCRIPTORS> ENGINEERING, INDUSTRIAL; COMPUTER SCIENCE; STATISTICS; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> NIL </ADVISER>
<CLASSIFICATIONS> BOOTSTRAP, JACKNIFE </CLASSIFICATIONS>
<ABSTRACT>
Since statistical prediction modeling is a well
established area of statistics, there is a plethora of
literature on the evaluation and validation of
statistical prediction models. Conversely, the
evaluation and validation of artificial neural networks
(ANN), a new class of nonparametric prediction models,
has been ignored in the ANN literature. The subject of
this dissertation research is error estimation for ANN
models. A systematic investigation was conducted under
the conditions of sparse data, on nine error estimation
methodologies: the two commonly used methods of ANN
evaluation (resubstitution and train-and-test), and
several variations on three resampling approaches (cross-
validation, jackknife, and bootstrap methods).
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  3375 </NUMBER>
<ORDER>   AAI9537894 </ORDER>
<TITLE> DIAGNOSING MULTIPLE INTERACTING DEFECTS WITH CUE COMBINATION DESCRIPTIONS  </TITLE>
<AUTHOR> REED, NANCY ELLEN </AUTHOR>
<YEAR> 1995 </YEAR>
<INSTITUTION> UNIVERSITY OF MINNESOTA; 0130 </INSTITUTION>
<DESCRIPTORS> COMPUTER SCIENCE; ARTIFICIAL INTELLIGENCE; HEALTH SCIENCES, HUMAN DEVELOPMENT; HEALTH SCIENCES, MEDICINE AND SURGERY </DESCRIPTORS>
<ADVISER> NIL </ADVISER>
<CLASSIFICATIONS> ARTIFICIAL INTELLIGENCE, CONGENITAL HEART DISEASE </CLASSIFICATIONS>
<ABSTRACT>
Conventional diagnostic methods assume that only a
single defect is present. Cases with multiple defects
can be difficult to diagnose because the defects can
interact, meaning that the observable cues are not a sum
of the cues for the component defects. Diagnostic
methods that use cue-to-defect relationships fail when
interactions between defects change the observable cues.
Model-based methods can be used to diagnose multiple
defects by simulating the results of interactions. Model-
based methods, however, are limited to domains with
accurate and complete models as well as enough available
data to initialize the models.
This research develops a description and classification
of the ways cues change when defects interact, based on
physical interactions and example cases. Each type of
cue may combine in a different way, so each has a
separate description. Also developed is a formula for
quantifying the amount of abnormal data explained by a
set of defects, termed explanation points. The
descriptions and formula are used in a domain-
independent computational diagnostic model that can
diagnose multiple defects, even when cues are altered or
missing due to interactions between the defects.
In the medical domain investigated in this research
(diagnosis of congenital heart defects), we found that
cues combine with one another in a small number of ways:
all cues may appear, the values of the cues may be
added, or dominant cues may mask any other cues present.
Cues of each type combine in one of these basic ways, or
use a combination of a few of the basic ways, based on
characteristics of the cues, case, or domain. The
diagnostic model is tested by constructing a program
with a knowledge base in Pediatric Cardiology and
testing it on cases of single and multiple defects from
hospital files. This program correctly diagnoses cases
with multiple interacting defects for which current
methods are not applicable or fail.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  3376 </NUMBER>
<ORDER>   AAI9537723 </ORDER>
<TITLE> MULTIRESOLUTIONAL SEARCH FOR THE DESIGN OF FEEDFORWARD CONTROLS  </TITLE>
<AUTHOR> UZZAMAN, SAMEH </AUTHOR>
<YEAR> 1995 </YEAR>
<INSTITUTION> DREXEL UNIVERSITY; 0065 </INSTITUTION>
<DESCRIPTORS> ENGINEERING, ELECTRONICS AND ELECTRICAL; ENGINEERING, INDUSTRIAL; ENGINEERING, SYSTEM SCIENCE; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> NIL </ADVISER>
<CLASSIFICATIONS> INTELLIGENT CONTROL, OPERATION TRAJECTORIES </CLASSIFICATIONS>
<ABSTRACT>
The list of desirable properties of an intelligent
controller includes the ability to navigate through an
unstructured environment using a knowledge base and
planning, to make predictions and form hypotheses, and
to demonstrate an ability to learn. A prerequisite for
the design of such a system is the delineation of the
necessary information processing tools and the quantity
and character of information required for the successful
design of trajectories of operation.
The goal of this research is to implement a
multiresolutional system for the synthesis of near-
optimal feedforward trajectories for dynamical systems.
The process of synthesis relies on an efficient analysis
of distributed information that is obtained as result of
testing and data-gathering. The information is organized
in a hierarchy of scale and scope, permitting the
consecutive algorithmic refinement of trajectories using
increasingly precise information within a more tightly
constrained envelope. The hierarchical organization is
shown to reduce the complexity of information storage
and analysis. The approach is illustrated using the
example of a linearized system, and is then applied in
order to derive a strategy of operation for more complex
systems.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  3377 </NUMBER>
<ORDER>   AAI9537608 </ORDER>
<TITLE> SPEAKER VERIFICATION USING SUBWORD NEURAL TREE NETWORKS </TITLE>
<AUTHOR> LIOU, HAN-SHENG </AUTHOR>
<YEAR> 1995 </YEAR>
<INSTITUTION> RUTGERS THE STATE UNIVERSITY OF NEW JERSEY - NEW BRUNSWICK; 0190 </INSTITUTION>
<DESCRIPTORS> ENGINEERING, ELECTRONICS AND ELECTRICAL; COMPUTER SCIENCE; PHYSICS, ACOUSTICS; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> RICHARD J. MAMMONE </ADVISER>
<CLASSIFICATIONS> NIL </CLASSIFICATIONS>
<ABSTRACT>
In this dissertation, a new neural-network-based
algorithm for text-dependent speaker verification is
presented. The algorithm uses a set of concatenated
Neural Tree Networks (NTN's) trained on subword units to
model a password. In contrast to the conventional
stochastic approaches which model the subword units by
Hidden Markov Models (HMM's), the new approach utilizes
the discriminative training scheme to train a NTN for
each subword unit. Two types of subword unit are
investigated, phone-like units (PLU's) and HMM state-
based units (HSU's).
The training of the models includes the following steps.
The training utterances of a password is first segmented
into subword units using a HMM-based segmentation
method. A NTN is then trained for each subword unit. In
order to retrieve the temporal information which is
relatively important in text-dependent speaker
verification, the proposed paradigm integrates the
discriminatory ability of the NTN with the temporal
models of the HMM. A new scoring method using phonetic
weighting to improve the speaker verification
performance is also introduced. The proposed algorithms
are evaluated by experiments on a TI isolated-word
database, YOHO database, and several hundred utterances
collected over telephone channel. Performance
improvements are obtained over conventional techniques.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  3378 </NUMBER>
<ORDER>   AAI9537408 </ORDER>
<TITLE> BAYESIAN REASONING FOR CSG-BASED OBJECT RECOGNITION </TITLE>
<AUTHOR> CHANG, JYH-CHIAN </AUTHOR>
<YEAR> 1995 </YEAR>
<INSTITUTION> NORTHWESTERN UNIVERSITY; 0163 </INSTITUTION>
<DESCRIPTORS> COMPUTER SCIENCE; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> WEI-CHUNG LIN </ADVISER>
<CLASSIFICATIONS> ARTIFICIAL INTELLIGENCE </CLASSIFICATIONS>
<ABSTRACT>
In this dissertation, a CSG-based (Constructive Solid
Geometry) vision system based on Bayesian reasoning
techniques is presented. Because of the problems of
inaccuracy in sensory equipment, loosely-constrained
models, highly cluttered environments, invisibility from
a single viewpoint, or occlusion by other primitives in
computer vision systems, adopting uncertainty reasoning
for 3-D object recognition is an inevitable trend.
Bayesian networks with solid probabilistic background
and well-developed syntax is one of the best choices to
deal with the inexact problems in computer vision. We
have successfully applied the Bayesian reasoning scheme
to both primitive segmentation and object recognition
processes, and our system is superior to the other
similar systems in both accuracy and speed.
The CSG primitive recognition subsystem is a hybrid
approach to recognize CSG primitives from range images,
where "hybrid" refers to a combination of region- and
edge-based approaches. After the edge map is obtained,
genetic algorithms are used to extract the contour
information from the edge map. When the contour
information and the surface properties of the image are
available, a Geometry Inference Network based on a
polytree Bayesian network is used to fuse both the
contour and surface information, and infer the CSG
primitives in the range image with certainty values
calculated as the results of considering the accuracy of
sensory equipments, environmental noise, and the
viewpoint of the range image.
The second subsystem is an object recognition system
based on geometric center labeling and a query-based
Bayesian decision tree to recognize objects by
precedence graph matching. This Bayesian network
constructs hypotheses, accumulates evidence about the
identities of the objects of interest in a scene and a
model database, and propagates the belief values from
evidence to hypothesis nodes. These belief values
reflect the likeness of the matched scene and model
features as well as the similarity of the relations
between the scene and model features. Experimental
results on several range images are presented to
demonstrate the performance of the proposed approaches.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  3379 </NUMBER>
<ORDER>   AAI9537382 </ORDER>
<TITLE> VIBRATION CONTROL USING ANALYTICALLY BASED ARTIFICIAL INTELLIGENCE  </TITLE>
<AUTHOR> ABE, MASATO </AUTHOR>
<YEAR> 1995 </YEAR>
<INSTITUTION> NORTHWESTERN UNIVERSITY; 0163 </INSTITUTION>
<DESCRIPTORS> ENGINEERING, CIVIL; APPLIED MECHANICS; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> TAKERA IGUSA </ADVISER>
<CLASSIFICATIONS> TUNED MASS DAMPERS </CLASSIFICATIONS>
<ABSTRACT>
Vibration control of structures is becoming increasingly
important as serviceability requirements are becoming
more severe. Tuned mass dampers, which are also known as
dynamic vibration absorbers, are commonly used in
structural control because of their relatively high
performance and compactness. In this thesis, novel
design methods are proposed for tuned mass dampers with
passive, semi-active and active configurations. These
design methods are developed based on analytical
solutions derived by perturbation analysis of
structure/tuned mass damper systems. Because all the
analytical solutions are in simple form, they provide
useful insight into the design of tuned mass dampers.
Thus it is possible to solve design problems without
recourse to numerical parametric study. The thesis
consists of three major parts. The first deals with
design of passive tuned mass dampers for continuous
structures. The validity and limitations of the commonly
used single mode approximation is established
analytically, with particular attention to the case of
structures with closely spaced natural frequencies. In
the second part, a semi-active tuned mass damper with
adjustable initial displacement and damping is proposed.
The proposed method enhances the performance of the
passive device considerably. Active tuned mass dampers
are introduced in the third part. Closed form solutions
are obtained for the optimal control laws with quadratic
performance index. The treatment of constraints on
actuator capacity and displacement of tuned mass damper
which are important in civil structures is discussed in
detail. These solutions are combined with those
developed in the second part to construct an intelligent
control algorithm. The algorithm is rule-based and the
control rules are derived from analytical and intuitive
knowledge on tuned mass dampers. The controller designed
by the proposed method has higher performance than the
conventional linear optimal controller especially when
the displacement of the tuned mass damper is restricted.
The active and semi-active control algorithms developed
in the second and third parts are applied to continuous
structures by the theory developed in the first part and
their performance is demonstrated by numerical
simulations.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  3380 </NUMBER>
<ORDER>   AAI9537375 </ORDER>
<TITLE> AUTOMATED ELECTRIC DISTRIBUTION SYSTEM PLANNING USING INTELLIGENT METHODS AND GEOGRAPHIC INFORMATION SYSTEM </TITLE>
<AUTHOR> YEH, ERH-CHUN </AUTHOR>
<YEAR> 1995 </YEAR>
<INSTITUTION> UNIVERSITY OF WASHINGTON; 0250 </INSTITUTION>
<DESCRIPTORS> ENGINEERING, ELECTRONICS AND ELECTRICAL; COMPUTER SCIENCE; GEOGRAPHY; ARTIFICIAL INTELLIGENCE; ENERGY </DESCRIPTORS>
<ADVISER> S. S. VENKATA </ADVISER>
<CLASSIFICATIONS> NIL </CLASSIFICATIONS>
<ABSTRACT>
Distribution system planning is a process through which
an electric utility assures that the delivery of
electric energy to its customers is reliable, efficient,
and economical. Good plans will save the utility
significant portions of their initial investments and
reduce the annual operating costs without sacrificing
the service reliability of the system. Many researchers
have addressed different aspects of such a planning
process. No matter what kind of methodologies these
researchers employed, they all agreed that three issues--
uncertainties of loads, geographical deployment of the
system, and large number of components--complicate the
planning process. The spatial distribution and
connection of customer loads are hard to model in an
accurate mathematical form, thus making most
optimization techniques inadequate for planning studies.
The combinatorial explosion of the search space and
vagueness in performance evaluations have made
distribution system planning too hard to optimize.
Instead of searching for absolute optimality, this work
attempts to develop a framework that evolves a better
solution based on available spatial heuristics and human
knowledge in a fully automated planning environment. In
so doing, this dissertation firstly devises a generic
data model that utilizes geographic information system
(GIS) capabilities in spatial modeling and management.
Secondly, it develops a simple planner that generalizes
the planning tasks from the topological perspective.
Thirdly, it exploits a set of spatial heuristics that
helps filter less desirable candidates while searching
for the optimal design in the planning process.
Fourthly, it proposes a heuristic based search algorithm
for optimal cable routing. Finally, it presents an
intelligent, adaptive search algorithm with implicit
parallelism that employs the learning capabilities of
genetic algorithms (GA's) as an underlying mechanism to
help approach optimality in the planning domain. The
novel features of this work are (1) its innovation,
according to the geographical relationship among
different objects, to streamlining the planning process
of the different analogous levels in a distribution
network, (2) taking advantage of spatial relationships
to resolve the NP-hard cable routing and site selection
problems, and (3) evolving high quality designs that are
near-optimal and unable to explore in a traditional
problem solving environment. Practical examples of
secondary system planning, primary system planning, and
street lighting planning demonstrate the feasibility of
the proposed approach.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  3381 </NUMBER>
<ORDER>   AAGMM07057 </ORDER>
<TITLE> COMMANDE DE TRAJECTOIRE VITESSE D'UN MOTEUR C.C. PAR RESEAU NEURONIQUE  </TITLE>
<AUTHOR> BABOS, CHRISTIAN </AUTHOR>
<YEAR> 1995 </YEAR>
<INSTITUTION> UNIVERSITE LAVAL (CANADA); 0726 </INSTITUTION>
<DESCRIPTORS> ENGINEERING, ELECTRONICS AND ELECTRICAL; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> HOANG LE-HUY </ADVISER>
<CLASSIFICATIONS> FRENCH TEXT </CLASSIFICATIONS>
<ABSTRACT>
La capacite des reseaux neuroniques d'apprendre des
relations lineaires et non-lineaires leur donne la
possibilite d'etre utilises dans des processus
d'identification de systeme. En structurant les entrees
et les sorties de differents reseaux neuroniques de
facon adequate, et en regroupant ceux-ci dans un systeme
ou chaque reseau implique aura sa tache predeterminee,
il est possible d'etablir des methodes de commande
predictive d'un systeme dont la dynamique est
explicitement inconnue. Ces techniques de commande
seront appliquees a une methode de commande de
trajectoire vitesse avec modele de reference, a une
methode de commande de trajectoire vitesse en boucle
fermee avec mecanisme de limitation du courant et a une
methode de commande en boucle ouverte egalement avec
mecanisme de limitation de courant, d'un moteur ce a
excitation separee entrai nant une charge non-lineaire.
Les parametres du moteur et de la charge sont
invariables dans le temps. Cependant, la dynamique non-
lineaire du groupement charge-moteur ne sera connue
qu'implicitement.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  3382 </NUMBER>
<ORDER>   AAI9537368 </ORDER>
<TITLE> A NEURAL NETWORK TECHNIQUE FOR INVARIANT RECOGNITION AND MOTION ESTIMATION OF THREE-DIMENSIONAL OBJECTS USING RANGE DATA </TITLE>
<AUTHOR> TSENG, YEN-HAO </AUTHOR>
<YEAR> 1995 </YEAR>
<INSTITUTION> UNIVERSITY OF WASHINGTON; 0250 </INSTITUTION>
<DESCRIPTORS> ENGINEERING, ELECTRONICS AND ELECTRICAL; COMPUTER SCIENCE; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> JENQ-NENG HWANG </ADVISER>
<CLASSIFICATIONS> NIL </CLASSIFICATIONS>
<ABSTRACT>
The research in 3-D object recognition and motion
estimation using range images is getting more attention
in recent years. Range images are taken from one view
and only depict partial shapes of 3-D objects.
Therefore, object recognition and motion estimation are
very difficult due to the missing data beyond visible
surfaces. Many researchers have proposed various
algorithms in order to solve this problem. However, all
the algorithms have their limitations and can only be
applied under certain conditions.
This dissertation introduces a neural network solution
to the problem due to single viewing of objects. The
proposed neural network approach directly utilizes the
acquired range data and requires no feature extraction.
Therefore, this method is more robust to occlusion and
noise corruption. In this algorithm, a 3-D object is
first implicitly and parametrically represented by a
distance transformation neural network (DTNN) trained by
the surface points of an exemplar object. When later
presented with the surface points of an unknown object
which has been rotated and translated, this DTNN
representation allows easy computation of the distance
measure between the exemplar object and the unknown
object. This mismatch information is then back-
propagated through the DTNN to iteratively determine the
best similarity transformation (translation and
rotation). This matching process is similar to the
structure of human's biological neural network. It has
been suggested by the studies of experimental psychology
that the task of matching rotated and translated shapes
by human is done by mentally rotating and translating
gradually one of the shapes into the orientation and
position of the other and then testing for a match.
Applications to invariant 3-D object recognition and
motion estimation using sparse range data collected from
one view are presented. This neural network approach can
also be applied to 3-D visualization of medical imaging.
The results of 3-D reconstruction of MRI scan slices are
given.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  3383 </NUMBER>
<ORDER>   AAI9537203 </ORDER>
<TITLE> SEGMENTATION AND MATCHING OF MOVING VEHICLES FROM COMPLEX OUTDOOR SCENES  </TITLE>
<AUTHOR> DUBUISSON, MARIE-PIERRE M. </AUTHOR>
<YEAR> 1995 </YEAR>
<INSTITUTION> MICHIGAN STATE UNIVERSITY; 0128 </INSTITUTION>
<DESCRIPTORS> COMPUTER SCIENCE; TRANSPORTATION; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> ANIL K. JAIN </ADVISER>
<CLASSIFICATIONS> MACHINE VISION, INTELLIGENT VEHICLES </CLASSIFICATIONS>
<ABSTRACT>
This thesis describes a machine vision system which is
able to extract moving vehicles from complex stationary
backgrounds and match them based on color and shape
information. This vision system was developed in support
of the Intelligent Vehicle/Highway Systems (IVHS)
program whose main goals are to reduce the number of
accidents on the road, increase the traffic density, and
provide route guidance to the travelers. The specific
problem of interest in this thesis is to estimate the
average travel time between two points in a road
network.
We propose an object matching system which includes a
number of modules that can be utilized in other
application domains. In particular, we have developed
four image segmentation algorithms. The motion
segmentation algorithm can identify the moving areas in
the image using a three-frame sequence. The color
segmentation algorithm combines edge information and a
split-and-merge technique to identify homogeneous
regions of different colors in a color image. These two
algorithms are general purpose image segmentation
algorithms.
The other two segmentation algorithms utilize object
model information. We propose an algorithm to extract an
accurate contour of the moving object in the image. This
technique fuses color and motion information using the
theory of active contours to constrain the contour of
the moving object to be smooth. The final image
segmentation algorithm constrains the object to be a
vehicle. We define a generic model of a vehicle and use
the theory of deformable templates to fuse motion and
edge information and obtain a segmentation and
classification of the vehicle of interest.
Once the vehicles of interest have been separated from
the stationary background and the other moving vehicles,
the matching strategy is based on color and shape
matching. For color matching, we compare the 3D color
histograms of the two objects. For shape matching, we
propose a modified Hausdorff distance between point sets
to compare the edge images of the vehicles.
We evaluated the performance of the vision-based
matching system on a database of 287 vehicles. We were
able to segment and correctly classify 91.6% of the
vehicles. We also demonstrated the efficacy of time-
based, vehicle class-based, and color-based indexing
schemes. We compared the machine vision results to the
results that experts obtained manually by looking at the
video tapes and concluded that the machine vision system
is a feasible tool for travel time estimation.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  3384 </NUMBER>
<ORDER>   AAI9537042 </ORDER>
<TITLE> ADAPTATION IN ANALOG VLSI: A NEURAL NETWORK IMPLEMENTATION </TITLE>
<AUTHOR> MONTALVO, ANTONIO JOSE </AUTHOR>
<YEAR> 1995 </YEAR>
<INSTITUTION> NORTH CAROLINA STATE UNIVERSITY; 0155 </INSTITUTION>
<DESCRIPTORS> ENGINEERING, ELECTRONICS AND ELECTRICAL; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> RONALD S. GYURCSIK </ADVISER>
<CLASSIFICATIONS> LEARNING, NONVOLATILE MEMORY </CLASSIFICATIONS>
<ABSTRACT>
The goal of this research is to develop VLSI techniques
that will allow neural networks to be applied to
problems in which very high performance computers cannot
be used. Examples are battery powered personal
communications devices and hand-held computers. Some of
the requirements for these applications are: low cost,
low power, high speed, on-chip learning, flexibility and
easy system integration.
It is shown that these requirements are best met with
analog circuits. A key building block is the weight
storage technique which exploits the fast learning
capability of dynamic memory as well as the reliable
long term storage of non-volatile memory. A semi-
parallel perturbation-based supervised learning
algorithm is implemented on-chip to provide fast
learning with very little external support. The
precision required for on-chip learning is achieved with
a weight update circuit that adds essentially zero
offset to weight updates. Temperature dependence in the
analog feedforward circuits is canceled, allowing
reliable operation independent of temperature. A
flexible architecture allows a user to select any two
layer (one hidden layer) topology.
These concepts are demonstrated in a fully functional 8
neuron and 64 synapse proof-of-concept chip. Feedforward
time is about 2 microseconds and active power
dissipation is 100 $murm W/weight.$ Due to the non-
volatile long-term weight storage, a zero power standby
mode is possible, allowing very low average power. The
chip can solve difficult problems such as 4-bit parity
in tens of milliseconds. Digital input and output, and
on-chip controlled learning make system integration very
easy.
The concepts presented in this dissertation can be used
to implement a 10,000 synapse and 100 neuron chip in
only 30 $rm mmsp2$ in a 1 $murm m$ technology.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  3385 </NUMBER>
<ORDER>   AAI9537037 </ORDER>
<TITLE> AN INTELLIGENT CONTROL OF VEHICLE DYNAMIC SYSTEMS BY ARTIFICIAL NEURAL NETWORK </TITLE>
<AUTHOR> KIM, HOYONG </AUTHOR>
<YEAR> 1995 </YEAR>
<INSTITUTION> NORTH CAROLINA STATE UNIVERSITY; 0155 </INSTITUTION>
<DESCRIPTORS> ENGINEERING, AUTOMOTIVE; ENGINEERING, MECHANICAL; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> PAUL I. RO </ADVISER>
<CLASSIFICATIONS> STEERING </CLASSIFICATIONS>
<ABSTRACT>
In this study, two artificial neural network controls
for a vehicle four wheel steering system, a sliding mode
control combined with an artificial neural network and
an unsupervised learning control, have been proposed. In
the first control scheme, the neural network estimates
known or even unknown dynamics such that the control
parameters of the sliding mode can be adaptively
adjusted. The adaptive capability of neural network
minimizes the necessary switching gain of the
discontinuous control to compensate for the
uncertainties. This control scheme generates less
chattering than the conventional sliding mode control,
resulting in reduced steady state errors as determined
by an approximation technique. Lyapunov's direct method
is employed to guarantee both the stability and the
level of performance of the global system.
The second control scheme, a neural controller using
unsupervised learning, is able to compensate for the
unknown uncertainties, resulting in the robust control
of nonlinear vehicle dynamics. The teaching signal for
the training is the difference between the actual plant
output and the reference model output. This control
scheme does not require a knowledge of the inverse
dynamics of the plant or the Jacobian information of the
learned plant. As a result an on-line control can be
carried out.
In order to describe the dynamics of a 4WS (Four Wheel
Steering) vehicle, a three degree-of-freedom (3 DOF)
vehicle handling model is used. A neural network tire
model is used for identification of the highly nonlinear
tire side force, a dominant external force to the
vehicle handling model. Comparison between the
simulation results and the field test measurements
demonstrates that the proposed tire model generates tire
force more accurately than the conventional tire model,
in which tire force is expressed by experimental
polynomial equations.
Each 4WS control scheme is evaluated by the response of
both J-turn maneuver and a lane change maneuver with a
driver model. The driver model is an evaluation tool for
vehicle handling performance used in the design stage.
In the simulation of the J-turn, both control schemes
reduced the yaw rate overshoot by 20% compared to that
of a 2WS vehicle. Although the lateral deviations of a
4WS vehicle are almost the same as that of 2WS in the
lane change maneuver, the yaw rate of 4WS was reduced by
approximately 15% compared to a 2WS system. Moreover,
the proposed control schemes are shown to be robust
against uncertainties of vehicle parameters and external
disturbances. The vehicle handling performance is
significantly improved.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  3386 </NUMBER>
<ORDER>   AAI9537001 </ORDER>
<TITLE> A STUDY ON DYNAMIC PURSUIT OF MOVING OBJECTS WITH HAND- EYE COORDINATION  </TITLE>
<AUTHOR> QIAN, YIFEI </AUTHOR>
<YEAR> 1995 </YEAR>
<INSTITUTION> GEORGIA INSTITUTE OF TECHNOLOGY; 0078 </INSTITUTION>
<DESCRIPTORS> ENGINEERING, MECHANICAL; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> KOK-MENG LEE </ADVISER>
<CLASSIFICATIONS> NEURAL NETWORKS, FUZZY LOGIC, MACHINE VISION </CLASSIFICATIONS>
<ABSTRACT>
This thesis addresses the problem of grasping moving
objects from a vibratory feeder with robotic hand-eye
coordination. The problem has been formulated in the
context of Prey Capture with the robot as a "pursuer"
and a moving object as a passive "prey" or "evader."
Since linguistic rules based on "rules-of-thumb"
experiences and engineering judgments have been used for
design of control laws and logical inference, this
strategy is particularly advantageous for systems or
processes which are highly nonlinear and impractical to
model accurately.
A hierarchical intelligent controller, that consists of
three levels, has been developed to direct the robot
gripper to pursue moving objects dynamically. The first
and second levels have implemented a qualitative control
strategy based on the fuzzy logic concept to help the
robot search for a target of interest and then pursue
it, while the third level has implemented a control
strategy based on neural network techniques to help the
robot grasp the target due to the fact that the robot
needs extra time to reach it after the grasping command
is issued, and the vision system is usually obstructed
by the robot gripper when it is approaching it. The
basis for the control strategy has been experimentally
verified. The experiments showed that the fuzzy logic
controller can command the robot to successfully follow
the highly nonlinear motion of a moving target to its
vicinity, and the trained backpropagation neural network
can estimate the target position fairly accurately
within a specified time.
The study has established an engineering basis for
target pursuit with hand-eye coordination in a loosely
structured unattended environment. The hierarchical
control structure and the combination of the fuzzy logic
control strategy with the neural network algorithm
represents the first detailed study to deal with such a
system or process, yet it provides a useful method for a
spectrum of applications.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  3387 </NUMBER>
<ORDER>   AAI9536950 </ORDER>
<TITLE> THREE-DIMENSIONAL OBJECT%RECOGNITION USING ANGLE VIEW DENSITIES  </TITLE>
<AUTHOR> WHANGBO, TAEGKEUN </AUTHOR>
<YEAR> 1995 </YEAR>
<INSTITUTION> STEVENS INSTITUTE OF TECHNOLOGY; 0733 </INSTITUTION>
<DESCRIPTORS> COMPUTER SCIENCE; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> R. MALIK </ADVISER>
<CLASSIFICATIONS> COMPUTER VISION </CLASSIFICATIONS>
<ABSTRACT>
One of the major goals in artificial intelligence is to
create systems with perceiving, reasoning, and motion
capabilities comparable with humans. Computer vision is
by far the most powerful sense for acquiring perception
about the physical world. Intelligent machines must have
the ability of manipulating, recognizing and locating
objects using images generated by computer vision
systems. Recognizing objects (especially 3-D objects)
has been a fundamental issue in this field for more than
two decades, yet no complete solution has developed.
Many of difficulties in object recognition are caused by
the fact that the images acquired in these systems
depend and change with the camera position. The key in
designing recognition algorithms must therefore be based
on understanding and quantifying the variation due to
object or camera orientation in geometric features of
objects. An objective of this dissertation is to present
a complete analysis of the variation in characteristic
geometric features in images. The primary features
selected here are the angles between landmarks in a
scene. The spatial arrangement of landmarks on an object
may constitute a unique characteristic of that object.
As an example the angles between the wing tips and the
nose cone of an aircraft may be adequate in
distinguishing amongst a given class of aircraft. In a
class of polyhedral objects the angles at certain
vertices may form a distinct and characteristic
alignment of faces. For many other classes of objects it
may be possible to identify distinctive spatial
arrangements of some readily identifiable landmarks.
The approach taken here is to model the measured angles
in an image (of a known object) as random variables and
to derive analytically the probability density function
of these angles. The randomness in angles arising from
the unknown (or random) position of the view point
relative to the object. The density function of the
measured angle and the joint density function of an
angle pair in images are derived given an isotropic view
orientation and an orthographic projection. The
significance of these densities arises from the utility
of these densities in decision algorithms for object
recognition and location. The analytical and
probabilistic analysis on the feature variation is a new
and powerful approach to object recognition. Previous
work in this area has quantified feature variations
using histogram techniques and has therefore not
produced the analytic results that are derived here. Two
robust methods, based on the density functions derived,
for recognizing objects has been developed. The
usefulness of the methods are verified by the
experiments conducted to identify simple planar
surfaces. The performance of the recognition scheme is
evaluated by calculating the probability of error when
distinguishing between two triangles.
Other contributions of this research are: (i) a new
proposed method for calculating the probability of
aspects in images of an object, (ii) the probabilistic
analysis of general and non-general view positions which
are ignored in most research on scene analysis of
objects. The aspect approach to object recognition has
been studied extensively, and the concept of probability
of aspects is introduced to reduce the known problems in
the aspect approach and to recognize the objects
efficiently.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  3388 </NUMBER>
<ORDER>   AAI9536948 </ORDER>
<TITLE> LINE SKETCH EXTRACTION OF POLYHEDRAL OBJECTS </TITLE>
<AUTHOR> SO, SIU LEUNG </AUTHOR>
<YEAR> 1995 </YEAR>
<INSTITUTION> STEVENS INSTITUTE OF TECHNOLOGY; 0733 </INSTITUTION>
<DESCRIPTORS> COMPUTER SCIENCE; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> RAASHID MALIK </ADVISER>
<CLASSIFICATIONS> IMAGE PROCESSING, OBJECT RECOGNITION </CLASSIFICATIONS>
<ABSTRACT>
An aim of conventional low level image processing is to
generate useful binary images from gray scale images.
The binary images generated by enhancement and threshold
edge detectors are usually unrefined outlines of the
underlying 3-D scene. Such images must be further
processed to isolate and identify region boundaries;
which, in the case of polyhedra, consist of straight
line segments. The line segments and intersections or
connection points (which are referred to as vertices)
collectively form a line sketch of the original scene.
This line sketch contains considerable information about
objects in the scene and may be used efficiently to
identify and locate targets or objects.
In this thesis we devise and explore methods for
extracting reliable line sketch renderings of scenes
with primarily polyhedral shapes. The methods fall into
three categories: finding and isolating straight
segments, identifying vertices, and establishing
consistencies in the evolving sketch. Straight segments
are located in images using modified Hough Transforms
and novel projection based schemes. The detection of the
absence or presence (and type) of line junctions or
vertices is accomplished using likelihood functions
derived from assumptions of an underlying noise
contamination model. Consistencies in the sketch are
propagated and inconsistencies are resolved using
various graph models and reduction and labeling
algorithms.
Experiments have been conducted and the results reported
in this thesis to verify the utility and judge the
performance of the proposed schemes. Synthetic images
with controlled amounts of noise are used to compare the
different methods and to quantify the effectiveness
under varying noise conditions. The results show that
the proposed schemes are useful and may be used to
obtain line sketches for object recognition.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  3389 </NUMBER>
<ORDER>   AAI9536921 </ORDER>
<TITLE> STABLE NEURAL NETWORK CONTROL SYSTEMS  </TITLE>
<AUTHOR> KUNTANAPREEDA, SUWAT </AUTHOR>
<YEAR> 1995 </YEAR>
<INSTITUTION> UTAH STATE UNIVERSITY; 0241 </INSTITUTION>
<DESCRIPTORS> ENGINEERING, MECHANICAL; ENGINEERING, ELECTRONICS AND ELECTRICAL; ENGINEERING, GENERAL; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> R. REES FULLMER </ADVISER>
<CLASSIFICATIONS> CONTINUOUS SYSTEMS, CLOSED LOOP CONTROL SYSTEMS </CLASSIFICATIONS>
<ABSTRACT>
This dissertation introduces a new training rule for
training neural network controllers for a class of
continuous systems, as well as sampled data systems. The
new training rule guarantees stability of the closed
loop control systems over a finite region of state
space. The controllers are assumed to be nonlinear,
feedforward, full state regulators implemented as single
hidden layer neural networks. The controlled systems
must be locally Hermitian, controllable, and accessible.
Stability of the closed loop systems is demonstrated by
determining a Lyapunov function, which can be directly
found as the by-product of the training process. The
finite region of stability around the regulation point
can be estimated using this Lyapunov function.
The idea of the new training rule is to impose some
stability condition into the training process while
minimizing the same original objective function.
Sufficient stability conditions for neural network
control systems are derived for both continuous and
sampled data systems. Also, a derivation of the new
training rule is shown. Furthermore, this dissertation
proved that the value of the objective function is
always decreased using this new training rule, unless a
minimum point is reached.
By simulations, performance comparisons between the
controllers using the standard backpropagation training
rule and the controllers using the new training rule
indicated that both training rules gave satisfactory
control results. However, only the stability of the
control systems with the controllers using the new
training rule can be verified. The simulations also
indicate that the new training method converges only
slightly slower than the standard backpropagation
training rule.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  3390 </NUMBER>
<ORDER>   AAI9536915 </ORDER>
<TITLE> EVALUATION OF PAVEMENT DISTRESS IMAGES USING ARTIFICIAL NEURAL NETWORKS  </TITLE>
<AUTHOR> CHOU, JACHING </AUTHOR>
<YEAR> 1995 </YEAR>
<INSTITUTION> UTAH STATE UNIVERSITY; 0241 </INSTITUTION>
<DESCRIPTORS> ENGINEERING, CIVIL; TRANSPORTATION; COMPUTER SCIENCE; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> WENDE A. O'NEILL </ADVISER>
<CLASSIFICATIONS> FUZZY LOGIC </CLASSIFICATIONS>
<ABSTRACT>
A novel approach of applying fuzzy logic, moment
invariants, and neural networks to analyze pavement
images is proposed in this research. This approach has
been divided into several steps: (1) pavement image
preprocessing, (2) pavement image enhancement, (3)
pavement image segmentation, and (4) pavement image
classification. In the pre-processing step, image
histogram distortion caused by nonuniform illumination
and background have been corrected. Due to the natural
characteristic (fuzziness rather than randomness) of
pavement distresses, an algorithm based on fuzzy logic
is used in the image enhancement step. Adaptive
thresholding, based on maximum fuzzy entropy, is
employed in determining the threshold value in the image
segmentation step. The theory of moment invariants is
applied to characterize distress features in the fuzzy
and ordinal domain. Backpropagation neural networks are
utilized as classifiers to recognize different types of
pavement distress.
Classification rates from this research are compared
with previous work in pavement image processing. A
higher distress classification rate (accuracy) is
obtained in both the fuzzy and ordinal domain.
Furthermore, in the fuzzy domain, image segmentation is
not required but accuracy of classification is
maintained. Moment invariants, neural networks, and the
theory of fuzzy sets are shown to be not only feasible,
but to have advantages in simplifying procedures and
reducing computational efforts in pavement image
processing.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  3391 </NUMBER>
<ORDER>   AAI9536612 </ORDER>
<TITLE> ULTRASONIC DIGITAL CHARACTERIZATION OF HUMAN LIVER TISSUES  </TITLE>
<AUTHOR> ZATARI, DAOUD ISHAQ DAOUD </AUTHOR>
<YEAR> 1995 </YEAR>
<INSTITUTION> SOUTHERN ILLINOIS UNIVERSITY AT CARBONDALE; 0209 </INSTITUTION>
<DESCRIPTORS> ENGINEERING, BIOMEDICAL; BIOPHYSICS, MEDICAL; ENGINEERING, ELECTRONICS AND ELECTRICAL; BIOLOGY, ANATOMY; BIOLOGY, CELL; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> NAZIEH M. BOTROS </ADVISER>
<CLASSIFICATIONS> NEURAL NETWORK </CLASSIFICATIONS>
<ABSTRACT>
This study involves the investigation of a comprehensive
characterization algorithm of human soft tissues. An
algorithm is developed using the artificial neural
network as a pattern classifier. The power spectra of
the backscattered signal from different depths in the
liver are determined. The acoustic attenuation
coefficient and the change of speed of sound with
frequency (dispersion) are estimated over a 3 MHz
bandwidth. These acoustic parameters are employed as
discrimination features. The algorithm is applied to
test in-vivo data earlier collected from 18 normal and
12 abnormal liver subjects. The network is used to
differentiate among two classes; normal and abnormal
liver. The results show that of the 22 tested cases, the
system diagnosed correctly 19 and 20 using attenuation
and velocity dispersion, respectively. The average
magnitude of dispersion of liver is estimated to be 1.67
$pm$ 0.1 m/s/MHz and about 2.3 $pm$ 0.18 m/s/MHz in the
normal and abnormal cases, respectively. The overall
performance of the system for liver differentiation is
91% for normal cases, and 86% for abnormal cases. Also,
the results suggest that the velocity dispersion is a
slightly better discriminator than is the attenuation.
Further examination for these data are made using the
Nearest Neighbor statistical classifier. The results
show that of the 30 cases examined, the classifier
differentiated correctly 23 cases. Therefore, the
results confirm that the neural network outperform the
traditional classifier. The algorithm is also
implemented to classify 32 data files generated through
a simulation technique. The generated data (the
backscattered signal) have approximately identical
statistical properties compared to the in-vivo data
discussed above. The data files are grouped into four
classes representing liver conditions; one normal and 3
types of abnormalities. The network is trained with 16
files (four files per class) and tested with 16 files
(four files per class). The results show that of the 16
tested cases, the system differentiated correctly 15
cases using velocity dispersion as the discriminating
feature.
A 20 MHz Data Acquisition System is designed and
constructed for data collection. The system is
implemented using Field Programmable Gate Arrays (FPGAs)
XILINX digital technology. The system is tested with
signals generated by a function generator and with
signals generated by simulation.
Further investigations are conducted to examine the
performance of the algorithm. Eight files from simulated
signals are converted to real signals through hardware
design. The converted signals are applied to the Data
Acquisition System and the sampled data are processed
and examined. Four files are used for training and four
for testing the network (one file per class). The
results show that 3 files are differentiated correctly.
The reason for the failed case is due to signal
compression (filtering).
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  3392 </NUMBER>
<ORDER>   AAGMM15384 </ORDER>
<TITLE> L'ANALYSE MULTIRESOLUTION ET LE PERCEPTRON MULTI-COUCHES POUR L'EXTRACTION DES CARACTERISTIQUES DE L'IMAGE </TITLE>
<AUTHOR> MKAOUAR, MOHAMED </AUTHOR>
<YEAR> 1995 </YEAR>
<INSTITUTION> ECOLE DE TECHNOLOGIE SUPERIEURE (CANADA); 1246 </INSTITUTION>
<DESCRIPTORS> ENGINEERING, ELECTRONICS AND ELECTRICAL; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> RICHARD LEPAGE </ADVISER>
<CLASSIFICATIONS> FRENCH TEXT, IMAGING, RESOLUTION, LAYERED, MULTIRESOLUTION ANALYSIS, NEURAL NETWORKS </CLASSIFICATIONS>
<ABSTRACT>
On etudie dans ce memoire trois differents schemas de
recherche d'aretes. La premiere approche est basee sur
le vieux principe: rehaussement de
discontinuites/seuillage. Il s'agit ici d'un rappel de
l'application d'une methode classique d'extraction des
caracteristiques de l'image ainsi que de ses limites.
La seconde approche est l'analyse multiresolution. Suite
a la structure intrinseque des objets dans l'image, on
propose une pyramide multiresolution pour l'extraction
des caracteristiques de l'image. Cet operateur integre
l'information de quelques frequences spatiales separees
pour former le croquis de l'image. De plus, il utilise
un indice de vigilance pour selectionner la nature de
l'information a inclure dans le croquis.
Comme dans le cas du controleur de qualite dans une
usine qui ne se concentre que sur les endroits de la
piece qui necessitent une inspection, l'indice de
vigilance donne au detecteur d'aretes la capacite de
selectionner un type d'informatino ou un autre dans la
scene selon les besoins du systeme de vision
artificielle.
Le fait d'utiliser l'analyse multiresolution dans le
present ouvrage a aussi resolu en partie le probleme
classique du seuillage. Les aretes detectees dans les
resolutions grossieres donnent quelques elements de
reponse a ce probleme.
Le reseau de neurones multi-couches est la troisieme
approche de recherche d'aretes etudiee dans ce memoire.
On rappelle d'abord quelques notions de base sur les
reseaux de neurones. Puis, on decrit l'algorithme de
retro-propagation du gradient. On montre alors comment
construire l'operateur en s'adaptant aux specificites du
probleme de detection d'aretes.
La presente etude conclut que les reseaux de neurones
sont robustes au bruit, rapides, et offrent un detecteur
avec une bonne capacite de localisation. L'analyse
multiresolution, pour sa part, est en mesure de prendre
en compte la structure intrinseque de l'image et de
selectionner l'information a extraire. (Abstract
shortened by UMI.)
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  3393 </NUMBER>
<ORDER>   AAGMM06923 </ORDER>
<TITLE> THE EFFECT OF LIMITED PRECISION-WEIGHTS ON THE CAPACITY AND GENERALIZATION OF THRESHOLD ADALINES </TITLE>
<AUTHOR> HUQ, SHAHEEDUL </AUTHOR>
<YEAR> 1995 </YEAR>
<INSTITUTION> THE UNIVERSITY OF NEW BRUNSWICK (CANADA); 0823 </INSTITUTION>
<DESCRIPTORS> COMPUTER SCIENCE; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> M. STEVENSON </ADVISER>
<CLASSIFICATIONS> NEURAL NETWORKS </CLASSIFICATIONS>
<ABSTRACT>
An Artificial Neural Network is an interconnected
assembly of simple computational elements, whose
functionality is based on biological neurons. In the
design of a dedicated neural network hardware, a key
issue concerns the number of bits to be used to
represent each weight. Recent works by many researchers
indicate that as the number of bits per weight
decreases, so does the capacity of the network, and
hence bigger networks are needed to accomplish the same
task.
In this dissertation, the effects of limited-precision
weights on some fundamental properties, such as the
capacity and the generalization, of threshold Adalines
are presented. More particularly, the capacity of the 5-
ary and the 7-ary Adalines and the index of the perfect
generalization of the binary, the ternary, and the 5-ary
Adalines have been determined. These results, together
with the previous results of the binary and the ternary
Adaline, allow a conjecture regarding the relationship
between the number of bits and the capacity. For the
case of the generalization, it is observed that the
threshold Adalines with limited-precision weights
achieve perfect generalization for relatively small
training set sizes. The number of patterns that is
needed in the training set to achieve perfect
generalization for the binary, the ternary, and the 5-
ary Adalines have been determined in this dissertation.
The research of the effects of limited-precision weights
on the capacity and the generalization of threshold
Adalines is fundamental. It is motivated by the need to
better understand the trade-off between relatively small
networks of high-precision circuitry and large networks
of low-precision circuitry.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  3394 </NUMBER>
<ORDER>   AAI9536523 </ORDER>
<TITLE> SHORT-TERM ELECTRIC LOAD FORECASTING USING NEURAL NETWORK WITH FUZZY SET BASED CLASSIFICATION </TITLE>
<AUTHOR> BUMROONGGIT, GUMPANART </AUTHOR>
<YEAR> 1995 </YEAR>
<INSTITUTION> SOUTHERN ILLINOIS UNIVERSITY AT CARBONDALE; 0209 </INSTITUTION>
<DESCRIPTORS> ENGINEERING, ELECTRONICS AND ELECTRICAL; PHYSICS, ELECTRONICS AND ELECTRICITY; ENGINEERING, GENERAL; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> MORTEZA DANESHDOOST </ADVISER>
<CLASSIFICATIONS> WEATHER FORECASTING </CLASSIFICATIONS>
<ABSTRACT>
This research studies a short-term electric load
forecasting technique using a multi-layer feedforward
Artificial Neural Network with a fuzzy set-based
classification algorithm. Based on the fact that the
power system load strongly depends on the weather of the
serving area, the hourly data is classified into
different classes of weather condition using the concept
of fuzzy set representation of weather variables. Then
the set of artificial neural networks for these classes
of weather condition is trained and used to perform the
forecasting. The load forecasting index is also
developed from the application of the fuzzy logic
system. The presented technique is tested with the
utility's data for various lead times ranging from 24 to
120 hours. The results indicate that the technique is
able to forecast the system load with excellent accuracy
and its performance does not deteriorate as the lead
time becomes longer.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  3395 </NUMBER>
<ORDER>   AAI9536145 </ORDER>
<TITLE> PRESENT STATUS AND PERCEIVED IMPORTANCE OF COMPUTER SKILLS IN A TAIWANESE SERVICE INDUSTRY </TITLE>
<AUTHOR> TSENG, EN-MING PATRICK </AUTHOR>
<YEAR> 1995 </YEAR>
<INSTITUTION> UNIVERSITY OF NORTHERN IOWA; 0743 </INSTITUTION>
<DESCRIPTORS> ENGINEERING, INDUSTRIAL; COMPUTER SCIENCE </DESCRIPTORS>
<ADVISER> CHARLES D. JOHNSON </ADVISER>
<CLASSIFICATIONS> ARTIFICIAL INTELLIGENCE, DATABASE MANAGEMENT, SPREADSHEET, WORD PROCESSING </CLASSIFICATIONS>
<ABSTRACT>
The purpose of this study was to provide researchers,
computer technologists, management and trainers with
information concerning the current status and importance
regarding computer skills for agents in the Taiwanese
life insurance industry. This research also identified
important computer skills for this population and
investigated differences in perceptions of computer
directors (system developers), sales managers (training
providers), and life insurance agents (end-users)
regarding the current status and importance of computer
skills for life insurance agents.
Survey instruments were developed through the literature
review and expert interviews and validations.
Investigated samples include all 30 computer directors
of member companies of the Taipei Life Insurance
Association, 200 randomly selected members of the
General Agents and Managers Association, and 400
randomly selected members of the Life Underwriters
Association in Taiwan. The usable return rate was 55.2%.
In this study, 49 important skills were identified in 8
categories: basic computer skills, database management,
spreadsheet, word processing, communication,
presentation, computer-based training, and artificial
intelligence.
One-way ANOVAs at the.05 level were used to detect
differences of perceptions among the three groups. The
Fisher's Least Significant Difference Procedure (three t-
tests at the.01 level) was used for all significant
ANOVAs to identify the significant differences between
each two groups. The majority of significant
differences, 28 out of 49 regarding importance level and
8 concerning level of expertise, were found between
sales managers and agents; 4 significant differences
concerning importance level and 1 concerning level of
expertise were found between sales managers and computer
directors; only 4 items related to importance level were
found significantly different between agents and
computer directors.
The ranking of both levels of importance and expertise
showed more consensus between agents and sales managers
than agents and computer directors. However, because of
the difference in sample sizes, this finding should be
interpreted with caution.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  3396 </NUMBER>
<ORDER>   AAI9535126 </ORDER>
<TITLE> A STATISTICAL METHOD FOR WORD-SENSE DISAMBIGUATION </TITLE>
<AUTHOR> BRUCE, REBECCA FRANCES </AUTHOR>
<YEAR> 1995 </YEAR>
<INSTITUTION> NEW MEXICO STATE UNIVERSITY; 0143 </INSTITUTION>
<DESCRIPTORS> COMPUTER SCIENCE; ARTIFICIAL INTELLIGENCE; LANGUAGE, LINGUISTICS </DESCRIPTORS>
<ADVISER> JANYCE M. WIEBE </ADVISER>
<CLASSIFICATIONS> NATURAL LANGUAGE </CLASSIFICATIONS>
<ABSTRACT>
In this dissertation, I apply statistical techniques to
the formidable natural language processing task of word-
sense disambiguation. In particular, I develop
probabilistic classifiers--systems that perform
disambiguation by assigning, out of a set of word
meaning designations, the one that is most probable
according to a probabilistic model. The model expresses
the relationships among the classification variable (in
this case, the variable representing the sense tag of
the ambiguous word) and variables that correspond to
properties of the ambiguous word and the context in
which it occurs (the non-classification variables).
Statistical approaches to natural language processing
are typically limited to simple models that include only
a small number of immediately surrounding non-
classification variables. The work in this dissertation
addresses this limitation. I present a procedure for
automatic model selection that makes use of a richer
class of probabilistic models than is typically used in
natural language processing, along with a technique for
fitting such models to the data. That is, rather than
making assumptions about which non-classification
variables to use and how they are related, a procedure
for using statistical techniques to answer these
questions is described. Further, the types of models
used in this work can express complex relationships
among diverse sets of variables. These contributions are
particularly important for word-sense disambiguation,
where a tremendous number of non-classification
variables, and interactions among them seem potentially
relevant.
The claims made in formulating this procedure for model
selection are supported by experimental verification. In
total, I develop and test word-sense classifiers for
twelve words: four nouns, four verbs and four
adjectives. Each of these words is disambiguated with
respect to the full set of sense distinctions provided
in the Longman Dictionary of Contemporary English.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  3397 </NUMBER>
<ORDER>   AAI0576501 </ORDER>
<TITLE> INTELLIGENT GRAPH-SEARCH TECHNIQUES: AN APPLICATION TO PROJECT SCHEDULING UNDER MULTIPLE RESOURCE CONSTRAINTS </TITLE>
<AUTHOR> ZAMANI, MOHAMMAD REZA </AUTHOR>
<YEAR> 1995 </YEAR>
<INSTITUTION> UNIVERSITY OF WOLLONGONG (AUSTRALIA); 0727 </INSTITUTION>
<DESCRIPTORS> OPERATIONS RESEARCH; BUSINESS ADMINISTRATION, MANAGEMENT; ENGINEERING, INDUSTRIAL; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> NIL </ADVISER>
<CLASSIFICATIONS> NIL </CLASSIFICATIONS>
<ABSTRACT>
The topic of graph-search techniques is of common
interest for both Operations Research (OR) and
Artificial Intelligence (AI) communities. Solutions
found by OR techniques are optimal and precise but may
be obtained at the price of high computation time. On
the other hand, those found by AI techniques have no
guarantee of being optimal but are usually achieved
quickly. In this research, these techniques of AI and OR
are investigated and a learning search method
integrating the features of both fields is presented.
The main characteristics of this method are its capacity
to learn along the search process and its ability to
trade speed with precision to whatever degree desired.
In order to develop this method, we utilise a technique
developed by Korf (1990) and expand its learning
capability to generate optimal solutions. Then, by the
use of a threshold parameter, the features of Korfs AI
algorithm and this new OR method are integrated to
represent a new learning technique. Through an intensive
programming task, the correctness of this integrating
method is presented by testing it on three different
graphs with different characteristics. A mathematical
proof is also developed to show that solutions found by
this method are always guaranteed to be within a
prescribed range of the optimal solution. This range is
determined by the user and can be any positive real
number.
The generality of this method allows its application to
all graph-search problems including all such
combinatorial problems. To show how efficiently
combinatorial problems can be solved by this method, it
is applied to the problem of Project Scheduling Under
Multiple Resource Constraints, which is one of the
hardest types in the scheduling area. It is shown that
the method is able to solve a benchmark problem of this
type manually and that it requires only 25 backtracks to
find its optimal solution and only 1 backtrack to find a
solution guaranteed to be within the range of 3 units of
the optimal one. It is emphasised that this method is
superior to all previous techniques which required tens
of seconds of computer time to solve the benchmark
problem.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  3398 </NUMBER>
<ORDER>   AAI0576389 </ORDER>
<TITLE> IMPROVING WORDSPOTTING PERFORMANCE WITH LIMITED TRAINING DATA  </TITLE>
<AUTHOR> CHANG, ERIC I-CHAO </AUTHOR>
<YEAR> 1995 </YEAR>
<INSTITUTION> MASSACHUSETTS INSTITUTE OF TECHNOLOGY; 0753 </INSTITUTION>
<DESCRIPTORS> ENGINEERING, ELECTRONICS AND ELECTRICAL; COMPUTER SCIENCE; PHYSICS, ACOUSTICS; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> RICHARD P. LIPPMANN; DAVID H. STAELIN </ADVISER>
<CLASSIFICATIONS> PATTERN DETECTION, NEURAL NETWORK </CLASSIFICATIONS>
<ABSTRACT>
This thesis addresses the problem of limited training
data in pattern detection problems where a small number
of target classes must be detected in a varied
background. There is typically limited training data and
limited knowledge about class distributions in this type
of spotting problem and in this case a statistical
pattern classifier can not accurately model class
distributions. The domain of wordspotting is used to
explore new approaches that improve spotting system
performance with limited training data. First, a high
performance, state-of-the-art whole-word based
wordspotter is developed. Two complementary approaches
are then introduced to help compensate for the lack of
data. Figure of Merit training, a new type of
discriminative training algorithm, modifies the spotting
system parameters according to the metric used to
evaluate wordspotting systems. The effectiveness of
discriminative training approaches may be limited due to
overtraining a classifier on insufficient training data.
While the classifier's performance on the training data
improves, the classifier's performance on unseen test
data degrades. To alleviate this problem, voice
transformation techniques are used to generate more
training examples that improve the robustness of the
spotting system. The wordspotter is trained and tested
on the Switchboard credit-card database, a database of
spontaneous conversations recorded over the telephone.
The baseline wordspotter achieves a Figure of Merit of
62.5% on a testing set. With Figure of Merit training,
the Figure of Merit improves to 65.8%. When Figure of
Merit training and voice transformations are used
together, the Figure of Merit improves to 71.9%. The
final wordspotter system achieves a Figure of Merit of
64.2% on the National Institute of Standards and
Technology (NIST) September 1992 official benchmark,
surpassing the 1992 results from other whole-word based
wordspotting systems. (Copies available exclusively from
MIT Libraries, Rm. 14-0551, Cambridge, MA 02139-4307.
Ph. 617-253-5668; Fax 617-253-1690.)
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  3399 </NUMBER>
<ORDER>   AAI9536411 </ORDER>
<TITLE> A KANTIAN CRITIQUE OF ARTIFICIAL INTELLIGENCE THROUGH THE CONCEPTUAL LENS OF IRONY </TITLE>
<AUTHOR> SHOWKOWY, WILLIAM NICHOLAS </AUTHOR>
<YEAR> 1995 </YEAR>
<INSTITUTION> EMORY UNIVERSITY; 0665 </INSTITUTION>
<DESCRIPTORS> HISTORY OF SCIENCE; COMPUTER SCIENCE; PHILOSOPHY </DESCRIPTORS>
<ADVISER> ROBERT A. PAUL </ADVISER>
<CLASSIFICATIONS> NIL </CLASSIFICATIONS>
<ABSTRACT>
This study shall be concerned with exploring fundamental
limits of the artificial intelligence (AI) effort to
simulate human cognition via machine artifacts. After
fifty years of research in conjunction with enormous
strides in the technological sphere, AI has failed to
deliver on its promises to create synthetic entities
capable of equaling, or even exceeding, human
intelligence. In fact, even with today's super
computers, AI researchers have been unable to
reduplicate the cognitive achievements of a two year old
child, not to mention a fully developed human intellect.
Why is this the case? Is there some invisible ceiling
which AI has been unwittingly up against?
I argue that there is indeed just such a fundamental
limit having to do not only with the polyvalence of what
constitutes human "reason," but also the dialectical
nature of human communication which manifests through
our pragmatic use of irony. My effort, therefore, shall
be a return to an essentially Kantian metaphysical
inquiry in order to account for AI's lack of critical
clarity concerning the nature and limits of what amounts
to its own unique and courageous gedanken experiment. In
spite of Dreyfus's claim that there has been no
adduction so far of an apriori critique against the
possibility of a synthetic intelligence, I will attempt
to do just such a dialectical assessment of the limits
of AI from the transcendental point of view proffered by
Kantian dialectic. Finally, I shall ground what might
otherwise be a free-floating speculative exercise
through referring to the praxis of our distributed
cognition and communication, using the human ability to
negotiate irony as that demonstration.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  3400 </NUMBER>
<ORDER>   AAI9528625 </ORDER>
<TITLE> A KNOWLEDGE-BASED DECISION SUPPORT SYSTEM USING DISTRIBUTED ARTIFICIAL INTELLIGENCE </TITLE>
<AUTHOR> BHASKAR, RAHUL </AUTHOR>
<YEAR> 1995 </YEAR>
<INSTITUTION> THE UNIVERSITY OF WISCONSIN - MADISON; 0262 </INSTITUTION>
<DESCRIPTORS> BUSINESS ADMINISTRATION, MANAGEMENT; COMPUTER SCIENCE; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> AMIT GUPTA </ADVISER>
<CLASSIFICATIONS> NIL </CLASSIFICATIONS>
<ABSTRACT>
The main purpose of this research is to use selected
tools and methodologies from the distributed artificial
intelligence (DAI) field to create a functioning
knowledge-based decision support system (KBDSS). This
KBDSS performs telephone analysis and financial
analysis. Furthermore, an observational study is
conducted to compare the prototype of the KBDSS, which
we call Sherpa, to the system currently in use.
The architecture of the prototype comprises a set of
problem solvers, all operating under the guidance of
meta-level knowledge. Each problem solver works as a
classifier system. The problem solving knowledge of each
solver is developed using machine learning and/or
knowledge engineering.
As part of the observational study, variables are
identified and hypotheses formulated. Statistical
analysis is carried out to test the hypotheses. Sherpa
outperforms the currently used system in all aspects
tested.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  3401 </NUMBER>
<ORDER>   AAIC440054 </ORDER>
<TITLE> STATISTICAL ASPECTS OF THE SPLIT SPECTRUM TECHNIQUE </TITLE>
<AUTHOR> GUSTAFSSON, MATS GORAN </AUTHOR>
<YEAR> 1995 </YEAR>
<INSTITUTION> UPPSALA UNIVERSITET (SWEDEN); 0903 </INSTITUTION>
<DESCRIPTORS> ENGINEERING, ELECTRONICS AND ELECTRICAL; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> NIL </ADVISER>
<CLASSIFICATIONS> NEURAL NETWORKS, GAUSSIAN NOISE </CLASSIFICATIONS>
<ABSTRACT>
A practical well established signal processing technique
for suppression of ultrasonic clutter known as split
spectrum processing (SSP) is studied in an attempt to
obtain better theoretical understanding and optimal
parameter tuning. The SSP technique relies on nonlinear
processing of the outputs from a filter bank which
splits the received signal into different frequency
bands.
A general approach to parameter tuning of SSP is
considered where an adaptive artificial neural network
(ANN) replaces the nonlinear part of the SSP. Extensions
to an adaptive filter bank are also considered in the
context of both a multilayer perception ANN operating on
a delay line and the Wiener model of nonlinear dynamical
systems. Both the ANN and the Wiener model are shown to
have the same structure as the SSP and the potential of
supervised learning of the ANN and system identification
of the Wiener model is discussed.
Originating from the ANN approach, many theoretical
aspects of how SSP works, are presented. New insights
about how SSP exploits phase and amplitude information
are elaborated and conceptual links between the SSP
filter bank and the short-time Fourier transform and
other time-frequency methods such as wavelets are
touched upon. Employing a statistical pattern
recognition perspective, the optimal detector for a
known transient in additive Gaussian noise (the matched
filter) is formulated as a time-frequency method and
used for nonlinear clutter suppression. The new
formulation is used to compare SSP with conventional
detection theory and to obtain a unifying link with
recent work on maximum likelihood amplitude estimation
in the context of ultrasonics. It is also employed to
show that the polarity thresholding SSP algorithm relies
on a test statistic which is a nonlinear function of the
observed samples.
A simple clutter model suitable for digital signal
processing is developed based on physical principles. It
is used mainly to motivate the theoretical studies of
the optimal detectors in additive Gaussian noise and for
evaluation of different algorithms.
As a final contribution, the underlying principle of SSP
to produce and compound uncorrelated filter signals is
reconsidered, resulting in a statistically based formula
for the number of optimal filters to use and insights
about the role of the filter bank in stationary as well
as nonstationary noise. Other results include a new SSP
algorithm based on a noncoherent detector for additive
Gaussian noise which demonstrates that the original SSP
filter bank can produce optimal statistics for in-phase
noncoherent subband detection.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  3402 </NUMBER>
<ORDER>   AAIC440046 </ORDER>
<TITLE> PATROONHERKENNING MET BEHULP VAN NEURALE NETWERKEN; PATTERN RECOGNITION WITH NEURAL NETWORKS </TITLE>
<AUTHOR> WEYMAERE, NICO JEAN-MARIE </AUTHOR>
<YEAR> 1995 </YEAR>
<INSTITUTION> RIJKSUNIVERSITEIT TE GENT (BELGIUM); 0215 </INSTITUTION>
<DESCRIPTORS> COMPUTER SCIENCE; ARTIFICIAL INTELLIGENCE ROZIER 9, B-9000 GENT, BELGIUM </DESCRIPTORS>
<ADVISER> NIL </ADVISER>
<CLASSIFICATIONS> NIL </CLASSIFICATIONS>
<ABSTRACT>
In this thesis, an analysis is made of the possibilities
and the limitations of multi-layer perceptrons for
pattern recognition. By means of a theoretical analysis
and practical examples, it is shown how a multi-layer
perceptron can be used for pattern classification.
First, the analysis leads to the introduction of a
general two-layer perceptron incorporating direct input-
output links and sigmoidal and Gaussian hidden nodes.
Moreover a method for properly initializing the weights
of a general two-layer perceptron is proposed. This
allows us to identify the most suitable network size and
topology for solving the classification problem under
investigation, without the need for any error-
backpropagation training. By initializing the weights to
values that are probably close to a good local minimum
in the energy space, it is very unlikely that an
additional training of these networks will converge
toward a poor local minimum in that space. Experiments
show that the performance of the initialized networks is
near optimal.
Further, it is also shown that the training of a multi-
layer perceptron can be improved significantly by
introducing appropriate transformations of the inputs,
and by adapting a general formulation of the
backpropagation algorithm. This formulation does not
correspond to a steepest descent search, as it allows
different learning rates for the different network
parameters. Experiments demonstrate that, compared to
the standard algorithm, the new algorithm provides a
faster convergence and an increased robustness against
different network architectures and input scalings.
Finally, a method is introduced that allows us to adapt
the network outputs in case of changing a priori
conditions. It allows us to obtain the a posteriori
probabilities under the new circumstances, without the
need for a new supervised training session.
To illustrate the power of the different methods
introduced in this thesis on a real world problem, the
broad phonetic classification of speech segments is
used.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  3403 </NUMBER>
<ORDER>   AAIC439639 </ORDER>
<TITLE> PEAK IDENTIFICATION IN AUDITORY EVOKED POTENTIALS USING ARTIFICIAL NEURAL NETWORKS </TITLE>
<AUTHOR> VAN GILS, MARCUS JOHANNIS </AUTHOR>
<YEAR> 1995 </YEAR>
<INSTITUTION> TECHNISCHE UNIVERSITEIT EINDHOVEN (THE NETHERLANDS); 0426 </INSTITUTION>
<DESCRIPTORS> ENGINEERING, BIOMEDICAL; ARTIFICIAL INTELLIGENCE DOLECH 2, PO BOX 513, EH 8.28,  NL-5600 MB EINDHOVEN, THE NETHERLANDS </DESCRIPTORS>
<ADVISER> NIL </ADVISER>
<CLASSIFICATIONS> NIL </CLASSIFICATIONS>
<ABSTRACT>
Automatically identifying peaks in auditory evoked
potentials (AEPs) poses difficulties for many types of
pattern recognition techniques. In this study three
types of artificial neural networks were investigated on
their usefulness for this task in the context of their
use in an anesthetic depth monitoring system.
Systems based on backpropagation networks, ART networks,
and Kohonen networks followed by an extra output layer
were developed and investigated. Various data sets were
used to assess the merits of the various networks.
Results indicate that ART networks are not useful for
this application. Backpropagation networks and Kohonen
networks are suited better; they show comparable
performances. Considering the relatively large
complexity and long training time associated with
backpropagation networks, the choice was made to perform
'acceptance tests' with Kohonen networks. For Kohonen
networks for peaks V and Na no significant differences
between the network's determination of peak locations
and those of human experts could be found. For peaks Pa
and Nb however, there is a significant difference.
It is concluded that the Kohonen network based system
provides a useful means for automatically identifying
peak V and Na in AEPs: its performance is comparable to
that of other methods reported in literature, even for
AEPs in which the location of sought peaks differs
dramatically from standard values. For peaks Pa and Nb
improvement of the system is necessary if it is to be
used in an on-line monitoring system. Problems arise in
particular with noisy AEPs that have small amplitudes.
The system can however be employed to considerably
decrease the time needed to score AEPs visually.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  3404 </NUMBER>
<ORDER>   AAG9625418 </ORDER>
<TITLE> PULSE COUPLED NEURAL NETWORK FOR IMAGE PROCESSING </TITLE>
<AUTHOR> KUNTIMAD, GOVINDARAJ </AUTHOR>
<YEAR> 1995 </YEAR>
<INSTITUTION> UNIVERSITY OF ALABAMA IN HUNTSVILLE; 0278 </INSTITUTION>
<DESCRIPTORS> COMPUTER SCIENCE; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> NIL </ADVISER>
<CLASSIFICATIONS> MEDICAL IMAGING </CLASSIFICATIONS>
<ABSTRACT>
The results of recent studies of the visual cortices of
cats and monkeys have led to the development of a new
class of artificial neuron models. These models resemble
biological neurons more closely than the commonly used
artificial neurons. Eckhorn and his co-workers have
developed one such neuron, referred to as Eckhorn's
neuron. They have demonstrated that the recurrent
networks of Eckhorn's neurons are capable of duplicating
some of the neuro-physiological phenomena observed in
cat's visual cortex.
In this dissertation Eckhorn's neuron model has been
modified so that the resulting neuron, referred to as
the pulse coupled neuron (PCN), becomes more suitable
for image processing applications than his original
model. It is shown that a single layered laterally
connected pulse coupled neural network (PCNN) is capable
of smoothing and segmenting digital images. It is also
shown that the PCNN can be utilized for detecting
objects in digital images.
Simulation results indicate that the performance of the
PCNN based smoothing technique is better than the
performance of the neighborhood averaging and median
filtering techniques. The PCNN based segmentation
outperforms some of the commonly used segmentation
methods--intensity thresholding, optimal thresholding
and region growing techniques. The PCNN approach yields
results that are comparable to the results obtained by
the probabilistic relaxation technique, but without the
restrictions associated with the relaxation technique.
The iterative knowledge based object detection system
developed in this dissertation shows that the PCNNs
being powerful and flexible have potential in real-time
image processing systems.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  3405 </NUMBER>
<ORDER>   AAIC436701 </ORDER>
<TITLE> RADIOTHERAPY OF PROSTATIC CANCER, WITH REFERENCE TO POSITIONING AND THREE-DIMENSIONAL DOSE PLANNING </TITLE>
<AUTHOR> LENNERNAS, BO NILS </AUTHOR>
<YEAR> 1995 </YEAR>
<INSTITUTION> UPPSALA UNIVERSITET (SWEDEN); 0903 </INSTITUTION>
<DESCRIPTORS> HEALTH SCIENCES, RADIOLOGY UPPSALA, SWEDEN </DESCRIPTORS>
<ADVISER> NIL </ADVISER>
<CLASSIFICATIONS> NIL </CLASSIFICATIONS>
<ABSTRACT>
Prostatic adenocarcinoma is frequently diagnosed in the
Western world. While the latent form of the malignancy
is very common throughout the world, the incidence of
more aggressive forms varies.
The treatment of prostatic adenocarcinoma is the subject
of much debate. In some cases, treatment may not affect
survival or quality of life, but there are cases that
benefit from aggressive curative treatment. If radical
radiotherapy is chosen, several parameters must be taken
into consideration for the therapy to be optimal.
Conformal therapy is a term used to denote external beam
irradiation based on three-dimensional dose-planning in
order to optimise the dose distribution in the target
and organs at risk. By altering the number of fields (4-
6), margins (10 or 20 mm) and field collimation
(multileaf collimator), it was found that field
collimation and margin reduction decreased the dose to
risk organs. However, an increase in the number of
fields did not improve the dose distribution in the
rectum or the bladder. On verification films of patients
with implanted gold seeds, it was not possible to reduce
the margins to 10 mm and a radiobiological model
predicted that small displacement errors in the fields
would have substantial impact on local control.
In order to improve dose distribution to risk organs,
positioning, fixation and verification systems must be
developed if margin reductions are to be a feasible
therapy option. A system that makes use of implanted
magnetic markers was found, in a phantom study, to
position the phantom with an accuracy of 0.5 mm.
Artificial intelligence neural networks were trained to
evaluate treatment plans presented as dose-volume
histograms and found to be able to accept or reject
plans according to the assessments of three radiation
oncologists.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  3406 </NUMBER>
<ORDER>   AAIC436608 </ORDER>
<TITLE> COMBINATORIAL OPTIMIZATION AND ARTIFICIAL NEURAL NETWORKS </TITLE>
<AUTHOR> OHLSSON, MATTIAS </AUTHOR>
<YEAR> 1995 </YEAR>
<INSTITUTION> LUNDS UNIVERSITET (SWEDEN); 0899 </INSTITUTION>
<DESCRIPTORS> PHYSICS, GENERAL; ARTIFICIAL INTELLIGENCE; PHYSICS, ELEMENTARY PARTICLES AND HIGH ENERGY; ENGINEERING, BIOMEDICAL; COMPUTER SCIENCE UNIVERSITY, SOLVEGATAN 14A,  S-223 62 LUND, SWEDEN </DESCRIPTORS>
<ADVISER> NIL </ADVISER>
<CLASSIFICATIONS> NIL </CLASSIFICATIONS>
<ABSTRACT>
Artificial neural networks (ANN) and variations thereof
are used to find good approximate solutions to different
combinatorial optimization problems. The ANN approach is
used to develop algorithms for track finding in high
energy physics and clustering in computer vision. These
algorithms are based on the deformable templates method
and augmented with a deterministic annealing procedure
for fast convergence. They are demonstrated to find good
solutions to problems with a large degree of noise. It
is also shown that ANN combined with mean field theory
(MFT) can be used to develop algorithms for discrete
optimization problems with inequality constraints. This
methodology was extensively tested on knapsack problems
with encouraging results.
ANN have also proven to be of value in pattern
classification problems. It is demonstrated how feed-
forward neural networks can be used to detect lead
reversed electrocardiograms (ECG) and to diagnose
possible myocardial infarctions using such ECG's.
Furthermore, a finite-size scaling theory of cumulants
of the order parameter at phase-coexistence is developed
and tested numerically in the low-temperature phase of
the two-dimensional Ising model.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  3407 </NUMBER>
<ORDER>   AAIC434386 </ORDER>
<TITLE> THE DESIGN OF NEURAL NETWORKS USING A PRIORI KNOWLEDGE </TITLE>
<AUTHOR> COZZIO-BUELER, ENRICO ALBERT </AUTHOR>
<YEAR> 1995 </YEAR>
<INSTITUTION> EIDGENOESSISCHE TECHNISCHE HOCHSCHULE ZUERICH (SWITZERLAND); 0663 </INSTITUTION>
<DESCRIPTORS> COMPUTER SCIENCE; ARTIFICIAL INTELLIGENCE TECHNOLOGY, ZURICH, SWITZERLAND </DESCRIPTORS>
<ADVISER> NIL </ADVISER>
<CLASSIFICATIONS> NIL </CLASSIFICATIONS>
<ABSTRACT>
We investigate methods for the design of neural networks
using application to specific knowledge. An integration
of both observation data and a priori knowledge into
neural networks should be tried. We show that using a
priori knowledge for the design of neural networks helps
to solve some basic difficulties encountered in
practice: Inefficient training and bad generalization of
neural networks. For that purpose, different types of a
priori knowledge are identified and corresponding design
methods are presented.
We develop a method that allows one to exploit ordinary
differential equations for the design of neural
networks. This algorithm determines the structure as
well as the weights of a network. It is based on a
generalization of the Taylor series method for the
approximation of differential equations and it generates
a set of equations for the network weights. We study the
necessary conditions that enforce solvability of these
equations and we show that both the class of radial
basis function networks and the class of modified
logistic networks satisfy these conditions.
A set of transformation rules is given that allows one
to transform most ordinary differential equations into a
form suitable for the design algorithm. If the
differential equations are linear, the standard neural
network architecture can be maintained, whereas if the
differential equations are in general form, a polynomial
preprocessing layer has to be added to the network.
Our design algorithm generates neural networks that
approximate the given differential equations. We test
their approximation quality by forecasting some time
series, which are generated by periodic sampling of
chaotic differential equations. We examine the Lorenz
system, the Rossler system and the circular pendulum
system of differential equations. Both one-step-ahead
forecasts and repeated forecasts are verified. It turns
out that the Lorenz system and the Rossler system can be
approximated well, whereas the circular pendulum system
proves to be more difficult. In all cases, the modified
logistic networks are superior to the radial basis
function networks.
We investigate opportunities to exploit the learning
capabilities of the networks after their initial design.
If a network is constructed on the basis of incomplete
differential equations, we can reduce the remaining
modeling defects by additional learning. Alternatively,
if the differential equations contain unknown
parameters, they can be estimated from observation data
using neural network training algorithms.
We test the latter aspect by estimating the parameters
of the Lorenz system, the Rossler system and the
circular pendulum system. A simulated annealing
algorithm is applied to minimize the one-step-ahead
forecasting error of a neural network. The resulting
parameter estimations match the correct parameters only
if they coincide with the global minimum of the
forecasting error. Consequently, if accurate parameter
estimations are desired, the neural network must be
constructed so that sufficient forecasting quality is
guaranteed. (Abstract shortened by UMI.)
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  3408 </NUMBER>
<ORDER>   AAIC434374 </ORDER>
<TITLE> HANDWRITING RECOGNITION USING NEURAL NETWORKS AND HIDDEN MARKOV MODELS </TITLE>
<AUTHOR> SCHENKEL, MARKUS E. </AUTHOR>
<YEAR> 1995 </YEAR>
<INSTITUTION> EIDGENOESSISCHE TECHNISCHE HOCHSCHULE ZUERICH (SWITZERLAND); 0663 </INSTITUTION>
<DESCRIPTORS> COMPUTER SCIENCE; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> NIL </ADVISER>
<CLASSIFICATIONS> NIL </CLASSIFICATIONS>
<ABSTRACT>
Handwriting recognition has challenged research
engineers since the 1960's. But it is only the more
recent interest in pen computing which has boosted
research activity in on-line handwriting recognition.
The arrival of new methods such as neural networks and
hidden Markov models in combination with increasing
computer power is promoting the realization of
operational systems.
This thesis presents a writer independent system for on-
line handwriting recognition which processes cursive
script and handprint in a variety of writing styles. It
is designed to provide an acceptable recognition rate
for any writer without requiring an additional training
session. The main design features are: word level
recognition, training from examples, recognition based
segmentation and integration of contextual information.
The input to the system is the pen trajectory
information. Via a touch sensitive pad (such as those
used by note-pad computers) the writing process is
encoded as a time-ordered sequence of feature vectors.
Features include X and Y coordinates, pen-lifts, speed,
direction and curvature of the pen trajectory.
The data is preprocessed by a normalization scheme which
makes no irreversible segmentation or recognition
decisions and processes complete words as units.
A time delay neural network (TDNN) with local
connections and shared weights estimates the a
posteriori probabilities for characters. Using these
probabilities a hidden Markov model (HMM) segments the
word into characters to optimize the word score with
respect to a dictionary.
The best system was trained on 20,000 words from 59
writers and used the 25,000 word UNIX dictionary. Using
test data from a disjoint set of writers, 98% of the
characters and 96% of the words were recognized in an
uppercase recognition task. For cursive words, the
recognition rate was 89% for characters and 80% for
words.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  3409 </NUMBER>
<ORDER>   AAIC429387 </ORDER>
<TITLE> NATURAL INTELLIGENCE IN ARTIFICIAL CREATURES </TITLE>
<AUTHOR> BALKENIUS, CHRISTIAN </AUTHOR>
<YEAR> 1995 </YEAR>
<INSTITUTION> LUNDS UNIVERSITET (SWEDEN); 0899 </INSTITUTION>
<DESCRIPTORS> COMPUTER SCIENCE; ARTIFICIAL INTELLIGENCE KUNGSHUSET/LUNDAGARD, S-222 22 LUND,  SWEDEN </DESCRIPTORS>
<ADVISER> NIL </ADVISER>
<CLASSIFICATIONS> NEURAL NETWORKS </CLASSIFICATIONS>
<ABSTRACT>
What mechanisms are needed in a cognitive system, such
as an animal or a robot, and how do these mechanisms
interact with each other?
The thesis presents a study of this problem within the
field of behavior-based systems and artificial neural
networks. The thesis brings together ideas from behavior-
based robotics, control theory and machine learning and
combines them with models from ethology, psychology and
neurobiology in an attempt to synthesize a complete,
artificial nervous system for a simulated artificial
creature.
It is argued that an intelligent system cannot be based
on a single general principle, but requires a large set
of interacting systems. The main goal of the thesis is
to identify these functional subsystems and to develop
computational miniature models that can be combined into
a complete system.
It is shown how goal-directed behavior can be
categorized as appetitive, aversive, exploratory or
neutral. This classification is a step away from a
single hedonic dimension, and gives a richer framework
for understanding reactive behavior. A number of
learning mechanisms are developed that take this new
framework into account, and it is shown how these
mechanisms can account for a large range of classical
and instrumental conditioning experiments, as well as
more cognitive processes such as category learning,
exploratory behavior and cognitive mapping. The role of
expectations in learning is emphasized to map out the
way for more cognitive abilities such as planning and
problem solving. It is also shown how categorical,
procedural and expectancy learning can all be based on
different types of matching between the actual and the
expected sensory state.
The central role of motivation and emotion within a
cognitive theory is discussed, and it is shown that a
central motivational system is necessary to coordinate
behavior.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  3410 </NUMBER>
<ORDER>   AAI1375083 </ORDER>
<TITLE> EFFICIENT TRAINING OF MULTI-LAYER PERCEPTRON NEURAL NETWORKS </TITLE>
<AUTHOR> MANOJ, KANAGALU RAMASWAMY </AUTHOR>
<YEAR> 1995 </YEAR>
<INSTITUTION> THE UNIVERSITY OF TEXAS AT ARLINGTON; 2502 </INSTITUTION>
<DESCRIPTORS> ENGINEERING, ELECTRONICS AND ELECTRICAL; COMPUTER SCIENCE; MATHEMATICS; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> MICHAEL T. MANRY </ADVISER>
<CLASSIFICATIONS> NIL </CLASSIFICATIONS>
<ABSTRACT>
In this thesis an efficient training algorithm for
training multi-layer perceptron (MLP) neural networks is
proposed. The structure and training algorithms of
existing MLP neural networks are reviewed and their
shortcomings are discussed. A polynomial activation MLP
is proposed. It is shown that the proposed polynomial
activation MLP neural networks are more efficient in
initializing the weights than the MLP neural networks
with sigmoidal activation. The back propagation
algorithm for the proposed network is derived. The
advantages of MLP neural networks with sigmoidal
activation are discussed. A method to convert the
polynomial activation MLP neural network to sigmoid
activation MLP neural network unit by unit is discussed
and the conversion equations are derived. Examples are
given which verify the advantages of the polynomial
mapping approach.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  3411 </NUMBER>
<ORDER>   AAI1374871 </ORDER>
<TITLE> RECURSIVE BACKPROPAGATION ALGORITHM APPLIED TO A GLOBALLY RECURRENT NEURAL NETWORK </TITLE>
<AUTHOR> DIONISI, STEVEN MICHAEL </AUTHOR>
<YEAR> 1995 </YEAR>
<INSTITUTION> UNIVERSITY OF NEVADA, LAS VEGAS; 0506 </INSTITUTION>
<DESCRIPTORS> ENGINEERING, ELECTRONICS AND ELECTRICAL; COMPUTER SCIENCE; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> NIL </ADVISER>
<CLASSIFICATIONS> NIL </CLASSIFICATIONS>
<ABSTRACT>
In general, recursive neural networks can yield a
smaller structure than purely feedforward neural network
in the same way infinite impulse response (IIR) filters
can replace longer finite impulse response (FIR)
filters. This thesis presents a new adaptive algorithm
that trains recursive neural networks. This algorithm is
based on least mean square (LMS) algorithms designed for
other adaptive architectures. This algorithm overcomes
several of the limitations of current recursive neural
network algorithms, such as epoch training and the
requirement for large amounts of memory storage.
To demonstrate this new algorithm, adaptive
architectures constructed with a recursive neural
network and trained with the new algorithm are applied
to the four adaptive systems and the results are
compared to adaptive systems constructed with other
adaptive filters. In these examples, this new algorithm
shows the ability to perform linear and nonlinear
transformations and, in some cases, significantly
outperforms the other adaptive filters. This thesis also
discusses the possible avenues for future exploration of
adaptive systems constructed of recursive neural
networks.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  3412 </NUMBER>
<ORDER>   AAI1374734 </ORDER>
<TITLE> DEVELOPMENT OF AN INTERACTIVE COMPUTER-BASED MULTIMEDIA DESIGN MANUAL FOR WATER RESOURCE APPLICATIONS </TITLE>
<AUTHOR> ROBINSON, BRENT C. </AUTHOR>
<YEAR> 1995 </YEAR>
<INSTITUTION> UTAH STATE UNIVERSITY; 0241 </INSTITUTION>
<DESCRIPTORS> ENGINEERING, CIVIL; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> WILLIAM J. GRENNEY </ADVISER>
<CLASSIFICATIONS> NIL </CLASSIFICATIONS>
<ABSTRACT>
An important advancement in computer technology has been
the ability to incorporate hypertext and multimedia
features into microcomputer-based applications. This
capability opens new opportunities to transfer technical
information into an easily accessible medium. A rule-
based decision support system (DSS) was developed to
interface with and integrate the functionality of
multiple independent modules including hypertext and
multimedia. This DSS was implemented on microcomputers
operating under Microsoft Windows 3.1.
Two engineering design manuals were used as the test bed
for development. DSSs were developed to implement the
procedures outlined in these manuals. Over 200 pages of
text were converted to hypertext topics and integrated
with the DSS. Tables, charts, and nomographs were
replaced with numerical equation solvers. The
application was also enhanced with visual images and
video and audio clips.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  3413 </NUMBER>
<ORDER>   AAI1374731 </ORDER>
<TITLE> SPEAKER-INDEPENDENT PHONEME RECOGNITION USING INTEGRATED RECURRENT NEURAL NETWORKS </TITLE>
<AUTHOR> REID, CHARLES VERN </AUTHOR>
<YEAR> 1995 </YEAR>
<INSTITUTION> UTAH STATE UNIVERSITY; 0241 </INSTITUTION>
<DESCRIPTORS> COMPUTER SCIENCE; ENGINEERING, ELECTRONICS AND ELECTRICAL; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> SCOTT CANNON </ADVISER>
<CLASSIFICATIONS> NIL </CLASSIFICATIONS>
<ABSTRACT>
A new pattern recognition methodology effectively
performs phoneme recognition on continuous multiple
speaker utterances. The methodology is based on the
integration of many recurrent neural networks having one-
to-one assignments to individual phonemes. This system
provides a simple and effective way to manage the unique
characteristics of each phoneme.
The phoneme recognition system's potential capabilities
are demonstrated by outperforming two methods documented
at Carnegie Mellon University (a premier research source
in speech recognition) for five individual vowel
phonemes and in the sonorant/nasal phoneme class.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  3414 </NUMBER>
<ORDER>   AAI1374698 </ORDER>
<TITLE> TIME SERIES PREDICTION USING NEURAL NETWORKS </TITLE>
<AUTHOR> AGNIHOTRI, VIKAS VASANT </AUTHOR>
<YEAR> 1995 </YEAR>
<INSTITUTION> UTAH STATE UNIVERSITY; 0241 </INSTITUTION>
<DESCRIPTORS> COMPUTER SCIENCE; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> NICHOLAS FLANN </ADVISER>
<CLASSIFICATIONS> NIL </CLASSIFICATIONS>
<ABSTRACT>
A time series is a sequence of values generated by a
mathematical equation. Successive values of the series
are obtained by substituting appropriate values for
time, which is the independent variable.
Time series prediction is the problem of determining the
future values of a time series given the past values and
the interval at which they were gathered. It essentially
involves finding the mathematical equation/model that
generated the time series and applying it to "unseen
data" to predict the value at some future time.
Time series prediction is an area that can offer
tremendous benefits if it is successful. Traditional
time series prediction methods using statistics and
long, cumbersome equations have been found to be too
unwieldy to use in real-life situations where we have a
large amount of input data available. Neural networks
show the promise of offering an elegant solution that
does not require as much expertise and judgment on the
part of the investigator, although some expertise is
required to design and train the neural network. Weather
prediction is an area where successful time series
prediction could give a lot of benefits. The weather or
climate in any region affects a wide variety of
activities in that area. Communications, farming, and so
forth are just a few of these activities. This study
looks at different ways in which neural networks can be
used for time series prediction applied to weather
prediction.
The results indicate that (1) recurrent neural networks
perform better than standard feed-forward
backpropagation neural networks; (2) providing
geographical contextual information to the neural
network improves the quality of prediction of the neural
network; and (3) providing additional information about
other climatically significant events in the region does
not have a significant impact on the quality of weather
prediction.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  3415 </NUMBER>
<ORDER>   AAG9625274 </ORDER>
<TITLE> INDUCTION AS KNOWLEDGE INTEGRATION </TITLE>
<AUTHOR> SMITH, BENJAMIN DOUGLAS </AUTHOR>
<YEAR> 1995 </YEAR>
<INSTITUTION> UNIVERSITY OF SOUTHERN CALIFORNIA; 0208 </INSTITUTION>
<DESCRIPTORS> COMPUTER SCIENCE; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> PAUL S. ROSENBLOOM </ADVISER>
<CLASSIFICATIONS> MACHINE LEARNING, ARTIFICIAL INTELLIGENCE </CLASSIFICATIONS>
<ABSTRACT>
Accuracy and efficiency are the two main evaluation
criteria for induction algorithms. One of the most
powerful ways to improve performance along these
dimensions is by integrating additional knowledge into
the induction process. However, integrating knowledge
that differs significantly from the knowledge already
used by the algorithm usually requires rewriting the
algorithm.
This dissertation presents KII, a Knowledge Integration
framework for Induction that provides a straightforward
method for integrating knowledge into induction, and
provides new insights into the effects of knowledge on
the accuracy and complexity of induction. The idea
behind KII is to express all knowledge uniformly as
constraints and preferences on hypotheses. Knowledge is
integrated by conjoining constraints and disjoining
preferences. A hypothesis is induced from the integrated
knowledge by finding a hypothesis consistent with all of
the constraints and maximally preferred by the
preferences.
Theoretically, just about any knowledge can be expressed
in this manner. In practice, the constraint and
preference languages determine both the knowledge that
can be expressed and the complexity of identifying a
consistent hypothesis. RS-KII, an instantiation of KII
based on a very expressive set representation, is
described. RS-KII can utilize the knowledge of at least
two disparate induction algorithms--AQ-11 and CEA
("version spaces")--in addition to knowledge that
neither algorithm can utilize. It seems likely that RS-
KII can utilize knowledge from other induction
algorithms, as well as novel kinds of knowledge, but
this is left for future work. RS-KII's complexity is
comparable to these algorithms when using only the
knowledge of a given algorithm, and in some cases RS-
KII's complexity is dramatically superior. KII also
provides new insights into the effects of knowledge on
induction that are used to derive classes of knowledge
for which induction is not computable.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  3416 </NUMBER>
<ORDER>   AAI1374691 </ORDER>
<TITLE> COMPUTER CONSULTANT FOR OPTIMIZING GERIATRIC PATIENT MEDICATION PLAN FOR MULTIPLE CONDITIONS: A MEDICAL EXPERT SYSTEM </TITLE>
<AUTHOR> KOCUR, JOHN, JR. </AUTHOR>
<YEAR> 1995 </YEAR>
<INSTITUTION> EAST TEXAS STATE UNIVERSITY; 0103 </INSTITUTION>
<DESCRIPTORS> COMPUTER SCIENCE; HEALTH SCIENCES, PHARMACY; ENGINEERING, BIOMEDICAL; GERONTOLOGY; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> SANG SUH </ADVISER>
<CLASSIFICATIONS> NIL </CLASSIFICATIONS>
<ABSTRACT>
Since physicians will use no medical expert system that
is not fast, friendly, convenient, and easy to use,
scores of demonstrably-skilled existing systems remain
clinically unemployed.
Gerirex prescribes for the geriatric patient with
multiple conditions. Accenting usability, a shell was
chosen for flexibility, power, and graphics. The user
interface minimizes typing. Backward-chaining provides
normal consultation flow and explanation facilities.
Matrix representation of drug knowledge provides speed.
Rich file access adds interoperability with other
systems.
Gerirex accepts the user's diagnosis, so uncertainty was
not a concern, but the shell's uncertainty handler was
employed to rank condition severities for customizing
treatment plans.
Gerirex performs at the near-expert level, handling up
to six conditions. Consultations are fast and easy, even
for novices. Drug data maintenance requires no
programming skills, and planned meta-rules will add self-
maintenance, incorporating drug data from CD-ROM
sources.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  3417 </NUMBER>
<ORDER>   AAI1374654 </ORDER>
<TITLE> FUZZY EXPERT SYSTEM IN HOUSE PRICE ESTIMATION </TITLE>
<AUTHOR> ARMSTRONG, HAIYAN WANG </AUTHOR>
<YEAR> 1995 </YEAR>
<INSTITUTION> UNIVERSITY OF NEVADA, RENO; 0139 </INSTITUTION>
<DESCRIPTORS> COMPUTER SCIENCE; ECONOMICS, GENERAL; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> CARL G. LOONEY </ADVISER>
<CLASSIFICATIONS> NIL </CLASSIFICATIONS>
<ABSTRACT>
This paper designs and develops a fuzzy expert system to
estimate house prices in the current market conditions.
It emulates the analysis process of real estate experts.
There are two types of data included in the knowledge
base: fixed value data and adjustable value data. The
fixed value data includes the costs of building the
house. The adjustable value data refers to the social,
economic, governmental and environmental forces. Forward
chaining reasoning is used for firing binary and fuzzy
rules to reach the conclusion. A fuzzy controller is
used to analyze the effects of each adjustable value
data on the house price. The fuzzy controller combines
the rule-based formalism with numerical factors so that
the expert system can interface with the continuous
outside world smoothly.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  3418 </NUMBER>
<ORDER>   AAI1374635 </ORDER>
<TITLE> USING BACK PROPAGATION NEURAL NETWORKS FOR PREDICTION OF INDIVIDUAL CELL PERFORMANCE IN A LONG STRING LEAD-ACID PEAK SHAVING BATTERY </TITLE>
<AUTHOR> YOUNG, RICHARD E. </AUTHOR>
<YEAR> 1995 </YEAR>
<INSTITUTION> SAN JOSE STATE UNIVERSITY; 6265 </INSTITUTION>
<DESCRIPTORS> CHEMISTRY, ANALYTICAL; ENGINEERING, ELECTRONICS AND ELECTRICAL; COMPUTER SCIENCE; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> SAM PERONE </ADVISER>
<CLASSIFICATIONS> NIL </CLASSIFICATIONS>
<ABSTRACT>
Neural networks were explored for the first time to
predict the performance of individual cells in a large
lead-acid battery. A simple time based index of routine
maintenance events from a three year period were used as
inputs into the neural networks. Using the back
propagation algorithm, the neural networks were trained
to recognize three performance classes of cells (low,
medium, and high), as measured by their capacity. The
objective was to accurately identify the low and high
performing cells. The high performing cells could be
predicted with 100% accuracy with less than 9% false
positive identification of the poor performing cells.
Alternatively, the number of false positives could be
kept to less than 5% of the poor performing cells but
the high performing cells were predicted with 95%
accuracy. The low performing cells could be predicted
with 95.7% accuracy with no false positives due to high
performing cells.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  3419 </NUMBER>
<ORDER>   AAI1362492 </ORDER>
<TITLE> NEURAL NETWORKS FOR RECOGNITION OF IONOGRAM TRACES </TITLE>
<AUTHOR> GALKIN, IVAN A. </AUTHOR>
<YEAR> 1995 </YEAR>
<INSTITUTION> UNIVERSITY OF LOWELL; 0111 </INSTITUTION>
<DESCRIPTORS> PHYSICS, ATMOSPHERIC SCIENCE; ENGINEERING, ELECTRONICS AND ELECTRICAL; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> BODO W. REINISCH </ADVISER>
<CLASSIFICATIONS> NIL </CLASSIFICATIONS>
<ABSTRACT>
Modern pattern recognition techniques are applied to
achieve high quality automatic processing of Digisonde
ionograms. An artificial neural network (ANN) was found
to be a promising technique for ionospheric echo
tracing. Two different trace models, a segment model and
a modified rotor model, were tested to construct the
Hopfield ANN with the mean field theory (MFT) updating
scheme. Tests of the models against various ionospheric
data showed that the modified rotor model gives good
results where conventional tracing techniques have
difficulties. Use of the ANN made it possible to
implement a robust scheme of trace interpretation that
considers local trace inclination angles available after
ANN completes tracing. The interpretation scheme
features a new algorithm for F1 layer identification
that estimates an $alpha$-angle of trace in the vicinity
of the critical frequency foF1. First off-line tests
show excellent results suggesting implementing of the
new operational software package in the world-wide
Digisonde network.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  3420 </NUMBER>
<ORDER>   AAI1362220 </ORDER>
<TITLE> A PERFORMANCE-DRIVEN FUZZY ALGORITHM FOR PLACEMENT OF MACRO CELLS </TITLE>
<AUTHOR> MACKEY, CAROL A. </AUTHOR>
<YEAR> 1995 </YEAR>
<INSTITUTION> THE UNIVERSITY OF ARIZONA; 0009 </INSTITUTION>
<DESCRIPTORS> ENGINEERING, ELECTRONICS AND ELECTRICAL; COMPUTER SCIENCE; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> JO DALE CAROTHERS </ADVISER>
<CLASSIFICATIONS> NIL </CLASSIFICATIONS>
<ABSTRACT>
Macro cell placement is an integral part of VLSI design.
Existing placement techniques do not use a realistic
human-like intuitive process for making decisions and
therefore, lack the ability to make decisions based on
several factors at once. In this research a quad-
partitioning algorithm with a tabu search and a fuzzy
cost function is used for macro cell placement. This
approach partitions the design into small pieces that
can be easily placed. The algorithm is based on a method
which tries to reduce the path lengths and reduce the
number of edges which cross out of a partition. The
fuzzy cost function adds the human reasoning missing
from other algorithms. The algorithm allows I/O cells to
be preplaced or it can optimize their placement. The
results show that this algorithm produces higher quality
placements than other macro cell algorithms such as Lim,
Chee and Wu and Lin and Du.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  3421 </NUMBER>
<ORDER>   AAI1362157 </ORDER>
<TITLE> A STRUCTURED VOCABULARY APPROACH TO FUZZY INFERENCE SYSTEMS </TITLE>
<AUTHOR> HACKERT, RICHARD DOUGLAS </AUTHOR>
<YEAR> 1995 </YEAR>
<INSTITUTION> STATE UNIVERSITY OF NEW YORK INSTITUTE OF TECHNOLOGY AT UTICA-ROME; 1026 </INSTITUTION>
<DESCRIPTORS> COMPUTER SCIENCE; ENGINEERING, SYSTEM SCIENCE; INFORMATION SCIENCE; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> ROGER CAVALLO </ADVISER>
<CLASSIFICATIONS> NIL </CLASSIFICATIONS>
<ABSTRACT>
A structured vocabulary approach to developing inference
systems is presented. While people often communicate
using vague terminology, they do not necessarily
consciously evaluate the fuzziness inherent within any
such terms. In everyday conversation, for the sake of
ease of communication, people will glaze over the
complications of interpreting fuzziness and view vague
concepts as linear and discrete. This paper explains the
notion of a Linguistic Space that attempts to parallel
the casual manner in which people normally view fuzzy
concepts.
A fuzzy inference system program, INFSYS, is developed
that accepts this human interpretation as input and
generates the necessary fuzzy constructs internally. A
program structure is devised for rule computations based
on Zadeh's Compositional Rule of Inference. Examples
show that this method provides an adequate means for
testing disparate combinations of operators and how
changes in them affect system output.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  3422 </NUMBER>
<ORDER>   AAI1362156 </ORDER>
<TITLE> AN INTELLIGENT HIGH PERFORMANCE PACKET SWITCHING NETWORK </TITLE>
<AUTHOR> BANERJEE, INDRAJIT </AUTHOR>
<YEAR> 1995 </YEAR>
<INSTITUTION> STATE UNIVERSITY OF NEW YORK INSTITUTE OF TECHNOLOGY AT UTICA-ROME; 1026 </INSTITUTION>
<DESCRIPTORS> COMPUTER SCIENCE; INFORMATION SCIENCE; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> SAM SENGUPTA </ADVISER>
<CLASSIFICATIONS> NIL </CLASSIFICATIONS>
<ABSTRACT>
In this thesis, a model for a workable network having a
hybrid design comprising two Ethernets and single Token
Ring components connected by an intelligent hub is
proposed. Simulation studies show that the proposed
model's performance is better than an individual
Ethernet or a Token Ring system, and even better than
the hybrid over one Ethernet and Token Ring (1 + 1
solution). What we conjecture here is that a (2 + 1)
solution, i.e., an integrated two Ethernets and one
Token Ring may prove to be the candidate architecture
that we seek for networking in a LAN environment with a
wide range of traffic density distribution. This is
particularly needed with large variance traffic
densities.
This thesis further comments on the probable use of the
proposed (2 + 1) Hybrid model over any existing,
standard fast medium.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  3423 </NUMBER>
<ORDER>   AAI1362033 </ORDER>
<TITLE> A K/N GATE DIGITAL NEURAL PROCESSOR </TITLE>
<AUTHOR> ORENSTEIN, BRUCE R. </AUTHOR>
<YEAR> 1995 </YEAR>
<INSTITUTION> CALIFORNIA STATE UNIVERSITY, FULLERTON; 6060 </INSTITUTION>
<DESCRIPTORS> ENGINEERING, ELECTRONICS AND ELECTRICAL; COMPUTER SCIENCE; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> NIL </ADVISER>
<CLASSIFICATIONS> NIL </CLASSIFICATIONS>
<ABSTRACT>
This thesis consisted of the design and test of a K/N
Gate Digital Neural Processor System. The primary
emphasis of this thesis was on the design of a K/N Gate
Digital Neural Parallel Processor that was developed
using ORCAD 4.1 CAE and XILINX XDM 2.6 software, and was
implemented with a XILINX XC4005PG156-5 FPGA. The system
was tested by programming it to recognize ten characters
0-9 with a maximum of 40 percent noise. Each character
with no noise, 10 percent random noise, 20 percent
random noise, and 30 percent random noise was provided
to the system and was correctly identified with little
or no ambiguity. Although there was ambiguity the system
correctly identified each character when it was
corrupted with 40 percent random noise.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  3424 </NUMBER>
<ORDER>   AAI1361869 </ORDER>
<TITLE> DESIGN AND DEVELOPMENT OF A FOUR DEGREE-OF-FREEDOM ROBOT ARM AND MULTI-NEURAL NETWORK INTELLIGENT PATH-PLANNING SUBSYSTEM </TITLE>
<AUTHOR> JOHNSON, JAMES PHILLIP </AUTHOR>
<YEAR> 1995 </YEAR>
<INSTITUTION> TEXAS A&M UNIVERSITY-KINGSVILLE; 1187 </INSTITUTION>
<DESCRIPTORS> ENGINEERING, ELECTRONICS AND ELECTRICAL; ENGINEERING, MECHANICAL; COMPUTER SCIENCE; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> RAJAB CHALLOO </ADVISER>
<CLASSIFICATIONS> NIL </CLASSIFICATIONS>
<ABSTRACT>
This thesis concerns a novel path-planning subsystem
applied in the intelligent control of a four degree of
freedom robot arm. The "intelligent control" is a multi-
neural network based control program written in C. The
control algorithm uses two Adaptive Resonance Theory II
(ART2) neural network classifiers and a Bi-directional
Associative Memory System (BAM System). These neural
networks allow the arm to remember the position of
obstacles in its workspace, allowing the generation of
trajectories (around the obstacles) in future movements.
Success in this project is considered to have several
levels. Because the robot arm is being designed and
built as part of this project, the first level of
success is the completion of, and full dynamic control
of the robot arm. The second level of success is the
successful completion of the controlling program. This
includes the reliable operation of the ART2 and BAM
System neural networks. The final level of success is
the actual performance of the arm/intelligent
controlling program in mapping and avoiding obstacles in
the robot's work area. The controlling algorithm is
considered a 'subsystem' which could be used with other
navigational sensory and control subsystems in a variety
of applications. The idea of multiple subsystems
available in an overall application provides the
protection of back-up systems in case of primary control
system failure, or inability to detect obstacles in
certain situations. Information in this thesis includes
some neural network theory, path-planning in robotic
control/trajectory generation methods, dynamic control
system theory concerning the hardware and software used
in this system, this system's approach at providing
trajectory generation and obstacle avoidance, and
implementation results.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  3425 </NUMBER>
<ORDER>   AAI1361691 </ORDER>
<TITLE> DESIGN FOR ENVIRONMENT METRICS AND FUZZY LOGIC </TITLE>
<AUTHOR> REINHARDT, MICHAEL </AUTHOR>
<YEAR> 1995 </YEAR>
<INSTITUTION> UNIVERSITY OF LOWELL; 0111 </INSTITUTION>
<DESCRIPTORS> ENGINEERING, GENERAL; ARTIFICIAL INTELLIGENCE; ENVIRONMENTAL SCIENCES; ENERGY </DESCRIPTORS>
<ADVISER> JOHN DUFFY </ADVISER>
<CLASSIFICATIONS> NIL </CLASSIFICATIONS>
<ABSTRACT>
In response to the complexities of analyzing the life-
cycle environmental impacts of engineering design
decisions and accounting for uncertainties, fuzzy
decision making methods have been adapted for Design for
Environment (DFE).
Two methods using fuzzy logic have been adapted for the
DFE approach. First, Fuzzy Weighted Averaging shows a
simple approach for incorporating uncertainty into
decision making processes among several alternatives.
Second, Fuzzy Composite Programming provides an
additional multilevel structure to the problem of
determining the relative performance of alternatives and
relative importance of objectives.
For choosing among several alternatives which have fuzzy
differences in environmental impact a new method was
developed based on the z-test from classical statistics.
To illustrate the application of these decision making
tools, a case study of the design choice among battery
technologies for use in electric vehicles has been
presented. The fuzzy logic methods used to perform the
case study analysis have been coded in Matlab.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  3426 </NUMBER>
<ORDER>   AAG9624537 </ORDER>
<TITLE> SYSTEMIC SOFTWARE REUSE THROUGH ANALOGICAL REASONING </TITLE>
<AUTHOR> WHITEHURST, R. ALAN </AUTHOR>
<YEAR> 1995 </YEAR>
<INSTITUTION> UNIVERSITY OF ILLINOIS AT URBANA-CHAMPAIGN; 0090 </INSTITUTION>
<DESCRIPTORS> COMPUTER SCIENCE; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> MEHDI T. HARANDI </ADVISER>
<CLASSIFICATIONS> NIL </CLASSIFICATIONS>
<ABSTRACT>
This research focuses on analogical reasoning as applied
to the problem of software reuse at the level of the
system architecture. The resulting methodology may be
thought of as a hybrid approach to software reuse, as it
combines a compositional developmental strategy with
synthesis of role-based behaviors. The components of
this research include: a methodology based upon an
extension of object-oriented design principles that
promotes decoupling of object representations and
provides mechanisms for composing systems from abstract
objects, relations, and frameworks; techniques for
measuring the degree that two systems are analogically
correlated; and automated support for the application of
analogically derived mappings in the translation of
system concepts from source to target domains.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  3427 </NUMBER>
<ORDER>   AAI0665740 </ORDER>
<TITLE> MULTISENSOR FUZZY STABILIZATION CONTROLLER FOR ILL- DEFINED PROCESSES, WITH REFERENCE TO COAL MILLING </TITLE>
<AUTHOR> VAN TONDER, JOHANNES CASPARUS </AUTHOR>
<YEAR> 1995 </YEAR>
<INSTITUTION> UNIVERSITY OF PRETORIA (SOUTH AFRICA); 6004 </INSTITUTION>
<DESCRIPTORS> ENGINEERING, ELECTRONICS AND ELECTRICAL; ENGINEERING, MINING; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> J. J. KRUGER </ADVISER>
<CLASSIFICATIONS> NIL </CLASSIFICATIONS>
<ABSTRACT>
A control methodology is developed for an automatic
stabilisation controller for an ill-defined process
currently under human operator control. The process
outputs are not directly measurable; an example is the
process of coal milling using a horizontal ball tube
mill.
A control structure that consists of an observer
(information extractor), a fuzzy identifier with
multisensor fusion and integration capabilities, a fuzzy
estimator, a control signal generator and actuators, is
proposed.
A general class of processes is defined with the same
properties as the coal milling process. A pilot plant to
the milling process is chosen and a controller is
designed for the pilot plant using the proposed design
methodology and controller structure. The validity of
the design methodology and controller structure for the
milling process is discussed and a projection is made on
the implementability of the controller on any process
belonging to the general class of processes.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  3428 </NUMBER>
<ORDER>   AAI0665655 </ORDER>
<TITLE> BEST SIZE FOR A NEURAL NETWORK </TITLE>
<AUTHOR> GONCALVES, DUARTE PAULO DA SILVA </AUTHOR>
<YEAR> 1995 </YEAR>
<INSTITUTION> UNIVERSITY OF PRETORIA (SOUTH AFRICA); 6004 </INSTITUTION>
<DESCRIPTORS> ENGINEERING, ELECTRONICS AND ELECTRICAL; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> ETIENNE BARNARD </ADVISER>
<CLASSIFICATIONS> NIL </CLASSIFICATIONS>
<ABSTRACT>
In applying a neural network to a problem, one needs to
consider how many hidden neurons to use for best
generalization. To measure the generalization
performance of these networks, we consider non-
parametric estimators like bootstrap and cross
validation is presented, which omits a block of samples
as opposed to just one sample. We model the variance,
bias and computational complexity of this estimator.
These models are evaluated against simulation results.
The performance of block cross validation is compared
experimentally with that of bootstrap.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  3429 </NUMBER>
<ORDER>   AAIMM97031 </ORDER>
<TITLE> EVALUATION DE L'APPLICABILITE DES RESEAUX NEURONAUX A LA VERIFICATION AUTOMATIQUE DES SIGNATURES MANUSCRITES </TITLE>
<AUTHOR> GODBOUT, MARIO </AUTHOR>
<YEAR> 1995 </YEAR>
<INSTITUTION> UNIVERSITE DE MONTREAL (CANADA); 0992 </INSTITUTION>
<DESCRIPTORS> ENGINEERING, ELECTRONICS AND ELECTRICAL; ARTIFICIAL INTELLIGENCE; COMPUTER SCIENCE </DESCRIPTORS>
<ADVISER> ROBERT SABOURIN </ADVISER>
<CLASSIFICATIONS> FRENCH TEXT </CLASSIFICATIONS>
<ABSTRACT>
Le facteur de forme (fonction de densite des dannees
directionnelles de l'image de la signature) et les
pretraitements font l'objet d'une etude intensive pour
permettre d'obtenir la meilleure performance en
verification. 152 pretraitements sont verifies dans
cette experience. En introduisant un filtre a
integration sur les donnees originales, le taux d'erreur
totale diminue de plus de 54%.
Puisqu'aucune regle ne precise la facon dont le reseau
doit terminer son entrai nement, un critere d'arret base
sur le nombre d'iterations et le taux d'erreur est
propose afin de mieux controler cet entrai nement. Selon
les experiences effectuees, 19% des reseaux ont termine
leur entrai nement avec un taux d'erreur totale
(memorisation et generalisation) de 0%. Ce critere
d'arret permet egalement de diminuer la probabilite
d'obtenir un sur-entrai nement.
Une experience utilisant exactement les memes ensembles
de donnees permet de comparer la performance de trois
classificateurs (reseau de neurones, la methode des plus
proches voisins et classificateur a distance minimale
avec seuil). Le reseau de neurones se suite entre la
methode des plus proches voisins (la meilleure) et le
classificateur a distance minimale avec seuil.
L'amelioration du classificateur de type neuronal est
egalement etudiee en proposant l'introduction d'une
notion de rejet et en optimisant une partie de la
topologie du reseau de neurones. Des experiences
permettent d'etablir des conclusions fiables sur cette
amelioration et les analyses statistiques montrent que
le reseau avec 8 neurones dans la couche cachee obtient
la meilleur performance. Les resultats demontrent
egalement que l'introduction du rejet et que
l'optimisation de l'architecture du reseau permettent de
reduire le taux d'erreur totale de plus de 50%. Le prix
a payer pour cette diminution de l'erreur totale est un
taux de rejet qui se situe a 4,51%. (Abstract shortened
by UMI.)
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  3430 </NUMBER>
<ORDER>   AAI9536314 </ORDER>
<TITLE> APPLICATION OF ARTIFICIAL NEURAL NETWORKS AND CHAOS IN CHEMICAL PROCESSES  </TITLE>
<AUTHOR> OTAWARA, KENTARO </AUTHOR>
<YEAR> 1995 </YEAR>
<INSTITUTION> KANSAS STATE UNIVERSITY; 0100 </INSTITUTION>
<DESCRIPTORS> ENGINEERING, CHEMICAL; PHYSICS, GENERAL; COMPUTER SCIENCE; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> L. T. FAN </ADVISER>
<CLASSIFICATIONS> FUZZY EXPERT SYSTEMS, LYAPUNOV EXPONENTS </CLASSIFICATIONS>
<ABSTRACT>
An artificial neural network (ANN) and chaos, conceived
and developed independently, are beginning to play
essential roles in chemical engineering. Nonetheless,
the ANN possesses an appreciable number of deficiencies
that need be remedied, and the capability of the ANN to
explore and tame chaos or an irregularly behaving system
is yet to be fully realized. The present dissertation
attempts to make substantial progress toward such ends.
The problem of controlling the temperature of an
industrial reactor carrying out semibatch polymerization
has been solved by an innovative adaptive hybrid control
system comprising an ANN and fuzzy expert system (FES)
complemented by two supervisory ANN's. The system
enhances the strength and compensates for the weaknesses
of both the ANN and FES.
The system, named dual ANN (DANN), has been proposed for
characterizing the nonlinear nature of chaotic time-
series data. Its capability to approximate the behavior
of a chaotic system has been found to far exceed that of
a conventional ANN.
A novel approach has been devised for training an ANN
through the modified interactive training (MIT) mode.
This mode of training has been demonstrated to
substantially outperform a conventional interactive
training (CIT) mode.
A method has been established for synchronizing chaos by
resorting to an ANN. This method is capable of causing
to be coherent the trajectories of systems whose
deterministic governing equations are insufficiently
known. This requires training the ANN with a time series
and a common driving signal or signals. Examples are
given for chaos generated by difference as well as
differential equations.
An alternative to the OGY method has been proposed for
controlling chaos; it meticulously perturbs an
accessible parameter of the chaotic system. A single,
highly precise ANN suffices to render stable any of an
infinite number of unstable periodic orbits embedded in
a chaotic or strange attractor.
A method for estimating sub-Lyapunov exponents or
conditional Lyapunov exponents is presented; it has been
developed by exploiting the learning capability of an
ANN. For some chaotic systems, the sub-Lyapunov
exponents determined by the method are in good accord
with the theoretical values.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  3431 </NUMBER>
<ORDER>   AAI9536132 </ORDER>
<TITLE> ON-LINE APPROXIMATOR AND CONTROLLER FOR UNKNOWN NONLINEAR SYSTEM VIA FUZZY LOGIC </TITLE>
<AUTHOR> YU, IN HYEOB </AUTHOR>
<YEAR> 1995 </YEAR>
<INSTITUTION> THE UNIVERSITY OF TEXAS AT ARLINGTON; 2502 </INSTITUTION>
<DESCRIPTORS> ENGINEERING, ELECTRONICS AND ELECTRICAL; ENGINEERING, MECHANICAL; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> KAI LIU </ADVISER>
<CLASSIFICATIONS> NIL </CLASSIFICATIONS>
<ABSTRACT>
A method of deriving a fuzzy logic-based linear model is
proposed for approximating nonlinear dynamical systems.
The nonlinear dynamical systems under consideration are
assumed to be unknown. The only information needed for
the unknown systems is that the nonlinear systems shall
be linearizable and the order of the systems is
available. It is the proven property of a fuzzy logic
system that it can approximate nonlinear systems with
any desired degree of accuracy. The basic structure of
fuzzy rule in the fuzzy logic system constructed in this
method is a set of linear models. The set of linear
models is tuned by an updating law in the fuzzy logic
system. The updating law is derived for stabilizing the
error between the fuzzy model and the nonlinear
dynamical system. The method of designing the fuzzy
logic system is considered in both cases that all state
variables of the unknown nonlinear system are measurable
and that only the output of the system is measurable.
An indirect adaptive fuzzy logic control system is
proposed for regulating unknown nonlinear dynamical
systems. The nonlinear system to be regulated is assumed
to be unknown, except for the order of the system.
Instead of directly regulating the nonlinear system, the
original unknown nonlinear system is first approximated
by a set of linear fuzzy logic-based models, then a set
of state-feedback regulators is designed, one for each
fuzzy linear model. These regulators measure the states
of the approximator, calculate the feedback gain
matrices by solving algebraic Riccati equations on-line,
and infer control signals through the centroid
defuzzification process. Simulation studies show that
the proposed fuzzy logic control system can effectively
regulate the states of unknown nonlinear dynamical
systems, either stable or unstable, to zero. Its
performance is better than a conventional adaptive
controller even though it knows nothing about the
structure and parameters of the nonlinear system to be
controlled.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  3432 </NUMBER>
<ORDER>   AAI9536128 </ORDER>
<TITLE> INTELLIGENT CONTROL OF FLEXIBLE/NONLINEAR SYSTEMS </TITLE>
<AUTHOR> VANDEGRIFT, MARK WILLIAM </AUTHOR>
<YEAR> 1995 </YEAR>
<INSTITUTION> THE UNIVERSITY OF TEXAS AT ARLINGTON; 2502 </INSTITUTION>
<DESCRIPTORS> ENGINEERING, MECHANICAL; ENGINEERING, SYSTEM SCIENCE; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> FRANK L. LEWIS </ADVISER>
<CLASSIFICATIONS> ROBOTICS, FLEXIBLE LINK </CLASSIFICATIONS>
<ABSTRACT>
The dissertation focused on two topics: control of
flexible-link robotic systems with known nonlinear rigid
and known distributed flexible dynamics and intelligent
control of flexible-link robotic systems and a class of
nonlinear systems both having partially unknown
dynamics.
For the case of flexible-link robotic systems with known
dynamics, an improved reduced-order (i.e. modified
assumed-mode model) is derived that does not simply
truncate high-order modes, but incorporates quasi-steady
state information about the neglected modes.
Experimental results are given for the above model.
Further, a nonlinear tracking controller for link-tip
positions and velocities of a multi-link flexible robot
arm is designed such that it gives guaranteed
performance. First, a feedback linearization is
performed with respect to the link tip position. Then,
relaxing the tracking requirement allows the application
of singular perturbation theory so that a boundary layer
correction term (fast control) can be derived and used
to stabilize the internal vibratory dynamics.
The intelligent control applications and theory
addressed in this work are neural and fuzzy systems.
Neural-network and fuzzy-logic systems are very powerful
control tools because they allow model-free closed-loop
control of complex nonlinear systems. A problem is that
for said systems it is difficult to obtain stability
theorems without a plant model. That is, generally the
use of ad hoc controller structures results in the
inability to guarantee adequate performance in terms of
small tracking error and bounded NN weights. In this
work, using both a neural network and singular
perturbation theory, a tracking controller is designed
for a partially known flexible-link robot arm. Here, a
closed-loop control stabilizes the internal dynamics of
the flexible arm because we choose a physically
meaningful modified output, the slow portion of the link-
tip motions. The final contribution is an adaptive fuzzy
logic controller that uses basis vectors based on the
fuzzy system to form a feedback controller that achieves
tracking control of an entire class nonlinear systems
with no plant model. Stability is proven and a
systematic repeatable design algorithm is given for this
fuzzy logic controller.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  3433 </NUMBER>
<ORDER>   AAI9536105 </ORDER>
<TITLE> BAYESIAN GUIDED DIAGNOSIS OF SOFTWARE FAILURES </TITLE>
<AUTHOR> BURNELL, LISA JOHANNA </AUTHOR>
<YEAR> 1995 </YEAR>
<INSTITUTION> THE UNIVERSITY OF TEXAS AT ARLINGTON; 2502 </INSTITUTION>
<DESCRIPTORS> COMPUTER SCIENCE; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> KAREN A. HARBISON </ADVISER>
<CLASSIFICATIONS> DEBUGGING, ARTIFICIAL INTELLIGENCE </CLASSIFICATIONS>
<ABSTRACT>
There is strong motivation for developing methodologies
that support modifying and maintaining legacy software.
We present a new approach, Bayesian-guided diagnosis, to
diagnose software failures caused by errors in the
program logic. Bayesian-guided diagnosis adopts the
premise that, realistically, perfect and complete
knowledge is rarely available, and even when it is, the
resources required to collect or generate it are often
too costly. As the primary case study, we examine in
detail the problem of algorithmic program debugging and
the DAACS (dump analysis and consulting system)
prototype. Demonstrating the generality of the system,
we also show other applications of the approach, most
notably to debugging AI-based planning systems.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  3434 </NUMBER>
<ORDER>   AAI9535859 </ORDER>
<TITLE> A COMPARISON OF MACHINE LEARNING SYSTEMS FOR MEDICAL CLASSIFICATION  </TITLE>
<AUTHOR> EISENSTEIN, ERIC L. </AUTHOR>
<YEAR> 1995 </YEAR>
<INSTITUTION> CLEVELAND STATE UNIVERSITY; 0466 </INSTITUTION>
<DESCRIPTORS> COMPUTER SCIENCE; ENGINEERING, BIOMEDICAL; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> FARROKH ALEMI </ADVISER>
<CLASSIFICATIONS> BAYESIAN LEARNING, NEURAL NETWORKS </CLASSIFICATIONS>
<ABSTRACT>
Logistic regression has traditionally been used to model
medical classification problems. However, recent studies
using artificial neural networks (ANN) and Bayesian
learning systems have reported accuracy levels which
exceed those previously reported for logistic regression
models. This dissertation investigated the ways in which
variations in training data set characteristics and
model design impacted the relative accuracies of
logistic regression, ANN and Bayesian learning system
models. The training data set consisted of myocardial
infarction patients admitted to twelve hospitals and the
outcome category was patient discharge status (alive or
dead). The data set characteristics investigated were:
size of the training sample (100 and 600 cases), number
of attributes in models (3 and 11), attribute selection
method (informativeness or rareness), and whether
missing data was allowed (yes or no). The results
demonstrated that all three model groups experienced
some problems in recognizing and modeling rare
attributes. In addition, logistic regression and ANN
models were less accurate than Bayesian learning system
models when data was missing. Overall, Bayesian learning
systems equalled or exceeded the performance of the
other two model groups in all situations tested.
Therefore, they are a viable alternative to logistic
regression and ANNs for modeling medical classification
problems and should be investigated further.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  3435 </NUMBER>
<ORDER>   AAI9535841 </ORDER>
<TITLE> A HYBRID CHIP SET ARCHITECTURE FOR ARTIFICIAL NEURAL NETWORK SYSTEMS WITH ON-CHIP LEARNING AND REFRESHING </TITLE>
<AUTHOR> ALHALABI, BASSEM ABDO </AUTHOR>
<YEAR> 1995 </YEAR>
<INSTITUTION> UNIVERSITY OF SOUTHWESTERN LOUISIANA; 0233 </INSTITUTION>
<DESCRIPTORS> ENGINEERING, ELECTRONICS AND ELECTRICAL; COMPUTER SCIENCE; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> MAGDY A. BAYOUMI </ADVISER>
<CLASSIFICATIONS> NIL </CLASSIFICATIONS>
<ABSTRACT>
Artificial neural networks have demonstrated an
unparalleled potential for tackling nonlinear
applications such as acoustics, linguistics, vision,
control, optimization, security, financial, medical,
industrial, and consumer products. This magnificent
processing power is manifested from the attempt to
emulate the brain structure which possesses a high
degree of connectivity and parallelism. The gap between
what is needed and what is accomplished is solely due to
the biological spatio-temporal parallelism which is
entirely or partially lost in the digital machines
because of their inherent sequential nature. Moreover,
in spite of the tremendous contributions in analog
neural paradigm offering smaller components and
consequently higher parallelism, only few have addressed
complete neural systems especially with on-chip
learning. Furthermore, they all lack either scalability,
direct neural I/O ports, on-chip dynamic learning, fault-
tolerance capabilities, data conversion, full
parallelism or any combination of the above.
In this research, we developed a new complete system-
level chip-set open architecture for feed-forward model
with full connectivity and back-propagation learning.
The system is based on two distinct chips, SynChip and
NeuChip which may be cascaded to form networks matching
any given application. The projected performance is
10,240 MCPS-MCUPS per SynChip and linearly grows
thereafter. We devised a new embedded/distributed
addressing technique which made the system self-
contained. It also enhanced the system scalability as it
allows multiple-chip enabling. Each SynChip has 32
$times$ 32 = 1024 analog synapses, SynMod, and a local
host-independent refreshing mechanism. Each NeuChip has
32 analog neuron, NeuMod, with special parallel learning
hardware. The SynMod and NeuMod modules are designed
with all-analog technology which enabled us to
incorporate on-chip dynamic learning and maintain high
degree of scalability, the two main characteristics
which could not be found together in other systems.
Furthermore, interfacing to the outside world is made
universal as to accommodate virtually any digital or
analog host systems via direct I/O ports. Each NeuChip
supports 32-analog and 128-digital direct I/O lines
which can be clustered into any word-length format to
further enhance the system scalability. Also, the system
may operate in continuous, step-discrete, or burst-
discrete modes. Other features such as fault-tolerant
capabilities, selective chip auditing, and a stand-by
mode are provided.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  3436 </NUMBER>
<ORDER>   AAI9535646 </ORDER>
<TITLE> EXPERIMENTS IN THE INTEGRATION AND CONTROL OF AN INTELLIGENT MANUFACTURING WORKCELL </TITLE>
<AUTHOR> PARDO-CASTELLOTE, GERARDO </AUTHOR>
<YEAR> 1995 </YEAR>
<INSTITUTION> STANFORD UNIVERSITY; 0212 </INSTITUTION>
<DESCRIPTORS> ENGINEERING, ELECTRONICS AND ELECTRICAL; ENGINEERING, MECHANICAL; COMPUTER SCIENCE; ENGINEERING, INDUSTRIAL; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> ROBERT H. CANNON, JR. </ADVISER>
<CLASSIFICATIONS> ROBOTICS </CLASSIFICATIONS>
<ABSTRACT>
This thesis comprises the experimental development of an
intelligent, dual-arm robotic workcell. The system
combines a high-level graphical user interface, an on-
line motion planner, real-time vision, and an on-line
simulator to control a dual-arm robotic system from the
task level.
The graphical user interface provides for high-level
user direction of the task to be done. The motion
planner generates complete on-line plans to carry out
these directives, specifying both single and dual-armed
motion and manipulation. Combined with the robot control
and real-time vision, the system is capable of
performing object acquisition from a moving conveyor
belt as well as reacting to environmental changes on-
line.
The thesis covers in detail four main topics: (1) System
design and interfaces. The system is based on a novel
"interface-first" design technique. This technique
structures the complex command and data flow as
combinations of three fundamental robotic interface
components: the world-state interface, the robot-command
interface, and the task-level-direction interface. (2)
Network communication architecture. Complex distributed
robotic systems require very complex data flow. A
powerful new subscription-based, network-data-sharing
system, was developed (and is being commercialized) that
enables transparent connectivity. (3) Control system.
The architecture and design of the hierarchical control
system for the experimental dual-arm assembly workcell
is described. (4) Path time-parameterization. A fast
(linear-time, proximate-optimal) solution to the
fundamental problem of time-parameterization of robot
paths is presented.
The design was verified experimentally in a dual-arm
robotic workcell. Experimental results are presented
showing the system performing complex, multi-step tasks
autonomously, including dual-arm object acquisitions
from a moving conveyor, object motion among obstacles,
re-grasps, and hand-overs. All these tasks occur under
task-level human supervision.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  3437 </NUMBER>
<ORDER>   AAG9624496 </ORDER>
<TITLE> INTERPRETING IMAGES OF POLYHEDRAL OBJECTS IN THE PRESENCE OF UNCERTAINTY  </TITLE>
<AUTHOR> SHIMSHONI, ILAN MOSHE </AUTHOR>
<YEAR> 1995 </YEAR>
<INSTITUTION> UNIVERSITY OF ILLINOIS AT URBANA-CHAMPAIGN; 0090 </INSTITUTION>
<DESCRIPTORS> COMPUTER SCIENCE; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> JEAN PONCE </ADVISER>
<CLASSIFICATIONS> MACHINE VISION, SHAPE RECOGNITION </CLASSIFICATIONS>
<ABSTRACT>
This thesis addresses various problems in computer
vision which are related to the interpretation of images
of polyhedral objects with a special emphasis on the
effects of uncertainty. Its contributions span three
areas: we first present an approach to the recovery of
3D shape from a single image using line-drawing analysis
and complex reflectance models. The algorithm deals
explicitly with uncertainty in vertex position. We then
propose an algorithm for computing the finite-resolution
aspect graph of polyhedral objects. For each region of
the aspect graph a representative finite-resolution
aspect is computed. Neighboring regions with identical
finite-resolution aspects are merged producing the
finite-resolution aspect graph. Finally, we develop a
probabilistic approach to object recognition. Match
hypotheses are ranked by the probability that they are
correct. For each hypothesis the pose of the object is
recovered and the region of the pose space compatible
with the image uncertainty is computed. Hypotheses which
match different features of the same model reinforce
each other when the corresponding uncertainty regions in
the pose space have a non-empty intersection. Sets of
consistent hypotheses are ranked by probability that
they are the correct interpretation of the features,
producing an ordering of the possible interpretations.
The three algorithms have been fully implemented and
examples are presented.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  3438 </NUMBER>
<ORDER>   AAI9535518 </ORDER>
<TITLE> SEMANTIC FEATURE EXTRACTION FROM TECHNICAL TEXTS WITH LIMITED HUMAN INTERVENTION </TITLE>
<AUTHOR> AGARWAL, RAJEEV </AUTHOR>
<YEAR> 1995 </YEAR>
<INSTITUTION> MISSISSIPPI STATE UNIVERSITY; 0132 </INSTITUTION>
<DESCRIPTORS> COMPUTER SCIENCE; LANGUAGE, LINGUISTICS; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> LOIS BOGGESS </ADVISER>
<CLASSIFICATIONS> NATURAL LANGUAGE PROCESSING, LEXICAL DISAMBIGUATION </CLASSIFICATIONS>
<ABSTRACT>
Natural Language Processing (NLP) and message
understanding systems often use semantic information in
order to perform lexical and syntactic disambiguation
and to assist them in "understanding" the text. Such
information is domain-specific in nature and hence
difficult to acquire in an automatic manner. This causes
a problem whenever an NLP system is moved from one
domain to another. Portability of an NLP system can be
improved if these semantic features can be acquired with
limited human intervention.
The semantic information needed by an NLP system may
take several different forms. This dissertation focuses
on two such semantic features--semantic classes present
in a given domain, and lexico-semantic patterns that
exist between content words in the domain. This document
discusses the techniques that are used to extract these
semantic features from a domain with limited human
intervention. Semantic classes are discovered by
clustering different objects on the basis of the lexico-
syntactic environments in which they appear in the
corpus. The results of some experiments with augmenting
the noun semantic classes with class information
obtained from WordNet are presented. A methodology for
formally evaluating the semantic classes extracted by
the system against classes provided by experts is also
presented. Once semantic classes have been obtained,
they are then used to generate lexico-semantic patterns
that are prevalent in the given domain.
A noteworthy feature of this research is that the
techniques used to acquire the semantic features require
very limited human intervention. The combination of
distributional and taxonomic techniques to obtain a set
of semantic classes for a given domain has also been
found to be useful.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  3439 </NUMBER>
<ORDER>   AAI9535413 </ORDER>
<TITLE> COMPUTATION IN DISCRETE-TIME DYNAMICAL SYSTEMS </TITLE>
<AUTHOR> CASEY, MICHAEL PATRICK </AUTHOR>
<YEAR> 1995 </YEAR>
<INSTITUTION> UNIVERSITY OF CALIFORNIA, SAN DIEGO; 0033 </INSTITUTION>
<DESCRIPTORS> MATHEMATICS; BIOLOGY, NEUROSCIENCE; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> MICHAEL H. FREEDMAN </ADVISER>
<CLASSIFICATIONS> NEURAL NETWORKS </CLASSIFICATIONS>
<ABSTRACT>
Deterministic finite state automata (DFA) can be
robustly modeled using collections of mappings of a
metric space into itself. We examine the extent to which
perfect knowledge of the computation to be performed
constrains possible phase space dynamics during
computation. We show that if a collection of mappings is
initialized to near constant maps, then some map must
undergo a bifurcation at some point as the system
evolves if it is to model a DFA with properties we will
describe later. We also show how to effectively predict
phase space dynamics in a such system which models a
DFA, and thereby allow one to understand computation
dynamics in spite of the possible existence of
unnecessary complexity in phase space dynamics.
We also address issues in using the cognitive science
approach to understanding systems that produce a
behavior that is of interest but not a result of
explicit system design, e.g. when an optimization
algorithm has been used to produce the system or when
the system is not man-made.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  3440 </NUMBER>
<ORDER>   AAI9535411 </ORDER>
<TITLE> CONTENT ADDRESSABLE NETWORKS </TITLE>
<AUTHOR> BRODSKY, STEPHEN ANDREW </AUTHOR>
<YEAR> 1995 </YEAR>
<INSTITUTION> UNIVERSITY OF CALIFORNIA, SAN DIEGO; 0033 </INSTITUTION>
<DESCRIPTORS> COMPUTER SCIENCE; ENGINEERING, ELECTRONICS AND ELECTRICAL; PHYSICS, ELECTRONICS AND ELECTRICITY; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> CLARK C. GUEST </ADVISER>
<CLASSIFICATIONS> NEURAL NETWORK </CLASSIFICATIONS>
<ABSTRACT>
High performance neural network computational systems
are investigated through theoretical and experimental
analysis of a new family of algorithms, the Content
Addressable Networks (CAN). The CAN algorithms are
demonstrated to be significantly more effective
implementations of neural networks in computer
technology than current network models.
Three CAN learning models have been developed:
supervised, self-organized, and tutored. The models are
described, derived, compared to leading neural networks,
and proven to converge. Conditions are established for
optimal recall. The networks are analyzed from a cost
benefit perspective, quantitatively establishing the
advantages of CAN networks over existing network
implementations.
Three experimental CAN systems have been constructed: An
optoelectronic system demonstrates all optical
computation of CAN weight recall, fault tolerance, and
learning on the experimental system. A second
optoelectronic system shows all optical computation of
CAN weight learning and recall with additional levels of
fault tolerance. A VLSI CAN chip illustrates the
capabilities and efficiency of CAN in CMOS VLSI. A key
circuit has been developed which dramatically reduces
area and greatly increases computational speed of CAN
networks.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  3441 </NUMBER>
<ORDER>   AAI9535376 </ORDER>
<TITLE> DESIGN OF A KNOWLEDGE-BASED SYSTEM FOR A DISTRIBUTED VERY LARGE AREA NETWORK </TITLE>
<AUTHOR> ZANDER, CAROL SUE </AUTHOR>
<YEAR> 1995 </YEAR>
<INSTITUTION> COLORADO STATE UNIVERSITY; 0053 </INSTITUTION>
<DESCRIPTORS> COMPUTER SCIENCE; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> NIL </ADVISER>
<CLASSIFICATIONS> VLAN) (ARTIFICIAL INTELLIGENCE, PROBLEM-SOLVING </CLASSIFICATIONS>
<ABSTRACT>
Distributed problem solving is a subfield of artificial
intelligence that deals with the interactions of groups
of intelligent agents attempting to cooperate to solve
problems. A coarse-grained problem decomposition with
multipurpose agents characterizes distributed problem
solving in the general subfield of distributed
artificial intelligence. A central issue in distributed
problem solving is how to distribute control and still
maintain coherent behavior. Interaction is structured
around coordination as an organizing principle.
Coordination is implemented by focusing on what agents
share with each other.
The central result of this dissertation is distributed
problem solving using a hierarchical model, a Very Large
Area Network (VLAN) or satellite network, which is a
network including at least one satellite. The focus is
on knowledge management--organization of knowledge
within each node and with relation to the entire system,
distribution of knowledge amongst the nodes, and
communication of knowledge between nodes.
The question addressed is: How can we manage the data
and control of a knowledge-based system in a VLAN to
effectively solve distributed problems? A problem-
solving framework in a distributed networking
environment is presented. The framework has three major
components including a control component that specifies
how the interaction occurs between nodes, a
communications component that provides the high-level
protocols for node interaction, and a knowledge
organization component that specifies how knowledge is
organized in individual nodes and distributed in the
network. The agents are decentralized in that both
control and data are logically and geographically
distributed. The nodes are grouped physically as well as
functionally.
This model has many potential applications including
distributed world-wide information systems and space
traffic control problems. The VLAN model design lends
itself well to handling physically (spatially) large
distributed problems. One foremost problem, the missile
detection-destruction problem, is presented within the
framework. The missile detection-destruction problem is
simulated and a critical analysis of the results is
presented. Effects of the assumptions, restrictions and
simplifications are discussed.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  3442 </NUMBER>
<ORDER>   AAI9535316 </ORDER>
<TITLE> DESIGNING BEHAVIOR NETWORKS FOR AUTONOMOUS ROBOTIC SYSTEMS  </TITLE>
<AUTHOR> CHERIAN, SUNIL </AUTHOR>
<YEAR> 1995 </YEAR>
<INSTITUTION> COLORADO STATE UNIVERSITY; 0053 </INSTITUTION>
<DESCRIPTORS> ENGINEERING, MECHANICAL; COMPUTER SCIENCE; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> NIL </ADVISER>
<CLASSIFICATIONS> ARTIFICIAL INTELLIGENCE </CLASSIFICATIONS>
<ABSTRACT>
Design paradigms for achieving intelligent behavior in
autonomous robotic systems are undergoing a shift from
symbolic reasoning paradigms to highly distributed,
reactive strategies that fall under the rubric of
behavior-based design. The unifying theme behind
behavior-based robotics is the view that intelligent
behavior in machines is the outcome of the global
dynamics of collections of loosely interconnected task-
achieving competence modules.
In this dissertation two control architectures are
developed with different methodologies for
interconnecting behavior modules. These control
architectures are validated within a computational
environment by using them to control simulated creatures
called animats. Analysis of the structure and dynamics
of these control algorithms leads to the view that the
collection of interconnected task-achieving behaviors,
or behavior network, is best viewed as a complex
dynamical system composed of many interacting
components. This view leads to new insights about basic
architectural requirements, system organization, and
analysis methods.
A review of some of the properties of naturally
occurring, autonomous, complex systems suggests new
directions of inquiry for behavior-based robotic
systems. In particular, the concept of a doubly
determinate representation hierarchy offers a novel
framework for investigating bi-directional control
relations between two adjacent layers in the hierarchy.
Of two such layers, the lower layer constitutes a micro-
description of the system and the higher layer
constitutes a macro-description of the same system. The
higher layer achieves its macro-description within a
representation space of lower dimensionality than that
employed by the lower layer. This concept of double
determinacy and its relevance to behavior-based robot
control is investigated in this dissertation.
In order to pursue this investigation, the concept of a
collection of $Delta$ machines, forming a $Delta$-
network, is introduced. $Delta$-networks constitute a
mechanism for formalizing the autonomous nature of each
task-achieving behavior and their causal interactions
with each other in a behavior network. The analysis of
the state-space dynamics of a simple behavior network,
considered as an instance of a $Delta$-network, provides
insight into the characteristic dynamics of behavior
networks.
The development of control architectures and the
analysis of behavior networks presented in this
dissertation is aimed at extending our understanding of
the synthesis of coherent global behavior in robots from
collections of low level task-achieving behaviors.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  3443 </NUMBER>
<ORDER>   AAI9535210 </ORDER>
<TITLE> NEURAL NETWORK CONTROL OF SPACE VEHICLE ORBIT TRANSFER, INTERCEPT, AND RENDEZVOUS MANEUVERS </TITLE>
<AUTHOR> YOUMANS, ELISABETH ANN </AUTHOR>
<YEAR> 1995 </YEAR>
<INSTITUTION> VIRGINIA POLYTECHNIC INSTITUTE AND STATE UNIVERSITY; 0247 </INSTITUTION>
<DESCRIPTORS> ENGINEERING, AEROSPACE; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> FREDERICK H. LUTZE </ADVISER>
<CLASSIFICATIONS> NIL </CLASSIFICATIONS>
<ABSTRACT>
The feasibility of neural networks to control dynamic
systems is examined. Control of a one-dimensional
problem is initially investigated to develop an
understanding of the structure and simulation of the
neural networks. A nondimensional problem is also
explored to apply a single neural network design to
controlling a class of systems with a wide variety of
modeling parameters. Finally, these techniques are
applied to control a space vehicle to transfer,
intercept, and rendezvous with another orbiting vehicle
using the Clohessy-Wiltshire equations of relative
motion in two dimensions. A combination of open-loop and
closed-loop neural network controllers is shown to work
effectively for this problem. Noise is added to the
neural network inputs to demonstrate the robustness of
these networks.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  3444 </NUMBER>
<ORDER>   AAI9535191 </ORDER>
<TITLE> AUTOMATED ANALYSIS OF THE DIGITIZED SECOND PALOMAR SKY SURVEY: SYSTEM DESIGN, IMPLEMENTATION, AND INITIAL RESULTS </TITLE>
<AUTHOR> WEIR, NICHOLAS </AUTHOR>
<YEAR> 1995 </YEAR>
<INSTITUTION> CALIFORNIA INSTITUTE OF TECHNOLOGY; 0037 </INSTITUTION>
<DESCRIPTORS> PHYSICS, ASTRONOMY AND ASTROPHYSICS; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> S. G. DJORGOVSKI </ADVISER>
<CLASSIFICATIONS> CALIFORNIA, OPTICAL IMAGING, IMAGE CLASSIFICATION, MACHINE LEARNING </CLASSIFICATIONS>
<ABSTRACT>
We describe the design, implementation, and initial
scientific results of a system for analyzing the
Digitized Second Palomar Observatory Sky Survey (DPOSS).
The system (SKICAT) facilitates and largely automates
the pipeline processing of DPOSS from raw pixel data
into calibrated, classified object catalog form.
A fundamental constraint limiting the scientific
usefulness of optical imaging surveys is the level at
which objects may be reliably distinguished as stars,
galaxies, or artifacts. The classifier implemented
within SKICAT was created using a new machine learning
technology, whereby an algorithm determines a near-
optimal set of classification rules based upon training
examples. Using this approach, we were able to construct
a classifier which distinguishes objects to the same
level of accuracy as in previous surveys using
comparable plate material, but nearly one magnitude
fainter (or an equivalent $Bsb0J sim 21.0$).
Our first analysis of DPOSS using SKICAT is of an
overlapping set of four survey fields near the North
Galactic Pole, in both the $J$ and $F$ passbands.
Through detailed simulations of a subset of these data,
we were able to analyze systematic aspects of our
detection and measurement procedures, as well as
optimize them. We discuss how we calibrate the plate
magnitudes to the Gunn-Thuan $g$ and $r$ photometric
system using CCD sequences obtained in a program devoted
expressly to calibrating DPOSS. Our technique results in
an estimated plate-to-plate zero point standard error of
under 0.10$sp0m$ in $g$ and below 0.05$sp0m$ in $r$, for
$J$ and $F$ plates, respectively.
Using the catalogs derived from these fields, we compare
our differential galaxy counts in $g$ and $r$ with those
from recent Schmidt plate surveys as well as predictions
from evolutionary and non-evolutionary (NE) galaxy
models. We find generally good agreement between our
counts and recent NE and mild evolutionary models
calibrated to consistently fit bright and faint galaxy
counts, colors, and redshift distributions. The
consistency of our results with these predictions
provides additional support to the view that very recent
($z < 0.1$) or exotic galaxy evolution, or some non-
standard forms of cosmology, may not be necessary to
reconcile these diverse observations with theory.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  3445 </NUMBER>
<ORDER>   AAI9534940 </ORDER>
<TITLE> AUTOMATED MODELING OF COMPLEX SYSTEMS TO ANSWER PREDICTION QUESTIONS  </TITLE>
<AUTHOR> RICKEL, JEFFREY WALTER </AUTHOR>
<YEAR> 1995 </YEAR>
<INSTITUTION> THE UNIVERSITY OF TEXAS AT AUSTIN; 0227 </INSTITUTION>
<DESCRIPTORS> COMPUTER SCIENCE; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> BRUCE W. PORTER </ADVISER>
<CLASSIFICATIONS> TRIPEL, EXPERT SYSTEMS </CLASSIFICATIONS>
<ABSTRACT>
The ability to answer prediction questions is crucial in
science and engineering. A prediction question describes
a physical system under hypothetical conditions and asks
for the resulting behavior of specified variables.
Prediction questions are typically answered by analyzing
(e.g., simulating) a mathematical model of the physical
system. To provide an adequate answer to a question, a
model must be sufficiently accurate. However, the model
must also be as simple as possible to ensure tractable
analysis and comprehensible results. Ensuring a simple
yet adequate model is especially difficult for complex
systems that include many phenomena that can be
described at many levels of detail. While tools exist
for analysis, modeling is a creative, time-consuming
task performed by humans.
We have designed algorithms for automatically
constructing models to answer prediction questions,
implemented them in a program called scTRIPEL, and
evaluated them in the domain of plant physiology. Given
a prediction question and domain knowledge, scTRIPEL
builds the simplest differential-equation model that can
adequately answer it and automatically passes the model
to a simulator to generate the desired predictions.
scTRIPEL uses knowledge of the time scales on which
processes operate to identify and ignore insignificant
phenomena and choose quasi-static representations of
fast phenomena. It also uses novel criteria and methods
to choose a suitable system boundary, separating
relevant subsystems from those that can be ignored.
Finally, it includes a novel algorithm for efficiently
searching through alternative levels of detail in a vast
space of possible models. scTRIPEL successfully answered
plant physiology questions using a large, multipurpose,
botany knowledge base (covering 300 processes and 700
plant properties) independently developed by a domain
expert. Because its methods are domain-independent,
scTRIPEL should be equally useful in many areas of
science and engineering.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  3446 </NUMBER>
<ORDER>   AAI9534924 </ORDER>
<TITLE> MAP LEARNING WITH UNINTERPRETED SENSORS AND EFFECTORS </TITLE>
<AUTHOR> PIERCE, DAVID MARK </AUTHOR>
<YEAR> 1995 </YEAR>
<INSTITUTION> THE UNIVERSITY OF TEXAS AT AUSTIN; 0227 </INSTITUTION>
<DESCRIPTORS> COMPUTER SCIENCE; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> BENJAMIN J. KUIPERS </ADVISER>
<CLASSIFICATIONS> ROBOTS, SENSORIMOTOR, MACHINE </CLASSIFICATIONS>
<ABSTRACT>
This dissertation presents a set of methods by which a
learning agent, called a "critter," can learn a sequence
of increasingly abstract and powerful interfaces to
control a robot whose sensorimotor apparatus and
environment are initially unknown. The result of the
learning is a rich, hierarchical model of the robot's
world (its sensorimotor apparatus and environment). The
learning methods rely on generic properties of the
robot's world such as almost-everywhere smooth effects
of actions on sensory features.
At the lowest level of the hierarchy, the critter
analyzes the effects of its actions in order to define
control signals, one for each of the robot's degrees of
freedom. It uses a generate-and-test approach to define
sensory features that capture important aspects of the
environment. It uses linear regression to learn action
models that characterize context-dependent effects of
the control signals on the learned features. It uses
these models to define high-level control laws for
finding and following paths defined using constraints on
the learned features. The critter abstracts these
control laws, which interact with the continuous
environment, to a finite set of actions that implement
discrete state transitions. At this point, the critter
has abstracted the robot's world to a finite-state
machine and can use existing methods to learn its
structure.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  3447 </NUMBER>
<ORDER>   AAI9534902 </ORDER>
<TITLE> LEARNING AS KNOWLEDGE INTEGRATION </TITLE>
<AUTHOR> MURRAY, KENNETH S. </AUTHOR>
<YEAR> 1995 </YEAR>
<INSTITUTION> THE UNIVERSITY OF TEXAS AT AUSTIN; 0227 </INSTITUTION>
<DESCRIPTORS> COMPUTER SCIENCE </DESCRIPTORS>
<ADVISER> BRUCE PORTER </ADVISER>
<CLASSIFICATIONS> NIL </CLASSIFICATIONS>
<ABSTRACT>
A fundamental challenge for Artificial Intelligence is
developing methods to build and maintain knowledge-based
systems. Knowledge integration is the task of
identifying how new and prior knowledge interact while
incorporating new information into a knowledge base.
This task is pervasive because substantial knowledge
bases must be developed incrementally: segments of
knowledge are added separately to a growing body of
knowledge. This task is difficult because new and prior
knowledge may interact in very subtle and surprising
ways, and unanticipated interactions may require changes
to the knowledge base. Performing knowledge integration
involves determining and effecting these changes. This
research investigates knowledge integration as a machine
learning task. Its contributions include formalizing
knowledge integration as a machine learning task,
developing a computational model for performing
knowledge integration, and instantiating the
computational model as an implemented machine learning
program.
The study of knowledge integration and methods that
perform it is important both for pragmatic concerns of
building knowledge-based systems and for theoretical
concerns of understanding learning systems. By
identifying subtle conflicts and gaps in knowledge,
knowledge integration facilitates building knowledge-
based systems. By avoiding unnecessary restrictions on
learning situations, knowledge integration reveals
important sources of learning bias and permits learning
behaviors that are more opportunistic than do
traditional machine learning tasks.
REACT is a computational model that identifies three
essential activities for performing knowledge
integration. Elaboration assesses how new and prior
knowledge interact. The system's limited capacity to
explore the interactions of new and prior knowledge
requires methods to focus its attention. This focus is
achieved by restricting elaboration to consider only
selected segments of prior knowledge. Recognition
selects the prior knowledge that is considered during
elaboration. By identifying the consequences of new
information for relevant prior knowledge, recognition
and elaboration reveal learning opportunities, such as
inconsistencies and gaps in the extended knowledge base.
Adaptation exploits these learning opportunities by
modifying the new or prior knowledge.
KI is a machine learning program that implements the
REACT model. Empirical studies demonstrate that KI
provides significant assistance to knowledge engineers
while integrating new information into a large knowledge
base.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  3448 </NUMBER>
<ORDER>   AAG9624423 </ORDER>
<TITLE> INDUCTIVE CLASSIFIER LEARNING FROM DATA: AN EXTENDED BAYESIAN BELIEF FUNCTION APPROACH </TITLE>
<AUTHOR> MA, YONG </AUTHOR>
<YEAR> 1995 </YEAR>
<INSTITUTION> UNIVERSITY OF ILLINOIS AT URBANA-CHAMPAIGN; 0090 </INSTITUTION>
<DESCRIPTORS> COMPUTER SCIENCE; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> DAVID C. WILKINS </ADVISER>
<CLASSIFICATIONS> ARTIFICIAL INTELLIGENCE </CLASSIFICATIONS>
<ABSTRACT>
A central problem in artificial intelligence is
reasoning under uncertainty. This thesis views inductive
learning as reasoning under uncertainty and develops an
Extended Bayesian Belief Function approach that allows a
two-layer representation of the probabilistic rules:
basic probabilistic belief and their confidences, which
are independent of each other and represent different
semantics of the rules. The use of the confidence
measure of probabilistic rules can thus handle many
difficult problems in inductive learning, including
noise, missing values, small samples, inter-attribute
dependency, and irrelevant or partially relevant
attributes, all of which are characteristics of real-
world induction tasks.
The theoretical framework is based upon an uncertainty
calculus, Dempster-Shafer theory which allows an
explicit representation of complete or partial lack of
knowledge. This explicit representation is used to
quantify and discount the effects of unreliable
probability estimates due to noise and small samples,
and to account for inter-attribute dependency and
irrelevant or partially relevant attributes. Based on
this methodology, a learning system, called IUR
(Induction of Uncertain Rules) that uses only the first-
order correlation information, is developed and
experimentally demonstrated to outperform the major
existing induction systems on many of the standard test
sets.
Future research includes extending IUR to use higher-
order correlation information and integrating the
Extended Bayesian Belief Function approach to other
learning paradigms such as decision trees and neural
networks.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  3449 </NUMBER>
<ORDER>   AAI9534826 </ORDER>
<TITLE> A MATHEMATICAL INVESTIGATION OF REASONING ABOUT ACTIONS </TITLE>
<AUTHOR> KARTHA, G. NEELAKANTAN </AUTHOR>
<YEAR> 1995 </YEAR>
<INSTITUTION> THE UNIVERSITY OF TEXAS AT AUSTIN; 0227 </INSTITUTION>
<DESCRIPTORS> COMPUTER SCIENCE; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> VLADIMIR LIFSCHITZ </ADVISER>
<CLASSIFICATIONS> ARTIFICIAL INTELLIGENCE, AUTOMATED REASONING </CLASSIFICATIONS>
<ABSTRACT>
Reasoning about actions is a central area of research in
artificial intelligence, related to the study of common
sense and nonmonotonic reasoning, knowledge
representation, planning and theorem proving. The
methodology of research in this area has not been quite
satisfactory; typically, a new proposal for reasoning
about actions is illustrated by way of a few examples
that have been known to be challenging to formalize, and
then claims are made that the method works in general.
This is not very satisfactory since minor modifications
of the examples might prove (indeed, have proven, in
many cases) to be difficult or impossible for the new
proposal to handle correctly. Such an example-oriented
methodology also makes it difficult to compare various
formalisms and thus to synthesize new ones.
In this dissertation, we present a systematic study of
reasoning about actions. The shortcomings of the example-
oriented methodology are avoided as follows. First,
declarative languages for describing actions are
introduced and their semantics defined in such a way as
to capture the underlying commonsense intuitions.
Different methods of reasoning about actions are
presented as translations from these languages and then
the adequacy of the different formalizations is
established by proving the soundness and completeness of
the translations.
The new declarative languages we propose are capable of
representing rich action domains, such as those where
actions can have indirect effects. In addition, we
introduce a new approach to reasoning about actions and
show its adequacy in formalizing a large class of action
domains. We show that, in conjunction with this
approach, symbolic methods can often be employed for
automating reasoning about actions. Finally, we point
out some limitations of proposed methods of reasoning
about actions and suggest ways to overcome these
limitations.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  3450 </NUMBER>
<ORDER>   AAI9534825 </ORDER>
<TITLE> DYNAMIC DATA RECTIFICATION VIA RECURRENT NEURAL NETWORKS </TITLE>
<AUTHOR> KARJALA, THOMAS WESLEY, JR. </AUTHOR>
<YEAR> 1995 </YEAR>
<INSTITUTION> THE UNIVERSITY OF TEXAS AT AUSTIN; 0227 </INSTITUTION>
<DESCRIPTORS> ENGINEERING, CHEMICAL; STATISTICS; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> DAVID M. HIMMELBLAU </ADVISER>
<CLASSIFICATIONS> KALMAN FILTERING </CLASSIFICATIONS>
<ABSTRACT>
Process data is often corrupted by a variety of
contaminants including Gaussian and autocorrelated
noise, gross errors, and measurement bias. In this work,
techniques were developed to reduce the uncertainty in
data taken from dynamic, nonlinear processes using
recurrent artificial neural networks singly, and in
conjunction with Kalman filtering.
While data rectification methods for data taken from
linear, steady-state processes are well developed, the
same cannot be said for data from nonlinear, dynamic
processes which require the use of an accurate first
principles model. Such models are typically unavailable
in practice, and if available, often cannot be solved
rapidly enough to be of use in on-line applications.
A major focus of this dissertation was to examine and
evaluate the use of feed-forward and recurrent neural
networks (RNN) for system identification. Both
internally and externally recurrent neural networks were
shown to be empirical, nonlinear, state space models.
When identified from process measurements, the nets
served as accurate models that could provide responses
in real time.
To illustrate the use of RNN for data rectification,
several simulations were run for a variety of dynamic
chemical processes in which the simulated data contain
uncertainty: (1) a draining tank, (2) a non-isothermal
continuous stirred tank reactor, (3) a tank/pipeline
combination, and (4) a packed distillation tower. The
results of the respective rectifications yielded
performance equal to if not greater than traditional
approaches to dynamic rectification. The RNN approach
worked well for uncorrelated measurement errors, but
less well when the measurement errors were auto-
correlated.
By embedding RNN within the predictor/corrector
framework of Kalman filtering, the performance of RNN
used for rectification improved. State augmentation was
used with noise and bias models so that rectification
using RNN could be extended to measurements corrupted by
auto-correlated noise, and to the estimation and removal
of time varying bias in the measurements.
Another phase of the work developed confidence intervals
based on linearization for the predictions of feed-
forward as well as recurrent neural network models under
the standard assumptions of regression. Monte Carlo
simulation was then used to validate the accuracy of
these intervals.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  3451 </NUMBER>
<ORDER>   AAI9534667 </ORDER>
<TITLE> IMPLEMENTING ADAPTIVE FUZZY LOGIC CONTROLLERS WITH NEURAL NETWORKS  </TITLE>
<AUTHOR> KIM, HUNG-MAN </AUTHOR>
<YEAR> 1995 </YEAR>
<INSTITUTION> THE UNIVERSITY OF ARIZONA; 0009 </INSTITUTION>
<DESCRIPTORS> ENGINEERING, ELECTRONICS AND ELECTRICAL; ENGINEERING, INDUSTRIAL; ENGINEERING, SYSTEM SCIENCE; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> FEI-YUE WANG </ADVISER>
<CLASSIFICATIONS> INTELLIGENT CONTROL </CLASSIFICATIONS>
<ABSTRACT>
The goal of intelligent control is to achieve control
objectives for complex systems where it is impossible or
infeasible to develop a mathematical system model but
expert skills and heuristic knowledge from human
experiences are available for control purposes. To this
end, an intelligent control system must have the
essential characteristics of human control experiences,
i.e., linguistic knowledge representation, which
facilitates the process of knowledge acquisition and
transfer, and adaptive knowledge evolution or learning,
which leads to the improvement in system performance and
knowledge. This dissertation presents an efficient
approach that combines fuzzy logic and neural networks
to capture these two important features required for an
intelligent control system.
A design method for adaptive neuro-fuzzy controllers has
been proposed using structured neuro-fuzzy networks. The
structured neuro-fuzzy networks consist of three types
of subnets for pattern recognition, fuzzy reasoning, and
control synthesis, respectively. Each subnet is
constructed directly from the decision-making procedure
of fuzzy logic based control systems. In this way, a one-
to-one mapping between a fuzzy logic based control
system and a structured neuro-fuzzy network is
established. This mapping enables us to create a
knowledge structure within neural networks based on
fuzzy logic, and to give a learning ability to fuzzy
controls using neural networks. From the perspective of
neural networks, the proposed design method offers a
mechanism to: construct networks with heuristic
knowledge, instead of using digital training pairs,
which are much more difficult to get, build decision
structures into networks, which divide a network into
several functional regions and make the network no
longer just as a black-box function approximator, and
conduct network learning in a distributed fashion, i.e.,
each sub-network of different functional regions can
learn its own function independently. On the other hand,
from the perspective of fuzzy logic, the proposed design
method provides a tool to: refine membership functions,
inference procedures, and defuzzification algorithms of
fuzzy control systems; generate new fuzzy control rules
so that fuzzy control systems can adapt to gradual
changes in environments and implement parallel execution
of rule matching, firing, and defuzzification.
Several simulation studies have been conducted to
demonstrate the use of the structured neuro-fuzzy
networks. The effectiveness of the proposed design
method has been clearly shown by the results of these
studies. These results have also indicated that fuzzy
logic and neural networks are complementary and their
combination is ideal to achieve the goal of intelligent
control.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  3452 </NUMBER>
<ORDER>   AAI9534573 </ORDER>
<TITLE> HANDWRITTEN DIGIT AND SCRIPT RECOGNITION USING DENSITY BASED RANDOM VECTOR FUNCTIONAL LINK NETWORK </TITLE>
<AUTHOR> PARK, GWANG HOON </AUTHOR>
<YEAR> 1995 </YEAR>
<INSTITUTION> CASE WESTERN RESERVE UNIVERSITY; 0042 </INSTITUTION>
<DESCRIPTORS> PHYSICS, ELECTRONICS AND ELECTRICITY; COMPUTER SCIENCE; ENGINEERING, ELECTRONICS AND ELECTRICAL; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> YOH-HAN PAO </ADVISER>
<CLASSIFICATIONS> NEURAL NETWORK </CLASSIFICATIONS>
<ABSTRACT>
A new formation of a neural network called a Density
Based Random Vector Functional Link Network (DBRVFLN) is
introduced to solve high dimensional real-world
problems. It is a hybrid technique which uses the
combination of a priori knowledge of the problem and
randomness to prepare unknown factors.
Simple but powerful feature extraction methods for
handwritten digit recognition and script recognition are
introduced. Handwritten digit recognition systems using
neural networks are introduced. For the script
recognition task, a global approach which uses whole
sets of features of the image and an analytical approach
from nonsegmented sequence of features via letters to a
word using neural networks are designed and explored.
The recognition systems are based on conventional
preprocessing methodologies, novel feature extraction
and reduction algorithms and quadratic approaches of
neural networks such as Radial Basis Function Neural
Network(RBNN) and DBRVFLN.
The recognition systems are tested using unconstrained
real-world databases. In the handwritten digit
recognition task, the performance of the recognition
system using DBRVFLN is better than that of RBNN if
there is enough priori knowledge. To attain 1%
substitution error rates, the current recognition system
needs to tolerate rejection rates of about 11%$sim$12%.
In the global approach of script recognition task, the
ability to construct a filter for one word is tested.
While keeping a very low substitution error rate of
0.74%, the recognition system which uses DBRVFLN rejects
11.48% and has better performance with 2.78% in the
rejection ratio than the system using RBNN even if they
have the same number of enhancement nodes.
The experimental results show that the random vector
enhancements for the unknown factor in DBRVFLN act very
nicely as decision enhancers and that they do improve
the classification performances in comparison with RBNN,
in the same recognition system.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  3453 </NUMBER>
<ORDER>   AAI9534571 </ORDER>
<TITLE> AN INFORMATION BASED APPROACH TO ANOMALY DETECTION IN DYNAMIC SYSTEMS  </TITLE>
<AUTHOR> OH, KI-TAE </AUTHOR>
<YEAR> 1995 </YEAR>
<INSTITUTION> CASE WESTERN RESERVE UNIVERSITY; 0042 </INSTITUTION>
<DESCRIPTORS> ENGINEERING, SYSTEM SCIENCE; ENGINEERING, ELECTRONICS AND ELECTRICAL; COMPUTER SCIENCE; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> KENNETH A. LOPARO </ADVISER>
<CLASSIFICATIONS> NEURAL NETWORK </CLASSIFICATIONS>
<ABSTRACT>
An ultimate goal in dynamic system control is the
development of a failure tolerant control system. Such
systems require an anomaly detection mechanism and a
reconfigurable controller. In this dissertation, a new
anomaly detection method is developed for high speed
detection. The problem is formulated mathematically in
the observation space, and a hypothesized input-output
model is assumed and associated with each anomaly class.
The detection method developed is based on statistical
information theory. The overall performance depends on
the speed at which distinguishable features in the
information are accumulating. Posterior distributions
are calculated and used for the decision procedure. The
speed of detection can be increased by effectively using
the input signal to probe the system. This probing
signal is synthesized in the time domain in feedback
form. The main idea is to maximize the relative entropy
between future output distributions of the two most
plausible models. Modeling uncertainty is considered in
the detection and in the synthesis of the probing
signal.
These detection mechanisms are extended to a Detection
Network to handle a Nonlinear Non-Gaussian model. This
is important for application purposes, because some
anomaly classes may not be mathematically described
using a Linear Gaussian model. In this Detection
Network, a prediction module and a Probability Density
Function (p.d.f.) module are used to obtain the
necessary posterior distribution, and each module is
built by using the Gaussian Basis Function Network
(GBFN). In the p.d.f. module, the Maximum Likelihood
estimation method incorporating Expectation Maximization
algorithms is used for training, and various low
complexity models in GBFN are considered. The Minimum
Description Length Principle is applied to the p.d.f.
model selection procedure to obtain a good compromise
between simplicity and likelihood.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  3454 </NUMBER>
<ORDER>   AAI9534569 </ORDER>
<TITLE> A NEW NEURO-COMPUTING APPROACH: SOFTWARE AND HARDWARE DESIGNS  </TITLE>
<AUTHOR> AKBARI, KAZEM </AUTHOR>
<YEAR> 1995 </YEAR>
<INSTITUTION> CASE WESTERN RESERVE UNIVERSITY; 0042 </INSTITUTION>
<DESCRIPTORS> COMPUTER SCIENCE; ENGINEERING, ELECTRONICS AND ELECTRICAL; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> CHRISTOS A. PAPACHRISTOU </ADVISER>
<CLASSIFICATIONS> NEURAL NETWORK </CLASSIFICATIONS>
<ABSTRACT>
This study also presents a new approach for both
software and hardware designs of neural networks. The
software design of this work presents a new scheduling
approach based upon a deterministic modified Hopfield
model to solve "File-Transfer" scheduling, an NP-
Complete constraint satisfaction problem. The proposed
model is mapped onto a two-dimensional neural
architecture for the transfer scheduling of files
between various nodes of a network, by which the overall
transfer times should be minimized. Neural Network-based
Scheduling is achieved by formulating the scheduling
problem in terms of energy function and by using the
"Motion Equation" corresponding to the variation of
energy levels.
The main contribution of this part is an efficient
parallel algorithm under time and resource constraints
appropriate for implementing on parallel machines.
Another quite important contribution of this part is
applying a novel technique which considerably improves
the performance and efficacy of the system. However,
neurons' motion equation is the core of this guided
movement mechanism and guarantees that the state of
system mostly converges to the optimal state. This part
was modeled and simulated in C language successfully.
The second part of this work presents a developmental
approach for hardware implementation of neural networks.
The primary goal of this part is to construct a general
purpose neural system, comprising sufficient neural
processors and powerful enough for mapping and testing
various neural algorithms and hypothesis. To do this,
first a new multipurpose neurocomputing system is
proposed (an SIMD machine), and then on the basis of the
proposed system a neural network architectural
representation is provided for the mapping and testing
of Artificial Neural Network (ANN) algorithms, modeled
behaviorally using the VHSIC Hardware Description
Language (VHDL). Due to some major impediments in
construction of ANN chips, VHDL design entities and
configurations were applied to neural network algorithm
and simulation, to model, test, and verify both circuit
and algorithm in the same VHDL representation.
After all testings and simulations confirmed the
capability and correctness of the system, the proposed
system is prepared for the fabrication processes using
"Compass Synthesizer tools" to create the corresponding
layouts.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  3455 </NUMBER>
<ORDER>   AAI9534348 </ORDER>
<TITLE> USE OF NEURAL NETWORKS FOR PREDICTION OF VAPOR-LIQUID EQUILIBRIUM K-VALUES FOR LIGHT HYDROCARBON MIXTURES </TITLE>
<AUTHOR> HABIBALLAH, WALID ABDUL-RAHIM </AUTHOR>
<YEAR> 1995 </YEAR>
<INSTITUTION> TEXAS A&M UNIVERSITY; 0803 </INSTITUTION>
<DESCRIPTORS> ENGINEERING, PETROLEUM; ENGINEERING, CHEMICAL; COMPUTER SCIENCE; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> R. A. STARTZMAN </ADVISER>
<CLASSIFICATIONS> NIL </CLASSIFICATIONS>
<ABSTRACT>
A new method for prediction of vapor-liquid equilibrium
ratios (K-values) was developed. The new method is based
on the new technology of neural networks, and predicts K-
values of a component in a mixture as a function
component identity, mixture pressure, temperature, and
convergence pressure.
About 8000 experimentally determined K-values were
collected from different publications. The data
represent K-values for Methane through normal-Decane in
different binary, ternary, and multicomponent mixtures.
The collected data was used to train a neural network.
Input to the network were: component's molecular weight
and specific gravity, mixture pressure, temperature, and
convergence pressure. The output of the network was the
component's K-value for the required pressure and
temperature. The average absolute error for training
data (8000 points) was at about 4.7%.
After training the network, the final network was
tested. Five sample tests were obtained from the
literature that were not part of the training data. Each
sample consisted of experimental K-values, compositional
analysis, and dew-point pressure data. The samples
represented three mixtures at different temperatures.
The neural network predicted K-values for every
component in all mixtures, with an overall average
absolute error of about 8%. The experimental data did
not include convergence pressure, and was calculated
using the dew point pressure.
Neural network K-value predictions were compared to
different published K-value methods and are shown to
have better accuracy for the samples used in testing.
Furthermore the neural network method is explicit and
doesn't involve iterations to determine K-values.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  3456 </NUMBER>
<ORDER>   AAI9534327 </ORDER>
<TITLE> DEVELOPMENT OF FOURIER SERIES AND ARTIFICIAL NEURAL NETWORK APPROACHES TO MODEL HOURLY ENERGY USE IN COMMERCIAL BUILDINGS </TITLE>
<AUTHOR> DHAR, AMITAVA </AUTHOR>
<YEAR> 1995 </YEAR>
<INSTITUTION> TEXAS A&M UNIVERSITY; 0803 </INSTITUTION>
<DESCRIPTORS> ENGINEERING, MECHANICAL; ARTIFICIAL INTELLIGENCE; ENERGY </DESCRIPTORS>
<ADVISER> DAVID E. CLARIDGE </ADVISER>
<CLASSIFICATIONS> NIL </CLASSIFICATIONS>
<ABSTRACT>
This dissertation develops Fourier series and artificial
neural network (ANN) approaches to model hourly energy
use in commercial buildings and illustrates application
to data-screening.
The procedure for modeling hourly energy use has two
steps: (i) Day-typing and (ii) Model development. The
mean diurnal energy use and the diurnal profile may be
different during working weekdays, weekends, holidays
and Christmas due to major changes in mode of operation.
The first step, known as day-typing, is important for
removing such effects. The second step is to develop
models for each day-type.
Fourier series analysis is eminently suitable for
modeling strongly periodic data. Energy use in
commercial buildings being strongly periodic, is
appropriate for Fourier series treatment. Generalized
Fourier series (GFS) model equations, developed for both
weather independent and weather dependent energy use,
give a set of parameters involving time and/or weather
variables. Stepwise regression is performed to select
the important parameters and a final model for each day-
type is developed using the selected parameters.
There are situations when only temperature data is
available. A temperature based Fourier series (TFS)
equation for modeling heating and cooling energy use has
been developed to deal with such cases. Two important
advantages of TFS are that it (i) represents nonlinear
variation of energy use in a linearized functional form
and (ii) can indirectly account for humidity and solar
effect in the cooling energy use.
ANNs with back propagation algorithms give high
prediction accuracy and have been applied by many
researchers to model hourly energy use in commercial
buildings. However, the training of Back Propagation
Network (BPN) algorithms is a long, uncertain process.
ANNs with local basis functions require significantly
shorter training times than conventional BPNs. A
methodology has been developed to model heating and
cooling energy use in commercial buildings using a one-
hidden-layer ANN with two dimensional wavelet basis
functions derived from cubic splines.
A suitable prediction interval can be generated and used
to perform data-screening. Application of the TFS
approach to data-screening is illustrated with monitored
data.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  3457 </NUMBER>
<ORDER>   AAI9534269 </ORDER>
<TITLE> MATHEMATICAL PROGRAMMING APPLICATIONS IN HANDWRITTEN DIGIT RECOGNITION  </TITLE>
<AUTHOR> BAILEY, JOHN HOYNE </AUTHOR>
<YEAR> 1995 </YEAR>
<INSTITUTION> THE GEORGE WASHINGTON UNIVERSITY; 0075 </INSTITUTION>
<DESCRIPTORS> OPERATIONS RESEARCH; ENGINEERING, INDUSTRIAL; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> ANTHONY V. FIACCO </ADVISER>
<CLASSIFICATIONS> IMAGE SCANNING </CLASSIFICATIONS>
<ABSTRACT>
There is considerable interest in machine recognition of
hand-written digits. The US Postal Service has
undertaken a large-scale effort to develop automated
address reading, especially zip codes. The potential
application of digit recognition to the banking
industry, IRS, Census bureau, and other commercial
sectors is clear. This dissertation examines the
handwritten digit recognition problem, and applies
mathematical programming formulations to digit
classification.
Following a survey of prior research on this problem,
the dissertation investigates a simple line scanning
system which extracts information from the unknown image
concerning the number, location, and orientation of
certain "primitive elements" of which digits are
constructed. Several types of features are examined. The
selected feature set permits determination of three key
elements of the primitives-shape, position and scale.
Several methods of classification are examined,
including heuristically determined classification
boundaries and boundaries determined using LP approaches
first proposed by Mangasarian. The classification
problem is placed in a general mathematical programming
problem context which unifies the formulations of
previous researchers. Recent results of Mangasarian and
Bennett are extended to permit determination of minimum
size ambiguity sets. Use of these ambiguity sets permits
classification of otherwise rejected images. An overall
recognition rate in excess of 90% is achieved.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  3458 </NUMBER>
<ORDER>   AAI9534221 </ORDER>
<TITLE> A PROBABILISTIC ALTERNATIVE TO FUZZY LOGIC CONTROLLERS </TITLE>
<AUTHOR> BARRETT, JOHN DOUGLAS </AUTHOR>
<YEAR> 1995 </YEAR>
<INSTITUTION> THE UNIVERSITY OF ALABAMA; 0004 </INSTITUTION>
<DESCRIPTORS> STATISTICS; COMPUTER SCIENCE; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> WILLIAM H. WOODALL </ADVISER>
<CLASSIFICATIONS> NIL </CLASSIFICATIONS>
<ABSTRACT>
The fuzzy logic controller has been used increasingly in
industrial applications. Proponents of fuzzy logic have
claimed that probability can not be used in these
applications. In this dissertation, we show that
probability can be used to construct a controller which
can serve the same purpose as the fuzzy logic controller
without sacrificing any performance qualities.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  3459 </NUMBER>
<ORDER>   AAG9624379 </ORDER>
<TITLE> SEER: MAXIMUM LIKELIHOOD REGRESSION FOR LEARNING-SPEED CURVES  </TITLE>
<AUTHOR> KADIE, CARL MYERS </AUTHOR>
<YEAR> 1995 </YEAR>
<INSTITUTION> UNIVERSITY OF ILLINOIS AT URBANA-CHAMPAIGN; 0090 </INSTITUTION>
<DESCRIPTORS> COMPUTER SCIENCE; STATISTICS; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> DAVID C. WILKINS </ADVISER>
<CLASSIFICATIONS> MACHINE LEARNING </CLASSIFICATIONS>
<ABSTRACT>
The research presented here focuses on modeling machine-
learning performance. The thesis introduces Seer, a
system that generates empirical observations of
classification-learning performance and then uses those
observations to create statistical models. The models
can be used to predict the number of training examples
needed to achieve a desired level and the maximum
accuracy possible given an unlimited number of training
examples. Seer advances the state of the art with (1)
models that embody the best constraints for
classification learning and most useful parameters, (2)
algorithms that efficiently find maximum-likelihood
models, and (3) a demonstration on real-world data from
three domains of a practicable application of such
modeling.
The first part of the thesis gives an overview of the
requirements for a good maximum-likelihood model of
classification-learning performance. Next, reasonable
design choices for such models are explored. Selection
among such models is a task of nonlinear programming,
but by exploiting appropriate problem constraints, the
task is reduced to a nonlinear regression task that can
be solved with an efficient iterative algorithm. The
latter part of the thesis describes almost 100
experiments in the domains of soybean disease, heart
disease, and audiological problems. The tests show that
Seer is excellent at characterizing learning-performance
and that it seems to be as good as possible at
predicting learning performance. Finally,
recommendations for choosing a regression model for a
particular situation are made and directions for further
research are identified.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  3460 </NUMBER>
<ORDER>   AAI9533603 </ORDER>
<TITLE> BENEFIT AND COST ANALYSIS:  THREE-DIMENSIONAL COMPUTER MODELS WITH INTEGRATED DATABASES IN THE MANAGEMENT OF CONSTRUCTION </TITLE>
<AUTHOR> LI, WENQING </AUTHOR>
<YEAR> 1995 </YEAR>
<INSTITUTION> COLUMBIA UNIVERSITY; 0054 </INSTITUTION>
<DESCRIPTORS> ENGINEERING, CIVIL; STATISTICS; COMPUTER SCIENCE </DESCRIPTORS>
<ADVISER> F. H. (BUD) GRIFFS </ADVISER>
<CLASSIFICATIONS> NIL </CLASSIFICATIONS>
<ABSTRACT>
The purpose of this research is to provide simple, cost
effective but structured and robust methodologies for
benefit-cost analysis. Two paradigms are investigated.
One is classical statistical technique-multiple
regression, the other is modern artificial intelligence
technique-neural networks. This study shows that
artificial neural networks deliver better performance in
terms of accuracy. However, regression analysis provides
the baseline for the newer methods. Each has unique
advantages and disadvantages, and hence each is
appropriate for distinct types of problems. The
combination of statistics and artificial neural network
yield the best results.
The objective of this research is to quantify the
benefit-cost impacts that occur on a construction
project if three-dimensional computer models with
integrated databases are used in the management of
construction. The results show that 3D computer models
when used properly in the management of construction
have significant influence on construction cost and
rework metrics. The use of 3D models has little
significant effect on construction duration metrics. The
level of model use is critical since poor use of 3D
computer models is worse than no use at all. This
research shows that three-dimensional computer models
with integrated databases can significantly improve the
construction metrics.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  3461 </NUMBER>
<ORDER>   AAI9533148 </ORDER>
<TITLE> SPATIALITY AND STOCHASTICITY IN ARTIFICIAL NEURAL NETWORKS  </TITLE>
<AUTHOR> LI, SHENG-TUN </AUTHOR>
<YEAR> 1995 </YEAR>
<INSTITUTION> UNIVERSITY OF HOUSTON; 0087 </INSTITUTION>
<DESCRIPTORS> COMPUTER SCIENCE; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> ERNST LEISS </ADVISER>
<CLASSIFICATIONS> ROBUST LEARNING </CLASSIFICATIONS>
<ABSTRACT>
Artificial neural networks (ANNs) are biologically-
inspired computational models whose study has become a
rapidly growing multidisciplinary research field. The
computations in ANNs model mainly the interaction
between a large number of very simple neuron-like units
whose exact details have little functional consequences.
This limited functionality of the units gives rise to
the problem of scaling and capacity for complicated
applications, partly because at least three
computationally significant features inherent in
neuronal information processing have traditionally been
ignored, namely, spatiality, stochasticity, and
temporality. This dissertation concentrates on the study
of spatial and stochastic complexities, in order to
facilitate the design of enhanced processors.
Motivated by the study of single-neuron computation, we
propose the generalized multi-dendrite (GMD) neuron
model in which the spatial complexity is taken into
account by abstracting a dendritic tree in the model. A
special unit of the GMD model, the so-called generalized
multi-dendrite product (GMDP), functions as a network of
independent dendrites with the ability of local
processing, forming higher-order receptive fields, and
constructing convex decision regions in the feature
space. Accompanied by an extended backpropagation
learning rule, feedforward networks with GMDP units are
shown to be sufficiently powerful to serve as a unified
framework for diverse higher-order networks.
To introduce stochasticity into GMDP networks, we model
stochastic fluctuations in the environmental stimuli so
that gross errors or outliers may occur; this requires a
robust learning rule. We apply this issue to the problem
domain of function approximation. In contrast to the
influence function approach adopted in most of the
literature, we apply the least trimmed squares method
based on the breakdown point approach to develop a
robust GMDP network. Our experiments show promising
results in tackling outliers. We also study function
approximation in detail and develop an adaptive robust
learning rule for the widely-used radial basis function
networks. We bound the maximal fraction of outlying data
in terms of the number of training data and number of
synaptic weights that the resulting network can
tolerate. The superiority of our proposed network in
robustness, stability, and efficiency, and in
controlling bias and variance is demonstrated through a
number of experiments on function approximation and
pattern classification as well as a simple Monte Carlo
simulation.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  3462 </NUMBER>
<ORDER>   AAI9532776 </ORDER>
<TITLE> ANALYSIS OF FEATURE MAPS WITH APPLICATIONS TO AUTOMATIC SPEECH RECOGNITION </TITLE>
<AUTHOR> DE HAAN, GREGORY ROBERT </AUTHOR>
<YEAR> 1995 </YEAR>
<INSTITUTION> UNIVERSITY OF CALIFORNIA, SANTA BARBARA; 0035 </INSTITUTION>
<DESCRIPTORS> COMPUTER SCIENCE; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> OMER EGECIOGLU </ADVISER>
<CLASSIFICATIONS> NEURAL NETWORKS </CLASSIFICATIONS>
<ABSTRACT>
Feature Map neural networks are trained such that the
weight vectors associated with neurons collectively form
a good representation of the training data. Furthermore,
Feature Map learning orders the weight vectors such that
the topological relationships between patterns in the
training data space are preserved in the topological
relationships between the corresponding neurons on the
Feature Map. Although many researchers have studied
Feature Maps' topology preservation, it has proven
difficult to rigorously define the notion of topology
preservation and to exploit the weight vector ordering
for practical applications: both are done here.
To use the topology preserving ordering of Feature Maps,
we first performed experiments to explore the special
capabilities of Feature Maps. These experiments yield
training strategies which help to increase the
likelihood of obtaining a good ordering of weight
vectors and also demonstrate that an attendant property
of topology preservation, automatic selection of feature
dimensions, is more powerful than previously reported.
After empirically determining effective training
strategies, Feature Maps topology preservation property
is then directly applied to automatic speech
recognition. Isolated digit recognition experiments are
performed where Feature Maps prove useful for feature
extraction and data reduction. Effective strategies for
using Feature Maps to normalize input patterns and to
integrate features are also presented. Feature Maps are
found to have versatile computational capabilities, as
they can be hierarchically combined to perform a variety
of functions.
A variant of Feature Maps called VQ-maps is introduced.
VQ-maps are trained to preserve topology by minimizing
neighborhood distortion functions. It is shown that
topology preservation naturally results from minimizing
neighborhood distortion. Analyses of optimal VQ-maps are
performed which show that traditional Feature Map
learning is not compatible with VQ-map optimality
requirements for a variety of neighborhood distortion
measures. Then a formulation of weighted vector
quantization is made to extend vector quantization to
handle neighborhood distortion. Optimality conditions
for codebooks are then derived and a learning algorithm
for VQ-maps is presented.
Another Feature Map variant, Learning Vector
Quantization, is also studied. An important instability
is identified and characterized, and the implications of
the instability for automatic speech recognition are
considered.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  3463 </NUMBER>
<ORDER>   AAI9532416 </ORDER>
<TITLE> A PATTERN RECOGNITION APPROACH TO DATA FUSION IN INTELLIGENT VEHICLE HIGHWAY SYSTEMS </TITLE>
<AUTHOR> PALACHARLA, PRASAD V. </AUTHOR>
<YEAR> 1995 </YEAR>
<INSTITUTION> UNIVERSITY OF ILLINOIS AT CHICAGO; 0799 </INSTITUTION>
<DESCRIPTORS> COMPUTER SCIENCE; ENGINEERING, SYSTEM SCIENCE; TRANSPORTATION; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> NIL </ADVISER>
<CLASSIFICATIONS> FUZZY LOGIC </CLASSIFICATIONS>
<ABSTRACT>
This research addresses two issues--traffic congestion
data fusion, and travel time data fusion and estimation.
Congestion level data fusion involves fusing data from
multiple sources into an estimate of the current
congestion level. Such information is needed for
Advanced Traveler Information Systems (ATIS)
applications which provide travelers with high-level
information on the transportation network. Travel time
data fusion involves fusing data from multiple sources
into an estimate of current link travel times. Such
fusion is needed for ATIS applications making use of
dynamic route guidance. The current methods for solving
the data fusion problem either uses simple selection and
aging technique or weighted averaging technique. These
techniques have many limitations such as ignorance of
data from one or more sources, lack of learning
capabilities, and lack of tolerance for uncertainty.
This research work targeted towards overcoming some of
these limitations using pattern recognition approach.
Research results showed that both the Dempster-Shafer
theory of evidence and fuzzy four-valued logic provide
interesting mechanisms for fusing uncertain traffic
congestion data. We have demonstrated the ability of a
counterpropagation neural network for travel time data
fusion. Our research results show that a method based on
both fuzzy logic and neural networks in combination can
significantly improve the accuracy of travel time
estimation and reduce the time and effort needed to
extract the traffic engineering knowledge and devise
fuzzy if-then rules.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  3464 </NUMBER>
<ORDER>   AAI9532175 </ORDER>
<TITLE> IMPROVEMENTS TO PROPOSITIONAL SATISFIABILITY SEARCH ALGORITHMS </TITLE>
<AUTHOR> FREEMAN, JON WILLIAM </AUTHOR>
<YEAR> 1995 </YEAR>
<INSTITUTION> UNIVERSITY OF PENNSYLVANIA; 0175 </INSTITUTION>
<DESCRIPTORS> COMPUTER SCIENCE; OPERATIONS RESEARCH </DESCRIPTORS>
<ADVISER> SANGUTHEVAR RAJASEKARAN </ADVISER>
<CLASSIFICATIONS> NIL </CLASSIFICATIONS>
<ABSTRACT>
In this dissertation, we examine complete search
algorithms for SAT, the satisfiability problem for
propositional formulas in conjunctive normal form. SAT
is NP-complete, easy to think about, and one of the most
important computational problems in the field of
Artificial Intelligence. From an empirical perspective,
the central problem associated with these algorithms is
to implement one that runs as quickly as possible on a
wide range of hard SAT problems. This in turn require
identifying a set of useful techniques and programming
guidelines. Another important problem is to identify the
techniques that do not work well in practice, and
provide qualitative reasons for their poor performance
whenever possible. This dissertation addresses all four
of these problems.
Our thesis is that any efficient SAT search algorithm
should perform only a few key technique at each node of
the search tree. Furthermore, any implementation of such
an algorithm should perform these techniques in
quadratic time total down any path of the search tree,
and use only a linear amount of space. We have justified
these claims by writing POSIT (for PrOpositional
SatIsfiability Testbed), a SAT tester which runs more
quickly across a wide range of hard SAT problems than
any other SAT tester in the literature on comparable
platforms. On a Sun SPARCStation 10 running SunOS
4.1.3$sb0-$U1, POSIT can solve hard random 400-variable
3-SAT problems in about 2 hours on the average. In
general, it can solve hard n-variable random 3-SAT
problems with search trees of size $O(2sp0n/18.7).$
In addition to justifying these claims, this
dissertation describes the most significant achievements
of other researchers in this area, and discusses all of
the widely known general techniques for speeding up SAT
search algorithms. It should be useful to anyone
interested in NP-complete problems or combinatorial
optimization in general, and it should be particularly
useful to researchers in either Artificial Intelligence
or Operations Research.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  3465 </NUMBER>
<ORDER>   AAI9532165 </ORDER>
<TITLE> THE DESIGN AND IMPLEMENTATION OF A GENERAL PURPOSE ANALOG NEURAL COMPUTER AND ITS APPLICATION TO SPEECH RECOGNITION </TITLE>
<AUTHOR> DONHAM, CHRISTOPHER DAVID </AUTHOR>
<YEAR> 1995 </YEAR>
<INSTITUTION> UNIVERSITY OF PENNSYLVANIA; 0175 </INSTITUTION>
<DESCRIPTORS> ENGINEERING, ELECTRONICS AND ELECTRICAL; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> JAN VAN DER SPIEGEL </ADVISER>
<CLASSIFICATIONS> NIL </CLASSIFICATIONS>
<ABSTRACT>
Despite the advances in computer technology which have
been witnessed over the decades since Eniac was built,
modern digital computers are well suited only for tasks
that can be solved using the iterative application of
simple mathematical and logical operations. The human
brain, while unable to match a digital computer for such
operations, is a vastly superior tool for extracting
patterns from, and interacting with, a real-world
environment. This thesis examines the design,
implementation and application of a general purpose
analog neural computer which is inspired by current
knowledge of the neurobiology and psychology of the
brain. During the design discussion, the translation of
the principles of biological neuron operation to a
silicon model is considered. Then, the integration of
the silicon models into chips and subsequently into a
system is described. The second half of the thesis
evaluates the performance of the neural computer through
its application to biologically motivated speech
recognition. A recognition model is generated based on
current theories of human speech recognition and
production, in combination with neurological data on
hearing. This model is implemented in the neural
computer and the performance of the recognition system
is analyzed. Finally, the pros and cons of the neural
computer substrate is evaluated with regards to how the
computer affected the design and performance of the
speech recognition system.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  3466 </NUMBER>
<ORDER>   AAI9531933 </ORDER>
<TITLE> SEISMIC SIGNAL PATTERN RECOGNITION </TITLE>
<AUTHOR> HSU, CHAOMING </AUTHOR>
<YEAR> 1995 </YEAR>
<INSTITUTION> THE PENNSYLVANIA STATE UNIVERSITY; 0176 </INSTITUTION>
<DESCRIPTORS> PHYSICS, ELECTRONICS AND ELECTRICITY; ARTIFICIAL INTELLIGENCE; GEOTECHNOLOGY </DESCRIPTORS>
<ADVISER> SHELTON S. ALEXANDER </ADVISER>
<CLASSIFICATIONS> NEURAL NETWORKS, EARTHQUAKES </CLASSIFICATIONS>
<ABSTRACT>
In this study several artificial neural network pattern
recognition techniques have been developed and
implemented to discriminate between natural earthquakes
and underground explosions using entire seismic
signatures recorded at regional distances. Seismic
events collected from the regional array (NORESS) in
Norway and the single station (WMQ) in China are used
for the purpose of testing various seismic signal
discrimination methods. The starting point of this study
is the transformation of observed time-domain seismic
signals into spectrum-normalized and noise-corrected
frequency-velocity or frequency-slowness spectral
images. Artificial neural network (ANN) pattern
recognition models are then designed and applied to
these noise-corrected composite seismic images.
Recent developments indicate that artificial neural
networks are appropriate for solving difficult problems
in signal discrimination and classification. To test the
ANN models, the entire composite seismic images or
feature images are used as input to the ANN models.
Thus, the geophysical information content of the entire
seismic image can be fully utilized. Several design
strategies using neural network pattern recognition
methods for seismic event identification are
investigated and applied to actual data from several
geographical regions. These include multilayer
perceptron, image compression neural network and
reference image identification. The ANN techniques for
seismic event identification are the principal focus in
this study.
For data sets of 11 natural earthquakes and 11 mining
(chemical) explosions recorded by the NORESS array in
Norway and 15 natural earthquakes and 15 nuclear
explosions recorded by the single station WMQ in China,
each event group (earthquake or explosion) is found to
be separable by the ANNs in the feature space chosen.
The recognition results of three different neural
network methods to seismic event identification show
that these neural network approaches are all very
effective and suitable for near-real-time, automatic
event recognition. They have the advantages that entire
seismic signatures rather than small subsets of
observations are used in the recognition and once
trained, the ANNs can be applied automatically,
eliminating or minimizing the need for human
intervention in the identification process.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  3467 </NUMBER>
<ORDER>   AAI9535711 </ORDER>
<TITLE> THE NATURALIZATION OF REFERENCE </TITLE>
<AUTHOR> ARAKAWA, NAOYA </AUTHOR>
<YEAR> 1995 </YEAR>
<INSTITUTION> TEMPLE UNIVERSITY; 0225 </INSTITUTION>
<DESCRIPTORS> PHILOSOPHY; LANGUAGE, GENERAL; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> DAVID WELKER </ADVISER>
<CLASSIFICATIONS> SPEECH ACTS, ARTIFICIAL INTELLIGENCE </CLASSIFICATIONS>
<ABSTRACT>
In this dissertation, I try to explain the referential
relation, which is the relation holding among the
speaker of a linguistic expression, what the speaker
refers to, and the expression, in non-intentional terms.
The explanation I seek is one of how the referring
relation could be physically realized. In this regard, I
try to explain referring relations in terms of language
users' cognitive abilities (such as the abilities to
identify objects in the environment, to categorize
things, and to plan and perform speech acts) and argue
that those abilities could be physically realized. After
discussing the conditions for reference with various
kinds of linguistic expressions (e.g., proper names,
demonstratives, and definite descriptions), I try to
demonstrate that a system with a certain functional
architecture could make reference in order to show how
referring relation could be physically realized. Along
the way, representation by symbols is explained in non-
intentional terms.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  3468 </NUMBER>
<ORDER>   AAI9534075 </ORDER>
<TITLE> INTELLIGENT TRAFFIC EVALUATOR FOR PROMPT INCIDENT DIAGNOSIS IN A MULTI MEDIA ENVIRONMENT: INTREPID MM </TITLE>
<AUTHOR> SUTTAYAMULLY, SOMPRASONG </AUTHOR>
<YEAR> 1995 </YEAR>
<INSTITUTION> THE OHIO STATE UNIVERSITY; 0168 </INSTITUTION>
<DESCRIPTORS> TRANSPORTATION; ENGINEERING, CIVIL; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> FABIAN C. HADIPRIONO </ADVISER>
<CLASSIFICATIONS> NIL </CLASSIFICATIONS>
<ABSTRACT>
Incident-related congestion on freeways costs the nation
millions of dollars a year in loss of productivity,
property damage, and personal injuries. The situation on
rural freeways is even worse than that on urban freeways
because the resources required for appropriate incident
responses are not always nearby. In addition, high-tech
equipment--incident detection systems and closed-circuit
televisions, is not available to detect and verify
incidents on rural freeways in a short period of time.
Furthermore, on rural freeways, incident responses are
based only on the judgment of a patrol officer who is at
the scene. Unfortunately, an experienced officer may not
always be available for managing such a situation. And
if all of the burden is left on unskilled officers, they
may unintentionally provide over or under incident
responses due to the inconsistency or inconsiderateness
of their judgement. To provide quick and suitable
responses, a knowledge-based system for incident
management is needed. The INtelligent TRaffic Evaluator
for Prompt Incident Diagnosis or INTREPID was developed
as an intelligent system to assist a dispatcher to
manage an incident with proper responses. INTREPID is a
part of the Advanced Rural Traffic Management Systems
(ARTS) which is a component of the Intelligent Vehicle
Highway System (IVHS) and Intelligent Transportation
System (ITS). In contrast to other existing systems,
users can directly enter the key information gathered
from eyewitnesses to obtain responses from the proper
agencies and to request the proper equipment without
delay. This dissertation addresses the development
processes of INTREPID: the knowledge acquisition,
including interviewing and literature searching;
knowledge representation, which involves the development
of a decision tree and decision tables; the knowledge
base development, consisting of detailed design of the
knowledge base; and system implementation in a multi
media environment. All the components of INTREPID also
are described.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  3469 </NUMBER>
<ORDER>   AAI9532434 </ORDER>
<TITLE> STRUCTURAL ANALYSIS OF BUSINESS PROCESSES USING FUZZY REASONING IN VIEW OF BUSINESS PROCESS RE-ENGINEERING </TITLE>
<AUTHOR> SHRIVASTAVA, ATUL </AUTHOR>
<YEAR> 1995 </YEAR>
<INSTITUTION> UNIVERSITY OF ILLINOIS AT CHICAGO; 0799 </INSTITUTION>
<DESCRIPTORS> BUSINESS ADMINISTRATION, GENERAL; INFORMATION SCIENCE; OPERATIONS RESEARCH; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> NIL </ADVISER>
<CLASSIFICATIONS> NIL </CLASSIFICATIONS>
<ABSTRACT>
In the context of Business Process Re-engineering, this
study provided a framework to model and measure some of
the quintessential, structural properties of a business
process. A business process is modeled as an aggregation
of a number of subprocesses and the relationships among
those subprocesses. The subprocesses are modeled to have
properties such as Operational Intensity and
Informational Intensity. The relationships or links are
modeled to have properties such as Operational
Dependence, Informational Dependence, and Time Lag
Factor. Some of these properties are modeled as fuzzy or
vague.
A frame of cognition is used to model and process
fuzziness in the subprocess and the link properties.
Reference scales or base variables are defined for each
of the fuzzy properties. Fuzzy subsets are constructed
on the domain of these base variables. Fuzzy rules are
defined for deriving composite descriptors--
Synchronization Index and Informational Dependence
Index. Using fuzzy reasoning, these composite
descriptors are derived at the subprocess level. The
composite descriptors are aggregated to derive process-
level descriptors, that characterize the structural
complexity of a business process. The aggregate measures
are considered as surrogates to the effectiveness of a
process.
A comprehensive method is provided to model and measure
the aforementioned properties of a business process.
This method was applied to two sets of real-life
business processes. Processes before and after re-
engineering were measured for comparative analysis. The
measures brought out significant structural distinctions
between the before and after process configurations. It
is the belief that these measures can distinguish
between two or more competing process configurations and
help in the redesign of a business process.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  3470 </NUMBER>
<ORDER>   AAG9624376 </ORDER>
<TITLE> STRUCTURE AND MOTION ESTIMATION AND RECOGNITION FOR CURVED THREE-DIMENSIONAL OBJECTS </TITLE>
<AUTHOR> JOSHI, TANUJA ABHAY </AUTHOR>
<YEAR> 1995 </YEAR>
<INSTITUTION> UNIVERSITY OF ILLINOIS AT URBANA-CHAMPAIGN; 0090 </INSTITUTION>
<DESCRIPTORS> COMPUTER SCIENCE; ENGINEERING, ELECTRONICS AND ELECTRICAL; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> NARENDRA AHUJA </ADVISER>
<CLASSIFICATIONS> COMPUTER VISION, OBJECT RECOGNITION </CLASSIFICATIONS>
<ABSTRACT>
The main focus of research in computer vision in the
past has been on polyhedral objects that give rise to
viewpoint-independent edges in the image. This thesis
focuses on smooth curved objects that give rise to
viewpoint-dependent edges. The research presented
primarily focuses on the problems of structure and
motion estimation and object recognition.
In the first part of the thesis, the structure and
motion of a smooth object are estimated from its
silhouettes observed by a trinocular stereo rig over
time. First, a model is constructed for the local
structure along the silhouette for each frame in the
temporal sequence. The local models are then integrated
into a global surface description by estimating the
motion between successive frames. The algorithm tracks
certain surface features (parabolic points) and image
features (silhouette inflections and frontier points)
that are used to bootstrap the motion estimation
process. Points on the entire silhouette, along with the
reconstructed local structures, are then used to refine
the initial motion estimate. The proposed approach is
implemented and results obtained on real images are
presented.
The second part of the thesis presents a new algorithm
for recognition of curved 3D objects from 2D images. The
algorithm is based on a representation composed of a
discrete set of HOT curves at which the surface admits
High Order Tangents. A method is presented to
automatically construct two of the HOT curves (the
parabolic and limiting bitangent curves) using the
results of the above structure and motion estimation
algorithm. There is a natural correspondence between
these two HOT curves and certain silhouette features:
the inflections and the bitangents. The recognition
approach uses these silhouette features to compute a set
of scale-independent image observables that serve as
indices in a database of models. This database is used
for pose estimation and model identification. Hypotheses
formed through indexing are verified through pose
estimation. The results obtained on real images are
presented.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  3471 </NUMBER>
<ORDER>   AAI9533209 </ORDER>
<TITLE> A STRATEGY FOR THE SYNTHESIS OF REAL-TIME STATISTICAL PROCESS CONTROL WITHIN THE FRAMEWORK OF A KNOWLEDGE BASED CONTROLLER </TITLE>
<AUTHOR> CROWE, EDWARD R. </AUTHOR>
<YEAR> 1995 </YEAR>
<INSTITUTION> OHIO UNIVERSITY; 0167 </INSTITUTION>
<DESCRIPTORS> ENGINEERING, CHEMICAL; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> W. J. CHEN </ADVISER>
<CLASSIFICATIONS> NIL </CLASSIFICATIONS>
<ABSTRACT>
Artificial intelligence is a broad field of computer-
based technologies designed to emulate the cognitive
abilities demonstrated in human behavior. These emerging
technologies are being investigated for a wide variety
of applications. Statistical process control,
conversely, is a classical technique used in process
monitoring to detect abnormal variation of key
parameters. This research proposes a strategy to
integrate these technologies into an intelligent control
system that can detect an extrinsic disturbance,
identify the cause, and adjust its control parameters to
compensate for a drift in product quality.
This control strategy, applied to a continuous
distillation process, provides two distinct feedback
control schemes. The primary feedback control structure
is based on fuzzy logic. The auxiliary feedback scheme,
based on the integrated technologies of neural networks,
expert system, and statistical process control, is
designed to detect and compensate for assignable causes
that normally require human intervention. These
disturbances are automatically identified and the
control parameters modified to compensate for their
effects.
Two objectives were achieved in this study. First, the
performance of fuzzy logic control was evaluated in
comparison to conventional PID control. Second, the
dynamic pattern recognition capability of a neural
network was demonstrated by imposing disturbances on the
process. This was realized through the integration of
process data conditioned by a CUSUM charting technique.
This data was then used as the input vector to a
backpropagation neural network. The cause of the
disturbance was identified by the embedded neural
network trained off-line to recognize certain
disturbance patterns. A set of IF-THEN rules was used to
validate the disturbance classification.
The results of this research clearly show promise for
further integration of these technologies. Fuzzy logic
exhibited excellent control characteristics for both set
point and load changes. The neural network, with the
CUSUM interface, correctly identified each extrinsic
disturbance and initiated an algorithm to regulate the
product quality within established control limits.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  3472 </NUMBER>
<ORDER>   AAI9533205 </ORDER>
<TITLE> TEACHING ACCOMMODATION TASK SKILLS: FROM HUMAN DEMONSTRATION TO ROBOT CONTROL VIA ARTIFICIAL NEURAL NETWORKS </TITLE>
<AUTHOR> WHALEN, PAUL VINCENT </AUTHOR>
<YEAR> 1995 </YEAR>
<INSTITUTION> AIR FORCE INSTITUTE OF TECHNOLOGY; 0002 </INSTITUTION>
<DESCRIPTORS> ENGINEERING, ELECTRONICS AND ELECTRICAL; ENGINEERING, MECHANICAL; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> CURTIS H. SPENNY </ADVISER>
<CLASSIFICATIONS> SKILL ACQUISITION </CLASSIFICATIONS>
<ABSTRACT>
A simple edge-mating task, performed automatically by
accommodating control, was used to study the feasibility
of using data collected during a human demonstration to
train an artificial neural network (ANN) to control a
common robot manipulator to complete similar tasks. The
2-dimensional (planar) edge-mating task which aligns a
peg normal to a flat table served as the basis for the
investigation. A simple multilayered perceptron (MLP)
ANN with a single hidden layer and linear output nodes
was trained using the back-propagation algorithm with
momentum. The inputs to the ANN were the planar
components of the contact force between the peg and the
table. The outputs from the ANN were the planar
components of a commanded velocity. The controller was
architected so the ANN could learn a configuration-
independent solution by operating in the tool-frame
coordinates. As a baseline of performance, a simple
accommodation matrix capable of completing the edge-
mating task was determined and implemented in simulation
and on the PUMA manipulator. The accommodation matrix
was also used to synthesize various forms of training
data which were used to gain insights into the function
and vulnerabilities of the proposed control scheme.
Human demonstration data were collected using a gravity-
compensated PUMA 562 manipulator and using a custom-
built planar low-impedance motion measurement system
(PLIMMS). The raw demonstration data collected using
both systems were found to be poor examples of
accommodation mappings for reasons that are discussed.
In addition to the problem of the existence of the
desired mapping in the demonstration data, the
sensitivity of the ANN paradigm to the richness of the
training data was also determined. For the proposed
controller training method, a key problem is one of
matching the distribution statistics (mean and standard
deviation) between the training data and what is to be
encountered in the measurement stream when the trained
ANN controller is implemented. Seven data processing
algorithms were investigated independently and in
combinations to determine if they could improve the
quality of the demonstration data. None were found to
produce very robust results, although mirroring the raw
data about all the axes to force a zero mean upon the
training data set was found to improve controller
performance significantly.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  3473 </NUMBER>
<ORDER>   AAI9533202 </ORDER>
<TITLE> THE MATHEMATICS OF MEASURING CAPABILITIES OF ARTIFICIAL NEURAL NETWORKS  </TITLE>
<AUTHOR> CARTER, MARTHA AYERS ALVEY </AUTHOR>
<YEAR> 1995 </YEAR>
<INSTITUTION> AIR FORCE INSTITUTE OF TECHNOLOGY; 0002 </INSTITUTION>
<DESCRIPTORS> MATHEMATICS; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> MARK E. OXLEY </ADVISER>
<CLASSIFICATIONS> COMBINATORIAL GEOMETRY, V-C DIMENSION, HYPERPLANE ARRANGEMENTS </CLASSIFICATIONS>
<ABSTRACT>
Researchers rely on the mathematics of Vapnik and
Chervonenkis to capture quantitative measures of the
capabilities of specific artificial neural network (ANN)
architectures. The measure is known as the V-C dimension
of a set of sets, $0cal C,$ and is defined as the
largest cardinality l of a set of vectors in R$sp0d$
such that there is at least one set of vectors of
cardinality l such that all partitions of that set into
two sets can be represented by a set $fin0cal C.$ There
is an abundance of research on determining the value of
V-C dimensions of ANNs.
The fundamental thesis of this research is that the V-C
dimension is not an appropriate measure of ANN
capabilities. Consequently, the results of this research
provide a basis of mathematics on which to build more
intuitive quantifiers. Specifically, lattice structures
for ANNs are established upon which a generalized method
of invariant analysis of an arrangement of hyperplanes
can be examined. In addition, a generalized function of
invariants is presented as a mechanism for defining
capability quantifiers. Moreover, a quantifier is
defined based on an invariant, geometric complexity. The
invariant is defined by concepts of combinatorial
geometry.
Research on V-C dimension is refined and extended
yielding formulas for evaluating V-C dimension for
certain cases. As a consequence of the study of
combinatorial geometry of hyperplane arrangements, it is
shown that solutions to the chamber counting problem
that are based on analysis of the Poincare polynomial
also provide a closed form relation for determining the
value of the V-C dimension of ANNs.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  3474 </NUMBER>
<ORDER>   AAI9533196 </ORDER>
<TITLE> DESIGN UNDER UNCERTAINTY: ENGAGING THE CONTEXT OF USE IN THE DESIGN OF EXPERT SYSTEMS </TITLE>
<AUTHOR> WIECKERT, KAREN ELIZABETH </AUTHOR>
<YEAR> 1995 </YEAR>
<INSTITUTION> UNIVERSITY OF CALIFORNIA, IRVINE; 0030 </INSTITUTION>
<DESCRIPTORS> COMPUTER SCIENCE; BUSINESS ADMINISTRATION, MANAGEMENT; PSYCHOLOGY, INDUSTRIAL; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> JOHN KING </ADVISER>
<CLASSIFICATIONS> GROUNDED THEORY </CLASSIFICATIONS>
<ABSTRACT>
This dissertation considers the design of computational
artifacts in organizational settings. I uncover the
complexities of designing information technology in
organizational contexts by drawing from fieldwork on the
design of expert systems, although I offer
generalizations to designing information technology. The
unit of analysis is the process of constructing a
computational artifact, rather than the artifact itself.
In order to study process, I focused on the activities
of designers in organizational contexts, and considered
what resources (materials, tools, and methods) they
required to accomplish their work. I expand the
traditional view of the innovation--an expert system--by
focusing on what resources were afforded to the
designers adopting the expert system package of
materials, tools, and methods, in order to construct
these systems. I focus in detail on the developmental
trajectories of three expert system projects. Through
detailed explanations of events in development, I
foreground how the evolving expert systems were
projected into contexts of use, who constructed these
projections, and what force these projections had on the
artifact and the design process. I assume that the
design of any technological system relies upon
projections to fill the distances between the present in
the context of design and the future in the context of
use. I conclude by considering the essential needs for
projection in the design process and what other contexts
should be available in the design process for
constructing projections.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  3475 </NUMBER>
<ORDER>   AAI9531813 </ORDER>
<TITLE> AUTOMATED IMAGE INSPECTION USING WAVELET DECOMPOSITION AND FUZZY RULE-BASED CLASSIFIER </TITLE>
<AUTHOR> ZHANG, ZHONG </AUTHOR>
<YEAR> 1995 </YEAR>
<INSTITUTION> IOWA STATE UNIVERSITY; 0097 </INSTITUTION>
<DESCRIPTORS> ENGINEERING, ELECTRONICS AND ELECTRICAL; COMPUTER SCIENCE; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> JOHN P. BASART </ADVISER>
<CLASSIFICATIONS> NIL </CLASSIFICATIONS>
<ABSTRACT>
A general purpose image inspecting system has been
developed for automatic flaw detection in industrial
applications. The system has a general purpose image
understanding architecture that performs local feature
extraction and supervised classification. Local features
of an image are extracted from the compactly supported
wavelet transform of the image. The features extracted
from the wavelet transform provide local harmonic
analysis and multi-resolution representation of the
image. Image segmentation is achieved by classifying
image pixels based on features extracted within a local
area near each pixel. The supervised classifier used in
the segmentation process is a fuzzy rule-based
classifier which is established from the training data.
The fuzzy rule base that is used to control the
performance of the classifier is optimized by combining
similar training data into the same rule. Therefore an
optimization is achieved for the established rule base
to provide the maximum amount of information with the
minimum amount of rules. The experimental results show
that the features extracted from the wavelet
decomposition give contextual information for the test
images. The optimized fuzzy rule-based classifier gives
the best performance in both the training and the
classification stages. Flaws in the test images are
detected automatically by the computer.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  3476 </NUMBER>
<ORDER>   AAI9531745 </ORDER>
<TITLE> PROPAGATION OF UNCERTAINTY IN A KNOWLEDGE-BASED SYSTEM TO ASSESS ENERGY MANAGEMENT STRATEGIES FOR NEW TECHNOLOGIES </TITLE>
<AUTHOR> HSU, CHUN-YEN </AUTHOR>
<YEAR> 1995 </YEAR>
<INSTITUTION> IOWA STATE UNIVERSITY; 0097 </INSTITUTION>
<DESCRIPTORS> ENGINEERING, MECHANICAL; ENERGY; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> RON M. NELSON; JOHN W. LAMONT </ADVISER>
<CLASSIFICATIONS> FUZZY LOGIC </CLASSIFICATIONS>
<ABSTRACT>
The goal of this project is to investigate the
propagation of uncertainty in a knowledge-based system
that assesses energy management strategies for new gas
and electric technologies that can help reduce energy
consumption and demand. The new technologies that have
been investigated include lighting, electric heat pumps,
motors, refrigerators, microwave clothes dryers, freeze
concentration, electric vehicles, gas furnaces, gas heat
pumps, engine-driven chillers, absorption chillers, and
natural gas vehicles distributed throughout the
residential, commercial, industrial, and transportation
sectors.
The description of a complex assessment system may be
simplified by allowing some degree of uncertainty. A
number of uncertainty-representing mechanisms, such as
probability theory, certainty factors, Dempster-Shafer
theory, fuzzy logic, rough sets, non-numerical methods,
and belief networks, were reviewed and compared. The
proper application of uncertainty provides an effective
and efficient way to represent knowledge.
A knowledge-based system has been developed to assess
the impacts of rebate programs on customer adoption of
new technologies and, hence, the reductions in energy
and demand. Three modes have been programmed: (1) one in
which uncertainty is not considered, (2) another where
fuzzy logic with linguistic variables is used to
represent uncertainty, and (3) one in which uncertainty
is represented using Dempster-Shafer theory with basic
probability assignments. A correlation for rebate,
expected (energy) savings, and customer adoption is
employed in the knowledge base. Predictions for annual
adoption of a new technology are made for specified
useful life, rebate, and expected savings; or a
suggested rebate can be determined for specified useful
life, expected savings, and annual adoption. With input
for energy use and demand for each technology, the
impacts of rebate programs on energy use and power
demand can be evaluated.
This report and the knowledge-based system should help
utilities determine these new technologies that are most
promising and these strategies that should be emphasized
in their energy management programs.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  3477 </NUMBER>
<ORDER>   AAI9531641 </ORDER>
<TITLE> CASE-BASED REASONING FOR MISSION PLANNING, CONTROL, AND DECISION-MAKING  </TITLE>
<AUTHOR> VASUDEVAN, CHERANELLORE </AUTHOR>
<YEAR> 1995 </YEAR>
<INSTITUTION> FLORIDA ATLANTIC UNIVERSITY; 0119 </INSTITUTION>
<DESCRIPTORS> COMPUTER SCIENCE; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> K. GANESAN </ADVISER>
<CLASSIFICATIONS> UNDERWATER VEHICLES </CLASSIFICATIONS>
<ABSTRACT>
Case-based reasoning (CBR) is a powerful reasoning
paradigm for many application domains like planning,
diagnosis, classification, and decision making.
Recognizing solutions of past instances which are
similar to the problem in hand is the central concept of
CBR. Accordingly, the main research issues in CBR are
efficient indexing, retrieval, and evaluation of cases.
Generalization of indices has been a major concern as it
directly influences the size of casebases and the
ability to recognize the right candidate cases. This
dissertation work presents a novel indexing scheme--
using fuzzy sets to represent case indices and fuzzy
aggregation operators to evaluate case matches. The
proposed scheme, REFIC (REasoning from Fuzzy Indexed
Cases), provides a flexible and transparent scheme to
generalize case indices leading to smaller casebases. A
hierarchical aggregation of different index matches is
suggested for case evaluation. Also, for continuous
variable domains, it is proposed to combine the
solutions of a small subset of best matching cases as
opposed to the conventional approach of selecting and
modifying a single best one. These schemes are
demonstrated by implementing a case-based navigation
planner for autonomous underwater vehicles (AUVs). This
navigation planner comprises of an annotated map
database, a case-based path planner, and a hybrid fuzzy-
CBR based reactive navigation module. The annotated map
database provides a general framework for modeling the
navigational environment. Annotations attached to
objects and geometrical query handling are two main
features of this database. Using this system as a
spatial casebase, an off-line path planning system for
AUV missions is designed. The obstacle avoidance module
employs CBR to dynamically select promising directions
of movement and to activate a subset of navigational
behaviors. This reactive navigation scheme has been
found to be very robust under noisy sensor data and
complex obstacle distribution patterns.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  3478 </NUMBER>
<ORDER>   AAI9531579 </ORDER>
<TITLE> REAL TIME HYBRID TARGET RECOGNITION USING GENERALIZED AND WAVELET PRE-PROCESSED MATCHED FILTERS </TITLE>
<AUTHOR> IFTEKHARUDDIN, KHAN MOHAMMA </AUTHOR>
<YEAR> 1995 </YEAR>
<INSTITUTION> THE UNIVERSITY OF DAYTON; 0327 </INSTITUTION>
<DESCRIPTORS> ENGINEERING, ELECTRONICS AND ELECTRICAL; PHYSICS, OPTICS; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> M. A. KARIM </ADVISER>
<CLASSIFICATIONS> NEURAL NETWORKS </CLASSIFICATIONS>
<ABSTRACT>
One special type of complex matched filter (CMF),
namely, amplitude-modulated phase-only filter (AMPOF)
effectively utilizes both amplitude and phase
information to obtain a narrower and larger
autocorrelation peak. The AMPOF is optimized for
improved target recognition applications. Both
correlation performance and output signal-to-noise-ratio
(SNR) for this optimized filter are found to be enhanced
within the theoretically identified range of the filter
parameters. The real-time implementation issues for the
CMFs are addressed next. To assure real-time automatic
target recognition (ATR), we develop a generalized
expression for the family of CMFs. In particular, both
amplitude and phase of the AMPOF are ternerized to yield
an improved performance of the correlator. In order to
achieve rotation-invariance for the CMFs, we proposed an
amplitude-coupled minimum-average-correlation-energy
(MACE) filter. This amplitude-coupled MACE filter is
implemented and tested for its rotation invariance
feature. The algorithm is also investigated for
probability of correct classification using synthetic
aperture radar (SAR) images.
The relatively new but powerful tool, namely, wavelet
transform (WT) can also be utilized appropriately in the
processing of CMF. Accordingly a WT pre-processed AMPOF
is introduced and implemented next. It is evaluated in
terms of various target recognition performance
statistics. The effect of nonlinear thresholding in
suppressing noise has also been studied. The WT pre-
processed and nonlinear thresholded AMPOF is found to
yield significantly better performance than the AMPOF.
Finally, a hybrid character recognition system that uses
a feature extraction method is proposed. The features
are extracted using WT, pre-classified using a k-nearest
neighbor neural network and subsequently post-processed
using an optical correlator. This feature-based neural
wavelet optical architecture is finally tested on
blurred character images.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  3479 </NUMBER>
<ORDER>   AAI9531567 </ORDER>
<TITLE> A STATISTICAL TRAINING METHODOLOGY FOR PATTERN CLASSIFYING NEURAL NETWORKS </TITLE>
<AUTHOR> GRAZIANO, MICHAEL JOHN </AUTHOR>
<YEAR> 1995 </YEAR>
<INSTITUTION> POLYTECHNIC UNIVERSITY; 0179 </INSTITUTION>
<DESCRIPTORS> ENGINEERING, ELECTRONICS AND ELECTRICAL; MATHEMATICS; STATISTICS; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> GEORGE BACHMAN; PHILIP E. SARACHIK </ADVISER>
<CLASSIFICATIONS> NIL </CLASSIFICATIONS>
<ABSTRACT>
Multivariate statistical methods serve as the foundation
for a new neural network training paradigm that
determines nodal connectivity for pattern classifying
neural networks. A strictly feedforward, multilayer
design is considered as the general network
architecture. Simple linear processing serve as the
nodes or neurons. Such networks are trained to solve
four problems. The first is the classic Fisher Iris
Problem in which a four dimensional vector of iris
measurements must be classified into one of three
closely related species. A second problem involving
character recognition is then solved. Financial data
gleaned from bankrupt and fiscally sound corporations
serves as the basis of a binary classification example.
Finally, the training algorithm is applied to
forecasting the behavior of a class of general, low
order, autoregressive, integrated, moving average
(ARIMA) time series. Such processes are characterized by
periods of relatively constant level punctuated by
shifts to new level regions. The network provides as
output an indication of when and in what direction
(increasing or decreasing) the time series is about to
exhibit a transition from a region of local stability or
equilibrium. The general nature of the time series model
permits the use of these networks for analyzing
conventional, discrete time series models as well as
point and compound counting processes. Each problem is
in turn then solved by neural nets of similar
architecture that were trained via conventional
backpropagation. The performance of the two training
methods is found to be comparable; however, the speed
with which the statistical training algorithm determines
the network connections presents a clear advantage over
backpropagation. In addition, the multivariate
techniques on which the approach are based provides
enhanced insight into the network operation.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  3480 </NUMBER>
<ORDER>   AAG9624352 </ORDER>
<TITLE> ON EFFICIENT APPROACHES TO THE UTILITY PROBLEM IN ADAPTIVE PROBLEM SOLVING </TITLE>
<AUTHOR> GRATCH, JONATHAN MATTHEW </AUTHOR>
<YEAR> 1995 </YEAR>
<INSTITUTION> UNIVERSITY OF ILLINOIS AT URBANA-CHAMPAIGN; 0090 </INSTITUTION>
<DESCRIPTORS> COMPUTER SCIENCE; OPERATIONS RESEARCH; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> GERALD DEJONG </ADVISER>
<CLASSIFICATIONS> MACHINE LEARNING, SCHEDULING </CLASSIFICATIONS>
<ABSTRACT>
Domain independent general purpose problem solving
techniques are desirable from the standpoints of
software engineering and human computer interaction.
They employ declarative and modular knowledge
representations and present a constant homogeneous
interface to the user, untainted by the peculiarities of
the specific domain of interest. Unfortunately, this
very insulation from domain details often precludes
effective problem solving behavior. General approaches
have proven successful in complex real world situations
only after a tedious cycle of manual experimentation and
modification. Machine learning offers the prospect of
automating this adaptation cycle, reducing the burden of
domain-specific tuning and reconciling the conflicting
needs of generality and efficacy. To date, however, the
utility problem--the realization that adaptive
strategies that were intended to improve problem solving
performance would actually degrade performance under
difficult to predict circumstances--has impeded the
development of adaptive problem solving techniques. Even
systems designed to address the utility problem can
seriously impair problem solving behavior, as they have
incompletely accounted for the subtleties of the
problem. In order to develop a more rigorous approach to
adaptive problem solving, this thesis details a formal
framework that highlights these prior shortcomings, and
presents a statistically rigorous solution to the
utility problem. Based on clearly articulated and well-
motivated assumptions, this statistical method is
applied successfully to learning heuristics for several
artificial and a real-world problem solving
applications. Although the focus of this work is on
adaptive planning and scheduling, the results of this
research have wider implications for operations
research, software simulation, and decision-tree
learning.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  3481 </NUMBER>
<ORDER>   AAI9531341 </ORDER>
<TITLE> PULSE OXIMETRY ARTIFACT DETECTION USING ARTIFICIAL NEURAL NETWORKS  </TITLE>
<AUTHOR> EGBERT, TIMOTHY P. </AUTHOR>
<YEAR> 1995 </YEAR>
<INSTITUTION> THE UNIVERSITY OF UTAH; 0240 </INSTITUTION>
<DESCRIPTORS> ENGINEERING, BIOMEDICAL; BIOPHYSICS, MEDICAL; HEALTH SCIENCES, HOSPITAL MANAGEMENT; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> DWAYNE R. WESTENSKOW </ADVISER>
<CLASSIFICATIONS> OXYGEN SATURATION </CLASSIFICATIONS>
<ABSTRACT>
The object of pulse oximetry is to provide continuous
estimates of arterial blood oxygen saturation
(SpO$sb2$), usually expressed as a percent, through
noninvasive means. Most of the factors that can
influence the accuracy of pulse oximeters are rare, can
be avoided or have been sufficiently ameliorated by
device engineering. One factor that continues to be a
problem is signal disturbance and consequent
inaccuracies brought on by patient motion. This research
uses the artificial neural network (ANN) as a pattern
recognition technique for postprocessing pulse oximeter
signals for motion artifact detection.
A treatment of basic pulse oximetry theory that
describes the theoretical underpinnings for an
understanding of the effects of artifact on pulse
oximetry signals is first presented.
The development of two ANN artifact detection systems
for detecting motion artifact is presented. Training
data waveforms were classified by a human expert as
"good" or "bad." One ANN correctly classified 94.9% and
the other ANN 90.66% of the good and bad waveforms that
were reserved for testing.
The results of two studies to evaluate the artifact
detection system performance are then presented. The
first study involved eleven volunteers who produced
controlled levels of motion artifact for 20 second time
intervals. The ANN artifact detection systems correctly
classified the data for all 51 of the motion artifact
events.
The second study incorporated the best artifact
detection system into an artifact rejection algorithm
which was used to process 212 hours of postsurgical
patient data from 14 patients on the hospital floor.
Performance was compared to that of an expert human
observer (the author). The total number of apparent
desaturation episodes (defined as SpO$sb2<90$% for at
least ten seconds) before artifact rejection was 554.
The ANN system found 349 episodes to be reliable and the
human expert found 354 to be reliable. Only 12 episodes
were classified differently. Similar results were
obtained for two other human experts.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  3482 </NUMBER>
<ORDER>   AAI9531293 </ORDER>
<TITLE> PATTERN RECOGNITION AND CLASSIFICATION IN USER MODELING: A NEURAL NETWORK APPROACH </TITLE>
<AUTHOR> CHEN, QIYANG </AUTHOR>
<YEAR> 1995 </YEAR>
<INSTITUTION> UNIVERSITY OF MARYLAND BALTIMORE COUNTY; 0434 </INSTITUTION>
<DESCRIPTORS> COMPUTER SCIENCE; BUSINESS ADMINISTRATION, MANAGEMENT; ENGINEERING, INDUSTRIAL; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> ANTHONY F. NORCIO </ADVISER>
<CLASSIFICATIONS> ADAPTIVE SYSTEM RESPONSES, COOPERATIVE FUNCTIONS </CLASSIFICATIONS>
<ABSTRACT>
In order to generate adaptive system responses to
individual users, it is often necessary that a system
establishes and maintains various hypothetical beliefs
about users' task-related characteristics. This process
is referred to as user modeling. An interface system
equipped with user models can exhibit cooperative
functionality and effective performance.
This study proposes a user modeling approach that
utilizes neural networks as the knowledge base and
reasoning mechanism. This approach organizes system
beliefs into associative memories. This approach
suggests that user modeling be a process of pattern
recognition and classification, in order to capture
complete and consistent profiles about users. A set of
neural networks is used to associate an incomplete
pattern about a user's domain knowledge with a complete
hypothetical knowledge pattern that characterizes the
user. Also, such patterns can be further classified into
different categories in terms of the similarities.
The structure of neural network based user modeling is
presented. Several different network paradigms, such as
Back-propagation, ART, and Bidirection Linear
Associator, are tested and integrated for pattern
association and pattern classification. The experimental
results are discussed in terms of the completeness,
consistency, and generalization. The study shows that
the proposed approach not only has the merits of
conventional modeling approaches, such as fast
stereotyping and assumption inheritances, but also
facilitates the system performance in default reasoning,
personalization, and knowledge elicitation.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  3483 </NUMBER>
<ORDER>   AAI9531246 </ORDER>
<TITLE> BELIEVABLE CONFLICT MANAGEMENT FOR DECENTRALIZED INTELLIGENT SYSTEMS </TITLE>
<AUTHOR> LEHMAN, TODD PAUL </AUTHOR>
<YEAR> 1995 </YEAR>
<INSTITUTION> FLORIDA INSTITUTE OF TECHNOLOGY; 0473 </INSTITUTION>
<DESCRIPTORS> COMPUTER SCIENCE </DESCRIPTORS>
<ADVISER> ROBERT A. MORRIS </ADVISER>
<CLASSIFICATIONS> NIL </CLASSIFICATIONS>
<ABSTRACT>
This dissertation presents original research that
contributes new advances to the field of Distributed
Artificial Intelligence (DAI). There is considerable
talk these days of the desirability of designing and
building "believable" agents, ones whose behavior is
similar to that found in humans. Believable agents are
desirable because they promote trust by human users
interacting with them. This criterion of believability
should extend to whole societies of computing agents.
That is, the behavior of the "computing society" as a
whole should be believable. This includes the ability of
agents to resolve conflicts that naturally occur in open
systems, just as they do in human societies.
My hypothesis is that based on the unavoidable existence
of conflict in open systems comprised of multiple agents
it is necessary to build agents that are capable of
reasoning conflicts in a manner that makes them
"believable" from the standpoint of human cognitive
abilities. There are two points of departure in this
investigation. The first stems from a common sense
theory of the cognitive abilities underlying conflict
management, including the regimentation of common sense
found in sociological, psychological, and economic
theory. The second is the computational model of
diagnostic problem solving. There are salient
similarities between the stages of the diagnostic
process and the way human conflict is detected,
classified, and resolved. Because diagnosis offers a
model of computation, it can be applied in the design of
systems of computational agents that are capable of
conflict resolution. The goal will be a computational
model of conflict management that functions "believably"
in multi-agent environments resulting in conflict
resolution.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  3484 </NUMBER>
<ORDER>   AAI9530974 </ORDER>
<TITLE> A COMMUNICATION AND COOPERATION SCHEME TO SUPPORT DISTRIBUTED KNOWLEDGE-BASED SYSTEMS </TITLE>
<AUTHOR> BAEK, GYUTAE </AUTHOR>
<YEAR> 1995 </YEAR>
<INSTITUTION> LEHIGH UNIVERSITY; 0105 </INSTITUTION>
<DESCRIPTORS> COMPUTER SCIENCE; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> DONALD J. HILLMAN </ADVISER>
<CLASSIFICATIONS> NIL </CLASSIFICATIONS>
<ABSTRACT>
Distributed Artificial Intelligence (DAI) is the
subfield of AI research concerned with concurrency in AI
computations. Many activities of each agent during
problem solving in this research must involve some
interaction with other distributed agents in order to
work together and solve complex problems requiring
combined expertise.
This dissertation describes an approach to communication
and cooperation in distributed knowledge-based systems
which allows agents to exchange and understand
information and solve common problems collaboratively.
This work presents several concepts necessary for a
rational interaction among distributed agents to solve
complex and distributed problems, that consists of a
transmission concept, a translation concept and a
cooperation concept. The transmission concept has been
established to provide a concurrent communication method
which transfers messages efficiently and does not
interrupt other agents' independent processes. The
translation concept has been developed to improve the
exchange of knowledge with understanding of knowledge
and support sharing of knowledge during problem-solving.
The cooperation concept has the dialogue fashion during
the problem solving process to integrate actions and
collaborate tasks, and achieve mutual goals.
The result of research is demonstrated as a prototype
within a KBS called the Cooperative Design Support
Environment (CDSE). This research project is one of
several KBS projects in design and construction
information systems cluster at the Advanced Technologies
for large Structure System (ATLSS) sponsored by National
Science Foundation (NSF). The CDSE system allows
distributed structure engineers to design cooperatively
alternatives of steel connection in preliminary design
and evaluate from multiple agents' perspectives, and
select the steel connection design which is the
feasible.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  3485 </NUMBER>
<ORDER>   AAI9530719 </ORDER>
<TITLE> ROENTGEN: A CASE-BASED RADIATION TREATMENT PLANNER </TITLE>
<AUTHOR> BERGER, JEFFREY </AUTHOR>
<YEAR> 1995 </YEAR>
<INSTITUTION> THE UNIVERSITY OF CHICAGO; 0330 </INSTITUTION>
<DESCRIPTORS> COMPUTER SCIENCE; ARTIFICIAL INTELLIGENCE; HEALTH SCIENCES, MEDICINE AND SURGERY </DESCRIPTORS>
<ADVISER> KRISTIAN J. HAMMOND </ADVISER>
<CLASSIFICATIONS> NIL </CLASSIFICATIONS>
<ABSTRACT>
This dissertation describes an artificial intelligence
approach to the problem of radiation treatment planning.
In particular, it describes a case-based reasoning (CBR)
system, Roentgen, that uses past treatment plans and
past repair episodes to arrive at plans for new
patients.
While radiation treatment planning (RTP) is a domain
that is inherently geometric, most previous CBR efforts
deal with domains that are more symbolic and qualitative
in nature. Design repair is a significant issue in RTP
since the first attempt to produce a good plan almost
always falls short of what is desired and the
improvement of even an almost acceptable treatment plan
so that it is acceptable can be a conditional and
iterative process. The character of the interaction
between the human and computer is important since the
well-being of the patient demands that a human expert be
embedded in the design loop. Hence, the main issues
examined in this dissertation include indexing,
geometric reasoning, design repair and human/computer
interaction.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  3486 </NUMBER>
<ORDER>   AAI9530636 </ORDER>
<TITLE> A PARALLEL RECOGNITION SYSTEM FOR ARABIC CURSIVE WORDS WITH NEURAL LEARNING CAPABILITIES </TITLE>
<AUTHOR> ALTUWAIJRI, MAJID MOHAMMED </AUTHOR>
<YEAR> 1995 </YEAR>
<INSTITUTION> UNIVERSITY OF SOUTHWESTERN LOUISIANA; 0233 </INSTITUTION>
<DESCRIPTORS> COMPUTER SCIENCE; ENGINEERING, ELECTRONICS AND ELECTRICAL; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> MAGDY A. BAYOUMI </ADVISER>
<CLASSIFICATIONS> OPTICAL CHARACTER, NEURAL NETWORKS </CLASSIFICATIONS>
<ABSTRACT>
Recognizing multi-font Arabic texts is a difficult task
in the area of optical character recognition (OCR)
because Arabic is a cursive type language. The first
chapter presents some of the work done in this field.
The scope of the surveyed work varies with respect to
complexity from printed isolated characters to
handwritten words.
In this work, a new system for recognizing multi-font
Arabic texts is proposed. Efficient preprocessing,
segmentation, and preclassification algorithms have been
designed and implemented to achieve this objective.
A new segmentation algorithm that has some recognition
capabilities is proposed. The segmentation of words into
characters consists of two main steps. The first step
segments words into subwords by assigning a different
color code for each connected component of the word. The
second step segments subwords into characters. It
produces the segmented characters along with some
information including, the character form, the character
height, and the color codes of the primary and secondary
parts of the character. Based on these information the
Arabic character set which includes 100 character
classes has been decomposed into 8 small sets. The
largest set includes only 12 character classes. This
preclassification technique reduces the learning time
taken by the classifier and increases the recognition
rate. It also enhances the parallelism so that
characters in different forms can be recognized
simultaneously.
Several features are examined for the purpose of
selecting good features for Arabic characters. The
actual classification is done using multi-layer
perceptrons with back-propagation learning. This paper
discusses the details of each algorithm and its
performance on samples from several texts. The system
shows a high accuracy of over 98%.
The high speed necessary for real time applications may
be achieved with emerging parallel processors.
Therefore, some of the algorithms presented in this work
are mapped to parallel algorithms to be executed on
parallel machines. As a case study, the MasPar, which is
a 2-D mesh architecture machine, is used as our
experimental tool.
Finally, two skeletonization algorithms suitable for
Arabic characters are proposed. These algorithms can be
used in systems that require thinning.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  3487 </NUMBER>
<ORDER>   AAI9530559 </ORDER>
<TITLE> FUZZY-NEURAL SLIDING MODE CONTROLLER AND ITS APPLICATION TO THE VEHICLE ANTI-LOCK BRAKING SYSTEMS </TITLE>
<AUTHOR> KUEON, YEONGSEOB </AUTHOR>
<YEAR> 1995 </YEAR>
<INSTITUTION> WAYNE STATE UNIVERSITY; 0254 </INSTITUTION>
<DESCRIPTORS> ENGINEERING, MECHANICAL; ENGINEERING, ELECTRONICS AND ELECTRICAL; ENGINEERING, AUTOMOTIVE; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> JATINDER S. BEDI; PAWEL KARLIC </ADVISER>
<CLASSIFICATIONS> NIL </CLASSIFICATIONS>
<ABSTRACT>
One of the major problems in designing the controller
for the vehicle anti-lock braking systems is finding the
appropriate control algorithms to rejecting the
parameter uncertainties such as friction coefficient,
road elevation, wind gust, road superelevation, vehicle
absolute speed, and so on. A new class of algorithms is
developed by combining sliding mode control technique
and fuzzy logic control theory with artificial neural
networks to achieve the following things: The most
important function of the vehicle anti-lock braking
controller is to provide the vehicle with sufficient
stopping ability without sacrificing the vehicle
stability and the steerability. The proposed controller
outperforms fuzzy-sliding mode controller and feedback
linearization and sliding mode controllers. The proposed
fuzzy-neural-sliding mode controller shows that the
performance of the vehicle ABS systems has been improved
when fuzzy-sliding mode controller was combined with
artificial neural networks since artificial neural
networks have abilities such as learning, adaptation,
and so on.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  3488 </NUMBER>
<ORDER>   AAI9530441 </ORDER>
<TITLE> RELATIONS AND FUNCTIONAL RELATIONS IN CATEGORIES, WITH EXAMPLES FROM FUZZY SET THEORY </TITLE>
<AUTHOR> JAYEWARDENE, ROMAINE D. </AUTHOR>
<YEAR> 1995 </YEAR>
<INSTITUTION> CARNEGIE-MELLON UNIVERSITY; 0041 </INSTITUTION>
<DESCRIPTORS> MATHEMATICS; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> OSWALD WYLER </ADVISER>
<CLASSIFICATIONS> NIL </CLASSIFICATIONS>
<ABSTRACT>
Relations in finitely complete categories with (cover,
image)-factorization structures for morphisms with
epimorphic covers and monomorphic images, have been
studied by various authors. Fuzzy set theory provides us
with examples of finitely complete categories with
(cover, image)-factorization structures for morphisms
with images still monomorphic, but covers no longer
epimorphic. Relations in finitely complete categories
having this factorization structure for morphisms are
studied here.
Consider a finitely complete category A with a (cover,
image)-factorization structure for morphisms, with
monomorphic images. A class $0cal Msb0$ of
representative morphisms for $0cal M,$ the class of
images in A, can be obtained by selecting a morphism
from each equivalence class of monomorphisms in $0cal
M.$ Relations from A to B for objects A and B of A can
be defined using the morphisms in $0cal Msb0$ with
codomain the product $Atimes B.$ If pullbacks of covers
by legs of relations are covers in A, then the relations
of A are the morphisms of a category Rel A, with objects
the objects of A. Functional relations are the morphisms
of a subcategory cx A of Rel A, and the relations
induced by morphisms in A are the morphisms of a
subcategory Ind A of cx A. cx A and Ind A are both
finitely complete categories that have (cover, image)-
factorization structures for morphisms, with epimorphic
covers and monomorphic images. $0cal Msb0$ provides us
with a class of representative morphisms $0cal Msb0$ for
$0cal M,$ the class of images in cx A. Every functional
relation in cx A is induced by a morphism in cx A. The
category Rel A is isomorphic to the category Rel cx A,
and this isomorphism preserves and reflects functional
relations and induced functional relations.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  3489 </NUMBER>
<ORDER>   AAI9530427 </ORDER>
<TITLE> HOMOTROPY APPROACHES FOR THE ANALYSIS AND SOLUTION OF NEURAL NETWORK AND OTHER NONLINEAR SYSTEMS OF EQUATIONS </TITLE>
<AUTHOR> COETZEE, FRANS MARTIN </AUTHOR>
<YEAR> 1995 </YEAR>
<INSTITUTION> CARNEGIE-MELLON UNIVERSITY; 0041 </INSTITUTION>
<DESCRIPTORS> ENGINEERING, ELECTRONICS AND ELECTRICAL; STATISTICS; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> V. L. STONICK </ADVISER>
<CLASSIFICATIONS> NIL </CLASSIFICATIONS>
<ABSTRACT>
In this thesis, we use constructive homotopy methods
both to geometrically explore the mapping capabilities
of finite neural networks, and to rigorously develop a
robust method for computing optimal solutions to systems
of nonlinear equations which, like neural network
equations, have an unknown number of solutions and may
have solutions at infinity.
First, a geometric perspective is presented which
separates a general input-output optimization problem
into a finite-dimensional projection problem, and a
manifold parameterization problem. Using this separation
the topology of the solutions can be characterized using
natural homotopy and differential geometry, while
simultaneously yielding quantitative and intuitive
insight into the mapping abilities of the nonlinear
system. This approach is applied to a natural homotopy
between linear and nonlinear feedforward neural
networks, thereby extending the valuable geometric
representations of the linear network properties to
nonlinear networks. Consequently, we identify conditions
under which an unique solution is guaranteed, and when
infinite or multiple, either isolate or functionally
related, weight solutions arise, thereby facilitating
future constructive design of optimal and parasimonious
nonlinear networks.
A new algorithm is developed which connects disjointed
homotopy path segments by solving a secondary homotopy
equation on a manifold intersecting these path segments.
This approach finds multiple solutions is unknown. We
develop an efficient numerical implementation for
continuation on general embedded manifolds using only
local coordinate maps, and demonstrate performance
advantages on standard optimization benchmark problems.
Using this algorithm is found that neural network
equations have an extraordinary number of saddle points
relative to the number of minima, making inefficient any
training method which computes the absolute minimum by
exhaustively finding all stationary points.
Many of the geometric results developed in the thesis
are directly applicable to, or can be extended to,
alternative nonlinear structures and performance
measures. The two-stage homotopy approach is expected to
be independently valuable for other applications,
including nonlinear circuit simulation, and the
numerically-robust continuation algorithms developed
allow for rapid prototypes of new homotopies defined on
arbitrary manifolds.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  3490 </NUMBER>
<ORDER>   AAI9529839 </ORDER>
<TITLE> NEURAL NETWORKS IN BIOPROCESSING AND CHEMICAL ENGINEERING  </TITLE>
<AUTHOR> BAUGHMAN, DONALD RICHARD </AUTHOR>
<YEAR> 1995 </YEAR>
<INSTITUTION> VIRGINIA POLYTECHNIC INSTITUTE AND STATE UNIVERSITY; 0247 </INSTITUTION>
<DESCRIPTORS> ENGINEERING, CHEMICAL; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> Y. A. LIU </ADVISER>
<CLASSIFICATIONS> PROCESS FORECASTING, EXPERT SYSTEMS </CLASSIFICATIONS>
<ABSTRACT>
This dissertation introduces the fundamental principles
and practical aspects of neural networks, focusing on
their applications in bioprocessing and chemical
engineering. This study introduces neural networks and
provides an overview of their structures, strengths, and
limitations, together with a survey of their potential
and commercial applications (Chapter 1). In addition to
covering both the fundamental and practical aspects of
neural computing (Chapter 2), this dissertation
demonstrates, by numerous illustrative examples,
practice problems, and detailed case studies, how to
develop, train and apply neural networks in
bioprocessing and chemical engineering. This study
includes the neural network applications of interest to
the biotechnologists and chemical engineers in four main
groups: (1) fault classification and feature
categorization (Chapter 3); (2) prediction and
optimization (Chapter 4); (3) process forecasting,
modeling, and control of time-dependent systems (Chapter
5); and (4) preliminary design of complex processes
using a hybrid combination of expert systems and neural
networks (Chapter 6).
This dissertation is also unique in that it includes the
following ten detailed case studies of neural network
applications in bioprocessing and chemical engineering:
(1) Process fault-diagnosis of a chemical reactor. (2)
Leonard-Kramer fault-classification problem. (3) Process
fault-diagnosis for an unsteady-state continuous stirred-
tank reactor system. (4) Classification of protein
secondary-structure categories. (5) Quantitative
prediction and regression analysis of complex chemical
kinetics. (6) Software-based sensors for quantitative
predictions of product compositions from fluorescent
spectra in bioprocessing. (7) Quality control and
optimization of an autoclave curing process for
manufacturing composite materials. (8) Predictive
modeling of an experimental batch fermentation process.
(9) Supervisory control of the Tennessee Eastman
plantwide control problem. (10) Predictive modeling and
optimal design of extractive bioseparation in aqueous
two-phase systems. This dissertation also includes a
glossary, which explains the terminology used in neural
network applications in science and engineering.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  3491 </NUMBER>
<ORDER>   AAGNN08515 </ORDER>
<TITLE> ARCHITECTURE DE SYSTEME TUTORIEL INTELLIGENT POUR L'ANALYSE DU RAISONNEMENT DE L'APPRENANT </TITLE>
<AUTHOR> DJAMEN, JEAN-YVES </AUTHOR>
<YEAR> 1995 </YEAR>
<INSTITUTION> UNIVERSITE DE MONTREAL (CANADA); 0992 </INSTITUTION>
<DESCRIPTORS> COMPUTER SCIENCE; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> CLAUDE FRASSON; MARC KALTENBACH </ADVISER>
<CLASSIFICATIONS> FRENCH TEXT, TUTORIALS, MACHINE LEARNING, COMPUTER ARCHITECTURE, ARTIFICIAL INTELLIGENCE </CLASSIFICATIONS>
<ABSTRACT>
"Il y a de la valeur a surmonter les difficultes ... "
(Claude Frasson, 11 avril 1995) Les systemes tutoriels
intelligents sont des programmes informatiques qui
simulent le comportement des enseignants et des
apprenants dans un contexte de formation. Ces systemes
sont nes d'une volonte d'adapter l'enseignement a un
individu. Les difficultes de conception et de
developpement de ces systemes sont traitees par certains
travaux en intelligence artificielle. vskip9pt
La simulation de l'intelligence humaine dans un systeme
tutoriel intelligent peut prendre plusieurs facettes. De
nombreux systemes developpes se sont bases sur une
architecture de systeme tutoriel intelligent composee de
modules decrivant quatre expertises importantes: (a) la
matiere a enseigner, (b) l'etat des connaissances de
l'apprenant, (c) l'art et la maniere d'enseigner et (d)
les diverses formes d'interaction avec l'apprenant.
Certains interets recents font aussi reference aux
differentes formes que devrait prendre un enseignement
automatise, et plaident pour la prise en compte d'autres
incarnations de l'enseignant et/ou de l'apprenant dans
le meme contexte de formation, ou encore pour certaines
perspectives liees a la vie sociale de l'apprenant.
Les differents axes de recherches, ainsi que les
systemes developpes, ont surtout permis de comprendre
que la simulation de l'intelligence dans un enseignement
automatise passe par une bonne appreciation des
raisonnements qui se font pendant la formation, et
singulierement ceux qui sont exhibes par l'apprenant a
travers ses differentes interactions avec le systeme.
Nous proposons dans cette these une architecture de
systeme tutoriel intelligent adaptee a une bonne analyse
du raisonnement de l'apprenant. Cette recherche prend
son importance a la lumiere des limites des techniques
d'intelligence artificielle utilisees pour representer
les connaissances etudiees.
La theorie PIF que nous proposons dans cette these
integre l'essentiel des perspectives necessaires et
suffisantes pour la conception et le developpement des
systemes tutoriels intelligents. En effet, ell
apprehende le monde etudie sous trois angles essentiels,
mettant respectivement en exergue ses structurations
physique, intentionnelle et fonctionnelle.
Une des contributions importantes de ce travail consiste
a donner un nouveau depart a la recherche dans les
systemes tutoriels intelligents, a travers une
architecture commune pour analyser differents formes de
raisonnement de l'apprenant.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  3492 </NUMBER>
<ORDER>   AAI9529814 </ORDER>
<TITLE> IDENTIFICATION AND FUZZY LOGIC CONTROL OF NONLINEAR DYNAMICAL SYSTEMS  </TITLE>
<AUTHOR> KAYMAZ, EMRE </AUTHOR>
<YEAR> 1995 </YEAR>
<INSTITUTION> TEXAS TECH UNIVERSITY; 0230 </INSTITUTION>
<DESCRIPTORS> ENGINEERING, ELECTRONICS AND ELECTRICAL; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> SUNANDA MITRA </ADVISER>
<CLASSIFICATIONS> NEURAL NETWORKS, CONTROLLERS, MANIPULATORS </CLASSIFICATIONS>
<ABSTRACT>
A generalized controller based on fuzzy clustering and
fuzzy generalized predictive control has been developed
for nonlinear systems. The proposed controller is
particularly useful when the dynamics of the nonlinear
system to be controlled are difficult to yield exact
solutions and the system specification can be obtained
in terms of crisp input-output pairs. It inherits the
advantages of both fuzzy logic and predictive control.
The identification of the nonlinear mapping of the
system to be controlled is realized by a three-layer
feed-forward neural network model employing the input-
output data obtained from the system. The speed of
convergence of the neural network is improved by the
introduction of a fuzzy logic controlled backpropagation
learning algorithm. The use of fuzzy clustering
facilitates automatic generation of membership relations
of the input-output data. Unlike the linguistic fuzzy
logic controller which requires approximate knowledge of
the shape and the numbers of the membership functions in
the input and output universes of the discourse, this
integrated neuro-fuzzy approach allows one to find the
fuzzy relations and the membership functions more
accurately. Furthermore, there is no need for tuning the
controller. The proposed controller is applied to a
nonlinear heating/cooling system and a multilink robot
manipulator and it is shown that its performance is
superior to the performances of the currently employed
conventional controllers both in terms of accuracy and
energy consumption.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  3493 </NUMBER>
<ORDER>   AAI9529810 </ORDER>
<TITLE> CHAOS AND LEARNING IN RECURRENT NEURAL NETWORKS </TITLE>
<AUTHOR> CORWIN, EDWARD MONROE </AUTHOR>
<YEAR> 1995 </YEAR>
<INSTITUTION> TEXAS TECH UNIVERSITY; 0230 </INSTITUTION>
<DESCRIPTORS> COMPUTER SCIENCE; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> WILLIAM J. B. OLDHAM </ADVISER>
<CLASSIFICATIONS> MACHINE LEARNING </CLASSIFICATIONS>
<ABSTRACT>
Recurrent neural networks have received a great deal of
attention recently because of the variety of dynamic
behaviors produced by such networks. However, attempts
to train recurrent networks to produce chaotic behavior
have met with great difficulty. This work examines a
fundamental problem with training recurrent neural
networks to produce discrete chaotic sequences and
proposes a training approach which addresses the
difficulties outlined.
A major result of this work is a proof that a continuous
model, with a bounded derivative, for a discrete chaotic
system does not exist. The implication of this result is
to motivate a training algorithm derived using discrete
mathematics. Other algorithms assume the existence of a
continuous model, which has now been shown not to exist.
Networks were trained to several data sets using the
traditional continuous methods and the discrete
algorithm. The discrete rule improved training accuracy
for all networks for the given data sets. The discrete
training rule, for which one time step and multiple time
step variations are presented, produced better results
than Logar's training rule for the Aihara-style network
and better results than Pearlmutter's algorithm for his
network. A simplified proof of Hayashi's training rule,
based on discrete mathematics is also presented and has
the advantage of being extendible to a recursive
multiple time step training algorithm. A new hybrid
network, and the associated learning rules, is also
presented in which coupled oscillators are positioned
inside of a feed forward network. This approach
alleviates some of the difficulties inherent in training
a pure oscillator network and greatly improved training
accuracy.
Extensions to the weight projections algorithm are also
presented. The main results are that a quadratic
approximation is the most effective choice for fitting a
curve to the weight trajectory, that the extrapolation
distance can be doubled if points generated later in the
trajectory are more heavily weighted than those
generated earlier, and that a goodness of fit test can
detect a poor projection in advance of making the
extrapolation.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  3494 </NUMBER>
<ORDER>   AAI9529738 </ORDER>
<TITLE> ADAPTIVE RECOGNITION OF TEMPORALLY CHANGING PATTERNS </TITLE>
<AUTHOR> MIRFAKHRAEI, KHASHAYAR </AUTHOR>
<YEAR> 1995 </YEAR>
<INSTITUTION> THE UNIVERSITY OF UTAH; 0240 </INSTITUTION>
<DESCRIPTORS> ENGINEERING, ELECTRONICS AND ELECTRICAL; ENGINEERING, BIOMEDICAL; COMPUTER SCIENCE; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> NIL </ADVISER>
<CLASSIFICATIONS> NEURAL NETWORK </CLASSIFICATIONS>
<ABSTRACT>
In problems involving pattern recognition, it is
sometimes the case that the patterns involved change
with time. It may be desirable for a pattern recognizer,
if used on a long-term basis, to be able to track these
changes without any a priori knowledge of whether or how
they occur. Traditionally, unsupervised pattern
recognition is the approach taken to solve such
problems; however, this may not be as effective as a
supervised approach. In particular, overlap in the
geometric distributions of samples, corresponding to
different patterns in a problem, impairs the performance
of unsupervised classifiers.
This dissertation introduces a novel method as an
alternative to unsupervised classification for tracking
temporally changing patterns. The study's particular
focus is on classifying shapes of action potentials in
chronic neural recordings whose behavior is similar to
the type of recognition problem described above.
In the second chapter of the thesis, the problem of
classifying patterns in the context of acute neural
recordings is addressed. Because identified samples of
different patterns in a recording were available and the
distribution of the noise involved was poorly modelled,
a customized feed forward multilayer perceptron
Artificial Neural Network (ANN) architecture was used as
a supervised nonparametric classifier. The ANN was
trained with a back error propagation algorithm and when
tested on data from 20 different recording experiments,
the ANN classifier outperformed a previously developed
supervised statistical classifier.
In the third chapter of the thesis, the adaptive
recognition of patterns that change with time, in the
context of chronic neural recordings, is addressed. A
novel scheme, called bootstrap, was designed and tested
on different simulated 2 and 3 class (unit) recordings.
Bootstrap used a supervised ANN classifier to classify
the newly recorded action potentials. Using these action
potentials and knowledge of their classification, new
training sets were formed to retrain the ANN classifier.
Repeating this procedure periodically enabled the ANN to
track the changes and recognize the new shapes of the
action potentials. The effects of different parameters
in the performance of bootstrap were subsequently
investigated and the optimum set of parameters was
identified. The bootstrapped ANN outperformed an
unsupervised classifier suited to the problem. Thus the
bootstrap procedure enables a supervised classifier to
operate in an unsupervised mode.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  3495 </NUMBER>
<ORDER>   AAI9529049 </ORDER>
<TITLE> INTELLIGENT BACKTRACKING ON CONSTRAINT SATISFACTION PROBLEMS: EXPERIMENTAL AND THEORETICAL RESULTS </TITLE>
<AUTHOR> BAKER, ANDREW B. </AUTHOR>
<YEAR> 1995 </YEAR>
<INSTITUTION> UNIVERSITY OF OREGON; 0171 </INSTITUTION>
<DESCRIPTORS> COMPUTER SCIENCE; OPERATIONS RESEARCH; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> MATTHEW L. GINSBERG; EUGENE M. LUKS </ADVISER>
<CLASSIFICATIONS> NIL </CLASSIFICATIONS>
<ABSTRACT>
The Constraint Satisfaction Problem is a type of
combinatorial search problem of much interest in
Artificial Intelligence and Operations Research. The
simplest algorithm for solving such a problem is
chronological backtracking, but this method suffers from
a malady known as "thrashing," in which essentially the
same subproblems end up being solved repeatedly.
Intelligent backtracking algorithms, such as backjumping
and dependency-directed backtracking, were designed to
address this difficulty, but the exact utility and range
of applicability of these techniques have not been fully
explored. This dissertation describes an experimental
and theoretical investigation into the power of these
intelligent backtracking algorithms.
We compare the empirical performance of several such
algorithms on a range of problem distributions. We show
that the more sophisticated algorithms are especially
useful on those problems with a small number of
constraints that happen to be difficult for
chronological backtracking. We also illuminate some
issues concerning the distribution of hard and easy
constraint problems. It was previously believed that the
hardest problems had a small number of constraints, but
we show that this result is an artifact of chronological
backtracking that does not apply to the more advanced
algorithms.
We then study the performance of a particular
intelligent backtracking algorithm that has been of much
interest: dynamic backtracking. We demonstrate
experimentally that for some problems this algorithm can
do more harm than good. We discuss the reason for this
phenomenon, and we present a modification to dynamic
backtracking that fixes the problem.
We also present theoretical worst-case results. It is
known that dependency-directed backtracking can solve a
constraint satisfaction problem in time exponential in a
particular problem parameter known as the "induced
width." This algorithm, however, requires about as much
space as time; that is, its space requirements also grow
exponentially in this parameter. This suggests the
question of whether it is possible for a polynomial-
space algorithm to be exponential in the induced width.
We show that for a large class of constraint
satisfaction algorithms, it is not possible. That is,
there is a trade-off in intelligent backtracking between
space and time.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  3496 </NUMBER>
<ORDER>   AAI9529015 </ORDER>
<TITLE> LEARNING RESTRICTED-READ BRANCHING PROGRAMS WITH QUERIES </TITLE>
<AUTHOR> WILKINS, DAWN ELISABETH </AUTHOR>
<YEAR> 1995 </YEAR>
<INSTITUTION> VANDERBILT UNIVERSITY; 0242 </INSTITUTION>
<DESCRIPTORS> COMPUTER SCIENCE; MATHEMATICS; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> VIJAY RAGHAVAN </ADVISER>
<CLASSIFICATIONS> NIL </CLASSIFICATIONS>
<ABSTRACT>
There are two predominant models of computational
learning theory--the probably approximately correct
(PAC) model and the exact model. The goal of
computational learning theory is to develop algorithms
for efficiently learning concept classes and to show
that classes cannot be efficiently learned. Boolean
classes are among the most natural classes to study and
are the focus of this dissertation.
There is cryptographic evidence to support the belief
that the class of general branching programs is not
predictable. Thus, our emphasis is on restricted
subclasses of of branching programs. We present both
positive and negative results. Specifically, a general
framework for learning projection-closed, "augmentable"
concept classes in the exact model (with membership
queries) is developed. We then present a
characterization of the class of $mu$-branching programs
(where each variable may appear in the branching program
at most once). The characterization is used to show that
$mu$-branching programs are augmentable, and therefore
learnable by the general framework. Using a result by
Angluin, it is easy to show that $mu$-branching programs
are also learnable in the PAC model (with membership
queries). The negative results show that (i) $mu$-
branching programs cannot be learned with membership
queries alone, or equivalence queries alone, (ii) $0kmu$-
branching programs (where each variable may appear at
most k times in the representation), for $k ge 3$, are
not predictable modulo cryptographic assumptions, and
(iii) the class of read-k-times branching programs
(where each variable may appear at most k times on any
root-to-terminal path), for $k ge 2$, is not predictable
modulo cryptographic assumptions.
Also included in the dissertation is a chapter on
equivalence testing of branching programs. Using the
characterization of $mu$-branching programs, we show
that a pair of $mu$-branching programs can be tested for
equivalence in O($0nalpha(n$)) time where n is the
number of nodes in the larger of the $mu$-branching
programs. Equivalence testing for the classes of $0kmu$-
branching programs, for $k ge 3$ and read-k-times
branching programs, for $k ge 2$ are show to be co-NP-
complete.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  3497 </NUMBER>
<ORDER>   AAI9529007 </ORDER>
<TITLE> IMPROVING THE ACCURACY OF DEFOCUS-BASED DEPTH ESTIMATION USING FUZZY LOGIC </TITLE>
<AUTHOR> SWAIN, CASSANDRA TURNER </AUTHOR>
<YEAR> 1995 </YEAR>
<INSTITUTION> VANDERBILT UNIVERSITY; 0242 </INSTITUTION>
<DESCRIPTORS> ENGINEERING, ELECTRONICS AND ELECTRICAL; COMPUTER SCIENCE; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> RICHARD ALAN PETERS, II </ADVISER>
<CLASSIFICATIONS> NIL </CLASSIFICATIONS>
<ABSTRACT>
This dissertation presents a method to improve the
estimation accuracy of a depth from defocus (DFD)
algorithm at far distances by applying fuzzy logic.
Depth estimation accuracy decreases as object distance
increases. Lower image resolution, coupled with image
noise, lens aberrations, spatial frequency variations,
and computational error, make depth estimation difficult
at far distances. DFD, a computationally simple method,
is an appropriate candidate for improvement because of
its high estimation error as compared to other
estimation methods. Fuzzy logic mathematically models
inaccurate data. It is applied to DFD methods to combine
accuracy and simplicity. Two issues are addressed:
automatic window selection and DFD accuracy improvement.
A defocus-based method to automatically select an image
processing window is presented. This method is important
in computer vision applications, such as motion tracking
and depth estimation, that operate in small windows.
Depth is estimated within the selected windows. These
windows contain high frequency features at a single
depth. High frequency features are indicated by low
defocus. Single depth is detected when there is
equivalent defocus in surrounding windows. Automatic
window selection with a fixed window size and with a
variable window size are compared. Results indicate a
good performance at higher camera zoom. The variable
window approach also performs well at low zoom and
handles varying object size and distance better than the
fixed window approach. The optimal window algorithm is
applied to two DFD methods to minimize estimation error.
Results show that an optimal window is determined by an
optimal spatial frequency.
Accuracy improvements of DFD methods--focal error,
spatial transform, and focus quality--are presented. The
focal error method measures the focus difference between
corresponding image points taken with different
apertures. The spatial transform method measures the
image defocus parameter in the spatial domain. Focus
quality measures defocus from edge strength in a single
image. Fuzzy logic is applied to the DFD methods in
three approaches: focal error with focus quality,
spatial transform with focus quality, and focal error
with spatial transform. Each combination of methods
provides two simple, independent measurements used by
fuzzy logic. Results show significantly improved depth
estimates in the three approaches using fuzzy logic.
Estimation errors improve +10% over the nonfuzzy
approaches. This fuzzy logic and depth from defocus
combination offers promising results for improving
accuracy, while maintaining computational simplicity.
This research is conducted in the Intelligent Robotics
Laboratory using a Sony CCD camera, with manually
controlled aperture, focus, and zoom, an Androx imaging
board, and a SPARC station.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  3498 </NUMBER>
<ORDER>   AAI9528963 </ORDER>
<TITLE> PLANNING UNDER UNCERTAINTY BY SPREADING ACTIVATION THROUGH AN ADAPTIVE PROBABILISTIC NETWORK </TITLE>
<AUTHOR> BAGCHI, SUGATO </AUTHOR>
<YEAR> 1995 </YEAR>
<INSTITUTION> VANDERBILT UNIVERSITY; 0242 </INSTITUTION>
<DESCRIPTORS> ENGINEERING, ELECTRONICS AND ELECTRICAL; COMPUTER SCIENCE; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> KAZUHIKO KAWAMURA </ADVISER>
<CLASSIFICATIONS> ROBOTICS </CLASSIFICATIONS>
<ABSTRACT>
As robotics and automation are applied to unstructured
environments such as those in the service sector,
researchers have to increasingly deal with the
uncertainty about the effects of performing actions in
these environments. Two broad approaches have been
devised for acting under uncertainty. The first approach
enhances traditional AI planning systems by
incorporating probabilities about the effects of actions
that are conditioned on the state of the environment.
This makes it possible to select plans that have the
highest probability of success. The other approach,
adopted by reactive systems, employs a set of predefined
situation-response rules that make it possible to move
towards the goal from any situation, whether expected or
unexpected.
This dissertation describes a planner that combines the
two approaches by having a proactive component that
generates plans with the most reliable actions in a
given situation, as well as a reactive component that
alters the action selection based on the unexpected
situations that tend to arise in an uncertain
environment. Action selection occurs through a spreading
activation mechanism through a probabilistic network
that encodes the domain knowledge.
Another aspect of this research is to learn the
probabilistic domain knowledge from the observation of
an expert and experience. This is relevant for
environments with uncertainty, where the reliability of
actions taken by the agent cannot be known a priori and
may change with time. This research has also developed a
learning by experimentation method that attempts to
remove "misconceptions" learned as a result of observing
action execution examples that are part of plan
sequences and therefore, not in random order.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  3499 </NUMBER>
<ORDER>   AAI9528910 </ORDER>
<TITLE> OPTIMAL RULE-BASED GUIDANCE FOR AUTONOMOUS VEHICLES </TITLE>
<AUTHOR> NIEHAUS, AXEL </AUTHOR>
<YEAR> 1995 </YEAR>
<INSTITUTION> PRINCETON UNIVERSITY; 0181 </INSTITUTION>
<DESCRIPTORS> ENGINEERING, MECHANICAL; ENGINEERING, AUTOMOTIVE; ENGINEERING, SYSTEM SCIENCE; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> NIL </ADVISER>
<CLASSIFICATIONS> STOCHASTIC OPTIMAL CONTROL, DECISION MAKING, ALLOCATION </CLASSIFICATIONS>
<ABSTRACT>
The goal of this dissertation is to investigate a new
type of guidance system for autonomous vehicles
operating in uncertain environments. The guidance system
has access to noise-corrupted measurements of the
vehicle and environment states. If some elements of the
environment are controlled by exterior agents, the
autonomous vehicle should not rely on accurate models of
these agents or assume communication of their
intentions. The response of the vehicle should be
optimal with respect to a stochastic cost function.
The proposed system combines stochastic optimal control
and estimation, artificial intelligence, and decision
making. Stochastic optimal control (SOC) provides
powerful tools for determining control histories that
minimize stochastic cost functions that depend on the
vehicle and/or environment states. However, for most
realistic (and complex) applications, SOC lacks
convergence guarantees and suffers from long execution
times. The suggested guidance system uses domain-
specific knowledge included in a dynamic rule-based
expert system to periodically analyze the situation,
deducing promising solution prototypes. SOC techniques
determine only the best solution among these prototypes,
resulting in drastically reduced search spaces. If small
enough search spaces can be obtained, convergence and
execution time problems are avoided.
A technique called "Worst-Plausible-Case Decision
Making" is used to generate stochastic predictions for
the evolution of the environment. Based on probability
theory and optimal estimation, this technique uses
domain-specific knowledge to deduce multiple plausible
evolutions of the environment for given candidate
control historie of the autonomous vehicle. The system
assumes the worst plausible evolution for allocating
resources.
The guidance system design is applied to the lateral and
longitudinal control of an autonomous highway vehicle as
part of the Intelligent Vehicle Highway Systems program.
Using a highway traffic simulator, promising results are
obtained for normal and emergency traffic situations
involving varying amounts of uncertainty.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  3500 </NUMBER>
<ORDER>   AAI9528858 </ORDER>
<TITLE> A FRAMEWORK FOR QUALITATIVE DECISION THEORY </TITLE>
<AUTHOR> TAN, SEK-WAH </AUTHOR>
<YEAR> 1995 </YEAR>
<INSTITUTION> UNIVERSITY OF CALIFORNIA, LOS ANGELES; 0031 </INSTITUTION>
<DESCRIPTORS> COMPUTER SCIENCE; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> JUDEA PEARL </ADVISER>
<CLASSIFICATIONS> DEFAULT REASONING </CLASSIFICATIONS>
<ABSTRACT>
This thesis describes a system for modeling commonsense
decision making. The system has three major components:
the belief module, the preference module, and the
decision module. As their names suggest, the belief and
preference modules model, respectively, the beliefs and
preferences of the reasoning agent. The belief module
accepts sentences of the form "if $alpha$, then
typically $beta$" (called normality defaults), while the
preference module accepts sentences of the form "if
$gamma$ is true, then prefer $alpha$ over $beta$"
(called conditional preferences). The decision module
accepts queries of the form "given that $phi$ is known
(or has been observed), is action $sigmasb1$ preferred
over $sigmasb2$?" The system interprets the inputs and
computes an answer to the query based on the normality
defaults and conditional preferences.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  3501 </NUMBER>
<ORDER>   AAI9528675 </ORDER>
<TITLE> A KNOWLEDGE-BASED APPROACH TO THE MANAGEMENT AND CONTROL OF FLEXIBLE  MANUFACTURING SYSTEMS </TITLE>
<AUTHOR> NAIK, BIJAYANANDA </AUTHOR>
<YEAR> 1995 </YEAR>
<INSTITUTION> THE UNIVERSITY OF WISCONSIN - MILWAUKEE; 0263 </INSTITUTION>
<DESCRIPTORS> ENGINEERING, INDUSTRIAL; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> AMIYA K. CHAKRAVARTY </ADVISER>
<CLASSIFICATIONS> SCHEDULING </CLASSIFICATIONS>
<ABSTRACT>
A major problem encountered in using flexible
manufacturing systems (FMSs) in discrete part
manufacturing is the lack of efficient scheduling and
control techniques. Many different techniques are
currently being investigated by researchers in an effort
to improve them. A promising approach involves the
application of a knowledge-based system (KBS) to select
scheduling rules based on system status in real-time.
This research investigates the performance of the
knowledge-based approach to dynamic scheduling of an FMS
consisting of a number of flexible manufacturing cells
(FMCs). The dissertation primarily deals with the
scheduling of FMCs, since it is an essential step toward
scheduling of a more complex FMS.
Six heuristic algorithms were designed for scheduling of
discrete parts in an FMC, and eight system status
attributes were defined to select the best scheduling
rule to be used at a given point in time. Two different
KBSs, corresponding to mean flowtime and mean tardiness
measures, were programmed with rules for selecting the
best heuristic algorithm given a set of system status
attribute values obtained from an FMC during its
operation. The rules in the knowledge bases were
obtained by conducting extensive simulation experiments,
and then applying a machine learning technique to the
data. The use of simulation experiments to acquire
knowledge about the behavior of an FMC is necessary
since human expertise in this field is not readily
available. The scheduling performance of the knowledge-
based approach was compared with that of individual
heuristic algorithms using statistical techniques.
The results of this research indicated that individual
heuristic algorithms differed in their performance. The
knowledge-based approach involving dynamic selection of
heuristic algorithms provided equal or better
performance in most cases, but not in all cases. When a
single heuristic algorithm dominates, the knowledge-
based approach may not provide any significant advantage
over using a single heuristic. However, when the
candidate heuristic algorithms perform more or less
equally, the knowledge-based approach may provide
superior results. Further research, covering greater
ranges of operating conditions of a system, will be
pursued in future to evaluate the performance of the
knowledge-based approach to real-time scheduling of a
flexible manufacturing system.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  3502 </NUMBER>
<ORDER>   AAGMM13630 </ORDER>
<TITLE> A FUZZY LOGIC APPLICATION TO RANGE FINDING FOR ROBOTICS </TITLE>
<AUTHOR> WANG, MING HUA </AUTHOR>
<YEAR> 1995 </YEAR>
<INSTITUTION> TECHNICAL UNIVERSITY OF NOVA SCOTIA (CANADA); 0300 </INSTITUTION>
<DESCRIPTORS> ENGINEERING, ELECTRONICS AND ELECTRICAL; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> C. R. BAIRD; K. WILKIE </ADVISER>
<CLASSIFICATIONS> NIL </CLASSIFICATIONS>
<ABSTRACT>
Use of robotics and intelligent machines in agricultural
harvesting has been under research and development for
years. Computer-vision systems play a key role in
enabling robots to work in complicated environments.
Different techniques have been developed to help robotic
systems to "see" and "sense" the real world. Range
finding is one technique to determine the 3-D position
of an object.
This thesis describes an experimental strawberry
harvesting system which uses a fuzzy logic range finding
method for getting 3-D information on the location of
strawberries. The robot is a SRS-M1A Small Industrial
Robot System. The robot gripper was developed by Lewis
et al (1994). The imaging system includes a miniature
single-board, monochrome, solid-state chip camera (model
CX-103) and a PC-486 IBM-compatible computer. All
software involved in image processing and the fuzzy
logic range-finding algorithm was developed in C and
compiled using TURBO C 2.0.
The basic idea of this fuzzy logic range finding
algorithm is to make use of information of an object
from camera motion as the fuzzy input and applying fuzzy
logic to determine the range of the object from the
camera.
The results of testing indicated that the fuzzy logic
range-finding is feasible although the speed of picking
is not encouraging. The low speed was mainly caused by
image acquisition and the movement of the robotic
system. To apply this fuzzy logic range-finding
algorithm in real world, a faster video frame grabber
and a faster robotic system are required.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  3503 </NUMBER>
<ORDER>   AAGNN08457 </ORDER>
<TITLE> KNOWLEDGE DISCOVERY IN DATABASES: AN ATTRIBUTE-ORIENTED ROUGH SET APPROACH </TITLE>
<AUTHOR> HU, XIAOHUA </AUTHOR>
<YEAR> 1995 </YEAR>
<INSTITUTION> THE UNIVERSITY OF REGINA (CANADA); 0148 </INSTITUTION>
<DESCRIPTORS> COMPUTER SCIENCE; ARTIFICIAL INTELLIGENCE; INFORMATION SCIENCE </DESCRIPTORS>
<ADVISER> N. CERCONE </ADVISER>
<CLASSIFICATIONS> RULES, DECISION MATRICES </CLASSIFICATIONS>
<ABSTRACT>
Knowledge discovery systems face challenging problems
from the real-world databases which tend to be very
large, redundant, noisy and dynamic. In this thesis, we
develop an attribute-oriented rough set approach for
knowledge discovery in databases. The method adopts the
artificial intelligent "learning from examples" paradigm
combined with rough set theory and database operations.
The learning procedure consists of two phases: data
generalization and data reduction. In data
generalization, our method generalizes the data by
performing attribute-oriented concept tree ascension,
thus some undesirable attributes are removed and a set
of tuples may be generalized to the same generalized
tuple. The goal of data reduction is to find a minimal
subset of interesting attributes that have all the
essential information of the generalized relation; thus
the minimal subset of the attributes can be used rather
than the entire attribute set of the generalized
relation. By removing those attributes which are not
important and/or essential, the rules generated are more
concise and ellicacious.
Our method integrates a variety of knowledge discovery
algorithms, such as DBChar for deriving characteristic
rules. DBClass for classification rules. DBDeci for
decision rules. DBMaxi for maximal generalized rules.
DMBkbs for multiple sets of knowledge rules and DBTrend
for data trend regularities, which permit a user to
discover various kinds of relationships and regularities
in the data. This integration inherit the advantages of
the attribute-oriented induction model and rough set
theory. Our method makes some contribution to the KDD. A
generalized rough set model is formally defined with the
ability to handle statistical information and also
consider the importance of attributes and objects in the
databases. Our method is able to identify the essential
subset of nonredundant attributes (factors) that
determine the discovery task, and can learn different
kinds of knowledge rules efficiently from large
databases with noisy data and in a dynamic environment
and deal with databases with incomplete information. A
prototype system DBROUGH was constructed under a
Unix/C/Sybase environment. Our system implements a
number of novel ideas. In our system, we use attribute-
oriented induction rather than tuple-oriented induction,
thus greatly improving the learning efficiency. By
integrating rough set techniques into the learning
procedure, the derived knowledge rules are particularly
concise and pertinent, since only the relevant and/or
important attributes (factors) to the learning task are
considered. In our system, the combination of transition
network and concept hierarchy provides a nice mechanism
to handle dynamic characteristic of data in the
databases. For applications with noisy data, our system
can generate multiple sets of knowledge rules through a
decision matrix to improve the learning accuracy. The
experiments using the NSERC information system
illustrate the promise of attribute-oriented rough set
learning for knowledge discovery for databases.
(Abstract shortened by UMI.)
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  3504 </NUMBER>
<ORDER>   AAI9526770 </ORDER>
<TITLE> AN APPROACH TO ON-LINE STATIC SECURITY ASSESSMENT OF POWER SYSTEMS USING ARTIFICIAL NEURAL NETWORK TECHNIQUES </TITLE>
<AUTHOR> AGUDO, MICHAEL ENGRACIA </AUTHOR>
<YEAR> 1995 </YEAR>
<INSTITUTION> THE GEORGE WASHINGTON UNIVERSITY; 0075 </INSTITUTION>
<DESCRIPTORS> ENGINEERING, ELECTRONICS AND ELECTRICAL; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> ROBERT JOSEPH HARRINGTON; RODNEY KINTORE LAY </ADVISER>
<CLASSIFICATIONS> NIL </CLASSIFICATIONS>
<ABSTRACT>
The conventional approach to on-line security assessment
of power systems involves the limit checking of on-line
measurements to determine the present steady-state
performance of the system, and the sequential execution
of an on-line load flow program to predict the steady-
state system behavior in response to pre-selected
contingencies. Since this approach is computationally
stringent and time-consuming, and becoming less
effective in meeting modern-day power system operation
requirement, system operators are seeking an on-line
security assessment tool that can quickly forewarn them
of threatening contingencies. To address this problem,
the dissertation research explores the application of
artificial neural network (ANN) techniques as an
alternative computing approach.
In the proposed ANN-based approach, the on-line
computations required in the conventional method are
conducted off-line to train the ANNs'. The trained ANNs'
are then installed on-line to respond to sets of on-line
measurements presented to them. Since the response of
the ANNs is significantly faster than that of an on-line
load flow program, the on-line assessment execution rate
can be significantly increased.
In this research, a modified on-line security assessment
scheme that includes voltage stability evaluation is
first developed. The scheme is centered on four ANN-
based functions: security monitoring, contingency
selection, contingency evaluation and voltage stability
evaluation. Simulation studies are conducted using a 22-
bus test system model. Off-line AC load flow and
contingency analyses are conducted on the test system,
and the data generated are used to train and test the
selected ANN techniques. The simulation results are
accurate for the speed of the ANNs' responses.
The benefits that the study may offer include the
following: (1) An ANN-based approach to on-line security
assessment of power systems that potentially increases
its execution rate; (2) an on-line security assessment
scheme that provides an opportunity for the realization
of on-line voltage stability evaluation; (3) an
architecture for integrating the four ANN-based security
assessment functions; and (4) description of a power
system operation scenario in which the proposed ANN-
based approach might be used as a practical application
tool for power system operators.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  3505 </NUMBER>
<ORDER>   AAI9532291 </ORDER>
<TITLE> A NEW METHOD FOR FORECASTING STOCK PRICES USING ARTIFICIAL NEURAL NETWORK AND WAVELET THEORY </TITLE>
<AUTHOR> TAK, BONGNAM </AUTHOR>
<YEAR> 1995 </YEAR>
<INSTITUTION> UNIVERSITY OF PENNSYLVANIA; 0175 </INSTITUTION>
<DESCRIPTORS> ECONOMICS, FINANCE; ECONOMICS, THEORY; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> ROBERTO MARIANO </ADVISER>
<CLASSIFICATIONS> NIL </CLASSIFICATIONS>
<ABSTRACT>
Recently, a new decomposition method known as wavelet
decomposition was introduced, which is accomplished
through the use of an orthogonal basis consisting of so-
called "wavelets". Wavelet analysis is a significant
advance over Fourier analysis for two reasons. First,
while Fourier analysis gives us only frequency
information, wavelet analysis gives us both frequency
information and time information. Secondly, wavelet
analysis can represent a nonstationary process better
than Fourier analysis by allowing us to look at the
series through wavelets of variable sizes. While the
wavelet theory has brought about significant
advancements in representation of functions, not much
work on its applicability to forecasting has been made.
Although an initial attempt to provide the statistical
framework for wavelet analysis was made by (Basseville,
et al. 1992a, b), the applicability of wavelet analysis
to forecasting needs to be further developed. The
purpose of this paper is to introduce new methodologies
based on wavelet decomposition that can forecast with
greater accuracy than existing models. (1) Several
models (including ARIMA, detrending and AR, random walk,
and artificial neural network) are applied to the
original series (Standard & Poor's 500 Index), and to
the wavelet decomposed series. The results from the two
approaches are compared to see whether the use of the
decomposed series (which is the special smoothed version
of the original series) in forecasting yields better
results than applying the models directly to the
original series. (2) An artificial neural network is
incorporated with wavelets to forecast the Standard &
Poor's 500 Index. (3) Information on the generating
process (i.e. relationship from the decomposed series to
the original series) is used for forecasting. The models
in (1) which use decomposed series, result in smaller
forecasting errors, i.e. RMSPE, MAPE, and TIC, than
models where the original series are directly applied.
The models described in (3) yield better results than
the models described in (1) and (2). Wavelet theory is a
concept that will need to be developed further for use
in economics and finance. While this paper utilizes the
simplest wavelets and a univariate case, it should be
possible to employ more complicated wavelets and
multivariate cases to see if their use can further
advance the role of wavelet theory in forecasting.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  3506 </NUMBER>
<ORDER>   AAI9531213 </ORDER>
<TITLE> DETERMINATION OF BUFFER SIZE AND LOCATION IN SCHEDULING SYSTEMS  </TITLE>
<AUTHOR> LUTZ, CHRISTIAN MARTIN </AUTHOR>
<YEAR> 1995 </YEAR>
<INSTITUTION> UNIVERSITY OF GEORGIA; 0077 </INSTITUTION>
<DESCRIPTORS> BUSINESS ADMINISTRATION, MANAGEMENT; OPERATIONS RESEARCH; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> K. ROSCOE DAVIS </ADVISER>
<CLASSIFICATIONS> BUFFER MANAGEMENT, INVENTORY PROFILES </CLASSIFICATIONS>
<ABSTRACT>
Competition among companies is becoming more and more
fierce. In addition to increased quality conformance,
companies with short manufacturing (cycle) times can
gain competitive advantages. Short cycle times are
achieved by having viable scheduling systems that
require minimal inventories. Many scheduling systems
such as Kanban, Drum-Buffer-Rope (DBR), and CONWIP, as
well as a new system referred to as Dynamic Flow Control
(DFC), have been developed that seek to achieve these
competitive advantages (objectives). But, most of these
systems fall short of achieving these objectives because
they do not clearly identify where and how much
inventory should be employed.
Obviously, zero inventory is inefficient and some
inventory is needed in a manufacturing line. However,
the exact determination of total inventory quantities
and the determination of the location and size of work-
in-process (WIP) inventories is difficult. It is
difficult, since it is impossible to forecast the impact
of all statistical fluctuations, which is needed to
determine work-in-process inventory structures. Many
real-world manufacturing lines side-step the problem by
employing high finished inventory levels. However, there
is a tradeoff in setting inventory levels and
inventories should not necessarily be set at high
levels. On the one hand, too low inventory levels starve
work centers which reduces line performance. On the
other hand high WIP inventory levels result in long
manufacturing cycle time, which operates
counterproductive to the competitive advantage of a
firm.
This dissertation deals with problems of WIP inventory
management and provides a simulation-search procedure
which can be used to determine inventory size and
location requirements of a firm. It shows that the size
and location of WIP inventory is a combinatorial problem
which is a function of buffer sizes at each operation in
a manufacturing line. This study identifies specific
inventory locations and minimal sizes, referred to as
"inventory profiles," which support manufacturing
scheduling systems. Because of the complexity of the
profiling process, simulation, combined with an
artificial intelligence based search heuristic, is
employed to address the problem. Simulation is used to
model the manufacturing facility under study, while a
Tabu Search metaheuristic is used to analyze the
simulated results, to direct the search process in the
combinatorial environment, and to identify optimal or
near optimal buffer profiles.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  3507 </NUMBER>
<ORDER>   AAI9531192 </ORDER>
<TITLE> EFFECTS OF TYPE AND TIMING OF FEEDBACK FOR NON-CRITICAL ERRORS WITH AN INTELLIGENT TUTORING SYSTEM </TITLE>
<AUTHOR> FARQUHAR, JOHN DAVID </AUTHOR>
<YEAR> 1995 </YEAR>
<INSTITUTION> UNIVERSITY OF GEORGIA; 0077 </INSTITUTION>
<DESCRIPTORS> EDUCATION, TECHNOLOGY; COMPUTER SCIENCE; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> MICHAEL OREY </ADVISER>
<CLASSIFICATIONS> ADAPTIVE INSTRUCTION </CLASSIFICATIONS>
<ABSTRACT>
Feedback has remained a useful construct through a shift
from a behavioristic explanation of learning to a more
cognitive understanding. Research in the use of feedback
in education suggests that corrective feedback, or
feedback that provides the correct answer, is more
effective than feedback that simply indicates an error.
However, contrary to an information-processing theory of
learning, these studies generally find no efficacy for
feedback of a more elaborative nature such as the use of
additional explanatory information.
In addition to studying the content of instructional
feedback, a large body of research has addressed the
effects of the timing of feedback. Recent analyses
generally conclude that immediate feedback is more
effective than delayed feedback in most instructional
situations. Immediate feedback, however, can be
disruptive to learning processes. Interestingly,
research in human-tutor interactions suggests that human
tutors modulate their feedback responses to the type of
error committed. Critical errors are most often
corrected immediately, whereas feedback for non-critical
errors is often delayed until a moment of opportunity.
The study described in this dissertation investigated
the type and timing of feedback for non-critical errors
within an intelligent console-operations tutor. The
results found no evidence to conclude that elaborative
feedback or the delay of feedback for non-critical
errors improves performance. However, results from an on-
line questionnaire indicated that subjects preferred the
use of elaborative feedback over the use of corrective
feedback. Additionally, subjects indicated a mix of
preferences for the delay of feedback for non-critical
errors. The conclusion reached is that the
inconsistencies between theories of instructional
feedback and research remain unresolved.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  3508 </NUMBER>
<ORDER>   AAI9529162 </ORDER>
<TITLE> THE EFFECTIVENESS OF INTELLIGENT COMPUTER-ASSISTED LANGUAGE INSTRUCTION IN TUTORING JAPANESE CONNECTIVES </TITLE>
<AUTHOR> KIKUCHI, MASATO </AUTHOR>
<YEAR> 1995 </YEAR>
<INSTITUTION> UNIVERSITY OF PITTSBURGH; 0178 </INSTITUTION>
<DESCRIPTORS> EDUCATION, TECHNOLOGY; EDUCATION, LANGUAGE AND LITERATURE; EDUCATION, CURRICULUM AND INSTRUCTION; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> NIL </ADVISER>
<CLASSIFICATIONS> CAI </CLASSIFICATIONS>
<ABSTRACT>
In recent years, intelligent computer-assisted language
instruction (ICALI) programs have undergone close
scrutiny. This dissertation dealt with the aspects of
comparing individualized instruction provided by an
ICALI program with small group instruction (an average
of 3 to 4 students per session) provided by an
experienced human instructor in the instruction of
Japanese temporal or conditional connectives. The focus
of the comparison was on the merits of the design
features of a NLP-based ICALI program, which generated
individualized, explanatory feedback. In order to
connect two Japanese sentences, one is required to
master semantically illusive concepts such as self-
controllability of actions and presuppositions involved
in the link between two propositions. Due to the
complexity of the analyses involved in detecting
problems in the connective expressions, few CALI
programs addressed this aspect of language utilization
in the past. A first-generation ICALI-Connective program
that handled two connected sentences was designed and
implemented. A formative study was performed to assess
the feedback produced by this program. Following the
formative study, a second-generation program with
enhanced grammatical and semantic knowledge and tutorial
strategies was created to handle more input variations
and produce better feedback. An experiment was then
conducted to test research hypotheses that the group
taught by a human instructor would differ from a group
taught by ICALI-Connective in the sentence generation
and sentence judgment tasks involving Japanese
connectives. A repeated-measure F test was conducted to
measure the initial learning effect and the interaction
effect, and a t test was conducted to measure the
retention of learning. The results favored the ICALI-
Connective group in general but did not support the
research hypotheses. Thus, the research hypotheses were
rejected in favor of the null hypotheses. That is, the
two instructional methods were equally effective as far
as teaching Japanese temporal or conditional connectives
was concerned. Subsequently, the recorded ICALI sessions
were compared with the human instructor sessions. The
discussion includes the theoretical implications of the
current findings, the limitations of the research, and
further research directions.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  3509 </NUMBER>
<ORDER>   AAI9530240 </ORDER>
<TITLE> AN INTELLIGENT DECISION SUPPORT SYSTEM FOR NEW PRODUCT DEVELOPMENT </TITLE>
<AUTHOR> THOMAS, RONALD EUGENE </AUTHOR>
<YEAR> 1995 </YEAR>
<INSTITUTION> ARIZONA STATE UNIVERSITY; 0010 </INSTITUTION>
<DESCRIPTORS> ENGINEERING, INDUSTRIAL; BUSINESS ADMINISTRATION, MANAGEMENT; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> NIL </ADVISER>
<CLASSIFICATIONS> NIL </CLASSIFICATIONS>
<ABSTRACT>
Enterprises expecting to be successful into the 21st
century must carefully select their new products to
develop. An intelligent decision support system (IDSS)
was designed to enhance the process of choosing a new
product from one or more alternatives. The critical
factors to consider include financial, marketing,
technology, organization and environmental criteria.
These tangible and intangible factors are effectively
combined to form a merit function composed of the value,
investment, and success potential of the proposed new
product. Uncertainty is accounted for within the IDSS by
allowing the decision maker(s) to input a range of
numbers and/or a most likely number. These inputs map
into probability distributions that are used in a Monte
Carlo type simulation to compute the probability
distribution of the merit function and its associated
elements. The rankings of the alternatives are
determined along with a sensitivity analysis pointing to
the factors that have the highest impact. Decision
maker(s) can effectively determine if and what data
inputs need to be refined during further iterations. The
IDSS has been designed with three hierarchical levels of
increasing detail using the Analytical Hierarchy Process
(AHP). The first level provides a simple decision
structure to more easily eliminate the weaker
alternatives without exercising the full decision model.
The second and third levels explore the higher ranking
alternatives in more depth making the decision process
more effective and efficient. The entire decision space
of the decision maker(s) is captured within the input
scaling. Since even the best of the alternatives being
considered may not rate high on the merit scale, the
decision maker(s) will have insight into the
attractiveness of the alternatives as they fit within
their decision space. An extensive literature search and
background study, an expert survey, and field trials at
three diverse corporations verified the unique
contributions and confirmed the usefulness of the IDSS.
The research developed a forward looking, widely
applicable guide for enterprises to use in selecting and
implementing their new product development efforts.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  3510 </NUMBER>
<ORDER>   AAI9530198 </ORDER>
<TITLE> THE HYBRID DECISION SUPPORT SYSTEM USING NEURAL NETWORKS, FUZZY LOGIC CONTROLLERS, AND OBJECT-ORIENTED DATABASES </TITLE>
<AUTHOR> DU, TIMON CHIH-TING </AUTHOR>
<YEAR> 1995 </YEAR>
<INSTITUTION> ARIZONA STATE UNIVERSITY; 0010 </INSTITUTION>
<DESCRIPTORS> ENGINEERING, INDUSTRIAL; COMPUTER SCIENCE; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> NIL </ADVISER>
<CLASSIFICATIONS> NIL </CLASSIFICATIONS>
<ABSTRACT>
A database management system is a tool to define, store
and manipulate data. A knowledge based system is
composed of an inference engine for reasoning and a
knowledge base for storing facts and rules. While the
database system is static, the knowledge base system is
dynamic. Therefore, it is advantageous of linking
knowledge bases with databases. The conventional
approaches to link the knowledge base and the database
have several problems. For example, such a system can
not deal with both fuzzy and nonfuzzy data, and requires
large, rigid, unadaptable rule domains.
The objective of this research is to develop a
methodology for supporting a hybrid decision system
which can (1) integrate knowledge bases and databases,
(2) have the benefits of different technologies, (3)
process fuzzy and nonfuzzy data, (4) maintain an
acceptable rule domain, (5) allow inconsistent
knowledge, (6) have adapting and fault-tolerance
features, and (7) operate actively. The methodology
integrates object-oriented databases, fuzzy logic
controllers, neural networks, and active systems. The
knowledge base (the fuzzy logic controllers and neural
networks) can be integrated with the database (the
object-oriented database) so that the data can be
organized statically and the system can be operated
dynamically. Three approaches have been developed for
integrating the hybrid architecture. They are: (1) using
neural networks to learn the fuzzy if-then rules, (2)
using the neural networks to simulate the membership
functions for a fuzzy logic system, and (3) using neural
networks for classification in which the input includes
both fuzzy variables and nonfuzzy variables.
Furthermore, the addition of triggers and constraints in
the hybrid decision support system has been analyzed. An
active material requirements planning model has been
built for validating and verifying the research. It has
also been demonstrated that the active MRP does not have
conventional period-by-period limitations leading to a
real-time and bucketless system.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  3511 </NUMBER>
<ORDER>   AAI9529730 </ORDER>
<TITLE> USING THREE-DIMENSIONAL FLUORESCENCE AND ARTIFICIAL NEURAL NETWORKS TO MATCH DIESEL-CONTAMINATED GROUND WATER WITH POSSIBLE SOURCES </TITLE>
<AUTHOR> SINSKI, JOSEPH FELIX </AUTHOR>
<YEAR> 1995 </YEAR>
<INSTITUTION> UNIVERSITY OF MONTANA; 0136 </INSTITUTION>
<DESCRIPTORS> CHEMISTRY, ANALYTICAL; ENVIRONMENTAL SCIENCES; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> GARON C. SMITH </ADVISER>
<CLASSIFICATIONS> NIL </CLASSIFICATIONS>
<ABSTRACT>
Petroleum products released into the environment pose a
health threat because of the toxic and carcinogenic
hydrocarbons they contain. This study utilizes 3-
dimensional fluorescence spectroscopy and artificial
neural networks to help identify the source of diesel
fuel that appeared in a freshly excavated sewer trench
in Havre, Montana. Persistent polycyclic aromatic
hydrocarbons (PAH's) naturally occurring in diesel
provide a fluorescent fingerprint that is characteristic
of a given source.
Samples of petroleum contaminated ground water were
collected from the sewer trench, from wells at five
potential source areas within the Havre rail yards and
from several monitoring wells upgradient from the sewer
trench. Three source areas were of major interest
because of their proximity to the trench: an open lagoon
holding wastewater from the rail yard operations, a
fueling station near the locomotive maintenance shops,
and an adjacent recovery zone from which subsurface
diesel is actively being recovered. Monitoring wells
from each area showed significant diesel fuel
contamination. Our technique attempts to determine which
of the three suspect areas, or combination thereof, is
responsible for the interceptor trench contamination.
In the course of these analyses, a systematic
description of concentration effects in fluorophore
mixtures (the red shift cascade) is offered. The
concentration-imposed complications are demonstrated for
a synthetic mixture mimicking diesel and several ternary
PAH mixtures.
Samples from the Havre field site were extracted into
benzene and filtered through 0.45mm PTFE membranes. The
extracted samples were then characterized by 3-
dimensional fluorescence spectroscopy which collects an
array of 8421 measurements over excitation and emission
wavelength ranges of 200 to 600 nm. Seven sequential
dilutions of each extract were also measured to capture
the entire range of spectral information available from
the red shift cascade effect.
Matching of contaminant spectra to source spectra was
performed with artificial neural networks. Digitized
fluorescence data from the original extract plus the
seven dilutions were concatenated into a single fact
file. Fact files from the 3 known areas within the rail
yard site were combined with some creosote samples and
random files to train the network. Several fact files
were withheld from the training run and used to test the
network's ability to recognize samples from each source
area. Seven generations of network design are
chronicled. Finally, contaminant samples of unknown
source origin were submitted to the best trained and
tested network for assignment of source area
probabilities. Results correlated well with observations
from hydrological engineers studying the same site.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  3512 </NUMBER>
<ORDER>   AAI9529730 </ORDER>
<TITLE> USING THREE-DIMENSIONAL FLUORESCENCE AND ARTIFICIAL NEURAL NETWORKS TO MATCH DIESEL-CONTAMINATED GROUND WATER WITH POSSIBLE SOURCES </TITLE>
<AUTHOR> SINSKI, JOSEPH FELIX </AUTHOR>
<YEAR> 1995 </YEAR>
<INSTITUTION> UNIVERSITY OF MONTANA; 0136 </INSTITUTION>
<DESCRIPTORS> CHEMISTRY, ANALYTICAL; ENVIRONMENTAL SCIENCES; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> GARON C. SMITH </ADVISER>
<CLASSIFICATIONS> NIL </CLASSIFICATIONS>
<ABSTRACT>
Petroleum products released into the environment pose a
health threat because of the toxic and carcinogenic
hydrocarbons they contain. This study utilizes 3-
dimensional fluorescence spectroscopy and artificial
neural networks to help identify the source of diesel
fuel that appeared in a freshly excavated sewer trench
in Havre, Montana. Persistent polycyclic aromatic
hydrocarbons (PAH's) naturally occurring in diesel
provide a fluorescent fingerprint that is characteristic
of a given source.
Samples of petroleum contaminated ground water were
collected from the sewer trench, from wells at five
potential source areas within the Havre rail yards and
from several monitoring wells upgradient from the sewer
trench. Three source areas were of major interest
because of their proximity to the trench: an open lagoon
holding wastewater from the rail yard operations, a
fueling station near the locomotive maintenance shops,
and an adjacent recovery zone from which subsurface
diesel is actively being recovered. Monitoring wells
from each area showed significant diesel fuel
contamination. Our technique attempts to determine which
of the three suspect areas, or combination thereof, is
responsible for the interceptor trench contamination.
In the course of these analyses, a systematic
description of concentration effects in fluorophore
mixtures (the red shift cascade) is offered. The
concentration-imposed complications are demonstrated for
a synthetic mixture mimicking diesel and several ternary
PAH mixtures.
Samples from the Havre field site were extracted into
benzene and filtered through 0.45mm PTFE membranes. The
extracted samples were then characterized by 3-
dimensional fluorescence spectroscopy which collects an
array of 8421 measurements over excitation and emission
wavelength ranges of 200 to 600 nm. Seven sequential
dilutions of each extract were also measured to capture
the entire range of spectral information available from
the red shift cascade effect.
Matching of contaminant spectra to source spectra was
performed with artificial neural networks. Digitized
fluorescence data from the original extract plus the
seven dilutions were concatenated into a single fact
file. Fact files from the 3 known areas within the rail
yard site were combined with some creosote samples and
random files to train the network. Several fact files
were withheld from the training run and used to test the
network's ability to recognize samples from each source
area. Seven generations of network design are
chronicled. Finally, contaminant samples of unknown
source origin were submitted to the best trained and
tested network for assignment of source area
probabilities. Results correlated well with observations
from hydrological engineers studying the same site.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  3513 </NUMBER>
<ORDER>   AAI9528143 </ORDER>
<TITLE> A NEW APPROACH FOR ROBUST PRODUCT AND PROCESS DESIGN USING ARTIFICIAL NEURAL NETWORKS AND THE TAGUCHI METHOD </TITLE>
<AUTHOR> HONG, JUNGEUI </AUTHOR>
<YEAR> 1995 </YEAR>
<INSTITUTION> UNIVERSITY OF MISSOURI - ROLLA; 0135 </INSTITUTION>
<DESCRIPTORS> ENGINEERING, INDUSTRIAL; ENGINEERING, MECHANICAL; ENGINEERING, AUTOMOTIVE; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> KENNETH M. RAGSDELL </ADVISER>
<CLASSIFICATIONS> INTELLIGENT MANUFACTURING </CLASSIFICATIONS>
<ABSTRACT>
The research presented in this dissertation concerns the
application of artificial neural networks to the Taguchi
type experimental design for robust product or process
design.
In Quality Engineering, and in most experimental design
cases, understanding the relationship between design
factors and product or process performance is essential
for improving quality. Because most manufacturing
conditions are so complicated, a large number of
experiments are generally required. Taguchi's approach
can systematically reduce the number of experiments
required. But in certain cases, where interaction exist
between design factors, the level average analysis will
not select optimum condition. To overcome this weakness,
after orthogonal array experiments are performed, an
artificial neural network is used to select the optimum
conditions instead of traditional level average
analysis.
Actual applications, design of a Wheatstone Bridge,
design of a four-bar linkage and design of an ultrasonic
plastic welding process, proved that this approach can
select real optimum points both within and between
factor levels.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  3514 </NUMBER>
<ORDER>   AAGNN08305 </ORDER>
<TITLE> DESIGN AND IMPLEMENTATION OF GALLIUM ARSENIDE CCD/MESFET ICS FOR ARTIFICIAL NEURAL NETWORK APPLICATION </TITLE>
<AUTHOR> CHEN, LIDONG </AUTHOR>
<YEAR> 1995 </YEAR>
<INSTITUTION> UNIVERSITY OF VICTORIA (CANADA); 0244 </INSTITUTION>
<DESCRIPTORS> ENGINEERING, ELECTRONICS AND ELECTRICAL; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> H. H. L. KWOK </ADVISER>
<CLASSIFICATIONS> NIL </CLASSIFICATIONS>
<ABSTRACT>
The research work in this thesis can be divided into two
parts. The first part was on the modeling and design of
high-speed GaAs CMCCDs (cermet-gate charge-coupled
devices), which is a part of a research collaboration
between TRIUMF and the University of Victoria. The
second part was a project on the design and the
implementation of a prototype GaAs artificial neural
network (ANN) IC using CMCCDs and MESFET technologies.
The research on high-speed GaAs CMCCDs in this thesis
primarily focused on the modeling of the charge transfer
properties of the device, as well as an attempt to
develop a design methodology to optimize the device
structure. On the modeling side, we have developed two-
dimensional numerical models such that they will allow
us to compute the channel potential distribution and the
charge transfer efficiency for different device
geometries and clocking schemes. In addition, an
equivalent circuit model was developed and it allowed us
to more efficiently (than the numerical model) study the
transient effects of the clock waveforms using a SPICE-
type simulator. Using our numerical device models and an
optimization algorithm, we have also developed a design
method that will allow us to optimize the device
geometry for both the two-phase and the uni-phase
CMCCDs. For the particular uni-phase CMCCD that is of
interest to us and TRIUMF, our theoretical analysis has
predicted a device performance that is in close
agreement with what we measured on a fabricated CMCCD.
The second phase of our research was on the design of a
prototype ANN IC using the GaAs CMCCDs and MESFET
circuits. The CMCCDs were to be used as the analog
storage elements of the synaptic weights as well as the
binary shift-register in the ANN circuit. For these
purposes, we have tested extensively the signal-to-noise
ratio and the linearity of the CMCCDs. The ANN circuit
was designed based on the popular Hopfield model and can
be used as an associative memory. We have developed a
hybrid ANN architecture to reduce the number of the
components that is required. In this architecture, each
synapse is made up of a CMCCD (for the weight storage)
and a transconductance amplifier (for the
multiplication). The result of the neuron weight-
summation is multiplexed by an activation circuit that
performs a hard-limiting function. The feedback to the
synapses was achieved using shift- and buffer-registers.
An ANN circuit with 16 neurons and several subcircuits
were fabricated using the NT/BNR 0.8 $mu$m GaAs
depletion-mode MESFET technology and this technology
unfortunately is not able to support the fabrication of
the CCDs. A multi-chip approach was therefore taken and
the CMCCDs were fabricated using the TRIUMF GaAs
technology. The individual subcircuits and CMCCDs were
tested at frequencies up to 200 MHz. The entire system,
however, was only tested up to 40 MHz due to the testing
environment. Nevertheless, a very good agreement between
measurements and simulations was observed. When it was
tested as an associative memory, the ANN IC appears to
be fairly robust since it can withstand an error rate up
to 25%.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  3515 </NUMBER>
<ORDER>   AAI9528047 </ORDER>
<TITLE> A COMPARATIVE INVESTIGATION OF THE UTILITY OF DYNAMIC COMPENSATION IN FUZZY CONTROL </TITLE>
<AUTHOR> LEWIS, HAROLD WARREN, III </AUTHOR>
<YEAR> 1995 </YEAR>
<INSTITUTION> STATE UNIVERSITY OF NEW YORK AT BINGHAMTON; 0792 </INSTITUTION>
<DESCRIPTORS> ENGINEERING, SYSTEM SCIENCE; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> NIL </ADVISER>
<CLASSIFICATIONS> NIL </CLASSIFICATIONS>
<ABSTRACT>
The broadest purpose of this dissertation is to present
a view of the fuzzy control methodology that emphasizes
its relationships with other technologies. Thus, three
introductory chapters contain detailed, conceptual
treatments of conventional control theory, artificial
intelligence, and fuzzy set theory; and two further
background chapters discuss how these three bodies of
knowledge tie together to provide a clearer
understanding of fuzzy control in its many, varied
forms. These chapters also contain a somewhat original
treatment of the mathematical formalisms that underlie
approximate reasoning by linguistic variables and fuzzy
logic. This treatment is arguably much more
straightforward than the one usually found in the
literature. However, a proof is also given to show that
the two treatments are equivalent in results.
This approach flows naturally into the second half of
the dissertation which describes original empirical
research. This is perhaps the most methodical research
to date that is addressed specifically to the question
of how valuable dynamic compensation is in the context
of fuzzy control designs. The essence of the behavior of
an actual, very small steam engine is captured within a
computer by means of neural approximation networks.
Next, fuzzy control devices, with and without various
forms of dynamic compensation, are designed to control
the steam engine. The various designs are optimized by
means of a genetic based auto-tuning technique. Finally,
the control designs are rigorously tested and compared
by simulation within the computer. The results indicate
that a derivative term is extremely valuable in fuzzy
control, not only because it improves performance, but
also because it makes the controller less sensitive to
possible imperfections in its design. An integral term
can also improve performance, but only under some
conditions, and only if some care is taken in optimizing
the design. Because auto-tuning techniques are not
readily available for fuzzy control, one can conclude
that most fuzzy control designs in the future should use
both derivative and integral terms.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  3516 </NUMBER>
<ORDER>   AAI9527772 </ORDER>
<TITLE> TIME-FREQUENCY ANALYSIS WITH NEURAL NETWORK CLASSIFICATION FOR INTRACARDIAC ARRHYTHMIA RECOGNITION </TITLE>
<AUTHOR> YAN, MING-CHUAN </AUTHOR>
<YEAR> 1995 </YEAR>
<INSTITUTION> THE UNIVERSITY OF MICHIGAN; 0127 </INSTITUTION>
<DESCRIPTORS> ENGINEERING, ELECTRONICS AND ELECTRICAL; ENGINEERING, BIOMEDICAL; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> JANICE M. JENKINS </ADVISER>
<CLASSIFICATIONS> CARDIAC ARRHYTHMIA, DEFIBRILLATORS </CLASSIFICATIONS>
<ABSTRACT>
Implantable cardioverter defibrillators (ICDs) are
capable of detecting potentially lethal cardiac
arrhythmias, the major cause of sudden cardiac death,
and providing corrective electrical therapy to suppress
the abnormal rhythm. Appropriate therapy from these
devices depends upon correct classification of malignant
and benign rhythms. Heart rate is the principal means of
discriminating arrhythmias from normal rhythms in ICDs.
This method, while highly sensitive, is seriously
lacking in specificity leading to numerous false
diagnoses and false delivery of shock. Algorithms
utilizing either time domain or frequency domain methods
have been designed to improve the specificity of
automated diagnosis. As an alternate approach to time or
frequency domain methods, in this thesis research a new
pattern recognition method was designed and implemented
based on time-frequency analysis (tfa) for intracardiac
signal detection and recognition. The purpose of this
implementation is to detect morphological changes
present on the intracardiac signal in the face of
electrophysiological abnormality. Different time-
frequency distributions (tfd) were tested on sinus
rhythm (SR) and ventricular tachycardia (VT) passages of
16 patients in this research. Results show that tfa
provides more obvious and detailed distinctions between
SR and VT in every patient than previous morphometrics.
Even in cases where SR and VT waveforms are highly
correlated in time domain, the SR and VT time-frequency
representations reveal distinct differences. Features
were extracted from the tfd of each cycle and a new
design for signal analysis by characterizing the time-
frequency features of normal and abnormal conduction was
developed. A neural network mechanism was added to
interpret and classify categories of rhythms via their
time-frequency domain features. Statistical analysis
shows that combined time-frequency analysis with neural
network classification provided better sensitivity and
specificity in intracardiac arrhythmia classification
than previously developed methods.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  3517 </NUMBER>
<ORDER>   AAI9527608 </ORDER>
<TITLE> A COMPARISON OF GENETIC ALGORITHMS AND OTHER MACHINE LEARNING SYSTEMS ON A COMPLEX CLASSIFICATION TASK FROM COMMON DISEASE RESEARCH  </TITLE>
<AUTHOR> CONGDON, CLARE BATES </AUTHOR>
<YEAR> 1995 </YEAR>
<INSTITUTION> THE UNIVERSITY OF MICHIGAN; 0127 </INSTITUTION>
<DESCRIPTORS> COMPUTER SCIENCE; HEALTH SCIENCES, PUBLIC HEALTH; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> JOHN H. HOLLAND; JOHN E. LAIRD </ADVISER>
<CLASSIFICATIONS> CORONARY ARTERY DISEASE </CLASSIFICATIONS>
<ABSTRACT>
The thesis project is an investigation of some well-
known machine learning systems and evaluates their
utility when applied to a classification task from the
field of human genetics. This common-disease research
task, an inquiry into genetic and biochemical factors
and their association with a family history of coronary
artery disease (CAD), is more complex than many pursued
in machine learning research, due to interactions and
the inherent noise in the dataset. The task also differs
from most pursued in machine learning research because
there is a desire to explain the dataset with a small
number of rules, even at the expense of accuracy, so
that they will be more accessible to medical researchers
who are unaccustomed to dealing with disjunctive
explanations of data. Furthermore, there is asymmetry in
the task in that good explanations of the positive
examples is of more importance than good explanations of
the negative examples.
The primary machine learning approach investigated in
this research is genetic algorithms (GA's); decision
trees, Autoclass, and Cobweb are also included. The GA
performed the best in terms of descriptive ability with
the common-disease research task, although decision
trees also demonstrated certain strengths. Autoclass and
Cobweb were recognized from the onset as being
inappropriate for the needs of common-disease
researchers (because both systems are unsupervised
learners that create probabilistic structures), but were
included for their interest in the machine learning
community; these systems did not perform as well as GA's
and decision trees in terms of their ability to describe
the data. In terms of predictive accuracy, all systems
performed poorly, and the differences between any two of
the three best systems is not significant. When positive
and negative examples are considered separately, the GA
does significantly better than the other systems in
predicting positive examples and significantly worse in
predicting negative examples.
The thesis illustrates that the investigation of "real"
problems from researchers in other fields can lead
machine learning researchers to challenge their systems
in ways they may not otherwise have considered, and may
lead these researchers to a symbiotic relationship that
benefits multiple research communities.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  3518 </NUMBER>
<ORDER>   AAI9527585 </ORDER>
<TITLE> A NEURAL NETWORK DECISION MODEL FOR MANAGING PRODUCT MIX IN MANUFACTURING </TITLE>
<AUTHOR> BENHAJLA, SAIDA </AUTHOR>
<YEAR> 1995 </YEAR>
<INSTITUTION> THE UNIVERSITY OF MICHIGAN; 0127 </INSTITUTION>
<DESCRIPTORS> ENGINEERING, INDUSTRIAL; OPERATIONS RESEARCH; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> JOHN R. BIRGE </ADVISER>
<CLASSIFICATIONS> NIL </CLASSIFICATIONS>
<ABSTRACT>
We address the product mix problem in manufacturing and
develop optimal and heuristic approaches to solving it
for realistic product mix problems. Our contribution has
three important dimensions: the first involves
developing a neural network to solving the two stage
stochastic program with mixed integer variables and
linear or non-linear objective functions. The second
contribution is the heuristic we design for solving
multiple criteria optimization problems using an
integration of our neural network and existing
interactive multiple objective procedures. Finally, our
third contribution is to provide computational results
on how our methodology can be used to make product mix
decisions that benefit the company as a whole and
maximize its performance. We use the data collected at a
major U.S. automaker and we present comparisons of our
algorithm's computational performance relative to
existing optimization tools.
A key advantage to our neural network methodology is
that we efficiently solve the resulting two stage
problem (with binary variables). Alternative traditional
cutting plane methods are not efficient in such cases
unless the stage II formulation is very simple.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  3519 </NUMBER>
<ORDER>   AAI9527517 </ORDER>
<TITLE> COLLABORATIVE LEARNING WITH INTELLIGENT TUTORING SYSTEMS </TITLE>
<AUTHOR> MCMANUS, MARGARET MARY </AUTHOR>
<YEAR> 1995 </YEAR>
<INSTITUTION> TEMPLE UNIVERSITY; 0225 </INSTITUTION>
<DESCRIPTORS> COMPUTER SCIENCE; EDUCATION, TECHNOLOGY; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> ROBERT AIKEN </ADVISER>
<CLASSIFICATIONS> NIL </CLASSIFICATIONS>
<ABSTRACT>
Collaborative learning has been used in education since
ancient times. However, students need to learn how to
work effectively in a collaborative learning
environment. Intelligent Tutoring Systems have
traditionally tutored individual students working on a
single computer or terminal. The methodology for
designing group support systems is provided by the area
of Computer-Supported Cooperative Work.
This dissertation describes an Intelligent Collaborative
Learning System (ICLS) and its Group Leader which are
based on these three research areas. The ICLS supports
students working in a networked collaborative learning
environment. The Group Leader paradigm of pedagogical
expertise coaches, monitors, and tutors students to
learn collaborative skills as they work on the task and
discussion levels.
We discuss the model, design, implementation, and
prototype of the ICLS and its Group Leader. The results
of qualitative experimental research show that students
were satisfied with the system and thought that it was
useful and successful for their collaborative work.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  3520 </NUMBER>
<ORDER>   AAI9527496 </ORDER>
<TITLE> STOCHASTIC ELECTRIC POWER SYSTEM OPERATIONS PLANNING </TITLE>
<AUTHOR> KASANGAKI, VINCENT B. A. </AUTHOR>
<YEAR> 1995 </YEAR>
<INSTITUTION> TEMPLE UNIVERSITY; 0225 </INSTITUTION>
<DESCRIPTORS> ENGINEERING, ELECTRONICS AND ELECTRICAL; OPERATIONS RESEARCH; ARTIFICIAL INTELLIGENCE; ENERGY </DESCRIPTORS>
<ADVISER> MUSOKE H. SENDAULA; SAROJ K. BISWAS </ADVISER>
<CLASSIFICATIONS> NEURAL NETWORKS </CLASSIFICATIONS>
<ABSTRACT>
The main objective of an electric power system
operations plan is to be able to meet demand at the
least possible cost, and with some specified level of
reliability and adequate quality. This dissertation
presents two new techniques for electric power system
operations planning under conditions of uncertainties in
both the load demand and unit availability. Electric
power operations planning is generally formulated as a
nonlinear mixed integer dynamic programming problem. The
system hourly load demand is modelled as a Gaussian
normal random variable. Unit outages are modelled as
Markov processes with appropriate characteristics. The
unit commitment-status variables are (0,1) integers
while the unit loading/dispatch levels take on decimal
values; thus making the problem a mixed integer one.
In both methods generalized stochastic Hopfield and Chua-
Kennedy neural networks for the non-linear optimization
problem are formulated. The first method formulates a
Hopfield artificial neural network for the deterministic
equivalent of the stochastic optimization problem. The
neural network when started from an arbitrary state
settles at a local minimum of the deterministic
equivalent energy function. The problem solutions are
the expected values of the unit commitment-status
variables, and unit loading levels. In the second
method, the fact that the system load demand and unit
availability are random processes is utilized. Hence the
unit commitment-status variables and the unit loading
levels are modelled as sample path solutions of
appropriately derived stochastic differential equations.
Both methods are applied to power system data from a
utility in the USA.
The major advantages of the new methods over those
currently in use for the stochastic problem are the
ability to commit and dispatch units simultaneously, and
to account for the effect of forced outages on unit
availability in a chronological manner. The operations
plans obtained by using the methods developed in this
dissertation are better than those obtained by
conventional techniques due to the more realistic
representation of the stochastic phenomena in the power
system.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  3521 </NUMBER>
<ORDER>   AAI9526935 </ORDER>
<TITLE> AN ADAPTIVE FUZZY LOGIC CONTROLLER FOR PROCESS CONTROL </TITLE>
<AUTHOR> LU, JUN </AUTHOR>
<YEAR> 1995 </YEAR>
<INSTITUTION> NORTH CAROLINA STATE UNIVERSITY; 0155 </INSTITUTION>
<DESCRIPTORS> ENGINEERING, MECHANICAL; ENGINEERING, SYSTEM SCIENCE; TEXTILE TECHNOLOGY; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> GORDON LEE; WARREN JASPER </ADVISER>
<CLASSIFICATIONS> NIL </CLASSIFICATIONS>
<ABSTRACT>
Complex industrial processes such as batch chemical
reactors, steelmaking, dyeing processes and metal
forming offer challenges in control due to the
uncertainty and complexity of the processes. Model-based
control methods generally require some knowledge of
system structure and possibly some bounds on the
uncertainty of the system parameters. In the case where
system identification is not feasible, knowledge-based
methods offer an alternative solution to control. One
such method, fuzzy logic control (FLC), which simulates
the decision making process of an experienced expert, is
discussed for this research.
The development of fuzzy logic controllers needs full
knowledge and experience of the processes, which
somewhat limits the application. In this dissertation,
self-learning adaptive fuzzy logic control schemes are
developed. The schemes are extended to multivariable
processes combined with optimization techniques. Also,
the stability issue of fuzzy logic controllers is
analyzed. Further, verification of the adaptive fuzzy
logic control schemes is shown through both computer
simulation results and actual experimental results of a
batch dyeing process.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  3522 </NUMBER>
<ORDER>   AAI9526836 </ORDER>
<TITLE> APPLICATION AND INTEGRATION OF QUANTUM-EFFECT DEVICES FOR CELLULAR VLSI  </TITLE>
<AUTHOR> LEVY, HAROLD JOSEPH </AUTHOR>
<YEAR> 1995 </YEAR>
<INSTITUTION> CALIFORNIA INSTITUTE OF TECHNOLOGY; 0037 </INSTITUTION>
<DESCRIPTORS> ENGINEERING, ELECTRONICS AND ELECTRICAL; COMPUTER SCIENCE; PHYSICS, ELECTRONICS AND ELECTRICITY; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> THOMAS MCGILL </ADVISER>
<CLASSIFICATIONS> MACHINE VISION, NEURAL NETWORK </CLASSIFICATIONS>
<ABSTRACT>
Cellular VLSI is that subclass of electronic systems for
which small perturbations in a repeated cell design can
dramatically influence the cost and performance of the
entire system. This thesis presents examples of how the
room-temperature quantum effects of tunneling and
resonance may be used to condense the functionality of
many conventional VLSI devices into a smaller and more
efficient subunit, thus yielding tremendous benefits for
the system as a whole. In particular, two and three-
terminal applications of a complimentary pair of quantum-
effect devices, the resonant-tunneling diode and the
tunneling-switch diode, are presented.
The first example is an image-segmentation network for
machine vision, implemented by using resonant-tunneling
diodes in one and two-dimensional networks to extract
boundaries between regions of constant spatial texture.
In this case a single quantum-effect device may replace
up to thirty-three CMOS transistors per pixel.
The second example is an artificial neural-network
processor based on multistate resistors for synaptic
conductances. These programmable resistors were produced
by combining a vertically-integrated stack of resonant-
tunneling diodes with a resistive load and a single
MOSFET driven in its ohmic region. This macrostructure
has the potential to provide synaptic changes on the
picosecond time scale at length scales well below one
micron.
The third example is a current-mode transistorless
memory array based on a two-dimensional network of cells
containing only a single tunneling-switch diode and a
resistive load. The resulting system has the potential
for reaching more than an order-of-magnitude more cell
density than state-of-the-art DRAM arrays, while
operating at state-of-the-art SRAM speeds and reasonable
power consumption.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  3523 </NUMBER>
<ORDER>   AAI9526749 </ORDER>
<TITLE> INTEGRATION OF MACHINERY CONDITION MONITORING AND RELIABILITY MODELING:  A PRELUDE TO PREDICTIVE MAINTENANCE  </TITLE>
<AUTHOR> LIN, CHANG-CJING </AUTHOR>
<YEAR> 1995 </YEAR>
<INSTITUTION> THE FLORIDA STATE UNIVERSITY; 0071 </INSTITUTION>
<DESCRIPTORS> ENGINEERING, INDUSTRIAL; ENGINEERING, AUTOMOTIVE; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> HSU-PIN (BEN) WANG </ADVISER>
<CLASSIFICATIONS> NEURAL NETWORK, CMAC </CLASSIFICATIONS>
<ABSTRACT>
Condition Based Maintenance (CBM) is a philosophical
approach that uses the most cost effective methodology
for the performance of machinery maintenance. The idea
is to ensure maximum operational life and minimum
downtime of machinery within predefined cost, safety and
availability constraints. When machinery life extension
is a major consideration the CBM approach usually
involves predictive maintenance. In this research a two-
level approach for predictive maintenance has been
defined: (1) to develop a Condition Monitoring and
Diagnostic System (CMDS) for machine fault detection and
maintenance suggestion, and (2) to develop a machine
performance estimation model for machine reliability
modeling and failure rate analysis. The objective is to
provide a new and practicable solution for condition-
based predictive maintenance.
In this research artificial neural network (ANN)
technologies and analytical models have been
investigated and incorporated to increase the
effectiveness and efficiency of CMDS. Several advanced
vibration trending methods have been studied and used to
quantify machine operating conditions. An on-line, multi-
channel condition monitoring procedure has been
developed and coded. The major technique used for fault
diagnostics is a modified ARTMAP neural network. In the
second part of this research a new method of obtaining
maintenance information has been developed. A Cerebellar
Model Articulation Controller (CMAC) neural network has
been employed to estimate and quantify machine
performance. By combining reliability theory with a real-
time, on-line CMAC Performance Estimation Model (CMAC-
PEM), machine reliability statistics such as failure
rate and mean time between failures (MTBF) can be
calculated. CMAC-PEM may provide a practicable solution
for condition-based predictive maintenance since it
estimates machine reliability measures on-line. In
addition, Weibull Proportional Hazards Model (WPHM), has
been implemented as a proven tool to verify CMAC-PEM
results. Real-world data obtained from a bearing fault
experiment and a bearing deterioration process were
provided to test the proposed methodologies.
Essentially, this research presents an innovative method
to synthesize low level information, such as vibration
signals, with high level information, like reliability
statistics, to form a rigorous theoretical base for
condition-based predictive maintenance.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  3524 </NUMBER>
<ORDER>   AAI9526632 </ORDER>
<TITLE> NOVEL ARCHITECTURES AND DEVICES FOR COMPUTING </TITLE>
<AUTHOR> WAUGH, FREDERICK ROGERS </AUTHOR>
<YEAR> 1995 </YEAR>
<INSTITUTION> HARVARD UNIVERSITY; 0084 </INSTITUTION>
<DESCRIPTORS> PHYSICS, SOLID STATE; COMPUTER SCIENCE; PHYSICS, ELECTRONICS AND ELECTRICITY; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> ROBERT M. WESTERVELT </ADVISER>
<CLASSIFICATIONS> NEURAL NETWORK, QUANTUM DOT, TUNNELING </CLASSIFICATIONS>
<ABSTRACT>
This thesis explores some of the more unusual
architectures and devices being considered today as the
basis for information processing, emphasizing
architectures that are highly parallel and devices that
are extremely small compared to current standards.
The first part of this thesis theoretically and
numerically analyzes analog electronic neural networks
in which competition within neuron clusters leads to
pattern classification and feature extraction abilities.
Global stability theorems, derived using a Liapunov
approach, provide general guidelines for network design
and operation. The theorems state that with continuous-
time updating, competitive networks converge only to
fixed points, while with discrete-time, parallel
updating, they converge to either fixed points or period-
two limit cycles. A stability criterion guarantees that
discrete-time networks converge only to fixed points
when a quantity related to the neuron gain, or transfer
function slope, is sufficiently small.
A set of analytical phase diagrams for competitive
associative memories is derived using a combination of
statistical mechanics and nonlinear dynamics. The
diagrams classify attractor types as a function of
pattern storage fraction and neuron gain. Numerical
tests agree well with the diagrams.
Analog annealing, a technique for improving network
performance by reducing neuron gain, is shown to improve
performance in an analog associative memory by
dramatically reducing the number of fixed points. The
number of fixed points decreases exponentially with
network size with a scaling exponent that decreases with
neuron gain. Numerical data based on fixed-point counts
in small networks support the results.
The second part of this thesis discusses low-temperature
tunneling measurements at zero magnetic field through
double and triple quantum dots with adjustable inter-dot
coupling, fabricated in a GaAs/AlGaAs heterostructure.
The devices have capacitances so small that the charging
energy of adding an electron is much greater than the
thermal energy at dilution refrigerator temperatures.
The measurements, which explore how changing inter-dot
coupling affects device conductance, are important for
quantum dots used as "artificial atoms" or as "single-
electron transistors" in larger arrays.
For single quantum dots, single-electron charging leads
to dramatic conductance peaks. For arrays of two and
three quantum dots, the conductance peaks each split
into two (double dot) or three (triple dot) peaks as the
inter-dot coupling increases. The splitting closely
tracks the measured tunnel conductance and
experimentally determines the interaction energy.
Coupled double and triple dots with different gate
capacitance show quasiperiodic beating. Monte Carlo
simulations of a classical capacitive charging model
qualitatively reproduce the observed structure, even
though the underlying splitting mechanism is most likely
quantum mechanical.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  3525 </NUMBER>
<ORDER>   AAGNN08237 </ORDER>
<TITLE> APPLICATION DE LA LOGIQUE PROBABILISTE A LA FIABILITE DES RESEAUX ELECTRIQUES ET DES SYSTEMES DE BARRAGES </TITLE>
<AUTHOR> DOUANYA NGUETSE, GUY BLAISE </AUTHOR>
<YEAR> 1995 </YEAR>
<INSTITUTION> ECOLE POLYTECHNIQUE, MONTREAL (CANADA); 1105 </INSTITUTION>
<DESCRIPTORS> COMPUTER SCIENCE; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> BRIGITTE JAUMARD; PIERRE HANSEN </ADVISER>
<CLASSIFICATIONS> FRENCH TEXT, BELIEF NETWORKS, PROBABILISTIC LOGIC, BOUNDS </CLASSIFICATIONS>
<ABSTRACT>
After a period of relative disfavor, models based on
probability theory are increasingly used for reasoning
under uncertainty in knowledge-based systems. Such
models differ in the independence assumptions which are
made and in the amount of information required from the
expert. At one extreme of the spectrum, belief networks
which represent graphically the variables of the domain
under study and their probabilistic relationship, make
strong conditional independence assumptions and require
sufficient information for the joint probability
distribution on the space of possible outcomes to be
entirely specified. When those requirements are
satisfied the probability of any event may be computed,
often in moderate time. However, the requirement of
giving precise conditional probabilities for an often
large number of configurations is very demanding and may
be unrealistic. At the other extreme of the spectrum
some models make no explicit independence assumptions
and require only as little and as much probability
information as is available. Moreover, this information
may be given by intervals instead of single values.
Among such models, probabilistic satisfiability (or
scPSAT, better known under the name of probabilistic
logic in artificial intelligence) has attracted much
attention. Given a set of logical sentences together
with probabilities that these sentences are true, the
decision version of scPSAT consists in assessing whether
these probabilities are consistent or not. The
optimization version of scPSAT consists in determining
best possible lower and upper bounds on the probability
of an additional sentence to be true. We first summarize
the many results obtained, since George Boole, for
scPSAT and its extensions. We then show that the
classical model of belief networks can be viewed as a
particular case of scPSAT. Moreover several significant
extensions may be taken into account while keeping a
linear model. Recently, a decomposition-oriented version
of scPSAT has been proposed. It is noted that both
versions of scPSAT give the same bounds on the truth
probability of the objective function sentence. As a
consequence, the usual version of scPSAT takes
implicitly into account, in terms of objective function
value, the conditional independence relations expressed
in the decomposition-oriented version. A column
generation algorithm for the decomposition-oriented
version of scPSAT is proposed. scPSAT has been
criticized on the grounds that the probability intervals
obtained may be too large and hence of little practical
use. As the bounds are, in fact, best possible, they
reflect the knowledge the expert has been willing to
provide. Getting more precise bounds requires further
information. This point is illustrated by an application
of scPSAT to two-terminal network reliability. Knowledge
of bounds on the probabilities of simultaneous operation
(or failure) of edges and pairs of edges significantly
improve bounds on two-terminal obtained using only data
on single edge operations. Moreover relaxing the
traditional assumption of failure independence makes
model more realistic.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  3526 </NUMBER>
<ORDER>   AAI9526349 </ORDER>
<TITLE> INSTRUMENTATION AND CONTROL OF MINIATURIZED ACTIVE VISION SYSTEM  </TITLE>
<AUTHOR> GREVE, DOUGLAS N. </AUTHOR>
<YEAR> 1995 </YEAR>
<INSTITUTION> BOSTON UNIVERSITY; 0017 </INSTITUTION>
<DESCRIPTORS> ENGINEERING, SYSTEM SCIENCE; COMPUTER SCIENCE; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> ERIC L. SCHWARTZ </ADVISER>
<CLASSIFICATIONS> ROBOT VISION </CLASSIFICATIONS>
<ABSTRACT>
An active vision system is a device which uses the
mobility of an eye or camera to enhance visual
perception. This dissertation describes robotic methods
used to instrument and control a low-cost, high-
performance, miniaturized, active vision system with
many features similar to biological vision, including
visual saccades and smooth tracking. The camera was
actuated by a novel mechanism known as the Spherical
Pointing Motor, or SPM. The SPM is a direct-drive device
that provides some unique advantages in speed, size, and
cost--parameters that are of importance in practical
applications of robotic vision systems. The motor and
camera occupy a volume of less than 11 cubic inches and
weigh only 365 grams. The dynamics of the SPM were
studied both theoretically and empirically. The SPM is
non-linear, cross-coupled, and also highly underdamped,
all properties unfavorable for active vision. Modern
control techniques could be used to compensate for these
problems if the absolute position of the SPM rotor were
available. The small size of the SPM precluded use of
traditional position sensors to measure the angles of
rotation. Accordingly, hardware for a custom position
sensor was designed, built, and integrated into the SPM.
This sensor, based on the search coil technique, added
virtually no size or weight to the motor. With this
position sensor, a hybrid open-/closed-loop control
scheme was implemented. It dampens the SPM using
negative velocity feedback and linearizes and decouples
the SPM response by using look-up tables. Though auto-
calibration of such look-up tables has often used a
cerebellum-inspired neural network (e.g., CMAC), the
repeatability of the SPM allowed off-line
precalibration. The system can make saccadic movements
in 200 milliseconds and achieves velocities in excess of
1500$spcirc$/sec. When integrated with a visual data
processing system that uses a control architecture
inspired by the mammalian vision system, the resulting
system can maintain tracking of a target moving at
80$spcirc$/sec. Excepting the optics, there are no
precision parts in the motor or position sensor. This
research demonstrated the feasibility of building
miniature active vision systems that are easily and
cheaply manufactured without sacrificing performance.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  3527 </NUMBER>
<ORDER>   AAI9526126 </ORDER>
<TITLE> BACKCALCULATION OF FLEXIBLE PAVEMENT MODULI FROM FALLING WEIGHT DEFLECTOMETER DATA USING ARTIFICIAL NEURAL NETWORKS  </TITLE>
<AUTHOR> MEIER, ROGER WILLIAM </AUTHOR>
<YEAR> 1995 </YEAR>
<INSTITUTION> GEORGIA INSTITUTE OF TECHNOLOGY; 0078 </INSTITUTION>
<DESCRIPTORS> ENGINEERING, CIVIL; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> GLENN J. RIX </ADVISER>
<CLASSIFICATIONS> NONDESTRUCTIVE TESTING, PAVEMENT </CLASSIFICATIONS>
<ABSTRACT>
The Falling Weight Deflectometer (FWD) test is one of
the most widely used tests for assessing the structural
integrity of pavement systems in a nondestructive
manner. A major limitation of existing techniques for
backcalculating pavement layer moduli from FWD results
is that they are computationally inefficient. This not
only makes them tedious to use, it also constrains them
to employ simplified static models of the FWD test that
can be computed relatively quickly. Studies have shown
that significant errors in the backcalculated pavement
moduli can accrue from using a static model of what is
inherently a dynamic test.
The goal of this research was to develop a method for
backcalculating pavement layer moduli from FWD data in
real time. This was accomplished by training an
artificial neural network to approximate the
backcalculation function using large volumes of
synthetic test data generated by static and dynamic
pavement response models. One neural network was trained
using synthetic test data generated by the same static,
layered-elastic model used in the conventional
backcalculation program WESDEF. That neural network was
shown to be just as accurate but 2500 times faster. The
same neural network was subsequently retrained using
data generated by a elastodynamic model of the FWD test.
The dynamic analysis provides a much better
approximation of the actual test conditions and avoids
problems inherent in the static analysis. Based on the
amounts of time needed to create the static and dynamic
training sets, a conventional program would likely run
20 times slower if it employed the dynamic model. The
processing time of the neural network, on the other
hand, is unchanged because it was simply retrained using
different data.
These artificial neural networks provide the real-time
backcalculation capabilities needed for more thorough,
more frequent, and more cost-effective pavement
evaluations. Furthermore, they permit the use of more-
realistic models, which can increase the accuracy of the
backcalculated moduli.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  3528 </NUMBER>
<ORDER>   AAI9526125 </ORDER>
<TITLE> SYNTAX-SEMANTICS INTERACTION IN SENTENCE UNDERSTANDING </TITLE>
<AUTHOR> MAHESH, KAVI </AUTHOR>
<YEAR> 1995 </YEAR>
<INSTITUTION> GEORGIA INSTITUTE OF TECHNOLOGY; 0078 </INSTITUTION>
<DESCRIPTORS> COMPUTER SCIENCE; LANGUAGE, LINGUISTICS; PSYCHOLOGY, GENERAL; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> KURT P. EISELT </ADVISER>
<CLASSIFICATIONS> NATURAL LANGUAGE, PARSING </CLASSIFICATIONS>
<ABSTRACT>
Natural language is the primary mode of human
communication. Developing a complete and well-specified
computational model of language understanding is a
difficult problem. Understanding a natural language
sentence requires the application of many types of
knowledge, such as syntactic, semantic, and conceptual
knowledge, to resolve the many types of ambiguities that
abound in natural language. Most unresolved issues in
both psychological and computational modeling of
sentence understanding are concerned with the questions
of when should each of the various types of knowledge be
applied in processing a sentence and how should the
different types of knowledge be integrated to select
unique interpretations of sentences.
In this work, we have developed a model of sentence
understanding called COMPERE (Cognitive Model of Parsing
and Error Recovery). Our model was built on the
hypothesis that a sentence processor has an architecture
with separate representations of the different types of
knowledge but a single unified process that integrates
the different types of knowledge. We have shown that
such an architecture addresses the modularity debate by
demonstrating how the same sentence processor can
produce seemingly modular behaviors in some situations
and interactive behaviors in other situations. We have
also shown how the unified arbitrating process can not
only resolve both syntactic and semantic ambiguities,
but also recover from its errors in both syntactic and
semantic ambiguity resolution.
We have developed a parsing algorithm called Head-
Signaled Left-Corner parsing to identify the time course
of points in the sentence where decisions are to be
made. This algorithm decides when to make a commitment
and when to delay a syntactic attachment. We have also
developed a simple arbitration algorithm for combining
information coming from multiple knowledge sources and
for resolving any conflicts between them. We also
present a theoretical framework for formal analyses of
the performance of sentence processors in various
situations. These analyses indicate that the HSLC
parsing algorithm, along with incremental interactions
between syntax and semantics controlled by the unified
arbitrator, reduces the amount of local ambiguity and
working memory requirements in processing a sentence. We
also present certain psychological predictions made by
the COMPERE model.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  3529 </NUMBER>
<ORDER>   AAI9526015 </ORDER>
<TITLE> A DESIGNED EXPERIMENT ON THE USE OF NEURAL-NETWORK MODELS IN SHORT-TERM HOURLY LOAD FORECASTING </TITLE>
<AUTHOR> CHOUEIKI, MOHAMAD HISHAM </AUTHOR>
<YEAR> 1995 </YEAR>
<INSTITUTION> THE OHIO STATE UNIVERSITY; 0168 </INSTITUTION>
<DESCRIPTORS> ENGINEERING, INDUSTRIAL; ENGINEERING, ELECTRONICS AND ELECTRICAL; STATISTICS; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> CLARK A. MOUNT-CAMPBELL </ADVISER>
<CLASSIFICATIONS> NIL </CLASSIFICATIONS>
<ABSTRACT>
This dissertation consists of three stand-alone papers.
The first paper illustrates how optimal experimental
design concepts can be used to systematically quantify
the impact of several factors and factor interactions on
neural-network performance. It also highlights the
importance of data selection from the input space for
training a neural network, especially in cases where
collecting one training example is very costly. Our
results show that it is possible to build a network that
generalizes with a small set of training examples as
long as these examples are carefully chosen rather than
randomly chosen from the input space.
In the second paper, the short-term load forecasting
(STLF) problem is addressed. A fractional factorial
experiment is conducted on using neural networks to
solve the STLF problem. From the results of the
experiment, a set of rules of thumb for building a
'quasi optimal' neural network to solve the STLF problem
is extracted. It is recommended that these rules, and
the restriction on their generality, be followed when
solving the STLF problem with neural networks. Finally,
a comparison study reveals the superiority of the 'quasi
optimal' neural network over the Box-Jenkins seasonal
ARIMA model in solving the STLF problem.
The third paper uses the rules of thumb developed in the
second paper, recognizes the temporal variability in the
cost of being in error over a 24-hour period, and
describes a training process to explicitly incorporate
this variability. This is accomplished by implementing a
weighted least squares procedure during training. The
results indicate that the neural-network model that
implements the weighted least squares procedure
outperforms the neural-network model that implements the
least squares procedure during the on-peak hours (the
expensive production hours) for the four criteria
specified, and for the cost related criterion during the
entire period.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  3530 </NUMBER>
<ORDER>   AAI9525940 </ORDER>
<TITLE> HARDWARE REDUNDANT SYSTEM SIGNAL VALIDATION USING ARTIFICIAL NEURAL NETWORKS </TITLE>
<AUTHOR> YOON, TAE SEOB </AUTHOR>
<YEAR> 1995 </YEAR>
<INSTITUTION> ARIZONA STATE UNIVERSITY; 0010 </INSTITUTION>
<DESCRIPTORS> ENGINEERING, ELECTRONICS AND ELECTRICAL; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> NIL </ADVISER>
<CLASSIFICATIONS> PATTERN RECOGNITION </CLASSIFICATIONS>
<ABSTRACT>
An artificial neural network technique is developed for
hardware redundant system signal validation. A
conventional artificial neural network is modified to
include an additional preprocessing layer that extracts
the classification features from the measurements. A
nonlinear feature extraction function is developed, and
it transforms the measurement space into the parity
space. This neural network implements the analytical
parity space approach (APS) to signal validation without
analytical parity equations. This new approach
integrates neural network and analytical parity space
approaches, and it is named "parity space neural
network" (PSNN). The PSNN makes a decision using parity
space division regions. Since the measurement space is a
continuous space and it has a large number of decision
regions, it is difficult to make correct decisions in an
accurate measurement system. The parity space is a
discrete space with a finite number of decision regions,
for example, 19 decision regions for 3 redundant scalar
measurement sensors, and therefore, it is very easy to
make the correct decision.
In the APS approach the threshold to the no fault region
is a regular hexagonal, and the threshold is not uniform
along directions from the origin. The PSNN uses this
regular hexagonal threshold, and can make the correct
decision. However, the APS uses a uniform (i.e., circle)
threshold, and it has a fundamental problem in accuracy.
The parity space is divided by fault regions, and the
neural networks provide detailed information about these
fault regions, but the APS provides information about
only the error axes. The PSNN combines the above
mentioned advantages of neural networks and the parity
space approach, and improves upon their disadvantages.
The conventional analytical parity space approach is
also implemented in order to compare with the neural
network method. Instantaneous synthetic and operational
data of hardware redundant systems are analyzed using
both techniques and their performance is compared. The
neural network approach makes correct fault detection
and isolation, and provides more detailed information
than the analytical parity space approach.
The analysis of instantaneous signals can easily detect
abrupt changes, however, it is difficult to find
incipient faults. Thus, long-term signal analysis is
performed using the parity space neural network and the
analytical parity space techniques. Long-term
measurement data is directly applied to the neural
network with a measurement space window, and correct
fault detection and isolation is obtained. The long-term
parity space approach is divided into fault detection
and isolation. Measurement data are applied to parity
equations, and a parity vector is obtained. The long-
term parity vector is analyzed using a parity space
window. The performance of the new parity space neural
network is good in instantaneous and long-term sensor
validation. The combination of instantaneous and long-
term signal validation can increase system reliability,
availability, and safety.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  3531 </NUMBER>
<ORDER>   AAI9525898 </ORDER>
<TITLE> EXPERIMENTS IN NEURAL-NETWORK CONTROL OF A FREE-FLYING SPACE ROBOT </TITLE>
<AUTHOR> WILSON, EDWARD </AUTHOR>
<YEAR> 1995 </YEAR>
<INSTITUTION> STANFORD UNIVERSITY; 0212 </INSTITUTION>
<DESCRIPTORS> ENGINEERING, ELECTRONICS AND ELECTRICAL; ENGINEERING, MECHANICAL; ENGINEERING, AEROSPACE; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> STEPHEN M. ROCK </ADVISER>
<CLASSIFICATIONS> NIL </CLASSIFICATIONS>
<ABSTRACT>
Because of their capabilities for adaptation, nonlinear
function approximation and parallel hardware
implementation, neural networks have proven to be well-
suited for some important control applications.
However, several issues are present in many real-world
neural-network control applications that have not yet
been addressed effectively in the literature. Four of
these important generic issues are identified and
addressed as part of the development of an adaptive
neural-network control system for an experimental 2-D
space robot prototype.
The first issue concerns the importance of true system-
level design of the control system. A new hybrid
strategy is developed here for the beneficial
integration of neural networks into the total control
system. The basic philosophy is to borrow heavily from
conventional control theory, using the neural network as
a key subsystem just where its nonlinear, adaptive, and
parallel processing benefits outweigh the associated
costs.
A second important issue concerns incorporating prior
knowledge into the neural-network controller. A "Fully-
Connected Architecture" (FCA) is developed with
functionality beyond that of layered networks, yet still
trainable with backpropagation. The enhanced
capabilities of the FCA are shown to be particularly
beneficial for control tasks. For example, they provide
the ability to pre-program the neural network directly
with a linear approximate controller.
A third issue is that while neural networks are commonly
trained using gradient-based optimization
(backpropagation), many real-world systems have discrete-
valued functions (DVFs) that are not continuously
differentiable. A new technique, using noisy-sigmoid-
based approximating functions during learning, is
developed to address this limitation. The algorithm is
applied to the on-off-thruster control problem, as well
as to training neural networks built with signums
instead of sigmoids.
The fourth issue, speed of adaptation, is often a
limiting factor in the real-time implementation of a
neural control system. This issue is resolved here by
drawing on the above contributions: using the FCA and
automatically growing the network combine to produce
rapid adaptation in an experimental demonstration on a
free-flying space robot.
The neural controller adapts in real time to account for
multiple destabilizing thruster failures. Stability is
restored within 5 seconds, and near-optimal performance
is achieved within 2 minutes.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  3532 </NUMBER>
<ORDER>   AAI9525891 </ORDER>
<TITLE> ALGORITHMS FOR WAVELET TRANSFORMS AND ADAPTIVE WAVELET PACKET DECOMPOSITIONS </TITLE>
<AUTHOR> TASWELL, CARL </AUTHOR>
<YEAR> 1995 </YEAR>
<INSTITUTION> STANFORD UNIVERSITY; 0212 </INSTITUTION>
<DESCRIPTORS> MATHEMATICS; COMPUTER SCIENCE; ENGINEERING, ELECTRONICS AND ELECTRICAL </DESCRIPTORS>
<ADVISER> JOSEPH B. KELLER </ADVISER>
<CLASSIFICATIONS> NIL </CLASSIFICATIONS>
<ABSTRACT>
A wavelet software toolbox called WavBox has been
developed for wavelet transforms and adaptive wavelet
packet decompositions. WavBox provides both a function
library for use in programming and a computing
environment for use in interactive exploratory data
analysis. The scope of this work therefore encompasses
both computational mathematics with the development of
new algorithms as well as computer science with the
development of new interfaces, both textual command and
graphical icon, for the use of these algorithms within
an interactive computing environment.
The development of interfaces for the WavBox computing
environment focused on principles of convenience and
utility for the user. All transform and decomposition
algorithms are integrated for simultaneous use with both
textual command and graphical icon interfaces through an
architectural design incorporating heirarchical modules,
switch-driven function suites, and an object property
expert system with artificial intelligence for
configuring valid property combinations.
The development of computational algorithms focused on
principles of pragmatism. New algorithms include the
development of (a) methods for computing the wavelet
transform of signals of arbitrary length not restricted
to a power of two, (b) satisficing searches instead of
optimizing searches for selecting bases in wavelet
packet transforms, and (c) parameterized-model coding
instead of quantized-vector or quantized-scalar coding
for further compression of the selected transform
decompositions. These methods are shown to be especially
useful for image compression.
Wavelet packet basis decompositions require selection of
a single basis represented as the terminal leaves of a
subtree within a redundant collection of many bases
represented as the full tree. For this purpose, top-down
and bottom-up tree searches with additive and non-
additive information cost functions as decision criteria
are proposed as selection methods. These new algorithms
are satisficing searches and find near-best basis
decompositions.
The satisficing searches are benchmarked in
computational experiments comparing their performance
with optimizing searches (the Coifman-Wickerhauser best
basis decomposition and the Mallat-Zhang matching
pursuit decomposition). Near-best basis decompositions
outperform the other decompositions as measured by
significant increases in efficiency of computation
(reductions in memory, flops, and time) for comparable
levels of distortion on reconstruction after fixed-rate
lossy compression.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  3533 </NUMBER>
<ORDER>   AAI9525882 </ORDER>
<TITLE> DYNAMIC SELECTION OF MODELS </TITLE>
<AUTHOR> RUTLEDGE, GEOFFREY WILLIAM </AUTHOR>
<YEAR> 1995 </YEAR>
<INSTITUTION> STANFORD UNIVERSITY; 0212 </INSTITUTION>
<DESCRIPTORS> HEALTH SCIENCES, MEDICINE AND SURGERY; COMPUTER SCIENCE; ENGINEERING, BIOMEDICAL </DESCRIPTORS>
<ADVISER> ROSS A. SHACHTER </ADVISER>
<CLASSIFICATIONS> CRITICAL CARE MEDICINE </CLASSIFICATIONS>
<ABSTRACT>
This dissertation develops an approach to high-stakes,
model-based decision making under scarce computation
resources, bringing together concepts and techniques
from the disciplines of decision analysis, statistics,
artificial intelligence, and simulation. A method is
developed and implemented to solve a time-critical
decision problem in the domain of critical-care
medicine. This method selects models that balance the
prediction accuracy and the need for rapid action.
Under a computation-time constraint, the optimal model
for a model-based control application is a model that
maximizes the tradeoff of model benefit (a measure of
how accurately the model predicts the effects of
alternative control settings) and model cost (a measure
of the length of the model-induced computation delay).
This work describes a real-time algorithm that selects,
from a graph of models (GoM), a model that is accurate
and that is computable within a time constraint. The DSM
algorithm is a metalevel reasoning strategy that relies
on a dynamic-selection-of-models (DSM) metric to guide
the search through a GoM that is organized according to
the simplifying assumptions of the models. The DSM
metric balances an estimate of the probability that a
model will achieve the required prediction accuracy and
the cost of the expected model-induced computation
delay. The DSM algorithm provides an approach to
automated reasoning about complex systems that applies
at any level of computation-resource or computation-time
constraint.
The DSM algorithm is implemented in Konan, a program
that performs dynamic selection of patient-specific
models from a GoM of quantitative physiologic models.
Konan selects models that allow a model-based control
application (a ventilator-management advisor) to make
real-time decisions for the control settings of a
mechanical ventilator.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  3534 </NUMBER>
<ORDER>   AAI9525880 </ORDER>
<TITLE> SHARP, RELIABLE PREDICTIONS USING SUPERVISED MIXTURE MODELS  </TITLE>
<AUTHOR> ROY, HOWARD SCOTT </AUTHOR>
<YEAR> 1995 </YEAR>
<INSTITUTION> STANFORD UNIVERSITY; 0212 </INSTITUTION>
<DESCRIPTORS> COMPUTER SCIENCE; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> MICHAEL GENESERETH </ADVISER>
<CLASSIFICATIONS> PROBABILISTIC, CLUSTERING ALGORITHMS </CLASSIFICATIONS>
<ABSTRACT>
This doctoral dissertation develops a new way to make
probabilistic predictions from a database of examples.
The method looks for regions in the data where different
predictions are appropriate, and it naturally extends
clustering algorithms that have been used with great
success in exploratory data analysis. In probabilistic
terms, the new method looks at the same models as
before, but it only evaluates them for the conditional
probability they assign to a single feature rather than
the joint probability they assign to all features. A
good models is therefore forced to classify the data in
a way that is useful for a single, desired prediction,
rather than just identifying the strongest overall
pattern in the data.
The results of this dissertation extend the clean,
Bayesian approach of the unsupervised AutoClass system
to the supervised learning problems common in everyday
practice. Highlights include: (1) clear probabilistic
semantics; (2) prediction and use of discrete,
categorical, and continuous data; (3) priors that avoid
the overfitting problem; (4) an explicit noise model to
identify unreliable predictions; (5) the ability to
handle missing data. A computer implementation,
MultiClass, validates the ideas with performance that
exceeds neural nets, decision trees, and other current
supervised machine learning systems.
The dissertation is written for a general audience with
many, many examples to motivate the new ideas. The scope
of potential applications is very large, including
problems like evaluating student admissions
applications, assessing credit risk, and identifying
customers likely to order from Tiffany's latest
Christmas gift catalog.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  3535 </NUMBER>
<ORDER>   AAI9525840 </ORDER>
<TITLE> NONSYSTEMATIC BACKTRACKING SEARCH </TITLE>
<AUTHOR> HARVEY, WILLIAM DAVID </AUTHOR>
<YEAR> 1995 </YEAR>
<INSTITUTION> STANFORD UNIVERSITY; 0212 </INSTITUTION>
<DESCRIPTORS> COMPUTER SCIENCE; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> MATTHEW L. GINSBERG </ADVISER>
<CLASSIFICATIONS> LIMITED DISCREPANCY </CLASSIFICATIONS>
<ABSTRACT>
Many practical problems in Artificial Intelligence have
search trees that are too large to search exhaustively
in the amount of time allowed. Chronological
backtracking can be applied to these problems, but it is
unlikely to find a solution in the explored fraction of
the space because of the order in which it examines
nodes. A nonsystematic technique known as iterative
sampling alleviates the problem by examining fringe
nodes in a random order. Although nonsystematic
techniques do not suffer from the problem of exploring
nodes in a bad order, they do reconsider nodes they have
already ruled out, a problem that is serious when the
density of solutions is low. Unfortunately, for many
practical problems, the order of examining nodes matters
and the density of solutions is low. Consequently,
neither chronological backtracking nor iterative
sampling has good average case performance.
We present a new search algorithm called bounded
backtrack search that combines the merits of
backtracking and iterative sampling. The algorithm
backtracks chronologically until reaching a backtrack
bound, whereupon it immediately backtracks to the root
and restarts on a new random path. We show that the new
algorithm does not suffer from the problems of the
alternatives, and we derive theoretical conditions that
guarantee better average case performance.
Our analysis also shows that chronological backtracking
does not use successor ordering heuristics effectively.
The accuracy of the heuristics for early decisions is
critical to the algorithm's efficiency, whereas the
accuracy is relatively unimportant deep in the tree
because the alternatives are considered quickly.
Unfortunately, heuristics are typically least reliable
for the early decisions--when they are most important.
We present a second new algorithm called limited
discrepancy search that examines nodes in increasing
order of "discrepancies," or points of disagreement with
a problem's heuristics. We show that the algorithm has
exceptional average case performance when the heuristics
are accurate and reasonable performance when the
heuristics are bad. We present experimental results in
job shop scheduling to show that the theoretical
conditions and the expected performance hold for real
problems.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  3536 </NUMBER>
<ORDER>   AAGNN07438 </ORDER>
<TITLE> PERFORMANCE IMPROVEMENT OF UNCERTAIN ROBOTIC SYSTEMS USING NEURAL NETWORKS: ANALYSIS AND EXPERIMENT </TITLE>
<AUTHOR> CHEN, CHAO YU PETER </AUTHOR>
<YEAR> 1995 </YEAR>
<INSTITUTION> UNIVERSITY OF TORONTO (CANADA); 0779 </INSTITUTION>
<DESCRIPTORS> ENGINEERING, MECHANICAL; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> JAMES K. MILLS; KENNETH C. SMITH </ADVISER>
<CLASSIFICATIONS> NIL </CLASSIFICATIONS>
<ABSTRACT>
The behavior of a robotic manipulator is effected by the
torques that drive the joints of the manipulator. Given
a sequence of torque signals, the motion of the
manipulator can be predicted based on an accurate
mathematical model of the manipulator. Controlling a
manipulator represents the "inverse" situation whereby
the desired motion of the manipulator is given and the
sequence of torque signals which produces such motion is
to be determined.
The desired torque signals could in principle be
generated based on the model and the prescription of the
desired motion. This method of deriving the torque
signal is called the "computed torque" method. Because
this control method is based on the mathematical model
of the manipulator, any "mismatch" between the model and
the real system degrades the performance of the
manipulator. It is owing to such mismatch that
uncertainty about the model arises. To improve the
performance of the manipulator requires that the
uncertainty be compensated.
A new approach to improving the performance of uncertain
robotic systems using a neural network is presented in
this dissertation. It is shown that this approach is
applicable to (1) robot free motion, (2) robot compliant
motion, and (3) multi-manipulator systems. In this
approach, a neural network is used to "nullify" the
uncertainty so that performance improvement can be
achieved.
Using techniques from nonlinear system theory, closed-
loop stability of each of the three types of robotic
system (incorporated with a neural network) is analyzed.
Results of the analyses confirm that the systems are
stable in the sense that all signals in each system are
bounded.
A new method for analyzing the performance of these
systems is developed. Using this method, it is shown
that the performance of all three types of system is
improved as the learning process of the neural network
is iterated. Numerical simulations are conducted. The
results of the simulations confirm the conclusions of
the theoretical analyses.
Two types of experiment, one involving robot free motion
and the other involving robot compliant motion, are
conducted. The results of the experiments clearly
demonstrate the effectiveness of the proposed approach.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  3537 </NUMBER>
<ORDER>   AAI9525527 </ORDER>
<TITLE> CONTROL STRUCTURES FOR THE AUTOMATED BENDING OF STEEL REINFORCING BARS  </TITLE>
<AUTHOR> DUNSTON, PHILLIP SHERWOOD </AUTHOR>
<YEAR> 1995 </YEAR>
<INSTITUTION> NORTH CAROLINA STATE UNIVERSITY; 0155 </INSTITUTION>
<DESCRIPTORS> ENGINEERING, CIVIL; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> LEONHARD E. BERNOLD </ADVISER>
<CLASSIFICATIONS> REBAR FABRICATION, NEURAL NETWORK CONTROL </CLASSIFICATIONS>
<ABSTRACT>
The objective of this research was to develop control
structures and test models for automating the bending of
straight steel reinforcing bars. Three major thrusts
provided the focus for approaching this problem: (1)
springback prediction using real-time electronic
sensing, (2) adaptive control of the bending operation,
and (3) transfer of the control system from a laboratory
prototype bender to a shop table bender.
A control framework is presented for linking control of
rebar fabrication automation to planning, scheduling,
and control in a CIC environment. A basic theory for
evaluating the cost of quality through automation
control information at the task level is described.
Bending tests were conducted with a shop table bender to
establish and compare alternative models for springback
prediction. Comparisons of the performance of the
alternative models demonstrated the feasibility of
successful controller operation. A neural network
springback prediction model was included in the
comparative study.
The bending torque curve is an appropriate model for
monitoring, and controlling the operation of a table
bender. Components from the laboratory prototype table
bender control system were successfully transferred to
the shop bender. Critical components of the control
structure were adapted to the new machine through
substitution of sensors and creation of new control
laws.
Springback model evaluations revealed that empirical
statistical models, neural networks, and in-process
relaxation perform well. Nearly 95 percent compliance
with an extrapolated industry standard is achieved with
the existing experimental testing facility. Shared
control through a human-machine interface, however, may
be the best alternative for achieving highest quality
standards and improving worker performance in the areas
safety and productivity.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  3538 </NUMBER>
<ORDER>   AAI9524598 </ORDER>
<TITLE> MULTICLASSIFIER NEURAL NETWORKS FOR HANDWRITTEN CHARACTER RECOGNITION  </TITLE>
<AUTHOR> CHAI, SIN-KUO </AUTHOR>
<YEAR> 1995 </YEAR>
<INSTITUTION> OHIO UNIVERSITY; 0167 </INSTITUTION>
<DESCRIPTORS> ENGINEERING, ELECTRONICS AND ELECTRICAL; COMPUTER SCIENCE; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> JANUSZ A. STARZYK </ADVISER>
<CLASSIFICATIONS> PATTERN RECOGNITION </CLASSIFICATIONS>
<ABSTRACT>
Handwritten character recognition is a highly
challenging area in the field of pattern recognition. In
performing recognition, any single classifier system has
its strengths and weaknesses. The objective of this
dissertation is to develop multiclassifier systems which
utilize the combined strength of several classifiers to
make a significant improvement in recognition over the
single classifiers. The multiclassifier systems
developed were cascaded, vote-to-decide, confidence
enhancement, and hierarchical learning systems. In each
multiclassifier system, the single classifiers contained
their own feature extraction, similarity measure,
learning, and classification stages.
Feature extraction extracted object features and formed
feature representations. Three feature representations
were developed, which were the angle sequence, vector
contour representation (VCR), and Fourier transform
representation (FTR). To evaluate the similarity of
objects in different representation forms, measures
based on Euclidean distance, vector correlation, string
matching cost, and Fourier transform were developed.
For learning, two supervised clustering techniques were
developed: maximum region clustering (MRC) and
accumulated potential clustering (APC). The MRC learning
maximized the clustering regions by including as many
samples of the same type as possible in each cluster
without enclosing any alien sample. In APC learning, the
feature space was viewed as an electrostatic field in
which each cluster served as a potential generating
center. Each object class established the minimum number
of cluster centers necessary to protect its members from
being attracted to other classes.
In the classification stage, the MRC classifiers
identified a test sample with the class of its nearest
cluster center. The APC classifiers assigned a test
sample to the object class which attracted it the most.
In a multiclassifier system, the final classification
decision was made based on the individual decisions made
by the single classifiers. The rules of making a final
classification decision depended on the multiclassifier
system and differed from system to system.
All the developed single classifier and multiclassifier
systems have been simulated on a Sun computer, and the
results were presented. The computer simulation results
showed that the multiclassifier system significantly
improved the recognition performance.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  3539 </NUMBER>
<ORDER>   AAINN95616 </ORDER>
<TITLE> NEURO-ADAPTIVE AND NONLINEAR DAMPING CONTROLS FOR ROBOT MANIPULATORS </TITLE>
<AUTHOR> DERBAL, YOUCEF </AUTHOR>
<YEAR> 1995 </YEAR>
<INSTITUTION> QUEEN'S UNIVERSITY AT KINGSTON (CANADA); 0283 </INSTITUTION>
<DESCRIPTORS> ENGINEERING, ELECTRONICS AND ELECTRICAL; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> M. M. BAYOUMI </ADVISER>
<CLASSIFICATIONS> NIL </CLASSIFICATIONS>
<ABSTRACT>
This thesis proposes a neuro-adaptive control theory for
a class of nonlinear systems. The backbone of the
approach lies in the blending of the linear adaptive
control methodology with neural network-based nonlinear
compensation. An analysis of the convergence of the
neural network adaptation and the stability of the
resulting control system is given. Through its
application to the robot motion control, the feasibility
and merits of the proposed control theory were analyzed.
The second part of the thesis addresses the issue of
robot force control. This part was intended to add to
the lot of available control solutions through seeking
alternative methodologies. In this respect, a nonlinear
active damping controller is proposed along with its
underlying theory. Finally, we proposed an explorative
discussion which addresses the possibility of extending
the application of neural networks to the robot force
control problem.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  3540 </NUMBER>
<ORDER>   AAI1361627 </ORDER>
<TITLE> AN IMPROVED NEURAL NET-BASED APPROACH FOR PREDICTING SOFTWARE QUALITY </TITLE>
<AUTHOR> GUASTI, PETER JOHN </AUTHOR>
<YEAR> 1995 </YEAR>
<INSTITUTION> FLORIDA ATLANTIC UNIVERSITY; 0119 </INSTITUTION>
<DESCRIPTORS> COMPUTER SCIENCE; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> TAGHI M. KHOSHGOFTAAR; ABHIJIT S. PANDYA </ADVISER>
<CLASSIFICATIONS> NIL </CLASSIFICATIONS>
<ABSTRACT>
Accurately predicting the quality of software is a major
problem in any software development project. Software
engineers develop models that provide early estimates of
quality metrics which allow them to take action against
emerging quality problems. Most often the predictive
models are based upon multiple regression analysis which
become unstable when certain data assumptions are not
met. Since neural networks require no data assumptions,
they are more appropriate for predicting software
quality. This study proposes an improved neural network
architecture that significantly outperforms multiple
regression and other neural network attempts at modeling
software quality. This is demonstrated by applying this
approach to several large commercial software systems.
After developing neural network models, we develop
regression models on the same data. We find that the
neural network models surpass the regression models in
terms of predictive quality on the data sets considered.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  3541 </NUMBER>
<ORDER>   AAI9526493 </ORDER>
<TITLE> ANALYSIS AND META-ANALYSIS OF FUZZY RELATIONAL STRUCTURES BY MEANS OF GENERALIZED MORPHISM AND THEIR COMPUTER-AIDED TOOL SUPPORT </TITLE>
<AUTHOR> KIM, EUNJIN </AUTHOR>
<YEAR> 1995 </YEAR>
<INSTITUTION> THE FLORIDA STATE UNIVERSITY; 0071 </INSTITUTION>
<DESCRIPTORS> COMPUTER SCIENCE; PSYCHOLOGY, CLINICAL; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> LADISLAV J. KOHOUT </ADVISER>
<CLASSIFICATIONS> NIL </CLASSIFICATIONS>
<ABSTRACT>
This dissertation describes a technique for
identification of the structures implicit in scientific
data and further develops the supporting methodology for
analysis of fuzzy relational structures using the
mathematical theory of Fuzzy Relations and Generalized
Morphism. Analysis of fuzzy relational structures are
made in three distinctive ways. In the first way, the
fuzzy relational structures which were computed in the
subdomain of the problem can be compared with those in
the complete domain by means of generalized morphism in
order to investigate their contextual matches or
dependencies. In the second way, the fuzzy relational
structures computed by means of various fuzzy logics can
be analyzed using generalized morphism; namely, meta
analysis of fuzzy relational structures. The result of
meta analysis is represented as the Hasse Diagram
structure of meta relations by classifying equivalent
classes of fuzzy relational structures. In the third
way, the property of contrapositive symmetry of fuzzy
relational structures can be efficiently detected using
the classification table of equivalent classes which was
constructed in the meta analysis. Such analysis
processes are also applied to data of several problem
domains: clinical psychological data on Parkinsonian
patients, test data of patients with Ectopic Pregnancy
and Endocrine data from two medical knowledge sources. A
computer-aided tool that supports this analysis, namely
Fuzzy Relational Structure Analysis System (FRSAS), is
designed using the methodology of Activity Structure.
FRSAS is implemented in the programming language Modula-
2.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  3542 </NUMBER>
<ORDER>   AAI9525289 </ORDER>
<TITLE> NEURAL NETWORK CONTROL OF NONLINEAR DISCRETE TIME SYSTEMS </TITLE>
<AUTHOR> ZAKRZEWSKI, RADOSLAW ROMUALD </AUTHOR>
<YEAR> 1995 </YEAR>
<INSTITUTION> OREGON STATE UNIVERSITY; 0172 </INSTITUTION>
<DESCRIPTORS> ENGINEERING, ELECTRONICS AND ELECTRICAL; ENGINEERING, SYSTEM SCIENCE; OPERATIONS RESEARCH; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> RONALD R. MOHLER </ADVISER>
<CLASSIFICATIONS> NIL </CLASSIFICATIONS>
<ABSTRACT>
The main focus of this work is on the problem of
existence of nonlinear optimal controllers realizable by
artificial neural networks. Theoretical justification,
currently available for control applications of neural
networks, is rather limited. For example, it is unclear
which neural architectures are capable of performing
which control tasks. This work addresses applicability
of neural networks to the synthesis of approximately
optimal state feedback. Discrete-time setting is
considered, which brings extra regularity into the
problem and simplifies mathematical analysis. Two
classes of optimal control problems are studied: time-
optimal control and optimal control with summable
quality index. After appropriate relaxation of the
optimization problem, the existence of a suboptimal
feedback mapping is demonstrated in both cases. It is
shown that such a feedback may be realized by a
multilayered network with discontinuous neuron
activation functions. For continuous networks, similar
results are obtained, with the existence of suboptimal
feedback demonstrated, except for a set of initial
states of an arbitrarily small measure. The theory
developed here provides basis for an attractive approach
of the synthesis of near-optimal feedback using neural
networks trained on optimal trajectories generated in
open loop. Potential advantages of control based on
neural networks are illustrated on application to
stabilization of interconnected power systems. A nearly
time-optimal controller is designed for a single-machine
system using neural networks. The obtained controller is
then utilized as an element of a hierarchical control
architecture used for stabilization of a multimachine
power transmission system. This example demonstrates
applicability of neural control to complicated,
nonlinear dynamic systems.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  3543 </NUMBER>
<ORDER>   AAI9524187 </ORDER>
<TITLE> A CONTINUOUS DENSITY NEURAL TREE NETWORK WORD SPOTTING SYSTEM </TITLE>
<AUTHOR> KOSONOCKY, STEPHEN VICTOR </AUTHOR>
<YEAR> 1995 </YEAR>
<INSTITUTION> RUTGERS THE STATE UNIVERSITY OF NEW JERSEY - NEW BRUNSWICK; 0190 </INSTITUTION>
<DESCRIPTORS> ENGINEERING, ELECTRONICS AND ELECTRICAL; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> RICHARD J. MAMMONE </ADVISER>
<CLASSIFICATIONS> NIL </CLASSIFICATIONS>
<ABSTRACT>
A new classifier is described that combines the
discriminatory ability of the neural tree network (NTN)
with the Gaussian mixture model to create a continuous
density neural tree network (CDNTN). The CDNTN provides
a method of blending a nonparametric tree type
classifier with a parametric mixture model, to allow
modeling complex distributions. The CDNTN is used within
a Hidden Markov Model (HMM), along with a nonparametric
state duration model to construct a continuous word
spotting system for real time applications. The new word
spotting system does not use a general background model,
allowing construction of word models whose performance
is independent of the number of models in the
recognition system, supporting a direct parallel
implementation. Although HMM word spotting systems are
shown to provide good performance when sufficient
training data is available, for applications where
background speech data is not available or only a
limited numbers of training tokens are available, the
CDNTN word spotting system is shown to out perform
comparable HMM systems. The CDNTN is also shown to
provide superior performance for a speaker verification
task compared with systems using vector quantization.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  3544 </NUMBER>
<ORDER>   AAI9524144 </ORDER>
<TITLE> AUTOMATED IDENTIFICATION OF UNNATURAL PATTERNS ON CONTROL CHARTS: AN APPLICATION OF STATISTICAL AND SELF- ORGANIZING NEURAL NETWORK PATTERN RECOGNITION TECHNIQUES </TITLE>
<AUTHOR> ALGHANIM, AMJED MAHMOUD </AUTHOR>
<YEAR> 1995 </YEAR>
<INSTITUTION> NEW MEXICO STATE UNIVERSITY; 0143 </INSTITUTION>
<DESCRIPTORS> ENGINEERING, INDUSTRIAL; STATISTICS; COMPUTER SCIENCE; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> SATISH J. KAMAT </ADVISER>
<CLASSIFICATIONS> NIL </CLASSIFICATIONS>
<ABSTRACT>
A major problem with quality control charts analysis is
the difficulty of judging whether a process has drifted
from normal operation. The objectives of this doctoral
work are, first, to cast this problem as a pattern
recognition problem, and, second, to automate the
decision-making process by implementing and testing
various forms of statistical and neural pattern
recognizers.
The process output presented on the control chart can be
viewed as a discrete-time signal composed of two
components: a random Gaussian noise signal plus an
unnatural 'pattern' signal. The random noise component
represents the natural and intrinsic variations of the
process that are unavoidable, while the presence of an
unnatural pattern indicates an external disturbance
agent working in the process, that must be eliminated.
Since several types of signals may appear on a control
chart (i.e., various unnatural patterns), the problem
becomes that of detecting and identifying unnatural
patterns, that is, to recognize unnatural patterns.
For the statistical pattern recognition approach, a set
of probability distribution functions (pdf's) are
constructed for some unnatural patterns, thus providing
the capability to derive optimal statistical decision
rules. Other patterns, however, cannot be characterized
by closed-form pdf's, and alternative approaches have to
be pursued. Cross correlation analysis provides the
basis for recognizing the latter set of unnatural
patterns. Parameters of the pattern distributions are
assumed to be unknown. These parameters, namely, the
mean vector and the covariance matrix, are estimated
from the training data using the Bayesian Estimation
Technique. In addition, various information processing
procedures, such as standardization, normalization, or
coding (for the neural approach) are implemented to
extract the maximum possible information from the given
process data. A set of performance indices
characterizing the operation of control charts are
defined and evaluated for different operating
conditions. The results obtained have shown the
feasibility of the statistical approach; in fact the
performance of the designed system outperformed existing
systems in terms of Type I and Type II probabilities of
error.
The self-organizing neural pattern recognition
methodology is motivated by the need to implement a
system that is capable of identifying unnatural patterns
even when these are not known a priori. This pattern
recognition methodology is primarily utilized to
identify a change in the process structure. In addition,
the potential of applying this technique to the
classification of detected patterns is investigated. As
a structure detector, the neural-based system is
designed to operate in continuous learning mode. This
strategy is based on the assumption that the process
always starts in a state of statistical control. During
this in-control period, called the training period, the
output data of the process is streamlined to train the
self-organizing network, that in turn, forms 'natural'
clusters describing the in-control process. To operate
the network in a testing mode, a set of labelled
patterns taken during training are used to calibrate the
network. This calibration or interpretation process is
aimed at identifying which clusters (i.e., network
nodes) correspond to the natural process output, which
in turn, facilitates the detection of unnatural output.
Performance indices, such as the false alarm rate, the
rate of detection, and speed of convergence are
evaluated for different network parameters. Performance
analysis of the neural-based system reveals the
viability of the approach to detect structural changes
in the process data.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  3545 </NUMBER>
<ORDER>   AAI9523300 </ORDER>
<TITLE> INCREMENTAL SEARCH METHODS FOR REAL-TIME DECISION MAKING </TITLE>
<AUTHOR> PEMBERTON, JOSEPH CARL </AUTHOR>
<YEAR> 1995 </YEAR>
<INSTITUTION> UNIVERSITY OF CALIFORNIA, LOS ANGELES; 0031 </INSTITUTION>
<DESCRIPTORS> COMPUTER SCIENCE; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> RICHARD KORF </ADVISER>
<CLASSIFICATIONS> BOUNDED RATIONALITY </CLASSIFICATIONS>
<ABSTRACT>
Many real-world problems, such as air-traffic control
and factory scheduling, require that a sequence of
decisions be made in real time, without complete
information. Since there is typically not sufficient
time for traditional methods to find a complete solution
before committing to a decision, we propose an
incremental search method for making real-time
decisions. Our approach is to separate the real-time
decision task into three sub-problems: where to spend
limited computational resources?, when to stop
computing?, and how to make decisions given incomplete
information? By interleaving computation with execution,
we can use the execution time to improve the solution
quality.
We present the last incremental decision problem as a
simplification of the general incremental decision
problem. We develop and analyze E(MPC), which is an
optimal last incremental decision method. We argue that
E(MPC) is impractical for large search trees, due to the
size and complexity of the expected-value equations. We
compare the performance of an existing incremental
search algorithm (MINIMIN) to E(MPC) on a set of small
search trees. In general, MINIMIN typically makes very
good decisions, choosing the optimal last incremental
decision almost as frequently as E(MPC).
We then develop an approximation to E(MPC) called k-
best. The idea is to approximate the E(MPC) decision
using the k-best frontier nodes under each child of the
root. k-best makes the same decisions as MINIMIN when k
equals one, and makes optimal decisions when each child
of the root has k or less frontier nodes. Thus k-best
defines a natural continuum between MINIMIN and optimal.
k-best produces slightly better quality decisions than
MINIMIN on random trees for a given search-depth. We
extend the k-best algorithm and apply it to a flowshop-
scheduling problem. Our results show that, although it
is possible to improve slightly upon the performance of
MINIMIN, the decision quality of MINIMIN is often quite
high. Since MINIMIN is efficient and easy to implement,
we conclude that MINIMIN will often be the decision
algorithm of choice. When we can further process the
information that we have gathered, then k-best is a
practical way to spend this additional computation.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  3546 </NUMBER>
<ORDER>   AAI9523171 </ORDER>
<TITLE> A COMPUTATIONAL THEORY OF GROUNDING IN NATURAL LANGUAGE CONVERSATION </TITLE>
<AUTHOR> TRAUM, DAVID ROOD </AUTHOR>
<YEAR> 1995 </YEAR>
<INSTITUTION> THE UNIVERSITY OF ROCHESTER; 0188 </INSTITUTION>
<DESCRIPTORS> COMPUTER SCIENCE; LANGUAGE, LINGUISTICS; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> JAMES F. ALLEN </ADVISER>
<CLASSIFICATIONS> NIL </CLASSIFICATIONS>
<ABSTRACT>
The process of adding to the common ground between
conversational participants (called grounding) has
previously been either oversimplified or studied in an
off-line manner. This dissertation presents a
computational theory, in which a protocol is presented
which can be used to determine, for any given state of
the conversation, whether material has been grounded or
what it would take to ground the material. This protocol
is related to the mental states of participating agents,
showing the motivations for performing particular
grounding acts and what their effects will be.
We extend speech act theory to account for levels of
action both above and below the sentence level,
including the level of grounding acts described above.
Traditional illocutionary acts are now seen to be multi-
agent acts which must be grounded to have their usual
effects.
A conversational agent model is provided, showing how
grounding fits in naturally with the other functions
that an agent must perform in engaging in conversation.
These ideas are implemented within the TRAINS
conversation system.
Also presented is a situation-theoretic model of plan
execution relations, giving definitions of what it means
for an action to begin, continue, complete, or repair
the execution of a plan. This framework is then used to
provide precise definitions of the grounding acts in
terms of agents executing a general communication plan
in which one agent must present the content and another
acknowledge it.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  3547 </NUMBER>
<ORDER>   AAGNN07403 </ORDER>
<TITLE> PERSPECTIVE ALIGNMENT BACK-PROJECTION FOR REAL-TIME MONOCULAR THREE-DIMENSIONAL MODEL-BASED COMPUTER VISION </TITLE>
<AUTHOR> VERGHESE, GILBERT </AUTHOR>
<YEAR> 1995 </YEAR>
<INSTITUTION> UNIVERSITY OF TORONTO (CANADA); 0779 </INSTITUTION>
<DESCRIPTORS> COMPUTER SCIENCE; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> JOHN K. TSOTSOS </ADVISER>
<CLASSIFICATIONS> ARTIFICIAL INTELLIGENCE </CLASSIFICATIONS>
<ABSTRACT>
Perspective Alignment is a novel method of performing
back-projection, the well-known problem of computing
high-level three-dimensional (3D) position and
orientation (pose) from low-level two-dimensional (2D)
image information. Previous top-down approaches to this
problem have been fairly robust to image noise but
prohibitively slow, imprecise, and prone to overlooking
solutions. Previous bottom-up approaches have been more
computationally efficient and precise. However, they
have been unstable to noise and occlusion, inapplicable
in situations of large rotation or underconstrained
pose, and prone to converging on false positives.
Perspective Alignment performs back-projection
efficiently through a series of incremental geometric
pose restrictions which satisfy a variety of image
constraints on model pose. It maximally constrains model
pose when either partial, unique, or multiple pose
solutions exist. Being constraint-based and incremental,
Perspective Alignment can also incorporate fixation,
self-occlusion, and articulation pose constraints at the
appropriate times during back-projection. It is the key
component of a new robust real-time 3D motion tracking
system. The thesis is that an incremental and constraint-
based back-projection formulation remedies many
deficiencies of previous approaches.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  3548 </NUMBER>
<ORDER>   AAI9523166 </ORDER>
<TITLE> ROBOT SKILL LEARNING THROUGH INTELLIGENT EXPERIMENTATION </TITLE>
<AUTHOR> SCHNEIDER, JEFF GERARD </AUTHOR>
<YEAR> 1995 </YEAR>
<INSTITUTION> THE UNIVERSITY OF ROCHESTER; 0188 </INSTITUTION>
<DESCRIPTORS> COMPUTER SCIENCE; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> CHRISTOPHER M. BROWN </ADVISER>
<CLASSIFICATIONS> NIL </CLASSIFICATIONS>
<ABSTRACT>
In robot skill learning the robot must obtain data for
training by executing expensive practice trials and
recording their results. The thesis is that the high
cost of acquiring training data is the limiting factor
in the performance of skill learners. Since the data is
obtained from practice trials, it is important that the
system make intelligent choices about what actions to
attempt while practicing. In this dissertation we
present several algorithms for intelligent
experimentation in skill learning.
In open-loop skills the execution goal is presented and
the controller must then choose all the control signals
for the duration of the task. Learning is a high-
dimensional search problem. The system must associate a
sequence of outputs with each commandable goal. We
propose an algorithm that selects practice actions most
likely to improve performance by making use of
information gained on previous trials. On the problem of
learning to throw a ball using a robot with a flexible
link, the algorithm takes only 100 trials to find a
"whipping" motion for long throws.
Most closed loop learners improve their performance by
gradient descent on a cost function. The main drawback
of this method is convergence to non-optimal local
minima. We introduce the concept of cooperation as a
means of escaping these local minima. We assume the
existence of several coaches that each improve some
aspect of the controller's performance. Switching
training between coaches can help the controller avoid
locally minimal solutions. On the task of curve tracing
with an inverted pendulum the cooperative algorithm
learns to track faster than with a traditional method.
In an integrated system with scarce sensor resources it
is preferable to perform tasks without sensing. We
observe that closed loop learning can function as an
efficient search technique for open-loop control. Our
system starts with closed loop learning. As it improves
its ability to control the plant, it replaces sensor
information with estimates. The result is a controller
that tracks long segments of a reference curve open
loop.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  3549 </NUMBER>
<ORDER>   AAI9522857 </ORDER>
<TITLE> NEURAL NETWORK INVERSION-THEORY, PRINCIPLE AND APPLICATIONS  </TITLE>
<AUTHOR> FEI, DONGYU </AUTHOR>
<YEAR> 1995 </YEAR>
<INSTITUTION> COLUMBIA UNIVERSITY; 0054 </INSTITUTION>
<DESCRIPTORS> GEOPHYSICS; COMPUTER SCIENCE; ENGINEERING, PETROLEUM; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> JOHN T. KUO </ADVISER>
<CLASSIFICATIONS> WAVEFORM </CLASSIFICATIONS>
<ABSTRACT>
This thesis deals with the neural network inversion--its
theory, principle and applications. It consists of two
independent mutually related papers for publication.
The neural network addresses the continuous function
mapping between two closed intervals, consisting of many
processing elements, each of which is strongly connected
to another by the modifiable connective weight.
Existence theorem for the k-layer $(k > 3)$ neural
network, to our knowledge, has not been formally proved.
Our existence theorem for the k-layer neural network
would provide a theoretical basis for the rapid
development of multi-layer neural network now underway.
The k-layer neural network can uniformly approximate any
continuous function in the sense of super-norm or mean-
squares-norm provided that the activation function is
locally Riemann integrable and non-polynomial.
In Part I (Paper One), the neural network inversion
algorithm is developed and applied to performing seismic
waveform inversion for acoustic velocity in an
inclusion, i.e., (1) a rectangular inclusion embedded in
a homogeneous half-space, and (2) a horizontal
lenticular inclusion is embedded in a layered medium. A
fast computing algorithm of the finite-element method is
used to generate a series of synthetic shot records for
training the neural network. The trained neural network
thus achieves the capability to find the optimal
acoustic velocity of the inclusions for both the cases
with a sufficient accuracy.
In Part II (Paper Two), the neural network inversion
method is applied to electric potential problems for a
finite-dimensional inclusion with a finite conductivity
contrast between the inclusion and the host medium. A
rectangular, vertical conductive plate is embedded in a
conducting homogeneous half-space with or without an
overburden layer for a dipole-dipole array
configuration. For training neural network, sounding
data are generated by means of the finite element
method. The average inversion accuracy for the
estimation of the resistivity of the plate is 2.8 to
5.0%. Although the apparent resistivity change is rather
insensitive to the change of the length of the embedded
conductive plate in a conducting medium, the average
inversion accuracy for the estimation of the length of
the plate is 2.1%.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  3550 </NUMBER>
<ORDER>   AAI9522148 </ORDER>
<TITLE> INDEED: AN ACTIVE DATABASE FOR CONCURRENT ENGINEERING </TITLE>
<AUTHOR> MATTOX, DAVID D. </AUTHOR>
<YEAR> 1995 </YEAR>
<INSTITUTION> UNIVERSITY OF ILLINOIS AT URBANA-CHAMPAIGN; 0090 </INSTITUTION>
<DESCRIPTORS> COMPUTER SCIENCE; ENGINEERING, MECHANICAL; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> STEPHEN LU </ADVISER>
<CLASSIFICATIONS> OBJECT ORIENTED, TRANSACTION MANAGEMENT </CLASSIFICATIONS>
<ABSTRACT>
Concurrent engineering is a methodology for design which
is increasing in popularity at large manufacturing
organizations. Because of this methodology's focus on
group rather than individual productivity, many computer-
based tools do not provide adequate support. This thesis
describes a model for an active, object-oriented
database which has been designed to support engineers
involved in a joint design effort. This database
provides the means to represent and manage information
that has traditionally not been within the scope of
computerized design tools. Users can represent the
heuristics and relationships present in the design as
well as the design objects. As well, the model allows
for the retention of historical information which can
show how values in the database were derived.
To facilitate the effective communication of this
information this thesis also describes a new
methodologies for accessing and sharing information. A
new transaction management system is described which
takes advantage of the dependency information recorded
in the database. This transaction model uses optimistic
locking to allow concurrent access to data by all users
but minimizes the effects of conflicts when they occur.
Also, a new workspace model is defined which breaks down
the rigid boundaries between workspaces and allows users
to selectively share information.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  3551 </NUMBER>
<ORDER>   AAI9522079 </ORDER>
<TITLE> DATA-BASED MATHEMATICAL MODELING: DEVELOPMENT AND APPLICATION  </TITLE>
<AUTHOR> BANAN, MOHMOUD-REZA </AUTHOR>
<YEAR> 1995 </YEAR>
<INSTITUTION> UNIVERSITY OF ILLINOIS AT URBANA-CHAMPAIGN; 0090 </INSTITUTION>
<DESCRIPTORS> ENGINEERING, CIVIL; COMPUTER SCIENCE; STATISTICS; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> KEITH D. HJELMSTAD </ADVISER>
<CLASSIFICATIONS> NEURAL NETWORKS, HIERARCHICAL ADAPTIVE RANDOM PARTITIONING </CLASSIFICATIONS>
<ABSTRACT>
This research study presents the mathematical basis for
building the MC-HARP data-processing environment. The MC-
HARP strategy determines the functional structure and
parameters of a mathematical model simultaneously. A
Monte Carlo (MC) strategy combined with the concept of
Hierarchical Adaptive Random Partitioning (HARP) and
fuzzy subdomains determines the multivariate parallel
distributed mappings. The constructed mapping can be
modeled as a neural network. The HARP algorithm is based
on a divide-and-conquer strategy that partitions the
input space into measurable connected subdomains and
builds a local approximation for the mapping task.
Fuzziness promotes continuity of the mapping constructed
by HARP and smooths the mismatching of the local
approximations in the neighboring subdomains. The Monte
Carlo superposition of a sample of random partitions,
reduces the localized disturbances among the fuzzy
subdomains, controls the global smoothness of the mean
average mapping, and improves the generalization of the
constructed mapping.
The tree structure of the HARP modules and the
independence of both the subdomain approximations and
the random partitions enable the MC-HARP environment to
quickly converge to a series of equally plausible
solutions without user interaction. The MC-HARP
environment enjoys a large-scale granularity produced by
the Monte Carlo parallelism and the geometric
parallelism achieved by partitioning the input space.
Therefore this environment can exhibit good performance
on parallel computers for large and complex scientific
databases.
The developed MC-HARP philosophy for building data-based
approximate mappings leads to a novel model selection
criterion and an original framework for classifying data-
fitting problems. The MC-HARP environment not only can
build approximate multivariate mappings with self-
organization capability, noise and fault tolerance,
adaptivity, generalization, highly plastic and stable
learning characteristics with respect to the addition of
new data points, and parallel structure but also can
answer fundamental questions in data-based mathematical
modeling. These questions include: (1) What is the
confidence level for each predicted output of the
constructed model? (2) What is the approximation
confidence measure for the constructed model? (3) How
does the functional complexity of the actual
multivariate mapping change over the input space? (4)
What is the suitable structural complexity for a data-
based model using noisy data? (5) What is the level of
noise in the data? (6) Is the amount of training data
adequate? If not, which regions of the input space need
more data? (7) Is the selected parametric model
suitable? (8) What is the conditioning of a data-fitting
problem? (9) Is data-based mathematical modeling
promising for the given task?
The developed MC-HARP environment can support the
diverse needs of the scientific and engineering
community. It has the versatility to develop and verify
parametric and nonparametric mathematical models and
also global and local approximate mappings. Furthermore,
It establishes an environment for unifying existing
mathematical modeling techniques in statistics,
approximation theory, information theory, system
identification, and neural networks.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  3552 </NUMBER>
<ORDER>   AAI9520273 </ORDER>
<TITLE> PARTICLE CLASSIFICATION WITH A COMBINATION OF CHEMICAL COMPOSITION AND SHAPE INDEX UTILIZING ARTIFICIAL NEURAL NETWORKS </TITLE>
<AUTHOR> XIE, YING </AUTHOR>
<YEAR> 1995 </YEAR>
<INSTITUTION> CLARKSON UNIVERSITY; 0049 </INSTITUTION>
<DESCRIPTORS> ENVIRONMENTAL SCIENCES; CHEMISTRY, PHYSICAL; CHEMISTRY, ANALYTICAL; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> PHILIP K. HOPKE </ADVISER>
<CLASSIFICATIONS> PATTERN RECOGNITION </CLASSIFICATIONS>
<ABSTRACT>
The identification and apportionment of sources of
particles is important in terms of protecting public
health and improving environmental quality. Until now
most apportionment studies have been based only on the
bulk chemical compositions of particle samples.
Alternatively, source apportionment can be based on
microscopic data of individual particles. Based on
chemical composition inferred from the fluorescence x-
rays, particles can be placed into classes (Kim and
Hopke, 1988a) and the mass in those classes used to
provide quantitative apportionment (Kim and Hopke,
1988b). However, some particles that share very similar
chemical compositions may not come from the same
sources. Therefore, an easy and quick method to quantify
particle shape could be very important in terms of
particle source identification and apportionment.
The two-dimensional multiple fractal dimensions method
and the chain code histogram method were developed and
tested to quantify the shape. It was found that the
chain code histogram method is powerful in
distinguishing spherical particles from non-spherical
particles. This method is fast so that it has the
potential to be incorporated into the on-line CCSEM
system.
Several other methods were also tested to determine
their abilities in distinguishing spherical particles
from non-spherical particles. All of those methods were
found not to be as powerful and practical as the chain
code histogram method.
Besides the exploration and the test of methods to
describe the shape, this project also included the test
of methods used to perform the particle classification.
Two newly developed artificial neural networks were
tested using chemical composition information and shape
indices of 92 airborne particles. These two neural
networks were the Tree-Map model and the adaptive
resonance theory (ART) based neural network. The Tree-
Map model is the combination of the Prim's minimal
spinning tree and Kohonen map. It was demonstrated that
the Tree-Map model can successfully project the m-
dimensional data set to a two-dimensional map. Particles
were well classified and the correlations between the
clusters were well determined. It was found that the
ART2A system is capable of classifying airborne
particles, and most importantly, it can dynamically
update rules for particle classes to include previously
unknown classes.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  3553 </NUMBER>
<ORDER>   AAI9522944 </ORDER>
<TITLE> MANAGEMENT OF SPEEDUP MECHANISMS IN LEARNING ARCHITECTURES  </TITLE>
<AUTHOR> CHENG, JOHN CHRISTOPHER </AUTHOR>
<YEAR> 1995 </YEAR>
<INSTITUTION> CARNEGIE-MELLON UNIVERSITY; 0041 </INSTITUTION>
<DESCRIPTORS> COMPUTER SCIENCE; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> TOM MITCHELL </ADVISER>
<CLASSIFICATIONS> MACHINE LEARNING, UTILITY PROBLEM </CLASSIFICATIONS>
<ABSTRACT>
Learning architectures typically operate rather
inefficiently. To increase performance, two strategies
are commonly used: speedup mechanisms are incorporated
into the architecture, and architecture operation is
simplified. Unfortunately, both these strategies have
drawbacks.
Because of the utility problem, inappropriate use of
speedup mechanisms can actually decrease system
efficiency. Hence, good speedup mechanism management--
deciding when, where, and which speedup mechanism to use
is--important if the mechanisms are to be effective.
Typically, however, good management strategies are not
available. Architecture-provided strategies are usually
very simple. and cannot use the mechanisms appropriately
all the time. Good user-provided strategies are also
difficult to develop--under a complex system or domain,
it can be difficult to understand system behavior well
enough to specify a good management strategy.
Furthermore, user or architecture-provided management
techniques are usually fixed, and cannot adapt to
environment dynamics. Hence, lack of good management
strategies limit the effectiveness of speedup
mechanisms.
Simplifying an architecture's inference mechanism yields
dramatic efficiency gains. Unfortunately, gaining
efficiency in this manner usually sacrifices fine-grain
control over the behavior of the system, or architecture
flexibility. Consequently, this speedup technique forces
the domain designer to operate at the
flexibility/efficiency tradeoff point chosen by the
architecture. This thesis investigates ways of handling
both of these problems. The speedup mechanism management
problem is approached by making the architecture itself
responsible for developing a management strategy. An
agent, embedded into the architecture, observes system
operation, invoking speedup mechanisms appropriately.
This approach allows the architecture to tailor its
strategies individually to different domains, increasing
speedup mechanism usefulness. Furthermore, because the
agent can monitor the architecture continuously, it can
adapt its management strategies to the dynamics of the
environment.
This dissertation also presents an algorithm that can be
used to reduce the flexibility/efficiency constraints on
the domain designer, giving him more options. The
designer is allowed architecture flexibility, but if
flexibility is not needed, the unnecessary flexibility
is automatically traded for efficiency.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  3554 </NUMBER>
<ORDER>   AAI9522942 </ORDER>
<TITLE> PRODUCTION MATCHING FOR LARGE LEARNING SYSTEMS </TITLE>
<AUTHOR> DOORENBOS, ROBERT B. </AUTHOR>
<YEAR> 1995 </YEAR>
<INSTITUTION> CARNEGIE-MELLON UNIVERSITY; 0041 </INSTITUTION>
<DESCRIPTORS> COMPUTER SCIENCE; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> JILL FAIN LEHMAN </ADVISER>
<CLASSIFICATIONS> MACHINE LEARNING, UTILITY PROBLEM, RETE UL </CLASSIFICATIONS>
<ABSTRACT>
One of the central results of AI research in the 1970's
was that to achieve good performance, AI systems must
have large amounts of knowledge. Machine learning
techniques have been developed to automatically acquire
knowledge, often in the form of if-then rules
(productions). Unfortunately, this often leads to a
utility problem--the "learning" ends up causing an
overall slowdown in the system. This is because the more
rules a system has, the longer it takes to match them
against the current situation in order to determine
which ones are applicable.
To address this problem, this thesis is aimed at
enabling the scaling up of the number of rules in
production systems. We examine a diverse set of testbed
systems, each of which learns at least 100,000 rules. We
show that with the best existing match algorithms, the
match cost increases linearly in the number of rules in
these systems. This is inadequate for large learning
systems, because it leads to a utility problem. We then
examine the causes of this linear increase, and develop
techniques which eliminate the major causes. The end
result is an improved match algorithm, Rete/UL, which is
a general extension of the existing state-of-the-art
Rete match algorithm. Rete/UL's performance scales well
on a significantly broader class of systems than
existing match algorithms. The use of Rete/UL rather
than Rete significantly reduces or eliminates the
utility problem in all the testbed systems.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  3555 </NUMBER>
<ORDER>   AAI0575932 </ORDER>
<TITLE> AN EVOLUTIONARY PROGRAMMING APPROACH TO PROBABILISTIC MODEL-BASED FAULT DIAGNOSIS OF CHEMICAL PROCESSES </TITLE>
<AUTHOR> ROJAS-GUZMAN, CARLOS </AUTHOR>
<YEAR> 1995 </YEAR>
<INSTITUTION> MASSACHUSETTS INSTITUTE OF TECHNOLOGY; 0753 </INSTITUTION>
<DESCRIPTORS> ENGINEERING, CHEMICAL; COMPUTER SCIENCE; ARTIFICIAL INTELLIGENCE; OPERATIONS RESEARCH </DESCRIPTORS>
<ADVISER> MARK A. KRAMER </ADVISER>
<CLASSIFICATIONS> GENETIC ALGORITHMS, BAYESIAN NETWORKS, EXPERT SYSTEMS </CLASSIFICATIONS>
<ABSTRACT>
Uncertainty is intrinsic to fault diagnosis in chemical
processes. The need to model uncertainty derives
primarily from engineering limitations both in process
modeling and measurement. Deterministic models for the
effects of faults cannot always be constructed, and
measurements to diagnose every fault uniquely may be
missing, noisy or inaccurate. This project develops and
exploits the advantages of a probabilistic approach to
construct an improved theoretical framework capable of
modeling and handling uncertain, incomplete and
conflicting information to perform fault diagnosis in
complex dynamic chemical processes.
The type of reasoning involved in diagnosis is called
abductive inference and consists of deriving the best
(most probable) globally consistent explanation for a
given set of evidence (measured or observed variables).
Bayesian networks are graphs used to model and reason
about uncertain systems by qualitatively (through the
network topology) and quantitatively (through the
probabilistic parameters) encoding conditional
dependence and independence among the system variables.
Bayesian networks have a sound theoretical basis, are
consistent with probability theory, use results from
graph theory, and constitute a powerful tool in
probabilistic reasoning. The Bayesian network framework
was selected as the basis for a unifying representation
for a probabilistic framework in which knowledge from
different sources can be integrated.
Recently developed methods to propagate probability
information in the belief network structure use
distributed parallel computations in which probabilistic
values are locally propagated between neighboring nodes
(Pearl, 1988). However, abductive inference in belief
networks belongs to the class of NP-hard problems.
Complexity increases drastically as a function of the
number of undirected cycles, discrete states per
variable, and variables in the network.
Approximate near-optimal methods constitute an
alternative. A graph-based genetic algorithm is
developed and implemented as part of this project by
posing inference as search in a large discrete multi-
dimensional space where the metric (phenotype) is the
probability of each diagnostic hypothesis. The space is
initially sampled randomly creating a population of
diagnostic hypotheses. The search effort is allocated in
parallel to O(N$sp3$) hyperplanes. Through several
iterations (generations), solutions (individuals) are
selected and combined (reproduction and crossover) to
improve (evolve) the quality of the solution set
(population) towards the optimal solution. Convergence
to a local optimum is avoided by introducing low
frequency random changes (mutations). Efficiency results
from the ease of evaluating any given solution, and from
the genotype representation (solution specification) as
a graph structure. By performing crossover in graphs, as
opposed to strings, semantic closeness is preserved
(meaningful sets of directly related variables are kept
together) and the compact building block hypothesis is
satisfied. This hypothesis states that highly fit, short-
defining-length schemata (or similarity templates) are
propagated through generations by giving exponentially
increasing samples to high phenotype individuals.
The Bayesian belief network theoretical paradigm is
extended to handle temporal reasoning and dynamics
through the incorporation of time-indexed nodes. The
resulting extended framework, the Multi-Stage Bayesian
Network (MSBN) can take advantage of the same inference
algorithms developed for Bayesian networks.
Experiments conducted on a well-known model are used to
quantify the performance of the algorithm, and to
optimize the algorithm parameters. A real-time on-line
industrial implementation in an unmanned, remotely
controlled chemical plant is used to illustrate the
capabilities of the methodology. (Copies available
exclusively from MIT Libraries, Rm 14-0551, Cambridge,
MA 02139-4307. Ph. 617-253-5668; Fax 617-253-1690.)
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  3556 </NUMBER>
<ORDER>   AAGNN07342 </ORDER>
<TITLE> SHAPE REGISTRATION USING OPTIMIZATION FOR MOBILE ROBOT NAVIGATION </TITLE>
<AUTHOR> LU, FENG </AUTHOR>
<YEAR> 1995 </YEAR>
<INSTITUTION> UNIVERSITY OF TORONTO (CANADA); 0779 </INSTITUTION>
<DESCRIPTORS> COMPUTER SCIENCE; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> EVANGELOS MILIOS </ADVISER>
<CLASSIFICATIONS> NIL </CLASSIFICATIONS>
<ABSTRACT>
The theme of this thesis is shape registration (also
called shape matching or shape alignment) using
optimization-based algorithms. We primarily address this
problem in the context of solving the mobile robot self-
localization problem in unknown environments. Here the
task is matching 2D laser range scans of the environment
to derive the relative position and heading of the
robot. The difficulties in this problem are that the
scans are noisy, discontinuous, not necessarily linear,
and two scans taken at different positions may not
completely overlap because of occlusion. We propose two
iterative scan matching algorithms which do not require
feature extraction or segmentation. Experiments
demonstrate that the algorithms are effective in solving
the scan matching problem.
Based on the result of aligning pairwise scans, we then
study the optimal registration and integration of
multiple range scans for mapping an unknown environment.
Here the issue of maintaining consistency in the
integrated model is specifically raised. We address this
issue by maintaining individual local frames of data and
a network of uncertain spatial relations among data
frames. We then formulate an optimal procedure to
combine all available spatial relations to resolve
possible map inconsistency. Two types of sensor data,
odometry and range measurements, are used jointly to
form uncertain spatial relations.
Besides the applications for mobile robots, we also
study the shape registration problem in other domains.
Particularly, we apply extensions of our methods for
registration of 3D surfaces described by range images,
and 2D shapes from intensity images.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  3557 </NUMBER>
<ORDER>   AAI0575682 </ORDER>
<TITLE> MEDIA STREAMS: REPRESENTING VIDEO FOR RETRIEVAL AND REPURPOSING </TITLE>
<AUTHOR> DAVIS, MARC ELIOT </AUTHOR>
<YEAR> 1995 </YEAR>
<INSTITUTION> MASSACHUSETTS INSTITUTE OF TECHNOLOGY; 0753 </INSTITUTION>
<DESCRIPTORS> COMPUTER SCIENCE; CINEMA; INFORMATION SCIENCE </DESCRIPTORS>
<ADVISER> KENNETH HAASE </ADVISER>
<CLASSIFICATIONS> NIL </CLASSIFICATIONS>
<ABSTRACT>
Current computing systems are just beginning to enable
the computational manipulation of digital video. Because
of the relative opacity of video, it must be represented
in order to be manipulable according to its content.
Knowledge representation techniques have been implicitly
designed for representing the physical world and its
textual representations. Video poses unique problems and
opportunities for knowledge representation which
challenge many of its assumptions about the structure
and function of what is represented. The semantics and
syntax of video require representational designs which
employ fundamentally different concepts of space, time,
character, action, identity, and transition. In
particular, the effect of the syntax of video sequences
on the semantics of video shots requires that
representation and retrieval technologies clearly
articulate the differences between the sequence-
dependent and sequence-independent semantics of video
data.
Implementing these ideas, Media Streams uses a stream-
based, semantic, memory-based representation with an
iconic visual language interface of hierarchically
structured, composable, and searchable primitives to
annotate video for content-based retrieval. Media
Streams addresses problems of annotation convergence and
human-system communication by creating a standardized
language for representing video content in a global
media archive. The system introduces new retrieval-by-
composition methods which reinvent video editing as a
process of logging and retrieval. Media Streams
generates pre-narrative, non-verbal video sequences
resembling short sequences from the cinematic styles of
silent film, compilation film, avant-garde cinema,
documentary, music video, and home video.
Developing Media Streams required interdisciplinary
research in artificial intelligence, film theory, and
user interface design. The research in AI draws from
work on dynamic memory, analogical understanding, and
case-based reasoning (Schank, Lenat, Haase); the film
analysis techniques borrow from formalist,
structuralist, reader-response, and semiotic approaches
(Metz, Eco, Bordwell, Iser), the work of Soviet silent
film practitioners (Kuleshov, Eisenstein), and recent
research on the aesthetics and practice of communities
of television fans who appropriate and reuse found
materials (Jenkins).
The thesis document is accompanied by a videotape with
examples of video sequences retrieved/generated by the
system. (Copies available exclusively from MIT
Libraries, Rm. 14-0551, Cambridge, MA 02139-4307. Ph.
617-253-5668; Fax 617-253-1690.)
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  3558 </NUMBER>
<ORDER>   AAI9516915 </ORDER>
<TITLE> A KNOWLEDGE-BASED METHOD FOR TEMPORAL ABSTRACTION OF CLINICAL DATA </TITLE>
<AUTHOR> SHAHAR, YUVAL </AUTHOR>
<YEAR> 1995 </YEAR>
<INSTITUTION> STANFORD UNIVERSITY; 0212 </INSTITUTION>
<DESCRIPTORS> ENGINEERING, BIOMEDICAL; COMPUTER SCIENCE; ARTIFICIAL INTELLIGENCE; HEALTH SCIENCES, GENERAL </DESCRIPTORS>
<ADVISER> MARK MUSEN </ADVISER>
<CLASSIFICATIONS> NIL </CLASSIFICATIONS>
<ABSTRACT>
This dissertation describes a reasoning framework for
knowledge-based systems, specific to the task of
abstracting higher-level, interval-based concepts from
time-stamped data, but independent of any domain. The
framework includes a logical model of time, parameters,
events and contexts: a knowledge-based temporal-
abstraction theory. The knowledge required for the
inference structure that I propose is well defined and
can be acquired for particular domains. I have applied
my framework to the domain of clinical medicine. My goal
is to create, from time-stamped patient data, interval-
based temporal abstractions, such as "severe anemia for
3 weeks in the context of administering AZT," and more
complex patterns, involving several intervals.
I define a knowledge-based temporal-abstraction method
that decomposes the task of abstracting higher-level
abstractions from input data into five subtasks. These
subtasks are solved by five separate, domain-
independent, temporal-abstraction mechanisms. The
temporal-abstraction mechanisms depend on four domain-
specific knowledge types. The knowledge types and the
role they play in each mechanism are defined formally.
The knowledge needed to instantiate the temporal-
abstraction mechanisms in any particular domain and task
can be parameterized and can be acquired from domain
experts manually or with automated tools.
I present a computer program implementing the knowledge-
based temporal-abstraction method: RESUME. RESUME
accepts input and returns output at all levels of
abstraction; accepts input out of temporal order,
modifying a view of the past or of the present, as
necessary; generates context-sensitive, controlled
output; and maintains several possible concurrent
interpretations of the data.
I have evaluated RESUME in the domains of protocol-based
care, monitoring of children's growth, and therapy of
diabetes. The knowledge required for instantiating the
temporal-abstraction mechanisms was acquired,
maintained, and reused for creating new application
systems.
A formal specification of a domain's temporal-
abstraction knowledge supports the design of systems
that perform temporal-reasoning tasks, the acquisition
of that knowledge, the maintenance of that knowledge,
the reuse of the temporal abstraction knowledge in other
domains, and the sharing of the domain-specific temporal
abstraction knowledge with other applications.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  3559 </NUMBER>
<ORDER>   AAI9516806 </ORDER>
<TITLE> THE RELATIVE VALUE OF LABELED AND UNLABELED SAMPLES IN PATTERN RECOGNITION </TITLE>
<AUTHOR> CASTELLI, VITTORIO </AUTHOR>
<YEAR> 1995 </YEAR>
<INSTITUTION> STANFORD UNIVERSITY; 0212 </INSTITUTION>
<DESCRIPTORS> ENGINEERING, ELECTRONICS AND ELECTRICAL; STATISTICS; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> THOMAS M. COVER </ADVISER>
<CLASSIFICATIONS> LABELED SAMPLES </CLASSIFICATIONS>
<ABSTRACT>
Learning in pattern recognition is the process of
constructing a classifier using a training set.
Traditionally, two approaches to learning have been
pursued: supervised learning, where the training set
contains only labeled samples, and unsupervised
learning, where the training set contains only unlabeled
samples.
In this dissertation we address the problem of learning
from both labeled and unlabeled observations and we ask
the following questions: When are unlabeled samples
useful? How useful are they? What is the relative value
of labeled and unlabeled samples? More precisely, if
R(l,u) is the probability of classification error of the
best procedure based on l labeled and u unlabeled
samples, what is the dependence of R(l,u) on l and on u?
How fast does it converge to the Bayes risk $Rsp*$?
First, we assume that the training set contains an
infinite number of unlabeled samples. Under
identifiability conditions, we show that the first
labeled sample reduces the probability of error from
$R(0,infty)= 1/2$ to $R(1,infty)= 2Rsp*(1-Rsp*)$. With
additional labeled samples, the probability of error
converges exponentially fast to the Bayes risk in l, and
the exponent is a function of Bhattacharyya distance
between the distributions of the two classes.
We then address two special cases of the general problem
where the training set is finite. We first assume that
the underlying distributions of the classes are known
and that the mixing parameter is unknown. We show that
the relative value of labeled and unlabeled samples is
the ratio of the corresponding Fisher informations. We
then assume that two distributions are given but we do
not know which class they correspond to, nor do we know
the mixing parameter. Here, labeled samples are
exponentially more valuable than the unlabeled samples
in reducing the risk.
Finally, we extend the result to Bayesian frameworks
where the family of distributions of the unlabeled
samples are Laplace regular and the family of
distributions of the labeled samples satisfy the
conditions for efficient likelihood estimation of the
parameters, and we conclude that labeled samples are
exponentially more valuable than unlabeled samples in
reducing the probability of error.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  3560 </NUMBER>
<ORDER>   AAI9516599 </ORDER>
<TITLE> LEARNING INPUT-OUTPUT MAPPINGS WITH SPARSE RANDOM NEURAL NETWORKS  </TITLE>
<AUTHOR> COULTRIP, ROBERT LEE </AUTHOR>
<YEAR> 1995 </YEAR>
<INSTITUTION> UNIVERSITY OF CALIFORNIA, IRVINE; 0030 </INSTITUTION>
<DESCRIPTORS> COMPUTER SCIENCE; BIOLOGY, NEUROSCIENCE; ENGINEERING, ELECTRONICS AND ELECTRICAL; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> RICHARD GRANGER </ADVISER>
<CLASSIFICATIONS> NEURAL NETWORKS </CLASSIFICATIONS>
<ABSTRACT>
In many parts of the brain neurons seem to have sparse
random connectivity as suggested, in part, by the
apparently random branching of axons and dendrites.
Here, I advance the thesis that randomly connected
networks of neurons with biological synaptic enhancement
mechanisms such as long term potentiation (LTP), can, in
the limit of large numbers of cells and synapses per
cell, learn by example to do either pattern
classification or nonparametric regression, depending on
circuitry assumptions. That is, the neural circuits
learn input-output mappings. One class of networks
studied approximates Bayes classifiers via Parzen's
method. Other networks explored approximate the Nadaraya
and k-nearest neighbor estimators used for nonparametric
regression. In addition, I have designed, fabricated,
and tested CMOS chips implementing winner-take-all and
classification algorithms inspired by these biological
networks.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  3561 </NUMBER>
<ORDER>   AAI9510810 </ORDER>
<TITLE> A KNOWLEDGE-BASED SYSTEM FOR ASSESSING OCCUPATIONAL EXPOSURES </TITLE>
<AUTHOR> KNECHTGES, PAUL LEE </AUTHOR>
<YEAR> 1995 </YEAR>
<INSTITUTION> GEORGE MASON UNIVERSITY; 0883 </INSTITUTION>
<DESCRIPTORS> ENVIRONMENTAL SCIENCES; HEALTH SCIENCES, OCCUPATIONAL HEALTH AND THERAPY; HEALTH SCIENCES, TOXICOLOGY; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> JAMES D. WILLETT </ADVISER>
<CLASSIFICATIONS> NIL </CLASSIFICATIONS>
<ABSTRACT>
Exposure assessment plays an important role in risk
assessment and is valuable in the diagnosis and medical
surveillance of occupationally and environmentally
induced diseases. Unfortunately, environmental
monitoring data are often scarce or missing, and
exposure assessments are often based on expert
judgement. The purpose of this study was to examine the
feasibility of using knowledge-based systems (i.e.
expert systems) to perform exposure assessment of job
tasks from the interviews of workers. The study
consisted of three phases.
The first phase of this study started with the
development of a knowledge base to link various
databases and derive estimates of workers' exposures to
occupational stressors or agents. A large aircraft
maintenance facility was chosen as the subject for
knowledge engineering. An inventory of materials was
obtained from the subject facility, and an extensive
list of ingredients for most of the materials was
downloaded from a hazardous materials information system
on a compact disc. The resulting knowledge-based system
links databases containing 25 major processes, 75
operations, 707 possible techniques, numerous hazardous
materials ($>$2,600 records total), and 665 agents to
derive qualitative and semi-quantitative exposure
estimates.
The second phase of this study involved validation
testing of the prototype system. A total of 82 workers
who handled solvents and paints were interviewed. The
system correctly identified 74 percent of the known
agents but also identified many more agents not listed
in survey documents. The semi-quantitative estimates
were used to rank the various tasks. Those rankings were
then compared with the rankings from air sampling data.
Some tasks were correctly ranked, but the overall
agreement in rankings was poor. However, in the third
phase of this study, several plausible explanations for
the disparity in rankings were tested by modifying the
knowledge base; the result was a relatively good fit of
the data (Spearman's rank correlation coefficient for
methylene chloride exposures changed from $-$0.315 to
0.857). Although further development and testing is
needed to validate the prototype system, the findings of
this study support the feasibility of a knowledge-based
approach to exposure assessment.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  3562 </NUMBER>
<ORDER>   AAI9509196 </ORDER>
<TITLE> NEURAL NETWORK MODELS OF TEMPORAL PROCESSING IN SPEECH PERCEPTION AND MOTOR CONTROL </TITLE>
<AUTHOR> BOARDMAN, IAN SCOTT </AUTHOR>
<YEAR> 1995 </YEAR>
<INSTITUTION> BOSTON UNIVERSITY; 0017 </INSTITUTION>
<DESCRIPTORS> BIOLOGY, NEUROSCIENCE; COMPUTER SCIENCE; PSYCHOLOGY, PSYCHOMETRICS; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> MICHAEL COHEN </ADVISER>
<CLASSIFICATIONS> NIL </CLASSIFICATIONS>
<ABSTRACT>
This dissertation studies three classes of neural
networks for temporal processing: the first models
storage of temporally ordered motor commands; the
second, temporal integration of rapidly changing and
quasi-static acoustic segments for rate-sensitive
phonetic discrimination; and the third, rate-invariant
grouping of phonetic percepts. Human performance in
recalling planned movement sequences and spoken word
lists from working memory indicates that output rate
depends dynamically on the number of remaining items. In
chapter 1, a neural network model is developed that
represents temporally ordered events as spatial
activation patterns. Events are performed at a rate that
is regulated by an internal measure of memory load and
an externally imposed arousal signal. Performance can be
interrupted and restarted using arousal, and made
dependent on efferent feedback. The model explains list
length and position effects, and predicts that subjects
tend toward a uniform output rate at moderate arousal.
Variations in model parameters can account for
variability in performance across subjects.
Chapter 2 models local speech rate effects on phonetic
discrimination; in particular, how the duration of a
subsequent vowel can shift the category boundary between
recognition of stop and semi-vowel for the prior
consonant. The model uses complementary processing of
the transient and sustained components of the speech
signal to generate phonetic decision contours that obey
the observed exponential relation between formant
transition rate and vowel duration.
Chapter 3 models adaptation of phonetic percepts to
global speech rate as exemplified by shifts of category
boundaries between single and double voiced stops due to
changes in mean closure interval. A dynamical neural
network model of a working memory and a list category
field is developed which automatically adjusts its
integration rate, or gain, according to the rate of
input presentations. Computer simulations quantitatively
generate the experimentally observed category boundaries
for voiced stop pairs that have the same or different
place of articulation. To explain why the closure
interval required to hear a double (geminate) stop is
typically more than twice as long as that needed to hear
two different stops, the model depends upon resonant
feedback between list categories and working memory.
Resonance facilitates category formation and sustains
expectation of the category until a reset occurs, either
rapidly due to mismatch or slowly due to transmitter
depletion.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  3563 </NUMBER>
<ORDER>   AAG9507141 </ORDER>
<TITLE> NEURAL NETWORK MODELS OF THREE-DIMENSIONAL SURFACE PERCEPTION: DA VINCI STEREOPSIS AND THE MCCOLLOUGH EFFECT </TITLE>
<AUTHOR> MCLOUGHLIN, NIALL PETER </AUTHOR>
<YEAR> 1995 </YEAR>
<INSTITUTION> BOSTON UNIVERSITY; 0017 </INSTITUTION>
<DESCRIPTORS> COMPUTER SCIENCE; PSYCHOLOGY, EXPERIMENTAL; BIOLOGY, NEUROSCIENCE; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> STEPHEN GROSSBERG </ADVISER>
<CLASSIFICATIONS> NIL </CLASSIFICATIONS>
<ABSTRACT>
Visual perception is mediated by two spatially disparate
transducers: the eyes. Each eye registers a different
view of the world, yet we perceive a single "solid"
three-dimensional (3-D) universe. This thesis
investigates how the left and right eye views are
integrated to form a single 3-D representation of space.
The psychophysical phenomena of DaVinci stereopsis and
the McCollough effect are examined through computational
and experimental techniques in an effort to tease apart
this integrative process.
While humans use a variety of cues to make relative
depth judgements, this thesis concentrates on the
fundamental role of horizontal disparity in surface
perception. Although variations in horizontal disparity
afford potent cues to perceptual depth segregation,
unmatched monocular regions from either eye, which may
occur due to occlusion, must also be integrated into our
global perception. DaVinci stereopsis refers to the
process of integrating these "half-occluded" regions
into our full 3-D percept. This thesis develops an
implementation of a neural network theory of biological
vision, called FACADE Theory, which was proposed and
refined by Grossberg and colleagues. FACADE theory is
shown through computer simulations to be capable of
replicating the percept of DaVinci stereopsis.
Recent psychophysical studies from McKee and colleagues
address the nature of this binocular integration
process. McKee has shown that integration is both
contrast-sensitive and context dependent. These studies
are readily explained by FACADE theory and a variety of
relevant dichoptic stimuli are simulated.
The McCollough effect (ME), a long-term negative color
aftereffect that probes the interaction between form and
color perception, is also examined from the perspective
of binocular integration. The ME is a valuable source of
information about how the visual system processes
monocular versus binocular stimuli. This thesis explores
a variety of monocular and binocular variations of the
standard paradigm. A model is introduced and model
predictions are tested in a series of psychophysical
experiments designed to investigate the effects of form
and/or color rivalry on induction strength.
Evidence from both DaVinci stereopsis and the ME support
FACADE theory's approach to visual perception.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  3564 </NUMBER>
<ORDER>   AAG9507134 </ORDER>
<TITLE> FUSION ARTMAP: NEURAL NETWORKS FOR MULTI-SENSOR FUSION AND CLASSIFICATION  </TITLE>
<AUTHOR> ASFOUR, YOUSIF RAJA </AUTHOR>
<YEAR> 1995 </YEAR>
<INSTITUTION> BOSTON UNIVERSITY; 0017 </INSTITUTION>
<DESCRIPTORS> COMPUTER SCIENCE; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> GAIL A. CARPENTER </ADVISER>
<CLASSIFICATIONS> OBJECT RECOGNITION </CLASSIFICATIONS>
<ABSTRACT>
Real-time neural networks for multi-sensor pattern
classification are developed. These networks classify
objects using information from multiple sensors of
different modalities, views or scales. Each sensor is
assigned an individual Adaptive Resonance Theory (ART)
classifier whose compressed output serves as input to a
global classifier. When global predictive errors occur,
individual sensor inouts are relassified to improve
system performance. Deciding which classifier to modify
is known as the credit assignment problem. Solving this
problem is a fundamental goal of the Fusion ARTMAP
design.
Two solutions to the credit assignment problem are
investigated. Parallel match tracking assigns blame for
global errors to the classifier with least confidence in
its prediction by raising the vigilance of all ART
modules in parallel. The Fusion ARTMAP network has a
symmetric organization such that each channel can be
dynamically configured to serve as either a data input
or a teaching input. Simulations using an artificial
Quadruped Mammal database show that Fusion ARTMAP
requires 2/3 as many connections as does the standard
method, vector concatenation.
The second approach assigns credit by resetting all
classifiers which mismatch the global recognition code.
The resulting system integrates multiple fuzzy ARTMAP
modules, slow learning, and ART-EMAP evidence
accumulation techniques. Performance is illustrated by
an extension of the circle-in-square benchmark. When
compared to the concatenation approach, slow learning
improves performance from 64% to 80% and reduces
connectivity from 620 to 416 connections. The ART-EMAP
method further improves performance to 85.6% without
changing connectivity.
Two multi-sensor pattern recognition applications are
also presented. The first uses ART-EMAP to recognize 3-D
objects sampled by multiple cameras. With four cameras,
the network achieves 100% performance compared to 95%
with the concatenation approach. A second application
illustrates a case where the concatenation approach may
be a better choice than a modular network. When
categorizing multispectral satellite images, a single-
channel fuzzy ARTMAP neural network achieves near
optimum (89%) performance in comparison to thirteen
other classification methods while achieving a 6:1 code
compression ratio. The choice between a modular approach
to multi-sensor fusion and vector concatenation is
discussed.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  3565 </NUMBER>
<ORDER>   AAGNN07195 </ORDER>
<TITLE> AFFINEMENT D'IMAGES DE PROFONDEUR PAR FUSION SENSORIELLE 2-D ET 3-D  </TITLE>
<AUTHOR> METHOT, JEAN-FRANCOIS </AUTHOR>
<YEAR> 1995 </YEAR>
<INSTITUTION> UNIVERSITE LAVAL (CANADA); 0726 </INSTITUTION>
<DESCRIPTORS> ENGINEERING, ELECTRONICS AND ELECTRICAL; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> DENIS POUSSART </ADVISER>
<CLASSIFICATIONS> FRENCH TEXT, MACHINE VISION, IMAGES, DEPTH PERCEPTION, ARTIFICIAL INTELLIGENCE </CLASSIFICATIONS>
<ABSTRACT>
Le sujet de cette these se situe dans le domaine de la
vision numerique. Le but vise consiste a augmenter la
performance des capteurs de profondeur. L'approche
choisie est celle de la fusion sensorielle qui consiste
a combiner l'information de divers modules afin
d'affiner la mesure de distance. La fusion sensorielle
proposee est celle entre des informations provenant de
differentes modalites de la vision: intensite et
profondeur.
Le probleme entier de la fusion peut se diviser en
plusieurs etapes. Cette these traite de la determination
des proprietes de reflectivite de surface des objets, de
l'estimation du degre de confiance des images d'entree
et de l'application de la fusion sensorielle entre les
donnees.
Les interets d'un tel projet se situent a plusieurs
niveaux. Premierement, il s'agit d'une approche
originale pour ameliorer la precision d'images de
profondeur. L'idee de base est un principe general qui
peut s'appliquer a des donnees provenant de n'importe
quel systeme d'acquisition de profondeur. Enfin, on
parvient a acquerir l'information de la nature desiree
selon des sources de natures differentes.
La demarche suivie consiste a determiner d'abord un
moyen d'acquerir l'information des proprietes de
reflectivite des surfaces pour ensuite, proceder a la
fusion. Celle-ci comporte deux etapes qui sont la
determination des orientations de surface par la
technique de forme par intensite (shape from shading) et
la reconstruction de la surface finale par integration.
Dans la partie experimentale, l'algorithme de fusion
developpe est teste sur deux systemes de vision 3-D: une
technique par absorption de lumiere dans un milieu
absorbant et la camera BIRIS (profondeur par
defocalisation).
Les resultats obtenus sont tres encourageants. Sur des
surfaces qui permettent de le mesurer, un facteur de
reduction du bruit variant entre 8 et 30 a ete observe
sur des images experimentales. Le gain correspondant sur
la plage dynamique est donc de 3 a 5 bits pour ces
examples.
Dans cette these, les contributions principales sont:
(i) d'avoir etabli une nouvelle approche pour
l'affinement des images de profondeur applicable dans
des conditions reelles de prise de mesures, (ii) d'avoir
etabli une solution qui tient compte de la nature des
sources d'entree et des contraintes entre celles-ci et
(iii) d'avoir choisi et montre une solution qui s'adapte
a un traitement massivement parallele.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  3566 </NUMBER>
<ORDER>   AAGNN06650 </ORDER>
<TITLE> COEFFICIENT COLOR CONSTANCY </TITLE>
<AUTHOR> FINLAYSON, GRAHAM DAVID </AUTHOR>
<YEAR> 1995 </YEAR>
<INSTITUTION> SIMON FRASER UNIVERSITY (CANADA); 0791 </INSTITUTION>
<DESCRIPTORS> ENGINEERING, ELECTRONICS AND ELECTRICAL; ARTIFICIAL INTELLIGENCE; PHYSICS, OPTICS </DESCRIPTORS>
<ADVISER> BRIAN FUNT </ADVISER>
<CLASSIFICATIONS> MACHINE VISION </CLASSIFICATIONS>
<ABSTRACT>
The goal of color constancy is to take the color
responses (for example camera rgb triplets) of surfaces
viewed under nn unknown illuminant and map them to
illuminant independent descriptors. In existing theories
this mapping is either a general linear 3 $times$ 3
matrix or a simple diagonal matrix of scaling
coefficients. The general theories have the advantage
that the illuminant can be accurately discounted but
have the disadvantage that nine parameters must be
recovered. Conversely while the coefficient theories
have only three unknowns, a diagonal matrix may only
partially discount the illuminant.
My starting point in this thesis is to generalize the
coefficient approach; the goal is to retain its inherent
simplicity while at the same time increasing its
expressive power. Under the generalized coefficient
scheme, I propose that a visual system transforms
responses to a new sensor basis before applying the
scaling coefficients. I present methods for choosing the
best coefficient basis for a variety of statistical
models of color responses. These models are rich enough
that the generalized coefficient approach suffices for
almost all possible sensor sets.
To achieve color constancy the correct coefficients must
be recovered. Existing algorithms can do so only when
strong constraints are satisfied. For example it is
often assumed that there is a white reflectance in every
scene. In the second part of any thesis, I develop a new
coefficient algorithm, which I call color in
perspective, based on very weak (and very reasonable)
assumptions about the world. I assume only that the
range of color responses induced by different
reflectances varies with a change in illumination and
that illumination itself can vary only within certain
bounds. I tested the algorithm on real images taken with
a color video camera--extremely good constancy is
delivered. Indeed the degree of constancy compares
favorably with the best which is theoretically possible.
The methods developed in this thesis can be applied to a
variety of other areas: including color graphics, color
reproduction and color appearance models.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  3567 </NUMBER>
<ORDER>   AAGC501533 </ORDER>
<TITLE> A DESIGN APPROACH TO INTEGRATED INTELLIGENT SYSTEMS IN A MANUFACTURING ENVIRONMENT </TITLE>
<AUTHOR> PARAMSOTHY, JEYAKUMAR </AUTHOR>
<YEAR> 1995 </YEAR>
<INSTITUTION> UNIVERSITETET I TRONDHEIM (NORWAY); 0941 </INSTITUTION>
<DESCRIPTORS> ENGINEERING, MECHANICAL; ENGINEERING, SYSTEM SCIENCE; ARTIFICIAL INTELLIGENCE N-7034 TRONDHEIM-NTH, NORWAY </DESCRIPTORS>
<ADVISER> NIL </ADVISER>
<CLASSIFICATIONS> EXPERT SYSTEMS </CLASSIFICATIONS>
<ABSTRACT>
This thesis provide the concept, methodology, and
implementation techniques of an Integrated Intelligent
System (IIS), as well as IIS applications in real-world
manufacturing industries. IIS is a knowledge integration
environment, which consists of six modules: a meta-
system, a graphic package, a data base system, a
spreadsheet system, numerical computations and an expert
system. The integrated software environments allows the
running of programs written in different languages, and
communicate among the programs as well as exchange of
data between programs and database. These isolated
intelligent systems, numerical packages and other
modules are under the control of a supervising
intelligent system, which is called a meta-system. The
meta-system manages the selection, coordination,
operation and communication of these programs.
This thesis consists of seven chapters. The tutorial
nature of some of the Chapters serves as an introduction
to the application techniques which may be employed,
particularly for industrial problem solving.
This thesis also has identified some of the more
important guidelines and has outlined how a low-cost
knowledge-processing system (called KnowledgePro) can be
used to facilitate their realisation. The KnowledgePro
system offers a 'rich' and 'intelligent' environment to
build an IIS.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  3568 </NUMBER>
<ORDER>   AAGC499812 </ORDER>
<TITLE> NEURAL NETWORKS FOR COMPUTER-AIDED DIAGNOSIS OF PULMONARY IMAGES IN NUCLEAR MEDICINE </TITLE>
<AUTHOR> LIVIERATOS-PETRATOS, GEORGE N. </AUTHOR>
<YEAR> 1995 </YEAR>
<INSTITUTION> UNIVERSITY OF SOUTHAMPTON (UNITED KINGDOM); 5036 </INSTITUTION>
<DESCRIPTORS> ENGINEERING, BIOMEDICAL; ENGINEERING, NUCLEAR; HEALTH SCIENCES, RADIOLOGY; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> NIL </ADVISER>
<CLASSIFICATIONS> NIL </CLASSIFICATIONS>
<ABSTRACT>
This research is concerned with the design of a system
that is able to recognize abnormalities in Perfusion and
Ventilation lung radioisotope images captured using a
Gamma camera attached to a computer system. Although
lung images are used, the intention is to develop a
system that is easily transferable to other medical
imaging diagnostic problems.
Other research has managed to detect specific abnormal
regions, such as tumours, in a medical image or to give
a Yes/No answer for the existence of a particular
disease. The raw images have a high level of noise as
well as shape and size dissimilarities. Moreover, they
are rotated slightly and not centred on the same point.
These factors influence the performance of the neural
network greatly and therefore the first task is to
preprocess the images. Typically, the inputs of these
systems are either regions of interest (ROI) or other
features of the image that have been chosen manually.
In contrast, this research provides an automatic system
whose inputs are raw images of a pair of lungs and
outputs are the location of the abnormal regions and the
level of the abnormalities. This information is required
for the detection of any disease and the estimation of
its stage. Two new ideas are introduced. The main one,
is a new approach in artificial neuron theory which has
different training principles. The other is a nonlinear
filter for the extraction of an object from a noisy
background that is used in the preprocessing stage.
Two different applications of the proposed neuron are
presented. They can either work independently or be
combined together. The results are assessed using the
receiver operating characteristic curve and an
experiment that, also, involves raw images. It is shown
that the system increases the accuracy and, especially,
the sensitivity of the diagnostic test. Furthermore, it
is able not only to confirm the experts' diagnoses but
also to reveal hidden information. Consequently, it is
also expected to assist the radiologist with the
diseases at their early stages.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  3569 </NUMBER>
<ORDER>   AAG9709415 </ORDER>
<TITLE> AGITATING DISSENT: METHODS FOR IMPROVING PERFORMANCE OF A NEURAL NETWORK COMMITTEE BY ERROR DECORRELATION </TITLE>
<AUTHOR> PARMANTO, BAMBANG </AUTHOR>
<YEAR> 1995 </YEAR>
<INSTITUTION> UNIVERSITY OF PITTSBURGH; 0178 </INSTITUTION>
<DESCRIPTORS> COMPUTER SCIENCE; STATISTICS; OPERATIONS RESEARCH; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> NIL </ADVISER>
<CLASSIFICATIONS> COMMITTEE ARCHITECTURE </CLASSIFICATIONS>
<ABSTRACT>
The idea of a neural network committee is to combine
several neural network predictors, instead of using a
single network, to perform collective decision-making
such as majority voting, simple averaging, or weighted
averaging. The potential of a committee in improving the
prediction performance has been well documented. Central
to the performance improvement of the committee compared
to the individual networks is the error correlation
between networks in the committee. Methods of achieving
error independence between the networks are the subject
of investigation in this dissertation. The proposed
methods have two major bulwarks. The first is to use
resampling techniques to compose different learning set
replicas for each network in the committee. The second
is learning algorithms based on ancillary tasks to
decorrelate the networks. The effectiveness of the
proposed methods are demonstrated in data sets with
different levels of noise and in real-world medical
diagnosis problems.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  3570 </NUMBER>
<ORDER>   AAGC489184 </ORDER>
<TITLE> SELF-ORGANIZING MAP AND REDUCED KERNEL DENSITY ESTIMATION  </TITLE>
<AUTHOR> HAMALAINEN, ARI </AUTHOR>
<YEAR> 1995 </YEAR>
<INSTITUTION> JYVASKYLAN YLIOPISTO (FINLAND); 0979 </INSTITUTION>
<DESCRIPTORS> COMPUTER SCIENCE; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> NIL </ADVISER>
<CLASSIFICATIONS> NEURAL NETWORKS </CLASSIFICATIONS>
<ABSTRACT>
This thesis has two main themes, properties of the self-
organizing map and reduced kernel density estimation.
These two topics are tied together by the RKDE density
estimation method. The literature overview given in
Section 2 shows that the mathematical analysis of the
self-organizing map is difficult. In particular, very
little is known about its topological ordering. In fact,
not even a generally accepted definition of ordering
exists. One suggestion was given in Section 2.3. In
Section 2.4, an automatic genetic algorithm (GA) based
method for self-organizing map network topology design
was proposed. The measure of disorder, proposed in
Section 2.3 was used in a fitness function of the GA.
The GA based method is computationally costly and should
be developed further until it can be useful in
applications.
In Section 3, the kernel density estimator (KDE) was
reviewed. The methods of choosing the smoothing
parameter and adaptive kernel density estimation were
also discussed. The generalization of the KDE to the
multivariate case is straightforward and only the mean
integrated squared error was given.
The self-organizing reduced kernel density estimator
(RKDE) was introduced in Section 4. The method estimates
the kernel centers using the SOM algorithm. The
smoothing parameters and the weights for each kernel can
also be estimated iteratively. Therefore, the method is
applicable in problems where the data become available
one sample point at a time. Such situations are typical
in applications of artificial neural networks. Since the
network structure used in the underlying self-organizing
map affects the density estimation properties of the
RKDE, the ideas developed in Section 2 may prove to be
useful in the further development of the self-organizing
reduced kernel density estimator.
To get an idea of how much complexity reduction is
possible in kernel density estimation, the binned kernel
density estimator (BKDE) was analyzed in Section 5. The
one dimensional results are analogous to those obtained
in (36, 96), although the derivation given here is
slightly different. The corresponding multivariate
result is new and it was shown in Section 6 that the
number of the kernels needed in the BKDE is of the order
$O(Nsp0d/(d+4)).$
The various density estimation techniques discussed in
this thesis were tested with real and artificial data in
Section 7. The results show that great complexity
reduction is possible when the RKDE method is used.
Further, it can be applied in a natural way in
situations involving dynamically changing environments.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  3571 </NUMBER>
<ORDER>   AAGC489028 </ORDER>
<TITLE> IMAGE SEGMENTATION BY CONTOUR GROUPING: KNOWLEDGE-BASED SEARCH IN ATTRIBUTED PROXIMITY GRAPH </TITLE>
<AUTHOR> VEHKOMAKI, TUOMO SAKARI </AUTHOR>
<YEAR> 1995 </YEAR>
<INSTITUTION> EIDGENOESSISCHE TECHNISCHE HOCHSCHULE ZUERICH (SWITZERLAND); 0663 </INSTITUTION>
<DESCRIPTORS> COMPUTER SCIENCE; ARTIFICIAL INTELLIGENCE 02150 ESPOO, FINLAND </DESCRIPTORS>
<ADVISER> NIL </ADVISER>
<CLASSIFICATIONS> NIL </CLASSIFICATIONS>
<ABSTRACT>
The intermediate level of a vision system has the task
to group unorganized primitives produced by an early
vision process into meaningful entities. This step is
also a prerequisite for object recognition done at a
higher level of the system and very often regarded as
the bottleneck in computer vision. Here, the main goal
has been to develop a segmentation concept for medical
applications, requiring that the user interaction be
reduced and sped up, and accuracy and reproducibility of
the results be improved compared with plain manual
tools.
The novel grouping techniques presented in this work are
based on extended graph description of the contour
fragments. The graph structure, created from edge
magnitude and orientation maps, describes the
neighborhood relations of binarized contour pixels and
contains a spectrum of additional information extracted
from the original image and available feature maps.
The attributed proximity graph is utilized to find
closed object contours, corresponding to paths in the
graph, by contour grouping algorithms. The developed
algorithms approach the problem from two different
directions. An algorithm based on path optimization can
be used when user supervision is necessary. Another
algorithm is region based and uses a split-and-merge
strategy and optimization with global criteria and does
not require user intervention. Both of these techniques
work natively with two dimensional images but for
segmentation of three dimensional data, such as medical
slice stacks, supporting information from neighboring
slices can be integrated with the graph structure.
The path optimization algorithm utilizes the quality
values assigned to the graph edges and uses a Dynamic
Programming technique to search for an optimal path in
the graph between control points selected by the user
within an interactive segmentation environment. Defining
several control points allows to split the search task
and to apply geometrical constraints, which implies
truly interactive response times.
The split-and-merge algorithm first creates an
oversegmentation of the image by enumerating elementary
cycles from the graph structure. Ignoring possible
holes, a set of neighboring cycles defines a hypothesis
of a closed outline. A quality function based on the
shape of the outline hypothesis, its match with image
features, and similarity with a possible model contour,
is evaluated. Tabu Search, a discrete optimization
technique, is used to find an optimal solution among the
hypotheses.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  3572 </NUMBER>
<ORDER>   AAI1378650 </ORDER>
<TITLE> INTELLIGENT CONTROL AND ADAPTIVE CRITIC ARTIFICIAL NEURAL NETWORKS </TITLE>
<AUTHOR> WATSON, JAMES DONALD </AUTHOR>
<YEAR> 1995 </YEAR>
<INSTITUTION> THE AMERICAN UNIVERSITY; 0008 </INSTITUTION>
<DESCRIPTORS> COMPUTER SCIENCE; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> LARRY R. MEDSKER </ADVISER>
<CLASSIFICATIONS> NIL </CLASSIFICATIONS>
<ABSTRACT>
Process control is the idea of exerting actions on some
system in order to generate a desired output. As we
develop more complex systems and require that they
operate in increasingly unstable environments, we find
traditionally designed controllers do not provide the
necessary level of control. Intelligent control offers
improvements over earlier control designs for
controlling systems in noisy, multi-variable, nonlinear
environments. A brief history of process control is
followed by a survey of current topics in intelligent
control, specifically adaptive and learning control.
Issues of implementation for four artificial
intelligence paradigms--artificial neural networks
(ANNs), expert systems, fuzzy logic, and genetic
algorithms--as well as hybrid approaches are also
covered. The survey helps explain process control and
intelligent methods. A chapter is dedicated to some of
the difficult subjects in ANN control. Implementation
suggestions are proposed.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  3573 </NUMBER>
<ORDER>   AAI1378649 </ORDER>
<TITLE> REPRESENTING HUMAN EMOTIONS IN INTELLIGENT AGENTS </TITLE>
<AUTHOR> STUDDARD, PATRICK </AUTHOR>
<YEAR> 1995 </YEAR>
<INSTITUTION> THE AMERICAN UNIVERSITY; 0008 </INSTITUTION>
<DESCRIPTORS> COMPUTER SCIENCE; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> MICHAEL A. GRAY </ADVISER>
<CLASSIFICATIONS> NIL </CLASSIFICATIONS>
<ABSTRACT>
The hysteretic computationally-based intelligent agent
architecture provides a powerful framework for
constructing agents capable of reasoning about and
interacting with their environment, including other
computationally-based agents. When asked to interact
with and attempt to cooperate with human agents, a
special problem is encountered. The emotions of the
human contribute to reasoning patterns far more
complicated than the symbolic logic used by the
computational agents.
In this thesis a series of systems is presented which
attempt to extend the world model of a class of
hysteretic intelligent agents to model human as well as
computational agents. The class of agents considered
uses a revisable belief system (such as a JRMS) to
construct and maintain its world model. First, the
possibilities of using an unmodified JRMS to represent
human emotions are investigated. The later systems
attempt to reduce unnecessary complexity by providing a
filtering mechanism and by providing default inference
rules.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  3574 </NUMBER>
<ORDER>   AAI1378271 </ORDER>
<TITLE> AN INSTANCE-BASED LEARNING ALGORITHM FOR PREDICTING NUMERIC VALUES AND ITS APPLICATIONS TO HIGHWAY ACCIDENT ANALYSIS </TITLE>
<AUTHOR> YIM, YEE-SAT </AUTHOR>
<YEAR> 1995 </YEAR>
<INSTITUTION> UTAH STATE UNIVERSITY; 0241 </INSTITUTION>
<DESCRIPTORS> COMPUTER SCIENCE; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> JIANPING ZHANG </ADVISER>
<CLASSIFICATIONS> ARTIFICIAL INTELLIGENCE </CLASSIFICATIONS>
<ABSTRACT>
In real world machine learning applications, tasks
usually involve predicting numeric values. One example
of such applications occurs in highway accident
frequency prediction. This thesis introduces a new
instance-based learning system, IB2N, which
incrementally learns and predicts numeric values, while
achieving storage reduction. The novel features of the
method are (1) three new prediction algorithms, (2) a
storage reduction algorithm, and (3) a weight-adjusting
algorithm. The IB2N method is also justified by
theoretical analysis.
Incrementally, IB2N's prediction methods carefully
select two stored instances to predict a new instance
using distances and class differences, its storage
reduction method stores only mispredicted instances, and
its weight-adjusting algorithm adjusts each attribute
weight after every prediction. The experiments conducted
to evaluate IB2N's prediction, storage reduction and
weight-adjusting methods qualified IB2N as a promising
learning system.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  3575 </NUMBER>
<ORDER>   AAI1378255 </ORDER>
<TITLE> ARTIFICIAL NEURAL NETWORK MAMMOGRAPHIC BREAST TISSUE CHARACTERIZATION </TITLE>
<AUTHOR> PARSONS, MARK DAVID </AUTHOR>
<YEAR> 1995 </YEAR>
<INSTITUTION> UTAH STATE UNIVERSITY; 0241 </INSTITUTION>
<DESCRIPTORS> HEALTH SCIENCES, RADIOLOGY; HEALTH SCIENCES, CHEMOTHERAPY; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> DONALD H. COOLEY </ADVISER>
<CLASSIFICATIONS> NIL </CLASSIFICATIONS>
<ABSTRACT>
This thesis explores the application of artificial
neural networks as an aid to the diagnosis of breast
disease. It discusses the current state of the art in
mammography and other research that utilized artificial
neural networks in mammography. It then provides a
detailed description of the novel concept of extracting
texture features from mammograms and characterizing the
region with a feedforward backpropagation artificial
neural network. The classifier used in this study
produced a true positive rate of 88.5% and a true
negative rate of 83.9% for the mammographic regions
presented.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  3576 </NUMBER>
<ORDER>   AAI1378253 </ORDER>
<TITLE> NEURAL NETWORK ANALYSIS OF THE INCOHERENT RADAR SPECTRUM </TITLE>
<AUTHOR> MUELLER, RICHARD JUDD </AUTHOR>
<YEAR> 1995 </YEAR>
<INSTITUTION> UTAH STATE UNIVERSITY; 0241 </INSTITUTION>
<DESCRIPTORS> PHYSICS, ATMOSPHERIC SCIENCE; ARTIFICIAL INTELLIGENCE; PHYSICS, FLUID AND PLASMA </DESCRIPTORS>
<ADVISER> A. R. BARAKAT </ADVISER>
<CLASSIFICATIONS> NIL </CLASSIFICATIONS>
<ABSTRACT>
In the high latitude F-region, the plasma horizontal
drift can be comparable to, or greater than the neutral
oxygen (O) thermal speed. As a result of the interplay
between the ionospheric ExB drift, and the O-O+
collisions, the O+ velocity distribution function, $rm
fsb0osp+ (v)$ deviates significantly from Maxwellian. As
the ExB drift velocity increases, the shape of $rm
fsb0osp+ (v)$ becomes bi-Maxwellian, and then toroidal.
The corresponding scattered wave spectrum of the
incoherent radar changes from a double-peaked, to a
triple-peaked, and then to a "baby-bottle" shape. The
standard analysis technique, which assumes a Maxwellian,
is not suitable under such conditions. Here, we applied
a backpropagation neural network to analyze the radar
spectrum corresponding to a non-Maxwellian $rm fsb0o+
(v).$ The performance of the neural network was
investigated for different physical conditions and
design parameters, including noise level, sampling
density, and aspect angle.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  3577 </NUMBER>
<ORDER>   AAI1378241 </ORDER>
<TITLE> PHONETIC TRANSCRIPTION FOR DISABLED SPEECH </TITLE>
<AUTHOR> HU, MEIFANG </AUTHOR>
<YEAR> 1995 </YEAR>
<INSTITUTION> UTAH STATE UNIVERSITY; 0241 </INSTITUTION>
<DESCRIPTORS> COMPUTER SCIENCE; ARTIFICIAL INTELLIGENCE; HEALTH SCIENCES, SPEECH PATHOLOGY </DESCRIPTORS>
<ADVISER> NICHOLAS FLANN </ADVISER>
<CLASSIFICATIONS> ARTIFICIAL INTELLIGENCE </CLASSIFICATIONS>
<ABSTRACT>
The goal of this research is to develop and evaluate an
automatic, on-line system, called the Speech Phonetic
Transcription System (SPTS). The SPTS enables speech
pathologists (SP) to automatically collect the phonetic
transcriptions of the words spoken by people with speech
disabilities. This system can also assist speech
pathologists with speech analysis of their clients'
remediation programs.
The SPTS consists of the Speech Sample Gathering Device
(SSGD), a speech synthesis output device, a public
domain speaker-independent word recognition system, a
large speech database, and support software.
This study utilized the speech patterns from fourteen
adults and nine children, who have either articulative
disabilities or hearing problems. The minimum edit
distance error analysis technique was used to determine
the final results by comparing the SPTS transcription
with the standard transcription, and with the
transcription made by the speech pathologists. The three
kinds of errors analyzed were those of insertion,
deletion, and substitution. Some factors contributed to
recognition errors in the SPTS. They are the
inconsistent duration of the client's utterance, the
sensitivity of the SSGD, and the use of the Viterbi
algorithm, which was applied during the recognition
processes. Analysis of the SPTS transcription showed
that speaker variability affected the recognition
results for these speech samples. Regarding speaker
variability, phonetic error reduction rules were
developed and applied in this study to improve the
recognition rate. Having encountered practical
inconveniences in collecting speech samples, we
recommend the use of a headset-mounted microphone to
improve the SPTS. (Abstract shortened by UMI.)
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  3578 </NUMBER>
<ORDER>   AAI1378219 </ORDER>
<TITLE> POSSIBILITY-BASED FUZZY NEURAL NETWORKS AND THEIR APPLICATIONS </TITLE>
<AUTHOR> CHEN, LI </AUTHOR>
<YEAR> 1995 </YEAR>
<INSTITUTION> UTAH STATE UNIVERSITY; 0241 </INSTITUTION>
<DESCRIPTORS> COMPUTER SCIENCE; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> DONALD H. COOLEY </ADVISER>
<CLASSIFICATIONS> NIL </CLASSIFICATIONS>
<ABSTRACT>
A generalized fuzzy neural network has been created and
implemented for this thesis. The major difference
between a standard neural network and the fuzzy neural
network proposed in this thesis is that the fuzzy neural
network can accept a set of possibility functions as
input as well as a vector of scalar values. This neural
network has been used in three applications: satellite
image classification, seismic straitgraphic pattern
recognition, and ionogram scaling. The results show that
the fuzzy neural network compares well with other neural
network and image processing methods.
This thesis describes the implementation of a two-stage
fuzzy neural network. The first stage of the network is
fuzzy-based in that the weights of the associated nodes
are implemented as possibility functions. The output of
this layer is a fuzzy set. This output forms the input
to a standard backpropagation-based neural network. Such
a fuzzy neural network shows promise for the
classification of complex feature sets because it
performs better with fewer nodes and layers than a
comparable performance backpropagation-based neural
network.
This thesis explains the reasons for introducing the
proposed neural network through several practical
problems. This thesis then examines theoretical results
based upon the neural network. The possibility-based
neural network is self-complete and unique.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  3579 </NUMBER>
<ORDER>   AAIMM06699 </ORDER>
<TITLE> LEARNING FROM KNOWLEDGE SYSTEMS </TITLE>
<AUTHOR> LARMAN, CRAIG </AUTHOR>
<YEAR> 1995 </YEAR>
<INSTITUTION> SIMON FRASER UNIVERSITY (CANADA); 0791 </INSTITUTION>
<DESCRIPTORS> COMPUTER SCIENCE; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> VERONICA DAHL; NICK CERCONE </ADVISER>
<CLASSIFICATIONS> NIL </CLASSIFICATIONS>
<ABSTRACT>
This thesis describes a case-based reasoning (CBR)
system, ISCN Student, which acquires its knowledge from
a previously developed rule-based knowledge system, ISCN
Expert. That is, ISCN Student is a second generation
knowledge system that learns from a first generation
one. ISCN Student has been shown to perform with the
same competence as ISCN Expert once trained. The
architecture for this solution is based upon the
creation of a general purpose object-oriented CBR
framework, written in Smalltalk, that has been
specialized to develop ISCN student, but which is
applicable to other CBR problem domains.
ISCN is a notation used by geneticists to describe
chromosome defects; the functional purpose of both ISCN
Expert and Student is to interpret expressions in ISCN.
To this end, several supporting paths of novel research
have been pursued in addition to the above. First, a
grammar and associated parser for ISCN were created.
Second was the development of a visual manipulation
system for displaying chromosome defects and introducing
new abnormalities as cases to ISCN Student.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  3580 </NUMBER>
<ORDER>   AAGC531988 </ORDER>
<TITLE> THE APPLICATION OF ARTIFICIAL NEURAL NETWORKS TO THE INTERPRETATION AND CLASSIFICATION OF FRESHWATER BENTHIC INVERTEBRATE COMMUNITIES </TITLE>
<AUTHOR> RUCK, BRENDAN MICHAEL </AUTHOR>
<YEAR> 1995 </YEAR>
<INSTITUTION> ASTON UNIVERSITY (UNITED KINGDOM); 0734 </INSTITUTION>
<DESCRIPTORS> ENVIRONMENTAL SCIENCES; BIOLOGY, LIMNOLOGY; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> NIL </ADVISER>
<CLASSIFICATIONS> NIL </CLASSIFICATIONS>
<ABSTRACT>
This thesis presents a thorough and principled
investigation into the application of artificial neural
networks to the biological monitoring of freshwater. In
contains original ideas on the classification and
interpretation of benthic macroinvertebrates, and aims
to demonstrate their superiority over the biotic systems
currently used in the UK to report river water quality.
The conceptual basis of a new biological classification
system is described, and a full review and analysis of a
number of river data set is presented. The biological
classification is compared to the common biotic systems
using data from the Upper Trent catchment. This data
contained 292 expertly classified invertebrate samples
identified to mixed taxonomic levels.
The neural network experimental work concentrates on the
classification of the invertebrate samples into
biological class, where only a subset of the sample is
used to form the classification. Other experimentation
is conducted into the identification of novel input
samples, the classification of samples from different
biotopes and the use of prior information in the neural
network models. The biological classification is shown
to provide an intuitive interpretation of a graphical
representation, generated without reference to the class
labels, of the Upper Trent data.
The selection of key indicator taxa is considered using
three different approaches; one novel, one from
information theory and one from classical statistical
methods. Good indicators of quality class based on these
analyses are found to be in good agreement with those
chosen by a domain expert. The change in information
associated with different levels of identification and
enumeration of taxa is quantified.
The feasibility of using neural network classifiers and
predictors to develop numeric criteria for the
biological assessment of sediment contamination in the
Great Lakes is also investigated.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  3581 </NUMBER>
<ORDER>   AAIMM06551 </ORDER>
<TITLE> A NEW APPROACH TO GENETIC-BASED AUTOMATIC FEATURE DISCOVERY </TITLE>
<AUTHOR> VAN BELLE, TERRY (THEODORE) B. </AUTHOR>
<YEAR> 1995 </YEAR>
<INSTITUTION> UNIVERSITY OF ALBERTA (CANADA); 0351 </INSTITUTION>
<DESCRIPTORS> COMPUTER SCIENCE; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> JONATHAN SCHAEFFER </ADVISER>
<CLASSIFICATIONS> NIL </CLASSIFICATIONS>
<ABSTRACT>
Systems which take raw data and categorize them into
discrete classes are ubiquitous in computer science,
having applications in fields such as vision, expert
systems, and game playing. These systems work by
extracting features from the data and then combining the
values of the features to form a judgement. While much
work has been done on ways to automatically combine
feature values, the task of automatic discovery of these
features is recognized to be much more difficult, and so
has become one of the holy grails of machine learning.
Classifier systems, an outgrowth of genetic algorithms,
seemed a promising approach to automatic feature
discovery, but it is difficult to get the full power of
the classifier system from existing implementations.
This thesis simplifies the classifier system into a
variant of the genetic algorithm, called the Population
Genetic Algorithm (PGA). PGAs are used to automatically
discover features for tic-tac-toe and checkers endgame
positions, and these features are automatically combined
using Bayesian statistics to classify each position as
won, lost, or drawn.
The theoretical maximum performance of the PGAs is
determined by using an exhaustive enumeration technique
to serve as a baselline comparison. The results indicate
that while PGAs can be made to perform at near-optimal
levels, the optimal solution is insufficient to
perfectly classify any of the domains studied.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  3582 </NUMBER>
<ORDER>   AAIMM05469 </ORDER>
<TITLE> AN EXPERT SYSTEM FOR EEG MONITORING IN THE PEDIATRIC ICU </TITLE>
<AUTHOR> PASUPATHY, ANITHA K. </AUTHOR>
<YEAR> 1995 </YEAR>
<INSTITUTION> MCGILL UNIVERSITY (CANADA); 0781 </INSTITUTION>
<DESCRIPTORS> ENGINEERING, ELECTRONICS AND ELECTRICAL; ENGINEERING, BIOMEDICAL; BIOLOGY, NEUROSCIENCE; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> NIL </ADVISER>
<CLASSIFICATIONS> NIL </CLASSIFICATIONS>
<ABSTRACT>
A knowledge-based expert system was developed to assess
the level of abnormality in the brain electrical
activity of pediatric patients monitored in the
intensive care unit. Six hours of an 8-channel EEG
record serves as the input to the monitoring device
based on which the brain activity is classified as being
normal, mildly abnormal, moderately abnormal or severely
abnormal.
Spectral band activity is computed for each channel for
every 30-second epoch. Artifact rejection is
accomplished by a median filter with a hard-limiter
thresholder. Quantitative variables reflecting possible
abnormality: a measure of amplitude depression, a
measure of assymmetry, a measure of anterio-posterior
differentiation and a measure of EEG variability over
time are extracted from each EEG record. Statistical
distributions of these measures are established for a
control "normal" population of about ten patients so
classified by a neurologist on visual interpretation.
New EEGs to be analysed are statistically compared with
the control population and a probability measures of
normality for the various measures are determined. The
expert system learns from prior examples of
classification done by the neurologist by a technique of
inductive machine learning. The monitor is trained and
tested using sixty examples using the rotation method of
error estimation.
The monitor had a tendency to classify the EEGs with a
higher level of abnormality than the expert. Possible
reasons and potential solutions are discussed.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  3583 </NUMBER>
<ORDER>   AAIMM05269 </ORDER>
<TITLE> THE APPLICATION OF NEURAL NETWORKS TO PREDICTING THE CONDUCTIVITY OF WATER </TITLE>
<AUTHOR> GATES, CARRIE ELAINE </AUTHOR>
<YEAR> 1995 </YEAR>
<INSTITUTION> DALHOUSIE UNIVERSITY (CANADA); 0328 </INSTITUTION>
<DESCRIPTORS> COMPUTER SCIENCE; ARTIFICIAL INTELLIGENCE; PHYSICS, ELECTRONICS AND ELECTRICITY </DESCRIPTORS>
<ADVISER> CAROLYN WATTERS; THOMAS TRAPPENBERG </ADVISER>
<CLASSIFICATIONS> NIL </CLASSIFICATIONS>
<ABSTRACT>
Water is the most precious resource known to man. It is
therefore important that testing on water be done
accurately, hence tests are needed to assure that the
results from these analyses are correct. Hughes et al.
(1) compared eleven different prediction methods,
including physical models, statistical methods and
neural networks, to predict the conductivity of water
based on the concentrations of ten major ions. Of these
tests, neural networks gave the poorest results.
An attempt is made in this thesis to analyse why the
network designed by this group performed so poorly and
to improve the performance of neural networks for this
problem. The results from tuning the variables of the
network are examined, including the values of $beta$,
the number of hidden nodes, the cost function and the
back-propagation method. A hybrid algorithm, similar to
the one recently presented by Baba et al. (2), was
tested. This algorithm combines back-propagation with a
random optimization method to assist in finding a global
minimum over a local minimum. Two modifications to the
algorithm of Baba et al. (2) are tested: allowing back-
propagation to occur on the weight vectors generated by
the random optimization method and using an entropic
instead of quadratic cost function.
The network is trained using 200
concentration/conductivity patterns and the results are
explored in terms of the theory of representability. The
trained network is then examined to see how well it can
generalize to patterns which are unknown. This is again
examined in terms of the theoretical basis of
generalizability and information theory. Several
possible reasons are given for the network's poor
performance and suggestions are made for future
directions.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  3584 </NUMBER>
<ORDER>   AAIMM05139 </ORDER>
<TITLE> NEURAL NETWORK APPLICATION TO VEHICLE SYSTEM DYNAMICS </TITLE>
<AUTHOR> TARABOULSI, CHOUCRI-GABRIEL </AUTHOR>
<YEAR> 1995 </YEAR>
<INSTITUTION> CONCORDIA UNIVERSITY (CANADA); 0228 </INSTITUTION>
<DESCRIPTORS> ENGINEERING, AUTOMOTIVE; ARTIFICIAL INTELLIGENCE; ENGINEERING, MECHANICAL </DESCRIPTORS>
<ADVISER> A. U. W. AHMED </ADVISER>
<CLASSIFICATIONS> NIL </CLASSIFICATIONS>
<ABSTRACT>
Neural Network (N.N.) and Neurocomputing have been
applied as a tool with artificial intelligence in many
areas such as pattern recognition, control,
classification, diagnostics, automation, etc. With the
advancement of parallel processing and computational
speed, N.N. has become an efficient tool for predicting
and simulating input-output relationship for complex
systems with large number of variables with poorly
defined relationships. Vehicle dynamics is such a
complex system when tire mechanics is included under
steering input. N.N. is developed using a commercial
software Neural-Works Professional II Plus to evaluate
its potential for simulation and control of vehicle
system under steering input. A three degree of freedom
vehicle model under steering input is developed to train
N.N. on the relationship between the tire parameter and
vehicle yaw velocity. Inverse dynamics is then used to
predict tire property for given vehicle yaw response,
including a minimum feasible yaw response. A six degrees
of freedom complete vehicle model is then used to study
the potential of N.N. for roll dynamics and its control,
under steering input. From this preliminary study, it is
concluded that N.N. can be used effectively in vehicle
dynamics applications, however, with some inherent
limitations. Its potential is significant in application
to control of vehicle system dynamics. A major
limitation being the inability of the N.N. to learn when
different combination of parameters lead to same
response.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  3585 </NUMBER>
<ORDER>   AAIMM05135 </ORDER>
<TITLE> NEURAL NETWORK BASED DECENTRALIZED CONTROL OF AN MZSH SYSTEM </TITLE>
<AUTHOR> SABOKSAYR, HOSSEIN S. </AUTHOR>
<YEAR> 1995 </YEAR>
<INSTITUTION> CONCORDIA UNIVERSITY (CANADA); 0228 </INSTITUTION>
<DESCRIPTORS> ENGINEERING, ELECTRONICS AND ELECTRICAL; ENGINEERING, CIVIL; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> R. V. PATEL; M. ZAHEE-UDDIN </ADVISER>
<CLASSIFICATIONS> NIL </CLASSIFICATIONS>
<ABSTRACT>
Efficient operation of space heating systems is a
practical control problem of considerable economic
significance. In this thesis, a multizone space heating
(MZSH) system is considered. The MZSH system consists of
a boiler, two environmental zones and two heat pumps
(one for each zone) and the associated distribution
network. The control problem is to operate the boiler
and the heat pumps such that good zone temperature
control can be achieved and energy savings can be
realized by implementing occupied and unoccupied
setpoint changes. This task of combining the setpoint
changes initiated by the occupants and those initiated
by the supervisory controller such as night setback into
one control strategy is investigated.
To this end a multivariable decentralized neural network
controller is proposed. The proposed controller is time-
varying and its design is based on the minimization of a
decentralized cost function. The performance of the
designed controller is compared with published results.
It is shown that the neural networks are trainable for
MZSH systems and the control system performs well over a
wide range of operation and gives better disturbance
rejection compared to the existing controllers.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  3586 </NUMBER>
<ORDER>   AAIMM05130 </ORDER>
<TITLE> A COMPUTER INTEGRATED SYSTEM FOR CRANE SELECTION FOR HIGH-RISE BUILDING CONSTRUCTION </TITLE>
<AUTHOR> AL-HUSSEIN, MOHAMED </AUTHOR>
<YEAR> 1995 </YEAR>
<INSTITUTION> CONCORDIA UNIVERSITY (CANADA); 0228 </INSTITUTION>
<DESCRIPTORS> ENGINEERING, CIVIL; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> S. AL-KASS </ADVISER>
<CLASSIFICATIONS> NIL </CLASSIFICATIONS>
<ABSTRACT>
Conventional algorithmic programs are unable to
manipulate heuristic and qualitative knowledge which is
necessary to solve construction problems such as the
equipment selection. On the other hand Knowledge Based
Expert System (KBES) are not robust in numerical data
manipulation, while being very effective in declarative
knowledge manipulation and handling of logical
inferences and reasoning. Therefore, expert systems and
conventional programming can be combined to support an
effective decision throughout the crane selection
process.
This research concentrates on presenting a methodology
for crane selection for high-rise building construction
projects. The methodology is incorporated into an
integrated computer system, called CRANE ADVISOR,
capable of advising the users on the selection of
appropriate cranes for their building construction
projects. Experts knowledge has been captured,
classified and coded in the system's knowledge-base.
The system incorporates two main modules. The first
being a Knowledge-Based module that contains experts
knowledge, heuristics and rules of thumb related to
cranes selection. The second is a Case-Based Reasoning
module containing information on various cases
representing already constructed buildings with
preselected crane(s).
The system benefits from the Object Oriented Programming
characteristics of the abstraction, inheritance,
modularity, and encapsulation of data. LEVEL 5 as an
Object-Oriented Expert System shell, has been used to
develop the CRANE ADVISOR. It allows for the stored data
and knowledge to be accessed by all parties involved in
the crane selection process. It is also capable of
facilitating user friendly interface. An example case is
presented in order to demonstrate the effectiveness of
the methodology.
The Crane Advisor contributes to the current automation
efforts in construction industry and its modular
architecture allows for further enhancements and
expansion. (Abstract shortened by UMI.)
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  3587 </NUMBER>
<ORDER>   AAIMM04912 </ORDER>
<TITLE> A LAZY TEXT-BASED APPROACH TO FOUNDATIONAL KNOWLEDGE ACQUISITION  </TITLE>
<AUTHOR> MASSEY, LOUIS </AUTHOR>
<YEAR> 1995 </YEAR>
<INSTITUTION> UNIVERSITY OF OTTAWA (CANADA); 0918 </INSTITUTION>
<DESCRIPTORS> COMPUTER SCIENCE; ARTIFICIAL INTELLIGENCE; INFORMATION SCIENCE; LANGUAGE, GENERAL </DESCRIPTORS>
<ADVISER> S. MATWIN </ADVISER>
<CLASSIFICATIONS> ARTIFICIAL INTELLIGENCE </CLASSIFICATIONS>
<ABSTRACT>
Knowledge Acquisition (KA) from text requires that a
large quantity of prior knowledge be made available to
the Natural Language Processing (NLP) system. This prior
knowledge is called foundational knowledge. The question
of where foundational knowledge comes from in the first
place is one of the biggest problem facing NLP.
Conventionally, foundational knowledge has been hand-
crafted on a task- and domain-specific basis. However,
it is difficult to determine beforehand exactly what
knowledge will be required. It has been shown within the
TANKA project that a potential solution to this problem
is to use surface NLP. Surface NLP relies solely on
syntax and on the help of a user to elicit knowledge
from text, hence effectively eliminating the need for
prior-hand crafting of foundational knowledge. However,
the domain knowledge obtained in this manner from a text
contains gaps. The work presented in this thesis
consisted in finding a better method than prior hand-
crafting to acquire the knowledge needed to fill those
gaps. The method presented, called Lazy KA, uses
examples (short NL stories) and failures of an
explanation mechanism such as EBL to find these gaps and
to interactively and incrementally learn the required
new knowledge. When the explanation of a particular
example fails, the user is guided through a process that
leads to the acquisition of the missing knowledge.
Initially, the user is heavily involved, but as more
examples are processed, the user becomes less and less
involved. The convergence hypothesis, that is that the
user interventions would decrease as examples are
processed, was verified experimentally by using the
prototype system FOKAS implementing these ideas.
(Abstract shortened by UMI.)
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  3588 </NUMBER>
<ORDER>   AAIMM04868 </ORDER>
<TITLE> SIMEX: A SIMULATION-BASED EXPERT PRODUCTION SCHEDULING SYSTEM  </TITLE>
<AUTHOR> COSKUN, RISVAN </AUTHOR>
<YEAR> 1995 </YEAR>
<INSTITUTION> UNIVERSITY OF OTTAWA (CANADA); 0918 </INSTITUTION>
<DESCRIPTORS> COMPUTER SCIENCE; ARTIFICIAL INTELLIGENCE; OPERATIONS RESEARCH </DESCRIPTORS>
<ADVISER> TUNCER OREN </ADVISER>
<CLASSIFICATIONS> ARTIFICIAL INTELLIGENCE </CLASSIFICATIONS>
<ABSTRACT>
A good methodology for production scheduling can result
in high efficiency in reducing manufacturing costs.
SIMEX is an experimental simulation-based expert
production scheduler developed by the author for
applications in flexible flow shop systems in a dynamic
factory environment. This study introduces the general
framework of SIMEX. A prototype is developed on an IBM
compatible PC in Prolog, MODSIM II, Visual Basic, and
Visual C++ to generate feasible and acceptable schedules
with a synchronous data exchange facility.
In general, primary tasks of SIMEX are to meet due dates
of the final products, to increase throughput by
reducing the number of setups, and to reduce inventory
cost in a flexible flow shop system in real time. SIMEX
has also an ability to change its expert system's rule
base interactively by means of a user interface. The
expert system module of SIMEX allows to use heuristics,
and production rules which are the simplifications that
help limit the search for possible problem solutions and
handling unexpected events. Simulation-based scheduler
written in MODSIM II, is another module of SIMEX. It
generates the schedules, repeatedly, to analyze and
verify proposed design and alternatives. (Abstract
shortened by UMI.)
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  3589 </NUMBER>
<ORDER>   AAI9624740 </ORDER>
<TITLE> BEHAVIORAL CHOICE IN AN ELECTRONIC NERVOUS SYSTEM </TITLE>
<AUTHOR> STRAUB, NEF </AUTHOR>
<YEAR> 1995 </YEAR>
<INSTITUTION> THE UNIVERSITY OF MICHIGAN; 0127 </INSTITUTION>
<DESCRIPTORS> COMPUTER SCIENCE; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> KEKI B. IRANI </ADVISER>
<CLASSIFICATIONS> NEURAL NETWORKS, ROBOTICS </CLASSIFICATIONS>
<ABSTRACT>
Much of neural network research being done is performed
in simulation, with simple, uniform neuron models and
connectivities, and using discrete activity and
evaluation steps. This research described herein
explores behavioral choices made by a continuous
heterogeneous network grounded within a physical robot.
Choices studied were dynamically made among both innate
and learned behaviors.
The study was accomplished by designing and implementing
an electronic nervous system composed of neuromimes with
excitatory, inhibitory, fatigue and threshold
characteristics. The network forms the sole control
structure for a tracked vehicle. Inputs arrive via
primitive contact, light, and motion sensors, and
outputs determine the vehicle's motion. The network
incorporates boredom, hunger, and fear drives, as well
as the capability for simple conditioning of the touch
stimuli to pain reflexes. The choice mechanism is
dynamic competition within the network, influenced by
current stimuli, internal drives, and recent network
history.
The resulting network, composed of 87 neuromimes and 342
synapses, utilizes dynamic competition at the sensory
interface, among the drives, and at the motor interface.
It embodies innate behaviors, learned behaviors, and a
method of choice effective over both behavioral sets.
To obtain a balance between behavioral persistence and
opportunism, we found fatigue to be a critical component
in all competitive circumstances. Positive feedback was
also found necessary for competition among drive
networks. We determined that fatigue and inhibition,
while causing similar effects with the neural model,
must be handled separately for reasons pertaining to
both competition and learning.
The inclusion of learning revealed a relation between
the structure of plastic synapses and the stability of
learned activity. Synapses structured to learn from
themselves form permanent memories; those which learn
only from other sources of excitation are subject to
memory decay on recall trials. We designed and
implemented a mechanism for actively reinforcing such
actively decaying memory.
Finally, it was concluded that learning elements of the
network must be placed within the innate competition
framework. The implementation presented automatically
includes learning and learned behaviors within the
innate choice mechanism.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  3590 </NUMBER>
<ORDER>   AAI9624308 </ORDER>
<TITLE> FEATURE GUIDED PIXEL MATCHING AND SEGMENTATION IN MOTION IMAGE SEQUENCES  </TITLE>
<AUTHOR> CHARAN, RAM </AUTHOR>
<YEAR> 1995 </YEAR>
<INSTITUTION> UNIVERSITY OF ILLINOIS AT URBANA-CHAMPAIGN; 0090 </INSTITUTION>
<DESCRIPTORS> ENGINEERING, ELECTRONICS AND ELECTRICAL; COMPUTER SCIENCE; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> NARENDRA AHUJA </ADVISER>
<CLASSIFICATIONS> MACHINE VISION, ARTIFICIAL INTELLIGENCE </CLASSIFICATIONS>
<ABSTRACT>
The problem of feature correspondences and trajectory
finding for a long image sequence has received
considerable attention. In this research, a coarse-to-
fine algorithm is developed to obtain pixel trajectories
through the sequence and to segment them into subsets
corresponding to objects moving distinctly. First, a
coarse-scale point-feature detector is used to detect
point features that are then used to form a 3D dot
pattern in the spatio-temporal region. The trajectories
are extracted as 3D curves formed by the points using
perceptual grouping. The set of feature points in each
frame is divided into subsets corresponding to objects
moving with different motion, using a measure of motion
similarity between feature points.
Next, increasingly dense correspondences are obtained
iteratively from the initial matches for sparse point
features. A Delaunay triangulation of the matched
features in each frame is computed. Additional point
features having higher densities are detected. The
motions of these denser features are predicted based on
the known motions of nearby, coarser-level features. The
coarser-level features near a detected fine-level
feature may belong to one or more objects with different
motions. All different motions are considered, and
candidate matches are computed using gray-level
correlation. The relaxation algorithm is used to select
the best candidate for each feature point. These finer-
level correspondences can again be segmented into
objects moving distinctly in the same way as was done at
the coarser level. This is followed by a reiteration of
the process of taking more feature points, predicting
their motions, computing candidate matches, selecting
the best match, and segmenting these finer-level feature
points into objects moving distinctly. The coarse-to-
fine level iteration is repeated until the feature
detector no longer provides useful new features.
Once the finest-level features are found and matched,
the matching of all pixels is done using intensity
correlation. Again, a pair of frames is considered for
this purpose. A Delaunay triangulation is computed for
the matched features at the finest level in a frame. The
three vertices of a Delaunay triangle may belong to one,
two, or three objects moving with different motions. All
of the motions are considered for computing candidate
matches for each pixel in a triangle. The relaxation
algorithm is used to obtain the best match in a way
similar to that used for finer-level matching. Once the
pixel-level matches are available between two frames, an
attempt is made to obtain the finest boundaries of the
moving objects. The results of feature-point matching at
the finest level are used to extend matches. Pixel-level
matches are computed from the results of finest-level
point-feature correspondences between a pair of frames.
The batches of overlapping frames are formed and
processed as described to obtain the results for an
entire sequence.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  3591 </NUMBER>
<ORDER>   AAGC524939 </ORDER>
<TITLE> DEVELOPING ROBOT BEHAVIOURS THROUGH NEURAL LEARNING </TITLE>
<AUTHOR> SOEMBAGIJO, ADHI SUDADI </AUTHOR>
<YEAR> 1995 </YEAR>
<INSTITUTION> KATHOLIEKE UNIVERSITEIT LEUVEN (BELGIUM); 5605 </INSTITUTION>
<DESCRIPTORS> ENGINEERING, MECHANICAL; ARTIFICIAL INTELLIGENCE CAMPUSBIBLIOTHEEKDIENST,  CELESTIJNENLAAN 300 A, B-3001 LEUVEN (HEVERLEE), BELGIUM </DESCRIPTORS>
<ADVISER> NIL </ADVISER>
<CLASSIFICATIONS> SENSORY MOTOR COORDINATION </CLASSIFICATIONS>
<ABSTRACT>
This dissertation addresses the use of the neural
network learning approach to achieve particular
behaviours of robots. It focuses on the development of
two chosen behaviours: robot reflexive behaviour, which
illustrates the on-line skill refinement process and
robot cooperative motion behaviour, which illustrates
the learning-from-example case.
Perception is a part of activities in the robot sensory-
motor coordination, where the robot has contact with the
environment. Perception involves not merely the reading
of sensory inputs but also the understanding of the
received patterns. A discussion on robot perception is
presented in advance, where the holistic nature of
perception is taken as the viewpoint. This discussion is
illustrated by the use of a neural network to achieve a
holistic robot touch perception. An experimental result
shows that an LVQ network can be used to classify
contact sensations in a robot gripper in a direct,
featureless fashion--which reflects the nature of
holistic perception.
Robot reflexive behaviour is represented by a visual
tracking behaviour, implemented by an eye-in-hand robot
arm system. This behaviour can be built through a
gradual improvement process based on an immediate
reward. A reinforcement-composition algorithm is
tailored to be used with a dynamic model of the
environment to control the action explorations. The
system configures two back-propagation networks as an
action network and a reward predictor network. A system
capability to predict the target object trajectory can
be built by utilising the property of a time-delay
neural network. This methodology is validated both in
simulated and real robot environments.
Robot cooperative motion behaviour is illustrated by a
control strategy for two cooperative robot arms. The
cooperative motion behaviour is developed through an off-
line learning by using a set of precollected examples. A
fully-position-based neural network mapping between two
arm configurations is presented, which is called gross-
motion mapping. A better representation about the robot
interaction is obtained through the sensed contact force
between the two arms. A control scheme is proposed to
train a neural network to find a relationship between
the contact forces at a certain actual arm position to
the compensating joint displacements needed to reduce
the positioning error based on only gross-motion
mapping. This compensation mapping is called fine-motion
mapping. RBF neural networks show their capability to
learn both gross- and fine-motion mappings, which are
fully non-linear. The effectiveness of this control
scheme is verified in a simulated robot environment.
The presented methodologies and results are aimed at
understanding the state of the art extending the use of
artificial neural networks and learning approach in
general, in building particular robot behaviours.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  3592 </NUMBER>
<ORDER>   AAI9624243 </ORDER>
<TITLE> A METHODOLOGY FOR THE MEASUREMENT AND EVALUATION OF COMPLEX SYSTEM DESIGNS </TITLE>
<AUTHOR> TALBERT, MICHAEL LANE </AUTHOR>
<YEAR> 1995 </YEAR>
<INSTITUTION> VIRGINIA POLYTECHNIC INSTITUTE AND STATE UNIVERSITY; 0247 </INSTITUTION>
<DESCRIPTORS> COMPUTER SCIENCE; ENGINEERING, SYSTEM SCIENCE; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> OSMAN BALCI </ADVISER>
<CLASSIFICATIONS> KNOWLEDGE-BASED, FUZZY LOGIC </CLASSIFICATIONS>
<ABSTRACT>
Most complex systems incorporate hardware, software and
humanware elements operating synergistically under
conflicting functional and nonfunctional objectives.
These systems are usually embedded, mission-critical,
performance-critical, real-time, distributed, highly
integrated, heterogeneous, cost millions of dollars, and
take many years to develop. Examples include space
stations, combat vessels and aircraft, nuclear power
stations, communication networks, and robotics-based
manufacturing.
Early system design evaluation is essential to assess a
design's potential for satisfying operational and
budgetary requirements, since a significant percentage
of the system life cycle cost is committed by design
decisions made early in the system life cycle. However,
at the design decision point, knowledge of technology,
the operational environment, the political climate,
etc., on which to make technically effective and cost
efficient decisions is incomplete. Consequently, early
design evaluation approaches are needed which yield
credible results in the presence of incomplete
knowledge.
This dissertation describes a multifaceted methodology
for complex system design measurement and evaluation
which exploits experience, techniques, and heuristics of
technical and operational domain experts. The
methodology is computer and knowledge based, and
includes indicator-based assessment, visual simulation,
the analytic hierarchy process, and fuzzy mathematics.
The use of this methodology enables qualitative and
quantitative measurement and evaluation of system
designs at any level of detail desired. An independent
assessment of the methodology by researchers and systems
engineering practitioners from the DOD, other federal
government agencies, commercial industry, and academia
affirmed the methodology to be a useful approach in the
measurement and evaluation of complex system designs.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  3593 </NUMBER>
<ORDER>   AAI9623689 </ORDER>
<TITLE> GRADIENT AND HAMILTONIAN DYNAMICS: SOME APPLICATIONS TO NEURAL NETWORK ANALYSIS AND SYSTEM IDENTIFICATION </TITLE>
<AUTHOR> HOWSE, JAMES WALTER, IV </AUTHOR>
<YEAR> 1995 </YEAR>
<INSTITUTION> THE UNIVERSITY OF NEW MEXICO; 0142 </INSTITUTION>
<DESCRIPTORS> ENGINEERING, ELECTRONICS AND ELECTRICAL; PHYSICS, GENERAL; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> GREGORY L. HEILEMAN </ADVISER>
<CLASSIFICATIONS> NIL </CLASSIFICATIONS>
<ABSTRACT>
The work in this dissertation is based on decomposing
system dynamics into the sum of dissipative (e.g.
convergent) and conservative (e.g. periodic) components.
Intuitively, this can be viewed as decomposing the
dynamics into a component normal to some surface and
components tangent to other surfaces. First, this
decomposition was applied to existing neural network
architectures to analyze their dynamic behavior. Second,
this formalism was employed to create models which learn
to emulate the behavior of actual systems. The premise
of this approach is that the process of system
identification can be considered in two stages: model
selection and parameter estimation. In this dissertation
a technique is presented for constructing dynamical
systems with desired qualitative properties. Thus, the
model selection stage consists of choosing the
dissipative and conservative portions appropriately so
that a certain behavior is obtainable. By choosing the
parametrization of the models properly, a learning
algorithm has been devised and proven to always
converges to a set of parameters for which the error
between the output of the actual system and the model
vanishes. So these models and the associated learning
algorithm are guaranteed to solve certain types of
nonlinear identification problems.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  3594 </NUMBER>
<ORDER>   AAI9623363 </ORDER>
<TITLE> PATTERN RECOGNITION AND SENSOR FUSION FOR QUALITY SORTING  </TITLE>
<AUTHOR> OZER, NISSIM </AUTHOR>
<YEAR> 1995 </YEAR>
<INSTITUTION> PURDUE UNIVERSITY; 0183 </INSTITUTION>
<DESCRIPTORS> AGRICULTURE, FOOD SCIENCE AND TECHNOLOGY; ENGINEERING, ELECTRONICS AND ELECTRICAL; ENGINEERING, INDUSTRIAL; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> BERNARD A. ENGEL; JAMES E. SIMON </ADVISER>
<CLASSIFICATIONS> NEURAL NETWORKS, ARTIFICIAL INTELLIGENCE, FRUIT CLASSIFICATION </CLASSIFICATIONS>
<ABSTRACT>
A methodology was developed for automatic sorting of
agricultural produce, using multiple sensors and was
applied to cantaloupes as a case study. The methodology
includes the examination of a multi-sensor fusion
approach with regard to grading criteria, human
classification, single sensors, multiple sensors and
classification methods.
Data acquired from eight sensors: vision, two firmness
sensors, fluorescence, color sensor, electronic sniffer,
refractometer and scale (weight) were analyzed and
provided input for five classification models. The
results indicated that fluorescence response and
firmness measured by an impact sensor were the best
indicators for fruit maturity among the sensors
evaluated.
A procedure was developed to estimate and minimize the
training size for supervised classification. New
criteria were developed to choose a training set such
that a recurrent auto-associative memory neural network
is stabilized. These methods developed for training size
selection and the criteria for choosing training samples
provides a prediction of classification error and
permits rapid training to compensate for fruit variation
from seasonal differences, cultivate differences, and
growing environment conditions.
An expert system was developed to measure variances in
human grading, and procedures for the evaluation of
classification performance were established. This
procedure ensures that the evaluation of performance is
not affected by the variability in human grading.
Mathematical formalization for incorporating multiple
sensors was presented, and parametric and non-parametric
classifiers for grading were examined. It has been shown
that multiple sensors significantly improve
classification accuracy. Statistical methods were found
to be as accurate as neural networks in grading.
Classification models by voting didn't enhance the
classification significantly. A hybrid model that
incorporated heuristic rules and a numerical classifier
was found to be superior in classification accuracy and
with half the processing time used solely by the
numerical classifier.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  3595 </NUMBER>
<ORDER>   AAI9623358 </ORDER>
<TITLE> MULTI-CRITERIA DESIGN AND CONTROL OF MANUFACTURING SYSTEMS USING SIMULATION AND ARTIFICIAL INTELLIGENCE </TITLE>
<AUTHOR> PIPLANI, RAJESH </AUTHOR>
<YEAR> 1995 </YEAR>
<INSTITUTION> PURDUE UNIVERSITY; 0183 </INSTITUTION>
<DESCRIPTORS> ENGINEERING, INDUSTRIAL; ARTIFICIAL INTELLIGENCE; OPERATIONS RESEARCH </DESCRIPTORS>
<ADVISER> JOSEPH J. TALAVAGE </ADVISER>
<CLASSIFICATIONS> NIL </CLASSIFICATIONS>
<ABSTRACT>
The objective of this research was to develop a
prescriptive simulation system for manufacturing: the
current systems have been found to suffer from short-
sightedness (myopia) and are unable to satisfy multiple
performance criteria simultaneously. To ameliorate the
deficiencies of current systems, an autonomous
prescriptive simulation system (APSS) is developed based
on the opportunistic model of problem-solving. The
problem of myopia in prescriptive systems is defined and
a cure proposed--based on knowledge of the structure and
behavior of the problem domain. System interference in
manufacturing is quantified and analyzed, and the
results used in the development of the prescriptive
system. A conflict-resolution algorithm is developed for
multi-criteria design and control of manufacturing
systems--based on goal-regressing planners used in the
field of artificial intelligence.
The system is evaluated against a discrete-valued
stochastic optimization technique and found to perform
satisfactorily. The system outperforms the optimization
technique in all cases where the defining variable set
is large. Finally, it is noted that a two-level
architecture for a prescriptive system based on domain
knowledge and blind-search may provide better results
than one based on domain knowledge alone.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  3596 </NUMBER>
<ORDER>   AAI9623214 </ORDER>
<TITLE> A DISTRIBUTED COOPERATIVE HOMOGENEOUS MULTI-AGENT APPROACH FOR PARALLEL FUZZY EXPERT SYSTEMS IN SURFACE MOUNT PWB ASSEMBLY </TITLE>
<AUTHOR> CHU, HAI-CHENG ERIC </AUTHOR>
<YEAR> 1995 </YEAR>
<INSTITUTION> STATE UNIVERSITY OF NEW YORK AT BINGHAMTON; 0792 </INSTITUTION>
<DESCRIPTORS> ENGINEERING, INDUSTRIAL; COMPUTER SCIENCE; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> K. SRIHARI </ADVISER>
<CLASSIFICATIONS> NIL </CLASSIFICATIONS>
<ABSTRACT>
Artificial Intelligence (AI) has been (and is being)
used in many fields, especially in the manufacturing
arena. Expert systems are a facet of AI which have been
widely applied in different domains from medical
diagnosis to industrial manufacturing. Recently, a new
branch of AI called Distributed Artificial Intelligence
(DAI) has emerged. It preserves the characteristics of
AI while demonstrating its distinct features. The use of
DAI for manufacturing systems applications in the
Printed Wiring Board (PWB) assembly arena is the focus
of this research along with the use of methods to deal
with issues that relate to the uncertainty that is
inherent in manufacturing.
The Distributed Cooperative Homogeneous Multi-agent
(DCHM) based approach uses multiple expert systems
(including fuzzy expert systems) for problem solving in
the surface mount PWB manufacturing domain. This
research combines Computer-Aided Design (CAD), dynamic
Computer-Aided Process Planning (CAPP), Concurrent
Engineering (CE), Design for Manufacturing (DFM),
Relational Data Base Management Systems (RDBMS), Local
Area Networks (LAN), DAI, distributed expert systems,
fuzzy expert systems, distributed processing, and the
management of uncertainties into one problem solving
system. The DCHM system includes an information center,
a stencil printing intelligent agent and a reflow
soldering intelligent agent. Review of the incoming CAD
design from a DFM perspective is done, and a cost
evaluation can also be performed.
Inputs to the DCHM system is primarily in the form of a
CAD file of the PWB's design. Outputs include a review
of the design from manufacturing perspectives as well as
process plans for some PWB assembly process (stencil
printing and reflow soldering). Communication,
cooperation, and negotiation among all the intelligent
agents with respect to the dynamic process planning
function is reflected in the DCHM system. Object-
Oriented Programming (OOP) concepts are widely used in
this research. Personal computers act as intelligent
agents, and the interaction between them occurs through
communication across a LAN.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  3597 </NUMBER>
<ORDER>   AAI9622907 </ORDER>
<TITLE> CLOSED-LOOP HEMODYNAMIC MANAGEMENT BY MEANS OF A RULE- BASED CONTROL SYSTEM USING FUZZY LOGIC </TITLE>
<AUTHOR> HELD, CLAUDIO M. </AUTHOR>
<YEAR> 1995 </YEAR>
<INSTITUTION> RENSSELAER POLYTECHNIC INSTITUTE; 0185 </INSTITUTION>
<DESCRIPTORS> ENGINEERING, BIOMEDICAL; HEALTH SCIENCES, MEDICINE AND SURGERY; ENGINEERING, ELECTRONICS AND ELECTRICAL; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> ROB J. ROY </ADVISER>
<CLASSIFICATIONS> ARTIFICIAL INTELLIGENCE </CLASSIFICATIONS>
<ABSTRACT>
A rule-based system was designed to control the mean
arterial pressure (MAP) and the cardiac output (CO) of a
patient with congestive heart failure (CHF), using the
infusion rates of two drugs: sodium nitroprusside (SNP)
and dopamine (DPM). The controller has three different
modes, that engage according to the hemodynamic state of
the patient. The critical conditions control mode (CCC)
drives the control action if any variable falls outside
of the defined criticality thresholds: an upper and a
lower boundary for the MAP and a lower boundary for the
CO. Inside the boundaries the control is performed by
the non-critical conditions control modes (NCCs). If the
CO is within normal range and the MAP is close to the
goal range, then the MAP is driven using only SNP, in
the NCC single input-single output mode (NCC-SISO).
Otherwise the NCC multiple input-multiple output is
active (NCC-MIMO).
The CCC is a rule-based controller that determines the
initial infusion rates, and continues active if needed.
The response strategy follows different rules if high
MAP, low MAP or low CO is the primary abnormality.
The NCCs are fuzzy logic controllers (FLC). The NCC-MIMO
has 36 rules and the NCC-SISO has 17 rules. For each
rule, each output has one of the defined fuzzy values,
but each input can have a range of fuzzy values. The
goal values for the controlled variables are expressed
as a band of 5 mmHg for the MAP and 5 mL/kg/min for the
CO. The NCC-MIMO includes a gain adaptation algorithm to
cope with the different sensitivities to SNP. The
contributions to the control action of the NCC-MIMO and
NCC-SISO are combined in mode melding.
Supervisory capabilities to ensure adequate drug
delivery complete the controller scheme. The drug input
ranges and allowable increases or drops in the infusion
rates are limited, with different constraints for the
different drugs and control modes. The controller
activates waiting periods to cope with pharmacokinetics
and pharmacodynamics delays. Heuristic features
considered by anesthesiologists are included, like the
observance of waiting periods, and a "forbidden zone"
for DPM infusion to avoid dopaminergic effects.
The control system was able to adequately control the
two hemodynamic variables when tested on a non-linear
model that simulates congestive heart failure in dogs.
Early tests in experiments on dogs showed a tendency to
steady-state oscillations. Further tuning led to an
adequate control, presenting a fast response to setpoint
changes with an acceptable overshoot.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  3598 </NUMBER>
<ORDER>   AAI9622753 </ORDER>
<TITLE> SELF-LEARNING NEURO-FUZZY CONTROL SYSTEM AND ITS APPLICATION ON HTST HEATING IN ASEPTIC PROCESSING </TITLE>
<AUTHOR> OU-YANG, FENG </AUTHOR>
<YEAR> 1995 </YEAR>
<INSTITUTION> PURDUE UNIVERSITY; 0183 </INSTITUTION>
<DESCRIPTORS> ENGINEERING, AGRICULTURAL; ARTIFICIAL INTELLIGENCE; AGRICULTURE, FOOD SCIENCE AND TECHNOLOGY </DESCRIPTORS>
<ADVISER> RAKESH K. SINGH </ADVISER>
<CLASSIFICATIONS> NEURAL NETWORKS, FUZZY SYSTEMS, ARTIFICIAL INTELLIGENCE </CLASSIFICATIONS>
<ABSTRACT>
The purpose of the present study was to develop a self-
learning neuro-fuzzy logic control system (SNFCS) to
provide a model-free-method for designing an intelligent
control system with self-learning ability for food
processing. This system was applied to temperature
control of a high-temperature-short-time (HTST) heat
exchanger in aseptic processing by a computer simulation
and pilot scale experiments. The time/temperature
profile in aseptic processing is critical to the quality
and sterility of aseptically processed foods. Better
temperature control will improve product quality and
reduce waste. The heating process becomes complicated
because of unsteady inlet temperature of raw product,
varying properties, changing flow rate, steam
hysteresis, etc.
The developed SNFCS is a hierarchy based control system
consisting of three levels: primary control, learning,
and supervising level. The primary control level is
designed to directly control the process by applying
several neuro-fuzzy decision systems (NFDS). The
performance of fuzzy system is strongly affected by
fuzzy rules and the membership functions of linguistic
variables derived from experienced operators. Therefore,
in the learning level the process performance
measurement and adapting procedures are to tailor the
knowledge base of control system to fit the new process
given in the beginning, and to adapt to the process
disturbances in-line. The supervisory control is
integrated in the supervising level with functions such
as alarming, fault diagnosis, start-up and shut-down
procedures and higher level information.
The results of the computer simulation and experiments
showed that the developed SNFCS can tailor its control
knowledge to fit new process conditions. SNFCS was more
robust to noises and achieved better control than the
conventional PID controllers. Besides, it was able to
improve the HTST heating of the aseptic processing by
adapting to the disturbances such as variation in raw
product temperature, time-changing parameters in the
process, varying product flow rate, and steam shut-off.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  3599 </NUMBER>
<ORDER>   AAI9622714 </ORDER>
<TITLE> GENERATION OF SYNTHETIC IMAGES FOR TRAINING AUTOMATED VISUAL ASSEMBLY INSPECTION ALGORITHMS </TITLE>
<AUTHOR> KHAWAJA, KHALID WALID </AUTHOR>
<YEAR> 1995 </YEAR>
<INSTITUTION> PURDUE UNIVERSITY; 0183 </INSTITUTION>
<DESCRIPTORS> ENGINEERING, ELECTRONICS AND ELECTRICAL; COMPUTER SCIENCE; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> ANTHONY A. MACIEJEWSKI </ADVISER>
<CLASSIFICATIONS> ARTIFICIAL INTELLIGENCE </CLASSIFICATIONS>
<ABSTRACT>
Visual assembly inspection can provide a low cost,
accurate, and efficient solution to the automated
assembly inspection problem, which is a crucial
component of any automated assembly manufacturing
process. In this work, CAD information is used to
generate synthetic images of an assembly. The synthetic
images are generated to train a new multiscale image
processing algorithm that is used to detect errors in
the assembled product. The CAD information guides the
inspection algorithm through its training stage by
addressing the different types of variations that occur
during manufacturing and assembly and by identifying
areas within the image that can be used for error
detection. In addition, since the performance of such an
inspection system is heavily dependent on the placement
of the camera and light source(s), new algorithms are
presented that use the CAD model of the finished
assembly for placing the camera and light source(s).
Using synthetic images in the training process adds to
the versatility of the technique by removing the need to
manufacture multiple prototypes and suggesting image
parameters that optimize performance. Once trained on
synthetic images, the algorithm can effectively detect
assembly errors by examining real images of the
assembled product.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  3600 </NUMBER>
<ORDER>   AAI9622445 </ORDER>
<TITLE> SPEECH RECOGNITION USING NEURAL NETWORKS </TITLE>
<AUTHOR> TEBELSKIS, JOSEPH MICHAEL </AUTHOR>
<YEAR> 1995 </YEAR>
<INSTITUTION> CARNEGIE-MELLON UNIVERSITY; 0041 </INSTITUTION>
<DESCRIPTORS> COMPUTER SCIENCE; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> ALEX WAIBEL </ADVISER>
<CLASSIFICATIONS> NIL </CLASSIFICATIONS>
<ABSTRACT>
This thesis examines how artificial neural networks can
benefit a large vocabulary, speaker independent,
continuous speech recognition system. Currently, most
speech recognition systems are based on hidden Markov
models (HMMs), a statistical framework that supports
both acoustic and temporal modeling. Despite their state-
of-the-art performance, HMMs make a number of suboptimal
modeling assumptions that limit their potential
effectiveness. Neural networks avoid many of these
assumptions, while they can also learn complex
functions, generalize effectively, tolerate noise, and
support parallelism. While neural networks can readily
be applied to acoustic modeling, it is not yet clear how
they can be used for temporal modeling. Therefore, we
explore a class of systems called NN-HMM hybrids, in
which neural networks perform acoustic modeling, and
HMMs perform temporal modeling. We argue that a NN-HMM
hybrid has several theoretical advantages over a pure
HMM system, including better acoustic modeling accuracy,
better context sensitivity, more natural discrimination,
and a more economical use of parameters. These
advantages are confirmed experimentally by a NN-HMM
hybrid that we developed, based on context-independent
phoneme models, that achieved 90.5% word accuracy on the
Resource Management database, in contrast to only 86.0%
accuracy achieved by a pure HMM under similar
conditions.
In the course of developing this system, we explored two
different ways to use neural networks for acoustic
modeling: prediction and classification. We found that
predictive networks yield poor results because of a lack
of discrimination, but classification networks gave
excellent results. We verified that, in accordance with
theory, the output activations of a classification
network form highly accurate estimates of the posterior
probabilities P(class/input), and we showed how these
can easily be converted to likelihoods P(input/class)
for standard HMM recognition algorithms. Finally, this
thesis reports how we optimized the accuracy of our
system with many natural techniques, such as expanding
the input window size, normalizing the inputs,
increasing the number of hidden units, converting the
network's output activations to log likelihoods,
optimizing the learning rate schedule by automatic
search, backpropagating error from word level outputs,
and using gender dependent networks.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  3601 </NUMBER>
<ORDER>   AAI9622437 </ORDER>
<TITLE> LEARNING SEARCH CONTROL KNOWLEDGE TO IMPROVE PLAN QUALITY </TITLE>
<AUTHOR> PEREZ, MARIA ALICIA </AUTHOR>
<YEAR> 1995 </YEAR>
<INSTITUTION> CARNEGIE-MELLON UNIVERSITY; 0041 </INSTITUTION>
<DESCRIPTORS> COMPUTER SCIENCE; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> JAIME CARBONELL </ADVISER>
<CLASSIFICATIONS> NIL </CLASSIFICATIONS>
<ABSTRACT>
Generating good, production-quality plans is an
essential element in transforming planners from research
tools into real-world applications, but one that has
been frequently overlooked in research on machine
learning for planning. Most work has aimed at improving
the efficiency of planning ("speed-up learning") or at
acquiring or refining the planner's action model. This
thesis focuses on learning search-control knowledge to
improve the quality of the plans produced by the
planner.
Knowledge about plan quality in a domain comes in two
forms: (a) a post-facto quality metric that computes the
quality (e.g. execution cost) of a plan, and (b)
planning-time decision-control knowledge used to guide
the planner towards high-quality plans. The first kind
is not operational until after a plan is produced, but
is exactly the kind typically available, in contrast to
the far more complex operational decision-time
knowledge. Learning operational quality control
knowledge can be seen as translating the domain
knowledge and quality metrics into runtime decision
guidance. The full automation of this mapping based on
planning experience is the ultimate objective of this
thesis.
Given a domain theory, a domain-specific metric of plan
quality, and problems which provide planning experience,
the scQUALITY architecture developed in this thesis
automatically acquires operational control knowledge
that effectively improves the quality of the plans
generated. scQUALITY can (optionally) learn from human
experts who suggest improvements to the plans at the
operator (plan step) level. We have designed two
distinct domain-independent learning mechanisms to
efficiently acquire quality control knowledge. They
differ in the language used to represent the learned
knowledge, namely control rules and control knowledge
trees, and in the kinds of quality metrics for which
they are best suited.
scQUALITY is fully implemented on top of the
scPRODIGY4.0 nonlinear planner. Its empirical evaluation
has shown that the learned knowledge produces near-
optimal plans (reducing before-learning plan execution
costs 8% to 96%). Although the learning mechanisms and
learned knowledge representations have been developed
for scPRODIGY4.0, the framework is general and addresses
a problem that must be confronted by any planner that
treats planning as a constructive decision-making
process.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  3602 </NUMBER>
<ORDER>   AAIC434381 </ORDER>
<TITLE> VERGLEICH VON MULTILAYER PERZEPTRON, KOHONEN MAPS UND HIDDEN MARKOV MODELLEN FUER DIE FEHLERDIAGNOSE IN ELEKTRISCHEN ENERGIEUEBERTRAGUNGSSYSTEMEN; COMPARISONS OF MULTILAYER PERCEPTRON, KOHONEN MAPS AND HIDDEN MARKOV MODELS FOR FAULT DIAGNOSIS IN ELECTRIC POWER SUBSTATIONS </TITLE>
<AUTHOR> BIELER, KASPAR JOHANN </AUTHOR>
<YEAR> 1994 </YEAR>
<INSTITUTION> EIDGENOESSISCHE TECHNISCHE HOCHSCHULE ZUERICH (SWITZERLAND); 0663 </INSTITUTION>
<DESCRIPTORS> ENGINEERING, ELECTRONICS AND ELECTRICAL; ENERGY ZENTRUM, CH-8092 ZURICH,  SWITZERLAND </DESCRIPTORS>
<ADVISER> NIL </ADVISER>
<CLASSIFICATIONS> NIL </CLASSIFICATIONS>
<ABSTRACT>
Electric power systems including their substations are
becoming more complex. On the other hand our society is
demanding an adequate quality of service, i.e., a high
availability of power and energy, which forces a utility
to take highly sophisticated measures to meet these
requirements.
One of these measures is the detection and location of a
fault and its subsequent clearing, as quickly as
possible. It is up to the operator to interpret alarms
and it depends on his expertise and ability to perform
an accurate diagnosis. Based on similar events which
occurred previously, the operator is able to learn and
to as acquire knowledge, i.e., a pure heuristic process.
It is difficult to come up with a purely logical
formulation of the alarm problem. Hence, any workable
approach must include some modelling of the
uncertainties. This thesis presents such methods. It is
shown that in one or the other way this is done by the
use of expert systems, artificial neural networks and
hidden Markov models. They are methods of artificial
intelligence.
In the case of expert systems (ES) the experience and
knowlege of numerous experts and/or cases is embedded in
the knowledge base. Rules can easily be changed or added
if required. It is easy to integrate new knowledge by
implementing new rules. Changes in the topology of a
substation can be treated by adding new facts without
changing the rules.
It is shown that with the Kohonen feature map (KFM), a
type of an artificial neural network (ANN), it is
possible to make a fault or the evolution of a fault
visible. Each new and inconsistent fault is mapped to
the region of the map where the most similarly-trained
fault cases are located. Depending on the position to
which the fault is mapped the explanation of the fault
is certain or uncertain. If the database is large enough
it is easy to create a well-clustered map. But the KFM
needs an input vector with a fixed length and the
implementation of time dependent messages is difficult
to realize. Moreover, changes in the topology are
difficult to handle because new KFM have to be trained
again with a new database.
Furthermore it is shown that with hidden Markov models
(HMM) time-dependent messages can easily be processed.
However it is difficult to find a good topology of a HMM
because the number of the fault messages of a fault name
is variable. The fault case can be a new one or a very
inconsistent one. However changes in the topology of a
substation entail a lot of work because the HMM have to
be trained again with a new set of fault cases.
The numerical results show quite high recognition rates
which seem practical for an implementation in
substations. ANN and HMM must be used where changes in
topology seldom occur, as for example on single lines,
transformers, small substations, etc. They act then as a
filter. The filtered messages can be evaluated center by
an ES.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  3603 </NUMBER>
<ORDER>   AAG9737799 </ORDER>
<TITLE> FEED-FORWARD NEURAL NETWORKS: LEARNING ALGORITHMS, STATISTICAL PROPERTIES, AND APPLICATIONS </TITLE>
<AUTHOR> LIN, YACHEN </AUTHOR>
<YEAR> 1996 </YEAR>
<INSTITUTION> SYRACUSE UNIVERSITY; 0659 </INSTITUTION>
<DESCRIPTORS> STATISTICS; MATHEMATICS; COMPUTER SCIENCE; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> NIL </ADVISER>
<CLASSIFICATIONS> BACKPROPAGATION </CLASSIFICATIONS>
<ABSTRACT>
In this study, we focus on feed-forward neural networks
with a single hidden layer. The research touches upon
several important issues in Artificial Neural Networks
such as the reliability and generalization of trained
networks. The convergence of the learning algorithm in
the computational sense and the strong consistency of
the stable states of networks in the statistical sense
have been addressed as major measures of reliability and
generalization, respectively. Based on the internal
structure of feed-forward neural networks with a single
hidden layer, Two-Stage learning is proposed. To
implement Two-Stage learning, we proposed two new
learning algorithms--Two-Stage(LS) and Two-Stage(Gibbs).
The reliability and generalization of these two learning
algorithms, i.e. the convergence in the computational
sense and the strong consistency in the statistical
sense, are rigorously studied. These optimal properties
of proposed learning algorithms are further confirmed by
intensive empirical studies such as comparisons made on
the Fisher's Iris Data ((1939) The use of multiple
measurements in taxonomic problems, Ann. Eugenics 7, Pt
II, pp. 197-188) between the proposed learning
algorithms and statistical methods (like Bayesian
discriminate analysis, Kernel density methods, and K-
nearest neighbors), comparisons between the proposed
learning algorithms and other existing learning
algorithms like Backpropagation, and simulation studies.
Both theoretical and empirical studies demonstrate the
potential of the proposed algorithms to the real world.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  3604 </NUMBER>
<ORDER>   AAG1383309 </ORDER>
<TITLE> VIRTUAL TOPOLOGY DESIGN OF OPTICAL MULTIHOP NETWORKS VIA HOPFIELD NEURAL NETWORK </TITLE>
<AUTHOR> SI, JIE </AUTHOR>
<YEAR> 1996 </YEAR>
<INSTITUTION> UNIVERSITY OF NEVADA, RENO; 0139 </INSTITUTION>
<DESCRIPTORS> ENGINEERING, ELECTRONICS AND ELECTRICAL; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> BANMALI S. RAWAT </ADVISER>
<CLASSIFICATIONS> NIL </CLASSIFICATIONS>
<ABSTRACT>
In this thesis, a new approach to design the virtual
topology of optical multihop networks has been
developed. The allowed traffic patterns of the optical
networks are fixed unbalanced traffic loads. The
considerations when designing an optical multihop
network, such as wavelength assignment and traffic
routing problem have been investigated. The objective
function of designing virtual topology is the
propagation delay and transmission delay of the optical
multihop traffic. 8-node and 16-node optical multihop
networks have been designed based on different types of
traffic demands.
The Hopfield neural network model has been used in this
thesis as the designing approach. With this method,
optimal solutions of designing optical multihop networks
have been obtained. All the solutions are compared with
the results of previous research work and good agreement
has been observed, thus establishing the validity of the
method developed. Some future directions in this area
have also been addressed.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  3605 </NUMBER>
<ORDER>   AAG1382908 </ORDER>
<TITLE> A SURVEY OF TECHNIQUES IN ROBOTICS PATH MAPPING AND PATH PLANNING </TITLE>
<AUTHOR> JOHNSON, G. CRAIG </AUTHOR>
<YEAR> 1996 </YEAR>
<INSTITUTION> PACIFIC LUTHERAN UNIVERSITY; 6200 </INSTITUTION>
<DESCRIPTORS> COMPUTER SCIENCE; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> RICHARD S. SPILLMAN </ADVISER>
<CLASSIFICATIONS> NIL </CLASSIFICATIONS>
<ABSTRACT>
A person typically defines the goal and parameters for a
robot. Normally, it is the person who selects the task
plan. The concept of a robot generating its own goals
and implementing task planning is still theoretical. The
objective of this thesis is to study the task of path
planning. Various technologies and their application to
the mapping and path planning tasks will be explored.
This thesis will examine an expert system using
production rules, an implementation of the Jarvis and
Byrne algorithm, Prolog, and a classifier system as
possible technologies for the robotic mapping task and
path planning task. This study will also discuss the
strengths and weaknesses of each implementation.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  3606 </NUMBER>
<ORDER>   AAG1382906 </ORDER>
<TITLE> SOLVING THE PLAYFAIR CIPHER USING GENETIC ALGORITHMS </TITLE>
<AUTHOR> KEEFER, OWEN BRADLEY </AUTHOR>
<YEAR> 1996 </YEAR>
<INSTITUTION> PACIFIC LUTHERAN UNIVERSITY; 6200 </INSTITUTION>
<DESCRIPTORS> COMPUTER SCIENCE; INFORMATION SCIENCE; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> RICHARD J. SPILLMAN </ADVISER>
<CLASSIFICATIONS> CRYPTOGRAPHY </CLASSIFICATIONS>
<ABSTRACT>
This paper examines a new cryptanalysis algorithm, based
on the use of Genetic Algorithms. By quickly searching a
space of 25! (15,511,210,043,330,985,984,000,000)
combinations, this algorithm can break the Playfair
Cipher cryptosystem. Throughout the search processes,
the algorithm learns what a good cipher key looks like,
so its accuracy continually improves. One conclusion of
this work is that Genetic Algorithm techniques increase
computational performance and accuracy, decreasing
decryption time and as a result offers a new tool for
cryptanalysis research.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  3607 </NUMBER>
<ORDER>   AAGMM15383 </ORDER>
<TITLE> SYSTEME EXPERT POUR LE TRAITEMENT D'IMAGES </TITLE>
<AUTHOR> MENARD, BRUNO </AUTHOR>
<YEAR> 1996 </YEAR>
<INSTITUTION> ECOLE DE TECHNOLOGIE SUPERIEURE (CANADA); 1246 </INSTITUTION>
<DESCRIPTORS> COMPUTER SCIENCE; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> DANIEL CREVIER </ADVISER>
<CLASSIFICATIONS> FRENCH TEXT, EXPERT SYSTEMS, IMAGES </CLASSIFICATIONS>
<ABSTRACT>
Le systeme expert decrit dans le present rapport est de
type consultatif et a buts multiples. Il permet donc a
l'utilisateur de choisir parmi une gamme elaboree de
buts couvrant les principaux domaines du traitement
d'images. Parmi ceux-ci on retrouve entre autres le
filtrage, la segmentation, le decompte d'objets, la
mesure et la classification. L'utilisateur consulte le
systeme en lui fournissant son but et des informations
supplementaires sur les attributs de l'image a traiter
afin que le systeme puisse fournir une solution
specifique au probleme. Cette solution peut etre
qualifiee de processus heuristique et est basee
principalement sur le raisonnement d'un expert humain
dans la resolution d'un probleme de ce genre.
La base de connaissances a ete construite a partir de
deux methodes: la revue de litterature et les
interviews.
La base de connaissances a ete impantee et testee pour
deux domaines seulement, soient le rehaussement et la
segmentation d'images. Le systeme est constitue d'un
ensemble de mecanismes generaux, tels la requete
d'information, l'activation d'operateurs (de traitement
d'images), l'ajustement de parametres et l'affichage des
resultats. Le systeme expert est donc une forme de
coquille specialisee permettant d'incorporer des
connaissances relatives au traitement d'images dans la
majeure partie des domaines.
Le systeme realise a ce jour est une maquette
fonctionnelle et assez flexible pour incorporer des
connaissances sur de nouveaux domaines du traitement
d'images autres que ceux implantes. (Abstract shortened
by UMI.)
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  3608 </NUMBER>
<ORDER>   AAGMM15370 </ORDER>
<TITLE> APPLICATION OF VECTOR-NETWORK THEORY AND ARTIFICIAL INTELLIGENCE TO DYNAMICS </TITLE>
<AUTHOR> WONG, CLEMENT CHEUK-WAH </AUTHOR>
<YEAR> 1996 </YEAR>
<INSTITUTION> UNIVERSITY OF WATERLOO (CANADA); 1141 </INSTITUTION>
<DESCRIPTORS> ENGINEERING, MECHANICAL; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> G. C. ANDREWS </ADVISER>
<CLASSIFICATIONS> NIL </CLASSIFICATIONS>
<ABSTRACT>
The purpose of this research was to develop an
intelligent algorithm for the formulation and solution
of problems in planar dynamics, given only a simple
description of the system as input. The algorithm is
intended to solve problems involving planar motion, with
or without closed kinematic loops, which require work-
energy methods, impulse-momentum methods or derivation
of equations of motion.
This research objective was addressed by utilizing a
combination of Vector-Network Theory and Blackboard
Architecture. Vector-Network Theory is a "graph-
theoretic" approach to dynamics. It is useful for
derivation of equations of motion and it has been
extended to include work-energy and impulse-momentum
formulations for planar systems of rigid bodies.
Blackboard Architecture is a popular problem-solving
model in Artificial Intelligence. The resulting program
is called The Dynamics Blackboard System (DBS) and it
links to Maple for symbolic formulations and
calculations.
The DBS graphical user interface (GUI) allows users to
describe a system in a convenient "point-and-click"
manner. The GUI then converts the user's description of
a system into the corresponding vector-network model.
After performing the vector-network symbolic
formulation, the DBS blackboard algorithm parses the
unknown variables specified by the user and organizes a
set of equations suitable for the solution.
The capability of DBS in dynamics problem solving is
demonstrated in this thesis by solving several examples
which cover a wide range of dynamics problems. The
achievements made in this research show that the Vector-
Network Theory is a sound basis for AI applications and
that the Blackboard Architecture, as implemented in DBS,
shows great potential for further possibly commercial
development.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  3609 </NUMBER>
<ORDER>   AAGMM15125 </ORDER>
<TITLE> LEARNING IN SMALL NEURAL NETWORKS </TITLE>
<AUTHOR> CORDEAU, JOHN LEO </AUTHOR>
<YEAR> 1996 </YEAR>
<INSTITUTION> QUEEN'S UNIVERSITY AT KINGSTON (CANADA); 0283 </INSTITUTION>
<DESCRIPTORS> ENGINEERING, ELECTRONICS AND ELECTRICAL; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> M. M. BAYOUMI </ADVISER>
<CLASSIFICATIONS> NIL </CLASSIFICATIONS>
<ABSTRACT>
A fundamental issue with feedforward neural networks is
network learning. In this thesis, we investigate the
learning behaviour of small feedforward networks. This
study of learning is carried out in three phases. First,
the surface of the cost function on a small network,
employed in the identification of example problems, is
critically studied. Secondly, we compare four existing
nonlinear optimization techniques, in order to adjust
network weights. These four techniques are compared on
the basis of stability, convergence time, and
reliability in the absence of well estimated initial
weight vector. Next, a model growing technique, that
employs the small networks, mentioned above, is used.
This technique may reduce the difference between the
actual and the desired output of the network structure,
at each successive stage. In addition, this method
enables escape from unsuitable local minima.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  3610 </NUMBER>
<ORDER>   AAGMM14951 </ORDER>
<TITLE> COOPERATIVE UNSUPERVISED LEARNING </TITLE>
<AUTHOR> WANG, HANDONG </AUTHOR>
<YEAR> 1996 </YEAR>
<INSTITUTION> THE UNIVERSITY OF WESTERN ONTARIO (CANADA); 0784 </INSTITUTION>
<DESCRIPTORS> COMPUTER SCIENCE; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> CHARLES Z. LING </ADVISER>
<CLASSIFICATIONS> MACHINE LEARNING, ARTIFICIAL INTELLIGENCE, CLASS LABELS, ATTRIBUTES </CLASSIFICATIONS>
<ABSTRACT>
In the supervised learning paradigm, each training
example is described by a set of attributes and a class
label. However, in many learning and knowledge discovery
situations, class labels are not available; instead,
they are replaced by another set of attributes. We call
this type of learning cooperative unsupervised learning.
The task of cooperative unsupervised learning is to
(re)construct and discover class labels consistent with
multiple sources of attributes. We design an algorithm,
called A scUTOL scABEL, that learns class labels from
unlabeled training examples described by two sets of
attributes. Our method first uses an attribute relevancy
criterion to partition training examples into uni-class
clusters. It then produces more succinct labeling
consistent with the two attribute sets.
We test A scUTOL scABEL on several artificial and real-
world datasets, and show that it constructs
classification labels accurately. Our learning paradigm
removes the fundamental assumption of providing class
labels in supervised learning, and gives a new
perspective to unsupervised learning.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  3611 </NUMBER>
<ORDER>   AAGMM14606 </ORDER>
<TITLE> HEURISTIC SEARCH TECHNIQUES FOR PROPOSITIONAL RESOLUTION PROOF SYSTEMS  </TITLE>
<AUTHOR> TREMAINE, DAVID </AUTHOR>
<YEAR> 1996 </YEAR>
<INSTITUTION> YORK UNIVERSITY (CANADA); 0267 </INSTITUTION>
<DESCRIPTORS> COMPUTER SCIENCE; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> Z. STACHNIAK </ADVISER>
<CLASSIFICATIONS> THEOREM PROVING, STACHNIAK, ARTIFICIAL INTELLIGENCE </CLASSIFICATIONS>
<ABSTRACT>
While automated theorem proving has been an area of
general interest to computer scientists since A.
Robinson proposed the resolution rule in 1965, it has
only been during the last two decades that serious
consideration has been given to automated theorem
proving systems for non-classical logics. Of the systems
that have emerged during this period, Stachniak's theory
of resolution proof systems, based on a non-clausal
resolution rule, is one of the most flexible and
universally applicable. And while much work has been
done by Stachniak and others, such as E.R. Harley (5)
and P. W. O'Hearn (19), to develop the theory so that it
can provide "minimal" proof systems for specific logics,
little consideration has been given to the issues
surrounding the implementation of resolution proof
systems such as methods for controlling the search space
during the refutational process. In this thesis, I will
discuss a refutationally complete search procedure and a
group of search strategies that are necessary in
producing an effective search for a refutation in a
resolution proof system. The strategies that will be
discussed will include existing ones such as polarity
and set-of-support, as well as newly developed
techniques for detecting and removing subsumed formulas
and for blocking tautologies. Also included will be the
results of empirical studies contrasting and comparing
the effectiveness of the different strategies with each
other and the effectiveness of the theorem prover as a
whole with other propositional theorem provers.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  3612 </NUMBER>
<ORDER>   AAGMM14561 </ORDER>
<TITLE> A STRATIFIED APPROACH FOR DEVELOPING SOLVENT KNOWLEDGE- BASED SYSTEMS FOR ACID GAS TREATING PROCESSES </TITLE>
<AUTHOR> GAO, WEN </AUTHOR>
<YEAR> 1996 </YEAR>
<INSTITUTION> THE UNIVERSITY OF REGINA (CANADA); 0148 </INSTITUTION>
<DESCRIPTORS> ENGINEERING, CHEMICAL; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> P. TONTIWACHWUTHIKUL; C. W. CHAN </ADVISER>
<CLASSIFICATIONS> CARBON DIOXIDE, HYDROGEN SULFIDE </CLASSIFICATIONS>
<ABSTRACT>
Realizing the limitation of previous work's attempts, a
solvent knowledge-based system for acid gas treating
process (SOLKB) has been developed by taking a
stratified approach, i.e. the SOLKB is constructed upon
three interdependent levels: knowledge level, algorithm
level, and program level.
At the knowledge level, first the solvent selection task
is decomposed into three subtasks of $solvent selection
for removal of COsb2, solving selection for simultaneous
removal of COsb2$-$Hsb2S, 0rm and solvent selection for
selective removal of Hsb2S/COsb2$. Then a method called
constraint satisfaction is proposed to analyze the
solvent selection process and formulize the solvent
selection knowledge in terms of constraints,
suitabilities and suitability functions.
At the algorithm level, the computational architecture
of SOLKB has been designed based on deliberative
architecture proposed in AI research. The architecture
consists of two major components: a Solvent Infobase and
a solvent Selecting Engine.
At the program level, based on the architecture designed
in the algorithm level, a prototype of SOLKB has been
built. (Abstract shortened by UMI.)
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  3613 </NUMBER>
<ORDER>   AAGMM14547 </ORDER>
<TITLE> AGGREGATE SCHEDULING OF MACHINING AND ASSEMBLY SUBSYSTEMS IN A FLEXIBLE MANUFACTURING ENVIRONMENT </TITLE>
<AUTHOR> ZHU, JINGYU </AUTHOR>
<YEAR> 1996 </YEAR>
<INSTITUTION> THE UNIVERSITY OF REGINA (CANADA); 0148 </INSTITUTION>
<DESCRIPTORS> ENGINEERING, INDUSTRIAL; ENGINEERING, SYSTEM SCIENCE </DESCRIPTORS>
<ADVISER> W. COOKE </ADVISER>
<CLASSIFICATIONS> NIL </CLASSIFICATIONS>
<ABSTRACT>
Job shop scheduling deals with the allocation of
resources over time to manufacturing tasks. Although job
shop scheduling problems are difficult in most general
cases, searches for efficient optimal solutions to
scheduling problems have been successful for some
special subproblems. Such solutions are preferred to
heuristic techniques and approximation algorithms.
This thesis is concerned with the subproblem of
aggregate scheduling of a flexible manufacturing system
which consists of machining and assembly subsystems
where the complexity of an exhaustive search is
exponential. An efficient algorithm in aggregate
scheduling was proposed where the flexible manufacturing
system consists of one machining and one assembly
subsystems. This thesis extends that method to the case
of two machining and one assembly subsystems. An
efficient optimal algorithm to handle the aggregate
scheduling under such conditions is derived.
The thesis also studies the problem of scheduling some
traffic flow over a tree network. Three patterns of
traffic flow (called collection, distribution, and
communication) were originally abstracted from an
information exchange problem in artificial intelligence.
The thesis shows that one of them can be applied to
scheduling in flexible manufacturing systems. The system
consists of multiple machining and assembly subsystems
organized according to the natural precedence of parts
and subassemblies of a product to be manufactured using
the system. A tree network may be rearranged such that
any node becomes the root and the problem of finding the
optimal scheduling root for the tree network is also
addressed. Several sufficient conditions are derived to
reduce the search space for finding the optimal root.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  3614 </NUMBER>
<ORDER>   AAGNN19356 </ORDER>
<TITLE> NEUROMORPHIC DISTRIBUTED GENERAL PROBLEM SOLVERS </TITLE>
<AUTHOR> BIESZCZAD, ANDRZEJ </AUTHOR>
<YEAR> 1996 </YEAR>
<INSTITUTION> CARLETON UNIVERSITY (CANADA); 0040 </INSTITUTION>
<DESCRIPTORS> COMPUTER SCIENCE; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> BERNARD PAGUREK </ADVISER>
<CLASSIFICATIONS> ARTIFICIAL INTELLIGENCE </CLASSIFICATIONS>
<ABSTRACT>
At this moment of time, it is justifiable to say that
the great promise of symbolic Artificial Intelligence,
including problem solving and planning systems, have not
satisfactorily materialized. There are some areas, for
example Expert Systems, that have made it through to the
mainstream technology. Most beautiful dreams are still
unfulfilled. That disillusionment to some extent drives
and justifies the research reported in this thesis and
similar efforts on applying ideas that do not have their
roots in formal logic.
I propose a new approach to problem solving that employs
neuromorphic methods for agents that attack a problem in
a distributed and cooperative manner.
I attempt to apply these agents to the task of
rearranging three different blocks in a variant of a
blocks world. Blocks worlds are popular in the
Artificial Intelligence community as testbeds for
problem solving systems. It is a consequence of their
relative simplicity, but, nonetheless, sufficient
complexity to present ideas and verify problem solving
concepts and techniques. Three types of agents are used:
sensing, manipulating and solving. The sensing agents
collect the state of the blocks world and communicate it
to the solving agent. The solving agent employs a
biologically inspired device that I call the
Neurosolver. The agent uses its Neurosolver-based brain
to record the detected trajectories in the state space
of the blocks world. When given a rearrangement task, it
uses the learned traces to perform searches and
construct plans to control the movements of the blocks.
The resolution plan is distributed amongst the
population of manipulating agents that actually
rearrange the blocks. All of the agents are mobile and
communicate while visiting the same blocks world
location.
An extended system that I call the Neuromorphic General
Problem Solver (NGPS) may employ multiple neurosolvers.
The knowledge may be distributed between the solvers in
a number of ways, yet they are able to solve the posed
problems cooperatively.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  3615 </NUMBER>
<ORDER>   AAGMM14496 </ORDER>
<TITLE> KNOW: A MODEL FOR OPEN HELP SYSTEMS </TITLE>
<AUTHOR> ZHANG, LARRY LIWEI </AUTHOR>
<YEAR> 1996 </YEAR>
<INSTITUTION> UNIVERSITY OF GUELPH (CANADA); 0081 </INSTITUTION>
<DESCRIPTORS> COMPUTER SCIENCE; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> TOM T. CAREY </ADVISER>
<CLASSIFICATIONS> NIL </CLASSIFICATIONS>
<ABSTRACT>
This research investigates on-line help systems whose
content can be dynamically updated as they are being
used. A model for such systems, named KNOW, is proposed
here. The KNOW design allows natural linguistic
interaction with users, and the simultaneous use of
knowledge engines written in different formalisms. Two
simplified prototypes, one being text-based and the
other using graphics and animation, were built and then
evaluated in a formative study. The evaluation results
indicted that KNOW is an effective and practical model,
and also suggested directions for future studies.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  3616 </NUMBER>
<ORDER>   AAGMM14492 </ORDER>
<TITLE> DATA FUSION APPROACH TO DISCRIMINATION OF FOREST COVER USING SAR IMAGE </TITLE>
<AUTHOR> WU, DENGRU </AUTHOR>
<YEAR> 1996 </YEAR>
<INSTITUTION> UNIVERSITY OF GUELPH (CANADA); 0081 </INSTITUTION>
<DESCRIPTORS> COMPUTER SCIENCE; ARTIFICIAL INTELLIGENCE; REMOTE SENSING </DESCRIPTORS>
<ADVISER> JAMES LINDERS </ADVISER>
<CLASSIFICATIONS> NIL </CLASSIFICATIONS>
<ABSTRACT>
Data fusion involves three techniques, namely, data
mining, data identification, and data classification.
The problem for data mining to solve is to extract the
information content from images. In this thesis, new
texture measures, namely structure features, are
introduced. The window types for the extraction of
structure features are discussed. A comparison of
accuracies was made between structure features and
conventional coocurrence features. Data identification
refers to how best to evaluate the quality of data mined
from different sensors and using different mining
methods. This thesis proposes three methods for finding
the "qualified or realible" features for the classifier.
A comparison of performance was made of the three
identification methods as well as a comparison with the
approach which inputs whole the available features
directly to the classifiers. Data classification entails
designing a classifier to find the boundaries which
separate the data classes. In this thesis, two new
classifiers are proposed, namely, fuzzy weighted
classifier and fuzzy weighted classifier with genetic
algorithms. Two other kinds of classifiers, statistical
classifier (stepwise discriminant analysis) and a neural
network (Kohonen's learning vector quantization (LKVQ)),
are also used in order to make a comparison of their
performance.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  3617 </NUMBER>
<ORDER>   AAGMM14428 </ORDER>
<TITLE> IDENTIFYING AND COMPARING DEPENDENCY RELATIONSHIPS IN FEEDFORWARD NEURAL NETWORKS </TITLE>
<AUTHOR> LEUNG, YUEN WAI (MIKE) </AUTHOR>
<YEAR> 1996 </YEAR>
<INSTITUTION> UNIVERSITY OF GUELPH (CANADA); 0081 </INSTITUTION>
<DESCRIPTORS> COMPUTER SCIENCE; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> DAVID K. Y. CHIU </ADVISER>
<CLASSIFICATIONS> NIL </CLASSIFICATIONS>
<ABSTRACT>
This thesis presents an approach to analyze dependency
in different kinds of connected feedforward neural
networks as a knowledge discovery and modeling tool. The
dependency measure is based on the summation of the
weighted paths between specified sequential nodes. From
the measure of dependency, we can identify the relevance
or redundancy of the nodes involved. The method can be
used to reduce the number of input nodes (a feature
selection problem) and hidden nodes (a network pruning
problem). A statistical test is presented to provide and
evaluation for comparison of the dependency structure
between the original and the new network with node(s)
deleted. The measure also provides useful information in
the reconfiguration of the network architecture for
better reliability and generalizability. The method is
illustrated by (1) applying to two-dimensional shape
classification problem using artificial and
electromagnetic images, (2) modeling of parity-three
function and sonar data, and (3) applying to equation-
based data and rule-based data. The experiments show
very successful results.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  3618 </NUMBER>
<ORDER>   AAGMM14391 </ORDER>
<TITLE> PERSONALITY AS AN ACCEPTABILITY FACTOR FOR AUTONOMOUS AGENTS  </TITLE>
<AUTHOR> DYACK, DENIS PETER </AUTHOR>
<YEAR> 1996 </YEAR>
<INSTITUTION> UNIVERSITY OF GUELPH (CANADA); 0081 </INSTITUTION>
<DESCRIPTORS> COMPUTER SCIENCE; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> TOM CAREY; JOHN MITTERER </ADVISER>
<CLASSIFICATIONS> COMPUTER GAME </CLASSIFICATIONS>
<ABSTRACT>
The main goal of this research was to investigate how
the use of the agency metaphor might help users of
interactive computer systems to learn more effectively.
To do this a framework was developed for the dimensions
affecting how effective an agent may be. Within this
framework a software agent was created to identify
strengths and weaknesses of the framework. The agent
provided advice to the users of a computer game.
A pilot study was conducted to further test the proposed
framework. Different versions of the agent were
developed in order to sort out which traits are
important in improving the user's response to
interfaces. The relative effectiveness of these versions
of the agent was determined by collecting measures of
both the speed with which the game was learned and the
users' satisfaction with the agent. This pilot study
yielded results that do support the proposed framework.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  3619 </NUMBER>
<ORDER>   AAGMM14374 </ORDER>
<TITLE> EXTRACTING KNOWLEDGE FROM CONCEPT-BASED SEARCHING SYSTEMS USING CONCEPTUAL GRAPHS </TITLE>
<AUTHOR> CHEN, HSIU-HONG </AUTHOR>
<YEAR> 1996 </YEAR>
<INSTITUTION> UNIVERSITY OF GUELPH (CANADA); 0081 </INSTITUTION>
<DESCRIPTORS> COMPUTER SCIENCE; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> JAMES LINDERS </ADVISER>
<CLASSIFICATIONS> NIL </CLASSIFICATIONS>
<ABSTRACT>
The formalism of conceptual graphs, introduced by John
Sowa (Sowa 84), is a powerful, flexible, and consistent
knowledge representation language with a well-defined
theoretical basis. This formalism can capture semantics
in the representation of data, thus it can be closely
mapped to natural language. It offers some useful
constructs which makes it a likely platform for a
knowledge-based system.
This thesis conceptual graphs as semantics and knowledge
processing for a concept-based searching system. It
addresses the growing potential of using a concept-based
searching system as the basis of an architecture for
effectively extracting knowledge from the large
database. A concept-based searching system which
addresses two areas, natural language processing and
graph matching, is presented in the thesis. It indicates
that when a natural language processor accurately
converts user queries to concepts and the graph matcher
accurately relates like-concepts, the natural language
processing and matching operations form a homomorphism
with human relevance judgments (that is, the retrieved
documents should be all and only those texts relevant to
the original query).
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  3620 </NUMBER>
<ORDER>   AAGMM14290 </ORDER>
<TITLE> DEVELOPPEMENT D'UN SYSTEME INFORMATISE D'AIDE A LA DECISION POUR LE CONTROLE DE LA CERCOSPOROSE DE LA CAROTTE </TITLE>
<AUTHOR> RIBLAIR, ERIC </AUTHOR>
<YEAR> 1996 </YEAR>
<INSTITUTION> UNIVERSITE LAVAL (CANADA); 0726 </INSTITUTION>
<DESCRIPTORS> ENGINEERING, AGRICULTURAL; AGRICULTURE, PLANT PATHOLOGY; AGRICULTURE, AGRONOMY; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> LAURENT GAUTHIER </ADVISER>
<CLASSIFICATIONS> FRENCH TEXT, CARROT, DAUCUS CAROTA, CERCOSPORA, DECISION SUPPORT </CLASSIFICATIONS>
<ABSTRACT>
La carotte est affectee par la cercosporose qui
occasionne des pertes a la recolte de 20 a 30%. L'etude
de l'evolution et du controle de la maladie demande le
traitement de donnees meteorologiques et biologiques et
l'intervention d'une expertise humaine. Pour faciliter
la prise de decision et l'homogeneite des
recommandations on peut recourir a un Systeme
Informatise d'Aide a la Decision (SIAD). Les objectifs
du projet etaient de (1) definir un cadre conceptuel
pour un module de protection de la carotte sous la plate-
forme logiciel SAGE, (2) integrer un modele previsionnel
de la cercosporose, (3) colliger et structurer les
donnees necessaires a la construction et au deploiement
de ce module, (4) integrer la saisie des donnees et la
presentation des recommandations et (5) valider le
module. Le produit final integre donc un modele de
developpement de la maladie et l'expertise d'un expert
traduite sous forme de regles. L'architecture et les
interfaces entre les composantes furent developpes sous
l'environnement de programmation Smalltalk. Cet
environnement supporte plusieurs modeles de
representation des connaissances et a facilite
l'integration des elements et des concepts necessaires a
la realisation du SIAD.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  3621 </NUMBER>
<ORDER>   AAGMM14218 </ORDER>
<TITLE> MODELISATION DU COMPORTEMENT EN CISAILLEMENT DES DISCONTINUITES ROCHEUSES A L'AIDE DES RESEAUX NEURONAUX </TITLE>
<AUTHOR> LESSARD, JEAN-SEBASTIEN </AUTHOR>
<YEAR> 1996 </YEAR>
<INSTITUTION> UNIVERSITE LAVAL (CANADA); 0726 </INSTITUTION>
<DESCRIPTORS> ENGINEERING, MINING; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> JOHN HADJIGEORGIOU </ADVISER>
<CLASSIFICATIONS> FRENCH TEXT, NEURAL NETWORKS, SHEARING </CLASSIFICATIONS>
<ABSTRACT>
Les reseaux neuronaux constituent une technique
d'intelligence artificielle qui imite la structure et le
fonctionnement du cerveau. Un reseau de neurones est
forme de plusieurs elements processeurs simples,
densement interconnectes et calculant en parallele. Les
reseaux neuroneux ont ete utilises pour le developpement
de modeles constitutifs de comportement en cisaillement
des discontinuites rocheuses. La base de donnees requise
pour le developpement des differents modeles a base
reseaux neuronaux a ete creee a partir d'une serie
d'essais en laboratoire. Des modeles constitutifs de
friction de base ont ete developpes pour des
discontinuites sciees. Un autre modele a ete developpe
pour le comportement en cisaillement des discontinuites
rugueuses. Parallelement a ceci, un reseau de neurones a
ete developpe pour determiner la rugosite des
discontinuites rugueuses par le biais de leur JRC.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  3622 </NUMBER>
<ORDER>   AAGMM14035 </ORDER>
<TITLE> LA SCIENCE COGNITIVE ET LE MODELE COMPUTATIONNEL DE L'ESPRIT LE ROLE DE L'INTELLIGENCE ARTIFICIELLE DANS L'ETUDE DE LA COGNITION </TITLE>
<AUTHOR> ARSENAULT, STEPHANIE </AUTHOR>
<YEAR> 1996 </YEAR>
<INSTITUTION> UNIVERSITE LAVAL (CANADA); 0726 </INSTITUTION>
<DESCRIPTORS> PHILOSOPHY; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> THOMAS DE KOMINCK </ADVISER>
<CLASSIFICATIONS> NIL </CLASSIFICATIONS>
<ABSTRACT>
Suite a l'echec du behaviorisme, une nouvelle forme
d'explication des etats mentaux qui pouvait tenir compte
du caractere subjectif de l'experience phenomenale
devenait necessaire. Les progres en mathematique et en
logique symbolique ont permis, en grande partie grace
aux travaux du britannique Alan Turing vers la fin des
annees 30, de developper un modele du cerveau auquel
participe ce que l'on nomme l'"intelligence
artificielle". Une pleiade de sciences se sont alors
regroupees autour de cette nouvelle discipline pour
former la "science cognitive". De cette union est nee la
theorie computationnelle de l'esprit ou "cognitivisme".
D'apres cette theorie, ie cerveau serait un ordinateur
digital qui traite de l'information, et l'esprit ne
serait qu'un programme informatique. Dans cette
perspective, la relation corps-esprit correspond a
l'approche "fonctionnaliste" et fait abstraction de la
nature du cerveau et de sa neurophysiologie. Tout comme
des ordinateurs aux architectures differentes arrivent a
produire les memes resultats, on suppose que deux
systemes ayant des etats fonctionnels isomorphes se
trouvent necessairement dans des etats cognitifs
identiques. Ainsi, le cerveau et l'ordinateur seraient
deux systemes physiques de calculs sur des
representations symboliques. Cependant, l'ordinateur
digital et l'intelligence artificielle ne fournissent
qu'un modele qu'il ne faut pas confondre avec la realite
de notre specificite. Ni la conscience ni
l'intentionnalite ne peuvent etre expliquees par une
simple metaphore et, en ce sens, le cerveau n'a rien
d'un ordinateur digital.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  3623 </NUMBER>
<ORDER>   AAG9716724 </ORDER>
<TITLE> APPLICATIONS OF EXPERT SYSTEMS, MACHINE LEARNING AND NEURAL NETWORKS IN COMPUTER NETWORKS DESIGN </TITLE>
<AUTHOR> FAHMY, HANY I. </AUTHOR>
<YEAR> 1996 </YEAR>
<INSTITUTION> UNIVERSITY OF MIAMI; 0125 </INSTITUTION>
<DESCRIPTORS> COMPUTER SCIENCE; ENGINEERING, ELECTRONICS AND ELECTRICAL; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> CHRISTOS DOULIGERIS </ADVISER>
<CLASSIFICATIONS> ARTIFICIAL INTELLIGENCE </CLASSIFICATIONS>
<ABSTRACT>
In this thesis we present "END", Expert Network
Designer, an automated system for large structured
computer networks design, modeling, simulation and
performance evaluation.
END employs formalized network design experience to
recommend the feasible network designs suitable for the
particular user's network environment, and explain why
such solutions have been chosen. END further ranks and
evaluates such solutions using artificial intelligence
optimization techniques and engineering simulation
tools.
END has been equipped with a neural network learning
utility to improve the time-efficiency of its network
design problem solver, and a machine learning utility to
enable the system to learn about new emerging
technologies, their optimal design techniques, and the
evolution of the specifications of the existing
technologies.
Also in this thesis a fuzzy expert system approach is
proposed as a replacement for the classical expert
system to alleviate some restrictions with the classical
hard-decisions expert system approach. Finally some
ideas of applying hybrid fuzzy expert systems are
discussed.
By employing such integrated subsystems, we are able to
obtain (1) network design solutions suitable for the
user's network environment, (2) reasoning analysis of
why these specific solutions have been chosen, (3)
performance evaluation for the different design options,
and (4) analytical ranking of the proposed solutions.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  3624 </NUMBER>
<ORDER>   AAG9716309 </ORDER>
<TITLE> ACOUSTIC EMISSION POTENTIAL FOR MONITORING CUTTING AND BREAKAGE CHARACTERISTICS OF COAL </TITLE>
<AUTHOR> SHEN, HOU-LUN WARREN </AUTHOR>
<YEAR> 1996 </YEAR>
<INSTITUTION> THE PENNSYLVANIA STATE UNIVERSITY; 0176 </INSTITUTION>
<DESCRIPTORS> ENGINEERING, MINING; ENGINEERING, MECHANICAL; HEALTH SCIENCES, OCCUPATIONAL HEALTH AND THERAPY </DESCRIPTORS>
<ADVISER> H. REGINALD HARDY JR. </ADVISER>
<CLASSIFICATIONS> DUST, PNEUMONOCONIOSIS, SILICOSIS, BLACK LUNG </CLASSIFICATIONS>
<ABSTRACT>
In the mining industry, the use of continuous mining,
longwall mining, and shortwall mining has been growing
in relation to conventional mining. The former methods
utilize high speed rotating bits to remove the coal from
the working face, and this generates a wide range of
fragment sizes. Fine dust from underground mining
operation has been blamed for several lung diseases such
as Coal Workers' Pneumoconiosis (CWP) and Silicosis. In
general, it is believed that the amount of fine coal
dust generated during coal cutting is related to the
cutting parameters, the bit condition, and the
mechanical properties of the coal.
The purpose of this research was to investigate the
character of the bit-coal interaction during coal
cutting and its influence on the size and shape
distributions of the generated dust, with the long term
aim of improving dust control. It is appreciated that
coal cutting mechanics are very complicated, and
developing a mathematical or numerical model may be
difficult, and impracticable for application to real
mining situations. An innovative approach to investigate
coal cutting and dust generation, namely; acoustic
emission (AE) monitoring coupled with pattern
recognition is evaluated for this purpose.
Two groups of coal cutting experiments, linear cutting
and rotary cutting, have been carried out in the Rock
Mechanics Laboratories at Penn State University and West
Virginia University, respectively. Detailed particle
size and shape distribution analyses were carried out on
the cut material. A commercially available artificial
intelligence package, ICEPAK (Intelligent Classifier
Engineering Package) developed by Tektrend International
Inc. has been utilized to provide a powerful and
objective means for AE wave form analysis. AE signals
associated with different coal cutting conditions were
studied using the ICEPAK program.
The studies have provided new insights into the coal-
cutting process, and have further promoted the
feasibility of utilizing AE techniques for remote
monitoring of coal cutting and dust generation.
Additional research is required before the results of
this research can be utilized in routine underground
applications and recommendations for this research are
included.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  3625 </NUMBER>
<ORDER>   AAGNN18653 </ORDER>
<TITLE> COMPUTATIONAL COMPLEXITY APPLICATIONS IN MACHINE LEARNING </TITLE>
<AUTHOR> TAMON, CHRISTINO THEODORE </AUTHOR>
<YEAR> 1996 </YEAR>
<INSTITUTION> UNIVERSITY OF CALGARY (CANADA); 0026 </INSTITUTION>
<DESCRIPTORS> COMPUTER SCIENCE; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> NADER H. BSHOUTY </ADVISER>
<CLASSIFICATIONS> LEARNABILITY, ARTIFICIAL INTELLIGENCE </CLASSIFICATIONS>
<ABSTRACT>
This thesis presents some theoretical investigations on
the learnability of Boolean functions using techniques
from computational complexity theory. Some of the main
findings are as follows. (1) Monotone Boolean functions
are learnable in the probably approximately correct
(PAC) model in subexponential time under product
distributions. (2) Booleans functions computable by some
classes of branching programs of width less than five
are efficiently learnable in the exact identification
model using equivalence and membership queries. (3)
Boolean functions computable by polynomial size circuits
and by polynomial size formulas in normal forms are
efficiently learnable in the exact identification model
using equivalence queries by a probabilistic oracle
Turing machine that has access to an $0cal NP$ oracle.
The first result is obtained through a new analysis of
the harmonic spectra of monotone Boolean functions. The
second result is in contract to the cryptographically
impossible task of learning width five branching
programs and is obtained through a combination of
techniques from harmonic analysis and automata theory.
An implication of the third result is that if Boolean
formulas in normal forms are not efficiently exactly
learnable from equivalence queries then $0cal Pnot= 0cal
NP$.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  3626 </NUMBER>
<ORDER>   AAG9716286 </ORDER>
<TITLE> A HIERARCHICAL STRUCTURE OF INTERACTING AUTOMATA FOR MODELING BATTLEFIELD DYNAMICS: CONTROLLABILITY AND FORMAL SPECIFICATION </TITLE>
<AUTHOR> PELUSO, EILEEN MARIAN MECONE </AUTHOR>
<YEAR> 1996 </YEAR>
<INSTITUTION> THE PENNSYLVANIA STATE UNIVERSITY; 0176 </INSTITUTION>
<DESCRIPTORS> COMPUTER SCIENCE; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> JONATHAN GOLDSTINE; SHASHI PHOHA </ADVISER>
<CLASSIFICATIONS> RAMADGE, WONHAM, DEDS, INTELLIGENT ASSISTANT, MISSION PLANNING, ARTIFICIAL INTELLIGENCE </CLASSIFICATIONS>
<ABSTRACT>
This dissertation extends the Ramadge and Wonham model
of interacting automata for the control of Discrete
Event Dynamic Systems (DEDS) to model the hierarchical
structure of large, complex systems. This research stems
from efforts to create an Intelligent Assistant for the
formulation and evaluation of dynamic, multi-layered
battleplans. The distinctive features of the extended
model are (1) its support of aggregation of information
at every level within the hierarchy, (2) its restriction
of information flow to contiguous hierarchical levels,
(3) its support of non-atomic high-level event
structures, and (4) its feedback mechanism,
appropriately permissive for battlefield dynamics.
We define formally the control imposed by the
hierarchical structure. The effects of aggregation
within this hierarchical framework on controllability
are presented in the notions of 2-level controllability
and markability which are necessary and sufficient
conditions for the existence of a hierarchically
structured supervisor as modeled within this framework.
The hierarchical structure of supervisors can result in
an exponential reduction in supervisory state space
size.
The set of 2-level controllable languages is not closed
under intersection or union. The intersection of 2-level
controllable languages is 2-level controllable if these
languages meet a nonconflicting requirement, as is the
case in the nonhierarchical framework. For any given
language that is not 2-level controllable, but for which
a subset exists that is 2-level controllable, the
existence of a unique supremal 2-level controllable
sublanguage is not guaranteed.
To facilitate the development of intuitive interfaces,
usable by non-computer professionals, we formulate a
class of language-based supervisor specifications, based
on top-down hierarchical design techniques, including
the specification of desired concurrency between
distributed system components. We define realizability
as a set of conditions on a given specification.
Realizability is a sufficient condition for the
existence of a hierarchy of supervisors exerting the
specified control and incorporating the desired
aggregation. We give an algorithm for the construction
of the appropriate hierarchy of automata, allowing for
the iterative process of supervisor specification,
simulation, and refinement.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  3627 </NUMBER>
<ORDER>   AAG9715943 </ORDER>
<TITLE> CULTURAL ALGORITHMS WITH GENETIC PROGRAMMING: LEARNING TO CONTROL THE PROGRAM EVOLUTION PROCESS </TITLE>
<AUTHOR> ZANNONI, ELENA </AUTHOR>
<YEAR> 1996 </YEAR>
<INSTITUTION> WAYNE STATE UNIVERSITY; 0254 </INSTITUTION>
<DESCRIPTORS> COMPUTER SCIENCE; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> R. G. REYNOLDS </ADVISER>
<CLASSIFICATIONS> SYMBOLIC REGRESSION, ARTIFICIAL INTELLIGENCE </CLASSIFICATIONS>
<ABSTRACT>
Traditional software engineering dictates the use of
modular and structured programming, and top-down
stepwise refinement techniques, which reduce the amount
of variability arising in the development process by
establishing standard procedures to be followed while
writing software. This focusing leads to a reduced
variability in the resulting products, due to the use of
standardized constructs.
Genetic Programming (GP) performs heuristic search in
the space of programs. Programs produced through the GP
paradigm emerge as the result of simulated evolution and
are built through a bottom-up process, incrementally
augmenting their functionality until a satisfactory
level of performance is reached. Can we automatically
extract knowledge from the GP programming process, that
can be useful to focus the search and reduce product
variability thus leading to a more effective use of the
available resources?
An answer to this question is investigated with the aid
of the Cultural Algorithm paradigm. A new system was
developed in this work called Cultural Algorithms with
Genetic Programming. CAGP embeds a genetic programming
system within a cultural algorithm framework. The pool
of genetic programs is the population level of CAGP. The
microevolution within the population brings about
potentially meaningful characteristics for the
achievement of the solution, such as properties
exhibited by the best performers in the population. CAGP
generalizes upon these features and represents them as
the set of the current beliefs. Beliefs correspond to
constraints which all of the genetic operators and
programs must follow. Interaction between the two levels
occurs in one direction through the generalization
process, and, in the other, through the modulation of an
individual's program parameters according to which and
how many of the constraints are followed.
CAGP is applied to solve an instance of the symbolic
regression problem, in which a function of one variable
needs to be discovered. The results of the experiments
show an overall improvement on the average performance
of CAGP over GP alone and a significant reduction of the
complexity of the produced solution. Moreover, the
execution time required by CAGP is comparable with the
time required by GP alone.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  3628 </NUMBER>
<ORDER>   AAG9715854 </ORDER>
<TITLE> VIRTUAL WORLD DATABASE MANAGEMENT SYSTEMS PRINCIPAL ANALYSIS AND PROOF OF CONCEPTS </TITLE>
<AUTHOR> JIANG, ZHAOWEI </AUTHOR>
<YEAR> 1996 </YEAR>
<INSTITUTION> WAYNE STATE UNIVERSITY; 0254 </INSTITUTION>
<DESCRIPTORS> COMPUTER SCIENCE; HEALTH SCIENCES, MEDICINE AND SURGERY; ENGINEERING, BIOMEDICAL </DESCRIPTORS>
<ADVISER> WILLIAM I. GROSKY </ADVISER>
<CLASSIFICATIONS> HIERARCHICAL HYPERVOXEL SPACE </CLASSIFICATIONS>
<ABSTRACT>
One of the challenges in virtual reality application is
to completely integrate complicated spatial and textual
information into an virtual environment. To solve the
problem needs a specific information management system.
In this document, the concept of virtual world database
management systems and their general scope have been
presented. Principles about virtual world databases are
studied and a generic architectures, together with
necessary software modules and query schemes are
introduced. The hierarchical hypervoxel space (HHVS)
which integrates spatial and textual information and
supports widely used spatial queries is introduced as
the kernel of our object-oriented generic architecture.
The development of a virtual world database is a multi-
discipline issue that covers techniques in relational
database systems, spatial database systems, object-
oriented database systems, multimedia database systems
and artificial intelligence. In order to prove our
principles about virtual world databases, we constructed
a virtual brain system based on our generic
architectures and software modules. Detailed
architectures and related algorithms implemented in the
virtual brain system are presented in the document. The
concept of "virtual brain counseling" is also introduced
which extend the benefit of virtual brain systems from
medical education and training to clinical activities.
We indicated that spatial queries contribute the
majority of these benefits. Although our proof of
concepts is only based on the virtual brain application,
due to generality and complexity of the virtual brain
system, this proof has much broader sense.
We have to admit that our currently existing studies for
virtual world database management systems are still
primitive. Our research work will continue to fully
develop a general virtual world database management
system, and expend our virtual brain system to a
complete, complex, multi-aspect, full-functional and
clinical convenient virtual brain system. We believe we
just opened a new era for virtual reality, and computer
assisted clinic applications.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  3629 </NUMBER>
<ORDER>   AAG9715536 </ORDER>
<TITLE> META-HEURISTICS FOR MANUFACTURING PROBLEMS </TITLE>
<AUTHOR> HOUCK, CHRISTOPHER RAYMOND </AUTHOR>
<YEAR> 1996 </YEAR>
<INSTITUTION> NORTH CAROLINA STATE UNIVERSITY; 0155 </INSTITUTION>
<DESCRIPTORS> ENGINEERING, INDUSTRIAL; OPERATIONS RESEARCH; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> MICHAEL G. KAY; RUSSELL E. KING </ADVISER>
<CLASSIFICATIONS> GENETIC ALGORITHMS, FUZZY SYSTEM, NEURAL NETWORK, OPTIMIZATION </CLASSIFICATIONS>
<ABSTRACT>
This research is an investigation of the effects of
using heuristic algorithms together with evolutionary
algorithms. Two different approaches to meta-heuristics,
the integration of heuristic algorithms into
evolutionary algorithms, are investigated: meta-
heuristics that extend the capabilities of an
evolutionary algorithm, thus allowing for multi-
attribute optimization; and meta-heuristics that
increase the computational efficiency of the
evolutionary algorithm through the use of local
improvement procedures. The first meta-heuristic
approach is briefly examined by developing a neural-
fuzzy system which is capable of learning a user's
preference function. This then provides the capability
of mapping a multi-attribute optimization problem into a
single attribute optimization function, that an
evolutionary algorithm can then optimize. The second
meta-heuristic approach involving the incorporation of
local improvement procedures is extensively explored
through case studies, empirical analysis, and
theoretical investigation. The effectiveness of using
local improvement procedures is examined through a case
study, the location-allocation problem. This leads to an
empirical analysis of the appropriate representation
strategy, Lamarckian, Baldwinian, or partial Lamarckian,
when using a hybrid algorithm. The development of a meta-
heuristic that uses a local improvement procedure as an
operator for the evolutionary algorithm is empirically
explored. The determination of the appropriate
application frequency is examined through a co-evolution
strategy, as well as from a global optimization strategy
that uses random linkage. A summary of the results of
these investigations is presented.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  3630 </NUMBER>
<ORDER>   AAG9715428 </ORDER>
<TITLE> CLASSIFICATION AND RECOGNITION OF SPEECH UNDER PERCEPTUAL STRESS USING NEURAL NETWORKS AND N-D HMMS </TITLE>
<AUTHOR> WOMACK, BRIAN DAVID </AUTHOR>
<YEAR> 1996 </YEAR>
<INSTITUTION> DUKE UNIVERSITY; 0066 </INSTITUTION>
<DESCRIPTORS> ENGINEERING, ELECTRONICS AND ELECTRICAL; HEALTH SCIENCES, SPEECH PATHOLOGY; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> JOHN H. L. HANSEN </ADVISER>
<CLASSIFICATIONS> HIDDEN MARKOV, STRESS </CLASSIFICATIONS>
<ABSTRACT>
The primary contribution of this study is the
formulation of a stress classification algorithm. The
secondary contribution is the formulation of a multi-
dimensional hidden Markov model (N-D HMM) for unified
stressed speech classification and recognition.
Perceptually induced stress affects a speaker's
intention to produce speech due to the presence of
emotion, environmental noise (i.e., Lombard effect), or
actual task workload. Analysis of articulatory,
excitation, and cepstral based features is conducted
using a previously established stressed speech database
(SUSAS). Targeted feature sets are selected across ten
stress conditions (Apache helicopter, Angry, Clear,
Fast, Lombard effect, Loud, Slow, Soft, and two workload
tasks). Four stress classification approaches are
formulated using both neural network and hidden Markov
model based systems. Stress classification rates for the
neural network based mono-partition non-targeted feature
and tri-partition targeted feature algorithms are 56.68%
(5 words, 1 speaker) and 91.01% (35 words, 11 speakers)
across ten stress conditions for specific application
scenarios. The stress classification rate for both the 1-
D and N-D HMM across Neutral, Angry, Clear and Lombard
effect speech is 57.6%, with the N-D model yielding
greater stress score separation. Stress directed speaker
independent speech recognition is shown to improve
performance over Neutral and multi-style trained speech
recognizers by +10.95% and +15.43%. Finally, the N-D HMM
is used to unify the stress classification and stress
dependent speech recognition tasks. The N-D HMM
structure is derived from Markov Random Field theory
enabling an explicit sub-phoneme stress classification
at the state level. This formulation better integrates
perceptually induced stress effects. An improvement of
+15.72% is observed for the N-D HMM at 94.41% over the 1-
D HMM based stress directed speech recognition system.
This is +26.67% better than the Neutral trained 1-D HMM
which has a recognition rate of 67.74%. It is suggested
that the developed stress classification algorithms are
applicable to other speech under stress environments,
yielding significant performance gains in speech
processing systems due to the incorporation of speaker
stress effects.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  3631 </NUMBER>
<ORDER>   AAG9715409 </ORDER>
<TITLE> INTELLIGENT COMPLIANCE/ADMITTANCE CONTROL FOR AUTOMATED ROBOTIC MANUFACTURING PROCESSES </TITLE>
<AUTHOR> PRABHU, SAMEER MANOHAR </AUTHOR>
<YEAR> 1996 </YEAR>
<INSTITUTION> DUKE UNIVERSITY; 0066 </INSTITUTION>
<DESCRIPTORS> ENGINEERING, MECHANICAL; ARTIFICIAL INTELLIGENCE; ENGINEERING, ELECTRONICS AND ELECTRICAL </DESCRIPTORS>
<ADVISER> DEVENDRA P. GARG </ADVISER>
<CLASSIFICATIONS> NEURAL NETWORKS, FUZZY LOGIC </CLASSIFICATIONS>
<ABSTRACT>
To be competitive in the emerging global economy,
manufacturing industries need flexible and automated
manufacturing equipment. Due to the inherent flexibility
in its design and its programmability, a robot
manipulator is an ideal choice for flexible automation
of typical manufacturing operations. However, previous
attempts at robotic automation of manufacturing have not
been very successful due to their inability to achieve
the transfer of knowledge, concerning the manufacturing
operation to be controlled, both within and outside the
manufacturing system. This dissertation presents two
control architectures which enable flexible robotic
automation of typical manufacturing operations, and at
the same time, enable the incorporation of knowledge
concerning the manufacturing operation in the controller
design. Since typical manufacturing operations require
the robot to undergo mechanical interactions with the
environment, this dissertation focuses on two general
classes of manufacturing processes, viz., stiffness and
damping processes, which arise in such tasks. To enable
the incorporation of, and the learning of, manufacturing
operation knowledge, fuzzy logic and neural network
techniques are used, respectively.
The issues which need to be addressed in developing
intelligent, flexible and automated robotic
manufacturing systems are highlighted first. A fuzzy
logic based compliance control approach is then
developed which enables the robotic automation of
stiffness related manufacturing process, and enables
process knowledge incorporation in the controller
design. The proposed approach is successfully applied to
a ball aligning task, which is included as an
illustrative example of a stiffness related
manufacturing process. A fuzzy logic based admittance
control approach is then developed for the robotic
automation, and knowledge incorporation of a damping
related manufacturing process. The proposed approach is
then applied to the robotic automation of a deburring
process, as an example of a damping related
manufacturing process. Finally the proposed fuzzy logic
based compliance and admittance approaches are analyzed
and some of their drawbacks are discussed.
A reinforcement learning fuzzy neural network (RLFNN) is
then proposed, which meets the requirements of knowledge
incorporation and learning, and also satisfies the
requirements of a controller for flexible robotic
automation of manufacturing process. The performance of
a RLFNN based compliance and admittance controller is
compared with a fuzzy logic based compliance and
admittance controller respectively, and benefits of the
RLFNN based approaches are highlighted. The RLFNN based
approaches are shown to meet the requirements of
flexible robotic automation of manufacturing processes,
and are thus an important contribution to the
development of intelligent, flexible and automated
manufacturing systems. Finally, suggestions are made to
further enhance the proposed schemes by, extending their
applicability to other types of sensory information, and
by means of sensor fusion.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  3632 </NUMBER>
<ORDER>   AAG9715190 </ORDER>
<TITLE> FREEWAY INCIDENT DETECTION USING ARTIFICIAL NEURAL NETWORKS  </TITLE>
<AUTHOR> ROH, KILLION BRUCE </AUTHOR>
<YEAR> 1996 </YEAR>
<INSTITUTION> THE UNIVERSITY OF IOWA; 0096 </INSTITUTION>
<DESCRIPTORS> ENGINEERING, INDUSTRIAL; COMPUTER SCIENCE; ENGINEERING, SYSTEM SCIENCE; ARTIFICIAL INTELLIGENCE; ENGINEERING, CIVIL </DESCRIPTORS>
<ADVISER> DENNIS L. BRICKER </ADVISER>
<CLASSIFICATIONS> TRAFFIC INCIDENTS </CLASSIFICATIONS>
<ABSTRACT>
Methods for the automatic detection of freeway traffic
incidents have been formulated and developed by many
authors. Fast and reliable detection of traffic
incidents is essential for effective incident
management, in which importance is given to the issues
of reducing traffic delay, increasing traffic safety,
and minimizing traffic congestion.
While existing automatic detection techniques provide
certain necessary information for incident management,
they suffer from a high level of false alarms and
prolonged detection time delay. A more reliable
technique is needed to attain an improved incident
management.
It is shown in the present study that neural networks
with the cascade correlation architecture can be used to
achieve better performance in detecting freeway
incidents. The application of the cascade correlation
algorithm to incident detection problem promises several
advantages. First, the algorithm not only eliminates the
need to guess the appropriate size of the neural
network, but also optimizes the network, in terms of the
number of hidden units, by itself. Secondly, at any
given time, we train only one layer of weights in the
network. The rest of the network is not changing.
In order to improve accuracy of the cascade correlation
algorithm for incident detection, three multi-network
models are introduced. It is shown that, using a
hierarchy of primary and secondary neural networks, a
multi-network architecture can perform better, in terms
of false alarm rates, than a single neural network. An
incrementally trained neural network algorithm is also
devised in order to improve the accuracy of incident
detection.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  3633 </NUMBER>
<ORDER>   AAG9714884 </ORDER>
<TITLE> COOPERATIVE HETEROGENEOUS INTELLIGENT PROCESSING SYSTEMS: APPLICATIONS AND TOOLS </TITLE>
<AUTHOR> VILLA, MARK FRANCIS </AUTHOR>
<YEAR> 1996 </YEAR>
<INSTITUTION> UNIVERSITY OF ALABAMA AT BIRMINGHAM; 0005 </INSTITUTION>
<DESCRIPTORS> COMPUTER SCIENCE; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> KEVIN DENIS REILLY </ADVISER>
<CLASSIFICATIONS> NEURAL NETWORKS, ARTIFICIAL INTELLIGENCE </CLASSIFICATIONS>
<ABSTRACT>
The human brain may be described as a group of
components, physically distinct and separated but in
full communication. This description, applicable to
computing systems as well, is a motivator for simulating
brain-like computation on a computer. This dissertation
thus takes neural network models as a prime focus.
Most artificial neural network (ANN) models discussed
are modular in nature and adaptable to heterogeneity
across modules. This thesis, however, extends this
heterogeneity to include conventional algorithm modules,
which provides the rationale for the characterizing
phrase, cooperative heterogeneous intelligent processing
system(s) (CHIPS).
CHIPS cooperate to the extent that their heterogeneous
elements work together to accomplish tasks of an
intelligent processing system; they exploit forms of
computation in a manner suitable to the needs of the
task. The Introduction develops this CHIPS notion in the
context of problems to be solved, ANN models relied upon
(e.g., fast learning nets), and tool development (given
that models must be implemented).
Beyond contributing to the development of modular neural
network and CHIPS computational styles, this research's
predication of implemented models has led us to
significant advances in tools for building models and
analyzing their results, in the spirit of the BEAK
(Build Execute Analyze Knowledge) model of the thesis'
advisor (Reilly, Barrett, Tarng, & Hyatt, 1995). Tool
exploration has settled upon an integrated collection of
methods that include a CHIPS connectivity and
communication library and command line interface, Stuple
Space, an ANN-oriented vector library, vecmat, and a set
of statistical programs and a graphical display program,
for monitoring and analyzing program output. The
resulting set of code forms a CHIPS development kit.
The collection of increasingly comprehensive artificial
intelligence (AI) models in this document, with major
applications to human behavior, include as a central
problem of study the use of strategies by children. The
CHIPS kit matures over three phases, in step with the
increasing sophistication of the applications. Several
published articles document our efforts through these
phases; the reader is directed toward the appendices for
these. Advancement of these models and the above
mentioned tools remains an ongoing effort.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  3634 </NUMBER>
<ORDER>   AAG9708269 </ORDER>
<TITLE> MODEL-BASED CONTROL OF LABORATORY HVAC SYSTEMS </TITLE>
<AUTHOR> AHMED, OSMAN </AUTHOR>
<YEAR> 1996 </YEAR>
<INSTITUTION> THE UNIVERSITY OF WISCONSIN - MADISON; 0262 </INSTITUTION>
<DESCRIPTORS> ENGINEERING, MECHANICAL; ENGINEERING, ELECTRONICS AND ELECTRICAL; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> JOHN W. MITCHELL </ADVISER>
<CLASSIFICATIONS> AIR FLOW, FEEDFORWARD CONTROL, NEURAL NETWORK </CLASSIFICATIONS>
<ABSTRACT>
The laboratory (lab) environment is unique in terms of
the comfort, safety and operation dynamics. The safety
constraint requires control of contaminants within the
fume hood and the lab space. A fume hood exhaust
captures and exhausts contaminants generated within the
fume hood. Contaminant leakage from the lab is prevented
by lowering the space pressure compared to the adjacent
space and thus inducing infiltration.
The volume flow rate of lab supply air is high for
effective ventilation and the safety criteria require
that 100% of the supply air come from outdoors. This air
flow is thermally treated which increases the lab energy
cost. The lab variable air volume (VAV) HVAC system
saves energy by reducing the supply air flow when the
lab exhaust decreases. The lab HVAC system consists of
multiple, coupled, non-linear and conflicting loops.
Present lab control systems use several feedback
controllers which work well at the tuning and peak
operating conditions. However, they exhibit poor
performance at other operating points and due to
component non-linearity. The lab HVAC system
commissioning is challenging and expensive due to the
complex process of feedback loops tuning.
This research proposes a model-based combined
feedforward and feedback control for lab HVAC system.
The feedforward controller has identification and
control algorithms. The identification algorithm
identifies and up-dates process characteristics on a
regular interval. They are passed to the control block
which generates the required control signal for given
room conditions. A simple memory based General
Regression Neural Network (GRNN) is used for
identification and control of HVAC components. Any
residual control signal needed to reach a steady state
is provided by the feedback controller.
The combination and feedback controllers are compared
for pressure, heating and cooling sequences under wide
operating conditions using simulations. In all cases,
the proposed system performed well compared to the
feedback only method in terms of providing stability and
accuracy. Implementation of the combined approach is
expected to be practical, cost-effective and simple.
Additional benefits of the proposed system includes
lowering commissioning and operation cost as it needs
less tuning and trouble shooting.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  3635 </NUMBER>
<ORDER>   AAG0597725 </ORDER>
<TITLE> CONTEXT AND CONFIGURATION-BASED SCENE CLASSIFICATION </TITLE>
<AUTHOR> LIPSON, PAMELA R. </AUTHOR>
<YEAR> 1996 </YEAR>
<INSTITUTION> MASSACHUSETTS INSTITUTE OF TECHNOLOGY; 0753 </INSTITUTION>
<DESCRIPTORS> COMPUTER SCIENCE </DESCRIPTORS>
<ADVISER> ERIC GRIMSON </ADVISER>
<CLASSIFICATIONS> MACHINE VISION, ARTIFICIAL INTELLIGENCE </CLASSIFICATIONS>
<ABSTRACT>
The problem of scene classification is one of the
significant open challenges in the field of machine
vision. During the past few years, there has been a
resurgence of interest in this area due to the potential
applications in content-based digital image database
indexing. Most proposed solutions have either skirted
the problem by using textual annotation or have employed
image statistics such as color histograms or local
textural measures. While adequate for some tasks, these
approaches are unable to capture the global
configuration of a scene, which seems to be of critical
significance in perceptual judgments of scene
similarity. The key question this thesis addresses is
how to encode a scene so as to incorporate its overall
structure in a manner that would allow subsequent
generalization to other members of the scene class. We
present a novel approach, called "configural
recognition", as a partial solution to this problem. The
main features of this approach are its use of
qualitative spatial and photometric relationships within
and across regions in low-resolution images. The
emphasis on qualitative measures endows the approach
with an impressive generalization ability and the use of
low-resolution images renders it computationally
efficient. We present results of testing this approach
on a large database of natural scenes. We also describe
how qualitative scene concepts may be automatically
learned from examples. The applicability of the
configural recognition approach is not limited to
natural scenes; we conclude by describing some other
domains for which the approach seems well suited. Copies
available exclusively from MIT Libraries, Rm. 14-0551,
Cambridge, MA 02139-4307. Ph. 617-253-1690.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  3636 </NUMBER>
<ORDER>   AAG9731946 </ORDER>
<TITLE> MODEL-BASED DIAGNOSIS </TITLE>
<AUTHOR> KELLY, JOHN JAMES, III </AUTHOR>
<YEAR> 1996 </YEAR>
<INSTITUTION> TULANE UNIVERSITY; 0235 </INSTITUTION>
<DESCRIPTORS> COMPUTER SCIENCE; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> FREDERICK PETRY </ADVISER>
<CLASSIFICATIONS> COMPONENT FAULTS, ARTIFICIAL INTELLIGENCE, CONSTRAINT PROPAGATION </CLASSIFICATIONS>
<ABSTRACT>
This dissertation presents an approach to the goal of
automated diagnosis, for which diagnosis is defined to
be the task of detecting and isolating component faults
within a system. The solution is applicable to systems
for which a behavioral model is available. Importantly,
no information regarding the failure modes of the
system, their likelihood, nor their symptoms, is
required. Engineered systems are within this domain. The
theoretical framework for this solution is presented
along with the procedures, an analysis of their
complexity, and sample problems.
The solution is a graph-theoretic extension to the
existing consistency-based approach. Using constraint
propagation over a constraint graph as the basis results
in a simpler formulation of the solution than those
presented to date. The use of appropriate constraint
solution techniques enables the required focusing to
achieve an efficient consistency-based solution.
Intuitions regarding adding sensors, swap testing, and
bench testing have been formally incorporated in the
consistency-based approach. The formal diagnosis has
been reconciled with the presentation requirements. The
interval algebra has been extended to have open and
closed intervals. The computational costs of the steps
in the diagnosis have been analyzed.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  3637 </NUMBER>
<ORDER>   AAG0597718 </ORDER>
<TITLE> ON CONSULTING A SET OF EXPERTS AND SEARCHING </TITLE>
<AUTHOR> GALPERIN, IGAL </AUTHOR>
<YEAR> 1996 </YEAR>
<INSTITUTION> MASSACHUSETTS INSTITUTE OF TECHNOLOGY; 0753 </INSTITUTION>
<DESCRIPTORS> COMPUTER SCIENCE </DESCRIPTORS>
<ADVISER> RONALD L. RIVEST </ADVISER>
<CLASSIFICATIONS> SCAPEGOAT TREES, QUAD TREES, ARTIFICIAL INTELLIGENCE </CLASSIFICATIONS>
<ABSTRACT>
Two chapters of this thesis analyze expert consulting
problems via game theoretic models; the first points out
a close connection between the problem of consulting a
set of experts and the problem of searching. The last
chapter presents a solution to the dictionary problem of
supporting S sc EARCH and update (I sc NSERT and D sc
ELETE) operations on a set of key values.
The first chapter shows that the problem of consulting
experts on-line can be modeled by a chip game similar
and in some cases identical to the Paul-Carole games
used to model a faulty search process. It presents the
best known worst-case algorithms for consulting finitely
many experts, and the best possible algorithms for
consulting infinitely many experts (model selection)
under some assumptions. It includes new results about
faulty search processes as well as generalizations and
new proofs of some known results.
The second chapter uses properties of coalitional games
to analyze the performance of the greedy heuristic for
the problem of hiring experts from a pool of candidates
using stochastic data. The results are instrumental in
suggesting an alternative to a known algorithm for
learning Lipschitz functions by a memory-based learning
systems via an analysis of the greedy approximate
solution of the s-median problem.
The third and last chapter is dedicated to the Scapegoat
trees data structure: a solution to the dictionary
problem that uses binary trees with no auxiliary
balancing data stored at the tree nodes to achieve
logarithmic worst-case search time, and logarithmic
amortized update time.
All chapters explore alternatives to the now standard
worst-case analysis of algorithms. The first chapter
introduces and advocates the notions of opportunism and
almost opportunism of on-line algorithms. The second
chapter contrasts the pessimism of worst-case analysis
with the optimism of the greedy heuristic, and points
out some benefits of exploring the latter. The last
chapter evaluates a novel data structure by computing
its amortized performance. (Copies available exclusively
from MIT Libraries, Rm. 14-0551, Cambridge, MA 02139-
4307. Ph. 617-253-5668; Fax 617-253-1690.)
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  3638 </NUMBER>
<ORDER>   AAG0597716 </ORDER>
<TITLE> UNSUPERVISED LANGUAGE ACQUISITION </TITLE>
<AUTHOR> DE MARCKEN, CARL G. </AUTHOR>
<YEAR> 1996 </YEAR>
<INSTITUTION> MASSACHUSETTS INSTITUTE OF TECHNOLOGY; 0753 </INSTITUTION>
<DESCRIPTORS> COMPUTER SCIENCE; LANGUAGE, LINGUISTICS </DESCRIPTORS>
<ADVISER> ROBERT C. BERWICK </ADVISER>
<CLASSIFICATIONS> GRAMMAR, ARTIFICIAL INTELLIGENCE </CLASSIFICATIONS>
<ABSTRACT>
Children are exposed to speech and other environmental
evidence, from which they learn language. How do they do
this? More specifically, how do children map from
complex, physical signals to grammars that enable them
to generate and interpret new utterances from their
language?
This thesis presents a computational theory of
unsupervised language acquisition. By computational we
mean that the theory precisely defines procedures for
learning language, procedures that have been implemented
and tested in the form of computer programs. By
unsupervised we mean that the theory explains how
language learning can take place with no explicit help
from a teacher, but only exposure to ordinary spoken or
written utterances. The theory requires very little of
the learning environment. For example, it predicts that
much knowledge of language can be acquired even in
situations where the learner has no access to the
meaning of utterances. In this way the theory is
extremely conservative, making few or no assumptions
that are not obviously true of the situation children
learn in.
The theory is based heavily on concepts borrowed from
machine learning and statistical estimation. In
particular, learning takes place by fitting a
stochastic, generative model of language to the
evidence. Thus, the goal of the learner is to acquire a
grammar under which the evidence is "typical", in a
statistical sense. Much of the thesis is devoted to
explaining conditions that must hold for this learning
strategy to arrive at the desired form of grammar. The
thesis introduces a variety of technical innovations,
among them a common representation for evidence and
grammars that has many linguistically and statistically
desirable properties. In this representation, both
utterances and parameters in the grammar are represented
by composing parameters. A second contribution is a
learning strategy that separates the "content" of
linguistic parameters from their representation.
Algorithms based on it suffer from few of the search
problems that have plagued other computational
approaches to language acquisition.
The theory has been tested on problems of learning
lexicons (vocabularies) from text and speech signals. It
performs extremely well on various objective criteria,
acquiring knowledge that causes it to assign almost
exactly the same linguistic structure to utterances as
humans do. The theory has application to data
compression, speech recognition, machine translation,
information retrieval, and other tasks that rely on
either structural or stochastic descriptions of
language. (Copies available exclusively from MIT
Libraries, Rm. 14-0551, Cambridge, MA 02139-4307. Ph.
617-253-5668; Fax 617-253-1690.)
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  3639 </NUMBER>
<ORDER>   AAG0597710 </ORDER>
<TITLE> ON THE REPRESENTATION OF NOVEL OBJECTS: HUMAN PSYCHOPHYSICS, MONKEY PHYSIOLOGY AND COMPUTATIONAL MODELS </TITLE>
<AUTHOR> BRICOLO, EMANUELA </AUTHOR>
<YEAR> 1996 </YEAR>
<INSTITUTION> MASSACHUSETTS INSTITUTE OF TECHNOLOGY; 0753 </INSTITUTION>
<DESCRIPTORS> BIOLOGY, NEUROSCIENCE; PSYCHOLOGY, EXPERIMENTAL; BIOLOGY, PHYSIOLOGY </DESCRIPTORS>
<ADVISER> TOMASO POGGIO </ADVISER>
<CLASSIFICATIONS> VISION, RECOGNITION, SHAPES, VIEWPOINTS, ARTIFICIAL INTELLIGENCE </CLASSIFICATIONS>
<ABSTRACT>
We recognize objects in three dimensions, despite the
diverse two-dimensional projections produced by changes
in orientation. To achieve recognition, visual input is
compared to stored shapes. These stored models may take
many forms. Much support has been given recently to the
proposal that object representation is specific to view-
point. This approach to the problem of object
recognition assumes that stored models are encoded in
particular orientations, usually those orientations from
which the input shapes were first observed. This thesis
combines psychophysical and physiological experiments,
together with computational simulations, providing
further support for this theory. These viewpoint-
dependent representations are characterized in detail
for the case of a particular class of novel wire-like
three-dimensional objects.
In Part I, in accordance with viewpoint-specific
theories, the psychophysical results reveal that
performance is consistently viewpoint-dependent, and
systematically disrupted by rotation in depth, more so
than by deformation of the object itself. Dependence of
performance on object deformation is studied in detail,
and it is suggested that both qualitative and
quantitative information is used in shape
representation.
In Part II, neurophysiological data show that cells in
inferotemporal cortex display properties suggesting a
representation of objects as a collection of views, each
coded by one or more neurons. The recordings reveal a
small population of neurons with remarkable selectivity
for individual views of a set of objects which monkeys
learned to recognize. An analysis of population
responses to different views of objects provides further
evidence that neural representation of object shape
depends on abstract two-dimensional views.
Part III describes a model of these view-tuned units.
The approach consists of representing a view in terms of
a few local features, computed and stored during the
training phase. Each feature is represented as the set
of responses of oriented filters at one location in the
image. During recognition, the system computes a robust
conjunction of the best matches to the stored features.
Simulations show that the model is consistent with
physiological data from single-cell responses. (Copies
available exclusively from MIT Libraries, Rm. 14-0551,
Cambridge, MA 02139-4307. Ph. 617-253-5668; Fax 617-253-
1690.)
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  3640 </NUMBER>
<ORDER>   AAGNN14470 </ORDER>
<TITLE> DYNAMIC FUZZY-REASONING-BASED SYSTEM AND ITS APPLICATIONS TO FOOD QUALITY ASSESSMENT </TITLE>
<AUTHOR> SUN, WEIPING </AUTHOR>
<YEAR> 1996 </YEAR>
<INSTITUTION> UNIVERSITY OF GUELPH (CANADA); 0081 </INSTITUTION>
<DESCRIPTORS> ENGINEERING, SYSTEM SCIENCE; AGRICULTURE, FOOD SCIENCE AND TECHNOLOGY; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> V. J. DAVIDSON </ADVISER>
<CLASSIFICATIONS> PEANUTS, VECTOR SPACE </CLASSIFICATIONS>
<ABSTRACT>
This thesis extends the conventional correlation of
instrumental measurements and sensory attributes of a
food product to a generalized correlation problem in the
framework of fuzzy set theory. To solve the generalized
correlation problem, this thesis develops a computer-
based system called DFS-based Fuzzy Classifier (DFSC).
It can accept a mixed pattern that may contain both
instrumental and sensory measurements of a food sample,
and give fuzzy evaluation of the sample in terms of the
overall quality and the sensory attributes.
The core of the DFSC is Dynamic Fuzzy-reasoning-based
System (DFS) that is the new approach developed in this
study. The DFS simulates and extends the local heuristic
interpolation with the help of fuzzy set theory and
vector space theory. Compared with other present model-
free approaches, the DFS is characterized by its
straightforwardness, flexibility and effectiveness.
Little training and knowledge acquisition are needed for
the application of the DFS to a particular problem.
Experiments with a number of real-world data in system
simulation and classification problems validated the DFS
and its advantages over conventional fuzzy systems.
The DFSC was applied to the quality assessment of
roasted peanuts. The results from the four case studies
showed that DFSCs solved the generalized correlation
problem in the quality assessment of roasted peanuts.
Different input formats were tested, and the
performances of DFSCs were comparable to the panel's
evaluation. Based on the experiments, we suggest to use
color measurements as the input to the DFSC for the
quality assessment of roasted peanuts.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  3641 </NUMBER>
<ORDER>   AAG9716508 </ORDER>
<TITLE> COMPUTERIZED ADAPTIVE TESTING: A COMPARISON OF ITEM RESPONSE THEORETIC APPROACH AND EXPERT SYSTEMS APPROACHES IN POLYCHOTOMOUS GRADING </TITLE>
<AUTHOR> WANG, KYUNGSU </AUTHOR>
<YEAR> 1996 </YEAR>
<INSTITUTION> INDIANA UNIVERSITY; 0093 </INSTITUTION>
<DESCRIPTORS> EDUCATION, TESTS AND MEASUREMENTS; PSYCHOLOGY, PSYCHOMETRICS; EDUCATION, TECHNOLOGY; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> NIL </ADVISER>
<CLASSIFICATIONS> NIL </CLASSIFICATIONS>
<ABSTRACT>
A computerized adaptive test (CAT) tailors the
assessment process by choosing test items which are
close to a person's ability level. This means that
questions which are too easy or too hard for an
individual are avoided, and the test ends as soon as an
a priori confidence level is reached. CATs tend to be
shorter than conventional fixed-length tests without
loss of reliability.
The most prevalent CAT method is based on item response
theory (IRT). While useful for large-scale testing
operations, this approach is impractical for classroom
use. IRT requires administration of a test item pool to
a very large number of persons in order to estimate item
parameters of difficulty, discrimination and lower
asymptotes.
An alternative to IRT was proposed by Frick and Plew,
which is based on an expert systems approach and the
sequential probability ratio test (EXSPRT). Past
research has demonstrated that the EXSPRT compares
favorably with the IRT approach when classifying persons
as masters and nonmasters.
Through retroductive and deductive reasoning, this study
theoretically extended the EXSPRT to classify persons
into more than two categories, such as conventional
letter grades. A Monte Carlo simulation was then
conducted to compare the extended EXSPRT with the IRT-
based approach.
In both approaches, mean adaptive test lengths were
shorter when there were fewer decision categories,
smaller item pools, and when simulated examinee ability
levels were more widely distributed. Decision accuracy
was higher when item pools were larger, there were fewer
decision categories, and when ability levels were
broadly distributed. Decision accuracy was determined by
comparing the CAT outcome with the known ability level
of each simulee.
Since EXSPRT requires a much smaller sample of persons
to determine the rule base than does the IRT approach,
EXSPRT shows promise as a practical alternative for
educators.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  3642 </NUMBER>
<ORDER>   AAG9715685 </ORDER>
<TITLE> THE OUT-OF-SAMPLE ROBUSTNESS OF PREDICTABLE SECURITY RETURNS  </TITLE>
<AUTHOR> COOPER, MICHAEL JEFFRY </AUTHOR>
<YEAR> 1996 </YEAR>
<INSTITUTION> THE UNIVERSITY OF NORTH CAROLINA AT CHAPEL HILL; 0153 </INSTITUTION>
<DESCRIPTORS> BUSINESS ADMINISTRATION, ACCOUNTING; ECONOMICS, FINANCE </DESCRIPTORS>
<ADVISER> JENNIFER CONRAD </ADVISER>
<CLASSIFICATIONS> EXPECTED RETURNS, STOCK MARKET </CLASSIFICATIONS>
<ABSTRACT>
Much recent work in finance has focused on the apparent
predictability of equity returns using in-sample
measures of fit. This paper examines whether the in-
sample predictive power of macroeconomic and
microeconomic factors and lagged returns survives in an
out-of-sample framework using a simple recursive
forecasting method. I find evidence of predictability
for some factors, but in most cases, the profitability
(over a simple buy-and-hold strategy) vanishes with the
inclusion of minimal transaction costs.
To discern the relation between in-sample explanatory
power and out-of-sample predictability, I examine the
association between in-sample adjusted R-squareds and
out-of-sample profitability. I find no relationship
between in-sample R-squared and out-of-sample
predictability. Thus, an implication of this study is
that inferences concerning predictability should not be
based upon classical in-sample statistical inferences
such as F statistics or levels of adjusted R-squared.
Rather, an out-of-sample methodology is essential for
model validation.
Last, to more directly assess the investor's, rather
than the ex post econometrician's problem, I modify the
out-of-sample forecasting methodology to even more
closely simulate "real time." This modified forecasting
methodology includes an artificial intelligence
component that performs an investor's portfolio
allocation decision via in-sample selection of factors,
assets, and filters on expected returns. This more
sophisticated forecasting model succeeds in earning
profits in excess of a buy-and-hold strategy even in a
high transaction cost setting. The success of this model
is due to an increase in the signal-to-noise ratio
emanating from the use of expected return filters.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  3643 </NUMBER>
<ORDER>   AAG9715494 </ORDER>
<TITLE> A MODEL FOR COMPUTER-BASED CRITIQUING OF SCHEDULING TASKS UTILIZING MULTIPLE KNOWLEDGE DOMAINS AND ARGUMENTATION </TITLE>
<AUTHOR> ABREU, CLAUDIO FRANCO </AUTHOR>
<YEAR> 1996 </YEAR>
<INSTITUTION> UNIVERSITY OF PITTSBURGH; 0178 </INSTITUTION>
<DESCRIPTORS> BUSINESS ADMINISTRATION, GENERAL; COMPUTER SCIENCE; OPERATIONS RESEARCH; ENGINEERING, INDUSTRIAL; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> NIL </ADVISER>
<CLASSIFICATIONS> DECISION-MAKING, PROBLEM-SOLVING </CLASSIFICATIONS>
<ABSTRACT>
Scheduling is an NP-Hard problem that impacts the
profitability of organizations. Critiquing systems are
an approach to support decision-makers in solving
reasonably complex problems. This dissertation describes
and evaluates the implementation of a critiquing system
method to support scheduling tasks. Additionally, it
describes and evaluates the implementation of multiple,
potentially conflicting, knowledge domains (chemistry
and scheduling) to support critiquing tasks. An
argumentation process is developed to support knowledge
conflicts (ambiguities, contradictions, and paradoxes).
This study presents a conceptual and a computational
model for critiquing manufacturing scheduling tasks.
Development of the models used questionnaires,
unstructured and structured interviews, and task
observations of plant personnel of a large chemical
corporation.
Additionally, this dissertation develops and validates a
mathematical model of the scheduling problem based on
the conceptual model and the field research performed.
The mathematical model is used to quantify the
computational model and as a validation vehicle.
Validation criteria included three different sets of
tests. The first criterion tested if the computational
model identified infeasible schedules. The second
criterion tested if the computational model identified
optimality. The third criterion quantified the
improvements recommended by the computational model over
manually generated historical schedules.
Thirty historical scheduling cases are used to validate
the computational model. Results indicate, on average, a
seventeen percent improvement over historical cases.
Improvements are primarily due to the use of multiple
knowledge domains. The use of the argumentation process
proved to be an effective method to support knowledge
conflicts.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  3644 </NUMBER>
<ORDER>   AAG0597711 </ORDER>
<TITLE> CASE STUDIES IN LANGUAGE LEARNABILITY </TITLE>
<AUTHOR> BROIHIER, KEVIN J. </AUTHOR>
<YEAR> 1996 </YEAR>
<INSTITUTION> MASSACHUSETTS INSTITUTE OF TECHNOLOGY; 0753 </INSTITUTION>
<DESCRIPTORS> LANGUAGE, LINGUISTICS; COMPUTER SCIENCE; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> KENNETH WEXLER </ADVISER>
<CLASSIFICATIONS> NATURAL LANGUAGE, PARSING, ARTIFICIAL INTELLIGENCE </CLASSIFICATIONS>
<ABSTRACT>
In the linguistic framework of Principles and Parameters
theory (Chomsky 1981), acquisition of a natural language
grammar involves fixing the value of a finite set of
finite-valued parameters. Theoretical and computational
analyses of several proposed classes of algorithms for
natural language parameter setting are reported here.
These include cue-based algorithms (Dresher and Kaye,
1990; Dresher 1994), the Triggering Learning Algorithm
(Gibson and Wexler 1994) and a class of algorithms that
deduce parameter values from the output of the parser
(Fodor 1995).
Properties of parametric spaces that will allow for
successful application of each type of algorithm are
identified. Computational analyses of some simplified
natural language parametric systems are performed to
indicate whether there is preliminary evidence to
suggest that these properties can be expected to hold of
the parameter spaces that underlie human linguistic
competence. (Copies available exclusively from MIT
Libraries, Rm. 14-0551, Cambridge, MA 02139-4307. Ph.
617-253-5668; Fax 617-253-1690.)
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  3645 </NUMBER>
<ORDER>   AAG9714764 </ORDER>
<TITLE> CONTROL OF GROWTH DYNAMICS OF FEED-FORWARD NEURAL NETWORK  </TITLE>
<AUTHOR> TANAKA, TOSHIYUKI </AUTHOR>
<YEAR> 1996 </YEAR>
<INSTITUTION> GEORGIA INSTITUTE OF TECHNOLOGY; 0078 </INSTITUTION>
<DESCRIPTORS> ENGINEERING, AEROSPACE; ENGINEERING, ELECTRONICS AND ELECTRICAL; ENGINEERING, SYSTEM SCIENCE; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> CHIEN-HSIUNG CHUANG </ADVISER>
<CLASSIFICATIONS> ARTIFICIAL INTELLIGENCE </CLASSIFICATIONS>
<ABSTRACT>
New methods in order to design feed-forward neural
networks by using the growth dynamics are proposed. The
dynamics exist when a hidden neuron is added one by one
and the corresponding connections strength is treated as
a control input. The objective of controlling the growth
dynamics is to find a controller (connection sequence)
that achieves a global asymptotic stability (GAS) of the
origin, that is, the zero error convergence
asymptotically. The theoretical foundation of the growth
control is developed in order to make the origin a
global asymptotic stable equilibrium point, where the
controller is called a GAS controller. The theoretical
foundation includes conditions for existence of the GAS
controller, mapping rules of hidden neurons for the GAS
controller, growth pattern and hierarchical structure
for the GAS controller. and extension of criteria.
Practical methods that guarantee to produce GAS
controllers are also proposed.
In the growing methods, the learning is not
simultaneously processed during the neural network is
growing. Therefore, the size of the grown neural network
is usually rather large for the given problem. Learning
methods for the given size neural network are also
proposed based on the growth dynamics, optimal control,
and neighboring control method. The learning based on
regulator can make the size of the network smaller after
the growth control, if the size of the grown neural
network is too large. The learning based on terminal
controller can make the error smaller rather quickly,
although it can not make the size of the grown network
smaller.
So far, the learning method is processed after the
neural network has grown. Another possibility is a
parallel processing of the learning method and the
growing method. Since real parallel processing of these
methods is difficult to realize, a quasi-parallel
processing method is also proposed. The grown and
trained neural network with much smaller size achieves
the same performance to the neural network that utilizes
the learning after the growth control. The quasi-
parallel processing method is extended for the cases for
which only distal information is available and gradient
of criterion is not available.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  3646 </NUMBER>
<ORDER>   AAG9714755 </ORDER>
<TITLE> RECONFIGURABLE CONTROL USING POLYNOMIAL NEURAL NETWORKS </TITLE>
<AUTHOR> RAMANI, VIPIN KEWAL </AUTHOR>
<YEAR> 1996 </YEAR>
<INSTITUTION> GEORGIA INSTITUTE OF TECHNOLOGY; 0078 </INSTITUTION>
<DESCRIPTORS> ENGINEERING, ELECTRONICS AND ELECTRICAL; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> GEORGE J. VACHTSEVANOS </ADVISER>
<CLASSIFICATIONS> FUZZY LOGIC </CLASSIFICATIONS>
<ABSTRACT>
The problem of designing a suitable control or control
strategy for a multiple operating modes for a given
system is a complicated problem. A hierarchical control
scheme is used to break the problem into smaller and
simpler problems. The objective of this research is to
develop an identification and reconfigurable control
strategies for large scale systems, so that the
operational integrity is maintained at the highest
possible level. This research introduces a systematic
methodology for the design of a hierarchical control
scheme for reconfiguration. Dynamic Polynomial Neural
Networks (DPNNs) are used for modeling and low-level
controller design. A fuzzy logic controller is used for
the high-level active control. This methodology is
implemented on the class of systems which can operate in
multiple modes. It is assumed that there is no
mathematical model available for the large scale system.
Dynamic Polynomial Neural Network is used to identify
the system. The DPNN is adaptively modified as the
structure is fine tuned to the data available. The
control is divided into two levels. The low-level
controller is designed using adaptive DPNN methodology.
The purpose of the low-level control is to maintain the
operation of the system in a stable operating mode. High-
level active control is used to combine the low-level
controllers to address the overall system problem. If
the system transitions from one of its stable operating
modes, the mode identifier tries to reconfigure the
system based on the available control authority at the
low-level, and a fuzzy logic based active controller is
used to assist in transitioning the system to a stable
operating mode. Fuzzy logic controller also provides
smoother transition when switching between various
modes. The fuzzy logic controller helps at the high-
level control in determining which mode to operate
under, and deals with the quasi-steady state transition
condition, the low-level control deals with the system
dynamics. Performance assessment is also done at the end
to compare the new methodology with existing strategies.
Sensitivity analysis is performed to assess the
robustness of the methodology. Stability analysis is
also performed in the framework of DPNNs and the high
level fuzzy controller.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  3647 </NUMBER>
<ORDER>   AAGNN18132 </ORDER>
<TITLE> VARIABLE RESOLUTION VISION: BIOLOGICALLY-MOTIVATED FOVEAL COMPRESSION AND PRIORITIZATION </TITLE>
<AUTHOR> WIEBE, KEVIN JAMES </AUTHOR>
<YEAR> 1996 </YEAR>
<INSTITUTION> UNIVERSITY OF ALBERTA (CANADA); 0351 </INSTITUTION>
<DESCRIPTORS> COMPUTER SCIENCE; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> ANUP BASU </ADVISER>
<CLASSIFICATIONS> ATM-BASED </CLASSIFICATIONS>
<ABSTRACT>
Computer Vision shares its interest in investigating
animate behaviour and biological processes with other
disciplines within the field of artificial intelligence
(AI). Our research focuses on two aspects of biological
vision and applies the knowledge gleaned from nature to
appropriate computer vision situations. Both variable
resolution image compression and spatially variant image
data prioritization are present within animate visual
systems and these concepts can be effectively
transferred to enhance several computer applications.
In the area of digital image compression, new techniques
are required to overcome significant storage and
transmission problems in computer vision. A strong
understanding of image characteristics enhances the
effectiveness of compression and many other image
processing operations. Traditional methods have
maintained a constant resolution throughout an image.
However, a survey of the various visual systems present
in the animal kingdom demonstrates the potential of
Variable Resolution (VR) compression methods. The author
models several animate visual systems and outlines novel
image compression techniques based on foveated vision.
Interesting variations on the simple fovea are proposed,
motivated by similar variations present in animate
visual systems--specifically multiple, dynamic and
weighted foveae, and visual streaks. Techniques for
efficient modelling of fovea movement are also
described.
The other topic discussed is the prioritization of image
data. A fundamental drawback to increasingly popular ATM-
based switching is the possibility of information loss
with congestion. We demonstrate that with intelligent,
fovea driven priority assignment of image data, we can
reduce the negative impact of information loss over ATM
networks. ATM standards allow a single bit to indicate
high or low packet priority. To reduce the effect of
this restriction we introduce the concept of priority
dithering. Network multimedia multicast scenarios over
heterogeneous link capacities where foveal
prioritization would be of benefit are described.
Included are network simulation results of this method,
which demonstrate the advantages of priority dithered
foveal prioritization over traditional methods.
Utilizing our knowledge of biological vision systems
provide us with insights into new developments in the
areas of image compression, image transmission,
videophones, multimedia, teleconferencing, and
telepresence. Original, substantive research is
presented.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  3648 </NUMBER>
<ORDER>   AAG9714612 </ORDER>
<TITLE> DYNAMIC HIERARCHICAL SELF-ORGANIZING NEURAL NETWORKS FOR PATTERN RECOGNITION </TITLE>
<AUTHOR> HUNG, HAI-LUNG </AUTHOR>
<YEAR> 1996 </YEAR>
<INSTITUTION> NORTHWESTERN UNIVERSITY; 0163 </INSTITUTION>
<DESCRIPTORS> COMPUTER SCIENCE; ENGINEERING, ELECTRONICS AND ELECTRICAL; ENGINEERING, BIOMEDICAL; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> NIL </ADVISER>
<CLASSIFICATIONS> ARTIFICIAL INTELLIGENCE </CLASSIFICATIONS>
<ABSTRACT>
In this dissertation, we propose three models of
unsupervised learning neural networks for pattern
recognition. They are: (1) Divisive Fuzzy Kohonen
Clustering Networks (DFKCN), (2) Cascaded Fuzzy Adaptive
Hamming Nets (CFAHN), and (3) Cascaded Fuzzy Adaptive
Resonance Theory (CFART) networks. In addition to the
essential characteristics of conventional unsupervised
learning neural networks, the proposed networks have two
extra major features, i.e. the hierarchical structure
and the capability of dynamically allocating new
neurons.
The DFKCN is a Kohonen-type network but is capable of
allocating new neurons dynamically during the learning
process and then determining its own topology. By
integrating the concept of decision tree classifiers, a
fuzzy membership function which measures the similarity
of the input data and a statistical hypothesis test
which determines the allocation of new neurons, the
DFKCN releases the limitations of a Kohonen net such as
the random initialization of weights, the selection of
neighborhood function, and the fixed number of neurons.
The CFAHN and the CFART are both ART-type networks. Both
of them consist of multiple layers of output nodes and
can function as extensible databases for on-line
learning. Unlike the conventional ART-type networks with
only single layer of output nodes, both the CFAHN and
the CFART can learn and organize the input data in a
multi-resolutional manner. At the learning stage, an
input pattern can be learned and stored in each layer in
a fine-to-coarse way. The categories in higher layers
form a superset of categories in lower layers.
Therefore, categories in higher layers could express a
more general view than could those in lower layers. At
the recalling or recognition stage, an unknown input
pattern can then be recognized or matched reversely
through a coarse-to-fine (top-down) search. Basically,
the CFART is an advanced model of the CFAHN. The
difference between a CFAHN and a CFART is that a CFART
has an additional novel top-down search (guiding)
mechanism. With this additional top-down guiding
mechanism, both the learning and recognition processes
through the multiple-layer structure can be speeded up.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  3649 </NUMBER>
<ORDER>   AAG9714586 </ORDER>
<TITLE> INTERACTION OF DISCOURSE PLANNING, INSTRUCTIONAL PLANNING AND DIALOGUE MANAGEMENT IN AN INTERACTIVE TUTORING SYSTEM </TITLE>
<AUTHOR> FREEDMAN, REVA K. </AUTHOR>
<YEAR> 1996 </YEAR>
<INSTITUTION> NORTHWESTERN UNIVERSITY; 0163 </INSTITUTION>
<DESCRIPTORS> COMPUTER SCIENCE; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> GILBERT K. KRULEE </ADVISER>
<CLASSIFICATIONS> CARDIOVASCULAR PHYSIOLOGY, NATURAL LANGUAGE </CLASSIFICATIONS>
<ABSTRACT>
We demonstrate the utility of natural language
generation as the underlying model for an intelligent
tutoring system (ITS) in cardiovascular physiology. We
have achieved this goal by dividing it into three
subgoals, each of which builds on its predecessor: (a)
developing a model of the tutorial dialogue of human
tutors based on current research in natural language
generation, with emphasis on text planning and the
Conversation Analysis school, (b) analyzing a corpus of
human-to-human tutoring sessions in cardiovascular
physiology in terms of this model, and (c) designing an
ITS which implements the model. We develop an abstract
model of tutorial dialogue in order to put text
generation for ITSs on solid theoretical footing. We
give a detailed analysis of our corpus using this model,
including a discussion of how tutors sequence their
corrections, begin and end phases of the discourse,
acknowledge responses, reply to student errors, teach
different kinds of information, provide hints, conduct
interactive explanations and choose between domain
models. We present a detailed design for an ITS which
uses this model to show that it can be implemented with
current technology. The system is divided into two
routines running in parallel, a global tutorial planner,
which makes discourse decisions for units larger than a
turn, and a turn planner, which assembles individual
turns. The tutorial planner does not generate text
directly, but generates a series of semantic forms. The
turn planner collects the semantic forms for a turn,
which may include information from multiple tutorial
and/or conversational goals, and generates text for them
as a unit. This architecture promotes coherent dialogue
while permitting the tutor to use multi-turn discourse
plans and change plans in response to student input. We
expect this model to produce longer, more complex, and
more varied dialogues than previous work.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  3650 </NUMBER>
<ORDER>   AAG9714584 </ORDER>
<TITLE> NON-AUTONOMOUS DYNAMICAL SYSTEMS APPLICABLE TO NEURAL COMPUTATION  </TITLE>
<AUTHOR> FISKE, MICHAEL STEPHEN </AUTHOR>
<YEAR> 1996 </YEAR>
<INSTITUTION> NORTHWESTERN UNIVERSITY; 0163 </INSTITUTION>
<DESCRIPTORS> MATHEMATICS; COMPUTER SCIENCE; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> DONALD G. SAARI </ADVISER>
<CLASSIFICATIONS> ARTIFICIAL INTELLIGENCE, CHAOS, GRADIENT DESCENT </CLASSIFICATIONS>
<ABSTRACT>
This thesis explores properties of classes of non-
autonomous and autonomous dynamical systems which are
relevant to neural network computation. In the
introduction two examples are used to illustrate the
critical role played by computation, training, and
generalization in neural network computation. Using
these examples, we explain why dynamical systems
effectively model basic notions that arise in neural
network computation.
In Chapter I, we introduce a way to compare two non-
autonomous systems. It is interesting that this approach
extends the notion of topological conjugacy for
autonomous systems. In Chapter II, we discuss stability
in non-autonomous systems. In Chapter III, some theorems
are offered about non-autonomous systems in which each
function is a contraction. In Chapter IV, we prove
theorems about topological entropy for non-autonomous
systems. In Chapter V we compute a lower bound for the
entropy of a chaotic attractor and also characterize the
geometry of the attractor. In Chapter VI, we show how to
use chaotic non-autonomous systems in optimization
algorithms as a method to find the global minima of the
error function. In particular, this demonstrates the use
of chaotic dynamics in a neural net training algorithm.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  3651 </NUMBER>
<ORDER>   AAG9714583 </ORDER>
<TITLE> A STRATEGY-BASED THEORY OF PLANNING FOR GOAL-BASED SCENARIO-LEARNING ENVIRONMENTS </TITLE>
<AUTHOR> FANO, ANDREW ERNEST </AUTHOR>
<YEAR> 1996 </YEAR>
<INSTITUTION> NORTHWESTERN UNIVERSITY; 0163 </INSTITUTION>
<DESCRIPTORS> COMPUTER SCIENCE; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> ROBERT SCHANK </ADVISER>
<CLASSIFICATIONS> ARTIFICIAL INTELLIGENCE, PROBLEM SOLVING, COMMON SENSE REASONING </CLASSIFICATIONS>
<ABSTRACT>
We all face problems every day in most aspects of our
lives. Much of our time is spent planning how we will
address these problems. Consequently, one of the central
goals of education has been to enable students to solve
the problems they will encounter. That is, we would like
students to plan effectively in the course of solving
their problems and achieving their goals. This
dissertation addresses the question: What, if anything,
can we teach students to make them effective planners
and problem-solvers?
Traditional attempts to address this question both in
the education and artificial intelligence communities
have generally assumed a model of problem-solving in
which a general problem-solving process is applied to a
body of domain knowledge. This view has largely
restricted research in planning and problem-solving
either to the domain knowledge required to solve very
specific types of problems, or to problem-independent
strategies intended to optimize the general problem-
solving process. Overlooked by the traditional view is
the fact that we encounter the same kinds of problems
time and again across many domains. Correspondingly, we
frequently rely on the same strategies to address these
problems. These "problem-based strategies", I argue, are
something we can teach students to make them better
problem solvers.
The primary contribution of this work lies in the
attempt to identify what some of these strategies are. I
outline and discuss a set of approximately 80 planning
strategies commonly used throughout the course of
pursuing goals across a variety of domains. I also
discuss Farmworld, a prototype goal-based scenario
designed to illustrate what it means to teach these
strategies, as well as CAST, an authoring tool created
to build additional systems of this kind.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  3652 </NUMBER>
<ORDER>   AAG9714437 </ORDER>
<TITLE> EVOLVED NEURAL NETWORKS FOR IDENTIFICATION AND CONTROL OF NONLINEAR DYNAMICAL SYSTEMS </TITLE>
<AUTHOR> ERIVES, HECTOR </AUTHOR>
<YEAR> 1996 </YEAR>
<INSTITUTION> NEW MEXICO STATE UNIVERSITY; 0143 </INSTITUTION>
<DESCRIPTORS> ENGINEERING, ELECTRONICS AND ELECTRICAL; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> WILEY E. THOMPSON </ADVISER>
<CLASSIFICATIONS> NIL </CLASSIFICATIONS>
<ABSTRACT>
The design of network controllers for dynamical systems
is one of the areas of control which is still under
research. The design of classical controllers is based
on extensive mathematical analysis of the systems and so
it is mandatory to have a clear knowledge of the
dynamics of the plant. Stochastic-trained methods such
as Artificial Neural Networks (ANNs) and random search
techniques such as Evolutionary Algorithms (EAs) have
been used for efficient parameterization, identification
and control of nonlinear dynamical systems.
During recent years, numerous authors have reported
using ANNs for identification and control of dynamical
systems. However, the main drawback is that a suitable
network architecture or topology is found by trial and
error. On the other hand, ANNs being gradient descent
techniques, are likely to get trapped in a local optima
if the learning or training parameters are not chosen
properly. Consequently, the training phase will become
computational expensive, if the training of the network
converges at all. The EAs, unlike ANNs, explore the
whole search space, rather than a single portion. These
techniques rely on the evolution of a set of solutions
for which, by means of known genetic operators, the best
solutions to the original problems are chosen and
reproduced to create yet new better solutions.
A hybrid system to automatically optimize the set of
structural and training parameters of a neural network
for identification and control of nonlinear systems is
developed. The system consists of evolutionary and
gradient descent algorithms to evolve and adapt the
parameters of two neurocontrollers. Evolved Radial Basis
Function Networks (ERBFNs) and Evolved Multilayer
Feedforward Networks (EMFNs) controllers, are used for
identification and control tasks. The techniques are
used to find an appropriate set of neurocontroller
parameters during the identification of three nonlinear
systems. An evaluation of the performance of the new
techniques and a comparison with previous approaches is
presented.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  3653 </NUMBER>
<ORDER>   AAG9714353 </ORDER>
<TITLE> WEED DETECTION USING COLOR MACHINE VISION </TITLE>
<AUTHOR> ELFAKI, MOHAMMED SALIH </AUTHOR>
<YEAR> 1996 </YEAR>
<INSTITUTION> KANSAS STATE UNIVERSITY; 0100 </INSTITUTION>
<DESCRIPTORS> ENGINEERING, AGRICULTURAL; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> NIL </ADVISER>
<CLASSIFICATIONS> IMAGE PROCESSING, NEURAL NETWORKS, PESTICIDES </CLASSIFICATIONS>
<ABSTRACT>
Weed detection algorithms were developed using RGB color
images. The emphasis was on weed species associated with
Kansas winter wheat and soybean. The study was completed
through five phases.
The first phase looked into the effect of soil moisture
content on weed detection. It was found that, by using
relative color indices, separation between weed stem and
soil would not be seriously affected by variations in
soil moisture content.
The second phase investigated the effects of
illumination on color indices of primary color plates.
The effects were found insignificant. Changes of color
indices with illumination followed patterns which could
be used in color-index calibration.
The third phase determined the optimum spatial
resolution for best classification. The optimum
horizontal and vertical resolution were found to be
0.052cm/pixel and 0.042cm/pixel, respectively.
During the fourth phase, algorithms were developed for
weed stem segmentation and noise removal using images of
six leading weed species commonly found in wheat and
soybean fields. Three detection methods employing
statistical and neural-network techniques were
developed. All detection methods gave satisfactory
results with the statistical classifier outperformed the
neural-network classifiers.
In the last phase, the algorithms were tested on field
images obtained under uncontrolled natural lighting
conditions. The outcome proved that the detection
algorithms were capable of detecting weeds in soybean
and wheat fields with significantly low
misclassification.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  3654 </NUMBER>
<ORDER>   AAG9714202 </ORDER>
<TITLE> CORRELATION-BASED TIME SERIES PATTERN RECOGNITION FOR IMPLANTABLE DEFIBRILLATORS </TITLE>
<AUTHOR> WILKINS, JEFFREY KOHL </AUTHOR>
<YEAR> 1996 </YEAR>
<INSTITUTION> STANFORD UNIVERSITY; 0212 </INSTITUTION>
<DESCRIPTORS> ENGINEERING, ELECTRONICS AND ELECTRICAL; ENGINEERING, BIOMEDICAL; STATISTICS; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> BERNARD WIDROW </ADVISER>
<CLASSIFICATIONS> ARTIFICIAL INTELLIGENCE, CARDIAC, ARRHYTHMIA </CLASSIFICATIONS>
<ABSTRACT>
Proper cardiac arrhythmia classification is of primary
importance in improving the efficacy of implantable
arrhythmia management devices. The problem is made more
challenging by the power/computation constraints imposed
by the limited capacity of implantable devices.
In this thesis, a computationally-efficient, correlation-
based arrhythmia classification architecture is
developed. The architecture classifies individual heart
beats by assessing similarity between an incoming
cardiac signal vector and a series of prestored class
templates. A series of these beat classifications are
used to make an overall rhythm assessment.
Four new results in correlation-based time series
pattern recognition are developed and applied to the
arrhythmia classification problem:
Optimal Filtering. Novel time- and frequency-domain FIR
filter design techniques are developed. More
specifically, "optimal" FIR filters which accentuate the
differences between beat classes are found using
nonlinear programming techniques. Several novel
objective function formulations are proposed.
Acceleration Techniques. New acceleration techniques are
introduced. Registration-level acceleration are used to
speed the registration process. Template-level
acceleration develop conditions under which the need to
calculate the correlation coefficient between a template
and the signal vector is obviated. Sample-level
acceleration allow classification to be performed using
only a fraction of the samples of the template.
Accelerations of up to 40x were measured experimentally
when the techniques were applied in an electrogram (EGM)
arrhythmia classification system.
Error Analysis. An error analysis for the proposed
architecture is developed and used to guide the
selection of key architectural parameters. Bounds are
developed for individual beat and rhythm classification
error rates. The impact of sampling rate on the measured
correlation coefficient is also studied to determine
conditions under which good classification performance
can be obtained.
Template Construction. An optimal template construction
algorithm is developed. Using the method of Lagrange
multipliers, a template producing the highest mean
correlation coefficient with a series of noisy
realizations is constructed.
Unprecedented Accuracy in EGM Arrhythmia Analysis. The
techniques proposed in this dissertation are used to
develop a novel, computationally-efficient EGM
arrhythmia classification system. The resulting system
achieved unprecedented accuracy in PVC detection and
SVT/VT discrimination.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  3655 </NUMBER>
<ORDER>   AAG9714190 </ORDER>
<TITLE> INTEGRATING SPECIALIZED PROCEDURES INTO PROOF SYSTEMS </TITLE>
<AUTHOR> SIKKA, VISHAL INDER </AUTHOR>
<YEAR> 1996 </YEAR>
<INSTITUTION> STANFORD UNIVERSITY; 0212 </INSTITUTION>
<DESCRIPTORS> COMPUTER SCIENCE; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> MICHAEL GENESERETH </ADVISER>
<CLASSIFICATIONS> ARTIFICIAL INTELLIGENCE, REASONING </CLASSIFICATIONS>
<ABSTRACT>
Ever since its early days, one of the goals in AI has
been the development of general systems that can utilize
the benefits of specialized reasoners. Recently,
research on hybrid reasoning systems has led to the
following problem: Can a formalism be developed that
allows specialized procedures to be flexibly integrated
into a general purpose reasoner?
In this thesis, we present $0cal C$-FOL--a formalism for
integrating specialized procedures into proof systems.
Existing approaches to solving this problem lack two
important properties: flexibility, and generality. This
thesis is motivated by the intuition that in order to
flexibly integrate specialized procedures into a proof
system, specialized procedures should be described to
it, instead of being built-in. We describe the
extensions to the syntax, semantics, and inference
machinery of a proof system so as to enable both the
description of specialized procedures, as well as their
use. We show how this allows C-FOL to (i) extend the
existing integration techniques such as those based on
attachments, and (ii) achieve the generality such as
that envisioned in some types of theory resolution, e.g.
partial-narrow theory resolution. We study two famous AI
systems that are viewed as instances of theory
resolution, and show that not only can C-FOL perform the
same types of reasoning, but that it provides a way to,
in general, implement some types of theory resolution.
We also present soundness and completeness results
pertaining to C-FOL, and some other results pertaining
to control issues that arise in the context of hybrid
reasoning. We conclude by putting our work in
perspective, against the backdrop of AI research in the
gray area of between deduction and computation.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  3656 </NUMBER>
<ORDER>   AAG9714057 </ORDER>
<TITLE> A MACHINE LEARNING METHOD SUITABLE FOR DYNAMIC DOMAINS </TITLE>
<AUTHOR> ROWE, MICHAEL CHARLES </AUTHOR>
<YEAR> 1996 </YEAR>
<INSTITUTION> UNIVERSITY OF NORTH TEXAS; 0158 </INSTITUTION>
<DESCRIPTORS> COMPUTER SCIENCE; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> NIL </ADVISER>
<CLASSIFICATIONS> ARTIFICIAL INTELLIGENCE </CLASSIFICATIONS>
<ABSTRACT>
The efficacy of a machine learning technique is domain
dependent. Some machine learning techniques work very
well for certain domains but are ill-suited for other
domains. One area that is of real-world concern is the
flexibility with which machine learning techniques can
adapt to dynamic domains. Currently, there are no known
reports of any system that can learn dynamic domains,
short of starting over (i.e., re-running the program).
Starting over is neither time nor cost efficient for
real-world production environments.
This dissertation studied a method, referred to as
Experience Based Learning (EBL), that attempts to deal
with conditions related to learning dynamic domains. EBL
is an extension of Instance Based Learning methods. The
hypothesis of the study related to this research was
that the EBL method would automatically adjust to domain
changes and still provide classification accuracy
similar to methods that require starting over. To test
this hypothesis, twelve widely studied machine learning
datasets were used. A dynamic domain was simulated by
presenting these datasets in an uninterrupted cycle of
train, test, and retrain. The order of the twelve
datasets and the order of records within each dataset
were randomized to control for order biases in each of
ten runs. As a result, these methods provided datasets
that represent extreme levels of domain change.
Using the above datasets, EBL's mean classification
accuracies for each dataset were compared to the
published static domain results of other machine
learning systems. The results indicated that the EBL's
system performance was not statistically different (p
$>$ 0.30) from the other machine learning methods.
These results indicate that the EBL system is able to
adjust to an extreme level of domain change and yet
produce satisfactory results. This finding supports the
use of the EBL method in real-world environments that
incur rapid changes to both variables and values.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  3657 </NUMBER>
<ORDER>   AAG9713837 </ORDER>
<TITLE> EXPLICIT N-BEST FORMANT FEATURES FOR SEGMENT-BASED SPEECH RECOGNITION  </TITLE>
<AUTHOR> SCHMID, PHILIPP HEINZ </AUTHOR>
<YEAR> 1996 </YEAR>
<INSTITUTION> OREGON GRADUATE INSTITUTE OF SCIENCE & TECHNOLOGY; 0284 </INSTITUTION>
<DESCRIPTORS> COMPUTER SCIENCE; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> ETIENNE BARNARD </ADVISER>
<CLASSIFICATIONS> ARTIFICIAL INTELLIGENCE </CLASSIFICATIONS>
<ABSTRACT>
This thesis investigates the use of explicit speech
knowledge in computer speech-recognition. Speech
knowledge is generally expressed in terms of acoustic
events occurring near phonetic segment boundaries and
the location, shape and dynamics of formant
trajectories. This suggests the creation of a segment-
based recognition framework and the use of explicit
formant features in a flexible integration scheme to
ultimately improve the phonetic recognition accuracy.
We describe a segmentation algorithm that produces a
lattice of segment hypotheses, each with an associated
broad phonetic identity. We build a single phonetic
segment classifier along with separate vowel/semi-vowel
and consonant classifiers based on traditional cepstral
features paying attention to reducing the mismatch
between training and deployment conditions.
We develop a robust, N-best formant tracking algorithm
that generates a list of up to N consistent formant
interpretations. The use of the N-best feature paradigm
is based on the observation that there are generally
only a handful of reasonable interpretation of the given
formant information. Instead of finding the best formant
interpretation through the use of a global cost function
that includes energy maximization and smoothness terms,
we delay the selection of the correct formant
interpretation until after the segment classification
and phonetic search.
We use the formant interpretations to extract features
for a vowel/semi-vowel segment classifier. The formant
trajectories are approximated either by three line
segments or by a third-order Legendre polynomial. We
show that together with formant amplitude, formant
bandwidth, pitch, and segment durations we can produce a
classifier of comparable performance to a cepstral-based
classifier. We further demonstrate the potential of the
N-best classification paradigm and show that a
combination of formant and cepstral features further
improves the classification accuracy. Finally, the
validity of the entire approach of using a segment-based
approach, separate classifiers for vowels and
consonants, and explicit formant features is verified by
phonetic recognition experiments.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  3658 </NUMBER>
<ORDER>   AAGNN17240 </ORDER>
<TITLE> UN SYSTEME MULTI-PARADIGME POUR LA MANIPULATION DES CONNAISSANCES UTILISANT LA THEORIE DES GRAPHES CONCEPTUELS </TITLE>
<AUTHOR> KABBAJ, ADIL </AUTHOR>
<YEAR> 1996 </YEAR>
<INSTITUTION> UNIVERSITE DE MONTREAL (CANADA); 0992 </INSTITUTION>
<DESCRIPTORS> COMPUTER SCIENCE; ARTIFICIAL INTELLIGENCE; INFORMATION SCIENCE </DESCRIPTORS>
<ADVISER> CLAUDE FRASSON </ADVISER>
<CLASSIFICATIONS> FRENCH TEXT, KNOWLEDGE BASE, CONCEPTUAL GRAPHS, EXPERT SYSTEMS </CLASSIFICATIONS>
<ABSTRACT>
Dans de domaines comme le genie logiciel, l'intelligence
artificielle, les systemes tutoriels intelligents et les
systemes multi-agents, plusiers types de connaissances
sont manipules dan sun meme systeme avec souvent des
formalismes differents, rendant difficile l'integration,
la communication, l'utilisation et le partage des
connaissances et des expertises, au sein du systeme
et/ou entre les systemes.
Un systeme multi-paradigme, base sur un formalisme
uniforme serait donc approprie.
John Sowa propose la theorie des Graphes Conceptuels
(GC) comme un formalisme universel de representation des
connaissances. Cette theorie est presentee non seulement
comme un fondement logique pour les reseaux semantiques
mais aussi comme une theorie du traitement de
l'information chez l'humain et la machine. Une
communaute de chercheurs s'est formee pour analyser,
etendre et ultiiser la theorie des GC dans differents
domaines (base de donnees, base de connaissances, genie
logiciel, systeme d'information, traitement du langage
naturel, acquisition des connaissances, etc.).
Il convient de considerar la possibilite d'utiliser un
systeme multi-paradigme base sur la theorie des GC.
Differents prototypes de systemes de manipulation des GC
ont ete developpes mais aucun systeme multi-paradigme
n'a ete concu. Nous nous sommes ainsi consacre dans
cette these a concevoir et a developper un systeme multi-
paradigme utilisant la theorie des GC.
Le systeme est copose: (1) d'un environnement graphique
comprenant un langage parallele et un modele de
formation incrementale d'une memoire dynamique. Le
langage, appele Synergy est base sur l'activation des GC
et integre differents modeles de programmation (en
l'occurence, le modele procedural, le modele fonctionnel
et le modele oriente-objet). Une application en Synergy
est organisee en une base de connaissances appelee
"memoire a long terme" et une zone de travail appelee
"memoire de travail", les deux sont composees de GC. Le
modele de formation porte sur la "memoire a long terme"
et specific comment de nouvelles connaissances y sont
intergrees automatiquement. (2) d'une extension
conceptuelle, contextuelle et orientee objet du langage
scPROLOG, appelee $Prolog+CG$. L'extension conceptuelle
se base sur les GC et l'extension orientee objet sur les
deux premieres extensions sinsi que sur une formulation
logique de la programmation orientee objet. $Prolog+CG$
etend scPROLOG sans le "masquer"; un programme Prolog
est aussi un programme $rm Prolog+CG$. (3) d'une
hierarchie d'operations sur les GC, incorporee dans
Synergy et $Porlog+CG$.
Motive par un souci de synthese, le but principal de
cette these est de concevoir et de developper le systeme
dans sa totalite, en essayant pour chaque composante
d'integrer plusieurs approches.
Les solutions que nous proposons peuvent etre utilisees
dans differents domaines. De telles utilistions
pourraient susciter de nouveaux developpements
permettant de completer et d'enrichir les composantes du
systeme ainsi que leur integration.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  3659 </NUMBER>
<ORDER>   AAG9713575 </ORDER>
<TITLE> DESIGN OF A LARGE-SCALE EXPERT SYSTEM USING FUZZY LOGIC FOR UNCERTAINTY REASONING AND ITS APPLICATION TO VISION- BASED MOBILE ROBOT NAVIGATION  </TITLE>
<AUTHOR> PAN, JUIYAO </AUTHOR>
<YEAR> 1996 </YEAR>
<INSTITUTION> PURDUE UNIVERSITY; 0183 </INSTITUTION>
<DESCRIPTORS> ENGINEERING, ELECTRONICS AND ELECTRICAL; COMPUTER SCIENCE; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> A. C. KAK </ADVISER>
<CLASSIFICATIONS> ROBOTICS </CLASSIFICATIONS>
<ABSTRACT>
There exist in the literature today many contributions
dealing with the incorporation of fuzzy logic in expert
systems. But, unfortunately, much of what has been
proposed can only be applied to small-scale expert
systems, that is when the number of rules is in the
dozens as opposed to in the hundreds. The more
traditional (non-fuzzy) expert systems are able to cope
with large numbers of rules by using Rete networks for
maintaining matches of all the rules and all the facts.
(A Rete network obviates the need to match the rules
with the facts on every cycle of the inference engine.)
In this dissertation, we present a more general Rete
network that is particularly suitable for reasoning with
fuzzy logic. The generalized Rete network consists of a
cascade of three networks: the Pattern Network, the Join
Network, and the Evidence Aggregation Network. The first
two layers are modified versions of similar layers for
the traditional Rete networks, and the last, the
aggregation layer, is a new concept that allows fuzzy
evidence to be aggregated when fuzzy inferences are made
about the same fuzzy variable by different rules.
Although the reasoning architecture we have implemented
is general, it will be tested specifically in the
context of vision-guided mobile robot navigation in
indoor environments.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  3660 </NUMBER>
<ORDER>   AAG9713495 </ORDER>
<TITLE> A FUZZY RULE-BASED METHODOLOGY FOR DYNAMIC KANBAN CONTROL IN A GENERIC KANBAN SYSTEM </TITLE>
<AUTHOR> CHANG, TE-MIN </AUTHOR>
<YEAR> 1996 </YEAR>
<INSTITUTION> PURDUE UNIVERSITY; 0183 </INSTITUTION>
<DESCRIPTORS> ENGINEERING, INDUSTRIAL; OPERATIONS RESEARCH; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> Y. YIH </ADVISER>
<CLASSIFICATIONS> SIMULATED ANNEALING </CLASSIFICATIONS>
<ABSTRACT>
This research studies the dynamic control of a
production system. A particular production control
scheme in flow shops, the generic kanban system, is
under study. A generic kanban system that originates
from the Toyota Kanban system is for production control
under dynamic environments with variable demands and
processing times. To ensure good production system
performance, an appropriate number of kanbans employed
in the system is essential.
Dynamic kanban control using fuzzy rule-based systems is
proposed to dynamically adjust the number of kanbans.
The proposed methodology includes two major modules:
example extraction and fuzzy system generation. Examples
are generated from system simulation and the simulated
annealing algorithm is adopted to extract desired
examples. From desired examples, a general methodology
to generate fuzzy systems is also proposed. We aim at
generating fuzzy systems with good mapping ability and
generalization ability as well.
Experiments are conducted to evaluate the general
methodology of generating fuzzy systems and the
methodology of dynamic kanban control by using fuzzy
rule-based systems, respectively. Experimental results
show that the generated fuzzy systems have good system
performance for iris data and data recorded from Sugeno
and Yasukawa's work.
Furthermore, fuzzy systems are generated for dynamic
kanban control in a generic kanban system. Generated
fuzzy systems are evaluated on the training process from
the extracted examples and on the feasibility of
applications in general situations. Finally, system
performance obtained from the fuzzy system approach is
compared with that from the simulated annealing approach
under the same system status. Their performance does not
differ much. The fuzzy system approach, however, can be
applied more generally in situations where the simulated
annealing approach does not work. This justifies the
feasibility of the fuzzy system approach to dynamically
control the number of kanbans in a generic kanban
system.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  3661 </NUMBER>
<ORDER>   AAG9713268 </ORDER>
<TITLE> SELF-LEARNING FUZZY CONTROL OF UNKNOWN PLANTS </TITLE>
<AUTHOR> LI, CHUNSHIEN </AUTHOR>
<YEAR> 1996 </YEAR>
<INSTITUTION> UNIVERSITY OF ILLINOIS AT CHICAGO; 0799 </INSTITUTION>
<DESCRIPTORS> ENGINEERING, ELECTRONICS AND ELECTRICAL; ENGINEERING, SYSTEM SCIENCE; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> NIL </ADVISER>
<CLASSIFICATIONS> ARTIFICIAL INTELLIGENCE </CLASSIFICATIONS>
<ABSTRACT>
A self-learning fuzzy logic controller is given for
fuzzy control of unknown plants, either single-input-
single-output plants or multiple-input-multiple-output
plants. The formation mechanism of a rule base and fuzzy
inference are expressed mathematically in terms of
vectors, matrices, and other data types. A concise
formulation of fuzzy controllers for plants is
presented. Through new terminology and data types,
relations among the crisp input vector to the fuzzy
controller, the fuzzy basis set for all linguistic input
variables, the cardinality vector of fuzzy partitions in
all input universes of discourse, the rule base
linguistic value set, and the fuzzy inference action
vector (fuzzy controller outputs) are established.
The self-learning fuzzy controller is cast into a neural
net structure with six feedforward layers. The neural-
net-based fuzzy controller preserves fuzzy knowledge
representation and fuzzy inference of a fuzzy logic
controller, and it provides learning ability and
parallel structure.
The fuzzy system parameters determining the behavior of
the fuzzy logic system are systematically adapted using
a new random optimization method and a training
strategy. The fuzzy logic system learns how to control a
plant, either SISO or MIMO, from observing its
input/output behavior, so that a model of the plant is
not required. The learning algorithm is a trial-and-
error algorithm with direction toward a desired goal.
The proof of convergence for the learning algorithm is
given to assure the validation of learning. The value of
a cost function is used as the learning index to evolve
a set of parameters in the fuzzy logic system.
Applications of self-learning fuzzy control are
illustrated for SISO and MIMO plants. For SISO plants, a
linear DC motor and a nonlinear inverted pendulum system
are used for fuzzy control. For MIMO plants, a two-input-
two-output plant with real poles and a two-input-two-
output RLC circuit with complex poles are used for fuzzy
control.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  3662 </NUMBER>
<ORDER>   AAG9713190 </ORDER>
<TITLE> QUADRATIC DETECTION FILTERS AND CLASSIFIERS </TITLE>
<AUTHOR> WEBER, DAVID MICHAEL </AUTHOR>
<YEAR> 1996 </YEAR>
<INSTITUTION> CARNEGIE-MELLON UNIVERSITY; 0041 </INSTITUTION>
<DESCRIPTORS> ENGINEERING, ELECTRONICS AND ELECTRICAL; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> DAVID P. CASASENT </ADVISER>
<CLASSIFICATIONS> NEURAL NETWORKS, DECISION SURFACES, GABOR FUNCTIONS, VEHICLE DETECTION, ARTIFICIAL INTELLIGENCE </CLASSIFICATIONS>
<ABSTRACT>
We present a new detection and classification algorithm
that is capable of creating spherical, elliptical,
hyperbolic and linear decision surfaces. This new
classifier is called the extended piecewise quadratic
neural network (E-PQNN). We prove that our simple E-PQNN
architecture is able to generate piecewise quadratic
decision surfaces of arbitrary rank. For classification,
the inputs to the E-PQNN are features. For detection, we
employ the outputs from a number of separetely designed
linear Gabor filters as inputs. The E-PQNN produces
several macro filters that are complex-valued linear
combinations of the Gabor functions; the outputs from
these macro filters are passed through a magnitude
square operation and are then linearly combined using
real weights to achieve the quadratic decision surface.
For detection, the creation of macro filters allows for
a substantial computational saving by reducing the
number of correlation operations required. We
demonstrate new methods for selecting the number of
neurons in the E-PQNN for classification and detection
and for selecting the Gabor filter parameters. We
present detection results obtained for an infra-red
vehicle detection problem and classification results for
a synthetic database, a SAR classification problem and
an agricultural inspection problem.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  3663 </NUMBER>
<ORDER>   AAG9713175 </ORDER>
<TITLE> ARTIFICIAL NEURAL NETWORKS FOR THE INTERPRETATION OF GROUND PENETRATING RADAR DATA FOR INFRASTRUCTURE CONDITION ASSESSMENT  </TITLE>
<AUTHOR> HEILER, MICHAEL DOUGLASS </AUTHOR>
<YEAR> 1996 </YEAR>
<INSTITUTION> CARNEGIE-MELLON UNIVERSITY; 0041 </INSTITUTION>
<DESCRIPTORS> ENGINEERING, CIVIL; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> NIL </ADVISER>
<CLASSIFICATIONS> PAVEMENT, MOISTURE CONTENT, ASPHALT THICKNESS </CLASSIFICATIONS>
<ABSTRACT>
Properly operating infrastructure, such as
transportation networks and facilities, is essential to
the economic health of a region. Continued assessment of
the condition of such infrastructure is key to effective
management, which ultimately leads to efficient
operation. Unfortunately, the size and extent of
transportation networks in any jurisdiction makes
adequate and timely condition assessment exceedingly
difficult at best. Because of this, better methods have
been sought to improve the quality and timeliness for
condition assessment. Ground penetrating radar (GPR) has
been gaining acceptance as a tool for infrastructure
condition assessment for the past 25 years. It has been
proven to provide quicker and more complete
infrastructure network data for several infrastructure
condition attributes of interest. However, GPR
assessment at the desired level of detail creates an
immense amount of condition data. Recently, artificial
neural networks (ANNs) have been applied to the problem
of interpreting GPR condition assessment data. ANNs
allow automated interpretation of condition data in real-
time (as it is being collected), which eliminates the
problem of timeliness.
Past approaches to the interpretation of sensor data,
such as GPR condition assessment data, using ANNs have
been one-step monolithic methods. These methods involve
using a single neural network to map raw, or slightly
processed, GPR data directly to properties of the
environment, such as pavement layer thickness, or
moisture content, for pavement condition data. This
thesis describes and investigates a segmented approach
to pavement condition assessment using ANNs. This
approach follows the steps that are performed during
manual interpretation. During manual collection and
interpretation, the user varies radar settings until the
data is of sufficient quality to recognize reflection
events, and then collects the data. Event locations and
amplitudes are then determined from the data, properties
are calculated about the data, from these events, and
from these properties decisions made are in accordance
with the objectives of the investigation.
Following these steps (data quality determination, event
location determination, and parameter calculation) with
ANNs provides better condition assessment results than
performing condition assessment in one step with a
single ANN. The decision making step adds another level
of evaluation not contained in other automated methods.
For the investigation described, the segmented approach
determined asphalt layer thickness values approximately
two times more accurately than the one-step approach
performed on the same data.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  3664 </NUMBER>
<ORDER>   AAG9713166 </ORDER>
<TITLE> EXPECTATION-BASED SELECTIVE ATTENTION </TITLE>
<AUTHOR> BALUJA, SHUMEET </AUTHOR>
<YEAR> 1996 </YEAR>
<INSTITUTION> CARNEGIE-MELLON UNIVERSITY; 0041 </INSTITUTION>
<DESCRIPTORS> COMPUTER SCIENCE; ARTIFICIAL INTELLIGENCE; OPERATIONS RESEARCH </DESCRIPTORS>
<ADVISER> NIL </ADVISER>
<CLASSIFICATIONS> FOCUSING, NEURAL NETWORKS, SALIENCY MAPS, AUTONOMOUS VEHICLE CONTROL, HAND TRACKING, OBJECT DETECTION, ARTIFICIAL INTELLIGENCE, WAFER FABRICATION, ANOMALY DETECTION, PLASMA ETCH, FACE DETECTION </CLASSIFICATIONS>
<ABSTRACT>
In many real-world tasks, the ability to focus attention
on the relevant portions of the input is crucial for
good performance. This work has shown that, for
temporally coherent inputs, a computed expectation of
the next time step's inputs provides a basis upon which
to focus attention. Expectations are useful in tasks
which arise in visual and non-visual domains, ranging
from scene analysis to anomaly detection.
When temporally related inputs are available, an
expectation of the next input's contents can be computed
based upon the current inputs. A saliency map, which is
based upon the computed expectation and the actual
inputs, indicates which inputs will be important for
performing the task in the next time step. For example,
in many visual object tracking problems, the relevant
features are predictable, while the distractions in the
scene are either unpredictable or unrelated to the task.
The task-specific selective attention methods can be
used to create a saliency map which accentuates only the
predictable inputs that are useful in solving the task.
In a second use of expectation, anomaly detection, the
unexpected features are important. Here, the role of
expectation is reversed; it is used to emphasize the
unpredicted features.
The performance of these methods is demonstrated in
artificial neural network based systems on two real-
world vision tasks: lane-marker tracking for autonomous
vehicle control and driver monitoring, and hand tracking
in cluttered scenes. For the hand-tracking task,
techniques for incorporating a priori available domain
knowledge are presented. These methods are also
demonstrated in a non-vision based task: anomaly
detection in the plasma etch step of semiconductor wafer
fabrication.
In addition to explicitly creating a saliency map to
indicate where a network should pay attention,
techniques are developed to reveal a network's implicit
saliency map. The implicit saliency map represents the
portions of the input to which a network will pay
attention in the absence of the explicit focusing
mechanisms developed in this thesis. Methods to examine
the features a network has encoded in its hidden layers
are also presented. These techniques are applied to
networks trained to perform face-detection in arbitrary
visual scenes. The results clearly display the facial
features the network determines to be the most important
for face detection. These techniques address one of the
largest criticisms of artificial neural networks--that
it is difficult to understand what they encode.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  3665 </NUMBER>
<ORDER>   AAG9712985 </ORDER>
<TITLE> WORLDS OF CHANGE: COUNTERFACTUAL REASONING AND CAUSATION </TITLE>
<AUTHOR> ORTIZ, CHARLES LOUIS, JR. </AUTHOR>
<YEAR> 1996 </YEAR>
<INSTITUTION> UNIVERSITY OF PENNSYLVANIA; 0175 </INSTITUTION>
<DESCRIPTORS> COMPUTER SCIENCE; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> NIL </ADVISER>
<CLASSIFICATIONS> ARTIFICIAL INTELLIGENCE </CLASSIFICATIONS>
<ABSTRACT>
The development of a commonsense theory of causation has
often been pursued along a number of, somewhat
orthogonal, directions. The work contained herein
examines the role that counterfactual reasoning can play
within such a theory. The sorts of inferences one might
draw in the course of causal attribution is first
examined; this pre-theoretic analysis is conducted
within the context of a rich microworld involving a
number of agents engaged in purposeful behavior. A new
theory of change, Explanatory Update Theory (EUT) is
developed in which: (1) a syntactic version of belief
updating underlies the semantics of counterfactuals and
in which events and time are explicitly represented at
the object level; (2) a new solution to the frame
problem is presented based on a notion of support for a
proposition which corrects a number of problems with
existing approaches involving unexplainable events, the
need for persistence rules, explanation in the context
of incompletely specified causal chains, and event
ramifications; (3) the solution to the frame problem is
integrated with the semantics for counterfactuals; and
(4) the epistemic preferences that underly the choice of
alternative worlds in accommodating a counterfactual
supposition in the course of causal attribution is
carefully articulated. EUT is then shown to correctly
handle a number of standard benchmark problems as well
as a number of new benchmarks emerging from the
microworld study. A commonsense causal language is
formalized consisting of terms such as preventing,
enabling, maintaining, letting, helping, hindering, and
so forth. The utility of counterfactual reasoning in
supporting the production of causal explanations
involving negative event descriptions is also
demonstrated. A stratified view of causal reasoning is
shown to emerge in which the utility of counterfactuals
manifests itself in two ways. First, as useful tools in
isolating the role that an event played in some nexus of
events, and also as providing an efficient means for
combining both causal and non-causal knowledge in the
production of causal explanations.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  3666 </NUMBER>
<ORDER>   AAG9712834 </ORDER>
<TITLE> AN INTELLIGENT SYSTEM FOR SURFACE EMG-BASED POSITION TRACKING OF HUMAN ARM MOVEMENTS FOR THE CONTROL OF MANIPULATORS </TITLE>
<AUTHOR> SURYANARAYANAN, SRIKANTH </AUTHOR>
<YEAR> 1996 </YEAR>
<INSTITUTION> THE UNIVERSITY OF AKRON; 0003 </INSTITUTION>
<DESCRIPTORS> ENGINEERING, BIOMEDICAL; ARTIFICIAL INTELLIGENCE; HEALTH SCIENCES, PHYSICAL THERAPY </DESCRIPTORS>
<ADVISER> NIL </ADVISER>
<CLASSIFICATIONS> ELBOWS, NEURAL NETWORKS, FUZZY LOGIC, ARTIFICIAL INTELLIGENCE, ROBOTICS, VIRTUAL REALITY </CLASSIFICATIONS>
<ABSTRACT>
The design of a natural and a synergistic interface is
essential to improve the human performance in a
telemanipulation or a Virtual Reality (VR) system. Bio-
electric signals, such as surface electromyogram (EMG),
are being researched as alternate interfacing strategies
for human arm position tracking and direct bio-control.
An understanding of human joint dynamics is required to
design a bio-electric interface for arm position
tracking. Due to the complex nature of EMG signal and
its relation to joint dynamics, an intelligent system is
required to predict movements using surface EMG.
The overall objective of this study was to design a
surface EMG based interface to track arm movements about
the elbow joint. An intelligent system, consisting of
neural networks and fuzzy logic, was developed to
predict the elbow joint angle. The interface was
evaluated on a computer simulated model of a robot.
Normal subjects were asked to perform flexion-extension
movements at various angles and speeds, as well as
pronate their arms. Surface EMG signals were measured
from the biceps muscle during flexion and from pronator
teres during pronation of the arm. The joint angle at
the elbow was measured using a goniometer. A signal
processing module was developed to analyze the surface
EMG signals and extract time varying magnitude-based
parameters. The neural network was trained to predict
the elbow joint angle using the magnitude and slope of
the processed EMG signal. The fuzzy logic system
computed an adaptive gain that compensated for changes
in the biceps EMG signal due to variation in the speed
of flexion. The interface was evaluated on a computer
simulated model of a robot. The actual joint angle
measured by the goniometer was compared against the
joint angle predicted by the intelligent system and
against the angle reproduced by the robot model. The
coefficient of correlation between the actual joint
angle and the predicted joint angle as well as the
reproduced joint angle was calculated.
The intelligent system predicted the joint angle with
average RMS errors of 5-25%. The correlation coefficient
between the actual and the predicted joint angle was
0.92 with the arm in a supine position, 0.75 with the
arm in a semi-prone position, and less than 0.5 with the
arm in a prone position. The system accurately predicted
for various angles and speeds of flexion, but the
accuracy of the prediction decreased with the arm
rotated (pronation). The average delay in tracking due
to computations associate with the signal processing and
the intelligent system was 0.2s. The robot model also
reproduced the joint angle with RMS errors of 5-25%. The
correlation coefficient between the actual and the
reproduced joint angle was 0.9 when the arm was in a
supine position. The overall delay in tracking due to
the intelligent system and the robot model was 0.5s.
The study has demonstrated a unique and novel approach
to position tracking and bio-control of telemanipulators
and VR environments using surface EMG. It also
represents a significant advancement in human joint
dynamics. A successful attempt has been made to predict
elbow joint angle using surface EMG with the aid of an
intelligent system. The interface has several important
applications in medicine, and perhaps the most
significant one is towards the rehabilitation of
paraplegics for myoelectric control of robotic assist
devices.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  3667 </NUMBER>
<ORDER>   AAG9712678 </ORDER>
<TITLE> EVOLUTION-ASSISTED DISCOVERY OF SENTINEL FEATURES IN EPIDEMIOLOGIC SURVEILLANCE </TITLE>
<AUTHOR> HOLMES, JOHN H. </AUTHOR>
<YEAR> 1996 </YEAR>
<INSTITUTION> DREXEL UNIVERSITY; 0065 </INSTITUTION>
<DESCRIPTORS> COMPUTER SCIENCE; HEALTH SCIENCES, PUBLIC HEALTH; INFORMATION SCIENCE; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> NIL </ADVISER>
<CLASSIFICATIONS> ARTIFICIAL INTELLIGENCE </CLASSIFICATIONS>
<ABSTRACT>
The use of a genetics-based classifier system (CS) in
generating epidemiologic hypotheses was investigated. In
addition, epidemiologic analytical techniques were used
to evaluate the performance of a CS in this problem
domain. Five component studies were implemented, using
epidemiologic surveillance data over a range of
prevalences. The evaluation study investigated the use
of the area under the receiver operating characteristic
curve $(theta)$ as an alternative to crude accuracy (CA)
during the training period. The classification study
examined the ability of the CS to classify unencountered
patients. The reproducibility study demonstrated the
stochastic processes underlying CS performance during
training and testing. The payoff-penalty
parameterization study investigated the effects of
differential penalty for false negative and false
positive decisions on learning rate and classification
ability. The risk assessment study examined the ability
of a CS to derive estimates of risk for purposes of
classification. At 50% prevalence, $theta$ was identical
to CA over the entire training period; with decreasing
prevalence, CA increasingly overestimated the learning
rate, while $theta$ provided more accurate depictions of
this measure. Across all four prevalences investigated,
the CS was able to classify unseen patients well, with
$theta$s ranging from 0.95 at 50% prevalence to 0.78 at
10%. The classifier populations after training indicated
considerable generalization; decision rules were
discernible on visual examination. When trained and
tested using 1,000 different data sets drawn from the
same pool, the CS was fairly consistent in terms of
learning rate and classification ability, although with
sufficient variation to warrant investigating the use of
bootstrapping techniques. Biasing the ratio of false
positive to false negative (FP:FN) decisions affected
the learning rate relative to prevalence. Learning rate
was most enhanced at 25% and 10% prevalence by a FP:FN
ratio of 4:1 and 10:1, respectively. Across all four
prevalences, the CS was able to produce risk estimates
that consistently outperformed decision rules derived
using logistic regression. The CS was shown to be a
useful adjunct to hypothesis generation during
epidemiologic surveillance.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  3668 </NUMBER>
<ORDER>   AAG1385194 </ORDER>
<TITLE> NEW ACCELERATION TECHNIQUE FOR THE BACKPROPAGATION ALGORITHM  </TITLE>
<AUTHOR> SADHU, PRASAD DURGA </AUTHOR>
<YEAR> 1996 </YEAR>
<INSTITUTION> UNIVERSITY OF NEVADA, LAS VEGAS; 0506 </INSTITUTION>
<DESCRIPTORS> COMPUTER SCIENCE; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> NIL </ADVISER>
<CLASSIFICATIONS> NEURAL NETWORKS, ARTIFICIAL INTELLIGENCE </CLASSIFICATIONS>
<ABSTRACT>
Artificial neural networks have been studied for many
years in the hope of achieving human like performance in
the area of pattern recognition, speech synthesis and
higher level of cognitive process. In the connectionist
model there are several interconnected processing
elements called the neurons that have limited processing
capability. Even though the rate of information
transmitted between these elements is limited, the
complex interconnection and the cooperative interaction
between these elements results in a vastly increased
computing power.
The neural network models are specified by an organized
network topology of interconnected neurons. These
networks have to be trained in order them to be used for
a specific purpose. Backpropagation is one of the
popular methods of training the neural networks. There
has been a lot of improvement over the speed of
convergence of standard backpropagation algorithm in the
recent past. Herein we have presented a new technique
for accelerating the existing backpropagation without
modifying it. We have used the fourth order
interpolation method for the dominant eigen values, by
using these we change the slope of the activation
function. And by doing so we increase the speed of
convergence of the backpropagation algorithm.
Our experiments have shown significant improvement in
the convergence time for problems widely used in
benchmarking. Three to ten fold decrease in convergence
time is achieved. Convergence time decreases as the
complexity of the problem increases. The technique
adjusts the energy state of the system so as to escape
from local minima.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  3669 </NUMBER>
<ORDER>   AAG9712321 </ORDER>
<TITLE> CHANGE OF REPRESENTATION IN MACHINE LEARNING, AND AN APPLICATION TO PROTEIN STRUCTURE PREDICTION </TITLE>
<AUTHOR> IOERGER, THOMAS RICHARD </AUTHOR>
<YEAR> 1996 </YEAR>
<INSTITUTION> UNIVERSITY OF ILLINOIS AT URBANA-CHAMPAIGN; 0090 </INSTITUTION>
<DESCRIPTORS> COMPUTER SCIENCE; ARTIFICIAL INTELLIGENCE; CHEMISTRY, PHYSICAL </DESCRIPTORS>
<ADVISER> LARRY A. RENDELL </ADVISER>
<CLASSIFICATIONS> ARTIFICIAL INTELLIGENCE </CLASSIFICATIONS>
<ABSTRACT>
While many excellent induction algorithms are known for
making predictions from databases in well-studied
domains, learning systems still perform poorly in many
difficult real-world domains, such as weather prediction
or financial risk analysis. Two characteristics of real-
world domains are inadequately addressed by current
machine learning research. First, the difficulty in
these domains is often caused by a low-level
representation, which necessitates shifting to a higher-
level representation. But the space of possible
representations is very large, so we need intelligent
methods for finding higher-level representations.
Second, background knowledge is almost always available
in real-world domains, which we would like to take
advantage of to increase predictive accuracy. However,
known roles for domain knowledge in machine learning are
often inflexible, requiring the use of a specific
induction algorithm or being sensitive to incorrectness
or incompleteness in the knowledge.
We propose a general framework for change-of-
representation based on searching for alternative
representations to improve the accuracy of an underlying
induction algorithm. Representations are selected as
candidates by querying a strategy component, which
relies on domain knowledge to suggest which alternatives
to search. An evaluation component then compares these
representations by applying each representation to a set
of examples and running the induction algorithm on the
transformed examples to empirically determine the effect
of the change on accuracy. This approach provides
solutions to the two characteristic problems of learning
in real-world domains. First, domain knowledge is used
as a heuristic to guide the search for alternative
representations, enabling more intelligent decisions
during change-of-representation. Second, the framework
provides a flexible role for knowledge that can be used
with any learning algorithm and is tolerant of
uncertainty. An implementation of this framework could
be used as an interface between a human expert and a
learning program in which: (1) the human uses background
knowledge to generate and prioritize alternative
representations, and (2) the system empirically
evaluates these to discover the best change for
improving accuracy.
We apply our framework for change-of-representation to
the difficult, real-world domain of protein tertiary
(3D) structure prediction. The best computational method
to date for determining the structure of a protein from
its amino acid sequence is homology modeling, which is
based on sequence alignments with a protein database.
Homology modeling can fail in cases where the sequence
similarity is low between proteins with similar
structures. However, the physical and chemical
properties of amino acids are believed to relevant to
protein structure. Using an instantiation of our
framework, we incorporate this domain knowledge to
suggest ways to change the representation of amino acid
sequences. Efficient search procedures are derived from
the knowledge that lead to the discovery of
representations that improve the ability to predict
protein structures by homology modeling.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  3670 </NUMBER>
<ORDER>   AAG9712259 </ORDER>
<TITLE> KNOWLEDGE-GUIDED CONSTRUCTIVE INDUCTION </TITLE>
<AUTHOR> DONOHO, STEVEN KIRK </AUTHOR>
<YEAR> 1996 </YEAR>
<INSTITUTION> UNIVERSITY OF ILLINOIS AT URBANA-CHAMPAIGN; 0090 </INSTITUTION>
<DESCRIPTORS> COMPUTER SCIENCE; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> LARRY RENDELL </ADVISER>
<CLASSIFICATIONS> DOMAIN KNOWLEDGE, MACHINE LEARNING, ARTIFICIAL INTELLIGENCE, TURFGRASS MANAGEMENT </CLASSIFICATIONS>
<ABSTRACT>
The relationship between constructive induction and
domain knowledge can be analyzed systematically. Recent
research has integrated knowledge and constructive
induction in isolated domains with some success, but
undue emphasis is often given to the technique developed
rather than the underlying phenomena. In contrast,
understanding how knowledge affects a domain's
constructed feature space and instance space allows us
to find better techniques more easily. Three case
studies (bankruptcy, turfgrass management, and
promoters) demonstrate how analysis of knowledge drives
development of techniques. Although knowledge in each
domain has its peculiarities, general relationships may
be discovered that lead to a more principled approach to
incorporating knowledge into constructive induction.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  3671 </NUMBER>
<ORDER>   AAG9712257 </ORDER>
<TITLE> SENSORY FEEDBACK AND CONTROL OF LEG-SUBSTRATE INTERACTIONS IN INSECTS AND ROBOTS </TITLE>
<AUTHOR> DING, ZHIMIN </AUTHOR>
<YEAR> 1996 </YEAR>
<INSTITUTION> UNIVERSITY OF ILLINOIS AT URBANA-CHAMPAIGN; 0090 </INSTITUTION>
<DESCRIPTORS> BIOLOGY, NEUROSCIENCE; ENGINEERING, ELECTRONICS AND ELECTRICAL; COMPUTER SCIENCE; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> MARK E. NELSON </ADVISER>
<CLASSIFICATIONS> MACHINE LEARNING, LOCOMOTION, NAVIGATION </CLASSIFICATIONS>
<ABSTRACT>
Sensory feedback plays an important role in adaptive
control of insect leg movements as required, for
example, in agile locomotion over irregular terrain.
Functionally, insect legs are not just effectors--they
are also sophisticated sensory devices that provide the
nervous system with a great deal of information about
the dynamic state of the leg and interactions with its
environment. Most previous research on the neural
control of multilegged locomotion has focused on the
problem of pattern generation, namely on how to produce
appropriately phased patterns of bursting activity in
leg motor neurons so as to generate stable walking
gaits. Fixed pattern generation alone, however, is not
sufficient to achieve agile locomotion over irregular
terrain.
To investigate the role of sensory feedback from leg
sense organs in movement control we have developed
simulation software that allows us to study the dynamic
interactions of all the elements in the sensory-motor
loop: the neural controller, sensors, actuators, leg
dynamics and interactions between the leg and its
environment. We also develop and test ideas about
sensory feedback in a physical robotic leg which
incorporate many of the functionally important
characteristics of insect legs. Each leg segment is
equipped sensors that provide information similar to the
ones found on insect legs. We modified the joint
actuators to emulate the dynamics of antagonistic muscle
pairs. Real-time neural controllers are implemented
using digital signal processor technology.
We describe neural controllers that implement a
substrate-finding reflex in which the leg searches for
and establishes a foothold on a spatially-restricted
support. By analyzing relatively simple single leg
reflexes, we demonstrate how rhythmic and adaptive
behavior can appear as an emergent property of the
coupled dynamics of the components of the sensory-motor
loop. Using this platform as our testbed, we also
explore the use of genetic algorithms and on-line
learning algorithms to optimize the design of neural
controllers.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  3672 </NUMBER>
<ORDER>   AAG9712112 </ORDER>
<TITLE> RELIABILITY QUANTIFICATION OF ADVANCED REACTOR PASSIVE SAFETY SYSTEMS  </TITLE>
<AUTHOR> VANDENKIEBOOM, JOHN JOSEPH </AUTHOR>
<YEAR> 1996 </YEAR>
<INSTITUTION> THE UNIVERSITY OF MICHIGAN; 0127 </INSTITUTION>
<DESCRIPTORS> ENGINEERING, NUCLEAR; ENERGY; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> JOHN C. LEE; EMERITUS WILLIAM KERR </ADVISER>
<CLASSIFICATIONS> COOLING, ARTIFICIAL INTELLIGENCE </CLASSIFICATIONS>
<ABSTRACT>
An incremental query learning algorithm is developed for
generating an accurate representation of a surface
defined in terms of a scalar function that can be
nonlinear and computationally expensive to evaluate. The
algorithm makes combined use of (1) an artificial neural
network (ANN), as an efficient nonlinear mapping tool,
to accurately map a complex surface represented by a set
of training examples and (2) a genetic algorithm (GA),
as a general optimization tool, to optimally locate new
examples sequentially in untested regions of the
surface. A training set, each point of which corresponds
to a function evaluation, is constructed by optimizing
an objective function, formulated to have maximum values
at points both near the surface and far from existing
points of the set.
The combined ANN-GA algorithm is used in quantifying the
reliability of the passive containment cooling system
(PCCS) of the Simplified Boiling Water Reactor. The
performance of the PCCS, subject to a main steam line
break inside containment, is modeled with the CONTAIN
thermal-hydraulics code. The limit surface, separating
the regions of PCCS success and failure in a space of
five system variables, is generated with 130 points,
each of which represents a CONTAIN run. The points were
selected sequentially by the incremental learning
algorithm and represent varying levels of component
degradations. With an ANN approximation to the limit
surface, we calculated the probability of the PCCS
failing to maintain containment pressure within its
design limit of 0.483 MPa, through Monte Carlo
integrations of the probability density functions for
the system variables. The representation of five
concurrent system degradations, including the drywell-
suppression chamber leakage, yields a two-fold increase
in the PCCS unreliability over that accounting for the
leakage alone. Although such an increase is generally
expected, our study clearly illustrates the importance
of explicitly accounting for multiple component
degradations through a continuum limit surface
representation.
Using the ANN-GA incremental learning algorithm, we were
able to minimize the number of production CONTAIN runs
needed to accurately represent the PCCS limit surface
and quantify the performance reliability. The ANN-GA
algorithm is general and should provide efficient
unsupervised learning capability for the analysis of
other complex nonlinear systems.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  3673 </NUMBER>
<ORDER>   AAG9712110 </ORDER>
<TITLE> POLITE RESCHEDULING: RESPONDING TO SCHEDULE DISRUPTIONS IN A MULTI-AGENT MANUFACTURING SYSTEM </TITLE>
<AUTHOR> TSUKADA, THOMAS KAEPPEL </AUTHOR>
<YEAR> 1996 </YEAR>
<INSTITUTION> THE UNIVERSITY OF MICHIGAN; 0127 </INSTITUTION>
<DESCRIPTORS> COMPUTER SCIENCE; ENGINEERING, INDUSTRIAL; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> KANG G. SHIN </ADVISER>
<CLASSIFICATIONS> ARTIFICIAL INTELLIGENCE </CLASSIFICATIONS>
<ABSTRACT>
Flexible manufacturing systems must be able to respond
to unexpected events. Polite rescheduling is an
intelligent way for a manufacturing cell controller to
respond to schedule disruptions (e.g., machine break-
down or new job arrival), when other cells in the
manufacturing system may be adversely affected by the
response. Local schedules at different cells may
interact through resource sharing and precedence
constraints; thus, local scheduling changes at one cell
may disrupt schedules at other cells. At worst, one
local schedule disruption may propagate throughout the
entire system. The polite rescheduling approach attempts
to respond to schedule disruptions so that other agents
are disrupted as little as possible, and so that the
propagation of disruptions can be contained. This
approach has the advantage of retaining much of any
original distributed plan.
Reasoning about how local scheduling decisions may
affect other cells often requires information about
other cells' states that is not available locally.
Negotiation with other possibly-affected cells may be
necessary for determining which local scheduling
decisions are most appropriate. Polite rescheduling thus
brings together ideas and techniques from the fields of
distributed artificial intelligence, factory scheduling,
and plan revision. It requires reasoning about global
constraints on local scheduling decisions, about how
negotiation with other cells may be pursued efficiently,
and about how current schedules may be modified to
satisfy new requirements.
We apply this concept to the domains of tool management
and scheduling, and job shop scheduling, and evaluate
the proposed method through simulation. We show that
polite rescheduling, which is local rescheduling using
local knowledge, performs close to good or optimal
methods that use global information, when workcells are
loosely-coupled; our method is appropriate for example
when workcells share one or two tools, or in job shops
in which work tends to flow in one direction. We also
propose PRIAM, a polite rescheduling architecture, in
which a negotiator module determines scheduling
priorities through evaluation of local information and
information gathered through negotiation, and a
rescheduler module, which uses various scheduling
methods to produce a revised schedule with these
priorities in mind. We investigate various ways
priorities can be determined using local knowledge or
uncertain information about remote cells' requirements,
and various scheduling methods by which constraints
imposed by remote cells can be satisfied.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  3674 </NUMBER>
<ORDER>   AAG9712059 </ORDER>
<TITLE> THE BEHAVIORAL ECOLOGY OF THE GLOSSY BLACK-COCKATOO CALYPTORHYNCHUS LATHAMI HALMATURINUS </TITLE>
<AUTHOR> PEPPER, JOHN WILLIAM </AUTHOR>
<YEAR> 1996 </YEAR>
<INSTITUTION> THE UNIVERSITY OF MICHIGAN; 0127 </INSTITUTION>
<DESCRIPTORS> BIOLOGY, ECOLOGY; BIOLOGY, ZOOLOGY; AGRICULTURE, FORESTRY AND WILDLIFE </DESCRIPTORS>
<ADVISER> RICHARD D. ALEXANDER </ADVISER>
<CLASSIFICATIONS> SOCIAL BEHAVIOR, FORAGING, ALLOCASUARINA VERTICILLATA </CLASSIFICATIONS>
<ABSTRACT>
Parrots are unusual in their relative brain size and
apparent intelligence in captivity, but little is known
of their natural behavior. I studied a habituated flock
of glossy black-cockatoos on Kangaroo Island, South
Australia, in 1991-1993. I photographed plumage markings
for individual identification, and used binoculars
during focal follows and scan samples.
The subspecies fed almost exclusively on seeds of the
drooping sheoak tree (Allocasuarina verticillata), and
spent most of their time extracting seeds. Preferred
trees yielded more nutritious seed at a higher rate than
other trees.
I generated an ethogram of vocal and non-vocal behaviors
for use in further analyses. Mated pairs remained
together within groups year round, and no divorces were
observed. Proximity within mated pairs was uncorrelated
with both breeding season and actual nesting, and was
not explained by male mate guarding. Pair bonds do
function as alliances in resource competition within
groups. The cockatoos temporarily defended individual
feeding trees and nest hollows, but were not
territorial. Non-random association patterns existed
between pairs, but were not stable across years.
Supplants revealed a linear dominance hierarchy with
paired above unpaired birds, and adults above subadults.
Preferences for one side in symmetric behaviors have
been studied in other animals as evidence of brain
organization and evolution. Glossy black-cockatoos show
extreme population-level laterality in manipulating food
with the foot, bill and tongue. Laterality involving
central rather than paired appendages is inconsistent
with functional explanations based on brain asymmetry. I
propose a new hypothesis based on the advantage
laterality provides in repetitive learning of complex
motor skills.
I describe a new and widely applicable method for
measuring social affinity from group composition data
using computer randomization.
A survey of the subspecies found 136 birds, including
90% adults and 1.4 males per female. Foraging habitat
was fragmented and reduced by land clearance to 1477 ha.
The best predictors of distribution were quantity and
quality of foraging habitat. A population viability
analysis suggested the reproductive rate is critically
low. I present a recovery plan comprising further
research, habitat protection and re-establishment,
provision of artificial nest boxes, and eventual
reintroduction to the mainland.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  3675 </NUMBER>
<ORDER>   AAG9712057 </ORDER>
<TITLE> LEARNING PROCEDURAL PLANNING KNOWLEDGE IN COMPLEX ENVIRONMENTS  </TITLE>
<AUTHOR> PEARSON, DOUGLAS JOHN </AUTHOR>
<YEAR> 1996 </YEAR>
<INSTITUTION> THE UNIVERSITY OF MICHIGAN; 0127 </INSTITUTION>
<DESCRIPTORS> COMPUTER SCIENCE; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> JOHN E. LAIRD </ADVISER>
<CLASSIFICATIONS> ARTIFICIAL INTELLIGENCE </CLASSIFICATIONS>
<ABSTRACT>
In complex, dynamic environments, an agent's knowledge
of the environment (its domain knowledge) will rarely be
complete and correct. Existing approaches to learning
and correcting domain knowledge have focused on either
learning procedural knowledge to directly guide
execution (e.g. reinforcement learners) or learning
declarative planning knowledge (e.g. theory revision
systems). Systems that only learn execution knowledge
are generally only applicable to small domains. In these
domains it is possible to learn an execution policy that
covers the entire state space, making planning
unnecessary. Conversely, existing approaches to learning
declarative planning knowledge are applicable to large
domains, but they are limited to simple agents, where
actions produce immediate, deterministic effects in
fully sensed, noise-free environments, and where there
are no exogenous events.
This research investigates the use of procedural
knowledge to support the learning of planning knowledge
in large and complex environments. We describe a series
of environmental properties that constrain learning and
are violated by existing approaches to learning planning
knowledge. We then present an operator-based
representation for planning knowledge that is
sufficiently expressive to model complex, conditional
actions that produce sequential effects over time. We
then present IMPROV, a system for learning and
correcting errors in this planning knowledge that only
requires procedural access to the knowledge. This
procedural restriction ensures that learning remains
tractable, even over these large, expressive
representations. We first explain how IMPROV
incrementally learns operator precondition knowledge. We
then demonstrate how a hierarchical, operator-based
representation can be used to reduce the problem of
learning operator effects to the problem of learning
operator preconditions. This result allows IMPROV to use
a single learning method to learn both operator
preconditions and effects. This also allows IMPROV to
learn complex models of actions that produce conditional
or sequential effects. Finally, we test the system in
two sample domains and empirically demonstrate that it
satisfies many of the constraints faced by learning
agents in complex and challenging environments.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  3676 </NUMBER>
<ORDER>   AAG9711991 </ORDER>
<TITLE> PLAN-BASED PLAN RECOGNITION MODELS FOR THE EFFECTIVE COORDINATION OF AGENTS THROUGH OBSERVATION </TITLE>
<AUTHOR> HUBER, MARCUS JAMES </AUTHOR>
<YEAR> 1996 </YEAR>
<INSTITUTION> THE UNIVERSITY OF MICHIGAN; 0127 </INSTITUTION>
<DESCRIPTORS> COMPUTER SCIENCE; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> EDMUND H. DURFEE </ADVISER>
<CLASSIFICATIONS> BELIEF NETWORKS, PROCEDURAL REASONING, ARTIFICIAL INTELLIGENCE </CLASSIFICATIONS>
<ABSTRACT>
Our research is aimed at providing agents with the
ability to use observations of actions taken by others
not only to recognize current actions but also to infer
ongoing plans and goals, a process called plan
recognition. Once our agents can recognize the plans and
goals of others, they can then employ a number of
techniques for coordinating their planned actions with
those of others. Multi-agent coordination has typically
been performed using explicit communication between
agents. Plan recognition offers several potential
advantages over explicit communication however,
including lower communication overhead, higher
reliability, greater information content, and robustness
in the face of agents who are not forthcoming about
their plans. On the other hand, it also has potential
disadvantages, including the fact that agents need to
know how other agents act in pursuit of their goals,
that actions might not be accurately observable or might
support multiple possible plans, and that inferring the
plans of others can be more time consuming than being
told explicitly by them.
In this research, we have developed a probabilistic plan
recognition model called a plan recognition network
(PRN) and a computational system called ASPRN (Automated
Synthesis of Plan Recognition Networks) that can
automatically construct a PRN from a plan model. PRNs
provide an observing agent with a wide range of inferred
information and handle the uncertainty associated with
plan recognition and observations in a natural, robust
manner. We demonstrate that plan recognition can be done
in a competitive, real-time, simulated environment such
that plan recognizing agents win up to 90% of the time,
despite the inherent overhead and uncertainty of the
recognition process. Our experiments reveal that even
though PRNs provide numeric information, they may
currently be more amenable to symbolic reasoning method
than decision-theoretic approaches. Other experiments
highlight that waiting for plan recognition information
to become more certain before acting upon it reduces
coordination performance because of the delay before
imitation of coordination activities. Analysis of our
experiments also highlights that the temporal
distribution of observations while performing plan
recognition has a distinctly negative impact upon the
observing agent's ability to effectively coordinate as
the distribution is pushed later toward the end of plan
execution. Lastly, our experiments show us that
coordinating agents can take advantage of plans with
early plan disambiguation points and that plans with
late plan disambignation points may hinder effective
plan recognition-based coordination.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  3677 </NUMBER>
<ORDER>   AAG9711932 </ORDER>
<TITLE> SEQUENTIAL COMPOSITION OF DYNAMICALLY DEXTEROUS ROBOT BEHAVIORS  </TITLE>
<AUTHOR> BURRIDGE, ROBERT RAVEN </AUTHOR>
<YEAR> 1996 </YEAR>
<INSTITUTION> THE UNIVERSITY OF MICHIGAN; 0127 </INSTITUTION>
<DESCRIPTORS> COMPUTER SCIENCE; ENGINEERING, ELECTRONICS AND ELECTRICAL; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> DANIEL KODITSCHEK </ADVISER>
<CLASSIFICATIONS> ARTIFICIAL INTELLIGENCE </CLASSIFICATIONS>
<ABSTRACT>
In this thesis we present a technique for the
composition of robot control laws in dynamical
environments. We propose a challenging robotic task,
called Dynamical Pick and Place, in which a robot
equipped with merely a soft paddle must capture and
contain a ball, safely negotiate it past obstacles, and
bring it to rest at a desired location. We develop a
composition technique for local controllers that
provides a formal guarantee of the stability of the
switching behavior required in this task, and provide
descriptive statistics of a working implementation. Our
robotic system displays unusually dexterous behavior in
the face of significant system noise, and recovers
gracefully from large unexpected perturbations caused by
the experimenters.
Our approach to controller composition makes use of the
funnel as a metaphor for asymptotic stability, is
motivated by the pre-image backchaining techniques
developed by Lozano-Perez, Mason and Taylor, and extends
their ideas from quasi-static environments to systems
with full dynamics. We introduce the concepts of
"dynamical obstacle avoidance" and "dynamical safety"
for systems with only intermittent control of their
environment, and show that it is important not only that
the system avoid obstacles directly, but also that the
system will never reach an obstacle before getting
another chance to effect control.
The Dynamical Pick and Place problem addressed by this
thesis is a difficult control problem, but an easy
planning problem. The system we develop provides a way
to engage more powerful AI planning tools without
sacrificing access to the stability arguments of
dynamical systems theory.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  3678 </NUMBER>
<ORDER>   AAG1383940 </ORDER>
<TITLE> A NATURAL LANGUAGE PROCESSOR WITH NEURAL NETWORKS </TITLE>
<AUTHOR> MARTINEZ-VARGAS, WILFRED M. </AUTHOR>
<YEAR> 1996 </YEAR>
<INSTITUTION> UNIVERSITY OF PUERTO RICO, MAYAGUEZ (PUERTO RICO); 0553 </INSTITUTION>
<DESCRIPTORS> COMPUTER SCIENCE; MATHEMATICS; ENGINEERING, ELECTRONICS AND ELECTRICAL; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> NIL </ADVISER>
<CLASSIFICATIONS> NIL </CLASSIFICATIONS>
<ABSTRACT>
A Natural Language Processor (NLP) for a multilingual
computer interface is presented. This NLP or NAtural
Language PROcessor with Neural Networks (NALPRONN)
demonstrates that artificial neural networks can be used
in such systems. NALPRONN implements a generalized NLP
system that emphasizes the modularity, adaptability, and
flexibility properties that are used in a number of
computer applications. It processes information for
different application language subsets and redirects
information to a specific active application. NALPRONN
has processing modules which are backpropagation
networks, and memory modules which are self-organized
feature map networks. Additional networks can be added
for further processing tasks. The processing modules are
the input subsystem and the output subsystem, and the
memory modules are the lexicon subsystem and the monitor
subsystem.
The NALPRONN system is a generalized, large-scale NLP
that is implemented at the subsymbolic level, that is,
the creation of the NLP follows a connectionist
approach. Using the characteristical symbolism of the
artificial neural network technology, the processing is
performed with distributed arrangements that are far
removed from the physical structures of language
communication. The system sets the basis for the
implementation of more versatile NLP systems which would
be able to communicate in a near natural fashion under
different environments. (Abstract shortened by UMI.)
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  3679 </NUMBER>
<ORDER>   AAG9711319 </ORDER>
<TITLE> AN ARTIFICIAL NEURAL NETWORK FOR WIND-INDUCED DAMAGE POTENTIAL TO NONENGINEERED BUILDINGS </TITLE>
<AUTHOR> SANDRI, PRAVEEN </AUTHOR>
<YEAR> 1996 </YEAR>
<INSTITUTION> TEXAS TECH UNIVERSITY; 0230 </INSTITUTION>
<DESCRIPTORS> ENGINEERING, CIVIL; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> KISHOR C. MEHTA </ADVISER>
<CLASSIFICATIONS> NIL </CLASSIFICATIONS>
<ABSTRACT>
Extreme winds such as hurricanes and tornadoes can be
extremely destructive and result in catastrophic
property losses and the tragic loss of human lives. The
need to predict damage and reduce the loss of life and
property is becoming more and more important with every
passing windstorm.
Artificial Neural Networks (ANN) provide a novel
approach for representing the wind-induced damage
prediction model. Modeled loosely after the biological
neural networks of the human brain, ANN are generally
used in situations where the interactions between the
input and the output variable is too complicated for an
analytical solution or where there is an insufficient
understanding of the problem domain. Predicting wind-
induced damage, however, is not a simple task due to the
complex, subjective nature, and limited understanding,
of the wind effects on buildings in extreme winds. This
research concentrates on the investigation of the
applicability of neural networks to wind-induced damage
prediction, as well as the corresponding implementation
issues. Even after years of post disaster windstorm
damage investigations, consistent, complete and robust
damage information is not available to train the ANN.
Thus, synthetic data instead of real building damage
information is being used. WIND-RITE$spcircler$, a
knowledge based expert system for grading individual
buildings in windstorms, is being used to provide the
necessary damage information for the synthetic data.
This research shows that a feed forward multi-layer
perceptron network with a backpropagation learning
algorithm can be used effectively to model wind-induced
damage predictions for residential buildings. As few as
four hundred residential building samples are sufficient
to train the network to learn the underlying
relationships between the features of the building and
its corresponding building damage grade. During
training, the ANN model is able to learn the
relationships between the input features and the
resulting building damage grade effectively. It was also
discovered that the ANN model is able to predict
reasonably for samples it has yet to encounter.
The approach presented in this work can be used
effectively for other building categories. In addition,
when sufficient real wind-induced building damage
information is available, this approach of using ANN
will give a more realistic representation of the
relationships between the building characteristics and
the resulting wind damage.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  3680 </NUMBER>
<ORDER>   AAG9711298 </ORDER>
<TITLE> ADAPTIVE FUZZY NONLINEAR INTERNAL MODEL CONTROL STRATEGY </TITLE>
<AUTHOR> KREESURADEJ, WORAPOJ </AUTHOR>
<YEAR> 1996 </YEAR>
<INSTITUTION> TEXAS TECH UNIVERSITY; 0230 </INSTITUTION>
<DESCRIPTORS> ENGINEERING, SYSTEM SCIENCE; ENGINEERING, ELECTRONICS AND ELECTRICAL; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> NIL </ADVISER>
<CLASSIFICATIONS> PROPORTIONAL INTERGRATAL DERIVATIVE, CONTROLLER </CLASSIFICATIONS>
<ABSTRACT>
Proportional-Integratal Derivative like Fuzzy Logic
Controllers (PID-FLCs), have been used for a variety of
nonlinear control problems. Basically, a PID-FLC
contains a control algorithm in the form of linguistic
fuzzy rules. The problem with PID-FLCs is that there is
no systematic design for developing fuzzy rules. It is
also difficult to develop the controllers to meet
specific requirements on control performances.
In this dissertation, a nonlinear internal model control
(NIMC) structure and an adaptive fuzzy NIMC strategy
have been proposed to overcome the problems of PID-FLCs.
One of the attractive features of the NIMC structure is
that the relations between some designed parameters and
the performance of the control system can be found
explicitly. Thus, this control structure allows
designers to systematically construct the fuzzy control.
An adaptive fuzzy NIMC strategy has been proposed. The
proposed strategy has two attractive features. First,
the strategy provides an on-line adaptation to improve
control performance and to keep the closed-loop system
stable. Second, a fuzzy basis function (FBF) expansion
is used to implement the controller. The use of the FBF
expansion enhances the ability of the strategy to
control practical nonlinear systems whose exact
mathematical models are difficult to obtain.
Finally, Simulation studies of controlling four
nonlinear systems (e.g., a pendulum, an inverted
pendulum, a forced Van der Pol equation, and a two-link
cylindrical robot manipulator) have been conducted. The
simulation results show that the proposed strategy has
successfully controlled the four nonlinear systems.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  3681 </NUMBER>
<ORDER>   AAG9711179 </ORDER>
<TITLE> MAYOR: PLAN USE IN AN EVERYDAY WORLD </TITLE>
<AUTHOR> FASCIANO, MARK JOSEPH </AUTHOR>
<YEAR> 1996 </YEAR>
<INSTITUTION> THE UNIVERSITY OF CHICAGO; 0330 </INSTITUTION>
<DESCRIPTORS> COMPUTER SCIENCE; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> KRIS HAMMOND </ADVISER>
<CLASSIFICATIONS> AUTONOMOUS, AGENTS, SIMCITY, ARTIFICIAL INTELLIGENCE </CLASSIFICATIONS>
<ABSTRACT>
Everyday worlds pose an important set of challenges to
building autonomous agents. The work described in this
thesis is driven by the need to bring planned agent
activity to the complex and dynamic, "everyday" world.
These environment factors raise several challenges for
building a planning agent to live in a everyday world.
First, because the world is dynamic, when an agent
deliberates, it shouldn't take so long that the world
can change enough that the resultant plan is unusable
because a deadline or opportunity has passed. Second,
since the world is complex and the agent cannot be
expected to predict the effects of its actions
perfectly, it should be able to recover from expectation
failures, and learn from them in the future. Finally,
the delayed effects of actions mean that the agent
cannot determine whether a plan has failed immediately
after execution, which necessarily draws the agent into
longer-term activity where it must reason about the
future. In complex, dynamic worlds with delayed effects,
an agent must treat plans as ongoing processes.
This thesis describes M scAYOR, a situated, run-time
planning agent that operates in S scIMC scITY that has
successfully clocked over two thousand simulator years
of activity. This thesis describes the architecture and
design that has enabled M scAYOR to handle multiple
short and long-term goals using a range of strategies
from reactive behaviors to the reuse of plans from
memory.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  3682 </NUMBER>
<ORDER>   AAG9711124 </ORDER>
<TITLE> THE USE OF ARTIFICIAL INTELLIGENCE TO IMPROVE THE NUMERICAL OPTIMIZATION OF COMPLEX ENGINEERING DESIGNS </TITLE>
<AUTHOR> SCHWABACHER, MARK ANDREAS </AUTHOR>
<YEAR> 1996 </YEAR>
<INSTITUTION> RUTGERS THE STATE UNIVERSITY OF NEW JERSEY - NEW BRUNSWICK; 0190 </INSTITUTION>
<DESCRIPTORS> COMPUTER SCIENCE; ENGINEERING, AEROSPACE; OPERATIONS RESEARCH; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> THOMAS ELLMAN; ANDREW GELSEY </ADVISER>
<CLASSIFICATIONS> GRADIENT-BASED, MACHINE LEARNING </CLASSIFICATIONS>
<ABSTRACT>
Gradient-based numerical optimization of complex
engineering designs promises to produce better designs
rapidly. However, such methods generally assume that the
objective function and constraint functions are
continuous, smooth, and defined everywhere.
Unfortunately, realistic simulators tend to violate
these assumptions. We present several artificial
intelligence-based techniques for improving the
numerical optimization of complex engineering designs in
the presence of such pathologies in the simulators. We
have tested the resulting system in several realistic
engineering domains, and have found that using our
techniques can greatly decrease the cost of design space
search, and can also increase the quality of the
resulting designs.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  3683 </NUMBER>
<ORDER>   AAG9711095 </ORDER>
<TITLE> EXPLAINING REASONING IN DESCRIPTION LOGICS </TITLE>
<AUTHOR> MCGUINNESS, DEBORAH LOUISE </AUTHOR>
<YEAR> 1996 </YEAR>
<INSTITUTION> RUTGERS THE STATE UNIVERSITY OF NEW JERSEY - NEW BRUNSWICK; 0190 </INSTITUTION>
<DESCRIPTORS> COMPUTER SCIENCE; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> ALEXANDER BORGIDA </ADVISER>
<CLASSIFICATIONS> ARTIFICIAL INTELLIGENCE </CLASSIFICATIONS>
<ABSTRACT>
Knowledge-based systems, like other software systems,
need to be debugged while being developed. In addition,
systems providing "expert advice" need to be able to
justify their conclusions. Traditionally, developers
have been supported during debugging by tools which
offer a trace of the operations performed by the system
(e.g., a sequence of rule firings in a rule-based expert
system) or, more generally by an explanation facility
for the reasoner. Description Logics, formal systems
developed to reason with taxonomies or classification
hierarchies, form the basis of several recent knowledge-
based systems but do not currently offer such
facilities.
In this thesis, we explore four major issues in
explaining the conclusions of procedurally implemented
deductive systems, concentrating on a specific solution
for a class of description logics. First, we consider
how to explain a highly optimized procedural
implementation in a declarative manner. We begin with a
formal proof-theoretic foundation for explanation and we
illustrate our approach using examples from our
implementation in the CLASSIC knowledge representation
system. Next, we consider the issue of handling long,
complicated deduction chains. We introduce methods
designed to break up description logic queries and
answers into small, manageable pieces, and we show how
these are used in our approach and how they support
automatically generated explanations of followup
questions. Next, we consider the problem of explaining
negative deductions. We provide a constructive method
for explanation based on generating counter-examples.
Finally, we address the issue of limiting both object
presentation and explanation. We offer a meta-language
for describing interesting aspects of complicated
objects and use this language to limit the amount of
information that should be presented or explained. The
work in this thesis has been motivated by design and
application work on a description logic-based system and
a significant portion of our work has been implemented
for CLASSIC and is in use.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  3684 </NUMBER>
<ORDER>   AAG9711070 </ORDER>
<TITLE> KNOWLEDGE-BASED MANAGEMENT OF LEGACY CODES FOR AUTOMATED DESIGN </TITLE>
<AUTHOR> KEANE, JOHN ERIC </AUTHOR>
<YEAR> 1996 </YEAR>
<INSTITUTION> RUTGERS THE STATE UNIVERSITY OF NEW JERSEY - NEW BRUNSWICK; 0190 </INSTITUTION>
<DESCRIPTORS> COMPUTER SCIENCE; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> THOMAS ELLMAN </ADVISER>
<CLASSIFICATIONS> NIL </CLASSIFICATIONS>
<ABSTRACT>
Systems for automated design optimization of complex
real-world objects can, in principle, be constructed by
combining domain-independent numerical routines with
existing domain-specific analysis and simulation
programs. Such "legacy" analysis codes are frequently
unsuitable for use in automated design. They may crash
for large classes of input, be locally non-smooth, or be
highly sensitive to control parameters. To be useful,
analysis programs must first be modified to reduce or
eliminate only the undesired behaviors, without altering
the desired computation. To do this by direct
modification of the programs is labor-intensive, and
necessitates costly re-validation.
This dissertation describes research into how legacy
analysis codes can be usefully employed in design
automation systems. We show that recovery from failure
is possible when the failure occurs in the context of a
search-based process such as optimization. We discuss
the importance of failure context in determining the
correct failure recovery action. We then describe an
approach to failure recovery that is both context-
sensitive and guarantees the integrity of the original
computation to which it is applied.
We have implemented a high-level language and run-time
environment (together called LCM) that allow context-
sensitive failure-handling strategies to be incorporated
into existing Fortran and C analysis programs while
preserving their computational integrity. Our approach
relies on globally managing the execution of these
programs at the level of discretely callable functions
so that the computation is only affected when problems
are detected. Problem handling procedures are
constructed from a knowledge base of generic problem
management strategies. We show that our approach is
effective in improving analysis program robustness and
design optimization performance in several real-world
design domains.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  3685 </NUMBER>
<ORDER>   AAG9710787 </ORDER>
<TITLE> GENERIC RECOGNITION OF ARTICULATED OBJECTS THROUGH REASONING ABOUT POTENTIAL FUNCTION </TITLE>
<AUTHOR> GREEN, KEVIN KENYATTA </AUTHOR>
<YEAR> 1996 </YEAR>
<INSTITUTION> UNIVERSITY OF SOUTH FLORIDA; 0206 </INSTITUTION>
<DESCRIPTORS> COMPUTER SCIENCE; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> KEVIN W. BOWYER; ARTHUR D. SNIDER </ADVISER>
<CLASSIFICATIONS> OBJECT RECOGNITION, ARTIFICIAL INTELLIGENCE </CLASSIFICATIONS>
<ABSTRACT>
This dissertation research is in the general area of
computer vision and artificial intelligence.
Specifically, it involves the creation of a "function-
based recognition system" and an analysis of its
performance on a set of functional and non-functional
shape descriptions. These shape descriptions all lie
within the example domain of "articulated" hand tool
objects. An articulated shape is a shape composed of
parts that are rigid by themselves, but that can move
relative to each other, such as a pair of scissors or
pliers. The research examines the four basic-level
object categories, scissors, pliers, adjustable wrench
and C clamp. The methodology presented in this work can
be extended to include other hand tool categories (e.g.,
hand drill, calipers) as well as domains other than hand
tools (e.g., military, aerospace).
This research examines the hypothesis that an object
recognition system that recognizes objects based upon
their "function," "shape," and "kinematics" is superior
to a traditional model-based vision system that
recognizes objects solely on the object's shape. The
"raw" data set that was used to test the object
recognition system consisted of over 60 different
articulated shapes. The set included both functional
examples of articulated shape models, as well as non-
functional articulated shape models (e.g., a pair of
scissors with no finger holes or a pair of scissors with
only one blade). The implementation of this dissertation
research was done on a SUN Sparc workstation using the X
window system and the programming language C. The object
model size varied between 10 to 20 kilobytes per object
model, and the recognition time varied between a few
seconds to a few minutes. The experimental results of
these articulated shapes are presented with various
degrees of membership ranging from poor to excellent.
The membership grades are based upon comparisons to
ideal hand tool models. The ideal hand tool models are
created for each hand tool category and are designed to
pass through the system perfectly.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  3686 </NUMBER>
<ORDER>   AAG9710782 </ORDER>
<TITLE> ADVANCED HANDOFF ALGORITHMS FOR MICROCELLS USING FUZZY TECHNIQUES  </TITLE>
<AUTHOR> EDWARDS, GEORGE ANTHONY </AUTHOR>
<YEAR> 1996 </YEAR>
<INSTITUTION> UNIVERSITY OF SOUTH FLORIDA; 0206 </INSTITUTION>
<DESCRIPTORS> ENGINEERING, ELECTRONICS AND ELECTRICAL; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> RAVI SANKAR </ADVISER>
<CLASSIFICATIONS> CELLULAR COMMUNICATION </CLASSIFICATIONS>
<ABSTRACT>
The cellular communication industry is experiencing
phenomenal growth. In order to manage the high call
density expected in future cellular and personal
communications systems, microcell must be used. The size
of the microcell will cause a dramatic increase in the
number of handoffs. In addition, the small size of the
microcell will require handoff algorithms that respond
faster than those in today's systems. Added to the mix
is the urban phenomenon referred to in the literature as
the Manhattan street corner effect. The corner effect
causes the received signal level at a mobile station to
drop by 20-30 dB in 10-20 meters after the mobile turns
a corner. Then there is always the need for more
analysis models to investigate handoff performance.
Analysis models are important in engineering because
they allow a researcher to investigate the impact of
different parameters on a particular system function,
which provides quantitative information for making
appropriate design decisions.
The primary purpose of this dissertation is to develop
handoff algorithms capable of good performance under
microcellular conditions. To this end, three distinct
handoff algorithms are developed. The first handoff
algorithm computes an average for the received
difference signals (the signal on the current and the
target base stations) using a fuzzy technique. The
algorithm determines that a handoff is necessary
whenever the average is considered poor. The second
handoff algorithm uses a fuzzy predictor to compute the
next input signal sample. Then the current and future
signal values are passed to another fuzzy controller,
which makes the handoff decision. Finally, the third
handoff algorithm uses the received signal strength and
base-to-mobile distance to determine a handoff decision.
This algorithm utilizes the capability of fuzzy logic to
coherently use multiple inputs to control a decision
process. Conventional handoff algorithms based on signal
averaging and averaging with hysteresis are used to
provide benchmarks against which the fuzzy performance
is compared. Simulation studies are made for both line-
of-sight and non-line-of-sight microcellular conditions.
The fuzzy handoff algorithms are stable and provide
overall superior performance over the conventional
algorithms.
Another purpose of this dissertation is to develop
analytical models to examine handoff performance using
conventional handoff techniques. Three analytical models
are developed. The first model investigates the
interrelationship between the hysteresis level and
signal variance, and their impact on handoff
performance. A secondary effect in this study relates to
the sampling period, which affects the variance. The
second handoff model examines the impact that the sample
size and hysteresis have on handoff probability. The
third model uses level crossing theory to examine the
probability of a handoff assignment (to a particular
base station). The impact of the averaging window is
taken into consideration. These analysis models are
tractable and provide valuable information on the
effects that different window size and hysteresis level
have on handoff performance.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  3687 </NUMBER>
<ORDER>   AAG9710745 </ORDER>
<TITLE> QUALITATIVE AND QUANTITATIVE NEAR INFRARED ANALYSIS USING ARTIFICIAL NEURAL NETWORKS </TITLE>
<AUTHOR> HANA, MAHA ATTIA </AUTHOR>
<YEAR> 1996 </YEAR>
<INSTITUTION> NORTH CAROLINA STATE UNIVERSITY; 0155 </INSTITUTION>
<DESCRIPTORS> ENGINEERING, AGRICULTURAL; ARTIFICIAL INTELLIGENCE; COMPUTER SCIENCE; CHEMISTRY, ANALYTICAL </DESCRIPTORS>
<ADVISER> FERD MCCLURE </ADVISER>
<CLASSIFICATIONS> LINEAR NEURON, BACKPROPAGATION, NICOTINE, TOBACCO </CLASSIFICATIONS>
<ABSTRACT>
The performance of artificial neural networks (ANNs) for
near infrared analysis was studied. Two ANNs were used
in this research: (1) a linear neuron and (2) a
backpropagation network.
The first paper discusses the design of back propagation
networks and a method of calibration and validation. The
optimum network architecture was chosen to be the one
which gave the best performance among the different
network architectures tested. Model calibration and
validation for ANNs were divided into: (1) a new
training approach for ANNs, (2) calibration model and
(3) true performance. The neural networks models were
trained by dividing the data into training sets and
tuning sets using 5-fold cross validation. As the
training process proceeded, the MSE of the tuning set
was recorded. The minimum MSE of the tuning set and its
corresponding epoch number were determined. Then, a
network was trained to the same epoch number using all
the available data. A calibration model was built using
all the available data. The true performance of the
model was determined by dividing the data using 10-fold
cross validation. The training procedure was applied for
each training set. The true performance was determined
as the average of the ten testing sets performance.
In the second paper, the quantitative performance of
ANNs models were compared to multiple linear regression.
Data set A and B were used as the basis of estimating
nicotine in tobacco. For data set A, the MSE of the
calibrated regression model and its true performance
(0.0105, 0.0122, respectively) were better than the
backpropagation network (0.0117, 0.0142) and the linear
neuron (0.0130, 0.0130). For data set B, the
backpropagation network (0.0256, 0.0384) outperformed
both the linear neuron (0.0478, 0.0592) and the
regression model (0.0478, 0.0592) for both the
calibration model and its true performance.
In the third paper, the performance of ANNs was compared
to a quadratic discriminant analysis model. The correct
classification rate for classifying Burley and flue-
cured tobacco (data set C) was (100%, 100%) using
discriminant analysis followed by (99.38%, 99.39%) using
backpropagation network for the calibration model and
it's performance. The linear neuron model gave (95.19%,
99.26%). The same three models were used to identify
native Burley tobacco (data set D). The results for the
calibration model and its true performance were (100%,
100%) for discriminant analysis, (89.12%, 88.46%) for
backpropagation network and (80.68%, 79.62%) for the
linear neuron model.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  3688 </NUMBER>
<ORDER>   AAG1382579 </ORDER>
<TITLE> A NEURAL NETWORK BASED CLASSIFIER FOR THE IDENTIFICATION OF SIMPLE FINGER MOTION </TITLE>
<AUTHOR> HEINZ, MICHAEL JAMES </AUTHOR>
<YEAR> 1996 </YEAR>
<INSTITUTION> SAN JOSE STATE UNIVERSITY; 6265 </INSTITUTION>
<DESCRIPTORS> ENGINEERING, ELECTRONICS AND ELECTRICAL; COMPUTER SCIENCE; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> R. BENJAMIN KNAPP </ADVISER>
<CLASSIFICATIONS> NIL </CLASSIFICATIONS>
<ABSTRACT>
The question of whether electromyographic data from a
single region of the forearm can be used to distinguish
between various simple classes of finger motion is
examined. Extensive clustering of data is performed to
identify useful features for pattern classification.
Sets of neural networks are trained to classify
movements from each possible pairing of fingers. A multi-
layered neural-fuzzy network is constructed to address
the five-finger classification problem.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  3689 </NUMBER>
<ORDER>   AAGMM18342 </ORDER>
<TITLE> ARTIFICIAL NEURAL NETWORKS AND THEIR APPLICATION TO WATER TREATMENT </TITLE>
<AUTHOR> ZHANG, QING </AUTHOR>
<YEAR> 1996 </YEAR>
<INSTITUTION> UNIVERSITY OF ALBERTA (CANADA); 0351 </INSTITUTION>
<DESCRIPTORS> ENGINEERING, ENVIRONMENTAL; ENGINEERING, SANITARY AND MUNICIPAL; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> STEPHEN J. STANLEY </ADVISER>
<CLASSIFICATIONS> NIL </CLASSIFICATIONS>
<ABSTRACT>
The artificial neural network is an emerging artificial
intelligence modeling technique which has a great
potential in environmental engineering and especially
related to treatment processes. In this thesis, an
artificial neural network modeling approach was used for
two applications in water treatment. First, an
artificial neural network model was built to forecast
the raw water colour in the North Saskatchewan River.
Similar models for the other raw water quality
parameters can be established by using the approach
outlined in the thesis. This thesis proceeds to provide
a survey of recent research applications of neural
networks in two process control strategies: adaptive
control and internal model control. From the analysis of
the benefits and deficiencies of these two control
strategies, and the associated engineering knowledge of
the water treatment process, a feedforward neural
network controller was proposed and built for the
Rossdale water treatment plant in Edmonton, Alberta.
Upon the success of both models, this thesis also
attempts to explain why neural network modeling
functions well from the viewpoints of inductive learning
and the computational theory. The methodology of making
the hypothesis space tractable in order to obtain the
optimum neural network model was also demonstrated.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  3690 </NUMBER>
<ORDER>   AAG1382507 </ORDER>
<TITLE> DISCOVERING MANUFACTURING CONTROL KNOWLEDGE USING GENETIC ALGORITHMS AND NEURAL NETWORKS </TITLE>
<AUTHOR> SUBBARAMAN, SUDHIR </AUTHOR>
<YEAR> 1996 </YEAR>
<INSTITUTION> MISSISSIPPI STATE UNIVERSITY; 0132 </INSTITUTION>
<DESCRIPTORS> ENGINEERING, INDUSTRIAL; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> ROYCE O. BOWDEN </ADVISER>
<CLASSIFICATIONS> NIL </CLASSIFICATIONS>
<ABSTRACT>
This thesis presents a reinforcement learning system
developed to derive scheduling and control knowledge for
discrete part production systems. The learning system
combines concepts from genetic algorithms, neural
networks and simulation. A genetic algorithm (GA) is
used to evolve a population of neural networks (NN) that
learns various control strategies for simulated
manufacturing systems. The GA/NN reinforcement learning
system was applied to three different manufacturing
control problems: a job routing problem, a single
machine mean tardiness problem and the job shop
scheduling problem. For the job routing problem, the
GA/NN system learns to dynamically assign routes to
incoming jobs to maximize the number of jobs completed
on schedule. For the single machine mean tardiness
problem, the GA/NN system learns to prioritize jobs in a
queue to minimize mean tardiness. In the case of the job
shop scheduling problem, the GA/NN system learns to
dynamically switch queue priority rules to minimize mean
tardiness. Experimental results demonstrate the
effectiveness and robustness of the GA/NN system for
evolving manufacturing control knowledge.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  3691 </NUMBER>
<ORDER>   AAG1382494 </ORDER>
<TITLE> INTEGRATING GENETIC ALGORITHMS, CLUSTERING AND REINFORCEMENT LEARNING TO EVOLVE MANUFACTURING CONTROL KNOWLEDGE </TITLE>
<AUTHOR> PALMER, DAVID ALAN </AUTHOR>
<YEAR> 1996 </YEAR>
<INSTITUTION> MISSISSIPPI STATE UNIVERSITY; 0132 </INSTITUTION>
<DESCRIPTORS> ENGINEERING, INDUSTRIAL; COMPUTER SCIENCE; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> ROYCE O. BOWDEN </ADVISER>
<CLASSIFICATIONS> NIL </CLASSIFICATIONS>
<ABSTRACT>
A reinforcement leaning system is developed by combining
genetic algorithms and prototype of a cluster knowledge
representation. The genetic algorithm employs variable
length genotypes and genetic operators to evolve control
knowledge in the form of collections of prototypes that
map sensory input to a control decision in the task
domain. The learning system is applied to pattern
classification and manufacturing control problems. A set
of 64 points of known classification is classified.
Dynamic job routing decisions are made in a
manufacturing system consisting of three parallel
machines. Dynamic dispatching heuristic selection is
used to prioritize jobs in a job shop system with the
objective of minimizing mean tardiness. Experimental
results from each system demonstrate the effectiveness
and robustness of the learning system.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  3692 </NUMBER>
<ORDER>   AAG1382352 </ORDER>
<TITLE> SYSTEM IDENTIFICATION, SIMULATION, AND CONTROL USING CLASSICAL AND INTELLIGENT TECHNIQUES </TITLE>
<AUTHOR> LOPEZ, LINDA LOU </AUTHOR>
<YEAR> 1996 </YEAR>
<INSTITUTION> TEXAS A&M UNIVERSITY-KINGSVILLE; 1187 </INSTITUTION>
<DESCRIPTORS> ENGINEERING, ELECTRONICS AND ELECTRICAL; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> RAJAB CHALLOO </ADVISER>
<CLASSIFICATIONS> NIL </CLASSIFICATIONS>
<ABSTRACT>
The primary focus of this thesis is broken down into
three stages. First to identify the overall transfer
function of a "real life" system using system
identification techniques. Second, to model the
identified system using the Control System Simulation
Station which was designed and built. And lastly, to
model the identified system using a neural network. The
identification process involves the collection of
input/output data taken form a "real life" system This
input/output data is then used with identification
techniques available in the commercially available
software package MATLAB$sp0rm TM$ to produce a
mathematical representation of the system. The
mathematical representation is then broken into two
parts, one which represents a proportional + integral +
derivative (PID) controller and the other which
represents the identified plant of the "real life"
system. These two subsystems, the controller and plant,
are then implemented using the designed Control System
Simulation Station. The same input/output data utilized
in the identification process is then used in the
process to produce a neural network model of the "real
life" system. Again utilizing the software package
MATLAB$sp0rm TM$ and its Neural Network Toolbox, the
input/output data is applied to a recurrent training
algorithm. As an example all three techniques will be
applied to a "real life" system called the Z-Axis, a
component of an IBM robotics arm. Overall this thesis
will provide knowledge of system identification
techniques, neural network modeling, and
controller/plant representation in the Simulation
Station. (Abstract shortened by UMI.)
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  3693 </NUMBER>
<ORDER>   AAG1382340 </ORDER>
<TITLE> ON-LINE VALIDATION AND RECONSTRUCTION OF CHEMICAL PROCESS DATA USING NEURAL NETWORKS </TITLE>
<AUTHOR> CALAWAY, JAMES EDWIN, JR. </AUTHOR>
<YEAR> 1996 </YEAR>
<INSTITUTION> TEXAS A&M UNIVERSITY-KINGSVILLE; 1187 </INSTITUTION>
<DESCRIPTORS> ENGINEERING, CHEMICAL; ENGINEERING, ELECTRONICS AND ELECTRICAL; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> WILLIAM HEENAN </ADVISER>
<CLASSIFICATIONS> NIL </CLASSIFICATIONS>
<ABSTRACT>
Neural networks are being used to model chemical
processes in today's industries for reasons of
simulation and control. In order to implement a neural
network, there needs to be a sufficient amount of
historical data on which to train the network. The
quality of the data is more of a problem than the amount
of data. Noise introduced into the data from any outside
source can reduce the accuracy of a networks learning.
This thesis is an attempt to implement an auto-
associative backpropagated neural network to remove
noise from data in order to improve training results.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  3694 </NUMBER>
<ORDER>   AAG1382242 </ORDER>
<TITLE> IMPLEMENTATION OF A NEURAL NET TRACKING CONTROLLER FOR A SINGLE FLEXIBLE LINK: COMPARISON WITH PD AND PID CONTROLLERS </TITLE>
<AUTHOR> GUTIERREZ, LUIS BENIGNO </AUTHOR>
<YEAR> 1996 </YEAR>
<INSTITUTION> THE UNIVERSITY OF TEXAS AT ARLINGTON; 2502 </INSTITUTION>
<DESCRIPTORS> ENGINEERING, ELECTRONICS AND ELECTRICAL; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> FRANK L. LEWIS </ADVISER>
<CLASSIFICATIONS> NIL </CLASSIFICATIONS>
<ABSTRACT>
The objective of this thesis is to show the results of
the practical implementation of a neural network
tracking controller on a single flexible link and
compare its performance to that of PD and PID standard
controllers. The NN controller is composed of an outer
PD tracking loop, a singular perturbation inner loop for
stabilization of the fast flexible mode dynamics, and a
neural network inner loop used to feedback linearize the
slow pointing dynamics. No off-line training or learning
is needed for the NN. It is shown that the tracking
performance of the NN controller is far better than that
of the PD or PID standard controllers. An extra friction
term was added in the tests to demonstrate the ability
of the NN to learn unmodeled nonlinear dynamics.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  3695 </NUMBER>
<ORDER>   AAG1382192 </ORDER>
<TITLE> RELOCATION OF AGENTS IN MOBILE ENVIRONMENTS </TITLE>
<AUTHOR> BALAKRISHNAN, SANTOSH </AUTHOR>
<YEAR> 1996 </YEAR>
<INSTITUTION> THE UNIVERSITY OF TEXAS AT ARLINGTON; 2502 </INSTITUTION>
<DESCRIPTORS> COMPUTER SCIENCE </DESCRIPTORS>
<ADVISER> ABDELSALAM HELAL </ADVISER>
<CLASSIFICATIONS> NIL </CLASSIFICATIONS>
<ABSTRACT>
Explosive growth in the market of inexpensive portable
machines and the growth of technologies like portable
digital assistants has kindled great interest in mobile
computing in both academia and industry. Mobile
computing, which in many ways is comparable to
distributed computing, is characterised by the low
bandwidth and frequent disconnections suffered by a
mobile user when connected to the fixed network.
Software agents, a concept borrowed from artificial
intelligence, has been proposed as a mechanism to work
around these limitations. A software agent, which can be
defined as a set of software processes that carry out
some activity, represents a mobile user on the fixed
network. Agents, when initiated by a mobile user,
perform activities as diverse as booking airline tickets
to filtering information from the World Wide Web and
also act as a interface to the fixed network. To improve
response times, the site of execution of an agent is
also moved along with the mobile user, as the point of
attachment to the fixed network changes with the mobile
node. This kind of naive, uncontrolled relocation can
result in considerable amount of load on the system.
This work presents algorithms which allow agent handling
systems to have better control over the process of
relocation, so that both objectives, improved response
times and better performance, can be achieved.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  3696 </NUMBER>
<ORDER>   AAGMM13862 </ORDER>
<TITLE> IDENTIFYING STOCK WINNERS AND LOSERS: A MULTILAYERED ARTIFICIAL NEURAL NETWORK APPROACH </TITLE>
<AUTHOR> SRIVASTAVA, ATUL </AUTHOR>
<YEAR> 1996 </YEAR>
<INSTITUTION> CARLETON UNIVERSITY (CANADA); 0040 </INSTITUTION>
<DESCRIPTORS> ECONOMICS, FINANCE; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> VIJAY JOG </ADVISER>
<CLASSIFICATIONS> NIL </CLASSIFICATIONS>
<ABSTRACT>
The artificial neural networks represent an exciting new
technology with wide scope for potential financial
applications ranging from routine credit assessment
operations to the driving of large scale portfolio
management strategies. This study is an attempt to
identify stock winners and losers using this technology.
Two sets of attributes are used for the network
training. The first set is modelled along the lines of
attributes that are used by Value Line Investment
Survey, whereas the second set of attributes is a
combination of the first set and some attributes taken
from the anomaly literature.
The evidence presented in this study suggests that a
blind, black box approach to artificial neural networks
may not be very useful. Some pragmatism and careful
knowledge of data is required for good results. A design
that takes into consideration issues such as, sample
size requirements, choice of attributes, presence of
influential data points in the input data and use of
classical techniques, such as multiple discriminant
analysis, to enhance the network performance, may result
in a potentially good system; it can even compare
favourably with the classical methods, but with some
caveats.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  3697 </NUMBER>
<ORDER>   AAGMM13860 </ORDER>
<TITLE> A KNOWLEDGE-BASED DECISION SUPPORT SYSTEM FOR PLANNING REFORESTATION PROJECTS IN DEVELOPING COUNTRIES: A GEOGRAPHIC INFORMATION SYSTEM </TITLE>
<AUTHOR> MEKONNEN, GEBREKIDUCE </AUTHOR>
<YEAR> 1996 </YEAR>
<INSTITUTION> CARLETON UNIVERSITY (CANADA); 0040 </INSTITUTION>
<DESCRIPTORS> BUSINESS ADMINISTRATION, MANAGEMENT; ARTIFICIAL INTELLIGENCE; GEOGRAPHY; AGRICULTURE, FORESTRY AND WILDLIFE </DESCRIPTORS>
<ADVISER> DAVID CRAY </ADVISER>
<CLASSIFICATIONS> NIL </CLASSIFICATIONS>
<ABSTRACT>
This thesis presents the design of a Knowledge-based
Reforestation Planning Decision Support System (KB-RDSS)
for developing countries; which integrates: (i) a
geographic information system (GIS); (ii) a multi
criteria decision making method (MCDM); (iii) a tree
data base; (iv) five knowledge bases; and (v) a final
plan review module. In view of current literature, it
can be maintained that it is the first of its kind. The
system, through a phased approach that reflects the
natural sequence of reforestation activities that is
driven by the user, accepts relevant site data and
produces a plan of: objectives, plantation management
authority (PMGTAs), plantation types (PTYPEs), people
mobilization strategies (PMSTs), site preparation
methods (SPMTs), plant protection methods (PPMTs) and
tree species (TSPECs) for each site niche to be
reforested. A prototype, which includes an objectives
determination module, and PMST & PPMT knowledge bases
has been developed and demonstrated using a
reforestation case study from Nepal.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  3698 </NUMBER>
<ORDER>   AAGMM13627 </ORDER>
<TITLE> LOOKING AT NEIGHBOURHOODS FROM A WOMAN'S VIEWPOINT: A KNOWLEDGE BASED SYSTEM APPROACH TO URBAN PLANNING </TITLE>
<AUTHOR> WATTS, JENNIFER LEE </AUTHOR>
<YEAR> 1996 </YEAR>
<INSTITUTION> TECHNICAL UNIVERSITY OF NOVA SCOTIA (CANADA); 0300 </INSTITUTION>
<DESCRIPTORS> URBAN AND REGIONAL PLANNING; WOMEN'S STUDIES; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> FRANK PALERMO </ADVISER>
<CLASSIFICATIONS> NIL </CLASSIFICATIONS>
<ABSTRACT>
This research involved the development and evaluation of
a computer program to consider the responsiveness of a
neighborhood in meeting women's needs. As part of this
research, a small prototype Knowledge Based System
(KBS), "Looking at Neighborhoods from a Women's
Viewpoint", was designed using Level 5 Object for
Microsoft Windows. In this thesis, the KBS was tested as
a tool to facilitate an educational process with women.
The knowledge used in building the KBS was gathered from
a literature search; from discussions with women from a
low income women's community group, community organizers
who work with women, and women planning students; and
from personal experience. The prototype was developed to
evaluate sidewalks according to criteria that meets
women's needs and to assess the main commercial section
of Fairview in Halifax. The prototype was tested with
women from the original low income community group and a
community organizer.
The findings of this research are that a fully developed
model of "Looking at Neighborhoods from a Women's
Viewpoint" could advance women and planning concerns on
local neighborhoods and on mainstream planning practice.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  3699 </NUMBER>
<ORDER>   AAGMM13124 </ORDER>
<TITLE> NEURAL NETWORK SIGNAL PROCESSING TECHNIQUES FOR ADVENTITIOUS LUNG SOUND CLASSIFICATION </TITLE>
<AUTHOR> FORKHEIM, KEVIN EDWARD </AUTHOR>
<YEAR> 1996 </YEAR>
<INSTITUTION> THE UNIVERSITY OF MANITOBA (CANADA); 0303 </INSTITUTION>
<DESCRIPTORS> COMPUTER SCIENCE; ARTIFICIAL INTELLIGENCE; ENGINEERING, BIOMEDICAL </DESCRIPTORS>
<ADVISER> DAVID SEUSE </ADVISER>
<CLASSIFICATIONS> NIL </CLASSIFICATIONS>
<ABSTRACT>
The purpose of this research is to compare the
performance of different representations of lung sounds
and different types of neural network models at
classifying wheezes. The result of combining multiple
neural networks is also investigated.
Lung sounds were recorded from the thorax region and
divided into segments of 0.2 seconds. These segments
were then classified as either containing a wheeze or
not containing a wheeze by a trained clinician. A neural
network was trained and tested using the raw signal,
filtered, and Fourier Transform representations so that
the best representation for the neural network could be
found. Once the best representation was found, five
different types of neural networks--Backpropagation
(BP), Self Organizing Maps (SOM), Learning Vector
Quantization (LVQ), Probabilistic Networks (PNN), and
Radial Basis Functions (RBF)--were compared to find the
best neural network for classifying wheezes. Experiments
were also performed with different post-processing
techniques such as thresholding and combining multiple
classifiers. (Abstract shortened by UMI.)
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  3700 </NUMBER>
<ORDER>   AAGMM18334 </ORDER>
<TITLE> FUZZY PROCESS IDENTIFICATION AND CONTROL </TITLE>
<AUTHOR> WONG, CHEE HENG </AUTHOR>
<YEAR> 1996 </YEAR>
<INSTITUTION> UNIVERSITY OF ALBERTA (CANADA); 0351 </INSTITUTION>
<DESCRIPTORS> ENGINEERING, INDUSTRIAL; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> SIRISH L. SHAH </ADVISER>
<CLASSIFICATIONS> NIL </CLASSIFICATIONS>
<ABSTRACT>
Two new fuzzy relational identification algorithms were
formulated--the Neuron-Based Predictive Identification
(NBPI) algorithm and the Fuzzy Relational Predictive
Identification (FRPI) algorithm. These algorithms
minimize the fuzzy prediction error over a user-
specified prediction horizon and maintain the predictive
capability of fuzzy relational models. These proposed
schemes were found to give better results than Shaw's
fuzzy relational models. These proposed schemes were
found to give better results than Shaw's fuzzy
relational identification technique. The FRPI algorithm
was also found to be practical for on-line applications.
The servo and regulatory performance of two fuzzy
relational controllers namely the Self-Learning
Predictive Fuzzy Controller (SLPFC) and the Fuzzy
Relational Long Range Predictive Controller (FRLRPC)
were evaluated experimentally on a highly non-linear,
interacting level process. Based on the integral sum of
errors, the SLPFC gave a slightly better performance.
The impact of on-line fuzzy relational identification
algorithms on controller performance was also verified.
It was found that the FRPI algorithm results in an
improvement in controller performance compared to Shaw's
fuzzy relational identification algorithm.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  3701 </NUMBER>
<ORDER>   AAG9710565 </ORDER>
<TITLE> ANALYSIS OF FREQUENCY SENSITIVE COMPETITIVE LEARNING </TITLE>
<AUTHOR> GALANOPOULOS, ARISTIDES S. </AUTHOR>
<YEAR> 1996 </YEAR>
<INSTITUTION> THE OHIO STATE UNIVERSITY; 0168 </INSTITUTION>
<DESCRIPTORS> ENGINEERING, ELECTRONICS AND ELECTRICAL; ARTIFICIAL INTELLIGENCE; COMPUTER SCIENCE </DESCRIPTORS>
<ADVISER> STANLEY C. AHALT </ADVISER>
<CLASSIFICATIONS> LEARNING PHASE, ARTIFICIAL INTELLIGENCE </CLASSIFICATIONS>
<ABSTRACT>
This is an analytical study of a conscience-type
competitive learning algorithm, called Frequency
Sensitive Competitive Learning (FSCL). The algorithm has
been studied in the context of vector quantization. We
address two fundamental questions, the convergence
properties of the algorithm and the steady state
equilibrium. We approximate the final phase of the FSCL
training schedule with a diffusion process and we derive
necessary and sufficient conditions for the process to
converge to an equilibrium state. We verify the final
phase results and we investigate the initial learning
phase dependence on the algorithm parameters using
simulations.
We derive analytical results on the steady state
equilibrium for one dimensional input data and for the
limit of large number of codewords. The algorithm is
shown to minimize a larger range of distortion measures
compared with other competitive learning type online
algorithms.
The results of this study are very useful for setting
the algorithm parameters in vector quantization
applications where the FSCL algorithm is used.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  3702 </NUMBER>
<ORDER>   AAG9710109 </ORDER>
<TITLE> MATHEMATICAL MODELING AND FUZZY PID CONTROL FOR FLEXIBLE- LINK ROBOTS  </TITLE>
<AUTHOR> SOORAKSA, PITIKHATE </AUTHOR>
<YEAR> 1996 </YEAR>
<INSTITUTION> UNIVERSITY OF HOUSTON; 0087 </INSTITUTION>
<DESCRIPTORS> ENGINEERING, ELECTRONICS AND ELECTRICAL; ENGINEERING, INDUSTRIAL; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> NIL </ADVISER>
<CLASSIFICATIONS> ROBOT ARMS </CLASSIFICATIONS>
<ABSTRACT>
In this dissertation, the Timoshenko theory is applied
to investigate a new mathematical model for the
"shoulder-elbow-like" single flexible link robot arm
with damping. Detailed analysis and derivation are given
to support the mathematical modeling of this particular
flexible mechanism. Moreover, by assuming that the
pinned-pinned mode shape of a Euler-Bernoulli beam is
the same as the more complete Timoshenko beam, an
analytic solution of the new model is derived. A new
design of a fuzzy-logic-based (PI + D)$sp2$ control
scheme is developed for both vibration suppression and
set-point tracking. Computer simulation results are
performed to verify the theoretical analysis and
mathematical formulation. These numerical results show
satisfactory agreement with the new mathematical model
and demonstrate that the fuzzy logic based controllers
perform very well for this flexible link model, which is
described by two higher-order partial differential
equations with initial-terminal and boundary-value
conditions. A stability analysis for the designed system
is also carried out, both graphically and analytically.
For the analytical stability analysis, the small gain
theorem is employed, and for the graphical stability
analysis, a new method is developed based on a two-
straight lines criterion. The agreement between
graphical stability analysis and the theoretical
analysis is very good.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  3703 </NUMBER>
<ORDER>   AAG9710105 </ORDER>
<TITLE> INTELLIGENT CONTROL OF A COMPLEX, DYNAMICAL AND MULTI- CONSTRAINED PLANNING SYSTEM FOR SPACE STATION CREW TRAINING  </TITLE>
<AUTHOR> ORTIZ, JAMES NORMAN </AUTHOR>
<YEAR> 1996 </YEAR>
<INSTITUTION> UNIVERSITY OF HOUSTON; 0087 </INSTITUTION>
<DESCRIPTORS> ENGINEERING, ELECTRONICS AND ELECTRICAL; ENGINEERING, INDUSTRIAL; OPERATIONS RESEARCH; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> NIL </ADVISER>
<CLASSIFICATIONS> ARTIFICIAL INTELLIGENCE </CLASSIFICATIONS>
<ABSTRACT>
This work represents the design, analysis and solution,
from the systems control perspective, of a complex,
dynamic, and multi-constrained planning system for
generating training plans for crew members of the NASA
International Space Station. Various intelligent
planning systems have been developed within the
framework of Artificial Intelligence (AI), but these
planning systems lack a rigorous mathematical formalism
to allow a reliable and flexible methodology for design,
modeling, and analysis of their performance in a
dynamical, time-critical, and multi-constrained
environment. Formulating the planning problem in the
domain of discrete-event systems under a unified
framework such that it can be modeled, designed, and
analyzed as a control system will provide a self-
contained theory for planning systems. This will also
provide a means to certify various planning systems for
operations in the dynamical and complex environments in
space. This dissertation completes the development of
such an intricate, large-scale, and representative
mathematical formulation, as well as design and
analysis, for intelligent control of a planning system
for Space Station crew training. The planning system was
developed as a control system, with the plant and the
supervisory controller modeled as a Discrete Event
System (DES) using Petri Nets, and with a planner that
implemented an heuristic search algorithm (the A$sp0*$
algorithm) to find the optimized solution. The planning
system was analyzed as a control system rather than as a
pure AI system, and characterized for controllability,
stability, and robustness. The planning system has been
successfully tested and incorporated into operational
use at NASA-JSC.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  3704 </NUMBER>
<ORDER>   AAG9709951 </ORDER>
<TITLE> NONLINEAR ADAPTIVE SIGNAL PROCESSING: LEARNING BEHAVIOR OF NEURAL NETWORKS FOR SYSTEM IDENTIFICATION </TITLE>
<AUTHOR> VAUGHN, JEFFREY L. </AUTHOR>
<YEAR> 1996 </YEAR>
<INSTITUTION> UNIVERSITY OF CALIFORNIA, IRVINE; 0030 </INSTITUTION>
<DESCRIPTORS> ENGINEERING, ELECTRONICS AND ELECTRICAL; ENGINEERING, SYSTEM SCIENCE; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> NEIL J. BERSHAD </ADVISER>
<CLASSIFICATIONS> NIL </CLASSIFICATIONS>
<ABSTRACT>
Backpropagation is an important class of training
algorithms for artificial neural networks. These
algorithms are based on gradient descent of an error
cost function and can have suboptimal local minima.
However, what conditions cause local minima to exist or
how they can be avoided are not known. Additionally, it
has been shown that backpropagation often gets "stuck"
in certain regions, requiring large numbers of
iterations before the algorithm proceeds to convergence.
This dissertation analyzes the suboptimal stationary
points of a modified backpropagation algorithm used to
train a particular two-layer perceptron. This involves
solving in closed form the mean gradient, Hessian
(matrix of gradient derivatives), and the gradient
correlation matrix. All of these stationary points
appear to be saddle points of the cost function, yet
they exhibit interesting "convergence" properties that
are predicted in the analysis and demonstrated by
simulation. The "downhill" direction determined by the
Hessian is very nearly in the null space of the gradient
correlation. Updates are dominated by components that
are driven back towards the stationary point, giving the
appearance of convergence. The analysis proves that
saddle points can cause the previously reported behavior
and explains why they cause this behavior in the
training algorithm. Simulations demonstrate that this
behavior occurs as predicted.
The high degree of correlation between different layers
of the perceptron causes inappropriate corrections of
the weights for the outer layer. This dissertation
vividly demonstrates this previously unreported problem
as well as a method for reducing the effect.
The bounds for the rate parameter are computed for this
perceptron network. The upper bound is shown to depend
on the angle between the inner-layer weight vectors.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  3705 </NUMBER>
<ORDER>   AAG9709714 </ORDER>
<TITLE> AN INTELLIGENT SENSOR FUSION APPROACH TO PATTERN RECOGNITION WITH AN APPLICATION TO BOND VALIDATION OF SURFACE-MOUNT COMPONENTS </TITLE>
<AUTHOR> DAR, IQBAL MAHMUD </AUTHOR>
<YEAR> 1996 </YEAR>
<INSTITUTION> GEORGIA INSTITUTE OF TECHNOLOGY; 0078 </INSTITUTION>
<DESCRIPTORS> ENGINEERING, ELECTRONICS AND ELECTRICAL; ENGINEERING, INDUSTRIAL; ENGINEERING, SYSTEM SCIENCE; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> GEORGE J. VACHTSEVANOS </ADVISER>
<CLASSIFICATIONS> FUZZY, VISION, ARTIFICIAL INTELLIGENCE </CLASSIFICATIONS>
<ABSTRACT>
Pattern recognition techniques are an important
component of intelligent and autonomous systems and are
used for both data processing and decision making. It is
desirable to use an autonomous system that performs its
task with speed and accuracy. This research effort
introduces a pattern recognition approach in a multi-
sensor environment by fusing information at various
levels of abstraction. An active perception concept is
presented and implemented which dynamically selects
features with high distinguishability and low processing
time to perform reliable classification in minimum time.
An index, called degree of certainty, is used as the
performance criterion for classification reliability.
The index is defined using Dempster-Shafer theory, and
fuzzy logic tools. A supervised fuzzy classifier has
been developed which can efficiently perform fuzzy
partitions for large training data sets. Development of
active perception as an intelligent paradigm provides on-
line adaptability and efficient recognition through
learning. A training data set is used for off-line
learning, which generates ordered feature sets for all
class pairs by maximizing the features'
distinguishability and minimizing their processing time.
The on-line learning is performed by monitoring the
feature effectiveness for classifying the unknown input
patterns and reordering the ordered feature sets. The
proposed pattern recognition architecture has been used
for development of inspection systems for solder joints
of surface-mount components using vision and infra-red
sensors and multi-chip modules using a vision system and
a wire bonder. Results are presented which demonstrate
the performance of the proposed methodology.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  3706 </NUMBER>
<ORDER>   AAG9709698 </ORDER>
<TITLE> HOW EMBEDDED MEMORY AFFECTS THE PERFORMANCE OF RECURRENT NEURAL NETWORKS  </TITLE>
<AUTHOR> LIN, TSUNG-NAN </AUTHOR>
<YEAR> 1996 </YEAR>
<INSTITUTION> PRINCETON UNIVERSITY; 0181 </INSTITUTION>
<DESCRIPTORS> ENGINEERING, ELECTRONICS AND ELECTRICAL; COMPUTER SCIENCE; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> NIL </ADVISER>
<CLASSIFICATIONS> FINITE MEMORY MACHINE, ARTIFICIAL INTELLIGENCE </CLASSIFICATIONS>
<ABSTRACT>
Dynamical neural networks are fascinating with respect
to their capacity of modeling nonlinear system dynamics
from input/output behavior. They differ from static
models in the sense that dynamical models have memory
elements, which are the key components for preserving
their states and making them able to handle time
dependent problems. A rigorous understanding of how the
memory elements affect the performance of dynamical
neural networks is thus very important in practice.
Since different architectures may be theoretically
equivalent in terms of representation power yet there
might be some practical advantages to use one
architecture over another. This dissertation attempts to
take a step in this direction. To achieve the goal, we
study carefully the effects of embedded memory on the
performance of a class of neural networks with
observable states (NARX neural networks); then extend to
other dynamical networks with hidden states.
First, we show that NARX networks are able to simulate a
class of finite state machines. Of particular interest
is the result that NARX networks are able to "learn"
very large state machines. Then, an extensive
exploration toward the effect of propagating the
gradient information through the embedded memory in NARX
networks on the problem of long-term dependencies is
presented. The third, we extend the similar improvement
in reducing the sensitivity to long-term dependency
learning to other types of recurrent neural networks.
Fourth, the effects of embedded memory on generalization
for NARX networks are also critically examined.
Increasing the order of embedded memory will increase
the learning performance, while the generalization
performance will also strongly depend on the memory
orders. Therefore, choosing a proper memory architecture
to balance the learning ability and generalization
performance becomes a crucial topic to be explored. With
an ambitious attempt to provide an efficient algorithm,
we propose a pruning-based algorithm to determine the
optimal memory architecture. The final memory
architectures always result in sparse connections which
will make useful information more explicit and help the
networks more robustly model the long-term behavior of
the underlying system.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  3707 </NUMBER>
<ORDER>   AAG9709626 </ORDER>
<TITLE> A TRAINABLE APPROACH TO COREFERENCE RESOLUTION FOR INFORMATION EXTRACTION  </TITLE>
<AUTHOR> MCCARTHY, JOSEPH FRANCIS </AUTHOR>
<YEAR> 1996 </YEAR>
<INSTITUTION> UNIVERSITY OF MASSACHUSETTS; 0118 </INSTITUTION>
<DESCRIPTORS> COMPUTER SCIENCE; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> WENDY G. LEHNERT </ADVISER>
<CLASSIFICATIONS> MACHINE LEARNING, NATURAL LANGUAGE </CLASSIFICATIONS>
<ABSTRACT>
This dissertation presents a new approach to solving the
coreference resolution problem for a natural language
processing (NLP) task known as information extraction.
It describes a new system, named R scESOLVE, that uses
machine learning techniques to determine when two
phrases in a test co-refer, i.e., refer to the same
thing. R scESOLVE can be used as a component within an
information extraction system--a system that extracts
information automatically from a corpus of texts that
all focus on the same topic area--or it can be used as a
stand-alone system to evaluate the relative contribution
of different types of knowledge to the coreference
resolution process.
R scESOLVE represents an improvement over previous
approaches to the coreference resolution problem, in
that it uses a machine learning algorithm to handle some
of the work that had previously been performed manually
by a knowledge engineer.
R scESOLVE can achieve performance that is as good as a
system that was manually constructed for the same task,
when both systems are given access to the same knowledge
and tested on the same data.
The machine learning algorithm used by R scESOLVE can be
given access to different types of knowledge, some
portions of which are very specific to a particular
topic area or domain, and other portions are more
general or domain-independent. An ablation experiment
shows that domain-specific knowledge is very important
to coreference resolution--the performance degradation
when the domain-specific features are disabled is
significantly worse than when a similarly-sized set of
domain-independent features is disabled.
However, even though domain-specific knowledge is
important for coreference resolution, domain-independent
features alone enable R scESOLVE to achieve 80% of the
performance it achieves when domain-specific features
are available. One explanation for why domain-
independent knowledge can be used so effectively is
illustrated in another domain, where the machine
learning algorithm discovers domain-specific knowledge
by assembling the domain-independent features of
knowledge into domain-specific patterns. This ability of
R scESOLVE to compensate for missing or insufficient
domain-specific knowledge is a significant advantage for
redeploying the system in new domains.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  3708 </NUMBER>
<ORDER>   AAG9709586 </ORDER>
<TITLE> LARGE-SCALE DYNAMIC OPTIMIZATION USING TEAMS OF REINFORCEMENT LEARNING AGENTS </TITLE>
<AUTHOR> CRITES, ROBERT HARRY </AUTHOR>
<YEAR> 1996 </YEAR>
<INSTITUTION> UNIVERSITY OF MASSACHUSETTS; 0118 </INSTITUTION>
<DESCRIPTORS> COMPUTER SCIENCE; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> ANDREW G. BARTO </ADVISER>
<CLASSIFICATIONS> ARTIFICIAL INTELLIGENCE, MACHINE LEARNING, ELEVATOR GROUP CONTROL </CLASSIFICATIONS>
<ABSTRACT>
Recent algorithmic and theoretical advances in
reinforcement learning (RL) are attracting widespread
interest. RL algorithms have appeared that approximate
dynamic programming (DP) on an incremental basis. Unlike
traditional DP algorithms, these algorithms do not
require knowledge of the state transition probabilities
or reward structure of a system. This allows them to be
trained using real or simulated experiences, focusing
their computations on the areas of state space that are
actually visited during control, making them
computationally tractable on very large problems. RL
algorithms can be used as components of multi-agent
algorithms. If each member of a team of agents employs
one of these algorithms, a new collective learning
algorithm emerges for the team as a whole. In this
dissertation we demonstrate that such collective RL
algorithms can be powerful heuristic methods for
addressing large-scale control problems.
Elevator group control serves as our primary testbed.
The elevator domain poses a combination of challenges
not seen in most RL research to date. Elevator systems
operate in continuous state spaces and in continuous
time as discrete event dynamic systems. Their states are
not fully observable and they are non-stationary due to
changing passenger arrival rates. As a way of
streamlining the search through policy space, we use a
team of RL agents, each of which is responsible for
controlling one elevator car. The team receives a global
reinforcement signal which appears noisy to each agent
due to the effects of the actions of the other agents,
the random nature of the arrivals and the incomplete
observation of the state. In spite of these
complications, we show results that in simulation
surpass the best of the heuristic elevator control
algorithms of which we are aware. These results
demonstrate the power of RL on a very large scale
stochastic dynamic optimization problem of practical
utility.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  3709 </NUMBER>
<ORDER>   AAG9709584 </ORDER>
<TITLE> ON INTEGRATING APPRENTICE LEARNING AND REINFORCEMENT LEARNING </TITLE>
<AUTHOR> CLOUSE, JEFFERY ALLEN </AUTHOR>
<YEAR> 1996 </YEAR>
<INSTITUTION> UNIVERSITY OF MASSACHUSETTS; 0118 </INSTITUTION>
<DESCRIPTORS> COMPUTER SCIENCE; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> PAUL E. UTGOFF </ADVISER>
<CLASSIFICATIONS> AGENTS, ARTIFICIAL INTELLIGENCE, PROBLEM SOLVING, MACHINE LEARNING </CLASSIFICATIONS>
<ABSTRACT>
Apprentice learning and reinforcement learning are
methods that have each been developed in order to endow
computerized agents with the capacity to learn to
perform multiple-step tasks, such as problem-solving
tasks and control tasks. To achieve this end, each
method takes differing approaches, with disparate
assumptions, objectives, and algorithms. In apprentice
learning, the autonomous agent tries to mimic a training
agent's problem-solving behavior, learning based on
examples of the trainer's action choices. In an attempt
to learn to perform its task optimally, the learner in
reinforcement learning changes its behavior based on
scalar feedback about the consequences of its own
actions.
We demonstrate that a careful integration of the two
learning methods can produce a more powerful method than
either one alone. An argument based on the
characteristics of the individuals maintains that a
hybrid will be an improvement because of the
complimentary strengths of its constituents. Although
existing hybrids of apprentice learning and
reinforcement learning perform better than their
individual components, those hybrids have left many
questions unanswered. We consider the following
questions in this dissertation. How do the learner and
trainer interact during training? How does the learner
assimilate the trainer's expertise? How does the
proficiency of the trainer affect the learner's ability
to perform the task? And, when during training should
the learner acquire information from the trainer? In our
quest for answers, we develop the A scSK FOR H scELP
integrated approach, and use it in our empirical study.
With the new integrated approach, the learning agent is
significantly faster at learning to perform optimally
than learners employing either apprentice learning alone
or reinforcement learning alone. The study indicates
further that the learner can learn to perform optimally
even when its trainer cannot; thus, the learner can
outperform its trainer. Two strategies for determining
when to acquire the trainer's aid show that simple
approaches work well. The results of the study
demonstrate that the A scSK FOR H scELP approach is
effective for integrating apprentice learning and
reinforcement learning, and support the conclusion that
an integrated approach can be better than its individual
components.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  3710 </NUMBER>
<ORDER>   AAG9709449 </ORDER>
<TITLE> REDUCED PERCEPTRON NETWORKS AND INVERSE MODELING CONTROL </TITLE>
<AUTHOR> MALINOWSKI, ALEKSANDER </AUTHOR>
<YEAR> 1996 </YEAR>
<INSTITUTION> UNIVERSITY OF LOUISVILLE; 0110 </INSTITUTION>
<DESCRIPTORS> ENGINEERING, ELECTRONICS AND ELECTRICAL; COMPUTER SCIENCE; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> JACEK M. ZURADA </ADVISER>
<CLASSIFICATIONS> ADAPTIVE CONTROL, NEURAL NETWORKS, MULTILAYER FEEDFORWARD, NONLINEAR, INVERSE MAPPING CONTROL, NETWORK PRUNING, ARTIFICIAL INTELLIGENCE </CLASSIFICATIONS>
<ABSTRACT>
This work describes research on nonlinear adaptive
control using multilayer feedforward neural networks. An
introduction to multilayer feedforward neural networks
is given followed by the summary of their application to
system modeling. Emphasis is on dynamic, nonlinear
systems. Subsequently, various approaches to inverse
dynamics control and their neural networks
implementation are discussed and presented. The inverse
mapping algorithm is used to build a so-called inverse
mapping controller. This controller is thoroughly tested
through simulations and several aspects of its behavior
are discussed.
The second main focus of this work is the reduction of
the neural networks models. The reduction of model size,
complexity and order is a very important aspect of
modeling. Since the reduction is strongly related to
network pruning, different approaches to network pruning
are discussed. Two methods, convergence suppression and
divergence facilitation and structural learning, based
on modified error-backpropagation training are
thoroughly analyzed in this context. The reduction of
model order based on neural network model size reduction
is also investigated. The discussion is illustrated with
several examples of both static and adaptive dynamic
cases.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  3711 </NUMBER>
<ORDER>   AAG1385298 </ORDER>
<TITLE> PARALLELIZING THE RETE-MATCH ALGORITHM FOR DISTRIBUTED MEMORY ARCHITECTURES </TITLE>
<AUTHOR> TAYYIB, MOHAMMED ABDUL-AZIZ HASSAN </AUTHOR>
<YEAR> 1996 </YEAR>
<INSTITUTION> KING FAHD UNIVERSITY OF PETROLEUM AND MINERALS (SAUDI ARABIA); 1088 </INSTITUTION>
<DESCRIPTORS> COMPUTER SCIENCE </DESCRIPTORS>
<ADVISER> NIL </ADVISER>
<CLASSIFICATIONS> NIL </CLASSIFICATIONS>
<ABSTRACT>
The Rete-Match algorithm is the main algorithm that is
used to develop Production Systems. A Production System
is a knowledge representation scheme in the Artificial
Intelligence. Although this algorithm is the fastest
known algorithm, for many patterns and many objects
matching, it still suffers from considerable amount of
time needed due to the recursive nature of the problem.
In this thesis, a parallel version of the Rete-Match
algorithm for distributed memory architectures is
designed, implemented, and analyzed. The implementation
of this parallel version accomplished considerable speed
up with respect to the number of processors over the
sequential execution of the Rete-Match algorithm.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  3712 </NUMBER>
<ORDER>   AAGMM18257 </ORDER>
<TITLE> HYBRID INTELLIGENT MATRIX SIMULATION SYSTEM FOR BCTMP PROCESS </TITLE>
<AUTHOR> FARZADEH, HASSAN </AUTHOR>
<YEAR> 1996 </YEAR>
<INSTITUTION> UNIVERSITY OF ALBERTA (CANADA); 0351 </INSTITUTION>
<DESCRIPTORS> ENGINEERING, SYSTEM SCIENCE; ENGINEERING, INDUSTRIAL; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> MING RAO </ADVISER>
<CLASSIFICATIONS> NIL </CLASSIFICATIONS>
<ABSTRACT>
This thesis describes the development of an Intelligent
Matrix Simulation system (IMS), a hybrid simulation
system for the operational support of a BCTMP pulp mill.
IMS combines features from neural networks, case based
reasoning, rule-based and frame-based intelligent
systems and simulates the process behavior. The IMS
knowledge base is organized using Meta-COOP frames. The
BCTMP process is divided into smaller subprocesses such
that each sub-process can be represented in one frame.
The inferencing in IMS is divided into a number of local
systems in terms of system functions and/or process
decomposition. Each local system integrates case based
reasoning (CBR), numerical calculation (NC), heuristic
rules (HR), and neural networks (NN) to solve individual
problems. IMS incorporates time-based historical process
data from MOPS, operational cost knowledge from the
relational database of Bale Quality Information System
(BQIS), mathematical simulation models, and experts
knowledge from the process and operations. It also
serves as a knowledge base for on-line fault diagnosis
and emergency handling in another module of IOMCS
project. (Abstract shortened by UMI.)
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  3713 </NUMBER>
<ORDER>   AAG9709325 </ORDER>
<TITLE> AN INFORMATION-THEORETIC PERSPECTIVE FOR LEARNING SYSTEMS WITH ENGINEERING APPLICATIONS </TITLE>
<AUTHOR> WANG, CHUAN </AUTHOR>
<YEAR> 1996 </YEAR>
<INSTITUTION> UNIVERSITY OF FLORIDA; 0070 </INSTITUTION>
<DESCRIPTORS> ENGINEERING, ELECTRONICS AND ELECTRICAL; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> JOSE C. PRINCIPE </ADVISER>
<CLASSIFICATIONS> ADAPTIVE FILTERS, NEURAL NETWORKS </CLASSIFICATIONS>
<ABSTRACT>
The major goal of this study is aimed at building a
unifying perspective for most learning systems (adaptive
filters and neural networks). A detailed analysis of the
adaptation rules is presented from the point of view of
generalized correlation learning. The analysis also
reveals that learning in recurrent networks is
equivalent to learning with second-order correlation
with different time lags, which highlights why recurrent
systems extract time information. It is well known that
supervised systems can be used either for static
learning (functional mapping MLPs) or temporal learning
(time delay neural networks or the Gamma model). But in
unsupervised learning, almost all neural networks are
trained statistically due to the absence of a teacher
signal. Therefore, a unified perspective of temporal
supervised and unsupervised learning requires a
mathematical extension to unsupervised learning. The
focus of extending static unsupervised systems to
temporal learning will be made with the Principal
Components Analysis (PCA) network. PCA is one of the
dominant networks in the unsupervised family and it is
based on the Hebbian rule which plays, by itself a
fundamental role for unsupervised learning. PCA in time
is examined in detail. It is shown that PCA in time
gives a set of adaptive time-varying orthogonal basis
ordered by variance which constitute the signal sub-
space. The relationships between PCA in time, Fourier
analysis, and wavelets are also pointed out. An
application to subspace adaptive filtering is outlined
which decreases significantly the training time. Then,
as an application of the PCA concepts to time
processing, a neural topology to compute the
crosscorrelation and autocorrelation on-line is
proposed. The algorithm exploits the unifying
perspective developed for the learning rules based on
correlation learning. This network is then used for
blind sources separation, which is a difficult problem
because the solution must estimate the transfer function
of a linear system based on the outputs of the system
alone. We then turn to the other goal of the thesis--to
propose a unified perspective for both supervised and
unsupervised learning. A simple but poorly understood
relationship between supervised and unsupervised
learning is revealed. It is shown that when the desired
signal is a zero mean noise, the supervised learning is
statistically equivalent to unsupervised learning. This
result combined with the knowledge of autoassociative
learning provides a basis to present a perspective for
learning from the point of view of information theory.
The main theoretical conclusion of the thesis can be
outlined as: In a supervised learning system, when the
mutual information between the input and the desired
signal reaches its extreme (maximum or minimum) the
learning degenerates into an unsupervised paradigm. With
this perspective, the classification of learning in
supervised or unsupervised is not only based on the
existence of a desired signal but must also take into
consideration the relationship between the external
signals.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  3714 </NUMBER>
<ORDER>   AAG9709263 </ORDER>
<TITLE> A SIMULATION-BASED APPROACH FOR DECISION MAKING AND ROUTE PLANNING  </TITLE>
<AUTHOR> LEE, JIN JOO </AUTHOR>
<YEAR> 1996 </YEAR>
<INSTITUTION> UNIVERSITY OF FLORIDA; 0070 </INSTITUTION>
<DESCRIPTORS> COMPUTER SCIENCE; ENGINEERING, INDUSTRIAL; OPERATIONS RESEARCH </DESCRIPTORS>
<ADVISER> PAUL A. FISHWICK </ADVISER>
<CLASSIFICATIONS> ARTIFICIAL INTELLIGENCE, INTELLIGENT CONTROL </CLASSIFICATIONS>
<ABSTRACT>
Decision making is an active area of research in
simulation, systems engineering and artificial
intelligence. One subset area of decision making,
automated route planning, is covered in this work with
our approach based on the technique of simulation rather
than on purely heuristic or geometric techniques. This
new technique is called simulation-based planning (SBP).
Simulation-based planning is useful for route planning
under various conditions including uncertain locations
and events with potential adversarial activity. We
propose that it is only by using simulation that one can
make the most effective plan in uncertain and complex
environments.
SBP extends the planning area mainly in three aspects.
First, probabilistic uncertainty is handled through
detailed and replicated simulation of models rather than
solving them analytically, for example, using
probability theory. Second, simulation models naturally
extend the level of reasoning to greater detail, often
involving continuous state space. Thus, SBP is able to
produce plans that are closer to the level of execution.
Additionally, one can often discover subtleties that may
be missed by higher level planners which are often rule-
based. Third, the complexity of multiagent adversarial
planning breaks down when object-oriented multimodel
simulation is used. Here, each agent or adversary is
individually modeled and simulated in response to each
plan. In addition, to ensure that SBP can be used within
reasonable time constraints, we develop general
experimental design algorithms and techniques which
reduce the overall simulation time.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  3715 </NUMBER>
<ORDER>   AAG9709208 </ORDER>
<TITLE> ON DECISION TREE INDUCTION FOR KNOWLEDGE DISCOVERY IN VERY LARGE DATABASES </TITLE>
<AUTHOR> ARGUELLO VENEGAS, JOSE RONALD </AUTHOR>
<YEAR> 1996 </YEAR>
<INSTITUTION> UNIVERSITY OF FLORIDA; 0070 </INSTITUTION>
<DESCRIPTORS> COMPUTER SCIENCE; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> SHARMA CHAKRAVARTHY </ADVISER>
<CLASSIFICATIONS> ASSOCIATION RULES, CLASSIFICATION, SELECTION METRICS, ARTIFICIAL INTELLIGENCE </CLASSIFICATIONS>
<ABSTRACT>
Knowledge Discovery in Databases is the process of
extracting new patterns from existing data. Decision
Tree Induction is the process of creating decision trees
from samples of data and validating them for the whole
data base. The approach taken in this project uses
decision trees not just for solving the classification
problem in Knowledge Discovery; but for forming
association rules from them which are in effect new and
explicit knowledge. Several performance problems need to
be addressed for using a decision tree approach to large
scale databases. I offer a new criterion which is better
suited to decision tree construction and its mapping to
association rules. The emphasis is on efficient,
incremental, and parallel algorithms as effective ways
to deal with large amounts of data. Comparisons with
existent systems are shown to illustrate the
applicability of the solution described in this
dissertation to the problem of finding rules (knowledge
discovery) and classifying data in very large databases.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  3716 </NUMBER>
<ORDER>   AAG9709069 </ORDER>
<TITLE> ALGORITHMS FOR SEQUENTIAL DECISION-MAKING </TITLE>
<AUTHOR> LITTMAN, MICHAEL LEDERMAN </AUTHOR>
<YEAR> 1996 </YEAR>
<INSTITUTION> BROWN UNIVERSITY; 0024 </INSTITUTION>
<DESCRIPTORS> COMPUTER SCIENCE; OPERATIONS RESEARCH; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> NIL </ADVISER>
<CLASSIFICATIONS> INTELLIGENT AGENTS, MARKOV DECISION PROCESS, GAME THEORY </CLASSIFICATIONS>
<ABSTRACT>
Sequential decision making is a fundamental task faced
by any intelligent agent in an extended interaction with
its environment; it is the act of answering the question
"What should I do now?" In this thesis, I show how to
answer this question when "now" is one of a finite set
of states, "do" is one of a finite set of actions,
"should" is maximize a long-run measure of reward, and
"I" is an automated planning or learning system (agent).
In particular, I collect basic results concerning
methods for finding optimal (or near-optimal) behavior
in several different kinds of model environments: Markov
decision processes, in which the agent always knows its
state; partially observable Markov decision processes
(scPOMDPS), in which the agent must piece together its
state on the basis of observations it makes; and Markov
games, in which the agent is in direct competition with
an opponent. The thesis is written from a computer-
science perspective, meaning that many mathematical
details are not discussed, and descriptions of
algorithms and the complexity of problems are
emphasized. New results include an improved algorithm
for solving scPOMDPS exactly over finite horizons, a
method for learning minimax-optimal policies for Markov
games, a pseudopolynomial bound for policy iteration,
and a complete complexity theory for finding zero-reward
scPOMDP policies.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  3717 </NUMBER>
<ORDER>   AAG9708818 </ORDER>
<TITLE> SOLVING COMBINATORIAL OPTIMISATION PROBLEMS USING NEURAL NETWORKS  </TITLE>
<AUTHOR> SMITH, KATE AMANDA </AUTHOR>
<YEAR> 1996 </YEAR>
<INSTITUTION> UNIVERSITY OF MELBOURNE (AUSTRALIA); 0123 </INSTITUTION>
<DESCRIPTORS> OPERATIONS RESEARCH; ENGINEERING, ELECTRONICS AND ELECTRICAL; COMPUTER SCIENCE; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> M. PALANISWAMI </ADVISER>
<CLASSIFICATIONS> TRAVELING SALESMAN PROBLEM </CLASSIFICATIONS>
<ABSTRACT>
Combinatorial optimisation problems (COP's) arise
naturally when mathematically modelling many practical
optimisation problems from science and engineering.
Unfortunately, existing neural techniques are widely
considered to be unsuited to optimisation due to their
tendency to produce infeasible or poor quality
solutions.
Over the last decade or so, two main types of neural
networks have been proposed for solving COP's--in
particular, the Travelling Salesman Problem (TSP). The
first of these neural approaches is the Hopfield neural
network which evolves in such a way as to minimise a
system energy function. In its original form, the
Hopfield energy function involves many parameters which
need to be tuned, and constructing a suitable energy
function which enables the network to arrive at feasible
near-optimal solutions is a difficult task. The other
main neural approach found in the literature is based
upon the theory of self-organisation. The vast majority
of research into self-organisation for solving COP's
however, has been restricted to solving the TSP. The
reason for this focus on the TSP is not just because of
its standing as a benchmark problem, but more because
most of these networks are embedded into the Euclidean
plane by their dependence on the Elastic Net method.
Consequently, results cannot be generalised to solve
many COP's arising from practical situations which are
not restricted to the Euclidean plane.
In this thesis, modifications are made to the Hopfield
neural network to enable escape from local minima, while
feasibility of the solutions is ensured. Convergence and
stability properties are analysed through a dynamical
systems perspective and are less restrictive than those
commonly accepted in the literature. A new self-
organising neural network is also designed which
generalises to solve a broad class of COP's. The
approach is purely combinatorial in nature, operating on
feasible permutation matrices rather than within any
restrictive geometric structures. Convergence properties
are also discussed.
The wide applicability of these neural techniques is
demonstrated in this thesis through the solution of
three practical COP's which have arisen from various
areas of Australian industry: car manufacturing, postal
services, and telecommunications.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  3718 </NUMBER>
<ORDER>   AAG9708676 </ORDER>
<TITLE> FUZZY IDENTIFICATION OF PROCESSES ON FINITE TRAINING SETS WITH KNOWN FEATURES </TITLE>
<AUTHOR> DIAZ-ROBAINAS, REGINO R. </AUTHOR>
<YEAR> 1996 </YEAR>
<INSTITUTION> FLORIDA ATLANTIC UNIVERSITY; 0119 </INSTITUTION>
<DESCRIPTORS> ENGINEERING, ELECTRONICS AND ELECTRICAL; MATHEMATICS; LANGUAGE, LINGUISTICS; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> MING ZEN HUANG; ALI ZILOUCHIAN </ADVISER>
<CLASSIFICATIONS> NIL </CLASSIFICATIONS>
<ABSTRACT>
A methodology is presented to construct an approximate
fuzzy-mapping algorithm that maps multiple inputs to
single outputs given a finite training set of argument
vectors functionally linked to corresponding scalar
outputs. Its scope is limited to problems where the
features are known in advance, or equivalently, where
the expected functional representation is known to
depend exclusively on the known selected variables.
Programming and simulations to implement the methodology
make use of Matlab Fuzzy and Neural toolboxes and a PC
application of Prolog, and applications range from
approximate representations of the direct kinematics of
parallel manipulators to fuzzy controllers.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  3719 </NUMBER>
<ORDER>   AAG9708323 </ORDER>
<TITLE> THE MATHEMATICS OF TRIANGULAR FUZZY NUMBERS TO SUPPORT A MODEL OF IMPRECISION IN DESIGN </TITLE>
<AUTHOR> GIACHETTI, RONALD EDWARD </AUTHOR>
<YEAR> 1996 </YEAR>
<INSTITUTION> NORTH CAROLINA STATE UNIVERSITY; 0155 </INSTITUTION>
<DESCRIPTORS> ENGINEERING, INDUSTRIAL; MATHEMATICS; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> NIL </ADVISER>
<CLASSIFICATIONS> FUZZY SET THEORY, CONCURRENT ENGINEERING </CLASSIFICATIONS>
<ABSTRACT>
Design is characterized by high levels of imprecision,
vague parameters, and ill-defined relationships. Few
design systems exist for adequately representing design
imprecision. Fuzzy set theory has considerable potential
for addressing the imprecision in design. Engineering
design is usually described in a domain of equations and
other mathematical relationships. Problems where fuzzy
sets have previously been applied are usually described
by rules, not mathematical expressions. While the
mathematics of fuzzy sets has been developed
theoretically, there are few implementations. One
obstacle of implementing fuzzy sets in design is
implementing the nonlinear operators of multiplication
and division. Direct calculation is computationally
complex and the existing approximations result in large
errors. This research begins by establishing the
requirement for modeling imprecision in design. This
research presents a model for using fuzzy mathematics in
design. Implementation of the design model requires a
review of fuzzy mathematics and the approximations used.
Analysis of the mathematical operators and the
approximation errors involved reveals that the existing
approaches are either computationally complex or may
result in significant errors. A new approximation is
developed which is computationally feasible for
implementation in a design support system. The new
approximation can be used in a system of algebraic
constraint and maintains some useful arithmetic
properties. The modeling techniques are demonstrated
with a design example which is solved and analyzed using
the new approximation. This approach appears to have
utility in solving concurrent engineering problems.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  3720 </NUMBER>
<ORDER>   AAG9708046 </ORDER>
<TITLE> SHARED EXPERTISE MODEL FOR BUILDING INTERACTIVE LEARNING AGENTS  </TITLE>
<AUTHOR> DYBALA, TOMASZ </AUTHOR>
<YEAR> 1996 </YEAR>
<INSTITUTION> GEORGE MASON UNIVERSITY; 0883 </INSTITUTION>
<DESCRIPTORS> COMPUTER SCIENCE; INFORMATION SCIENCE; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> GHEORGHE TECUCU </ADVISER>
<CLASSIFICATIONS> MACHINE LEARNING </CLASSIFICATIONS>
<ABSTRACT>
The research goal of this dissertation is to define,
implement and apply the Shared Expertise Model to build
interactive learning agents in complex real-world
domains. An interactive learning agent is a specialized
knowledge-based system that can be taught by a user to
assist him, or other users, in various ways.
The theoretical foundation for the Shared Expertise
Model is an integration of apprenticeship and
multistrategy learning methods, within the Plausible
Version Space paradigm. The model allows an expert to
teach the agent in much the same way in which the expert
would teach a human apprentice--by giving the agent
specific examples of tasks and solutions, providing
explanations of these solutions, and supervising the
agent as it performs new tasks. During such
interactions, the expert shares his expertise with the
agent, which is continuously extending and improving its
knowledge and performance abilities. These kinds of
agent capabilities are achieved by a synergistic
integration of several learning and knowledge
acquisition methods: systematic elicitation of
knowledge, empirical inductive learning from examples,
learning from explanations, and learning by analogy and
experimentation.
A software toolkit called DISCIPLE and a methodology for
using it to build learning agents for various domains
are used to validate the Shared Expertise Model. The
toolkit and the methodology have been experimentally
verified and validated by developing a knowledge base
for a personal assistant of a computer workstation
configuration specialist, and an assessment agent for
users of the Multimedia and Thinking Skills system.
The main contributions of this thesis are: the
development of the Shared Expertise Model, the toolkit
implementation of the model, and the development of
experimental agents for several complex domains.
Specific technical contributions are: the development of
a modular architecture of the toolkit, Knowledge Query
Language, Knowledge Elicitation Tools, and Learning
Tools.
The main claim made by this thesis is that the knowledge
acquisition bottleneck can be overcome by teaching the
agent, rather than manually encoding its knowledge. This
is mainly achieved by the Shared Expertise Model of
interaction between the instructor and the agent, and by
use of the Plausible Version Space learning paradigm.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  3721 </NUMBER>
<ORDER>   AAG9707841 </ORDER>
<TITLE> NEURAL NETWORKS WITH FOURIER PLANE NONLINEAR FILTERING FOR PATTERN RECOGNITION </TITLE>
<AUTHOR> LI, JIAN </AUTHOR>
<YEAR> 1996 </YEAR>
<INSTITUTION> THE UNIVERSITY OF CONNECTICUT; 0056 </INSTITUTION>
<DESCRIPTORS> ENGINEERING, ELECTRONICS AND ELECTRICAL; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> NIL </ADVISER>
<CLASSIFICATIONS> NIL </CLASSIFICATIONS>
<ABSTRACT>
We propose using Fourier plane nonlinear filtering to
construct a two-layer neural network for pattern
recognition. Nonlinear filtering techniques are used
between the input layer and the first layer. We show
that nonlinear filtering forms a locally closed convex
region in the pattern space, which can be easily used to
approximate any complex region. We show that a two-layer
network with nonlinear filters can be used to form
complex regions for complicated pattern recognition
problems. This two-layer network has the following
advantages: the size of the network is comparatively
small; the training is always convergent; and the
network does not necessarily need the information from
the other classes to form the decision region.
Phase encoding of the reference pattern for the Fourier
plane nonlinear filtering is analyzed. We show that
phase encoded nonlinear filtering can be used to
construct a two-layer network for pattern recognition.
The advantage of using phase encoding is its security.
Composite images can be formed from the training images.
When the composite images are used as the connecting
weights, the hidden units can be reduced. We construct a
two-layer network using nonlinear filters with composite
images for face recognition.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  3722 </NUMBER>
<ORDER>   AAG9707661 </ORDER>
<TITLE> SEMANTICS OF KNOWLEDGE-BASED SYSTEMS WITH MULTIPLE FORMS OF NEGATION  </TITLE>
<AUTHOR> RUIZ, CAROLINA </AUTHOR>
<YEAR> 1996 </YEAR>
<INSTITUTION> UNIVERSITY OF MARYLAND COLLEGE PARK; 0117 </INSTITUTION>
<DESCRIPTORS> COMPUTER SCIENCE; ARTIFICIAL INTELLIGENCE; INFORMATION SCIENCE </DESCRIPTORS>
<ADVISER> JACK MINKER </ADVISER>
<CLASSIFICATIONS> ARTIFICIAL INTELLIGENCE, INTELLIGENT DATABASES </CLASSIFICATIONS>
<ABSTRACT>
This dissertation introduces and investigates formalisms
that admit several forms of default negation which
interact with each other and with explicit negation in
the same application. Some theoretical aspects of this
research include the investigation of the expressive
power of the new formalisms and the characterization of
their semantics. Practical issues include the
implementation of inference mechanisms to compute in
these formalisms and the calculation of the
computational complexity of different reasoning tasks
under the proposed semantics. One application of these
formalisms is to the problem of merging several
knowledge bases, each of which uses a different rule for
negation, and finding answers to queries in the combined
knowledge base.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  3723 </NUMBER>
<ORDER>   AAGMM17719 </ORDER>
<TITLE> SURVEILLANCE EN LIGNE PAR RESEAUX NEURONAUX DES SYSTEMES ASSERVIS  </TITLE>
<AUTHOR> MARTIN, STEPHANE </AUTHOR>
<YEAR> 1996 </YEAR>
<INSTITUTION> ECOLE POLYTECHNIQUE, MONTREAL (CANADA); 1105 </INSTITUTION>
<DESCRIPTORS> ENGINEERING, ELECTRONICS AND ELECTRICAL; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> RICHARD J. MARLEAU; INNOCENT KAMWA </ADVISER>
<CLASSIFICATIONS> FRENCH TEXT, NEURAL NETWORKS, HYDRAULIC GENERATOR </CLASSIFICATIONS>
<ABSTRACT>
The subject of this thesis is to explore the diagnostic
capacity of neural networks to detect faults or latent
problems in the control system of a plant. The
particular control system considered here is that of a
hydraulic generator. To be more specific, we will target
the voltage regulator and the stabilizer.
The thesis comprises two parts. The first consists of
two chapters dealing with the numerical model of the
dynamic system monitored. Details are given of each
component of a complete model of a synchronous generator
built and validated in Matlab/Simulink software on the
basis of other standard models from highly specialized
and complex software.
The second part of the thesis describes the application
of the Simulink model of the generator for testing the
devised strategy for fault detection. This strategy uses
neural networks to identify and predict the dynamic
behaviour of the monitored system. One predictor model
(MPSF) is trained off line with the signals of a healthy
system. The second, a predictor model of the current
system (MPSA), is trained in real time with currently
available signals (possibly reflecting a degraded
dynamic system) and can be qualified as a short-term
model.
The performance of three types of neural networks is
evaluated: the conventional feedforward network, the
memory neuron network and a recurrent network. The
memory neuron, a hybrid network between the feedforward
and recurrent networks, is used as the predictor model
to present our example of discrimination between a
healthy system and defective systems. The results show
the potential of the detection strategy applied to a
complex model of the hydraulic generator with many
nonlinearities. (Abstract shortened by UMI.)
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  3724 </NUMBER>
<ORDER>   AAG9707638 </ORDER>
<TITLE> AUTOMATED DISCOVERY OF SELF-REPLICATING STRUCTURES IN CELLULAR SPACE AUTOMATA MODELS </TITLE>
<AUTHOR> LOHN, JASON D. </AUTHOR>
<YEAR> 1996 </YEAR>
<INSTITUTION> UNIVERSITY OF MARYLAND COLLEGE PARK; 0117 </INSTITUTION>
<DESCRIPTORS> ENGINEERING, ELECTRONICS AND ELECTRICAL; COMPUTER SCIENCE; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> ROBERT W. NEWCOMB </ADVISER>
<CLASSIFICATIONS> GENETIC ALGORITHMS, RULE DISCOVERY </CLASSIFICATIONS>
<ABSTRACT>
This thesis demonstrates for the first time that it is
possible to automatically discover self-replicating
structures in cellular space automata models rather
than, as has been done in the past, to design them
manually. Self-replication is defined as the process an
entity undergoes in constructing a copy of itself. Von
Neumann was the first to investigate artificial self-
replicating structures and did so in the context of
cellular automata, a cellular space model consisting of
numerous finite-state machines embedded in a regular
tessellation. Interest in artificial self-replicating
systems has increased in recent years due to potential
applications in molecular-scale manufacturing,
programming parallel computing systems, and digital
hardware design, and also as part of the field of
artificial life.
In this dissertation, genetic algorithms are used with a
cellular automata framework for the first time to
automatically discover self-replicating structures. The
discovered self-replicating structures compare favorably
in terms of simplicity with those generated manually in
the past but differ in unexpected ways. This
dissertation presents representative samples of the self-
replicating structures and analyses them both
quantitatively and qualitatively. In order to
effectively search the underlying rule space of such
automata models, a fitness function consisting of three
independent criteria is designed and successfully
applied. Also, a new cellular space automata model
called effector automata is introduced. It is shown to
be more computationally feasible and to promote the
discovery of more self-replicating structures as
compared to the cellular automata models used in
previous studies. In addition, a new paradigm for
cellular space models with weak rotational symmetry
called component-sensitive input is introduced and shown
to facilitate discovery of self-replicating structures.
The results presented suggest that genetic algorithms
can be powerful tools for exploring the space of
possible self-replicating structures. Furthermore, this
research sheds light on the nature of creating self-
replicating structures and opens the door to further
studies that could eventually lead to the discovery of
new self-replicating molecular structures.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  3725 </NUMBER>
<ORDER>   AAG9707583 </ORDER>
<TITLE> SELF-REPLICATING STRUCTURES IN A CELLULAR AUTOMATA SPACE </TITLE>
<AUTHOR> CHOU, HUI-HSIEN </AUTHOR>
<YEAR> 1996 </YEAR>
<INSTITUTION> UNIVERSITY OF MARYLAND COLLEGE PARK; 0117 </INSTITUTION>
<DESCRIPTORS> COMPUTER SCIENCE; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> JAMES A. REGGIA </ADVISER>
<CLASSIFICATIONS> ARTIFICIAL INTELLIGENCE </CLASSIFICATIONS>
<ABSTRACT>
Biological experience and intuition suggest that self-
replication is an inherently complex phenomenon, and
early cellular automata self-replication models
developed by computer scientists and mathematicians
supported that view. However, since von Neumann's
original work in the 1950's, the study of cellular
automata models of self-replicating systems has
progressively led to smaller and simpler systems. This
thesis demonstrates for the first time that it is
possible to create automatically self-replicating
structures in cellular automata models rather than, as
has been done in the past, to design them manually.
These emergent self-replicating structure employ a
General Purpose Self-Replicating cellular automata rule
set which can support the replication of structures of
different sizes and their growth from smaller to larger
ones. This thesis demonstrates that, by letting self-
replicating structures carry additional information
besides replication instructions, they can be used to
solve computationally hard problems such as the
Satisfiability (SAT) problem. It is shown that self-
replicating structures can be made to carry
characteristic codes and selection forces can be
implemented in cellular automata space. This study opens
the door to further studies that could lead to general,
solution-evolvable structures and truly self-programming
systems.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  3726 </NUMBER>
<ORDER>   AAG0597571 </ORDER>
<TITLE> GRAMMATICAL BIAS FOR EVOLUTIONARY LEARNING </TITLE>
<AUTHOR> WHIGHAM, PETER ALEXANDER </AUTHOR>
<YEAR> 1996 </YEAR>
<INSTITUTION> UNIVERSITY OF NEW SOUTH WALES (AUSTRALIA); 0423 </INSTITUTION>
<DESCRIPTORS> COMPUTER SCIENCE; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> NIL </ADVISER>
<CLASSIFICATIONS> INDUCTION, ARTIFICIAL INTELLIGENCE </CLASSIFICATIONS>
<ABSTRACT>
A framework for declarative bias, based on the genetic
programming paradigm (GP), is presented. The system, CFG-
GP, encapsulates background knowledge, inductive bias
and program structure. A context-free grammar is used to
create a population of programs, represented by their
corresponding derivation trees. These computer programs
evolve using the principle of Darwinian selection. The
grammar biases the form of language that is expressible
and the inductive hypotheses that are generated. Using a
formal grammar to define the space of legal statements
allows a declarative language bias to be stated. The
defined language may express knowledge in the form of
program structure and incorporate explicit beliefs about
the structure of possible solutions. Additionally, the
form of the initial population of programs may be
explicitly biased using a merit selection operation.
This probabilistically biases particular statements
generated from the grammar.
The program induction system, CFG-GP, represents search
bias with three operators, namely selective crossover,
selective mutation and directed mutation. Each of these
operators allows a bias to be explicitly defined in
terms of how programs are modified and how the search
for a solution proceeds. Hence, both a search and
language bias are declaratively represented in an
evolutionary framework.
The use of a grammar to define language bias explicitly
separates this bias from the learning system. Hence, the
opportunity exists for the learning system to modify
this bias as an additional strategy for learning. A
general technique is described to modify the initial
grammar while the evolution for a solution proceeds.
Feedback between the evolving grammar and the population
of programs is shown to improve the convergence of the
learning system. The generalising properties of the
learnt grammar are demonstrated by incrementally
adapting a grammar for a class of problems.
A theoretical framework, based on the schema theorem for
Genetic Algorithms (GA), is presented for CFG-GP. The
formal structure of a grammar allows a clear and concise
definition of a building block for a general program.
The result is shown to be a generalisation of both fixed-
length (GA) and variable-length (GP) representations
within the one framework.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  3727 </NUMBER>
<ORDER>   AAG0577870 </ORDER>
<TITLE> INCREMENTING INDUSTRIAL COST SAVINGS THROUGH INTELLIGENT DEMAND MANAGEMENT </TITLE>
<AUTHOR> ROOS, JOHANNES GYSBERTUS </AUTHOR>
<YEAR> 1996 </YEAR>
<INSTITUTION> UNIVERSITY OF PRETORIA (SOUTH AFRICA); 6004 </INSTITUTION>
<DESCRIPTORS> ENGINEERING, ELECTRONICS AND ELECTRICAL; ENERGY; ENGINEERING, INDUSTRIAL; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> I. E. LANE </ADVISER>
<CLASSIFICATIONS> ARTIFICIAL INTELLIGENCE, LOAD MANAGMEMENT </CLASSIFICATIONS>
<ABSTRACT>
Industrial load management is any action taken by
industrial end users of electricity and/or the utility
to change the end user's present load curve shape in
order to gain from reduced total system peak loads,
increased load factors and improved utilisation of
scarce and expensive resources.
In a literature survey that is conducted on the topic of
industrial load management, it became evident that
dynamic electricity tariffs, and especially the real-
time pricing tariff, are excellent management
alternatives with which the utility may attempt to reach
its energy conservation as well as demand-side
management goals.
However, there is a lack of information observed in the
literature with regard to knowledge of this tariff
structure's cost saving potential to industrial end
users when demand management is applied, and the cost of
unserved energy due to the implementation of these
demand management actions. One of the main objectives of
this thesis is therefore to acquire and provide the
necessary knowledge of the cost saving potential of real-
time pricing due to demand management, and the
associated cost of unserved energy. An analytical
approach is followed to propose an optimal demand
control strategy in order to minimize the electricity
costs of an industrial end user. Knowledge in the form
of originally derived mathematical expressions and
qualitative reasoning are obtained which give more
insight into the identified need.
The cost saving potential is expressed as a function of
variables familiar to the end user and utility. These
variables describe the real-time pricing structure, the
configuration constraints of the plant, and the spare
energy consumption capacity of the end user. A
qualitative description of the cost of unserved energy
due to demand control under real-time pricing is given.
A methodology is proposed which may be followed in
customizing an electricity tariff during a bilateral
negotiation process between the end user and the
utility. A knowledge-based end user demand response
modelling tool to serve as a decision support system in
this process is proposed, developed, and evaluated in an
industrial case study. The potential and feasibility of
this demand response modelling tool is demonstrated.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  3728 </NUMBER>
<ORDER>   AAGNN13663 </ORDER>
<TITLE> AUTOMATED TOOL CONDITION MONITORING IN MACHINING USING FUZZY NEURAL NETWORKS </TITLE>
<AUTHOR> LI, SHENGMU </AUTHOR>
<YEAR> 1996 </YEAR>
<INSTITUTION> MCMASTER UNIVERSITY (CANADA); 0197 </INSTITUTION>
<DESCRIPTORS> ENGINEERING, MECHANICAL; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> M. A. ELBESTAWI </ADVISER>
<CLASSIFICATIONS> NIL </CLASSIFICATIONS>
<ABSTRACT>
A new approach for automated tool condition monitoring
in machining by using fuzzy neural networks is proposed.
The Multiple Principal Component (MPC) fuzzy neural
networks are built based on three major components of
soft computation, namely fuzzy logic, neural networks,
and probability reasoning.
The system architecture is a partially connected neural
network with fuzzy classification at neurons and fuzzy
membership grades for interconnections. Principal
component analyses in multiple directions are
implemented for the feature extraction and the "maximum
partition". The partitions of the learning samples are
based on the distributions of the monitoring indices in
the principal component directions. A fuzzy membership
function is used to measure uncertainties in the sampled
data and to form "soft boundaries" between the classes.
A processing element in the network is connected to
others through the fuzzy membership grades and other
information available. The partial connections make
short training times and short routines in
classifications.
Three major issues in developing the MPC fuzzy neural
networks are supervised classification, unsupervised
classification and knowledge updating. The system
obtains the knowledge about classifications by learning.
The learning samples are obtained from cutting tests
performed through a reasonable range of cutting
conditions.
Several sensors are used for monitoring feature
extraction. The signals from different types of sensors
at different locations insure that the most significant
information about the changes in tool conditions is
collected. Metal cutting mechanics are first considered
for the sensor selection and the sensor allocation. The
measured signals are further analyzed and the monitoring
features are extracted. These indices are the inputs for
the fuzzy neural networks. The tool conditions
considered include sharp tool, tool breakage, and a few
selected stages of tool wear. The experimental results
in turning and drilling have shown good performance of
the proposed monitoring system in these tests.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  3729 </NUMBER>
<ORDER>   AAGNN13623 </ORDER>
<TITLE> INVESTIGATION OF THE EFFECTS OF QUANTIZATION ERRORS ON THE PERFORMANCE OF NEURAL NETWORKS </TITLE>
<AUTHOR> SEN, SELCUK </AUTHOR>
<YEAR> 1996 </YEAR>
<INSTITUTION> TECHNICAL UNIVERSITY OF NOVA SCOTIA (CANADA); 0300 </INSTITUTION>
<DESCRIPTORS> ENGINEERING, ELECTRONICS AND ELECTRICAL; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> WILLIAM ROBERTSON </ADVISER>
<CLASSIFICATIONS> NIL </CLASSIFICATIONS>
<ABSTRACT>
This thesis is concerned with the investigation of the
errors on the performance of neural networks. The
measurement of output performance of the neural networks
is an important consideration in th hardware design of
the neural networks. To this end, the ability to predict
the performance degradation both in multi layer
perceptrons (MLP) and radial basis functions (RBF) is
demonstrated by using a statistical approach. Using a
statistical approach, a formula that predicts the
standard deviation of output errors for both MLP and RBF
based on the network parameters is derived. These
parameters are the weight, input distributions, the
number of units, and the number of layers for the MLP,
whereas the input, cluster center distributions, the
imput dimension, and the average width of a cluster
center distributions, the imput dimension, and the
average width of a cluster center of RBF. In addition,
The formula can be used to determine the required number
of bits for successful operation in the feed forward
recall phase for the MLP, and the recall phase of the
RBF. The successful operation of an application is
solely dependent of what type of output recognition is
desirably by the designer. Two real time speech
processing problems are designed to demonstrate the
experimental (simulation) results as well as the
theoretical results. These examples are chosen so that
they both could be representative of typical speech
recognition applications solved by two neural network
architectures. The first example chosen is for the
recognition of unvoiced stop consonants by the means of
a time delay neural network (TDNN), and the other is a
single digit recognition neural network (SDNN). The same
problems are also adapted to be used in the case of RBF.
The theoretical results of these two examples agree
closely with simulation results for both neural network
architectures.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  3730 </NUMBER>
<ORDER>   AAGNN13490 </ORDER>
<TITLE> DISTRIBUTED MODELING AND CONTROL OF NONLINEAR SYSTEMS WITH APPLICATIONS IN ROBOTICS: A FUZZY LOGIC-BASED SWITCHING APPROACH  </TITLE>
<AUTHOR> RUEDA MEZA, JOSE ALEJANDRO </AUTHOR>
<YEAR> 1996 </YEAR>
<INSTITUTION> THE UNIVERSITY OF MANITOBA (CANADA); 0303 </INSTITUTION>
<DESCRIPTORS> ENGINEERING, ELECTRONICS AND ELECTRICAL; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> WITOLD PEDRYCZ </ADVISER>
<CLASSIFICATIONS> ARTIFICIAL INTELLIGENCE, COMPLEX SYSTEMS </CLASSIFICATIONS>
<ABSTRACT>
The problem of modeling and control of complex systems
is studied in this thesis. A hierarchical structure
designed using qualitative information is used to
coordinate the operation of a number of local modules.
The coordination system consists of a fuzzy logic
processor. A design method is proposed and a number of
analytical results are presented. The hierarchical
architecture is applied to the design of distributed
controllers and distributed models. Application examples
of modeling and control in the area of robotics are
considered. This thesis demonstrates that certain
artificial intelligence techniques along with standard
methods can provide excellent and practical results in
complex modeling and control problems.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  3731 </NUMBER>
<ORDER>   AAGNN13227 </ORDER>
<TITLE> A HYPERMEDIA-BASED INTELLIGENT COMPUTER-ASSISTED INSTRUCTION MODEL  </TITLE>
<AUTHOR> JOSHUA, OGAZI ROSE </AUTHOR>
<YEAR> 1996 </YEAR>
<INSTITUTION> THE UNIVERSITY OF MANITOBA (CANADA); 0303 </INSTITUTION>
<DESCRIPTORS> COMPUTER SCIENCE; EDUCATION, CURRICULUM AND INSTRUCTION; EDUCATION, TECHNOLOGY; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> D. H. SCUSE </ADVISER>
<CLASSIFICATIONS> TUTORING </CLASSIFICATIONS>
<ABSTRACT>
A model for intelligent tutoring is discussed whose aim
is to provide an adaptive system that directs a student
to high-level mastery of learned concepts. Several open
problems exist in intelligent tutoring, including
adaptivity, sufficient subject matter, explanations,
student modeling and identification and revision of
beliefs. Expert-system-based tutors lack sufficient
subject matter while hypermedia-based tutors lack
inference knowledge and cannot provide intelligent
tutoring. We have combined these two technologies for
detailed study material as well as intelligent
interaction with a student. Our model components include
the Tutoring Strategy Module, Student Modeling Module,
Expert Problem-Solver, Knowledge-base, Dynamic Questions
Module, Study-Management Module, and the hypermedia
component providing an electronic textbook and a
browser. The adaptive and opportunistic tutor addresses
misconceptions as they occur, and receives adaptation
input from the Modeler. We also propose the Collection
and Invitation intervention technique by which the tutor
would not offer solution assistance to a student unless
otherwise directed. Our Modeler differs from the
traditional overlay and buggy models by performing
solution-strategy-independent modeling based on the
correctness and completeness of a student's solution.
Using the final result obtained by the Expert Problem-
Solver, it uses the knowledge-base to compute a set of
paths to the same solution, identifies student beliefs
from interactions, and identifies which paths are
applied by the student based on the frequencies of
beliefs in the computed strategy-base. The Modeler does
not employ a mal-rule-base but labels beliefs and
identifies misconceptions and missing beliefs by
processing the knowledge-base. It also performs
Instructional Belief Update by maintaining two belief
sets and removing contradictions from an opposing belief-
set before arriving beliefs are stored. For belief
revision we have defined an improved coherencist scheme
based on the resolvent model developed by Dalal (1988).
We have also specified algorithms for components of the
Modeler which are of reasonable running times. The
Expert Problem-Solver as well as the alternative-path-
computation phase of the Modeler have been implemented.
The thesis has contributed to intelligent tutoring
research in three ways: solution-strategy-independent
modeling, identification of misconceptions using the
knowledge base rather than a mal-rule set, and the
improved belief revision scheme which incorporates
derived beliefs, adjusts the status of persistent
beliefs whose justifiers have been detected, and does
not fail in multiple contradictions.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  3732 </NUMBER>
<ORDER>   AAGNN12404 </ORDER>
<TITLE> FAULT DIAGNOSIS IN MOBILE MINING EQUIPMENT </TITLE>
<AUTHOR> KNIGHTS, PETER FIELDEN </AUTHOR>
<YEAR> 1996 </YEAR>
<INSTITUTION> MCGILL UNIVERSITY (CANADA); 0781 </INSTITUTION>
<DESCRIPTORS> ENGINEERING, MINING; INFORMATION SCIENCE </DESCRIPTORS>
<ADVISER> L. K. DANESHMEND; J. PECK </ADVISER>
<CLASSIFICATIONS> DECISION SUPPORT, INTRANETS </CLASSIFICATIONS>
<ABSTRACT>
The development of decision support systems for
equipment diagnosis has been found to be an iterative
process whereby functionality and knowledge are
continually added to a prototype until satisfactory
performance is achieved. In order to reduce both the
dependency on compiled knowledge sources and the number
of prototype stages necessary to develop diagnostic
decision support systems, this thesis examines, adapts
and applies a set theoretical approach to mechanism
diagnosis first developed in the field of Artificial
Intelligence. The approach does not require the
development of computational models to simulate
equipment behaviour.
The set theoretical approach was applied to the
development of a diagnostic decision support system for
a semi-automated Atlas Copco Wagner ST-8B Load-Haul-Dump
vehicle. Hypothesis sets were generated for the
vehicle's hydraulic circuit and Deutz FL-413-FW diesel
engine. A high level of diagnostic resolution was
achieved for the hydraulic circuit, but limited
resolution was achieved for the diesel engine. This was
postulated to be due to the ratio of observable system
outputs to input sub-systems, and the number of least
repairable units making up each system.
Manual knowledge acquisition was undertaken in an
underground mine to refine the diagnostic knowledge
developed from the hypothesis sets and to add knowledge
to discriminate between competing failure hypotheses.
Heuristic failure likelihoods were used to rank
hypotheses in order of frequency of occurrence. The
knowledge base was implemented as a hypertext decision
support system using HyperText Mark-up Language (HTML).
The resulting decision support system is platform
independent, upgradeable and able to be maintained by
site personnel. The system is currently installed at
surface level and at 1800 level at INCO Limited's Stobie
Mine in Sudbury, Ontario.
The thesis makes a number of original contributions, the
first two of which are of generic significance. It is
the first work to apply set theoretical concepts to
structural models of mobile mining equipment in order to
diagnose faults. A number of modifications are advanced
to the conventional trace-back analysis technique for
generating contributor and normality sets, and heuristic
guidelines are provided for estimating the costs and
benefits of developing, implementing and maintaining
diagnostic decision support systems. It is also the
first work to formalise a decision support system in
HTML and to suggest the application of company-wide
internets ("intranets") to disseminate maintenance
knowledge within mines.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  3733 </NUMBER>
<ORDER>   AAG9710397 </ORDER>
<TITLE> CONSTRUCTING A REPLACEMENT FOR THE SOUL: THE GRAMMARS OF SELF-REFLECTION AND TEMPORALITY AS THE LIMITS OF LANGUAGE IN "FINNEGANS WAKE", "PHILOSOPHICAL INVESTIGATIONS", AND COGNITIVE SCIENCE  </TITLE>
<AUTHOR> BOURBON, BRETT RYAN </AUTHOR>
<YEAR> 1996 </YEAR>
<INSTITUTION> HARVARD UNIVERSITY; 0084 </INSTITUTION>
<DESCRIPTORS> LITERATURE, ENGLISH; PHILOSOPHY </DESCRIPTORS>
<ADVISER> NIL </ADVISER>
<CLASSIFICATIONS> LUDWIG WITTGENSTEIN, JAMES JOYCE, MARTIN HEIDEGGER </CLASSIFICATIONS>
<ABSTRACT>
In my dissertation I explore how literary art can
function as a kind of cognitive philosophy. I begin with
the proposition that Artificial Intelligence programs,
and the game worlds they spawn, attempt to articulate an
aesthetic with ontological force, poems to blow our
heads off. This possibility or promise frames my
examination of Joyce's Finnegans Wake, Wittgenstein's
Philosophical Investigations, and my own description of
a hypothetical machine I have designed that generates a
fictional future within which it figures itself. I
analyze Finnegans Wake as a philosophical text, and
Wittgenstein's Philosophical Investigations as
describing an aesthetic. Both texts do not articulate a
theory of meaning, but model meaning within what
Wittgenstein called our "forms of life," our attunement
within our language, culture, history, psychology,
biology, and so on. How is it possible for human beings
to inhabit this 'our' at all? How can I use an 'our' as
mine? In writing towards and at the limits of language,
I am trying to speak an 'our' as our species-being, and
it this speaking enact the particularity of meaning
instantiated through my particular involvement in
language. Both Investigations and the Wake explore the
limits of what it means to be human by examining how
linguistic meaning works through the interactions
between sense and nonsense. I analyze how the shifting
between language games, between sense and nonsense
described and enacted within Finnegans Wake and
Philosophical Investigations articulates a multivalent
temporal sense. I investigate the ways in which the
limits between sense and nonsense construct a grammar of
temporality that is simultaneously a literary aesthetic
and a theory of mind. Time becomes a grammatical effect.
The theoretical machine I have designed pressures the
interpretative limit between the animate and the
inanimate and between sense and nonsense toward the
ontological limits described by causal languages. My
dissertation is an attempt to describe the ways in which
such grammars determine what counts as human.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  3734 </NUMBER>
<ORDER>   AAGMM17661 </ORDER>
<TITLE> SHIP MANOEUVRABILITY PREDICTION USING NEURAL NETWORKS </TITLE>
<AUTHOR> WANG, YIE </AUTHOR>
<YEAR> 1996 </YEAR>
<INSTITUTION> MEMORIAL UNIVERSITY OF NEWFOUNDLAND (CANADA); 0306 </INSTITUTION>
<DESCRIPTORS> ENGINEERING, MARINE AND OCEAN; ENGINEERING, MARINE; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> M. R. HADDARA </ADVISER>
<CLASSIFICATIONS> NIL </CLASSIFICATIONS>
<ABSTRACT>
This thesis is divided into three parts. The first two
parts deal with two different methods for predicting the
manoeuvring characteristics of ships using a neural
network technique. The third part deals with the
application of the random decrement concept to the
coupled sway-yaw motions.
In the first part of this thesis, a new predictive
method is presented for the estimation of the
hydrodynamic characteristics of a ship performing
certain standard manoeuvres. This method uses the static
neural network technique to predict the nonlinear
hydrodynamic forces of the ship during its motion in the
horizontal plane.
The generalization of the trained neural network model
is checked by simulating the manoeuvres of the ship in a
situation different from the one used in the training of
neural network.
In the second part of this thesis, another approach to
predict ship turning manoeuvres is proposed. This model
maps the relationship between sway velocities and yaw
rates during the circular manoeuvre using a neural
network technique.
In the last part of the thesis work, the extension of
the random decrement approach to the nonlinear sway-yaw
motions is presented. (Abstract shortened by UMI.)
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  3735 </NUMBER>
<ORDER>   AAG9708555 </ORDER>
<TITLE> THE FUTURE OF FRIENDSHIP IN LITERATURE </TITLE>
<AUTHOR> FLETCHER, STEVEN QUIN </AUTHOR>
<YEAR> 1996 </YEAR>
<INSTITUTION> UNIVERSITY OF VIRGINIA; 0246 </INSTITUTION>
<DESCRIPTORS> LITERATURE, ENGLISH </DESCRIPTORS>
<ADVISER> STEPHEN D. ARATA </ADVISER>
<CLASSIFICATIONS> SCIENCE FICTION, ISAAC ASIMOV, RELATIONSHIPS </CLASSIFICATIONS>
<ABSTRACT>
This dissertation explores how various authors have
depicted near-ideal friendships. In doing so, it
repeatedly demonstrates a strong continuity of the
dictates of classical friendship thought--even in works
of science fiction, where the circumstances and kinds of
participants in friendship contracts become radically
altered. The conclusion analyzes how one author (Isaac
Asimov) overcomes enduring philosophical problems to
convincingly depict a nearly ideal friendship between a
human and a totally new kind of being.
The introduction to the work argues that literary
critics would find that examining texts with a strong
attention to how friendships are portrayed can open new
and fruitful ways to talk about those texts. It also
argues that science fiction is a wonderful genre for
imagining new permutations of friendships in "what if"
scenarios.
Chapter one establishes the paper's focus on ideal
friendship, and considers the fundamental writings of
Aristotle and Cicero, as well as various early myths.
The archetypal friendships between Achilles and
Patroklos, and Damon and Pithias, are closely examined,
and subsequently serve as touchstones for considering
the friendships depicted in more modern texts.
Chapter two discusses the genealogy of cyberspace, and
shows that authors since E. M. Forster have found
cyberspace a fertile realm for imagining human
interaction. The chapter goes on to examine science
fiction texts by Vinge, Cadigan, Heinlein, Delaney and
Steiger, and Varley--texts with friendships where one or
more of the participants exists in cyberspace through a
virtual body (avatar) or via artificial intelligence (as
in the case of a sentient computer). The lack of a
"real" body is shown to be highly problematical when
portrayal of a near-ideal friendship is attempted.
Chapter three addresses the problem of friendships with
created, bodily constructs--namely sophisticated robots
in the works of Asimov. The important problem of the
constructs' autonomy is considered, and also the
historical problem of friends' responsibility to each
other versus responsibility to the greater good of all.
Texts by Dickens, George Eliot, Mark Twain, Conrad and
others are used to show the legacy of these problems,
and to help understand the way that Asimov solves them.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  3736 </NUMBER>
<ORDER>   AAGNN12365 </ORDER>
<TITLE> COGNITIVE MULTI-TASKING IN SITUATED MEDICAL REASONING </TITLE>
<AUTHOR> FARAND, LAMBERT </AUTHOR>
<YEAR> 1996 </YEAR>
<INSTITUTION> MCGILL UNIVERSITY (CANADA); 0781 </INSTITUTION>
<DESCRIPTORS> EDUCATION, EDUCATIONAL PSYCHOLOGY; EDUCATION, PSYCHOLOGY; HEALTH SCIENCES, MEDICINE AND SURGERY; HEALTH SCIENCES, HOSPITAL MANAGEMENT; HEALTH SCIENCES, EDUCATION </DESCRIPTORS>
<ADVISER> VIMLA L. PATEL </ADVISER>
<CLASSIFICATIONS> PROBLEM-SOLVING </CLASSIFICATIONS>
<ABSTRACT>
This study evaluates the hypothesis that medical
reasoning in real clinical situations involves multiple
cognitive tasks whose complex interactions are
coordinated in an opportunistic manner. A problem-
solving architecture originating from research in
artificial intelligence, the blackboard model, is
proposed as an integrative framework for representing
these characteristics of situated medical reasoning and
for reconciling different theoretical perspectives about
medical reasoning. A naturalistic clinical situation,
involving the manipulation of the patient record by an
internist while managing a case, provides the empirical
data for this in depth qualitative case study. The video
recording of the subject's record manipulation behavior
allows the cueing of retrospective think-aloud
verbalizations and the preservation of the real-time
aspects of problem solving. The association of theory-
driven task analysis using the blackboard model with
data-driven propositional analysis confirm that medical
reasoning in this situation indeed comprises a variety
of cognitive tasks, which are described. Also, the
opportunistic character of control knowledge and the
complex interactions between control strategies and
cognitive tasks are confirmed and described. The
blackboard model allows the principled representation of
these characteristics of situated medical reasoning,
thus supporting its integrative character. However,
certain aspects of the data, mostly related to the
ambivalence of several concepts that are used by the
subject during the course of problem-solving, are not
explained in the most parsimonious manner by the
blackboard model, nor by symbolic cognitive
architectures in general. A connectionist alternative is
proposed which seems to better account for these
phenomena. Finally, a tentative neurophysiological
interpretation of the blackboard framework is offered
for integrating the symbolic and connectionist
perspectives. This study has additional implications
concerning the relations between normative and
descriptive perspectives on medical reasoning, as well
as ethical implications regarding patient empowerment
and physicians' involvement in patient education.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  3737 </NUMBER>
<ORDER>   AAGC537439 </ORDER>
<TITLE> BELIEF-FUNCTION THEORY AND ITS APPLICATION TO THE MODELING OF UNCERTAINTY IN FINANCIAL STATEMENT AUDITING </TITLE>
<AUTHOR> VAN DEN ACKER, CARINE CHRISTEL </AUTHOR>
<YEAR> 1996 </YEAR>
<INSTITUTION> KATHOLIEKE UNIVERSITEIT LEUVEN (BELGIUM); 5605 </INSTITUTION>
<DESCRIPTORS> ECONOMICS, FINANCE; ARTIFICIAL INTELLIGENCE LADEUZEPLEIN, 21, B-3000 LEUVEN,  BELGIUM </DESCRIPTORS>
<ADVISER> NIL </ADVISER>
<CLASSIFICATIONS> ARTIFICIAL INTELLIGENCE </CLASSIFICATIONS>
<ABSTRACT>
This thesis discusses belief-function theory as a theory
of evidence and applies it to the audit of the financial
statements.
Early work on belief-function theory was performed in
the late sixties by A. Dempster. Its formal foundations
are described by G. Shafer in 1976 in his monograph 'A
Mathematical Theory of Evidence'. In reference to these
pioneer developments, the theory is sometimes called
'Dempster-Shafer' theory. At that time, it received
limited attention because of its computational
complexity and because of criticism on some of its
mechanisms. More than a decade later, the focus on
artificial intelligence (AI) and knowledge based systems
redirected the attention to belief-function theory for
modeling knowledge and reasoning under uncertainty. The
interest from the rapidly growing field of AI inspired
many researchers to develop the theory further. Today's
research is mainly oriented at efficient implementation
strategies and interpretational and conceptual modeling
issues.
As financial statement auditing is defined as the
collection and evaluation of evidence to judge the
fairness of a company's financial statements 'beyond
reasonable doubt', this is the type of problem for which
belief-function theory is well-suited. The theory's
potential for auditing was already brought to the
attention in the late eighties, but in general received
only limited attention in the auditing literature. In
our opinion, belief-function theory and the progress
made by AI-researchers entail many promises for
auditing. Firstly, because it can offer a comprehensive
model of the audit process that can represent and
combine test results without additional input
requirements (in contrast to Bayesian models). Secondly,
it allows for computerized support and interactive test
planning. Thirdly, it can easily integrate all types of
uncertain evidence. In this thesis, such a belief-
function based model is built that shows these
advantages.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  3738 </NUMBER>
<ORDER>   AAGC526011 </ORDER>
<TITLE> NEURAL NETWORKS IN ECONOMIC MODELLING: AN EMPIRICAL STUDY </TITLE>
<AUTHOR> VERKOOIJEN, WILHELMUS JOHANNES HENRIKUS </AUTHOR>
<YEAR> 1996 </YEAR>
<INSTITUTION> KATHOLIEKE UNIVERSITEIT BRABANT (THE NETHERLANDS); 0687 </INSTITUTION>
<DESCRIPTORS> ECONOMICS, FINANCE; SOCIOLOGY, THEORY AND METHODS; ECONOMICS, THEORY; ARTIFICIAL INTELLIGENCE NETHERLANDS </DESCRIPTORS>
<ADVISER> NIL </ADVISER>
<CLASSIFICATIONS> NIL </CLASSIFICATIONS>
<ABSTRACT>
In economic data modelling one tries to find
relationships among economic entities. The increasing
availability of computer power has stimulated research
in data modelling techniques that search for an
approximating function over some large classes of
functions using the data sample at hand. The neural
network is a popular flexible regression technique. In
economics, however, most modelling is still performed
using parametric methodology.
This thesis applies neural networks to economic and
financial problems of prediction. The aim is to
investigate the usability and the practical relevance of
neural networks in the specification of economic (time
series) models and their position among alternative
(statistical) techniques. An additional aim is to
stimulate cross-fertilization between the neural network
field on the one hand, and the statistics and
econometrics field on the other hand.
The global outline of the study is as follows. Part I
(Chapters 1-5) discusses the theoretical aspects of
economic modelling and neural networks. Chapter 1
describes the general economic modelling problem and the
parametric approach to model building, which is
generally accepted in econometrics. As alternatives to
this parametric approach, Chapter 2 introduces several
flexible regression methodologies; among them are neural
networks. Different aspects of the neural network
methodology are then discussed in chapters 3 and 4.
Chapter 5 discusses the usefulness of neural networks in
modelling nonstationary time series.
Part II (Chapters 6-10) deals with the practical aspects
of applying neural networks to problems in economics and
finance. Chapter 6 reviews the literature on neural
networks in economics and finance. The practical
usability of neural networks is examined in three case
studies, presented in Chapters 7, 8, and 9 respectively.
The final conclusion is that neural networks are a
valuable addition to the econometrician's toolbox, but
that they are no panacea.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  3739 </NUMBER>
<ORDER>   AAGC524619 </ORDER>
<TITLE> CONFIGURATIONS OF MULTIPLE-VARIANT PRODUCTS: APPLICATION ORIENTATION AND VAGUENESS IN CUSTOMER REQUIREMENTS </TITLE>
<AUTHOR> SCHWARZE, STEPHAN RUDOLF </AUTHOR>
<YEAR> 1996 </YEAR>
<INSTITUTION> EIDGENOESSISCHE TECHNISCHE HOCHSCHULE ZUERICH (SWITZERLAND); 0663 </INSTITUTION>
<DESCRIPTORS> COMPUTER SCIENCE; ARTIFICIAL INTELLIGENCE HAUPTBIBLIOTHEK, ETH-ZENTRUM,  CH-8092 ZURICH, SWITZERLAND </DESCRIPTORS>
<ADVISER> NIL </ADVISER>
<CLASSIFICATIONS> FUZZY LOGIC, EXPERT SYSTEMS </CLASSIFICATIONS>
<ABSTRACT>
In recent years the shift from make-to-market to make-to-
order production has had a major influence on corporate
strategies. The integration of the customer into the
company is becoming more important for production
companies as well as for service companies. A fast time-
to-market and a high flexibility towards customer
requirements are essential conditions to survival.
Modern companies must consider the desires of individual
customers, especially where products are concerned.
Therefore, a modem configuration approach is necessary
for improved customer orientation.
In this work, a method for splitting the entire product
configuration process into three stages is developed.
The Specification Mapping stage maps functional
requirements to structural data, the Technical
Configuration stage determines a set of final products
and checks consistency, and the Optimization stage
decides on an optimal product. The Specification Mapping
stage is the most important for the integration of
application-oriented customer knowledge.
Since the Specification Mapping is neglected in most
existing configuration systems, a configuration data
model in which functional, application-oriented
knowledge is integrated has been developed. This model
covers all knowledge that is used in the Specification
Mapping.
Based on the model a rule-based approach for solving a
Specification Mapping problem has been developed. Since
the task is data-driven, the preferred inference
strategy is forward chaining. The main subtasks that
have to be taken into account are value assertions for a
set of essential parameters, the detection of
contradictions in the customer's requirements, and the
exhaustive use of knowledge must be guaranteed to infer
as much structural data as possible from the functional
input.
A major problem in the Specification Mapping stage is
that vague knowledge appears frequently in individual
customer requirements as well as in product expert
knowledge. Since both types of uncertainty are
linguistic, fuzzy logic is used for integrating vague
knowledge into the Specification Mapping system.
Therefore, vague knowledge is also integrated into the
configuration data model, and linguistic variables with
associated linguistic terms have to be defined.
Another theme of this work is that the Specification
Mapping approach is applicable for service products as
well as for engineering products. The similarity of both
types of products with regard to configuration is shown.
Since for some service products the product structure is
simpler but the functional requirements are more
complex, the Specification Mapping stage is even more
important. Furthermore, the input to service product
specifications is commonly "vague knowledge". As an
example, the configuration of an individual bank credit
is described.
An implementation guideline for putting a Specification
Mapping system into practise is described. It covers
steps that have to be executed and discusses the
personnel who would be responsible for them. A prototype
system for the examples of bicycle and individual bank
credit configurations has been implemented with the
expert system shell FuzzyCLIPS.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  3740 </NUMBER>
<ORDER>   AAGC524264 </ORDER>
<TITLE> GLOBAL DISCRIMINATIVE MODELLING FOR AUTOMATIC SPEECH RECOGNITION  </TITLE>
<AUTHOR> JOHANSEN, FINN TORE </AUTHOR>
<YEAR> 1996 </YEAR>
<INSTITUTION> NORGES TEKNISKE HOGSKOLE (NORWAY); 5714 </INSTITUTION>
<DESCRIPTORS> ENGINEERING, ELECTRONICS AND ELECTRICAL; ARTIFICIAL INTELLIGENCE N-7034 TRONDHEIM-NTH, NORWAY </DESCRIPTORS>
<ADVISER> NIL </ADVISER>
<CLASSIFICATIONS> PHONEMES </CLASSIFICATIONS>
<ABSTRACT>
The thesis studies discriminative techniques for
acoustic-phonetic modelling in automatic speech
recognition. The principle called global discriminative
modelling treats each continuous speech utterance as a
single sample, and regards the entire recogniser system
as a pattern classifier, with the purpose of
discriminating between utterance-level symbols. This is
a well-known principle, but it is often violated by
several approximations and assumptions in practical
system design.
Global discrimination methods based on the conditional
maximum likelihood (CML) criterion and some of its
approximations are examined experimentally on TIMIT
phoneme recognition. With a sample, single mixture
diagonal Gaussian HMM, global discriminative training
raised the accuracy from 53.0% (conventional Baum-Welch
trained HMM) to 64.4% on the standard 39-class task when
using Viterbi decoding. THe use of forward decoding
instead of Viterbi increased the accuracy to 68.2% with
the CML trained models. With Baum-Welch trained models,
however, no improvement was found with forward decoding.
In order to facilitate model architectures with higher
complexity, different optimisation methods were
compared. A stochastic gradient search method, with
proper parameter scaling, was found to be faster than
MMI reestimation.
The most efficient CML training method and the forward
decoder was used to compare slightly different hybrid
ANN/HMM architectures to the baseline HMM system. Both
hybrids used MLPs instead of Gaussian mixture densities,
but otherwise had the same constraints as the Gaussian
HMM. None of the hybrids performed better than the
traditional HMM architecture.
The thesis concludes that global discriminative training
methods are particulary useful to improve the
performance of simple model structures. The methods are
also valuable tools for comparison of different
recogniser architectures.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  3741 </NUMBER>
<ORDER>   AAG9707778 </ORDER>
<TITLE> IDENTIFICATION AND CONTROL OF SMART STRUCTURAL SYSTEMS UTILIZING MULTIPLE DISTRIBUTED SENSORS </TITLE>
<AUTHOR> BUTLER, ROBERT KEITH </AUTHOR>
<YEAR> 1996 </YEAR>
<INSTITUTION> UNIVERSITY OF MISSOURI - ROLLA; 0135 </INSTITUTION>
<DESCRIPTORS> ENGINEERING, ELECTRONICS AND ELECTRICAL; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> VITTAL RAO </ADVISER>
<CLASSIFICATIONS> POLYVINYLIDENE FLUORIDE, ARTIFICIAL INTELLIGENCE </CLASSIFICATIONS>
<ABSTRACT>
The design of smart structural systems improved
vibrational characteristics requires the selection and
placement of sensor and actuator components, the
development of signal conditioning electronics, the
identification of control models and the design and
implementation of control systems. None of these tasks
are independent of the others and only the most
comprehensive designs can realize the full potential of
the system. A design technique is developed which
unifies the selection and placement of the sensors, the
system identification process and the control system
implementation.
Shaped distributed sensing using polyvinylidene fluoride
(PVDF) film is utilized which allows for the measurement
of structural parameters. The shape functions required
for the parametric measurements are given. A segmenting
technique is developed which allows for multiple
parametric measurements of a vibrating structure from a
single sheet of PVDF film. The simplicity of the shape
functions simplifies the sensor construction and allows
for the segmentation.
A system identification technique is proposed which
utilizes the multiple parametric measurements provided
by the shaped PVDF film sensors. The sensor outputs
simplify the identification process by allowing for the
measurement of the eigenvectors of the structural
system. The system identification technique produces
state space models in which the sensor outputs are the
states of the state space system. Several cases are
presented and extensions to the basic technique with
experimental examples and data.
A variety of robust controllers are designed and
implemented on structural systems. With the
identification technique producing a model with measured
states, state feedback controllers are implemented with
simple analog hardware. Several cases are presented in
which a reduced number of measurements are used in the
identification. For these cases, robust output feedback
control is implemented.
The state space system matrices of the model are
calculated strictly in terms of measured parameters in
the identification process. This allows for the
incorporation of structured uncertainties in the design
model. The uncertainty modeling is formulated in the
framework of Bernstein's $Hsb2/Hsb0infty$ control design
algorithm. Design examples are given which incorporate
structured natural frequency uncertainty and
unstructured uncertainty.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  3742 </NUMBER>
<ORDER>   AAG9707087 </ORDER>
<TITLE> A STUDY OF VARIOUS REPRESENTATIONS USING NEXTPITCH: A LEARNING CLASSIFIER SYSTEM </TITLE>
<AUTHOR> FEDERMAN, FRANCINE </AUTHOR>
<YEAR> 1996 </YEAR>
<INSTITUTION> CITY UNIVERSITY OF NEW YORK; 0046 </INSTITUTION>
<DESCRIPTORS> COMPUTER SCIENCE; ARTIFICIAL INTELLIGENCE; MUSIC </DESCRIPTORS>
<ADVISER> JACQUELINE A. JONES </ADVISER>
<CLASSIFICATIONS> ARTIFICIAL INTELLIGENCE, PITCH </CLASSIFICATIONS>
<ABSTRACT>
Our model, NEXTPITCH, a learning classifier system using
genetic algorithms, inductively learns to predict the
next note in a nursery melody. Just as a listener
develops expectations of what is to follow based on what
has been heard, NEXTPITCH models human music learning by
developing the rules that represent actual pitch
transitions in the melody.
The focal point of this research is to compare and
analyze different representations of specific features
of Western tonal music within the construct of a
learning classifier system. The rationale for the
specific note representations merges ideas from learning
classifier systems and genetic algorithms with concepts
espoused by the music cognition community.
The areas of study addressed are representation of
music, classifier format and the number of classifiers
to use. Our results are correlated by analyses of
classes so that we may examine the applicability of the
results from one set of melodies to another.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  3743 </NUMBER>
<ORDER>   AAG9706829 </ORDER>
<TITLE> AN EXTENSIBLE META-LEARNING APPROACH FOR SCALABLE AND ACCURATE INDUCTIVE LEARNING </TITLE>
<AUTHOR> CHAN, PHILIP KIN-WAH </AUTHOR>
<YEAR> 1996 </YEAR>
<INSTITUTION> COLUMBIA UNIVERSITY; 0054 </INSTITUTION>
<DESCRIPTORS> COMPUTER SCIENCE; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> SALVATORE J. STOLFO </ADVISER>
<CLASSIFICATIONS> MACHINE LEARNING, ARTIFICIAL INTELLIGENCE </CLASSIFICATIONS>
<ABSTRACT>
Much of the research in inductive learning concentrates
on problems with relatively small amounts of data. With
the coming age of ubiquitous network computing, it is
likely that orders of magnitude more data in databases
will be available for various learning problems of real
world importance. Some learning algorithms assume that
the entire data set fits into main memory, which is not
feasible for massive amounts of data, especially for
applications in data mining. One approach to handling a
large data set is to partition the data set into
subsets, run the learning algorithm on each of the
subsets, and combine the results. Moreover, data can be
inherently distributed across multiple sites on the
network and merging all the data in one location can be
expensive or prohibitive.
In this thesis we propose, investigate, and evaluate a
meta-learning approach to integrating the results of
multiple learning processes. Our approach utilizes
machine learning to guide the integration. We identified
two main meta-learning strategies: combiner and arbiter.
Both strategies are independent to the learning
algorithms used in generating the classifiers. The
combiner strategy attempts to reveal relationships among
the learned classifiers' prediction patterns. The
arbiter strategy tries to determine the correct
prediction when the classifiers have different opinions.
Various schemes under these two strategies have been
developed. Empirical results show that our schemes can
obtain accurate classifiers from inaccurate classifiers
trained from data subsets. We also implemented and
analyzed the schemes in a parallel and distributed
environment to demonstrate their scalability.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  3744 </NUMBER>
<ORDER>   AAGMM17031 </ORDER>
<TITLE> MODELING THE DYNAMIC RESPONSE OF THE HUMAN SPINE TO MECHANICAL SHOCK AND VIBRATION USING AN ARTIFICIAL NEURAL NETWORK </TITLE>
<AUTHOR> NICOL, JORDAN JAMES </AUTHOR>
<YEAR> 1996 </YEAR>
<INSTITUTION> SIMON FRASER UNIVERSITY (CANADA); 0791 </INSTITUTION>
<DESCRIPTORS> ENGINEERING, MECHANICAL; APPLIED MECHANICS; BIOPHYSICS, MEDICAL; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> J. B. MORRISON; A. RAWICZ </ADVISER>
<CLASSIFICATIONS> NIL </CLASSIFICATIONS>
<ABSTRACT>
The ability to model the spinal response to shock and
vibration is an important step in assessing the health
hazard effects of repeated impacts to vehicle
passengers. Current methods used for this purpose, such
as the Dynamic Response Index and the British Standard
6841 filter, were found to perform poorly when the input
consists of large-magnitude shocks typical of those
experienced by occupants of tanks, trucks, and other off-
road vehicles. In this thesis I present a novel approach
to the problem of modeling the spinal response of the
seated passenger to vertical accelerations applied at
the seat. The modeling approach taken utilizes an
artificial neural network (ANN) to predict the z-axis
(vertical) acceleration at the fourth lumbar vertebra
based on measured z-axis seat acceleration. An ANN is a
universal approximator, capable of modeling any
continuous function if trained with a sufficiently
representative set of measured input-output data. The
seat-spine system was modeled as a network with five
inputs and one output. The Levenberg-Marquardt algorithm
was used to train the network by adjusting the network
parameters so as to minimize the square of the
prediction error. The inputs to the network are delayed
samples of the measured inputs and predicted outputs of
the nonlinear simulation. It is shown that the trained
network significantly outperforms three different linear
models examined for predicting the z-axis acceleration
at the L-4 vertebra.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  3745 </NUMBER>
<ORDER>   AAG9706502 </ORDER>
<TITLE> BIFURCATIONS IN BRAIN DYNAMICS </TITLE>
<AUTHOR> IZHIKEVICH, EUGENE M. </AUTHOR>
<YEAR> 1996 </YEAR>
<INSTITUTION> MICHIGAN STATE UNIVERSITY; 0128 </INSTITUTION>
<DESCRIPTORS> ENGINEERING, SYSTEM SCIENCE; BIOLOGY, NEUROSCIENCE; ENGINEERING, ELECTRONICS AND ELECTRICAL; MATHEMATICS </DESCRIPTORS>
<ADVISER> F. C. HOPPENSTEADT </ADVISER>
<CLASSIFICATIONS> NEURONS, SYNAPSES, ARTIFICIAL INTELLIGENCE </CLASSIFICATIONS>
<ABSTRACT>
Mathematical models of the brain are studied with the
assumption that the connections between neurons are
weak. This leads to weakly connected systems, which are
called Weakly Connected Neural Networks (WCNNs). Local
dynamics of the WCNNs is studied using bifurcation
theory.
First it is proved that the WCNNs could have interesting
local dynamics with possible applications to
neurocomputers only near bifurcations. Then it is shown
that near the bifurcations the WCNNs can be
significantly simplified and reduced to canonical
models.
Derivation and analysis of the canonical models for
multiple (quasi-static) saddle-node, pitchfork and
Andronov-Hopf bifurcations and multiple cusp
singularities is presented. Mathematical analysis of the
canonical models suggests a new neural network paradigm--
non-hyperbolic neural networks. It also sheds some light
on possible synaptic organizations of the brain. In
particular, it reveals the relationship between synaptic
architectures (anatomy) and dynamical properties
(function) of networks of neural oscillators.
A part of this dissertation (Chapters 2 and 7) received
the SIAM Student Paper Prize in applied mathematics for
1995.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  3746 </NUMBER>
<ORDER>   AAG9706495 </ORDER>
<TITLE> TOWARDS A LEARNING SYSTEM FOR ROBOT HAND-EYE COORDINATION  </TITLE>
<AUTHOR> HOWDEN, SALLY JEAN </AUTHOR>
<YEAR> 1996 </YEAR>
<INSTITUTION> MICHIGAN STATE UNIVERSITY; 0128 </INSTITUTION>
<DESCRIPTORS> COMPUTER SCIENCE; ENGINEERING, ELECTRONICS AND ELECTRICAL; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> NIL </ADVISER>
<CLASSIFICATIONS> MACHINE VISION, ARTIFICIAL INTELLIGENCE </CLASSIFICATIONS>
<ABSTRACT>
Through careful consideration of the Hand-Eye
Coordination (HEC) problem, it can be viewed as the
process of performing a sequence of transformations from
an input space to an output space. Specifically, the
entire process from eye to hand can be viewed as a
mapping from scene space to arm configuration space.
This single mapping may be broken into a sequence of
mappings from one space to another. The sequence we have
chosen to model is the following: scene space to image
space; image space to camera coordinate system; camera
coordinate system to arm/world coordinate system;
arm/world coordinate system to arm configuration space.
Additionally, an active vision system is incorporated
which introduces an image space to head configuration
space mapping.
Given the view that these subtasks are mappings from a N-
dimensional input space to a M-dimensional output space,
this research presents a unified framework by which the
various subtasks of the HEC problem may be implemented.
This framework uses a recursive partitioning algorithm
to build a hierarchical tree classifier which uses a
nearest neighbor classification based on the Voronoi
tessellation as its decision making criteria. The
resulting data structure is a Recursive Partition Tree
(RPT), which is the heart of the framework. The topology
of the RPT is not determined a priori, or hand-coded.
Instead the topology is allowed to develop during its
construction, based on the given set of training samples
and the order in which they are presented to the
construction algorithm. Each node of the RPT represents
a cell of the space which is further partitioned by its
children via a Voronoi tessellation. Each leaf node
corresponds to a training sample and stores the
corresponding output. This general framework provides us
with a method for systematically dealing with the
complex relationship between the sensors and the
manipulator. In the performance phase, given an input,
the RPT is used to retrieve the desired output. The RPT
results in a logarithmic average time complexity in the
number of stored training samples.
Extensive simulations have been performed with two
implemented modules. Experiments using a real setup
demonstrate the ability of a system using RPTs to
accomplish the stereo calibration, head-to-object space
mapping, and point-to-point movement of the hand within
the HEC task. Experiments using real data required that
the current approach be simplified since collecting real
data for training proved to be much more difficult and
time consuming than generating simulated data.
Nevertheless, promising results are obtained.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  3747 </NUMBER>
<ORDER>   AAG9706395 </ORDER>
<TITLE> SELF-ORGANIZED ARTIFICIAL NEURAL NETWORKS WITH NOVEL PHASE TRANSITION LEARNING RULE FOR SOLVING BISTABLE REVERSIBLE FIGURES AND XOR PROBLEMS  </TITLE>
<AUTHOR> LU, FENG </AUTHOR>
<YEAR> 1996 </YEAR>
<INSTITUTION> THE AMERICAN UNIVERSITY; 0008 </INSTITUTION>
<DESCRIPTORS> COMPUTER SCIENCE; ENGINEERING, SYSTEM SCIENCE; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> HAROLD SZU </ADVISER>
<CLASSIFICATIONS> ARTIFICIAL INTELLIGENCE </CLASSIFICATIONS>
<ABSTRACT>
This writing wishes to apply the phase transition
cooperative phenomena to neurocomputing. Specifically
the collaborated H. Haken synergetic computer theory and
Per Bak self-organized criticality theory will be
adapted to artificial neural network models for the
applications in image processing, pattern recognition,
self-architecture neural networks and information
processing.
An artificial perceptron neural network model is
proposed to explain the multistable perception in
"reversible figures". The networks are composed of a
shifting invariant smart eye preprocessing unit, a depth
processing unit and the main brain computing unit. The
main brain computing network is a revised back error
propagation network. A polynomial energy function is
used for the performance measure replacing the least
mean square energy. The test of "reversible figures" is
subsequently controlled by the phase transition tuning
parameter driven bottom up from test image data. The
effects of the tuning parameter are illustrated, and the
modeling of multistable perception is discussed. It is
demonstrated that the brain computing networks trained
with the new energy function generally have better
performance in training speed and classification of
patterns than the standard back error propagation
networks trained by the least mean square energy
function.
The behavior of a self-architecting neural network with
a new phase transition learning rule is investigated.
This model is based on Adaptive Performance Network
purposed by Stassinopoulos, Alstrom, and Bak with two
significant modifications: An L$sp1$ energy function and
a non-unity energy threshold in the weight update
equation are articulated; Instar instead of the outstar
normalization is performed. The simulation indicates
that the basic structure of an APN is quite tolerant to
the learning rule changes of its composing elements, it
also showed that even at the converged state the
performance of the revised APN model exhibits much
random fluctuation resembling the l/f power spectrum
law. These characteristics are the main signature of the
Per Bak self-organized criticality state.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  3748 </NUMBER>
<ORDER>   AAG9705988 </ORDER>
<TITLE> NONLINEAR DYNAMIC SYSTEMS, VOLTERRA SERIES, AND UNIFORM APPROXIMATIONS  </TITLE>
<AUTHOR> XU, LILIAN YUNYI </AUTHOR>
<YEAR> 1996 </YEAR>
<INSTITUTION> THE UNIVERSITY OF TEXAS AT AUSTIN; 0227 </INSTITUTION>
<DESCRIPTORS> ENGINEERING, ELECTRONICS AND ELECTRICAL; ENGINEERING, SYSTEM SCIENCE; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> I. W. SANDBERG </ADVISER>
<CLASSIFICATIONS> NEURAL NETWORKS, BANACH SPACES, ARTIFICIAL INTELLIGENCE </CLASSIFICATIONS>
<ABSTRACT>
In the study of control systems it is almost always
possible to view a system, or a part of a system as a
nonlinear map from one particular space to an- other.
For this reason, and for a variety of problems
concerning compensation, adaptivity, or identification,
results concerning the representation and approximation
of nonlinear maps can be of particular interest to
control engineers. Especially pertinent is much of the
progress that has been made in recent years in the
neural networks area. For certain discrete-time
approximately-finite-memory systems, it is known that
their input-output maps can be uniformly approximated
arbitrarily well by a structure consisting of a linear
preprocessing stage followed by a memoryless nonlinear
network. The first part of this dissertation shows that
these linear parts can be derived from a single
prespecified function that meets certain conditions.
This is followed by a treatment of the problem of
approximating nonlinear functionals on compact subsets
of reflexive Banach spaces. The aforementioned two-stage
structure can also be used to approximate the input-
output maps that are myopic, a concept related to
approximately-finite-memory. This part of the study
provides criteria, in different settings, under which
multidimensional myopic maps can be uniformly
approximated arbitrarily well. These results address
noncausal as well as causal systems, and also systems in
which inputs and outputs are functions of several
variables. Specializations of these results yield, for
example, generalized finite Volterra series
approximations or focused gamma network approximations.
The last part of this dissertation reports an extension
of the theory for the steady-state response of linear
systems. This study addresses the relationship between
the nature of the error response and the system type for
nonlinear systems of certain forms. A convergent
algorithm is given for computing the limit of the steady-
state response whenever it exists.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  3749 </NUMBER>
<ORDER>   AAG9705548 </ORDER>
<TITLE> LEARNING BAYESIAN NETWORKS FROM DATA </TITLE>
<AUTHOR> CHICKERING, DAVID MAXWELL </AUTHOR>
<YEAR> 1996 </YEAR>
<INSTITUTION> UNIVERSITY OF CALIFORNIA, LOS ANGELES; 0031 </INSTITUTION>
<DESCRIPTORS> COMPUTER SCIENCE; STATISTICS; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> JUDEA PEARL; RICHARD KORF </ADVISER>
<CLASSIFICATIONS> MACHINE LEARNING, ARTIFICIAL INTELLIGENCE </CLASSIFICATIONS>
<ABSTRACT>
The traditional approach to probabilistic reasoning
requires an expert to construct and quantify a network
model of a domain. The two major problems with this
approach are (1) there may be no expert available to
build the model, and (2) even if the model can be
constructed, any inaccuracies encoded in that model will
adversely affect future predictions. This dissertation
addresses both problems by defining a Bayesian learning
system that combines prior knowledge with data to learn
both the structure and the parameters of a network with
discrete variables.
Bayesian learning methods, although conceptually simple,
have previously been difficult to apply because of
computational costs; the methods must evaluate a scoring
function to rank candidate structures, and also must
apply search techniques to identify the highest-ranking
structure(s). I provide a transformational
characterization of equivalent network structures that
leads to a computationally efficient scoring function. I
prove that when using this scoring function, the
corresponding search problem is NP-hard, and
consequently heuristic search is appropriate. I define a
new search space that can be used for learning entire
equivalence classes of network structures as opposed to
individual structures, and show experimentally that
learning accuracy improves by using the new space. I
demonstrate the importance of prior knowledge to both
the scoring function and the search procedure. I compare
several asymptotic approximations that are used to
handle missing data, and identify two such
approximations that are both accurate and efficient. I
demonstrate the applicability of the learning system to
assessing the effectiveness of a drug, using data from
real clinical trials where subject compliance is
imperfect. This assessment has traditionally been
considered difficult if not impossible, especially when
the number of subjects is small, and consequently this
dissertation provides the clinical research community
with a new practical tool to be used whenever full
compliance cannot be enforced.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  3750 </NUMBER>
<ORDER>   AAG9704838 </ORDER>
<TITLE> CONTINUOUS TIME NEURAL NETWORKS FOR SYSTEM IDENTIFICATION AND CONTROL </TITLE>
<AUTHOR> HABIB, SHAHID </AUTHOR>
<YEAR> 1996 </YEAR>
<INSTITUTION> THE GEORGE WASHINGTON UNIVERSITY; 0075 </INSTITUTION>
<DESCRIPTORS> ENGINEERING, ELECTRONICS AND ELECTRICAL; ENGINEERING, SYSTEM SCIENCE; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> NIL </ADVISER>
<CLASSIFICATIONS> NIL </CLASSIFICATIONS>
<ABSTRACT>
A comprehensive technique that takes a total advantage
of neural networks, in devising a fast learning
neurocontroller is developed under this research. This
is a concurrent process which uses a continuous time
neuroplant and neurocontroller; and provides an
effective design and algorithm for nonlinear plant
control.
Over the last several years, there have been a number of
researchers who have used feedforward and feedback
neural networks for system identification and control to
solve both linear and nonlinear problems. A majority of
these techniques have used discrete algorithms, and have
delivered successful neurocontrollers for specific
applications. However, very little attention has been
paid to continuous time neural network algorithms for
the use of dynamic pattern recognition. A serious effort
is made here in introducing a continuous time
neuroidentification and neurocontroller design and
architecture for the nonlinear plant control. The
continuous time algorithm developed here is directly
applicable to nonlinear plant, and eliminates any need
for discrete plant models. The application of this
algorithm along with the use of a rolling wave data
window (RWDW) technique, allows for an easy on-line
learning process. The RWDW method, as proposed here, has
proven to be an effective means to handle and manage
real-time plant data or dynamic patterns. In fact, this
plays a critical role in selecting and organizing the
dynamic patterns required by the neurocontroller. The
neurocontroller design, once integrated with the RWDW
and the on-line training process, results in an
efficient, fast learning architecture. This work further
introduces a process for achieving a standardized neural
network architecture that is applicable to both
regulating and tracking types of problems. Special
attention is given to the overall neural network
complexity in terms of the number of layers and neurons.
In fact, it is shown that a simpler neural network
configuration can produce accurate results without
utilizing complex adaptive control techniques in
parallel mode. This work further capitalizes on the
fundamentals of neural network methods and applies them
to achieve realistic and, at the same time, introduces a
vibrant design of the continuous time neurocontroller.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  3751 </NUMBER>
<ORDER>   AAG9704712 </ORDER>
<TITLE> FOREIGN ACCENT CLASSIFICATION IN AMERICAN ENGLISH </TITLE>
<AUTHOR> ARSLAN, LEVENT MUSTAFA </AUTHOR>
<YEAR> 1996 </YEAR>
<INSTITUTION> DUKE UNIVERSITY; 0066 </INSTITUTION>
<DESCRIPTORS> ENGINEERING, ELECTRONICS AND ELECTRICAL; LANGUAGE, LINGUISTICS; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> JOHN H. L. HANSEN </ADVISER>
<CLASSIFICATIONS> SPEECH RECOGNITION, INTONATION, ARTIFICIAL INTELLIGENCE </CLASSIFICATIONS>
<ABSTRACT>
This dissertation addresses the problem of automatic
foreign accent classification in American English.
Foreign accent is one of the major factors that degrade
automatic speech recognition performance. In this
thesis, it is shown that by using accent information,
speech recognition performance can be increased
substantially for non-native speakers.
In order to analyze foreign accented speech, first a
database is established based on isolated words and
phrases that are known to be sensitive to accent. Using
this database, an extensive acoustic analysis of foreign
accented speech is performed in order to identify the
most significant relayers of accent. Investigated
features include intensity, intonation, temporal
parameters, and frequency characteristics. Among the
temporal features studied, it is found that word-final
stop release time is a very significant indicator of
foreign accent. In general, the duration of pause before
a voiced stop consonant at the end of a word is
significantly longer for non-native speakers.
In terms of frequency analysis, another interesting
result is obtained. The frequency range between 1500 and
2500 Hz is found to be more significant than other
frequencies in the spectrum in discriminating foreign
accent. This frequency range does not comply with the
most significant frequency range for automatic speech
recognition which is 0 to 1000 Hz. Based on this
finding, a new frequency scale is formulated which
emphasizes accent sensitive frequencies in the
calculation of cepstrum coefficients instead of the
commonly used Mel-scale. Experiments on the accent
database as well as the OGI multi-language database
verified that the new scale results in better
performance.
Based on the acoustic feature set developed, an HMM
based accent classifier is formulated. It is found that
as the length of the utterance increases better accent
classification performance can be obtained. After 7-8
words, the speaker accent can be identified with 93%
accuracy, whereas the accuracy is 62% when a single word
is used as the test utterance.
Finally, two methods to improve accent classifier
performance is proposed.
First, the training process is improved by assigning
different weights to the training tokens based on the
level of foreign accent they exhibit acoustically.
Second, the scoring stage is improved by estimating a
bias among the accent models based on the classification
performance on the training data.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  3752 </NUMBER>
<ORDER>   AAG9704347 </ORDER>
<TITLE> HIERARCHICAL SET REPRESENTATIONS OF SPEECH </TITLE>
<AUTHOR> SARUKKAI, RAMESH R. </AUTHOR>
<YEAR> 1996 </YEAR>
<INSTITUTION> THE UNIVERSITY OF ROCHESTER; 0188 </INSTITUTION>
<DESCRIPTORS> COMPUTER SCIENCE; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> DANA H. BALLARD </ADVISER>
<CLASSIFICATIONS> PATTERN RECOGNITION, ARTIFICIAL INTELLIGENCE </CLASSIFICATIONS>
<ABSTRACT>
This work demonstrates that a unified hierarchy of non-
sequential set representations of speech exists at
different temporal scales. This is due to the fact that
speech is not only distinguishable as an ordered
temporal sequence of elements, but has a high degree of
discernibility in a non-temporal sense. This thesis has
been evaluated at the acoustic, phonetic, and word
levels and provides new insights into the speech
recognition problem.
The advantages of having set representations as the
central framework is apparent at different levels of the
speech hierarchy. Distance set representations enable
compact acoustic models. The method of phonetic set
indexing is a very fast method of pre-fetching word
lists. At the word level, the concept of word sets
allows for long distance relations between words to be
captured, and gives rise to the concept of utterance and
dialogue triggers which have been implemented in the
context of the derived Trigger and Adaptive Boosting
(TAB) algorithm. Voting with unified codebooks for
speaker identification is also presented. Experiments
have been performed in various speech domains including
TIMIT, Trains-93, and Trains-95 corpus.
Set representations of speech have been utilized in two
novel applications: multi-modal integration, and web
browsing with speech. The notion of using loosely
synchronized eye-fixation information to improve speech
recognition is proposed and evaluated in the TRAINS
domain. The novel concept of web triggered word sets is
introduced in the World Wide Web(WWW) speech interface
system, NetSpeak, for improved HTML link access.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  3753 </NUMBER>
<ORDER>   AAG9704334 </ORDER>
<TITLE> MORPHOLOGICAL CUES FOR LEXICAL SEMANTICS </TITLE>
<AUTHOR> LIGHT, MARC NOEL </AUTHOR>
<YEAR> 1996 </YEAR>
<INSTITUTION> THE UNIVERSITY OF ROCHESTER; 0188 </INSTITUTION>
<DESCRIPTORS> COMPUTER SCIENCE; LANGUAGE, LINGUISTICS; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> LENHART K. SCHUBERT </ADVISER>
<CLASSIFICATIONS> NATURAL LANGUAGES, ARTIFICIAL INTELLIGENCE </CLASSIFICATIONS>
<ABSTRACT>
Most natural language processing tasks require lexical
semantic information such as verbal argument structure
and selectional restrictions, corresponding nominal
semantic class, verbal aspectual class, synonym and
antonym relationships between words, and various verbal
semantic features such as causation and manner. This
dissertation addresses two primary questions related to
such information: how should one represent it and how
can one acquire it.
It is argued that, in order to support inferencing, a
representation with well-understood semantics should be
used. Standard first order logic has well-understood
semantics and a multitude of inferencing systems have
been implemented for it. However, standard first order
logic, although a good starting point, needs to be
extended before it can efficiently and concisely support
all the lexically-based inferences needed. Using data
primarily from the TRAINS dialogues, the following
extensions are argued for: modal operators, predicate
modification, restricted quantification, and non-
standard quantifiers. These representational tools are
present in many systems for sentence-level semantics but
have not been discussed in the context of lexical
semantics.
A number of approaches to automatic acquisition are
considered and it is argued that a "surface cueing"
approach is currently the most promising. Morphological
cueing, a type of surface cueing, is introduced. It
makes use of fixed correspondences between derivational
affixes and lexical semantic information. The semantics
of a number of affixes are discussed and data resulting
from the application of the method to the Brown corpus
is presented.
Finally, even if lexical semantics could be acquired on
a large scale, natural language processing systems would
continue to encounter unknown words. Derivational
morphology can also be used at run-time to help natural
language understanding systems deal with unknown words.
A system is presented that provides lexical semantic
information for such derived unknown words.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  3754 </NUMBER>
<ORDER>   AAGMM16722 </ORDER>
<TITLE> A FUZZY LOGIC CONTROL SYSTEM FOR INFRARED HEAT TREATMENT OF THREE-GRAIN CEREAL FOR HUMAN CONSUMPTION </TITLE>
<AUTHOR> ROTHWELL, TERRENCE MICHAEL </AUTHOR>
<YEAR> 1996 </YEAR>
<INSTITUTION> UNIVERSITY OF GUELPH (CANADA); 0081 </INSTITUTION>
<DESCRIPTORS> ENGINEERING, AGRICULTURAL; AGRICULTURE, FOOD SCIENCE AND TECHNOLOGY; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> R. B. BROWN </ADVISER>
<CLASSIFICATIONS> NIL </CLASSIFICATIONS>
<ABSTRACT>
A supervisory fuzzy logic control system for controlling
infrared roasting of three-grain hot breakfast cereal
was designed and tested. The design incorporated
commercial fuzzy preprocessor software, which
facilitated encapsulation of the underlying human-based
reasoning used to govern the process. The controller was
tested in a simulator using heated air, rather than
grain, as the medium. This permitted rapid commissioning
of the system in the manufacturing facility where it is
now employed. In situ testing confirmed that the
controller provided final product characteristics that
were at least equal to those obtained with human
(manual) control procedures.
It was determined that the maximum safe (product)
temperature for roasting the cereal with the IR roaster
at the test facility was lower than the 90$spcirc$C
optimum suggested in previous work. Attempts to achieve
90$spcirc$C caused serious overheating.
The controller was subjected to appreciable load
disturbances which it was able to accomodate.
The system significantly reduced the dependency on
constant human supervision of this process, and
therefore eliminated the most drudgery-like aspects of
roaster control.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  3755 </NUMBER>
<ORDER>   AAG9703297 </ORDER>
<TITLE> DECISION THEORY MADE TRACTABLE: THE VALUE OF DELIBERATION, WITH APPLICATIONS TO MARKOV DECISION PROCESS PLANNING </TITLE>
<AUTHOR> TASH, JONATHAN KING </AUTHOR>
<YEAR> 1996 </YEAR>
<INSTITUTION> UNIVERSITY OF CALIFORNIA, BERKELEY; 0028 </INSTITUTION>
<DESCRIPTORS> COMPUTER SCIENCE; PHILOSOPHY; OPERATIONS RESEARCH </DESCRIPTORS>
<ADVISER> STUART RUSSELL; LOTFI ZADEH </ADVISER>
<CLASSIFICATIONS> NIL </CLASSIFICATIONS>
<ABSTRACT>
This dissertation addresses the construction of an
operational definition of rationality in the face of
computational constraints. Rational decision problem
classes are often NP hard, almost certainly eliminating
the possibility of any agent ever exhibiting behavior
that fully meets the decision-theoretic characterization
of rationality.
The most promising approaches extant in the artificial
intelligence literature, bounded optimality and
metalevel control of computational expenditures, do
provide insight into possible agent architectures
capable of exhibiting many interesting behaviors that
have parallels in human problem-solving. They do not,
however, resolve the fundamental difficulty of how
rationality can be redefined so as to take into account
the costs of its own application. This work argues that
the role of rationality is in the evaluation of the
agent from an external perspective, rather than in the
generation of decisions by the agent, providing a new
conception of the role of background or situation in
decision making. It clarifies what rational metalevel
controllers can accomplish and how they should be
designed.
Rational metalevel control allows for problem-solving
strategies to be much more responsive to a variety of
resource constraints and environmental factors. This
work presents metalevel architectures for problem
domains modellable as Markov decision processes. They
are demonstrated to exhibit the desired responsiveness
on some simple examples such as mazes. They cope well
with time pressure and random environmental variations.
They exhibit behaviors that take account of their
previous planning efforts, such as sticking to known
solutions when thinking is expensive. These features
offer new hope for scaling algorithmic stochastic
planning to large domains.
Also discussed are methods of abstracting a decision
model by coarse graining its state space, and the loss
to decision model quality incurred by such an
approximation. This work concludes with a discussion of
issues that arise when abstract actions are
characterized as plans to plan.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  3756 </NUMBER>
<ORDER>   AAG9700774 </ORDER>
<TITLE> EXTRACTING COMPREHENSIBLE MODELS FROM TRAINED NEURAL NETWORKS  </TITLE>
<AUTHOR> CRAVEN, MARK WILLIAM </AUTHOR>
<YEAR> 1996 </YEAR>
<INSTITUTION> THE UNIVERSITY OF WISCONSIN - MADISON; 0262 </INSTITUTION>
<DESCRIPTORS> COMPUTER SCIENCE; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> JUDE W. SHAVLIK </ADVISER>
<CLASSIFICATIONS> MACHINE LEARNING </CLASSIFICATIONS>
<ABSTRACT>
Although neural networks have been used to develop
highly accurate classifiers in numerous real-world
problem domains, the models they learn are notoriously
difficult to understand. This thesis investigates the
task of extracting comprehensible models from trained
neural networks, thereby alleviating this limitation.
The primary contribution of the thesis is an algorithm
that overcomes the significant limitations of previous
methods by taking a novel approach to the task of
extracting comprehensible models from trained networks.
This algorithm, called T scREPAN, views the task as an
inductive learning problem. Given a trained network, or
any other learned model, T scREPAN uses queries to
induce a decision tree that approximates the function
represented by the model. Unlike previous work in this
area, T scREPAN is broadly applicable as well as
scalable to large networks and problems with high-
dimensional input spaces. The thesis presents
experiments that evaluate T scREPAN by applying it to
both individual networks and ensembles of neural
networks trained in classification, regression, and
reinforcement-learning domains. The experiments
demonstrate that T scREPAN is able to extract decision
trees that are comprehensible, yet maintain high levels
of fidelity to their respective networks. In problem
domains in which neural networks provide superior
predictive accuracy to conventional decision tree
algorithms, the trees extracted by T scREPAN also
exhibit superior accuracy, but are comparable in terms
of complexity, to the trees learned directly from the
training data.
A secondary contribution of this thesis is an algorithm,
called BBP, that constructively induces simple neural
networks. The motivation underlying this algorithm is
similar to that for T scREPAN: to learn comprehensible
models in problem domains in which neural networks have
an especially appropriate inductive bias. The BBP
algorithm, which is based on a hypothesis-boosting
method, learns perceptrons that have relatively few
connections. This algorithm provides an appealing
combination of strengths: it provides learnability
guarantees for a fairly natural class of target
functions; it provides good predictive accuracy in a
variety of problem domains; and it constructs
syntactically simple models, thereby facilitating human
comprehension of what it has learned. These algorithms
provide mechanisms for improving the understanding of
what a trained neural network has learned.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  3757 </NUMBER>
<ORDER>   AAG1382158 </ORDER>
<TITLE> EXPERT PILOT SYSTEM </TITLE>
<AUTHOR> WESTBROOK, THOMAS DARREL </AUTHOR>
<YEAR> 1996 </YEAR>
<INSTITUTION> STATE UNIVERSITY OF NEW YORK INSTITUTE OF TECHNOLOGY AT UTICA-ROME; 1026 </INSTITUTION>
<DESCRIPTORS> COMPUTER SCIENCE; ENGINEERING, AEROSPACE; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> ROGER CAVALLO </ADVISER>
<CLASSIFICATIONS> GLOBAL POSITIONING SYSTEM, COCKPIT AUTOMATION </CLASSIFICATIONS>
<ABSTRACT>
The deployment of the United States Global Positioning
System (GPS) has sparked an increase in the market of
precision placement of objects on and above the earth's
surface. An area where GPS has great potential is global
aviation. The GPS system can potentially restructure the
global aviation market through reduced fuel usage,
decreased flying time between departure and arrival
airports, and increased airport accessibility. The
Federal Aviation Administration (FAA) is investigating
concepts that will radically change the United States
air route structure and put more of the air route
clearance authority in the cockpit. More authority in
the aircraft cockpit will require cockpit automation.
This thesis explores one approach to increasing cockpit
automation through the definition, formulation, and
partial implementation of an Expert Pilot System (EPS).
The EPS would be capable of directing an aircraft from
the departure gate to the destination arrival gate.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  3758 </NUMBER>
<ORDER>   AAG1382147 </ORDER>
<TITLE> AN INTELLIGENT CONTROLLER FOR THE TAKE-OFF OF THE RUNNING STRIDE OF A LINKED LEG </TITLE>
<AUTHOR> VENKATESH, MANI </AUTHOR>
<YEAR> 1996 </YEAR>
<INSTITUTION> LAMAR UNIVERSITY - BEAUMONT; 0424 </INSTITUTION>
<DESCRIPTORS> COMPUTER SCIENCE; ARTIFICIAL INTELLIGENCE; ENGINEERING, MECHANICAL </DESCRIPTORS>
<ADVISER> NIL </ADVISER>
<CLASSIFICATIONS> ROBOTICS </CLASSIFICATIONS>
<ABSTRACT>
This thesis is a preliminary investigation into the use
of neuro-fuzzy learning techniques used to control the
height, distance and angular momentum of a single
running stride of a simulated linked leg. Learning from
experience is the key to achieving autonomous
intelligent behavior. It makes this technique more
attractive than techniques that use the physical
equations of motion to control the robot. Local training
enables the robot to learn new strides without global
off-line training.
This thesis presents the design of the controller and
the results obtained in preliminary training on test
data. The controller is trained only to the extent
necessary to identify and analyze the trends in
performance caused by changes in the various training
parameter values. Also constraints are introduced to
reduce the problem size. Hence this thesis is a partial
solution and provides an insight into the design and
appropriate training parameter values for this problem.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  3759 </NUMBER>
<ORDER>   AAG1382118 </ORDER>
<TITLE> NEURAL NETWORK MODELING AND OPTIMIZATION OF ZEOLITIC AUTOMOBILE EXHAUST CATALYSTS </TITLE>
<AUTHOR> SRINIVASAN, NITHYA </AUTHOR>
<YEAR> 1996 </YEAR>
<INSTITUTION> UNIVERSITY OF LOUISVILLE; 0110 </INSTITUTION>
<DESCRIPTORS> ENGINEERING, CHEMICAL; ARTIFICIAL INTELLIGENCE; ENGINEERING, AUTOMOTIVE </DESCRIPTORS>
<ADVISER> RAUL MIRANDA </ADVISER>
<CLASSIFICATIONS> NIL </CLASSIFICATIONS>
<ABSTRACT>
Recent research in automobile exhaust catalysts
addresses the substitution of platinum-group metals Pt,
Pd and Rh by metals such as Cu, Co, Ag, Zn, Mn and Sr
impregnated on zeolites, TiO$sb2$ or ZrO$sb2$ carriers.
Experimentally designing an exhaust catalyst to convert
the pollutants such as hydrocarbons (HC), carbon
monoxide (CO) and nitrogen oxides (NO$rmsb0x)$ into
H$sb2$O, CO$sb2$ and N$sb2$ is expensive and time
consuming. With the objective of identifying a
simulation technique robust enough to be adaptable for
designing catalysts, neural networks have been used to
correlate the catalyst synthesis variables and the
resulting exhaust conversions, and hence determine the
optimum catalyst composition and operating conditions
for a specified exhaust conversion.
A back-propagation algorithm was used to train the
network and the optimum architecture consisted of two
hidden layers with 45 and 60 neurons in the first and
second hidden layers respectively. The effects of
learning factor and momentum gain coefficient were
studied. The effects of the operating and compositional
parameters on NO$rmsb0x$ conversion by Cu-ZSM-5 were
found.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  3760 </NUMBER>
<ORDER>   AAG1382101 </ORDER>
<TITLE> AN EXPERT SYSTEM FOR RIVERBANK PROTECTION </TITLE>
<AUTHOR> GOPINATHAN, MAHESH </AUTHOR>
<YEAR> 1996 </YEAR>
<INSTITUTION> UNIVERSITY OF LOUISVILLE; 0110 </INSTITUTION>
<DESCRIPTORS> COMPUTER SCIENCE; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> DAR-JEN CHANG </ADVISER>
<CLASSIFICATIONS> NIL </CLASSIFICATIONS>
<ABSTRACT>
The RB Expert system is a rule-based expert system
supported with graphical user interface on a database
platform designed to suggest protective measures on
riverbanks against riverbank failures, based on bank
classifications on bed and material stability, planform
geometry, and other hydrologic and morphologic features.
The program uses a set of rules to drive in its search
for stream classifications and utilizes backward
chaining method in sifting though its rule set. The data
on classifications, vegetation and erosion history are
stored in a knowledgebase forming the base for deriving
intelligent solutions provided by the expert system. A
complete Client/Server system, comprising of a set of
tables created with relational database management
system (RDBMS) concepts and graphical user interface
(GUI) was developed and implemented. The system has
provision to store and retrieve graphic, audio and video
images of the different riverbanks using open database
connectivity (ODBC) and object linking and embedding
(OLE) features of the frontend tools.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  3761 </NUMBER>
<ORDER>   AAG1381743 </ORDER>
<TITLE> STATISTICAL REPRESENTATION OF WAVELET TRANSFORMS FROM LOW-FEATURE ULTRASHORT LASER PULSE SPECTROGRAMS FOR IMPROVED NEURAL NETWORK RECOGNITION </TITLE>
<AUTHOR> SEARCY, MARTIN L. </AUTHOR>
<YEAR> 1996 </YEAR>
<INSTITUTION> UTAH STATE UNIVERSITY; 0241 </INSTITUTION>
<DESCRIPTORS> COMPUTER SCIENCE; PHYSICS, OPTICS; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> DONALD H. COOLEY </ADVISER>
<CLASSIFICATIONS> NIL </CLASSIFICATIONS>
<ABSTRACT>
The electric field associated with spectrograms
generated by Frequency-Resolved Optical Gating (FROG) of
ultrashort laser pulses can be recovered through an
iterative computational process. The process, however,
is limited in application by its long compute time.
Training a neural network to recognize features in the
spectrograms, or FROG traces, gives a more direct, or
instantaneous, solution of the electric fields.
This thesis is a study of an original method of compact
FROG trace feature description for neural network
training. The method consists of performing a wavelet
transform on each trace, and then describing groups of
meaningful wavelet coefficients in each wavelet order
through statistical moments in three dimensions.
Experimental results demonstrate that this approach of
using a wavelet transform as a basis for training a
neural network on large low-feature FROG images is quite
successful in terms of standard recognition error
estimates.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  3762 </NUMBER>
<ORDER>   AAG1381742 </ORDER>
<TITLE> AN ADAPTIVE "NATURAL LAW" FUZZY CONTROLLER </TITLE>
<AUTHOR> SEQUEIRA, SANDEEP DOMINIC </AUTHOR>
<YEAR> 1996 </YEAR>
<INSTITUTION> UTAH STATE UNIVERSITY; 0241 </INSTITUTION>
<DESCRIPTORS> ENGINEERING, ELECTRONICS AND ELECTRICAL; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> ROBERT W. GUNDERSON </ADVISER>
<CLASSIFICATIONS> NIL </CLASSIFICATIONS>
<ABSTRACT>
This thesis research has explored the notion that fuzzy
control, despite being a rule-based control strategy,
can be approximated in the limit by a linear control
scheme and can, further, be reconciled with more
conventional design and analysis methods. By extending
the results of the "natural law" theorems by Bouslama
and Ichikawa to the control of digital servo-systems,
this thesis presents a systematic design procedure for a
fuzzy controller by utilizing the considerable resources
and well-developed techniques of linear control theory.
The preliminary contribution of this thesis has been to
show that the "natural law" limit theorem remains valid
for the more widely used scaled (correlation-product)
inference with the faster center-of-sums
defuzzification. By relating the theoretical results
obtained to conventional control theory, a systematic
design scheme has been proposed based on linear state
feedback and direct digital design. A unique method of
relating the state-feedback gains to the partitions of
the fuzzy sets has also been presented. By employing a
modified MRAC scheme, direct adaptation capability has
been provided to modify the fuzzy sets on-line. To the
author's knowledge, this adaptive "natural law" fuzzy
controller (ANFC) is a novel attempt at applying
advanced techniques directly from linear systems theory
to fuzzy control.
This research has resulted in a coherent procedure for
the design of adaptive fuzzy controllers for digital
servo-systems. This design method has been implemented
as a control algorithm and used successfully to balance
an inverted pendulum. The performance comparisons of the
ANFC with other control schemes offer definite
encouragement for future research along these lines.
(Abstract shortened by UMI.)
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  3763 </NUMBER>
<ORDER>   AAG1381549 </ORDER>
<TITLE> HARMONIC FILTER DESIGN FOR LOW VOLTAGE INDUSTRIAL POWER SYSTEMS USING AN EXPERT SYSTEM </TITLE>
<AUTHOR> HARRELL, DALE HARMON </AUTHOR>
<YEAR> 1996 </YEAR>
<INSTITUTION> UNIVERSITY OF SOUTH ALABAMA; 0491 </INSTITUTION>
<DESCRIPTORS> ENGINEERING, ELECTRONICS AND ELECTRICAL; ARTIFICIAL INTELLIGENCE; ENERGY </DESCRIPTORS>
<ADVISER> ARIFUR RAHMAN </ADVISER>
<CLASSIFICATIONS> NIL </CLASSIFICATIONS>
<ABSTRACT>
In this thesis, using visual basic programming, an
expert system and a spreadsheet are combined, to design
harmonic filters for low and medium voltage power
systems. Based on the spreadsheet being utilized by ABB
controls of Wichita Falls, Texas, the spreadsheet
simulates the harmonic content of a low or medium
voltage power system at the Point of Common Coupling
(PCC). The PCC is the dividing point between the
consumer and the utility company, which is usually the
last transformer before the consumer's meter. The
spreadsheet incorporates the harmonic spectrum readout
of a BMI meter with the customer's power system data.
From these two items, data are transferred to the
spreadsheet, which calculates the harmonic content of
the system. The spreadsheet can utilize up to twelve odd
filters (i.e. 3-25), and can accommodate up to 4 fixed
harmonic filters, that is filters that may already be in
use in the system. The spreadsheet and the expert system
are linked together by a series of Visual Basic
programs. (Abstract shortened by UMI.)
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  3764 </NUMBER>
<ORDER>   AAG1381519 </ORDER>
<TITLE> FOUR DEGREE-OF-FREEDOM ROBOTIC ARM CONTROL USING ADAPTIVE FUZZY LOGIC </TITLE>
<AUTHOR> NGAMSOM, PINIT </AUTHOR>
<YEAR> 1996 </YEAR>
<INSTITUTION> TEXAS A&M UNIVERSITY-KINGSVILLE; 1187 </INSTITUTION>
<DESCRIPTORS> ENGINEERING, MECHANICAL; ENGINEERING, ELECTRONICS AND ELECTRICAL; ENGINEERING, SYSTEM SCIENCE; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> ROBERT A. MCLAUCHLAN </ADVISER>
<CLASSIFICATIONS> NIL </CLASSIFICATIONS>
<ABSTRACT>
A four degree-of-freedom robotic arm is controlled by an
adaptive fuzzy logic scheme. The arm has three revolute
joints allowing the corresponding links to move
horizontally. The other translation joint permits the
arm to move vertically.
In the path-planning algorithm, the problem of
singularity and redundancy have been solved by using the
magnitude of difference of the joint angels between two
consecutive states. The computation time necessary for
this algorithm is very small.
The control strategy is divided into two levels. The
meta-level scheme adjusts the firing strength of each
fuzzy rule while the basic-level scheme emits control
action to the system.
The mathematical model for simulation includes the
dynamics of the arm and that of the joint motors. In
addition to that, the control board and motor driver
have been designed and implemented to perform the
experiment on the real system. The results of simulation
and experiment are satisfactory.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  3765 </NUMBER>
<ORDER>   AAGMM16207 </ORDER>
<TITLE> IDENTIFICATION OF BIRDSONG USING ARTIFICIAL NEURAL COMPUTING </TITLE>
<AUTHOR> MCILRAITH, ALEXANDER LESLIE </AUTHOR>
<YEAR> 1996 </YEAR>
<INSTITUTION> THE UNIVERSITY OF MANITOBA (CANADA); 0303 </INSTITUTION>
<DESCRIPTORS> ENGINEERING, ELECTRONICS AND ELECTRICAL; ARTIFICIAL INTELLIGENCE; ENVIRONMENTAL SCIENCES; BIOLOGY, ZOOLOGY </DESCRIPTORS>
<ADVISER> M. C. CARD </ADVISER>
<CLASSIFICATIONS> NIL </CLASSIFICATIONS>
<ABSTRACT>
Recently birds have become a focus of attention as
indicators of environmental quality, and as part of the
growing hobby of bird-watching. Many bird sounds are
distinctive enough that one can identify a species by
its sound.
Like speech, bird songs have characteristic temporal and
spectral qualities. Techniques such as linear predictive
coding (LPC) and power spectral density (PSD) analysis
combined with temporal cues provides useful input for
pattern recognition methods including neural networks or
discriminant analysis.
In this study, 133 recorded bird songs of six species
were sampled and digitally pre-processed. From sampled
data, spectral and temporal measurements were made. Two
different approaches were taken in pre-processing and
subsequent identification.
Identification of records in the test sets involved the
use of a back-propagation neural network and quadratic
discriminant analysis. Experimentation suggested that a
network with eight inputs, six hidden units and six
outputs trained over 200 epochs was appropriate.
Accuracy was 82%. However, with discriminant analysis,
this method achieved an accuracy of 93.3%. Further
research would be required to determine whether or not
additional tuning of the neural network architecture and
parameters could improve its performance relative to
discriminant analysis.
Given the result, the second approach, with discriminant
analysis, appears to be the best choice for two reasons.
First, it required less computational time since a
smaller network with fewer training epochs was required.
Secondly, identification accuracy was essentially
equivalent to that of the first approach. (Abstract
shortened by UMI.)
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  3766 </NUMBER>
<ORDER>   AAG1381171 </ORDER>
<TITLE> HYBRID PERCEPTRONS </TITLE>
<AUTHOR> LLAGOSTERA, JORDI XARGAYO </AUTHOR>
<YEAR> 1996 </YEAR>
<INSTITUTION> PACIFIC LUTHERAN UNIVERSITY; 6200 </INSTITUTION>
<DESCRIPTORS> COMPUTER SCIENCE; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> RICHARD SPILLMAN </ADVISER>
<CLASSIFICATIONS> NEURAL NETWORKS, ARTIFICIAL INTELLIGENCE </CLASSIFICATIONS>
<ABSTRACT>
The astonishing capabilities of the human brain have
always captured the attention of researchers from
different scientific disciplines. Pioneers like Ramon i
Cajal and Jackson initiated one century ago a study of
the brain that lead to the creation of a new area of
research known today by many different names such as
neural networks or parallel distributed processing. More
recently, the development of genetic algorithms provided
new tools for approaching traditional issues such as the
weight selection problem in neural networks. With these
new tools it is possible to create hybrid systems that
combine elements of neural networks and genetic
algorithms. This thesis project has two main objectives.
First, it attempts to serve as a theoretical
introduction to parallel distributed processing and
genetic algorithms. Second, it studies the practical
application of genetic algorithms to the weight
selection process in a multilayer perceptron.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  3767 </NUMBER>
<ORDER>   AAG1381092 </ORDER>
<TITLE> A RELIABILITY CENTERED MAINTENANCE DECISION SYSTEM FOR A DISCRETE PART MANUFACTURING FACILITY </TITLE>
<AUTHOR> PUJADAS, WAYNE </AUTHOR>
<YEAR> 1996 </YEAR>
<INSTITUTION> FLORIDA INTERNATIONAL UNIVERSITY; 1023 </INSTITUTION>
<DESCRIPTORS> ENGINEERING, INDUSTRIAL; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> F. FRANK CHEN </ADVISER>
<CLASSIFICATIONS> NIL </CLASSIFICATIONS>
<ABSTRACT>
This thesis develops and validates the framework of a
specialized maintenance decision support system for a
discrete part manufacturing facility. Its construction
utilizes a modular approach based on the fundamental
philosophy of Reliability Centered Maintenance (RCM).
The proposed architecture uniquely integrates System
Decomposition, System Evaluation, Failure Analysis,
Logic Tree Analysis, and Maintenance Planning modules.
It presents an ideal solution to the unique maintenance
inadequacies of modern discrete part manufacturing
systems. Well established techniques are incorporated as
building blocks of the system's modules. These include
Failure Mode Effect and Criticality Analysis (FMECA),
Logic Tree Analysis (LTA), Theory of Constraints (TOC),
and an Expert System (ES). A Maintenance Information
System (MIS) performs the system's support functions.
Validation was performed by field testing of the system
at a Miami based manufacturing facility. Such a
maintenance support system potentially reduces downtime
losses and contributes to higher product quality output.
Ultimately improved profitability is the final outcome.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  3768 </NUMBER>
<ORDER>   AAG1381062 </ORDER>
<TITLE> REDUCING MATCH TIME VARIANCE IN PRODUCTION SYSTEMS WITH HAL </TITLE>
<AUTHOR> LEE, POU-YUNG </AUTHOR>
<YEAR> 1996 </YEAR>
<INSTITUTION> UNIVERSITY OF HOUSTON; 0087 </INSTITUTION>
<DESCRIPTORS> COMPUTER SCIENCE; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> ALBERT M. K. CHENG </ADVISER>
<CLASSIFICATIONS> NIL </CLASSIFICATIONS>
<ABSTRACT>
Existing match algorithms approach the matching process
similarly to the querying process of relational
databases but incrementally. The potentially
combinatorial nature of the matching process and the
difference in the quantity of data each rule needs to
process introduce match time variance in the matching
cycles. Current match algorithms utilize local matching
support networks containing redundant working memory
elements. This compounds the variance by increasing
further the quantity of data that need to be matched.
Large match time variance makes them unsuitable for real-
time applications requiring timing constraint. We
introduce the Heuristically-Annotated-Linkage (HAL)
match algorithm to reduce match time variance. HAL
treats rules and classes as objects, or nodes, in only
one global bipartite-graph-like connection and
communication scheme to reduce data redundancy. In
addition, HAL is suitable for real-time applications
because it is capable of immediate characterization of
any datum upon arrival to allow immediate execution of
timing constrained actions.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  3769 </NUMBER>
<ORDER>   AAG1381046 </ORDER>
<TITLE> FEATURE SELECTION FOR CLASSIFICATION OF MEDICAL IMAGES OF HUMAN TISSUE FOR CANCER RECOGNITION </TITLE>
<AUTHOR> TSAREV, VALERI V. </AUTHOR>
<YEAR> 1996 </YEAR>
<INSTITUTION> UNIVERSITY OF NEVADA, LAS VEGAS; 0506 </INSTITUTION>
<DESCRIPTORS> COMPUTER SCIENCE; HEALTH SCIENCES, RADIOLOGY; HEALTH SCIENCES, CHEMOTHERAPY; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> NIL </ADVISER>
<CLASSIFICATIONS> PROSTATE CANCER </CLASSIFICATIONS>
<ABSTRACT>
A statistical pattern recognition system for ultrasound
medical images of prostatic tissue for cancer has been
proposed. Using the autocorrelation method, the correct
size of a statistical sliding window for feature
extraction was defined. Known texture discrimination
features have been tested for effectiveness. Another set
of discriminating features, based on edge value
distribution, Fourier power spectrum and wavelet
transform has been derived and investigated. The set can
be used as an input to a neural net classifier.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  3770 </NUMBER>
<ORDER>   AAG1381013 </ORDER>
<TITLE> OBJECT IDENTIFICATION FOR ROBOTIC APPLICATIONS USING EXPERT SYSTEMS </TITLE>
<AUTHOR> DEVARAJAN, SURESHKUMAR </AUTHOR>
<YEAR> 1996 </YEAR>
<INSTITUTION> UNIVERSITY OF NEVADA, LAS VEGAS; 0506 </INSTITUTION>
<DESCRIPTORS> ENGINEERING, MECHANICAL; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> NIL </ADVISER>
<CLASSIFICATIONS> NIL </CLASSIFICATIONS>
<ABSTRACT>
The objective of this project is to develop an
intelligent machine vision system for robotic
applications to identify engineering tools and
components.
The imaging system consists of a 2-D digital camera and
an ultrasonic range sensor attached to the robot end
effector. Images of the target objects are captured by
the camera. The images are then processed to remove the
signal noise and to extract the object boundary.
One major objective is to develop object feature
descriptions which are invariant to scaling, translation
or orientation. Efficient data reduction to an array of
fewer than 25 numbers is achieved by the use of Fourier
and regional descriptors. One of the array elements,
object thickness, is determined directly from ultrasound
range measurement.
An expert system was successfully developed to classify
the objects based on their descriptors. The knowledge
base consists of rules for searching and pattern
matching. The sensors were integrated to form a working
vision system for the PUMA 500 robot. The performance of
the vision system was tested with a set of objects. The
expert system was found to be efficient, successful, and
reliable in identifying all tested objects even with
signal noise being present.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  3771 </NUMBER>
<ORDER>   AAG1381007 </ORDER>
<TITLE> DESIGN OF FUZZY LOGIC BASED ADAPTIVE TRAFFIC SIGNAL CONTROLLER </TITLE>
<AUTHOR> ANDE, MURALI MOHAN </AUTHOR>
<YEAR> 1996 </YEAR>
<INSTITUTION> UNIVERSITY OF NEVADA, LAS VEGAS; 0506 </INSTITUTION>
<DESCRIPTORS> ENGINEERING, CIVIL; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> NIL </ADVISER>
<CLASSIFICATIONS> NIL </CLASSIFICATIONS>
<ABSTRACT>
Traffic control of street intersections is one of the
most critical elements in providing an efficient flow of
traffic in urban networks. Conventionally, pretimed
controllers are used, but they cannot respond to real
time fluctuations in traffic demand. Traffic actuated
signals provide an improvement over pretimed
controllers, but their performance deteriorates under
heavy traffic conditions. These conditions necessitate
the development of a controller that responds to actual
traffic demand in real time, with the objective of
minimizing vehicle delays, number of stops, etc. Fuzzy
logic provides the potential for development of a system
that would address these needs.
The objective of this research is to design and evaluate
a fuzzy logic based controller for traffic intersections
that is adaptive to traffic demand. The design uses the
standard input traffic flow parameters generated by
existing loop detectors. The outcome of this research is
a traffic controller that is very responsive to real-
time traffic flow for various traffic simulations,
including both recurring and non-recurring conditions.
Evaluation of the performance of the system is based on
minimization of delay and the number of stops. The
performance of the fuzzy controller is compared to that
of a pretimed controller with the help of traffic
packages NETSIM & SOAP-84.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  3772 </NUMBER>
<ORDER>   AAGMM12924 </ORDER>
<TITLE> A NEW DESIGN APPROACH TO SERVICEABILITY USING ACTIVITY BASED COSTING, FUZZY LOGIC AND MODULAR DESIGN </TITLE>
<AUTHOR> SAHOTA, DALJINDER SINGH </AUTHOR>
<YEAR> 1996 </YEAR>
<INSTITUTION> UNIVERSITY OF CALGARY (CANADA); 0026 </INSTITUTION>
<DESCRIPTORS> ENGINEERING, MECHANICAL; OPERATIONS RESEARCH; BUSINESS ADMINISTRATION, ACCOUNTING; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> PEIHUA GU </ADVISER>
<CLASSIFICATIONS> NIL </CLASSIFICATIONS>
<ABSTRACT>
This thesis presents a methodology to assist the product
designer in calculating and reducing product life-cycle
service costs during initial design stages. A simple and
effective format has been devised to represent the
product disassembly sequences in a hierarchical form.
Activity Based Costing (ABC) has been used to calculate
the part service costs. This costing technique supports
the tracing of the service costs to the service
characteristics of the respective parts. Two strategies
have been explored for reducing the product service
costs. The first technique grades all the parts
according to their service requirements. The second
technique involves combining the parts, having similar
service requirements, into modules. Both techniques
provide suggestions (possible design modifications) to
decrease the product service costs. The modifications
are evaluated for corresponding decrease in service cost
to test their efficacy. Finally, the methodology is
tested using two case study products to check its
versatility.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  3773 </NUMBER>
<ORDER>   AAGMM12587 </ORDER>
<TITLE> IMPLEMENTATION AND PERFORMANCE OF TRANSACTION LOGIC IN PROLOG </TITLE>
<AUTHOR> HUNG, SAMUEL YET KEUNG </AUTHOR>
<YEAR> 1996 </YEAR>
<INSTITUTION> UNIVERSITY OF TORONTO (CANADA); 0779 </INSTITUTION>
<DESCRIPTORS> COMPUTER SCIENCE; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> ANTHONY BONNER </ADVISER>
<CLASSIFICATIONS> NIL </CLASSIFICATIONS>
<ABSTRACT>
Transaction Logic is a recently proposed logic which
accounts for state changes in logic programs and
databases. With this increase in functionality, it can
be used in a wide class of applications such as in logic
programming, graph theory, and AI.
The contributions of this thesis are twofold. First, we
present a Prolog implementation of the serial-Horn
fragment of Transaction Logic. We developed four
prototypes, which range from simple but slow, to fast
but complex. The functionality of the implementation
includes queries, bactrackable updates, serial execution
of transactions, bulk updates, and procedural
constructs, such as iterative loops. Second, we exercise
and test our implementations on various graph problems.
We test several different Transaction Logic prototypes
implemented on top of several different Prologs. The
results effectively compare the query and update
performance of different Prologs. They also show that
with some Prologs, Transaction Logic programs achieve
efficiency comparable to programs with destructive
updates in procedural programming languages.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  3774 </NUMBER>
<ORDER>   AAGMM12253 </ORDER>
<TITLE> ANALYSIS OF A DELAY DIFFERENTIAL EQUATION MODEL OF A NEURAL NETWORK </TITLE>
<AUTHOR> OLIEN, LEONARD </AUTHOR>
<YEAR> 1996 </YEAR>
<INSTITUTION> MCGILL UNIVERSITY (CANADA); 0781 </INSTITUTION>
<DESCRIPTORS> MATHEMATICS; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> JACQUES BELAIR </ADVISER>
<CLASSIFICATIONS> NIL </CLASSIFICATIONS>
<ABSTRACT>
In this thesis I examine a delay differential equation
model for an artificial neural network with two neurons.
Linear stability analysis is used to determine the
stability region of the stationary solutions. They can
lose stability through either a pitchfork or a
supercritical Hopf bifurcation. It is shown that, for
appropriate parameter values, an interaction takes place
between the pitchfork and Hopf bifurcations. Conditions
are found under which the set of initial conditions that
converge to a stable stationary solution is open and
dense in the function space. Analytic results are
illustrated with numerical simulations.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  3775 </NUMBER>
<ORDER>   AAGMM12152 </ORDER>
<TITLE> SENSIBLE HEAT FLUX ESTIMATION OVER A PRAIRIE GRASSLAND BY NEURAL NETWORKS </TITLE>
<AUTHOR> ABARESHI, BEHZAD </AUTHOR>
<YEAR> 1996 </YEAR>
<INSTITUTION> MCGILL UNIVERSITY (CANADA); 0781 </INSTITUTION>
<DESCRIPTORS> PHYSICS, ATMOSPHERIC SCIENCE; ARTIFICIAL INTELLIGENCE; REMOTE SENSING </DESCRIPTORS>
<ADVISER> PETER SCHUEPP </ADVISER>
<CLASSIFICATIONS> NIL </CLASSIFICATIONS>
<ABSTRACT>
Sensible heat flux, a key component of the surface
energy balance, is difficult to estimate in practice.
This study was conducted to see if backpropagation
neural networks could estimate sensible heat flux by
using horizontal wind speed, air temperature,
radiometric surface temperature, net radiation, and time
as input. Ground measurements from the First ISLSCP
(International Satellite Land Surface Climatology
Project) Field Experiment (FIFE), collected in 1987 and
1989 over a prairie grassland in Kansas, were used for
network training and validation. Networks trained on
part of the data from a narrow range of space-time
coordinates performed well over the other part, with
error (root mean square error divided by mean of
observations) values as low as 0.24. This indicates the
potential in neural networks for linking sensible heat
flux to routinely measured meteorological variables and
variables amenable to remote sensing. When the networks
were tested with data from other space-times,
performance varied from good to poor, with average error
values around 1.26. This was mainly due to lack of input
variables parameterizing canopy morphology and soil
moisture, indicating that such variables should be
incorporated in the design of future networks intended
for large scale applications.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  3776 </NUMBER>
<ORDER>   AAGMM15727 </ORDER>
<TITLE> FORMAL SPECIFICATION AND FEATURE INTERACTION DETECTION IN THE INTELLIGENT NETWORK </TITLE>
<AUTHOR> KAMOUN, JALEL </AUTHOR>
<YEAR> 1996 </YEAR>
<INSTITUTION> UNIVERSITY OF OTTAWA (CANADA); 0918 </INSTITUTION>
<DESCRIPTORS> COMPUTER SCIENCE; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> LUIGI LOGRIPPO </ADVISER>
<CLASSIFICATIONS> NIL </CLASSIFICATIONS>
<ABSTRACT>
Over the past few years, the subject of Intelligent
Network (IN) has captured the interest of the
telecommunications community. The objective of IN is to
allow the introduction of new capabilities in the
telecommunications network and to facilitate and
accelerate in a cost-effective manner, service
implementation and provisioning, in a multivendor
environment. However, this objective confronts a major
obstacle known as the feature interaction problem. The
feature interaction problem occurs when a feature is
prevented from performing its functionalities in the
presence of other features.
In the first part of the thesis, we describe a LOTOS
model for structuring the Functional Entities (FEs) that
are defined in the Distributed Functional Plane (DFP) of
the CS1 IN Conceptual Model (INCM), and that are
involved in the establishment of a call/connection and
invocation and processing of services. The specification
of IN services is achieved using Service Independent
building Blocks (SIBs). It is designed in a way that
independent specification and rapid introduction of
services is provided.
In the second part of the thesis, a method for detecting
feature interactions between services is developed. The
method is limited to the detection of interactions
caused by violation of features properties. It is based
on formalization of feature's properties, derivation of
goals satisfying the negation of these properties and
use of Goal Oriented Execution to detect traces
satisfying these goals. A trace satisfying a goal shows
that an interaction exists between the specified
features by describing a scenario violating one of the
properties of the introduced features.
It is concluded that LOTOS is useful as a Formal
Description Technique (FDT) in the Service Creation
Environment (SCE). The developed specification can be
used for adding specifications of new services, and for
detecting interactions caused by violation of
properties, if there are any.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  3777 </NUMBER>
<ORDER>   AAGMM12144 </ORDER>
<TITLE> A DIMENSIONAL ANALYSIS SYSTEM FOR KNOWLEDGE-AIDED DESIGN IN ELECTROMAGNETICS </TITLE>
<AUTHOR> TREMBLAY, LUC </AUTHOR>
<YEAR> 1996 </YEAR>
<INSTITUTION> MCGILL UNIVERSITY (CANADA); 0781 </INSTITUTION>
<DESCRIPTORS> ENGINEERING, ELECTRONICS AND ELECTRICAL; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> DAVID LOWTAER </ADVISER>
<CLASSIFICATIONS> NIL </CLASSIFICATIONS>
<ABSTRACT>
This thesis considers the dimensional analysis theory in
engineering. A Knowledge-Aided Design Tool is presented
which permits the solution of many aspects of
Dimensional Analysis for electromagnetics. The KAD Tool
was coded in the language Lisp with Allegro Common Lisp
in a Microsoft-Windows environment on a PC with a 486
microprocessor. It represents 10 196 lines of code. The
mathematical functions are supported by the mathematical
libraries of the software MAPLE. A menu with nine
choices corresponding to nine functionalities of
Dimensional Analysis is offered to the user.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  3778 </NUMBER>
<ORDER>   AAGMM12130 </ORDER>
<TITLE> SOUND AND VISION: AUDIOVISUAL ASPECTS OF A VIRTUAL- REALITY PERSONNEL-TRAINING SYSTEM </TITLE>
<AUTHOR> OKAPUU-VON VEH, ALEXANDER FREDERICK </AUTHOR>
<YEAR> 1996 </YEAR>
<INSTITUTION> MCGILL UNIVERSITY (CANADA); 0781 </INSTITUTION>
<DESCRIPTORS> ENGINEERING, ELECTRONICS AND ELECTRICAL; EDUCATION, TECHNOLOGY; EDUCATION, VOCATIONAL; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> ALFRED S. MALOWANY </ADVISER>
<CLASSIFICATIONS> NIL </CLASSIFICATIONS>
<ABSTRACT>
This thesis describes a prototype virtual reality (VR)
training system. E scSOPE-VR, designed and implemented
for Hydro-Quebec by graduate students at McGill
University and Ecole Polytechnique de Montreal. The
project was motivated by the necessity of providing a
realistic training environment for substation operators,
while ensuring their safety and the network's integrity
at all times.
With the simulator, trainees can carry out all the
switching operations necessary for their work in
absolute safety, while staying in a realistic
environment. A speech-recognition system controls the
training session, while audio immersion adds a dimension
of realism to the virtual world. An expert-system
validates the trainee's operations at all times and a
steady-state power-flow simulator recalculates network
parameters. The automatic conversion of single-line
diagrams enables the construction of three-dimensional
models of substation equipment.
The present thesis focuses on the speech command, audio,
video and network aspects of the system. A survey of
current VR applications and an overview of VR technology
are followed by a summary of the E scSOPE-VR project.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  3779 </NUMBER>
<ORDER>   AAGMM12114 </ORDER>
<TITLE> RISK ANALYSIS OF CONTAMINATED SITES: A FUZZY SET APPROACH </TITLE>
<AUTHOR> COTE, KARL </AUTHOR>
<YEAR> 1996 </YEAR>
<INSTITUTION> MCGILL UNIVERSITY (CANADA); 0781 </INSTITUTION>
<DESCRIPTORS> ENGINEERING, CIVIL; ENVIRONMENTAL SCIENCES; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> RAYMOND N. YONG </ADVISER>
<CLASSIFICATIONS> NIL </CLASSIFICATIONS>
<ABSTRACT>
A computer programme has been developed to evaluate
risks that contaminated sites might pose to human
health. Pollutants present in soils and sediments can
potentially migrate from source to receptors, via
different pathways. In the programme, pathways are
represented by transport models.
Humans can be affected by contaminant migration through
land and water use. Health risks can arise from
ingestion of and dermal contact with contaminated water
and soil, as well as through inhalation of contaminated
air. Quantitative estimates of risks are calculated for
both carcinogenic and non-carcinogenic contaminants.
Soil and sediment systems are very heterogeneous and are
characterized by uncertain parameters. Concepts of fuzzy
set theory have been used in the programme to take
uncertainty into account. Uncertain input parameters are
represented by fuzzy numbers. An inference model using
fuzzy logic has been constructed to reason about data in
the decision making process.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  3780 </NUMBER>
<ORDER>   AAGMM12106 </ORDER>
<TITLE> IMPLEMENTING AND EVALUATING A VITAL SIGN MONITORING SYSTEM IN AN ICU </TITLE>
<AUTHOR> ABU-SHIHAB, OSAMA </AUTHOR>
<YEAR> 1996 </YEAR>
<INSTITUTION> MCGILL UNIVERSITY (CANADA); 0781 </INSTITUTION>
<DESCRIPTORS> ENGINEERING, ELECTRONICS AND ELECTRICAL; HEALTH SCIENCES, HOSPITAL MANAGEMENT; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> ALFRED S. MALOWANY </ADVISER>
<CLASSIFICATIONS> NIL </CLASSIFICATIONS>
<ABSTRACT>
The rapid growth of medical sciences and technologies
created the need of increased use of computers to
address the recognized problems associated with
information overload, and to help health care
professionals provide better quality decisions.
This thesis presents the development, implementation,
and evaluation of a real-time expert monitoring system
(EMS) developed for the patient data management system
(PDMS) of a pediatric intensive care unit. The objective
of the EMS is to generate real-time warning signals in
the event of life threatening patient conditions.
The research in this thesis concentrated on the analysis
of the performance of the expert system in the intensive
care environment by monitoring several patients over a
period of days. The results obtained were generally in
agreement with the actual medical interpretations given
by the health care professionals at the MCH. However,
some false positive and false negative results were
observed and these are discussed in the thesis.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  3781 </NUMBER>
<ORDER>   AAG9703450 </ORDER>
<TITLE> SPEECH RECOGNITION BASED ON TIME-DELAY NEURAL NETWORKS </TITLE>
<AUTHOR> WU, DUANPEI </AUTHOR>
<YEAR> 1996 </YEAR>
<INSTITUTION> CLEMSON UNIVERSITY; 0050 </INSTITUTION>
<DESCRIPTORS> ENGINEERING, ELECTRONICS AND ELECTRICAL; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> JOHN N. GOWDY </ADVISER>
<CLASSIFICATIONS> ARTIFICIAL INTELLIGENCE </CLASSIFICATIONS>
<ABSTRACT>
Two novel neural network architectures, Tunable Time-
Delay Neural Networks with Signal-Shifting (TTDNN-SS)
and K-Subspaces Time-Delay Autoassociators (KS-TDAA), as
well as their training algorithms for isolated word and
phoneme recognition, are presented. The first
architecture is proposed to remove the constraint
imposed on TDNNs that input patterns must have a fixed
number of frames. Hence, it facilitates the application
of TDNNs to isolated-word speech recognition. The TTDNN-
SS architecture consists of a group of sub-nets, named
as TDNN-SS. Each TDNN-SS is constructed with the basic
architecture of TDNNs with signals shifting into the
architecture and assigned to one and only one recognized
unit, such as an isolated-word and phoneme. TTDNN-SS has
successfuly been applied to isolated-word and phoneme
recognition tasks with excellent recognition accuracies.
For isolated-word recognition using the TI 20-word
database, it yielded a recognition accuracy of 100% for
all single-speaker data sets, 99.5% for a double-speaker
data set and 98.83% for a six-speaker data set. For
phoneme recognition, it obtained a recognition accuracy
of 90.26% for a three voiced-stop-consonants (/b/, /d/
and /g/), speaker-independent phoneme recognition task.
The second proposed architecture, KS-TDAA, combines the
time-delay design in TDNNs for phoneme recognition and
the technique of Multi-Layer Perceptron (MLP)
autoassociators. The KS-TDAA is designed to extend the
approach of using autoassociators to perform phoneme
recognition proposed by Nakamura et al. by incorporating
time-delay units to input and hidden layers and using K
such autoassociators to characterize the multi-model
data. To train the KS-TDAA, a new training algorithm is
also proposed. This non-discrimination training
algorithm provides a method to avoid the drawback
encountered in most neural networks of output values of
networks not representing the candidate likelihoods.
Simulations have shown that the KS-TDAA has
significantly improved the recognition performance of
Nakamura et al. approach. In the same time, it retains
the same advantages such as network output values
representing candidate likelihoods. Simulations have
also shown that the performance of KS-TDAAs is very
close to that obtained from successful neural network
structures for phoneme recognition such as TDNNs and ST-
LVQ.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  3782 </NUMBER>
<ORDER>   AAG9703417 </ORDER>
<TITLE> FINDING MOST PROBABLE EXPLANATIONS UNDER CONDITIONS OF UNCERTAINTY USING BAYESIAN BELIEF NETWORKS </TITLE>
<AUTHOR> ABDELBAR, ASHRAF MOHAMED </AUTHOR>
<YEAR> 1996 </YEAR>
<INSTITUTION> CLEMSON UNIVERSITY; 0050 </INSTITUTION>
<DESCRIPTORS> COMPUTER SCIENCE; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> SANDRA M. HEDETNIEMI </ADVISER>
<CLASSIFICATIONS> ARTIFICIAL INTELLIGENCE </CLASSIFICATIONS>
<ABSTRACT>
We investigate several issues with regard to the Most
Probable Explanation (MPE) problem, which is also known
as the maximum a posteriori (MAP) assignment problem.
The MPE problem has only been proven to be NP-hard in
1994 (92). That proof leaves open the possibility of
finding a polynomial-time constant ratio-bounded
algorithm for this problem. Unfortunately, we prove that
such an algorithm cannot exist with any constant ratio
bound unless P = NP. We also show that this holds for
some polynomial ratio bounds. In addition, we
investigate the complexity of randomized approximation.
We prove that a polynomial-time algorithm which
guarantees any fixed probability of finding the optimal
solution cannot exist unless RP = NP.
We prove that the problem of finding a second-best
solution given the optimal solution is NP-hard. Even
approximating the second-best solution given the optimal
solution is NP-hard. We also investigate dynamically
changing evidence sets. We find that finding, or
approximating, the most probable assignment for one
evidence set given the optimal assignment for a related
evidence set is NP-hard even if the two evidence sets
are only marginally dissimilar.
Further, we investigate the relationship between the MPE
problem and the Cost Based Abduction problem (CBA). In
CBA, we are given a set of rules with associated
numerical costs and a goal to be proved, and the
objective is to find the lowest cost proof for the given
goal. It has been suggested by Santos (84) that the MPE
problem can be modelled by the CBA problem. We prove
this relationship by presenting a general method for
using any heuristic algorithm for cost based abduction
to find high probability assignments for belief
networks.
We develop a general method, called the UFO method, for
hybridizing genetic algorithms and simulated annealing
on a multiprocessor system. Our method is a variation of
an algorithm called SAGA; however our method requires
less synchronization between processors and is thus more
suitable for loosely coupled processors. We implemented
the UFO method on a network of SUN work-stations running
PVM. We ran experiments with the number of parallel
processors varying from 1 to 17. We found that the
speedup obtained was greater than the number of
processors suggesting that our hybridization of genetic
algorithms and simulated annealing is algorithmically
superior to either of the two by itself.
Finally, we investigate the application of recurrent
neural networks, which have been successfully applied to
many optimization problems, to the MPE problem. The most
popular neural network for optimization applications is
the Hopfield network which is a recurrent network of
quadratic order. The objective function being optimized
in the MPE problem is generally of high order; the order
is equal to the maximum in-degree in the network's
underlying directed acyclic graph. We applied a cubic
order generalization of the Hopfield network, called
QNET, to the MPE problem for belief networks with a
maximum in-degree of 2. Although unlike the Hopfield
network, the stability and convergence of QNET are not
theoretically guaranteed, in our experiments the optimal
solution was found 87% of the time. (Abstract shortened
by UMI.)
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  3783 </NUMBER>
<ORDER>   AAG9703041 </ORDER>
<TITLE> A BAYESIAN DECISION-THEORETIC FRAMEWORK FOR REAL-TIME MONITORING AND DIAGNOSIS OF COMPLEX SYSTEMS: THEORY AND APPLICATION </TITLE>
<AUTHOR> ALAG, SATNAM S. S. </AUTHOR>
<YEAR> 1996 </YEAR>
<INSTITUTION> UNIVERSITY OF CALIFORNIA, BERKELEY; 0028 </INSTITUTION>
<DESCRIPTORS> ENGINEERING, MECHANICAL; COMPUTER SCIENCE; ENGINEERING, INDUSTRIAL </DESCRIPTORS>
<ADVISER> ALICE M. AGOGINO </ADVISER>
<CLASSIFICATIONS> NIL </CLASSIFICATIONS>
<ABSTRACT>
This work presents a theoretical framework for real time
monitoring and diagnosis of complex systems. This
framework addresses issues associated with supervisory
control of complex systems: sensor validation, multi-
sensor data fusion, and fault detection. This work
subsequently applies and demonstrates the resulting
algorithms and methods in the context of extant
practical systems, namely gas turbine power plants and
automated vehicles in an intelligent vehicle highway
system (IVHS).
This work develops a single unified framework, which is
the synthesis of techniques used in artificial
intelligence and in 'modern control theory', with
probability theory as the common thread between them. By
combining these two approaches into a broad and
integrated framework, we provide a new perspective, that
not only draws from, but also builds on previous work.
We use networks and graphs to represent the various
states of the system, the relationships between them,
and the uncertainty associated with them. We derive
rigorous calculi for inference in these graphical
structures. We illustrate how many previously developed
algorithms, such as the Kalman filter, interacting
multiple model, as well as new algorithms can be derived
by using this graphical representation and the rules for
inference developed here.
In order to build our framework, we extend Gaussian
probabilistic networks to the case where a node could be
used to represent multiple variables, thus creating
vector Gaussian probabilistic networks. We derive
rigorous rules for inference in these vector
probabilistic networks. These rules have been developed
using, two different approaches, first the method of
message propagation and second, the method of topology
transformation. These two approaches lead to the
development of algorithms, that can be implemented
either in a centralized or a decentralized architecture.
We model the process of on-line learning of temporal
transition probabilities in these networks as an
optimization problem and derive a recursive method for
it. We also illustrate how additional uncertainty in the
system can be modeled by the addition of discrete nodes.
Using our framework, we have built on previous work to
develop a better algorithm for sensor fusion. This
algorithm can learn the relative performance of the
various sensors over time and leads to better fused
estimates in the presence of clutter and non-Gaussian
noise. We have extensively investigated the performance
of various Bayesian algorithms for a number of
conditions through Monte Carlo simulations.
Using these concepts, we develop a comprehensive
methodology for sensor validation, fusion, and sensor
fault detection for complex systems. The methodology
consists of four steps. (1) Redundancy Creation
generates multiple values. (2) State Prediction uses
temporal information. (3) Sensor Data Validation and
Fusion determines integrity of the information, and
combines various estimates. (4) Fault detection
evaluates the performance of the sensors. We illustrate
this methodology by applying it to data obtained from a
gas turbine power plant.
Using our unified framework we also develop a
probabilistic methodology for sensor validation and
fusion to be used in automated vehicles in an IVHS. We
investigate the efficacy of the various algorithms
developed in this dissertation by simulating platooning
operations and by applying it to real data. Our
methodology leads to improved ride quality, better
tracking, and increases the safety of the IVHS system.
The concepts and the unified framework developed here
are generally applicable to most dynamic sensor-based
systems, that have uncertainty associated with them. In
this dissertation, we provide the reader with a new
perspective in addressing issues related with: sensor
validation, multi-sensor data fusion, and fault
detection.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  3784 </NUMBER>
<ORDER>   AAG9702582 </ORDER>
<TITLE> MACHINE VISION SENSING OF AJUGA PLANT CELL SUSPENSION CULTURES  </TITLE>
<AUTHOR> LI, ZHIWEI </AUTHOR>
<YEAR> 1996 </YEAR>
<INSTITUTION> UNIVERSITY OF ILLINOIS AT URBANA-CHAMPAIGN; 0090 </INSTITUTION>
<DESCRIPTORS> ENGINEERING, AGRICULTURAL; BIOLOGY, CELL; ENGINEERING, ELECTRONICS AND ELECTRICAL; ENGINEERING, BIOMEDICAL; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> JOHN F. REID </ADVISER>
<CLASSIFICATIONS> ANTHOCYANIN, COLOR </CLASSIFICATIONS>
<ABSTRACT>
A computer controlled machine vision sensing system for
in vitro production of plant pigments was designed and
implemented. The system consisted of a machine vision
microscopic sensing subsystem and a computer controlled
automatic sampling/delivery subsystem.
The machine vision microscopic sensing system included a
central control computer, color CCD camera, microscope,
and a machine vision system. The central control
computer synchronized with the other subsystem, sending
commands to the sampling control computer to start the
sampling process. It also performed the functions of
acquiring color images and analyzing images. The
sampling system performed the functions of diluting
samples, delivering samples and sampling loop and flow-
cell cleaning. The communication between the central
control computer and the sampling control computer was
through serial ports on both computers.
Microscopic color images from suspension cultures of
anthocyanin-producing Ajuga cells were analyzed with
machine vision to estimate cell culture mass and pigment
productivity. For suspension culture analysis, the
detailed RGB (red-green-blue) information extracted in
each of the color microscopic images did not allow
separation of pigmented cells and cell aggregates from
non-pigmented entities and background in the medium,
however, conversion of RGB data to the HSI (hue-
saturation-intensity) coordinate system permitted clear
separation of object classes based on a combination of
dimensional and photometric information. Further
segmentation using saturation and intensity
characteristics of the HSI values allowed categorization
of low, medium, and highly-pigmented cells and
aggregates in the mixed suspension culture, and both
machine vision on-line and off-line data were able to
track both biomass accumulation and anthocyanin pigment
formation over time as verified by conventional (mass
and spectrophotometric) analysis of the same culture.
The degree of Ajuga cell aggregation was shown to
correlate with cell anthocyanin formation. With machine
vision, a mathematical methodology was proposed to
evaluate the degree of cell aggregation for Ajuga plant
cells. Machine vision estimation and manual estimation
of aggregates was compared.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  3785 </NUMBER>
<ORDER>   AAG9702544 </ORDER>
<TITLE> AUTOMATED DESIGN OF KNOWLEDGE-LEAN HEURISTICS: LEARNING, RESOURCE SCHEDULING, AND GENERALIZATION </TITLE>
<AUTHOR> IEUMWANANONTHACHAI, ARTHUR </AUTHOR>
<YEAR> 1996 </YEAR>
<INSTITUTION> UNIVERSITY OF ILLINOIS AT URBANA-CHAMPAIGN; 0090 </INSTITUTION>
<DESCRIPTORS> COMPUTER SCIENCE; ENGINEERING, ELECTRONICS AND ELECTRICAL; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> BENJAMIN W. WAH </ADVISER>
<CLASSIFICATIONS> MACHINE LEARNING, ARTIFICIAL INTELLIGENCE </CLASSIFICATIONS>
<ABSTRACT>
In this thesis we present new methods for the automated
design of new heuristics in knowledge-lean applications
and for finding heuristics that can be generalized to
unlearned test cases. These applications lack domain
knowledge for credit assignment; hence, operators for
composing new heuristics are generally model free,
domain independent, and syntactic in nature. The
operators we have used are genetics based; examples of
which include mutation and crossover. Learning is based
on a generate-and-test paradigm that maintains a pool of
competing heuristics, tests them to a limited extent,
creates new ones from those that perform well in the
past, and prunes poor ones from the pool. We have
studied four important issues in learning better
heuristics: (a) partitioning of a problem domain into
smaller subsets, called subdomains, so that performance
values within each subdomain can be evaluated
statistically, (b) anomalies in performance evaluation
within a subdomain, (c) rational scheduling of limited
computational resources in testing candidate heuristics
in single-objective as well as multi-objective learning,
and (d) finding heuristics that can be generalized to
unlearned sub domains.
We show experimental results in learning better
heuristics for (a) process placement for distributed-
memory multicomputers, (b) node decomposition in a
branch-and-bound search, (c) generation of test patterns
in VLSI circuit testing, (d) VLSI cell placement and
routing, and (e) blind equalization.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  3786 </NUMBER>
<ORDER>   AAG9702072 </ORDER>
<TITLE> INTELLIGENT TEXT PROCESSING </TITLE>
<AUTHOR> ZHAO, YI </AUTHOR>
<YEAR> 1996 </YEAR>
<INSTITUTION> THE UNIVERSITY OF TEXAS AT DALLAS; 0382 </INSTITUTION>
<DESCRIPTORS> COMPUTER SCIENCE; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> KLAUS TRUEMPER </ADVISER>
<CLASSIFICATIONS> NATURAL LANGUAGE, SPELL CHECKING </CLASSIFICATIONS>
<ABSTRACT>
Spell checking and syntax checking are two major tasks
of text processing. Research on computer techniques for
spell and syntax checking has been in progress since the
1960s, but the techniques developed so far still leave
room for improvements. This dissertation presents new
techniques of processing English text intelligently that
are different from the commonly used approaches for text
processing.
We consider the user's spelling and typing behavior when
detecting and correcting errors. This new approach
improves performance by intelligently adapting spell
checking to an individual user. Instead of parsing a
sentence, we carry out the syntax checking task with new
strategies and algorithms. Learning and reasoning are
two key features of the methods we propose. Learning
during spell and syntax checking involves on-line
learning of the user's spelling, typing, and writing
behavior. Reasoning techniques are employed to diagnose
errors, suggest candidate words, and analyze sentences.
Based on the text processing techniques discussed in the
dissertation, we have designed and implemented a new
system for processing English text intelligently, called
the Laempel System. The system is coded in C under the
Unix environment. The reasoning of the system is
formulated and carried out in propositional logic, using
the Leibniz System for logic programming. The Laempel
System has been released. It is being used by several
universities and research institutes. The system is also
being used as a building block in other research
projects.
This research was supported in part by the Office of
Naval Research under Grant N00014-93-1-0096.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  3787 </NUMBER>
<ORDER>   AAGMM15715 </ORDER>
<TITLE> A GIS-BASED FUZZY LOGIC METHOD FOR MINERAL POTENTIAL MAPPING: AN EXPERIMENT WITH A GEOLOGICAL MAP OF THE PARRY ISLANDS, NORTHWEST TERRITORIES, CANADA </TITLE>
<AUTHOR> EDDY, BRIAN G. </AUTHOR>
<YEAR> 1996 </YEAR>
<INSTITUTION> UNIVERSITY OF OTTAWA (CANADA); 0918 </INSTITUTION>
<DESCRIPTORS> PHYSICAL GEOGRAPHY; GEOLOGY; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> GRAEME BONHAM-CARTER </ADVISER>
<CLASSIFICATIONS> NIL </CLASSIFICATIONS>
<ABSTRACT>
The application of fuzzy logic in a GIS framework is a
valuable method to assist in mineral resource
assessments (MRA) in areas where data are sparse. This
study uses a digital geological map, backed by a digital
geological data model, derived from published legends
and reports. Together they function as a 'spatial-
attribute relational data model' that provides evidence,
in the form of derivative maps, to support mineral
potential according to deposit model criteria. A
knowledge-base is created with fuzzy membership
functions linked to the classes of each derivative map
that indicate favourability between geological features
present in the database with those required by model
criteria. A fuzzy-logic-based 'inference net', as
implemented in the GIS modelling language, is used to
combine spatial evidence to determine mineral resource
potential for three mineral deposit sub-types: (1) MVT
Pb-Zn, (2) Sedimentary Cu and (3) Sediment-Hosted
Sulphides. This method is shown to be valuable for
providing an 'audit trial' for the complex decision-
making process associated with resource assessment; it
provides a means for experimenting and testing various
hypotheses and viewpoints associated with mineral
deposit models, and mimics some aspect of how geologists
determine mineral potential for a region using
information provided in geological maps and mineral
deposit model literature.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  3788 </NUMBER>
<ORDER>   AAG9701864 </ORDER>
<TITLE> INTEGRATION OF AIR AND GROUND-BASED METHANE MEASUREMENTS WITH THOSE OF THE NASA EARTH OBSERVING SYSTEM </TITLE>
<AUTHOR> ASHCROFT, PETER DELL </AUTHOR>
<YEAR> 1996 </YEAR>
<INSTITUTION> CARNEGIE-MELLON UNIVERSITY; 0041 </INSTITUTION>
<DESCRIPTORS> PHYSICS, ATMOSPHERIC SCIENCE; ENGINEERING, AEROSPACE; BIOGEOCHEMISTRY; ARTIFICIAL INTELLIGENCE; ENVIRONMENTAL SCIENCES; REMOTE SENSING </DESCRIPTORS>
<ADVISER> NIL </ADVISER>
<CLASSIFICATIONS> REMOTE SENSING, GLOBAL CHANGE </CLASSIFICATIONS>
<ABSTRACT>
This analysis addressed a number of remote sensing
policy issues in the context of the NASA Earth Observing
System, (EOS). Repeated redesign of EOS in response to
budgetary restrictions has highlighted the need for
comprehensive analysis of the interdependencies of space-
based instruments and their integration with air and
ground-based measurements, as well as a methodology for
accommodating further budget restrictions. In the
context of the case study chosen for this analysis,
characterization of methane sources, three sets of
questions were addressed. The first set of questions
pertained to the importance of simultaneity in space-
based observations. The second set of questions
pertained to orbital selection for space-based
observation of methane relative to the current EOS
configuration. The final set pertained to the spatial
resolution appropriate for observation of methane
sources, the relative capabilities of different
measurement methods, and comparative costs.
FASCODE radiative transfer code was used to simulate
MOPITT signals under a number of scenarios of methane
enhancement, temperature, and relative humidity
profiles. Uncertainty on the Maximum Likelihood
Estimator (MLE) of the methane mixing ratio was used as
a measure of system performance subject to assumptions
of surface albedo and calculated photon counting noise.
Separation of MOPITT and AIRS+, and the resulting
degradation of knowledge of the temperature and humidity
profile was found to increase the minimum detectable
methane mixing ratio enhancement by a factor of four.
The second portion of the analysis pertained to orbital
choice and the suitability of the EOS sun-synchronous
orbit for methane source observation relative to a
diurnal sampling alternative. This portion used current
estimates of the global methane source distribution and
global mean cloud cover observations to evaluate orbital
choices with regard to latitudinal coverage and revisit
time. The analysis concluded that the EOS AM-1 orbit
will provide approximately 25% less methane coverage
than would be provided by a lower inclination orbit.
The third portion of the analysis examined the spatial
resolution and accuracy of various measurement
approaches, evaluating them with respect to anticipated
sources. This analysis concluded that few source areas
will be of sufficient strength to be observable from
space. Sources averaging 100 mg m$sp0-2$ d$sp0-1$ will
need to be larger than 10 km in order to be observable
by TES, and an order of magnitude larger in linear
dimension to be observable by MOPITT. The complementary
nature of sensitive small-scale, and less sensitive
large-scale measurements was qualitatively demonstrated
for plausible source characteristics. Implications of a
lognormal small scale source distribution were explored
drawing from existing measurements such as those of the
ABLE program. A cost comparison based on the spatial
variability of methane sources observed by existing
programs demonstrated that the cost of a space-based
remote sensing instrument is much greater than the cost
of airplane-based micrometeorological measurements
yielding comparable uncertainty on mean flux.
The questions discussed here in the context of methane
characterization recur for other remote sensing
objectives throughout EOS. Examinations of the evolving
capabilities of EOS like this case study provide a
starting point for subsequent investigation of the
decision making process that has guided the program, the
evolving mission of the program, and the implicit
attitudes of the decision-makers toward risk.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  3789 </NUMBER>
<ORDER>   AAG9701862 </ORDER>
<TITLE> AN AUTONOMOUS VISION-GUIDED HELICOPTER </TITLE>
<AUTHOR> AMIDI, OMEAD </AUTHOR>
<YEAR> 1996 </YEAR>
<INSTITUTION> CARNEGIE-MELLON UNIVERSITY; 0041 </INSTITUTION>
<DESCRIPTORS> ENGINEERING, ELECTRONICS AND ELECTRICAL; ENGINEERING, SYSTEM SCIENCE; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> NIL </ADVISER>
<CLASSIFICATIONS> MACHINE VISION, ARTIFICIAL INTELLIGENCE </CLASSIFICATIONS>
<ABSTRACT>
Helicopters are indispensable air vehicles for many
applications ranging from rescue and crime fighting to
inspection and surveillance. They are most effective
when flown at close proximity to objects of interest
while performing tasks such as delivering critical
supplies, rescuing stranded individuals, or inspecting
damaged buildings. These tasks require dangerous flight
patterns which risk human pilot safety. An unmanned
helicopter which operates autonomously can carry out
such tasks more effectively without risking human lives.
The work presented in this dissertation develops an
autonomous helicopter system for such applications. The
system employs on-board vision for stability and
guidance relative to objects of interest in the
environment.
Developing a vision-based helicopter positioning and
control system is challenging for several reasons.
First, helicopters are inherently unstable and capable
of exhibiting high acceleration rates. They are highly
sensitive to control inputs and require high frequency
feedback with minimum delay for stability. For stable
hovering, for example, vision-based feedback rates must
be at least 30-60 Hz with no more than 1/30 second
latency. Second, since helicopters rotate at high
angular rates to direct main rotor thrust for
translational motion, it is difficult to disambiguate
rotation from translation with vision alone to estimate
helicopter 3D motion. Third, helicopters have limited on-
board power and payload capacity. Vision and control
systems must be compact, efficient, and light weight for
effective on-board integration. Finally, helicopters are
extremely dangerous and present major obstacles to safe
and calibrated experimentation to design and evaluate on-
board systems.
This dissertation addresses these issues by developing:
a "visual odometer" for helicopter position estimation,
a real-time and low latency vision machine architecture
to implement an on-board visual odometer machine, and an
array of innovative indoor testbeds for calibrated
experimentation to design, build and demonstrate an
airworthy vision-guided autonomous helicopter. The
odometer visually locks on to ground objects viewed by a
pair of on-board cameras. Using high-speed image
template matching, it estimates helicopter motion by
sensing object displacements in consecutive images. The
visual odometer is implemented with a custom-designed
real-time and low latency vision machine which modularly
integrates field rate (60 Hz) template matching
processors, synchronized attitude sensing and image
tagging circuitry, and image acquisition, convolution,
and display hardware. The visual odometer machine along
with a carrier-phase differential Global Positioning
System receiver, a classical PD control system, and
human augmentation and safety systems are integrated on-
board a mid-sized helicopter, the Yamaha R50, for vision-
guided autonomous flight.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  3790 </NUMBER>
<ORDER>   AAG9701814 </ORDER>
<TITLE> SOLVING ELECTROMAGNETIC INVERSE PROBLEMS BY ARTIFICIAL INTELLIGENCE METHODS </TITLE>
<AUTHOR> XU, MINGHUI </AUTHOR>
<YEAR> 1996 </YEAR>
<INSTITUTION> THE UNIVERSITY OF AKRON; 0003 </INSTITUTION>
<DESCRIPTORS> ENGINEERING, ELECTRONICS AND ELECTRICAL; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> NIL </ADVISER>
<CLASSIFICATIONS> NIL </CLASSIFICATIONS>
<ABSTRACT>
Electromagnetic inverse problems are very interesting
and useful for industries, but hard to solve and analyze
so far since they are highly nonlinear and there are no
conventional methods to follow. Based on this reason,
new techniques are needed to explore. In this
dissertation, some methods in artificial intelligence
are introduced to solve this kind of problems.
First, the fundamental theories of the artificial neural
networks, genetic algorithms and evolutionary
programming are presented, and their properties are
analyzed. Then two examples of the inverse problems are
given to solve by applying these methods and compare the
corresponding results with the existing analytical
solutions.
The results shows that the neural networks method can be
used for the electromagnetic inverse problems, but with
some limitations because of its divergence when the
initial random numbers are not appropriate and the
required accuracy is high. But the novel evolutionary
programming technique is fully successful for both of
the examples. It is never divergent under any conditions
and always gives better accuracy, which means the
evolutionary programming approach is stable.
Finally, this research work is summarized: This is the
first time to attempt to solve electromagnetic inverse
problems by introducing evolutionary technique, and this
method has many advantages over the neural networks one.
This work provides us new ideas and approaches when the
classical methods for inverse problems are not exist or
applicable. The evolutionary programming method is
recommended based on the examples because of its
stability.
The computer code for solving the examples with both
artificial neural networks and evolutionary programming
methods are attached in the appendix. This is also an
indispensable content of the entire research.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  3791 </NUMBER>
<ORDER>   AAG9701155 </ORDER>
<TITLE> DATA-DRIVEN IDENTIFICATION OF KEY VARIABLES: A FUZZY SET APPROACH  </TITLE>
<AUTHOR> YUAN, BO </AUTHOR>
<YEAR> 1996 </YEAR>
<INSTITUTION> STATE UNIVERSITY OF NEW YORK AT BINGHAMTON; 0792 </INSTITUTION>
<DESCRIPTORS> ENGINEERING, SYSTEM SCIENCE; STATISTICS; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> NIL </ADVISER>
<CLASSIFICATIONS> SURFACE MOUNT MANUFACTURING, MAHALANOBIS METRICS </CLASSIFICATIONS>
<ABSTRACT>
In this dissertation, we investigate a problem raised
from a real-world application, surface mount
manufacturing. The problem can be abstracted as a
general problem: to identify key variables that
contribute to a partition of a given data set. We have
developed two algorithms that can be applied to dealing
with this problem. Both algorithms are based on fuzzy
sets, fuzzy measures, fuzzy integrals, and evolutionary
strategies.
The first algorithm is based on the idea that by
employing different Mahalanobis metrics, one can weight
variables differently. It is called an evolutionary
fuzzy c-means algorithm. The algorithm involves a search
for an optimal Mahalanobis metric under which the fuzzy
c-means algorithm derives a fuzzy partition that is as
close as possible to a given partition.
The second algorithm is based on the idea that each data
point can be considered as an evaluation function of an
object with respect to several features. Fuzzy measures
are used to weight different features, and fuzzy
integrals are used to define partitions of data points.
An evolutionary strategy is again used to identify the
optimal fuzzy measure under which values of fuzzy
integral of data points define a partition which is as
close as possible to a given partition. Both algorithms
are tested on the benchmark data, the Iris data set.
A by-product of our investigation is a method for
constructing fuzzy measures from a given data set by
solving fuzzy relation equations. Moreover, we have also
developed a theoretically justified method for
approximate solutions of fuzzy relation equations.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  3792 </NUMBER>
<ORDER>   AAG9701052 </ORDER>
<TITLE> ORDERED LOGIC AND PRIORITIZATION IN NONMONOTONIC REASONING </TITLE>
<AUTHOR> GEERTS, PATRICIA </AUTHOR>
<YEAR> 1996 </YEAR>
<INSTITUTION> UNIVERSITAIRE INSTELLING ANTWERPEN (BELGIUM); 0314 </INSTITUTION>
<DESCRIPTORS> COMPUTER SCIENCE; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> D. VERMEIR </ADVISER>
<CLASSIFICATIONS> NIL </CLASSIFICATIONS>
<ABSTRACT>
With the development of the first nonmonotonic reasoning
formalisms in the early eighties, a new and interesting
domain of research was initiated. Investigating their
ability to formalize commonsense reasoning, these
pioneers in nonmonotonic reasoning turned out to suffer
from the same problem: sometimes extensions or possible
worlds are derived which do not correspond to human
intuition. The reason for this is that the early
formalisms are unable to prioritize knowledge in a
straightforward way. Nowadays, the concept of
prioritization has been generally accepted as a tool to
eliminate unintuitive extensions. Literature shows us
two major tendencies following this idea: some
formalisms use an implicit kind of prioritization based
on specificity, while others provide an explicit
prioritization tool. Both approaches have their pros and
cons, which motivates us to investigate a smooth
integration of both kinds of prioritization. One way to
tackle this challenge is to use the specificity
principle for transforming a "flat" knowledge base into
an "ordered" one, by making the implicit specificity
information explicit. The suppliance of additional
priorities can then be left to the user. Another
approach is to allow for the combination of implicit and
explicit priorities from the very beginning, making it
necessary to define a new nonmonotonic formalism. Both
approaches are dealt with in this thesis.
Next to pursuing the combination of implicit and
explicit priorities, this thesis aims at providing a
catalogue of the major formalisms using prioritization.
These formalisms are compared with respect to the basic
design options they obey, and relationships and
differences between them are shown. One of these
formalisms, called ordered logic, is dealt with in
detail. Ordered logic is a nonmonotonic reasoning
formalism we developed and which can be classified in
the family of formalisms based on explicit priorities.
Next to formalizing commonsense reasoning, ordered logic
also allows to formalize multi-expert reasoning, due to
the broader interpretation given to explicit priorities.
This broader interpretation, differentiating ordered
logic from other formalisms based on explicit
priorities, makes it possible to model the knowledge of
multiple experts or internal perspectives and to resolve
conflicts between competing perspectives without
obscuring their opinions.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  3793 </NUMBER>
<ORDER>   AAG9700654 </ORDER>
<TITLE> A KNOWLEDGE-BASED APPROACH FOR MONITORING AND SITUATION ASSESSMENT AT NUCLEAR POWER PLANTS </TITLE>
<AUTHOR> HEABERLIN, JOAN OYLEAR </AUTHOR>
<YEAR> 1996 </YEAR>
<INSTITUTION> OREGON STATE UNIVERSITY; 0172 </INSTITUTION>
<DESCRIPTORS> ENGINEERING, NUCLEAR </DESCRIPTORS>
<ADVISER> NIL </ADVISER>
<CLASSIFICATIONS> NIL </CLASSIFICATIONS>
<ABSTRACT>
An approach for developing a computer-based aid to
assist in monitoring and assessing nuclear power plant
status during situations requiring emergency response
has been developed. It is based on the representation of
regulatory requirements and plant-specific systems and
instrumentation in the form of hierarchical rules.
Making use of inferencing techniques from the field of
artificial intelligence, the rules are combined with
dynamic state data to determine appropriate emergency
response actions.
In a joint project with Portland General Electric
Company, a prototype system, called EM-CLASS, has been
created to demonstrate the knowledge-based approach for
use at the Trojan Nuclear Power Plant. The knowledge
domain selected for implementation addresses the
emergency classification process that is used to
communicate the severity of the emergency and the extent
of response actions required. EM-CLASS was developed
using Personal Consultant Plus (PCPlus), a knowledge-
based system development shell from Texas Instruments
which runs on IBM-PC compatible computers. The knowledge
base in EM-CLASS contains over 200 rules.
The regulatory basis, as defined in 10 CFR 50, calls for
categorization of emergencies into four emergency action
level classes: (1) notification of unusual event, (2)
alert, (3) site area emergency, and (4) general
emergency. Each class is broadly defined by expected
frequency and the potential for release of radioactive
materials to the environment. In a functional sense,
however, each class must be ultimately defined by a
complex combination of in-plant conditions, plant
instrumentation and sensors, and radiation monitoring
information from stations located both on- and off-site.
The complexity of this classification process and the
importance of accurate and timely classification in
emergency response make this particular application
amenable to an automated, knowledge-based approach.
EM-CLASS has been tested with a simulation of a 1988
Trojan Nuclear Power Plant emergency exercise and was
found to produce accurate classification of the
emergency using manual entry of the data into the
program.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  3794 </NUMBER>
<ORDER>   AAG0577746 </ORDER>
<TITLE> LEARNING FROM IMPERFECT DATA IN THEORY AND PRACTICE </TITLE>
<AUTHOR> SLONIM, DONNA KAREN </AUTHOR>
<YEAR> 1996 </YEAR>
<INSTITUTION> MASSACHUSETTS INSTITUTE OF TECHNOLOGY; 0753 </INSTITUTION>
<DESCRIPTORS> COMPUTER SCIENCE; BIOLOGY, GENETICS; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> RONALD L. RIVEST </ADVISER>
<CLASSIFICATIONS> NOISE, ERROR </CLASSIFICATIONS>
<ABSTRACT>
This thesis explores several problems of learning with
noisy or incomplete data. Most machine learning
applications need to infer correct conclusions from
available information, although some data may be
incorrect and other important data may be missing. In
this thesis, we describe algorithms for handling
imperfect data in several projects that range from the
theoretical to the practical.
In Chapter 2 we present new formal models of learning
with a teacher who makes mistakes or fails to answer
some questions, and we show that learning can succeed in
these models. We first consider learning with a
"randomly fallible teacher" who is unable to answer a
random subset of the learner's questions, and we present
a probabilistic algorithm for learning monotone DNF
formulas in this model. We then introduce a learning
model in which queries on "borderline" examples may
receive incorrect answers. We describe efficient
algorithms for learning intersections of halfspaces and
subclasses of DNF formulas in this new model.
Our results in Chapter 3 show how teams of learners can
work together to learn graphs in the absence of key
information that distinguishes nodes. On a graph with
indistinguishable nodes, a robot cannot tell if it is
placed on a node that it has previously seen. We
describe a probabilistic polynomial-time algorithm for
two cooperating robots to learn any strongly-connected
directed graph, even graphs that would most likely
require exponential time to explore by walking randomly.
We also present a random-walk algorithm that is faster
for a special class of graphs.
In Chapter 4 we examine the application of machine
learning techniques and algorithm design to a real
problem in molecular biology: building large-scale human
gene maps using the new technique of radiation hybrid
mapping. We represent uncertainty about noise in the
data with a hidden Markov model. We introduce new search
methods for finding good maps, and we use these methods
to build the first radiation hybrid map of the entire
human genome.
Our work demonstrates that an approach combining
theoretical models and practical search heuristics can
yield excellent results in a real application of
learning from imperfect data. (Copies available
exclusively from MIT Libraries, Rm. 14-0551, Cambridge,
MA 02139-4307. Ph. 617-253-5668; Fax 617-253-1690.)
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  3795 </NUMBER>
<ORDER>   AAG0577731 </ORDER>
<TITLE> PREDICTION-DRIVEN COMPUTATIONAL AUDITORY SCENE ANALYSIS </TITLE>
<AUTHOR> ELLIS, DANIEL P. W. </AUTHOR>
<YEAR> 1996 </YEAR>
<INSTITUTION> MASSACHUSETTS INSTITUTE OF TECHNOLOGY; 0753 </INSTITUTION>
<DESCRIPTORS> ENGINEERING, ELECTRONICS AND ELECTRICAL; COMPUTER SCIENCE; PSYCHOLOGY, EXPERIMENTAL; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> BARRY L. VERCOE </ADVISER>
<CLASSIFICATIONS> MACHINE HEARING, ARTIFICIAL INTELLIGENCE </CLASSIFICATIONS>
<ABSTRACT>
The sound of a busy environment, such as a city street,
gives rise to a perception of numerous distinct events
in a human listener--the 'auditory scene analysis' of
the acoustic information. Recent advances in the
understanding of this process from experimental
psychoacoustics have led to several efforts to build a
computer model capable of the same function. This work
is known as 'computational auditory scene analysis'.
The dominant approach to this problem has been as a
sequence of modules, the output of one forming the input
to the next. Sound is converted to its spectrum, cues
are picked out, and representations of the cues are
grouped into an abstract description of the initial
input. This 'data-driven' approach has some specific
weaknesses in comparison to the auditory system: it will
interpret a given sound in the same way regardless of
its context, and it cannot 'infer' the presence of a
sound for which direct evidence is hidden by other
components.
The 'prediction-driven' approach is presented as an
alternative, in which analysis is a process of
reconciliation between the observed acoustic features
and the predictions of an internal model of the sound-
producing entities in the environment. In this way,
predicted sound events will form part of the scene
interpretation as long as they are consistent with the
input sound, regardless of whether direct evidence is
found. A blackboard-based implementation of this
approach is described which analyzes dense, ambient
sound examples into a vocabulary of noise clouds,
transient clicks, and a correlogram-based representation
of wide-band periodic energy called the weft.
The system is assessed through experiments that firstly
investigate subjects' perception of distinct events in
ambient sound examples, and secondly collect quality
judgments for sound events resynthesized by the system.
Although rated as far from perfect, there was good
agreement between the events detected by the model and
by the listeners. In addition, the experimental
procedure does not depend on special aspects of the
algorithm (other than the generation of resyntheses),
and is applicable to the assessment and comparison of
other models of human auditory organization. (Copies
available exclusively from MIT Libraries, Rm. 14-0551,
Cambridge, MA 02139-4307. Ph. 617-253-5668; Fax 617-253-
1690.)
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  3796 </NUMBER>
<ORDER>   AAG0577529 </ORDER>
<TITLE> PROGRESSIVE LEARNING OF ENDPOINT FEEDBACK SYSTEMS WITH MODEL UNCERTAINTY AND SENSOR NOISE </TITLE>
<AUTHOR> LI, SHIH-HUNG </AUTHOR>
<YEAR> 1996 </YEAR>
<INSTITUTION> MASSACHUSETTS INSTITUTE OF TECHNOLOGY; 0753 </INSTITUTION>
<DESCRIPTORS> ENGINEERING, MECHANICAL; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> HARUHIKO ASADA </ADVISER>
<CLASSIFICATIONS> ADAPTIVE CONTROL </CLASSIFICATIONS>
<ABSTRACT>
In the control of high performance robots and machine
tools, feedback from the endpoint sensor measuring the
position of the end effector has great promise for
improving accuracy. This endpoint feedback, however,
often incurs instability due to the non-collocated
sensor-actuator configuration coupled with unmodeled
dynamics and sensor noise. Plant dynamics is often
uncertain, and the tuning of endpoint feedback
controllers is beyond the capacity of the users. The
objective of this thesis is to develop an automatic
tuning algorithm for non-collocated endpoint feedback
systems.
In our attempt to solve problems associated with
adaptive control, we proposed a progressive learning
algorithm. The idea of progressive learning is to tune
the system step by step in the frequency domain in order
to expand the system bandwidth. In this work, the
stability issue has been discussed in the framework of
the model reference adaptive control (MRAC). Our main
focus of the research is to guarantee the stability and
the robustness of the system subject to the presence of
the unmodeled dynamics and output noise. The system is
tuned gradually and progressively by increasing either
the trajectory frequency or the controller's order.
Thus, fewer parameters need to be learned in each stage.
This progressive cascading of controller stage by stage
in order to achieve wider control bandwidth is referred
to as model augmentation. In this research, we address
the model augmentation as to when to augment the model
and how to maintain stability, despite unmodeled
dynamics and sensor noise. Next, a series of reference
trajectories are designed in such a way that the system
can be excited progressively starting from a low
frequency range moving up to a full spectrum. To
validate the theoretical results, a simulation is shown
first and followed by experimental results and
discussions of three endpoint controlled systems: a high-
speed chip-placement machine, a linear slider, and a
coordinate measuring machine (CMM). (Copies available
exclusively from MIT Libraries, Rm. 14-0551, Cambridge,
MA 02139-4307. Ph. 617-253-5668; Fax 617-253-1690.)
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  3797 </NUMBER>
<ORDER>   AAGNN11848 </ORDER>
<TITLE> EFFECTIVE CLASSIFICATION LEARNING </TITLE>
<AUTHOR> SCHUURMANS, DALE ERIC </AUTHOR>
<YEAR> 1996 </YEAR>
<INSTITUTION> UNIVERSITY OF TORONTO (CANADA); 0779 </INSTITUTION>
<DESCRIPTORS> COMPUTER SCIENCE; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> HECTOR LEVESQUE </ADVISER>
<CLASSIFICATIONS> MACHINE LEARNING, TRAINING, ARTIFICIAL INTELLIGENCE </CLASSIFICATIONS>
<ABSTRACT>
This thesis addresses the problem of learning a
classification rule from random examples. We first
consider the problem of learning a target concept with
guaranteed accuracy and reliability given that the
target belongs to some known class C; a task commonly
referred to as probably approximately correct (pac)
learning. Previous work on this problem assumes a fixed-
sample-size approach to data collection that fails to
achieve practical data-efficiency in most applications.
In this thesis we consider an alternative "sequential"
approach where the learner observes training examples
one-at-a-time and decides on-line when to stop training.
We prove that sequential learning strategies can pac-
learn with fewer training examples than previous fixed-
sample-size approaches, even while incurring minimal
computational overhead. Moreover, these new strategies
use many times fewer training examples in practical case
studies.
Next, we study the average error of a learner's
hypotheses as a function of training sample size--its so
called learning curve. Specifically, we investigate the
best learning curve that can be achieved in the worst
case over a class of concepts C. Previous work has shown
that rational convergence to zero error can always be
obtained in this model, but it is impossible to do
better in the worst case. However, recent empirical
studies have shown that exponential convergence can be
achieved in many experimental settings. We explain this
discrepancy by noting that the previous analysis is non-
uniform in training sample size, and prove that a
uniform analysis predicts that exact same dichotomy as
observed in the experimental studies. Overall, this
thesis shows how the worst case theory of classification
learning can be brought closer to practice.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  3798 </NUMBER>
<ORDER>   AAGMM15707 </ORDER>
<TITLE> FUZZY FOIL: A FUZZY LOGIC BASED INDUCTIVE LOGIC PROGRAMMING SYSTEM </TITLE>
<AUTHOR> CHEN, GUIMING </AUTHOR>
<YEAR> 1996 </YEAR>
<INSTITUTION> UNIVERSITY OF OTTAWA (CANADA); 0918 </INSTITUTION>
<DESCRIPTORS> COMPUTER SCIENCE; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> STAN MATWIN </ADVISER>
<CLASSIFICATIONS> NIL </CLASSIFICATIONS>
<ABSTRACT>
In many domains, characterizations of a given attribute
are imprecise, uncertain and incomplete in the available
learning examples. The definitions of classes may be
vague. Learning systems are frequently forced to deal
with such uncertainty. Traditional learning systems are
designed to work in the domains where imprecision and
uncertainty in the data are absent. Those learning
systems are limited because of their impossibility to
cope with uncertainty--a typical feature of real-world
data.
In this thesis, we developed a fuzzy learning system
which combines inductive learning with a fuzzy approach
to solve problems arising in learning tasks in the
domains affected by uncertainty and vagueness. Based on
Fuzzy Logic, rather than pure First Order Logic used in
FOIL, this system extends FOIL with learning fuzzy logic
relation from both imprecise examples and background
knowledge represented by Fuzzy Prolog. The
classification into the positive and negative examples
is allowed to be a degree (of positiveness or
negativeness) between 0 and 1. The values of a given
attribute in examples need not to be the same type.
Symbolic and continuous data can exist in the same
attribute, allowing for fuzzy unification (inexact
matching). An inductive learning problem is formulated
as to find a fuzzy logic relation with a degree of
truth, in which a fuzzy gain calculation method is used
to guide heuristic search. The Fuzzy FOIL's ability of
learning the required fuzzy logic relations and dealing
with vague data enhances FOIL's usefulness.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  3799 </NUMBER>
<ORDER>   AAGNN11824 </ORDER>
<TITLE> THE EFFECTS OF EMOTION ON HUMAN INFERENCE: TOWARDS A COMPUTATIONAL MODEL  </TITLE>
<AUTHOR> NUNDY, SEEMA </AUTHOR>
<YEAR> 1996 </YEAR>
<INSTITUTION> UNIVERSITY OF TORONTO (CANADA); 0779 </INSTITUTION>
<DESCRIPTORS> PSYCHOLOGY, EXPERIMENTAL; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> KEITH OATLEY </ADVISER>
<CLASSIFICATIONS> ARTIFICIAL INTELLIGENCE, REASONING </CLASSIFICATIONS>
<ABSTRACT>
A common criticism of AI has been that computational
models have not been theoretically grounded and as such
lack testability. In this research I attempt to address
this criticism by looking at the interaction between
emotions and reasoning from both a theoretical and
empirical perspective then suggesting a possible role
for emotions in both human and machine inference. Three
studies examining the role of emotions in three
different types of reasoning tasks were conducted: juror
reasoning, syllogistic reasoning and narrative reasoning
from text. In the first two studies (juror and
syllogistic reasoning), happy and sad emotional states
were induced by asking subjects to view happy and sad
film clips. In the juror reasoning task, subjects were
asked to read through a trial transcript to offer a
verdict and to answer some other questions about the
trial; in the syllogistic reasoning task, subjects were
asked to ascertain the validity of ten categorical
syllogisms. In the narrative reasoning task no mood
inductions were performed, instead subjects were asked
to read a short story, and to record simultaneously what
emotions they felt. After completing the story they were
asked to answer interpretive questions pertaining to the
story. The results of all three studies showed that
affect plays roles in reasoning that have significant
measurable effects--even in a domain as structured as
syllogistic reasoning.
What the results of these studies suggested, moreover,
is that it is not enough to merely look at the
influences of positive and negative mood on social
judgment (the method of the large majority of studies
thus far performed) but that the influence of particular
emotions needs to be examined more carefully. In each
study it was not just the effect of positive or negative
mood induction, but more specific effects of particular
emotions (usually happiness, sadness or anger) that
influenced reasoning style. Analyses of the data also
suggested that the dynamic event of a change in
intensity of emotion may be worth considering as a cause
of triggering particular chains of reasoning. The
reasoning strategy each emotion triggered was based on a
number of variables such as the task domain; the nature
of prior search; the juncture reached in the ongoing
plan; and the inferencing patterns shown by people in
similar situations. A model machine inference that
incorporates the effects of emotions in human reasoning
that would be useful for programming commonsense
reasoning in a multiple-agent, multiple-goal dynamic
environment is presented.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  3800 </NUMBER>
<ORDER>   AAGNN11757 </ORDER>
<TITLE> RULE BASE REORGANIZATION FOR FUZZY EXPERT SYSTEM DESIGN </TITLE>
<AUTHOR> JIANG, SHAONING (SIMON) </AUTHOR>
<YEAR> 1996 </YEAR>
<INSTITUTION> UNIVERSITY OF TORONTO (CANADA); 0779 </INSTITUTION>
<DESCRIPTORS> ENGINEERING, INDUSTRIAL; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> I. B. TURKSEN </ADVISER>
<CLASSIFICATIONS> ARTIFICIAL INTELLIGENCE </CLASSIFICATIONS>
<ABSTRACT>
The research presented in this thesis focuses on the
algorithms and methodologies for fuzzy knowledge
representation related issues. Those issues include
compensatory connectives, fuzzy rule base organization
algorithms, and preprocessing algorithms for a fuzzy
rule base with a large number of production rules.
In the work documented here, (i) fuzzy rule base
reorganization with single and multiple antecedent fuzzy
rules were thoroughly studied, and (ii) new algorithms
for fuzzy rule base reorganization were developed. The
computational complexity issues and robustness issues
were carefully addressed within the context. For rule
bases with a large number of rules and/or redundant rule
clusters, preprocessing algorithms were designed to
reduce the number of rules in size and format. The
reorganization algorithms presented here can be
efficiently implemented in terms of computational
complexity. A new family or compensatory scAND operators
(c- scAND for short) are proposed. They are based on the
notion of latent connectives, known as compensatory
connectives, and of interval-valued fuzzy sets. The
basic properties of this family of connectives were
studied in depth in this work. A number of theoretical
properties were discovered among the normal form based
fuzzy c- scAND operators and latent connectives. The
compensatory scAND connectives facilitate the study of
the behaviour and robustness of a reorganized rule base.
With these developments, various aspects of fuzzy rule
base reorganization activities were prototyped and
verified for a service centre control system. That
system has a fuzzy rule base model based on an
analytical M/M/c queuing model. Experimental results
show that the proposed algorithms can reduce more than
70% of the rules without affecting the performance of
the system (based on the paired-T test at 0.05 degree
significance). It has been found that the complexity of
a fuzzy rule base was greatly reduced in terms of fuzzy
inferences and fuzzy rule searches.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  3801 </NUMBER>
<ORDER>   AAG9640222 </ORDER>
<TITLE> COMPUTATIONAL TREATMENT OF ASPECTUAL SEMANTICS </TITLE>
<AUTHOR> GUILLEN-CASTRILLO, ROCIO-TERESITA </AUTHOR>
<YEAR> 1996 </YEAR>
<INSTITUTION> NEW MEXICO STATE UNIVERSITY; 0143 </INSTITUTION>
<DESCRIPTORS> COMPUTER SCIENCE; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> SERGEI NIRENBURG </ADVISER>
<CLASSIFICATIONS> NATURAL LANGUAGE, ARTIFICIAL INTELLIGENCE, RULE-BASED </CLASSIFICATIONS>
<ABSTRACT>
In Artificial Intelligence, in particular Natural
Language Processing, the problem of representing and
semantically interpreting aspect information is
recognized as a relevant issue since much of language
involves time. Several computational approaches for both
monolingual and multilingual environments have been
developed for the treatment of aspectual semantics,
i.e., for assigning an aspectual category or a set of
aspectual values to an event. Most of these approaches
are static since they preassign an aspectual category to
a verb without taking context into account. The purpose
of my research is to investigate the procedures involved
in dynamically determining the aspectual meaning of
events from whatever context is present.
My research for building and implementing a
computational treatment of aspectual semantics involves
the following tasks: selection of a set of corpus of
texts containing clues potentially useful in determining
aspectual values; analysis, comparison and
classification of these clues extracted from various
knowledge sources; definition of a language for
representing the rules that assign aspectual values
using these clues; construction of the set of rules; the
design and implementation of a rule-based system that
determines and assigns aspectual values by applying
these rules; experimentation with the system on a set of
texts and evaluation of results.
The results obtained from the research done follow. I
identified and classified a set of clues extracted from
the context of sentences in a corpus of texts; found
that a data-driven approach proved to be helpful in
finding and extracting these clues by means of pattern
matching techniques on a large corpus of unconstrained
text; discovered a set of rules for assigning aspectual
values based on the different combinations of static and
contextual clues contained as conditions in the left-
hand side of the rules; showed that a dynamic approach
for processing aspectual semantics is feasible by
implementing the set of rules in a rule-based system;
found that results of the experiments with the system
using a set of texts are promising. In average, 97
percent of the cases were assigned correct values.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  3802 </NUMBER>
<ORDER>   AAG9640220 </ORDER>
<TITLE> AN EFFICIENT METHOD FOR DESIGNING INTELLIGENT FUZZY CONTROLLERS  </TITLE>
<AUTHOR> AKBAR, SYED ALI </AUTHOR>
<YEAR> 1996 </YEAR>
<INSTITUTION> NEW MEXICO STATE UNIVERSITY; 0143 </INSTITUTION>
<DESCRIPTORS> ENGINEERING, ELECTRONICS AND ELECTRICAL; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> WILEY E. THOMPSON </ADVISER>
<CLASSIFICATIONS> SIMULATED ANNEALING, ARTIFICIAL INTELLIGENCE </CLASSIFICATIONS>
<ABSTRACT>
The design of intelligent control systems has become an
area of intense research interest. Fuzzy control is a
knowledge based control scheme in which membership
functions of physical variables are used to cope with
uncertainty in process dynamics or signal measurements.
Design of a fuzzy controller requires specification of
both membership functions and decision rules. In this
study, a generalized model for implementation and
performance of fuzzy and neural network controllers
scheme is presented. This new method provides a
structure for combining linguistic and numerical
information into a common framework. This common
framework can be used to implement equivalent fuzzy or
neural controllers. This method provides a unified way
for implementing equivalent controllers from different
sets of information. Further, it provides a pair basis
for comparing two different controller strategies since
they use the same information for both controllers.
Also, this model gives freedom to a designer to choose
the most appropriate controller regardless of the type
of information available. This method yields a
controller which gives excellent performance when either
kind of information alone is incomplete.
Designing a fuzzy controller not only requires knowledge
of the process but also knowledge of the effect of the
membership functions on the performance of the fuzzy
controller. Specification of membership function for a
fuzzy logic controller has been an important issue. The
traditional method of selecting membership functions has
been, in most cases, an ad hoc procedure. In this
thesis, an optimization algorithm based on simulated
annealing for designing a fuzzy membership functions for
fuzzy controllers is introduced. To demonstrate the
method, a fuzzy controller for the truck backup problem
is designed and implemented using this procedure.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  3803 </NUMBER>
<ORDER>   AAG9639581 </ORDER>
<TITLE> PREDICTION INTERVALS AND CONFIDENCE INTERVALS FOR NEURAL NETWORKS AND HELP </TITLE>
<AUTHOR> DING, AIDONG ADAM </AUTHOR>
<YEAR> 1996 </YEAR>
<INSTITUTION> CORNELL UNIVERSITY; 0058 </INSTITUTION>
<DESCRIPTORS> ENGINEERING, INDUSTRIAL; STATISTICS; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> J. T. GENE HWANG </ADVISER>
<CLASSIFICATIONS> NIL </CLASSIFICATIONS>
<ABSTRACT>
Prediction intervals and confidence intervals are very
important tools with wide applications. This thesis
studies the construction of such intervals for two new
areas: neural networks and High-dimensional empirical
linear prediction (HELP). Both models are motivated from
engineering applications.
In both cases, the models are unidentifiable. However,
the objective is to construct statistical intervals for
the future observation, called prediction intervals, and
for the expected value of the future observation, called
confidence intervals. It is shown that in both cases,
the unidentifiability does not prevent us in doing so.
In fact, it is shown that unidentifiability is "cured"
by prediction. This appears to be a general phenomenon.
In both cases, the intervals were studied by simulation
and were also tested with real data. It was shown that
these asymptotic valid solutions work well with
simulation as well as with the real data. We also
provide consistent estimator of the number of parameters
in both cases: the number of hidden nodes in neural
networks and the true dimensionality of the problem in
HELP. In the second case, we studied an unusual
asymptotic situation where the the size of the
covariance matrix approaches infinity. This is a
theoretically challenging problem and is very important
for the applications. The resultant intervals are shown
to improve greatly upon existing intervals.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  3804 </NUMBER>
<ORDER>   AAG9639368 </ORDER>
<TITLE> A MODULAR INTEGRATION OF KNOWLEDGE-BASED SYSTEMS AND ARTIFICIAL NEURAL NETWORKS FOR PROCESS FAULT DIAGNOSIS </TITLE>
<AUTHOR> WANG, CHUNG-MIN </AUTHOR>
<YEAR> 1996 </YEAR>
<INSTITUTION> THE OHIO STATE UNIVERSITY; 0168 </INSTITUTION>
<DESCRIPTORS> ENGINEERING, CHEMICAL; COMPUTER SCIENCE; ENGINEERING, SYSTEM SCIENCE; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> JAMES F. DAVIS </ADVISER>
<CLASSIFICATIONS> ARTIFICIAL INTELLIGENCE </CLASSIFICATIONS>
<ABSTRACT>
The development of intelligent computer-aided systems
for process monitoring, control, scheduling and
optimization is evolving towards integrating the
different techniques for improved performance. The
Neural-Expert hybrid approach, consisting of Knowledge-
Based Systems (KBSs) and Artificial Neural Networks
(ANNs), is one of the promising developments. Areas of
research and development include the fundamentals of
hybrid systems, as well as theoretical and practical
integration techniques. From an engineering point of
view, the research focus is to develop a practical
integration system that is most appropriate to apply to
a given problem. If the problem is in a domain where
expertise can be easily obtained, we can use ANN to
improve the KBS performance. The integration should
emphasize the verification and refining of expertise by
data or obtaining a heuristic evaluation function
through the ANN to reduce the search efforts in the KBS.
On the other hand, if data are abundant for the target
problem, the ANN should be core in the integration. We
can use a KBS to improve the quality of data and to
guide and verify the training of the ANN. In situations
where both knowledge and data are available but
incomplete, such as most of fault detection and
isolation (FDI) problems, an integration must
effectively manipulate the information sources and use
the KBS and ANN to complement one another.
This research proposes a modular design to integrate a
KBS and an ANN for process fault diagnosis. Both
techniques serve as inference components and help
control the functioning of one another. Each module can
be either a KBS, which utilizes a known set of causal
relations, or an ANN, which implicitly extracts
knowledge from archived data. For those parts of a
diagnostic problem where data and knowledge are
available, a decision integrator is used to improve the
system's performance by considering and combining the
diagnostic conclusions from the ANN and the KBS. The
decision integrator provides ranks for the fault
candidates selected by KBS and ANN to reflect the
confidence of occurring. The ranking process is based on
the records of past performance of the tools.
The principal advantage of the modular integration
system is its structured methodology that takes into
account both qualitative reasoning and empirical
modeling. In addition, the modular approaches require
less effort in acquiring knowledge for the KBS since the
ANN can better handle events of a quantitative nature.
Conversely, the KBS will complement the ANN when the
events require logical representations. A case study
using a simulated recycle reactor process to demonstrate
the successful application of this methodology is
presented.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  3805 </NUMBER>
<ORDER>   AAG9639118 </ORDER>
<TITLE> DEVELOPMENT AND VALIDATION OF PARENTAL ALERT AND REMINDER ASSISTANT: A PRENATAL EXPERT SYSTEM PROTOTYPE </TITLE>
<AUTHOR> SAGER, JOYCE TANIMOTO </AUTHOR>
<YEAR> 1996 </YEAR>
<INSTITUTION> THE UNIVERSITY OF UTAH; 0240 </INSTITUTION>
<DESCRIPTORS> COMPUTER SCIENCE; HEALTH SCIENCES, OBSTETRICS AND GYNECOLOGY; HEALTH SCIENCES, MEDICINE AND SURGERY; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> NIL </ADVISER>
<CLASSIFICATIONS> DECISION SUPPORT </CLASSIFICATIONS>
<ABSTRACT>
The Prenatal Alert and Reminder Assistant (PARA) was
developed at the LDS Hospital at Salt Lake City, Utah,
as part of the HELP hospital information system. PARA is
the third expert system prototype to computerize the
prenatal record and provide decision support to the
obstetric team with patient specific alerts and
reminders. Its development and validation are presented,
as well as the studies into (1) the control of error
propagation and (2) data modeling of pregnancy outcome.
The experimental knowledge base with 25 rules was
validated using a retrospective study of 50 prenatal
charts (25 normal and 25 hypertensive pregnancies).
PARA's knowledge base was validated with a mean score of
98.9% correct as compared to 97.8% for the obstetric
team (p = 0.0216). The difference of 1.1% represents a
50% reduction in the error rate (2.2%) as compared to
the obstetric team.
Propagation of erroneous decision-support messages in a
large clinical database was controlled through the use
of Truth Maintenance techniques. These techniques
included tagging messages as "active" and "inactive,"
limiting the reasoning to active messages, and requiring
each Medical Logic Module (MLM) in PARA's knowledge base
to have rules that would assert the message was false,
unless it could be asserted true.
The patient charge for a labor-and-delivery admission
was used as a crude index of pregnancy outcomes. A model
of the relationships of certain pregnancy complications
to this pregnancy outcome variable was developed. The
regression model's 17 independent variables had a
strong, positive correlation (R = 0.70) with the
dependent variable, log hospital charges. The
association was statistically significant (p = 0.0001).
Forty-eight percent of the variance in the hospital
charges were explained by the 17 variables (adjusted
multiple R-square = 0.482).
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  3806 </NUMBER>
<ORDER>   AAG9638977 </ORDER>
<TITLE> STRUCTURE-BASED CONNECTIONIST NETWORK FOR FAULT DIAGNOSIS OF HELICOPTER GEARBOXES </TITLE>
<AUTHOR> JAMMU, VINAY BHASKAR </AUTHOR>
<YEAR> 1996 </YEAR>
<INSTITUTION> UNIVERSITY OF MASSACHUSETTS; 0118 </INSTITUTION>
<DESCRIPTORS> ENGINEERING, MECHANICAL; ENGINEERING, AEROSPACE; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> KOUROSH DANAI </ADVISER>
<CLASSIFICATIONS> ARTIFICIAL INTELLIGENCE </CLASSIFICATIONS>
<ABSTRACT>
A diagnostic method is introduced for helicopter
gearboxes that uses the gearbox structure and
characteristics of the 'features' of vibration to define
the influences of faults on features. The structural
influences in this method are defined based on the root
mean square value of vibration obtained from a
simplified lumped-mass model of the gearbox. Featural
influences characterize the frequency-specific
information of the vibration features which correspond
to the type of gearbox faults the features represent.
These influences are defined as fuzzy variables to
account for the approximate nature of the simplified
model of the gearbox. The fuzzy structural and featural
influences are then incorporated as the weights of a
connectionist network for diagnosis, so as to avoid
supervised training of the network. Diagnosis in this
Structure-Based Connectionist Network (SBCN) is
performed by propagating the abnormal features through
the weights of SBCN to obtain fault possibility values
for the components in the gearbox.
In the proposed diagnostic method, vibration features
obtained from raw vibration are first utilized by an
unsupervised Fault Detection Network (FDN) for
identifying the presence of faults. Fault diagnosis is
then performed by SBCN only if the presence of a fault
is prompted by FDN. Since SBCN uses abnormal vibration
features as inputs, an unsupervised pattern classifier
is designed for abnormality-scaling of features. The
abnormality-scaled features are then propagated through
the weights of SBCN for isolating faulty components.
The proposed diagnostic method is experimentally
evaluated in application to two helicopter gearboxes: OH-
58A and S-61. Experimental vibration data for the OH-58A
gearbox were collected at the NASA Lewis Research
Center, and vibration data from three S-61 gearboxes
rejected in field operation were collected at Sikorsky
Aircraft. The proposed method is evaluated in diagnosis
of the OH-58A gearbox faults as well as isolating the
faults within the three S-61 gearboxes. The diagnostic
results indicate that the SBCN is able to correctly
diagnose about 80% of the OH-58A gearbox faults and all
the faults in S-61 gearboxes. In addition to evaluation
of the structural influences based on diagnostic
results, they are validated by comparing them with
influences obtained from experimental RMS values as well
as the weights of a neural network structurally similar
to SBCN, but trained through supervised learning.
Moreover a sensitivity analysis is performed to study
the effect of variations in structural influences on
diagnostic results. The structural influences developed
in this method can also be utilized for assessing the
importance of various gearbox accelerometers in
diagnosis. Three indices are defined based on the
structural influences to quantify various aspects of
accelerometer significance and are evaluated using the
data from the OH-58A gearbox.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  3807 </NUMBER>
<ORDER>   AAG9638937 </ORDER>
<TITLE> COMPUTATIONAL EXPLORATIONS OF THE EVOLUTION OF ARTIFICIAL NEURAL NETWORKS IN PAVLOVIAN ENVIRONMENTS </TITLE>
<AUTHOR> BURGOS, JOSE ENRIQUE </AUTHOR>
<YEAR> 1996 </YEAR>
<INSTITUTION> UNIVERSITY OF MASSACHUSETTS; 0118 </INSTITUTION>
<DESCRIPTORS> PSYCHOLOGY, BEHAVIORAL; COMPUTER SCIENCE; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> JOHN W. DONAHOE </ADVISER>
<CLASSIFICATIONS> NIL </CLASSIFICATIONS>
<ABSTRACT>
The present work initiates a research line in the study
of artificial life, through a preliminary
characterization of a computational approach to
evolutionary interpretations of Pavlovian-conditioning
phenomena. The approach was implemented through a Neuro-
Computational/Genetic-Algorithm (or NC-GA) hybrid model.
The NC model described the fimctioning of neuron-like
processing elements that were interconnected forming
artificial neural networks (ANNs). The GA consisted of a
set of rules for selecting ANNs for mating and
reproduction. ANNs were developed from virtual
chromosomes encoding variables determining the course of
a neurodevelopmental program motivated by general
concepts from developmental neuroscience. All
chromosomes had a fixed length and encoded for the same
set of variables. Also, that program involved a one-many
relation, for most of the variables encoded by the
chromosomes were probabilistic.
The NC-GA model was characterized through computer
simulations. Four simulation experiments were performed,
each consisting of two kinds of simulations, evolution
and test. In the evolution simulations, the GA was used
to evolve ANNs that were trained in a Pavlovian
procedure. ANNs with higher conditional-response
proportions had a higher probability of being selected
for mating and reproduction. In the test simulations,
the behavioral competence of the evolved ANNs was
determined by exposing them to conditions different from
the ancestral ones.
In general, the results from the evolution simulations
demonstrated that the mean chromosomic overlap and the
mean population fitness increased as negatively
accelerated functions of generations. Also, most ANNs at
the beginning of evolution showed no learning, whereas
ANNs by the end of evolution showed learning.
In Experiment 1, ANNs were selected for increased
responding under forward-delay procedures in which the
interstimulus interval (ISI), and the kind of CS were
manipulated. After evolution, ANN sizes increased as a
function of ISIs, and ANN performances in the test
simulations were consistent with ISI functions, optimal-
ISI noninvariance, and CS nonequipotentiality. In
Experiment 2, two CSs were independently paired with the
US. After evolution, ANN sizes increased as a
nonmonotonic function of the ISI, and ANN performances
in the test simulations showed generalization,
discrimination, and blocking. In Experiments 3 and 4,
ANNs were selected for orthogonal and nonorthogonal
discrimination, respectively. Performances in the test
simulations of both experiments also showed
generalization, discrimination, and blocking.
Collectively, these results are consistent with the
pursuit of general-process approaches to learning.
However, such approaches also allow for interpretations
in which biological constraints on learning are seen as
emerging from variations in general neurobiological
processes, and as imposing limits on the range of
variation of general biobehavioral processes.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  3808 </NUMBER>
<ORDER>   AAG9730432 </ORDER>
<TITLE> GENERALIZATION AND NEURAL NETWORKS </TITLE>
<AUTHOR> FORESEE, FOREST DAN </AUTHOR>
<YEAR> 1996 </YEAR>
<INSTITUTION> OKLAHOMA STATE UNIVERSITY; 0664 </INSTITUTION>
<DESCRIPTORS> ENGINEERING, ELECTRONICS AND ELECTRICAL; ARTIFICIAL INTELLIGENCE; COMPUTER SCIENCE </DESCRIPTORS>
<ADVISER> MARTIN T. HAGAN </ADVISER>
<CLASSIFICATIONS> REGULARIZATION </CLASSIFICATIONS>
<ABSTRACT>
Scope and method of study. The purpose of this work was
to study methods of improving generalization performance
for feed forward fully connected two layer neural
networks used for nonlinear regression. There are many
methods in use today to improve generalization
performance, but they are difficult to compare given
their different notation styles and characteristic
assumptions. We sought to categorize these methods, to
explore some of them in depth, and to compare
performance of key methods. We also sought to develop an
improved generalization technique and to test this new
method on real-world problems.
Findings and conclusions. We placed the Network
Information Criterion, regularization and stopped
training techniques in a common mathematical framework
for theoretical comparison. Then we implemented each
using the Levenberg-Marquardt training algorithm for
application comparison. We found the most promising
method of improving generalization performance was to
apply regularization. Further, we incorporated MacKay's
Bayesian optimization ideas for automatic dynamic
selection of the regularization parameter size. However,
this method requires calculating the Hessian of the
objective function for each training step. Though this
is computationally expensive, we found that the Gauss-
Newton approximation to the Hessian works extremely well
and since it is a by-product of the Levenberg-Marquardt
algorithm it is already available, thus minimizing the
computational cost of implementation. Lastly, we
presented four diverse real-world examples of how our
GNBR (Gauss-Newton approximation to Bayesian
Regularization) algorithm consistently produced optimal
generalization results for any modestly oversized neural
network architecture.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  3809 </NUMBER>
<ORDER>   AAG9638200 </ORDER>
<TITLE> CONSTRUCTABILITY KNOWLEDGE ACQUISITION: A MACHINE LEARNING APPROACH </TITLE>
<AUTHOR> LUEPRASERT, KAMOLWAN </AUTHOR>
<YEAR> 1996 </YEAR>
<INSTITUTION> PURDUE UNIVERSITY; 0183 </INSTITUTION>
<DESCRIPTORS> ENGINEERING, CIVIL; ENGINEERING, SYSTEM SCIENCE; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> MIROSLAW J. SKIBNIEWSKI </ADVISER>
<CLASSIFICATIONS> NIL </CLASSIFICATIONS>
<ABSTRACT>
Project constructability can be devaluated significantly
because of poor structural design decisions. However,
the aspects of structural design decisions in
constructability have not been thoroughly emphasized in
the constructability concepts currently applied in the
industry. This research proposes a methodology to
acquire constructability knowledge according to
structural design decisions made during conceptual
phase. Constructability is understood as "an important
feature of a structural design and construction project
site conditions which determines the level of complexity
of executing the associated structural assembly task".
Constructability knowledge is acquired from structural
design data of building structures, proposed
construction methods, and resource availability
conditions.
Determining constructability of a project requires
experience and expertise, which may not be available. A
inductive learning system is proposed as an alternative
knowledge acquisition tool. The system is capable of
knowledge acquisition and generating desired concepts
from classified constructability examples. Three methods
for; (1) the preparation of constructability examples;
(2) the constructability knowledge acquisition; and (3)
the verification and validation of acquired knowledge,
were proposed to develop such a learning system for
constructability knowledge acquisition. Constructability
knowledge is acquired in form of decision rules, and can
be updated by implementing multistage knowledge
acquisition process.
Direct data extraction is proposed to extract structural
design data from design drawings in CAD. Additional
information necessary to the knowledge acquisition can
be obtained from preliminary project plan and proposal.
Acquired constructability knowledge can be used for
future applications in the constructability domain, e.g.
identifying potential structural design problems to
improve overall project's constructability.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  3810 </NUMBER>
<ORDER>   AAG9638142 </ORDER>
<TITLE> ADAPTIVE SELF-ORGANIZING NEURAL NETWORKS FOR MATRIX EIGEN-DECOMPOSITION PROBLEMS AND THEIR APPLICATION TO FEATURE EXTRACTION </TITLE>
<AUTHOR> CHATTERJEE, CHANCHAL </AUTHOR>
<YEAR> 1996 </YEAR>
<INSTITUTION> PURDUE UNIVERSITY; 0183 </INSTITUTION>
<DESCRIPTORS> ENGINEERING, ELECTRONICS AND ELECTRICAL; COMPUTER SCIENCE; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> VWANI P. ROYCHOWDHURY </ADVISER>
<CLASSIFICATIONS> NIL </CLASSIFICATIONS>
<ABSTRACT>
We describe artificial neural networks and self-
organizing learning algorithms to adaptively solve a set
of matrix algebra problems. We discuss algorithms to
compute the following matrix functions: (1) the
normalized mean of a data sequence, (2) the inverse of
the square root of the positive definite correlation
matrix of a data sequence, and (3) several algorithms to
compute the generalized eigenvectors of two correlation
matrices of two data sequences.
Although several applications are mentioned for these
algorithms, we have used them primarily to obtain
adaptive estimates of class-separability features. The
feature extraction networks discussed in this study are:
(1) a network for normalized correlation features, (2)
networks for unimodal and multi-cluster Gaussian data in
the multi-class case, (3) a network for multivariate
linear discriminant analysis (LDA) in the multi-class
case, (4) a network for Bhattacharyya distance measure
for the two-class case, and (5) a network for
multivariate LDA derived from a hetero-associative
supervised network.
For each algorithm, the convergence with probability one
is proven by using stochastic approximation theory, and
a single layer linear network architecture for the
algorithm is described. In some cases, such as LDA,
combinations of these algorithms are used to extract the
features. In these cases, our methods allow for
simultaneous training of the multi-layer networks.
Convergence of the networks under simultaneous training
is also proven.
A key property of our training procedures is that they
are adaptive in nature and hence, they are well-suited
for online applications and can be easily implemented by
VLSI technologies. Every network considers a flow or
sequence of inputs for training, thereby eliminating the
need for a pooled data for training. Numerical studies
on the performance of the networks for multi-class
random data are presented.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  3811 </NUMBER>
<ORDER>   AAG9638045 </ORDER>
<TITLE> A VALUE-DIRECTED APPROACH TO PLANNING </TITLE>
<AUTHOR> WILLIAMSON, MIKEL RAY </AUTHOR>
<YEAR> 1996 </YEAR>
<INSTITUTION> UNIVERSITY OF WASHINGTON; 0250 </INSTITUTION>
<DESCRIPTORS> COMPUTER SCIENCE; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> STEVEN J. HANKS </ADVISER>
<CLASSIFICATIONS> ARTIFICIAL INTELLIGENCE </CLASSIFICATIONS>
<ABSTRACT>
The traditional definition of planning in the field of
artificial intelligence provides only a very narrow
notion of plan quality, namely that a plan is good just
in case it achieves a specified goal. For many
applications, this all-or-nothing notion of quality is
insufficiently expressive. This dissertation extends the
definition of planning to provide a much richer
conception of plan quality.
We propose that a planning problem should be posed in
terms of a decision-theoretic value function, and that
planning should be seen as an optimization process. We
describe P scYRRHUS, A planning system which uses a
branch-and-bound algorithm to find optimal plans for a
class of goal-directed value functions which is strictly
more expressive than the kind of goal formulas used by
classical planning. Such value functions allow one to
express not just one's goals, but also how important
those goals are, ways in which they may be partially
achieved, and the worth of resources that may be
consumed by a plan. We empirically explore issues of
heuristic control that arise during the planning
process, compare the difficulty of value-directed
planning to comparable classical planning problems, and
examine the relationship between characteristics of our
value representation and the difficulty of planning.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  3812 </NUMBER>
<ORDER>   AAG9638021 </ORDER>
<TITLE> DEVELOPMENT OF AN INTELLIGENT AIR BRAKE WARNING SYSTEM FOR COMMERCIAL VEHICLES </TITLE>
<AUTHOR> SCHEIBE, ROBERT R. </AUTHOR>
<YEAR> 1996 </YEAR>
<INSTITUTION> UNIVERSITY OF WASHINGTON; 0250 </INSTITUTION>
<DESCRIPTORS> ENGINEERING, MECHANICAL; ENGINEERING, AUTOMOTIVE; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> PER G. REINHALL </ADVISER>
<CLASSIFICATIONS> NIL </CLASSIFICATIONS>
<ABSTRACT>
Air-brake-equipped vehicles are prone to serious
problems peculiar to their design that can result in
loss of braking effectiveness with little warning to the
driver. Research is presented that leads to the design
of an intelligent air brake warning device (IBWD) that,
through various sensors and an analytical algorithm,
will provide drivers and authorities with critical
information about brake condition. The IBWD performs an
inferential, on-board, real-time assessment of vehicle
brake performance through measurement of only a few
parameters, namely deceleration, application air
pressure, vehicle weight, speed, and response pressures
at various axles. It will not involve wheel-to-wheel
measurements of brake adjustment or temperature, though
it will be sensitive to loss of performance from
excesses in either.
Full scale testing of various heavy truck configurations
was performed in two sessions. Data analysis from the
first session assessed the significance of the various
measurable parameters and provided a foundation for a
software mock-up of an IBWD. The second test session
demonstrated the feasibility of the IBWD software and
gathered data under more realistic conditions. Data were
then extensively analyzed for traits that portend loss
of brake efficiency. Multiple regression model
optimization techniques were used to develop several
robust models that accurately describe vehicle braking
propensity. Models of three response variables were
found to hold promise for the IBWD algorithm:
deceleration, air transmission lag time, and brake
response pressure decay time.
A framework for an IBWD algorithm is presented. A two-
mode system is proposed: vehicles will first be
"trained" with brakes that are cool and properly
maintained; once trained, brake performance data
acquired while the vehicle is in normal operation will
be compared with the model. Deviations from the model
will be analyzed; if warranted, a warning of impending
brake degradation will be issued.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  3813 </NUMBER>
<ORDER>   AAG9638013 </ORDER>
<TITLE> INTELLIGENT SYSTEM METHODS FOR ENERGY INTERCHANGE DECISION-MAKING IN A COMPETITIVE ELECTRIC POWER SYSTEM ENVIRONMENT </TITLE>
<AUTHOR> ROSENWALD, GARY WALDO, JR. </AUTHOR>
<YEAR> 1996 </YEAR>
<INSTITUTION> UNIVERSITY OF WASHINGTON; 0250 </INSTITUTION>
<DESCRIPTORS> ENGINEERING, ELECTRONICS AND ELECTRICAL; ENERGY; ARTIFICIAL INTELLIGENCE; ECONOMICS, GENERAL </DESCRIPTORS>
<ADVISER> CHEN-CHING LIU </ADVISER>
<CLASSIFICATIONS> NIL </CLASSIFICATIONS>
<ABSTRACT>
Recent changes in the regulation of the electric power
industry are increasing the access to electrical power
transmission systems, unbundling power system services,
and creating competitive, cost-based markets for trading
electric energy. Many new problems resulting from these
changes in power system operation, planning,
reliability, pricing, and economics have resisted
precise definition, and the research and development
required to satisfy these upcoming needs are just
beginning. In this research, one of these new technical
problems, energy interchange evaluation in a competitive
market, is identified, and methods are developed to
satisfy the upcoming demands.
Before the changes in the regulatory structure, handling
interchange contracts was a problem in electric
utilities. Many interchange decisions relied on
incomplete information, intuition, and experience. To
address the increased need for methods to analyze
interchange contracts expected in the new market, a
methodology for COntract Handling and Optimization
(COHO) has been developed. The COHO system consists of
three new methods to identify feasible interchange
contracts, to model the competitive electric energy
market, and to optimize contract decisions for multiple
objectives. The method developed for screening the
consistency of interchange contracts with respect to
system constraints uses if-then rules to model contracts
and system constraints, and employs rule-based system
inference procedures to evaluate contract consistency.
With increasing emphasis on profit and competition, the
new heuristic search technique based on human
negotiation operators will be increasingly important for
optimizing interchange contract decisions and evaluating
the tradeoffs between competing objectives (e.g.,
security and economy). A game theoretic method for
calculating prices expected to result from potential
interchange contract negotiations is adopted to model
the electric energy market and provide data for the
analysis to determine an optimal set of interchange
partners.
The acceptance of many advanced methods which have shown
encouraging results in a variety of applications, such
as those used in COHO, has been hindered by the lack of
methods to maintain these systems. A (semi-)automated
approach to maintenance, including a method to
automatically identify a minimal number of test
scenarios to completely cover the software's input
space, has been developed to address this need for rule-
based systems.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  3814 </NUMBER>
<ORDER>   AAG9637783 </ORDER>
<TITLE> A HIERARCHICAL APPROACH TO EQUILIBRIUM CYCLE NUCLEAR FUEL ANALYSIS  </TITLE>
<AUTHOR> JUNEAU, JON </AUTHOR>
<YEAR> 1996 </YEAR>
<INSTITUTION> THE LOUISIANA STATE UNIVERSITY AND AGRICULTURAL AND MECHANICAL COL.; 0107 </INSTITUTION>
<DESCRIPTORS> ENGINEERING, NUCLEAR </DESCRIPTORS>
<ADVISER> MARK L. WILLIAMS </ADVISER>
<CLASSIFICATIONS> CONSTRAINT PROPAGATION, FUEL MANAGEMENT </CLASSIFICATIONS>
<ABSTRACT>
This research involved developing an expert system that
allows a nuclear fuel engineer to quickly provide
answers to strategic nuclear fuel management questions,
which are typically broad based. Current nuclear fuel
analysis research concentrates on getting more accurate
and precise answers at the expense of using large
computer programs to get answers that are too specific
to answer the broad based questions. The expert system
brings together several artificial intelligence
techniques to allow a nuclear fuel engineer to consider
several scenarios in a general way in order to quickly
answer the fuel management questions asked.
The expert system is based upon a hierarchy of several
abstraction levels using a constraint propagation system
at the lowest level. The constraint propagation system
prevents a novice nuclear fuel engineer from studying a
scenario with input conditions that contradict standard
nuclear fuel management relationships. The other
abstraction levels include generic number
representations, generic mathematical operators, and
generic relationships for economic analysis. The highest
level of the hierarchy is the knowledge base for nuclear
fuel analysis of the equilibrium nuclear fuel cycle. The
simplicity of adding other number representations to the
expert system is demonstrated by implementing an
interval number representation. Since the mathematical
operators used at the knowledge domain level are
generic, any new number representations, such as fuzzy
numbers, could be added without having to change the
basic domain knowledge. An example session shows how the
system can be used to provide guidance to a nuclear fuel
analyst in search of a good nuclear fuel management
strategy. By using the interval number representation,
the example session includes a simple sensitivity study
on how some of the input variables' uncertainty affects
the objective variable's value.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  3815 </NUMBER>
<ORDER>   AAG9637207 </ORDER>
<TITLE> THE HUMAN FACE RECOGNITION PROBLEM: A SOLUTION BASED ON THIRD-ORDER SYNTHETIC NEURAL NETWORKS AND ISODENSITY ANALYSIS  </TITLE>
<AUTHOR> UWECHUE, OKECHUKWU A. </AUTHOR>
<YEAR> 1996 </YEAR>
<INSTITUTION> FLORIDA ATLANTIC UNIVERSITY; 0119 </INSTITUTION>
<DESCRIPTORS> COMPUTER SCIENCE; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> ABHIJIT S. PANDYA </ADVISER>
<CLASSIFICATIONS> ARTIFICIAL INTELLIGENCE, PATTERN RECOGNITION </CLASSIFICATIONS>
<ABSTRACT>
Third-order synthetic neural networks are applied to the
recognition of isodensity facial images extracted from
digitized grayscale facial images. A key property of
neural networks is their ability to recognize
invariances and extract essential parameters from
complex high-dimensional data. In pattern recognition an
input image must be recognized regardless of its
position, size, and angular orientation. In order to
achieve this, the neural network needs to learn the
relationships between the input pixels. Pattern
recognition requires the nonlinear subdivision of the
pattern space into subsets representing the objects to
be identified. Single-layer neural networks can only
perform linear discrimination. However, multilayer first-
order networks and high-order neural networks can both
achieve this. The most significant advantage of a higher-
order net over a traditional multilayer perceptron is
that invariances to 2-dimensional geometric
transformations can be incorporated into the network and
need not be learned through prolonged training with an
extensive family of exemplars. It is shown that a third-
order network can be used to achieve translation-, scale-
, and rotation-invariant recognition with a significant
reduction in training time over other neural net
paradigms such as the multilayer perceptron. A model
based on an enhanced version of the Widrow-Hoff training
algorithm and a new momentum paradigm are introduced and
applied to the complex problem of human face recognition
under varying facial expressions. Arguments for the use
of isodensity information in the recognition algorithm
are put forth and it is shown how the technique of
coarse-coding is applied to reduce the memory required
for computer simulations. The combination of isodensity
information and neural networks for image recognition is
described and its merits over other image recognition
methods are explained. It is shown that isodensity
information coupled with the use of an "adaptive
threshold strategy" (ATS) yields a system that is
relatively impervious to image contrast noise. The new
momentum paradigm produces much faster convergence rates
than ordinary momentum and renders the network behaviour
independent of its training parameters over a broad
range of parameter values.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  3816 </NUMBER>
<ORDER>   AAG9637162 </ORDER>
<TITLE> IMAGE PROCESSING AND NEURAL NETWORKS </TITLE>
<AUTHOR> SHAO, WEI </AUTHOR>
<YEAR> 1996 </YEAR>
<INSTITUTION> UNIVERSITY OF SOUTH CAROLINA; 0202 </INSTITUTION>
<DESCRIPTORS> MATHEMATICS; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> RONALD A. DEVORE </ADVISER>
<CLASSIFICATIONS> WAVELETS, FEATURE EXTRACTION </CLASSIFICATIONS>
<ABSTRACT>
Two subjects were investigated in this thesis: image
processing and neural networks.
For image processing, we studied the applications of
wavelets to the following areas: image compression,
feature extraction, and image registration.
A survey of wavelets is contained in Chapter 1. Two
important applications of wavelets, image compression
and denoising, are studied in this Chapter.
Chapter 2 is devoted to image registration. Image
registration is one of the basic image processing
operations in remote sensing. With the increase in the
number of images collected every day from different
sensors, the automated registration of multi-
sensor/multi-spectral images has become a very important
issue.
A new algorithm for registering an image with an
arbitrary rigid body transformation is developed. This
algorithm consists of two phases: feature extraction and
feature matching.
Chapter 3 considers one of the most important
mathematical problems in theory of the neural networks:
the Complexity Problem. We approach the Complexity
Problem in two different contexts: linear or nonlinear.
(i) In linear approximation, we have obtained the
following result: A function from a Sobolev space can be
approximated with a neural network with a single hidden
layer with the optimal order for this class in the sense
of linear approximation. (ii) For nonlinear
approximation, we generalize a recent important result
of Andrew Barron for approximation in a Hilbert space.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  3817 </NUMBER>
<ORDER>   AAG9637127 </ORDER>
<TITLE> A MACHINE LEARNING APPROACH TO AUTOMATED CONSTRUCTION OF KNOWLEDGE BASES FOR EXPERT SYSTEMS FOR REMOTE SENSING IMAGE ANALYSIS WITH GIS DATA </TITLE>
<AUTHOR> HUANG, XUEQIAO </AUTHOR>
<YEAR> 1996 </YEAR>
<INSTITUTION> UNIVERSITY OF SOUTH CAROLINA; 0202 </INSTITUTION>
<DESCRIPTORS> GEODESY; REMOTE SENSING; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> JOHN R. JENSEN </ADVISER>
<CLASSIFICATIONS> NIL </CLASSIFICATIONS>
<ABSTRACT>
Knowledge-based remote sensing image analysis with GIS
data is acknowledged as a promising technique. However,
the difficulty in knowledge base construction, a well-
known bottleneck in building knowledge-based or expert
systems, impedes the adoption of this technique.
Automating knowledge base construction is therefore in
demand. This research presents a machine learning
approach to automated construction of knowledge bases
for remote sensing image analysis expert systems
incorporating GIS data. The methodology developed in
this research is based on inductive learning techniques
in machine learning, a subarea of artificial
intelligence. It involves training with examples from
remote sensing and GIS data, learning using the
inductive principles, decision tree generating, rule
generating from the decision tree, and knowledge base
building for an image analysis expert system. With this
method, building a knowledge base for a rule-based
expert system for remote sensing image analysis with GIS
data becomes much easier than with the traditional
knowledge acquisition approach. An operational image
expert system was also developed to test the usability
of the knowledge base generated by the proposed
approach. The expert system has been incorporated with
ERDAS IMAGINE, one of the most popular commercial image
processing systems. This method was used to construct a
knowledge base for wetland classification of Par Pond on
the Savannah River Site, South Carolina with SPOT image
and GIS data. To evaluate the proposed approach, four
classifications, i.e., the proposed machine-learning-
expert-system (MLES) with spectral and GIS data, the
MLES with only spectral data, the maximum likelihood
with spectral and GIS data, and unsupervised with only
spectral data, are conducted to classify wetland land
cover in Par Pond. The accuracy assessment and the
analysis of the resultant production rules suggest that
the knowledge bases built by the machine learning method
are of good quality for image analysis. The research
demonstrates that this method can provide an effective
approach to integration of remotely sensed and GIS data
in geographic information processing.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  3818 </NUMBER>
<ORDER>   AAG9636805 </ORDER>
<TITLE> PERSEUS: AN EXTENSIBLE VISION SYSTEM FOR HUMAN-MACHINE INTERACTION  </TITLE>
<AUTHOR> KAHN, ROGER EWING </AUTHOR>
<YEAR> 1996 </YEAR>
<INSTITUTION> THE UNIVERSITY OF CHICAGO; 0330 </INSTITUTION>
<DESCRIPTORS> COMPUTER SCIENCE; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> MICHAEL J. SWAIN </ADVISER>
<CLASSIFICATIONS> COMPUTER VISION, ARTIFICIAL INTELLIGENCE </CLASSIFICATIONS>
<ABSTRACT>
Interpersonal communication involves more than simply
spoken information. Gestures are commonly used to more
efficiently and precisely communicate. An important
gesture because of its descriptive power and frequency
of use is pointing. To produce a more natural and
powerful human-robot interface, a purposive visual
architecture called Perseus has been developed and used
to locate objects a person is pointing to.
In real-time, Perseus is able to determine when a person
enters the scene, track the relevant parts of the person
including the hands and head, and recognize when he is
pointing. Once the person points, the object pointed to
is located. The Perseus architecture allows knowledge
about the task and context to be used at all levels of
visual analysis for improved performance. This knowledge
is explicitly represented in the Perseus system to
facilitate the extension of Perseus to other tasks and
environments.
This thesis describes Perseus and how it is used to
solve this task. Experiments showing the success of the
Perseus system with numerous naive users in varied
environments is presented.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  3819 </NUMBER>
<ORDER>   AAG1385293 </ORDER>
<TITLE> VIBRATION CONTROL OF ROTOR-BEARING SYSTEMS USING NEURAL NETWORKS </TITLE>
<AUTHOR> SIDDIQUI, MOHSIN </AUTHOR>
<YEAR> 1996 </YEAR>
<INSTITUTION> KING FAHD UNIVERSITY OF PETROLEUM AND MINERALS (SAUDI ARABIA); 1088 </INSTITUTION>
<DESCRIPTORS> ENGINEERING, MECHANICAL; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> NIL </ADVISER>
<CLASSIFICATIONS> NIL </CLASSIFICATIONS>
<ABSTRACT>
A neural network controller is described and implemented
for controlling the vibrations of a Rotor Bearing
System. A multi-layered neural network is used to model
the inverse dynamics of the rotor-bearing system on-
line; it is learned by backpropagation algorithm, and
delta rule in which the difference between the actual
control input to the plant, which is generated from the
neural controller, and the input estimated from the
inverse-dynamics model by using an actual plant output
is minimized. The results show a satisfactory diminished
response of the rotor-bearing system when the controller
is applied to the system.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  3820 </NUMBER>
<ORDER>   AAG9729762 </ORDER>
<TITLE> A PREDICTABLE AND INFERABLE COGNITION SYSTEM USING A CONNECTIONIST MODEL  </TITLE>
<AUTHOR> WU, CIHIJUIA </AUTHOR>
<YEAR> 1996 </YEAR>
<INSTITUTION> ILLINOIS INSTITUTE OF TECHNOLOGY; 0091 </INSTITUTION>
<DESCRIPTORS> PSYCHOLOGY, COGNITIVE; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> JAMES KENEVAN; DOUGLAS J. CORK </ADVISER>
<CLASSIFICATIONS> NEURAL NETWORK, PAST EXPERIENCE </CLASSIFICATIONS>
<ABSTRACT>
How do humans proceed to the next cognitive step. When
humans have a problem to solve, the most efficient
solution may derive from past experience.
In order to arrive at a solution using the connectionist
approach, four systems must be addressed via algorithm
and analysis. (1) The first system is comprised of a
neural network. The neural network that can learn during
its learning phase and generate a class during its
generating phase uses unsupervised learning. This type
of network possesses predictable capability in
classification. The system infers a conclusion if the
input data's attribute relates closely to the event. (2)
The second system is a rule-based system translated from
the traditional production rule (PROLOG-notion) to a
neural network. The system uses supervised learning. The
top layer of the system is based on the "winner-take-
all" neural network which provides embedded probability.
(3) The third system is dynamic in nature with
attributes that can be deleted, modified, or added to by
changes in the environment. (4) The final system
displays the actions using recurrent back-propagation.
State space consists of these actions and every action
that has been trained uses the recurrent back-
propagation model. The system uses recurrent back-
propagation to simulate a finite-state-machine
construction for each action.
This thesis focuses on a method that can automatically
infer a solution based on attributes of the current
environment. For knowledge representation, the
production rule (PROLOG) will be translated into neural
network. For knowledge extraction, the Discovering
Predictable Classification (DPC) concept will be
included as an address to fetch methods from rule-based
system. For modification rule-based system, variable
attributes must be input, then bottom-up method will be
used to transport its node and alter its weight and
threshold. When a good method is found, the action must
be fired from state space because state space has stored
many actions that can simulate a finite-state-machine.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  3821 </NUMBER>
<ORDER>   AAG9636679 </ORDER>
<TITLE> LEARNING IN FIXED-WEIGHT RECURRENT NEURAL NETWORKS </TITLE>
<AUTHOR> YOUNGER, ARTHUR STEVEN </AUTHOR>
<YEAR> 1996 </YEAR>
<INSTITUTION> THE UNIVERSITY OF UTAH; 0240 </INSTITUTION>
<DESCRIPTORS> COMPUTER SCIENCE; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> NIL </ADVISER>
<CLASSIFICATIONS> ARTIFICIAL INTELLIGENCE, MACHINE LEARNING </CLASSIFICATIONS>
<ABSTRACT>
Conventional artificial neural networks perform
functional mappings from their input space to their
output space. The synaptic weights encode the
information about how to perform the mapping in a manner
analogous to long term memory in biological systems.
This dissertation presents a method of designing neural
networks where recurrent signal loops store this
knowledge in a manner similar to short-term memory in
biology. The fixed synaptic weights of these networks
encode a learning algorithm. This gives these networks
the ability to dynamically learn any functional mapping
from a (possibly very large) set of mappings, without
changing any synaptic weights. This method is named
fixed-weight learning. These networks are adaptive.
Learning is continually taking place as part of the
network's overall behavior, instead of a separate,
externally driven process. Fixed-weight learning should
have advantages for certain VLSI and optical neural
network implementations, where changing the synaptic
weights is particularly problematic. Designs are
presented for four higher-order, fixed-weight learning
networks. Two of these networks have the standard
Backpropagation learning algorithm embedded in their
synaptic weights, and two have more efficient modified
Gradient descent based learning methods. I present
empirical tests showing that these networks were able to
successfully learn functions from both discrete
(Boolean) and continuous function sets. Finally, I
discuss implementation considerations, such as
tolerances of synaptic weights and numerical precision
required for good network performance.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  3822 </NUMBER>
<ORDER>   AAG9636479 </ORDER>
<TITLE> A HYBRID DECISION SUPPORT SYSTEM FOR AUTOMATED EGG GRADING  </TITLE>
<AUTHOR> PATEL, VIRENKUMAR C. </AUTHOR>
<YEAR> 1996 </YEAR>
<INSTITUTION> UNIVERSITY OF GEORGIA; 0077 </INSTITUTION>
<DESCRIPTORS> ENGINEERING, AGRICULTURAL; ARTIFICIAL INTELLIGENCE; COMPUTER SCIENCE </DESCRIPTORS>
<ADVISER> RONALD W. MCCLENDON </ADVISER>
<CLASSIFICATIONS> ARTIFICIAL INTELLIGENCE, NEURAL NETWORKS, COMPUTER VISION </CLASSIFICATIONS>
<ABSTRACT>
The processing of poultry eggs for human consumption has
four major steps--collecting, washing, grading, and
packaging. The collecting, washing, and packaging steps
have been mechanized. However, the egg grading step, in
which eggs are inspected for defects such as blood
spots, cracks, and dirt stains, is still done manually.
Typically, a grader must inspect a dozen eggs per second
and make decisions on whether to allow an egg to pass,
reject and remove it, or send it to be rewashed. This
leads to overpull, where good eggs are graded as
defective, and underpull where defective eggs are
undetected. Automation of the egg grading process is
desirable since it promises to help control costs,
reduce the work load on graders, and improve the quality
control process.
Neural network models were developed to identify eggs
with defects using gray scale images. A gray scale
computer vision system was used to obtain images of
grade A eggs and eggs with a single type of defect.
Image histograms based on the intensity level were
constructed. For each type of egg defect, a neural
network model was developed using the histograms of eggs
with the defect and eggs without that defect. The neural
networks were tested and validated on independent data
sets. Accuracies of 85.6%, 90.0%, and 80.0% were
achieved by the blood spot, crack, and dirt stain
detection neural networks, respectively. The blood spot
and crack detection neural networks were able to produce
graded samples that would exceed the USDA's
requirements. The dirt stain neural network was not able
to meet the USDA's specifications.
Other neural networks were developed using color images
of eggs. A similar approach was used in developing
neural networks with a color computer vision system as
with the gray scale system. The use of a color computer
vision system improved the accuracy of the neural
networks. The accuracies were 92.8%, 87.8% and 85.0%,
for blood spots, cracks, and dirt stains, respectively.
These accuracy levels were sufficient to produce graded
samples that would pass USDA inspections.
An expert system was developed to sort eggs into use-
based categories. The expert system used the outputs of
the neural networks to make sorting decisions. Variable
thresholds influenced the sorting decisions of the
expert system. Experiments with different threshold
settings were performed. Lower threshold settings could
be used to obtain high quality eggs. This also resulted
in more eggs being rewashed, inspected, or rejected.
Higher threshold values reduced the number of eggs
sorted for rewashing, inspection, or rejection. The
threshold variables provided the capability to implement
desired sorting policies. The expert system demonstrated
significant potential to reduce the work load on human
graders.
The color computer vision system, the neural networks,
and the expert system formed integral parts of a
decision support system for grading eggs. The decision
support system was successfully implemented and
demonstrated.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  3823 </NUMBER>
<ORDER>   AAG9636363 </ORDER>
<TITLE> THE APPLICATION OF INDUCTIVE LEARNING IN SIMULATION OF QUEUING SYSTEMS  </TITLE>
<AUTHOR> PARISAY, SIMA </AUTHOR>
<YEAR> 1996 </YEAR>
<INSTITUTION> UNIVERSITY OF SOUTHERN CALIFORNIA; 0208 </INSTITUTION>
<DESCRIPTORS> ENGINEERING, INDUSTRIAL; ARTIFICIAL INTELLIGENCE; ENGINEERING, SYSTEM SCIENCE </DESCRIPTORS>
<ADVISER> NIL </ADVISER>
<CLASSIFICATIONS> DECISION SUPPORT, ID3 ALGORITHMS </CLASSIFICATIONS>
<ABSTRACT>
Expert systems may be used for enhancing the
applicability of computer simulation as a decision
support tool. This could assist in the process of
simulation model modification and refinement which would
achieve a set performance goals for the system under
study. Machine learning can be applied as an effective
method for extracting heuristic rules to support the
knowledge base of such an expert system.
In this research, the effectiveness of inductive
learning, more specifically the family of ID3
algorithms, was studied to obtain the required rules.
This tool was tailored for output analysis of a
simulated queuing system. Several examples of the
system, referred to as instance-sets, are required for
learning. Each instance is represented by its class and
by several control-features of the system.
This research initially focused on control-feature
engineering in queuing system simulation. Later, the
focus was on artificial instance generation for the
required instance-set. It is shown that the generation
of the required instance-set is a complex search
problem. An automatic instance generation procedure is
proposed which assists in generating suitable instance-
sets in the absence of realistic instances. The proposed
procedure is a combination of the three search methods
of grid base, forward search, and backward search.
Experiments were initially performed on those examples
of a M/M/1 queuing system for which enough information
to validate the experiment progress and final results
was available. Later, experiments with a two-serial-
server queuing system are used to generalize the
findings to some extent.
This report shows that in general the induction tree
algorithm generated prediction-rules that were effective
in the output analysis of the queuing systems under
study. Also, the designed control-features for the
queuing system indicated no preference over the common
control-features. The proposed automatic instance
generation procedure has been suitable for this
research, and it could be updated to match similar
situations. The results further suggest that inductive
learning can be considered as a suitable alternative to
knowledge acquisition for expert systems that are used
in the analysis of simulation output.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  3824 </NUMBER>
<ORDER>   AAG0577597 </ORDER>
<TITLE> COMBINING PRIOR KNOWLEDGE AND NONPARAMETRIC MODELS OF CHEMICAL PROCESSES  </TITLE>
<AUTHOR> THOMPSON, MICHAEL LEWIS </AUTHOR>
<YEAR> 1996 </YEAR>
<INSTITUTION> MASSACHUSETTS INSTITUTE OF TECHNOLOGY; 0753 </INSTITUTION>
<DESCRIPTORS> ENGINEERING, CHEMICAL; STATISTICS; ENGINEERING, SYSTEM SCIENCE </DESCRIPTORS>
<ADVISER> MARK A. KRAMER </ADVISER>
<CLASSIFICATIONS> PROCESS MODELING </CLASSIFICATIONS>
<ABSTRACT>
Modeling is an important task in all fields that benefit
from quantitative descriptions of the systems being
studied. These fields include engineering, the sciences,
applied mathematics and econometrics; all of which
require accurate models despite the complexity and
uncertainty inherent in the problems they address. In
particular, engineers and scientists in the chemical
process and biotechnology industries must often resolve
problems complicated by the underlying biological,
chemical, and physical phenomena. Additionally, the
process data are often sparse and corrupted by noise,
sensor faults and missing values. This inherent
uncertainty prevents a modeler from synthesizing
accurate models solely from first principles.
Consequently, development is often limited to only a
partial specification of the underlying phenomena. The
resulting models may not be robust enough to satisfy the
demands of many systems engineering applications such as
process control, design and optimization.
This thesis presents a probabilistic approach for
synthesizing robust models despite the uncertainty
present in complex systems typical of the chemical,
biotechnology, and petroleum industries. By applying
probability theory, the methodology unifies advances in
artificial intelligence, e.g., radial basis function
neural networks, with statistical methods. This allows a
modeler to combine prior knowledge of first principles
with flexible models derived from data (i.e.,
nonparametric models). Importantly, the thesis also
presents the implementation of the methodology as a
computationally efficient suite of computer routines
that performed well in predicting process behavior
despite the existence of unmeasured variables and
corrupted data.
At the heart of this approach is the uniform
representation of knowledge as probability density
functions. Probability density functions (pdfs) are
capable of capturing the full range of knowledge about a
quantity from absolute certainty to complete ignorance.
This thesis identifies the appropriate pdfs for the
domain or chemical process modeling and formulates the
general state estimation problem in a decision theoretic
framework. This general framework expresses the systems
engineering tasks of state prediction, data
rectification, and fault diagnosis as siblings descended
from the same state estimation family tree.
Despite the concise problem formulation, finding the
optimal estimate of the state remains a difficult task
because of the mathematical complexity of the pdfs
involved. However, this thesis proposes approximating
pdfs by finite mixtures of normal distributions and
using techniques such as expectation-maximization (EM)
to solve the resulting Bayesian estimation problem.
Additionally, it is shown that the framework justifies
an empirically motivated approach that synthesizes
hybrid models combining radial basis function neural
networks and first principles. This hybrid approach is
shown to be an approximation to a special case derived
from the probabilistic framework. This helps explain the
hybrid approach's good performance in practical
applications.
The results have been promising. The methodology has
been successfully applied in modeling fed-batch
penicillin fermentation and vinyl acetate
polymerization. The synthesized models have been more
accurate and more robust, hence reliable, than models
synthesized from either first principles alone or
completely nonparametric (fully data-derived) models. In
light of these positive results, broader usage of this
probabilistic paradigm for systems engineering is
advocated. (Copies available exclusively from MIT
Libraries, Rm. 14-0551, Cambridge, MA 02139-4307. Ph.
617-253-5668; Fax 617-253-1690.)
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  3825 </NUMBER>
<ORDER>   AAGNN11077 </ORDER>
<TITLE> INDUCTIVE LEARNING WITH THE EVOLVING TREE TRANSFORMATION SYSTEM  </TITLE>
<AUTHOR> KAMAT, VITHAL NARASINHA </AUTHOR>
<YEAR> 1996 </YEAR>
<INSTITUTION> THE UNIVERSITY OF NEW BRUNSWICK (CANADA); 0823 </INSTITUTION>
<DESCRIPTORS> COMPUTER SCIENCE; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> V. C. BHAVSAR; L. GOLDFARB </ADVISER>
<CLASSIFICATIONS> HANDWRITING </CLASSIFICATIONS>
<ABSTRACT>
Inductive learning is one of the more difficult problems
in artificial intelligence. Here, inductive learning is
treated as an optimization process, the (last) state of
generalization of which is characterized by the
discovery of the class concept. The role of the
structure inherently present, both, in the objects and
the class concept has been underplayed in much of the
learning tasks today. This thesis attempts to highlight
the importance of structure in representation by
generating a new ordered labeled (symbolic) tree
representation and in learning by using these trees in a
new learning machine (LM) based on the Evolving Tree
Transformation System (ETTS) model.
The ETTS model is an adaptation of the general inductive
learning model called by Goldfarb an Evolving
Transformation System (ETS), to an environment in which
objects are represented as trees. The central concept of
the ETTS model is a tree distance function that is
defined on a set of ordered labeled trees in terms of
weighted generalized edit operations. Transformation of
one tree into another is made possible through these
operations. An edit operation along with its weight is
called a feature. A class concept is an optimal set of
features that give suitable distances for the best class
separation measured in terms of an optimization
function.
An ETTS model based LM that can perform handwritten
character recognition has been designed. The LM consists
of two main algorithms--a generalized edit operations
based tree Distance Algorithm (DA) and a Learning
Algorithm (LA). A reprocessing algorithm has also been
developed that accepts handwritten characters and feeds
symbolic trees to the LM. The symbolic trees are
isomorphic to (preserve the structure of) the characters
unlike many other representations.
A dynamic programming styled DA that runs in polynomial
time and space and that is amenable to parallelization
has been built. The generalized edit operations in DA
refer to elementary operations that operate on a single
node and also to macro operations that operate on
multiple node subtrees.
The nature of the optimization function is studied to
build a simple and reliable LA that essentially
optimizes weights and builds new features. The role of
weights and the need for optimizing weights associated
with the tree edit operations is fully realized in this
thesis for the first time. The process of building new
macro features (consisting of macro operations) and
adding them to the earlier set of features is own to
give the class concept if the earlier set is incapable
of doing so.
The LA is shown to successfully learn with small
training sets. The unification of the discrete
(symbolic) tree structure with the continuous weights
gives the concept the ability to describe the class in a
compact and powerful form. The weights in the concept
provides the necessary robustness and noise tolerance.
The symbolic tree structure in the concept provides the
necessary descriptive power to communicate in language
that the external agent understands. By storing the
concept rather than the instances of a class, the LM is
shown to achieve parsimony in storage space and
retrieval time.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  3826 </NUMBER>
<ORDER>   AAGNN10912 </ORDER>
<TITLE> PERCEPTION-BASED ALGORITHMS AND ANALYSIS </TITLE>
<AUTHOR> YIN, HONGFENG </AUTHOR>
<YEAR> 1996 </YEAR>
<INSTITUTION> CONCORDIA UNIVERSITY (CANADA); 0228 </INSTITUTION>
<DESCRIPTORS> COMPUTER SCIENCE; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> STAN KLASA </ADVISER>
<CLASSIFICATIONS> OJA, WIDROW HOFF, NEURAL NETWORKS </CLASSIFICATIONS>
<ABSTRACT>
An unsupervised Perceptron algorithm and several of its
generalizations are proposed in this thesis. Under some
conditions, it is proved that the unsupervised
Perceptrons converge to the first principal component of
the input data. Also, the convergence speed, robustness,
bias and variance of a neural network learning algorithm
are defined and analyzed. The learning performances of
the unsupervised Perceptron algorithms, the Oja learning
algorithms and the Widrow-Hoff learning algorithm are
analyzed. Some simulation results and comparisons are
provided. A tree classifier based on the unsupervised
Perceptrons is given and applied to Chinese character
recognition. In addition, an asymmetric associative
memory network is proposed using the Perceptron learning
algorithm. A deepening impression method is given to
enhance the performance of the associative memory.
Moreover, the back-propagation algorithm is improved for
pruning the hidden neurons in a three layered neural
network.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  3827 </NUMBER>
<ORDER>   AAGNN09932 </ORDER>
<TITLE> VERS UNE MEETHODOLOGIE INTEGREE D'ANALYSE DE SURETE DE FONCTIONNEMENT DES SYSTEMES MANUFACTURIERS AUTOMATISES </TITLE>
<AUTHOR> BOUTI, ABDELKADER </AUTHOR>
<YEAR> 1996 </YEAR>
<INSTITUTION> UNIVERSITE LAVAL (CANADA); 0726 </INSTITUTION>
<DESCRIPTORS> ENGINEERING, MECHANICAL; ENGINEERING, INDUSTRIAL </DESCRIPTORS>
<ADVISER> DAOUD AIT-KADI </ADVISER>
<CLASSIFICATIONS> FRENCH TEXT, AUTOMATED MANUFACTURING, IDEFO, OBJECT- ORIENTED, DEPENDABILITY </CLASSIFICATIONS>
<ABSTRACT>
This thesis deals with the problem-solving of the
automated manufacturing systems (AMSs) modeling and
dependability analysis. To model and to understand the
normal operation of a given AMS, a multi-model approach
centered on a new technique called O$sp2$IDEFO (for
Object-Oriented IDEFO) was developed. O$sp2$IDEFO is
based on the concept of generic function (issued from
the artificial intelligence area) and on the concepts of
Object-Oriented modeling (specifically, the Coad and
Yourdon method). In addition to allowing the
representation of the structuro-functional view of a
given AMS, it contributes to the build-up of other
system views. To highlight this statement, we propose a
procedure for the generation of an extended Petri net
based behavioral model from an O$sp2$IDEFO
representation.
The second part of this thesis concerns the
investigation of the AMS failures. In this text, we
propose a qualitative approach allowing to infer on the
AMS simple failures and frequently to conduct the FMECA-
Process. The results are compiled using a new FMECA form
called 'FMECA-House'. On the other side, the
contribution of an O$sp2$IDEFO model to the elaboration
of other dependability analysis methods especially the
digraph technique is highlighted. The FMECA, the digraph
and other techniques do not ensure exhaustivity and
completeness. Consequently, we propose an integrated and
intelligent methodology of AMSs dependability analysis
(named MIAS$sp2$ for Methodologie Integree d'Analyse de
Surete de fonctionnement des Systemes manufacturiers
automatises'). The MIAS$sp2$ integrates different
techniques of a system normal operation understanding
and dependability analysis. It can be used during the
different life cycle phases of the AMS. Its results can
be exploited by other engineering activities such as:
diagnostic, maintenance, and quality control.
The third part of this thesis deals with the application
of the MIAS$sp2$ to a mould components manufacturing and
assembly cell.
Finally, an appendix is dedicated to the MIAS$sp2$
automation. For this purpose we discuss a conceptual
intelligent framework based on a blackboard
architecture.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  3828 </NUMBER>
<ORDER>   AAG9639234 </ORDER>
<TITLE> A MODEL OF THE CONSTRUCTION AND PRAXIS OF THE EPISTEMOLOGICAL MATHEMATICAL SYSTEM OF A MATHEMATICS CHILD PRODIGY </TITLE>
<AUTHOR> FITZSIMMONS, JAMES ALAN </AUTHOR>
<YEAR> 1996 </YEAR>
<INSTITUTION> THE OHIO STATE UNIVERSITY; 0168 </INSTITUTION>
<DESCRIPTORS> EDUCATION, EDUCATIONAL PSYCHOLOGY; EDUCATION, PSYCHOLOGY; EDUCATION, MATHEMATICS </DESCRIPTORS>
<ADVISER> PATRICIA A. BROSNAN </ADVISER>
<CLASSIFICATIONS> NIL </CLASSIFICATIONS>
<ABSTRACT>
This research is a case study of a mathematics child
prodigy. Its aim is to answer three questions: "How does
the participant child prodigy explain mathematics and
mathematical thought?" "How does the participant child
prodigy think about mathematics and learn mathematics?"
and "Is there sufficient evidence to corroborate the
proposed epistemological model (or a modification of
it)?" The research involved four years of mathematical
contact with a mathematics child prodigy and included
videotaped mathematics mentoring sessions with the
participant; audiotaped interviews with parents,
teachers, and professors; and mathematical writing,
journal entries, and other data involved in some way.
The study has found that the best explanations of the
participant's mathematics and mathematical thought came
from his written solutions and proofs and from his oral
explanations and answers to questioning. It was observed
that he was better able to explain his mathematics and
mathematical thought when he was asked for explanations
or verifications than he was when asked for a "proof,"
which seemed intimidatingly formal.
A proposed model of mathematical knowledge acquisition
and use is at the core of the research and has evolved
throughout the study. The final form of this learning
theory model is described here. The child prodigy
participant constructed his own mathematical systems
consisting of knowledge graphs (information processing
knowledge representations based upon graph theory and
artificial intelligence state spaces). He then made use
of these knowledge graphs through problem-solving search
strategies similar to those employed with artificial
intelligence state spaces (e.g., depth-first search).
Three sets of factors were seen to affect both the
construction and use of the knowledge graphs.
Motivation, energy, and focus provided the impetus for
the participant's mathematics. Organization and memory
facilitated the structure of the mathematical system.
Unconstrained mathematics contributed to his creativity
and the nonstandard ways in which he constructed and
used mathematics.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  3829 </NUMBER>
<ORDER>   AAG9636477 </ORDER>
<TITLE> INTELLIGENT REDUCTION METHODS FOR SOLVING NETWORK FLOW MODELS  </TITLE>
<AUTHOR> NEMATI, HAMID REZA </AUTHOR>
<YEAR> 1996 </YEAR>
<INSTITUTION> UNIVERSITY OF GEORGIA; 0077 </INSTITUTION>
<DESCRIPTORS> ECONOMICS, COMMERCE - BUSINESS; ECONOMICS, COMMERCE- BUSINESS; OPERATIONS RESEARCH; ENGINEERING, INDUSTRIAL; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> JAY E. ARONSON </ADVISER>
<CLASSIFICATIONS> ARTIFICIAL INTELLIGENCE </CLASSIFICATIONS>
<ABSTRACT>
Network flow models have many practical applications
which arise in a wide range of physical settings. Some
of the more familiar examples include the distribution
of products from factories to warehouses, production
planning aircraft re-routing and building evacuation
models. The capacitated pure network flow problems (NFP)
are the most fundamental of all network flow models.
Since most of these applications are time sensitive,
when constructing network flow models to solve real
world problems, the emphasis has not only been on
keeping such models tractable but also to achieve a
solution in a timely manner.
This dissertation describes the development and
implementation of two efficient methods, TABUNET and
STEEPNET, for solving the capacitated pure network flow
problems. The methods combine the redundancy and
reduction concepts with Tabu Search (TS) to solve an NFP
by reducing its active problem size. Both algorithms
begin by solving, to optimality, a Reduced NFP (RNP)
consisting of all the nodes of the original NFP and a
small subset of its arcs. The optimum value of this RNP
gives an upper bound to the optimum objective value to
the original NFP. Tabu Search (TS) is used to construct
a candidate list of arcs, whose corresponding dual
constraints violate the solution of the current RNP,
that can potentially be added to the RNP. A portion of
the arcs in the candidate list is added to the RNP,
which is then re-solved. Once all arcs in the candidate
list are added to the RNP, a new candidate list is
constructed. This TS candidate list strategy continues
until no such candidate lists can be constructed at
which time the algorithm terminates.
In this dissertation, two different methods for
constructing the candidate lists are described and
implemented. Since these methods intelligently reduce
the dimensionality of the NFP, they significantly reduce
the number of pivots required to solve the network flow
problem. As a result, substantial reductions in the
total solution CPU time are achieved. Numerical tests on
a set of benchmark problems indicate that computational
performance of both methods are far superior to that of
the standard network simplex implementation.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  3830 </NUMBER>
<ORDER>   AAG9636359 </ORDER>
<TITLE> KNOWLEDGE-BASED ORGANIZATIONAL PROCESS REDESIGN: USING PROCESS FLOW MEASURES TO TRANSFORM PROCUREMENT </TITLE>
<AUTHOR> NISSEN, MARK ERIK </AUTHOR>
<YEAR> 1996 </YEAR>
<INSTITUTION> UNIVERSITY OF SOUTHERN CALIFORNIA; 0208 </INSTITUTION>
<DESCRIPTORS> BUSINESS ADMINISTRATION, MANAGEMENT; ENGINEERING, INDUSTRIAL; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> WALT SCACCHI </ADVISER>
<CLASSIFICATIONS> REENGINEERING </CLASSIFICATIONS>
<ABSTRACT>
Business Process Reengineering represents a pervasive
and important phenomenon in the fast-paced global
economy, and has become an area of active interest and
research in academics. However, reengineering in
practice has been consultant-driven and problematic, as
process redesign is only just beginning to advance from
mysterious art to a learnable craft, much less an
explainable, predictable, and replicatable science.
The focus of this dissertation research is upon the
advancement of reengineering toward a science, with
express objectives of increasing the explainability,
predictability, and replicatability of process redesign,
and alleviating practitioners' dependence upon the ever-
growing external consulting industry. This research
begins with a focused review of the reengineering
literature. I also draw from a number of useful
reference disciplines (e.g., Accounting, Artificial
Intelligence, Industrial Engineering, Organizational
Design) and an emerging Theory of Articulation to
develop a model of organizational processes and their
redesign through process transformation.
Operationalization is accomplished in a manner that
enables computer-based representation and automated
measurement of organizational processes, and substantial
redesign knowledge is formalized in terms of a rulebase
suitable for incorporation into a production system.
These theory-building activities culminate in the
logical design of a knowledge-based system for
"intelligent" redesign support (named KOPeR).
The military procurement process is then selected for
model instantiation and validation, and a multiple case
study design is used to guide field research at two Navy
procurement sites in Southern California. The field
research also includes a funded action component, as the
model is employed to guide the redesign of three Navy
procurement processes.
Results from this field research include the diagnosis
of five, serious shortcomings and flaws in the
procurement process, and the induction of several domain-
dependent and instance-specific process flow measures
with strong diagnostic performance. The model also
proves to be effective in terms of both explanation and
prediction, and knowledge gained through its usage
provides fresh evidence to dispel a number of myths and
misconceptions that are prevalent in the practice of
process redesign. This investigation also sets forth an
agenda for future research along these lines.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  3831 </NUMBER>
<ORDER>   AAG9729743 </ORDER>
<TITLE> AN END-USER DEVELOPMENT SYSTEM FOR BAYESIAN DECISION SUPPORT SYSTEMS THAT ESTIMATE PROBABILITIES FROM DATABASES </TITLE>
<AUTHOR> CHANG, LI-JEN </AUTHOR>
<YEAR> 1996 </YEAR>
<INSTITUTION> ILLINOIS INSTITUTE OF TECHNOLOGY; 0091 </INSTITUTION>
<DESCRIPTORS> COMPUTER SCIENCE; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> MARTHA W. EVENS </ADVISER>
<CLASSIFICATIONS> EXPERT SYSTEM, MACHINE LEARNING </CLASSIFICATIONS>
<ABSTRACT>
This research has three purposes. One is to build a
software system that allows the end user to develop a
Bayesian decision support system that estimates
probabilities from the actual data. The second is to use
this system and a data set to build a knowledge base and
then test the knowledge base and the system's Bayesian
inference engine on the same data. The third is to
compare the classification performance between the
proper Bayesian approach and the simple Bayesian
approach.
The major problem of applying Bayes' Theorem to solve
real-world problems is that substantial number of
probabilities are needed, but these probabilities are
hard to obtain. Although subjective probabilities have
been used as an alternative, they are almost always
biased and give unsatisfactory results. Research has
shown that estimating probabilities from the actual data
objectively is not only feasible but also helps people
make better decisions. Recent computer technologies such
as Online Analytical Processing, Data Warehousing, Data
Mining, and Knowledge Discovery in Databases make
probability estimation from actual data easier and
better. However, there are some technical issues such as
data storage, database accessibility, availability of
the probability acquisition system, the Bayesian
inference engine, and the explanation facility. These
make the process of converting the raw data into
knowledge for Bayesian inference difficult, inefficient,
and often unsuccessful. Existing software systems also
do not provide the environment for the end user to
implement Bayesian inference for their classification
problems.
We have developed methods for data modeling, user
interfaces, a new knowledge representation scheme called
the E-F pattern, knowledge acquisition, knowledge
retrieval, mathematical and textual explanation
approaches, proper and simple Bayesian approaches, and
data visualization. Two data sets are used to build
knowledge bases. One data set is used to analyze and
compare the error rates of the two Bayesian approaches.
These methods have been used to build and test a working
data mining system.
We have also used our system to explore the difference
between simple and proper Bayesian classification. Our
proper Bayesian system showed an error rate of only 10%
compared to 50% for the simple Bayesian classification.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  3832 </NUMBER>
<ORDER>   AAGC521547 </ORDER>
<TITLE> THE INFORMATICAL WORLD VIEW: AN INQUIRY INTO THE METHODOLOGY OF COMPUTER SCIENCE </TITLE>
<AUTHOR> JONGENEEL, CHRISTIAN JAN BASTIAAN </AUTHOR>
<YEAR> 1996 </YEAR>
<INSTITUTION> TECHNISCHE UNIVERSITEIT TE DELFT (THE NETHERLANDS); 0951 </INSTITUTION>
<DESCRIPTORS> COMPUTER SCIENCE; INFORMATION SCIENCE; PHILOSOPHY BOX 513, EH 8.28,  NL-5600 M.B. EINDHOVEN, THE NETHERLANDS </DESCRIPTORS>
<ADVISER> NIL </ADVISER>
<CLASSIFICATIONS> NATURAL SOLVERS, ARTIFICIAL INTELLIGENCE </CLASSIFICATIONS>
<ABSTRACT>
The thesis argues that on the abstract level three
different attitudes towards information exist, named
instructionism, inventionism and adaptivism. These three
attitudes have evolved during three cultural-
psychological stages in human history: primitive,
oriental and occidental. The main appearances of the
three are: natural language, mathematics and physics.
The limits of the validity of these three has been
explored by Wittgenstein, Godel and Heisenberg/system
theory.
In computer science the three attitudes can be tracked
as well, namely in imperative programming languages,
declarative programming languages and natural solvers
(neural networks, genetic algorithms). Moreover, the
philosophical dilemmas attached to these computer
methods may be linked to the considerations of
Wittgenstein, Godel and system theory. Hence it is
argued that the information handling methods of
computers are not isolated, but rather directly derived
from broader human methods of information handling.
Within this framework a deeper investigation is made of
general system theory, especially the relation between
natural and artificial systems. It is argued that
artificial systems by definition need control. This may
be a decisive problem when trying to simulate natural
systems on (parallel) computers. Therefore it is better
to exploit available knowledge and concentrate on hybrid
methods which combine (for instance) natural solvers and
expert systems.
In passing, it is argued that Godel's theorem is a
special case of Wittgenstein's theorem, extensions are
given of Lucas's and Searle's arguments on artificial
intelligence, the nature-nurture controversy is claimed
to be deceptive, and a general theory of natural solvers
is sketched.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  3833 </NUMBER>
<ORDER>   AAGC519670 </ORDER>
<TITLE> TOPOGRAPHIC MAPPINGS AND FEEDFORWARD NEURAL NETWORKS </TITLE>
<AUTHOR> TIPPING, MICHAEL E. </AUTHOR>
<YEAR> 1996 </YEAR>
<INSTITUTION> ASTON UNIVERSITY (UNITED KINGDOM); 0734 </INSTITUTION>
<DESCRIPTORS> COMPUTER SCIENCE; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> NIL </ADVISER>
<CLASSIFICATIONS> NIL </CLASSIFICATIONS>
<ABSTRACT>
This thesis is a study of the generation of topographic
mappings--dimension reducing transformations of data
that preserve some element of geometric structure--with
feed-forward neural networks.
As an alternative to established methods, a
transformational variant of Sammon's method is proposed,
where the projection is effected by a radial basis
function neural network. This approach is related to the
statistical field of multidimensional scaling, and from
that the concept of a 'subjective metric' is defined,
which permits the exploitation of additional prior
knowledge concerning the data in the mapping process.
This then enables the generation of more appropriate
feature spaces for the purposes of enhanced
visualisation or subsequent classification.
A comparison with established methods for feature
extraction is given for data taken from the 1992
Research Assessment Exercise for higher educational
institutions in the United Kingdom. This is a difficult
high-dimensional dataset, and illustrates well the
benefit of the new topographic technique.
A generalisation of the proposed model is considered for
implementation of the classical multidimensional scaling
(CMDS) routine. This is related to Oja's principal
subspace neural network, whose learning rule is shown to
descend the error surface of the proposed $rm Csb0MDS$
model.
Some of the technical issues concerning the design and
training of topographic neural networks are
investigated. It is shown that neural network models can
be less sensitive to entrapment in the sub-optimal
global minima that badly affect the standard Sammon
algorithm, and tend to exhibit good generalisation as a
result of implicit weight decay in the training process.
It is further argued that for ideal structure retention,
the network transformation should be perfectly smooth
for all inter-data directions in input space.
Finally, there is a critique of optimisation techniques
for topographic mappings, and a new training algorithm
is proposed. A convergence proof is given, and the
method is shown to produce lower-error mappings more
rapidly than previous algorithms.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  3834 </NUMBER>
<ORDER>   AAGC514033 </ORDER>
<TITLE> A NOVEL DESIGN FOR A TACTILE SENSOR WITH MATHEMATICAL MODELLING AND DATA INTERPRETATION USING NEURAL NETWORKS </TITLE>
<AUTHOR> SINGH, RANJIT </AUTHOR>
<YEAR> 1996 </YEAR>
<INSTITUTION> COVENTRY UNIVERSITY (UNITED KINGDOM); 1201 </INSTITUTION>
<DESCRIPTORS> ENGINEERING, ELECTRONICS AND ELECTRICAL; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> NIL </ADVISER>
<CLASSIFICATIONS> NIL </CLASSIFICATIONS>
<ABSTRACT>
The work presented in this dissertation considers the
problem of tactile sensing in the field of robotics. We
have proposed a novel tactile sensor design based on
magnetic field effect which can measure both the normal
and shear forces. The sensor design makes use of an
array of thin magnetic sheets embedded in a compliant
layer. The distribution of field patterns due to thin
square magnetic sheets both singularly and in arrays
obtained by modelling the magnetic sheet as a square
coil is presented. With these results, the feasibility
of the proposed tactile sensor design strategy is
examined. The predictions made by the square coil model
calculations are then compared with the measurements
made on a thin sheet of a magnetised material embedded
in a rubber pad. The response of this rubber pad
subjected to various combinations of normal and shear
forces is also discussed.
The use of analogue neural networks is shown: (1) to
solve the "inverse problem" of tactile sensing from the
values of normal strain and displacements for
cylindrical, flat and wedge indenters, (2) for
recognising the objects in contact with the tactile
sensor from its characteristic surface stress
distribution pattern. The functioning of the analogue
neural networks is demonstrated by using a set of normal
displacements generated from the finite element analysis
of a compliant layer of finite dimensions in contact
with cylindrical, flat and wedge type indenters. The
finite element method is also used: (1) to "point out"
the problem of scaling constant in calculating
displacements for an elastic half-space subjected to a
concentrated normal force in the 2D plane strain
analysis and (2) to understand the variation of stress
and displacements in a tactile surface of finite
dimensions.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  3835 </NUMBER>
<ORDER>   AAGC507792 </ORDER>
<TITLE> NEW DISTANCE TRANSFORMS FOR GRAY-LEVEL IMAGE COMPRESSION </TITLE>
<AUTHOR> TOIVANEN, PEKKA JUHANI </AUTHOR>
<YEAR> 1996 </YEAR>
<INSTITUTION> LAPPEENRANNAN TEKNILLINEN KORKEAKOULU (FINLAND); 5755 </INSTITUTION>
<DESCRIPTORS> COMPUTER SCIENCE; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> NIL </ADVISER>
<CLASSIFICATIONS> COMPUTER VISION </CLASSIFICATIONS>
<ABSTRACT>
This thesis deals with distance transforms which are a
fundamental issue in image processing and computer
vision. In this thesis, two new distance transforms for
gray-level images are presented. As a new application
for distance transforms, they are applied to gray-level
image compression.
The new distance transforms are both new extensions of
the well-known distance transform algorithm developed by
Rosenfeld, Pfaltz and Lay. With some modification their
algorithm which calculates a distance transform on
binary images with a chosen kernel has been made to
calculate a chessboard-like distance transform with
integer numbers (DTOCS) and a real-value distance
transform (EDTOCS) on gray-level images.
Both distance transforms, the DTOCS and EDTOCS, require
only two passes over the gray-level image and are
extremely simple to implement. Only two image buffers
are needed: The original gray-level image and the binary
image which defines the region(s) of calculation. No
other image buffers are needed even if more than one
iteration round is performed. For large neighborhoods
and complicated images the two-pass distance algorithm
has to be applied to the image more than once, typically
3-10 times. Different types of kernels can be adopted.
It is important to notice that no other existing
transform calculates the same kind of distance map as
the DTOCS. All the other gray-weighted distance
function, GRAYMAT etc. algorithms find the minimum path
joining two points by the smallest sum of gray levels or
weighting the distance values directly by the gray
levels in some manner. The DTOCS does not weight them
that way. The DTOCS gives a weighted version of the
chessboard distance map. The weights are not constant,
but gray-value differences of the original image.
This thesis introduces a new application area for
distance transforms. Three new image compression
algorithms based on the DTOCS and one based on the
EDTOCS are presented. Control points, i.e. points that
are considered fundamental for the reconstruction of the
image, are selected from the gray-level image using the
DTOCS and the EDTOCS. The first group of methods selects
the maximas of the distance image to new control points
and the second group of methods compares the DTOCS
distance to binary image chessboard distance. The effect
of applying threshold masks of different sizes along the
threshold boundaries is studied. The time complexity of
the compression algorithms is analyzed both analytically
and experimentally. It is shown that the time complexity
of the algorithms is independent of the number of
control points, i.e. the compression ratio. Also a new
morphological image decompression scheme is presented,
the 8 kernels' method.
Several decompressed images are presented. The best
results are obtained using the Delaunay triangulation.
The obtained image quality equals that of the DCT images
with a 4 x 4 normalization matrix.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  3836 </NUMBER>
<ORDER>   AAGC507777 </ORDER>
<TITLE> RULENET: A KNOWLEDGE-BASED NEURAL NETWORK MODEL WITH APPLICATION EXAMPLES IN MOBILE ROBOTICS </TITLE>
<AUTHOR> TSCHICHOLD-GURMAN, NADINE NIVART </AUTHOR>
<YEAR> 1996 </YEAR>
<INSTITUTION> EIDGENOESSISCHE TECHNISCHE HOCHSCHULE ZUERICH (SWITZERLAND); 0663 </INSTITUTION>
<DESCRIPTORS> COMPUTER SCIENCE; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> NIL </ADVISER>
<CLASSIFICATIONS> EXPERT SYSTEMS </CLASSIFICATIONS>
<ABSTRACT>
Current research in robotics is focusing on the
realization of systems having the abilities to operate
on uncertain and imprecise data and to adapt their
behavior to the environment and the current task. To
realize such systems, hybrid models combining different
computing techniques are required, as in the brain,
where different information processing principles
cooperate with each other. For this purpose, the
existing models have to be understood better to enable
information exchange between the different processing
systems. Furthermore, new models with different
properties from the existing ones need to be developed
to achieve new interesting characteristics in their
hybrid application. This thesis presents a step in this
direction by introducing a new neural network model,
RuleNet, that enables a natural integration of fuzzy and
binary knowledge based systems with neural and classical
machine learning systems.
RuleNet is a feedforward network model with a supervised
learning algorithm, a dynamic architecture and discrete
outputs. The central properties of RuleNet are its
efficient learning and propagation algorithms and the
possibility to translate symbolic knowledge into the
network and vice-versa without loss of information.
The main application area of RuleNet is pattern
classification. Results on benchmark problems have shown
that the performance of RuleNet for classification
problems is comparable, in most cases even superior to
different other methods. RuleNet is also well suited for
the generation or the refinement of symbolic knowledge;
this property of RuleNet has also been demonstrated on
at several benchmark problems.
We also present the extension of RuleNet with fuzzy
logic, Fuzzy RuleNet. The application areas of Fuzzy
RuleNet are fuzzy classification and generation of fuzzy
systems, i.e. rules and the corresponding membership
functions, from training examples. This extension to
RuleNet is motivated by the fact that both, fuzzy logic
and neural networks, have complementary features,
although there are also substantial areas of overlap.
For this reason, there is a great interest in the
synergistic combination of these paradigms.
As a real-world application of RuleNet the problem of
mobile robot navigation is chosen. For this purpose the
concept of a situation based behavior selector (SBBS) is
introduced. The SBBS is the module where different
behaviors and reflexes of a mobile robot are coordinated
to perform a task. Different SBBS modules utilizing
RuleNet and Fuzzy RuleNet networks have been implemented
and their performances have been compared to each other
in a simulation environment. Furthermore the SBBS module
has been implemented and trained on a real mobile robot
platform. Experiments have shown that a small RuleNet
network is sufficient to navigate the mobile robot
safely in a cluttered environment.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  3837 </NUMBER>
<ORDER>   AAGC507602 </ORDER>
<TITLE> MODELISATION ET APPRENTISSAGE DES PREFERENCES PAR RESEAUX DE NEURONES POUR L'AIDE A LA DECISION MULTICRITERE; LEARNING AND EXPLAINING PREFERENCES WITH NEURAL NETWORKS FOR MULTIPLE CRITERIA DECISION-MAKING </TITLE>
<AUTHOR> FRAMLING, KARY AKE </AUTHOR>
<YEAR> 1996 </YEAR>
<INSTITUTION> INSTITUT NATIONAL DES SCIENCES APPLIQUEES DE LYON (FRANCE); 5285 </INSTITUTION>
<DESCRIPTORS> OPERATIONS RESEARCH; ARTIFICIAL INTELLIGENCE AVENUE ALBERT EINSTEIN, F-69621  VILLEURBANNE CEDEX, FRANCE </DESCRIPTORS>
<ADVISER> NIL </ADVISER>
<CLASSIFICATIONS> CONTEXT DEPENDENCE, MACHINE LEARNING </CLASSIFICATIONS>
<ABSTRACT>
The goal of this Ph.D. work is to improve multiple-
criteria decision-making by the use of "context-
dependent" preference models. Such models are more
realistic than ones used previously, but it is usually
difficult for the decider to express their preferences.
This is the reason for using machine learning employing
neural networks for identifying the preference model.
A neural net "learns" the preference model by the
principles of non-linear regression, where the decision
model is expressed by examples of decisions. The INKA
neural network developed reduces the number of examples
necessary, which is essential for the practical use of
this technique. Learning times are also sufficiently
short to make possible the interactive acquisition of
the preference model.
The interactive decision support system developed using
INKA is one of the first to use machine learning to
identify a global preference model. The visualisation of
the learned model and the indicators of precision and
sensibility developed help the decider to decide when to
stop the interactive procedure. This is especially
important for learning the preferences of "abstract
deciders" (a group of people, consumers, nature, $...),$
who cannot interact with the system.
Explaining the results is still a great problem both for
decision support systems and for neural networks. The
methods developed here make it possible to reduce or
eliminate this problem. It is therefore possible to
explain, understand and analyse even the preferences of
"abstract deciders." This information may then be used
for improving group decision making or for improving
product sales which depend on consumer preferences.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  3838 </NUMBER>
<ORDER>   AAGC507535 </ORDER>
<TITLE> NEURAL NETWORK APPLICATIONS IN DEVICE AND SUBCIRCUIT MODELLING FOR CIRCUIT SIMULATION </TITLE>
<AUTHOR> MEIJER, PETER BARTUS LEONARD </AUTHOR>
<YEAR> 1996 </YEAR>
<INSTITUTION> TECHNISCHE UNIVERSITEIT EINDHOVEN (THE NETHERLANDS); 0426 </INSTITUTION>
<DESCRIPTORS> ENGINEERING, ELECTRONICS AND ELECTRICAL; ARTIFICIAL INTELLIGENCE BOX 513, EH 8.28,  NL-5600 M.B. EINDHOVEN, THE NETHERLANDS </DESCRIPTORS>
<ADVISER> NIL </ADVISER>
<CLASSIFICATIONS> NIL </CLASSIFICATIONS>
<ABSTRACT>
This thesis describes the main theoretical principles
underlying new automatic modelling methods, generalizing
concepts that originate from theories concerning
artificial neural networks. The new approach allows for
the generation of (macro-)models for highly nonlinear,
dynamic and multidimensional systems, in particular
electronic components and (sub)circuits. Such models can
subsequently be applied in analogue simulations. The
purpose of this is twofold. To begin with, it can help
to significantly reduce the time needed to arrive at a
sufficiently accurate simulation model for a new basic
component--such as a transistor, in cases where a
manual, physics-based, construction of a good simulation
model would be extremely time-consuming. Secondly, a
transistor-level description of a (sub)circuit may be
replaced by a much simpler macromodel, in order to
obtain a major reduction of the overall simulation time.
Basically, the thesis covers the problem of constructing
an efficient, accurate and numerically robust model,
starting from behavioural data as obtained from
measurements and/or simulations. To achieve this goal,
the standard backpropagation theory for static
feedforward neural networks has been extended to include
continuous dynamic effects like, for instance, delays
and phase shifts. This is necessary for modelling the
high-frequency behaviour of electronic components and
circuits. From a mathematical viewpoint, a neural
network is now no longer a complicated nonlinear
multidimensional function, but a system of nonlinear
differential equations, for which one tries to tune the
parameters in such a way that a good approximation of
some specified behaviour is obtained.
Based on theory and algorithms, an experimental software
implementation has been made, which can be used to train
neural networks on a combination of time domain and
frequency domain data. Subsequently, analogue
behavioural models and equivalent electronic circuits
can be generated for use in analogue circuit simulators
like Pstar (from Philips), SPICE (University of
California at Berkeley) and Spectre (from Cadence). The
thesis contains a number of real-life examples which
demonstrate the practical feasibility and applicability
of the new methods.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  3839 </NUMBER>
<ORDER>   AAGC507500 </ORDER>
<TITLE> MODEL GENERATION AND SAMPLING ALGORITHMS FOR DYNAMIC STOCHASTIC PROGRAMMING </TITLE>
<AUTHOR> POIRE, XAVIER CORVERA </AUTHOR>
<YEAR> 1996 </YEAR>
<INSTITUTION> UNIVERSITY OF ESSEX (UNITED KINGDOM); 0873 </INSTITUTION>
<DESCRIPTORS> COMPUTER SCIENCE; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> NIL </ADVISER>
<CLASSIFICATIONS> NIL </CLASSIFICATIONS>
<ABSTRACT>
Very large-scale dynamic stochastic programming models
arise from perspective planning, finance, economics and
management. Although these problems represent reality
accurately, its specification involves complex data
files, that in order to be used effectively in practice,
require automatic implementation. This dissertation
introduces a state-of-the-art model generator which
exploits the current facilities for Linear Programming
to generate standard input files for Stochastic
Programming.
Once the solution of a problem is obtained, the Expected
Value of Perfect Information (EVPI) is defined at each
state of decision of the problem. This is a measure of
the degree of stochasticity against which the
corresponding decision have to be made.
Low EVPI values imply that some decision states are
virtually redundant to the problem, therefore large
multi-state stochastic programming problems can
accurately be reduced to a reasonable dimension, to be
used for parametrical analysis. Numerical results are
reported on low, medium and high EVPI problems. Problems
from the literature are criticised in the sense that
large dimension stochastic problems can be represented
by deterministic ones, solved in a fraction of the time.
Moreover, based on an accurate estimate of the EVPI, and
search techniques for Artificial Intelligence (AI), an
innovative class of sampling algorithms for multi-stage
programs is developed. At each iteration these
algorithms solve a relatively limited dimension problem,
this is refined at those most important decision states
in order to improve the sample representation of the
problem. A convergence result in the continuous case is
included.
An empirical study tests different AI techniques, and
shows that these iterative algorithms are very efficient
for solving multi-stage stochastic programs, for general
underlying discrete stochastic processes.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  3840 </NUMBER>
<ORDER>   AAGC507486 </ORDER>
<TITLE> AN APPLICATION ORIENTED COMPARISON OF OPTIMISATION AND NEURAL NETWORK BASED DESIGN TECHNIQUES </TITLE>
<AUTHOR> TALBOT, N. L. C. </AUTHOR>
<YEAR> 1996 </YEAR>
<INSTITUTION> UNIVERSITY OF ESSEX (UNITED KINGDOM); 0873 </INSTITUTION>
<DESCRIPTORS> ENGINEERING, ELECTRONICS AND ELECTRICAL; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> NIL </ADVISER>
<CLASSIFICATIONS> VLSI </CLASSIFICATIONS>
<ABSTRACT>
This thesis describes an investigative comparison of the
performance of artificial neural networks and
conventional optimization algorithms in electronic
engineering design. For generality, two classes of
problem were considered involving, respectively,
discontinuous and continuous variables. The
discontinuous-variable problem chosen was concerned with
the practically important issue of block placement in
VLSI design. As an example of a realistic design problem
in which the variables are continuous, electronic
analogue filter design was chosen. For this research,
placement was divided into three subclasses: quadratic
assignment, force-directed placement and min-cut. For
each subclass, a neural network and a conventional
method were implemented, and their performance analysed.
Using quadratic assignment, the optimization process is
reduced to solving a set of simultaneous linear
equations, which, conventionally, can be solved using
methods such as the Gauss-Seidel iterative algorithm or
Gaussian elimination. In comparison, a neural
implementation, based on a linear recurrent network, was
developed and shown to be guaranteed to converge to the
solution, given certain criteria. Force-directed
placement calculates the optimal position for each
module, through modelling electrical connections between
modules as an elastic force. Each module is then moved
iteratively in the direction of the net force acting on
it, until a stable floorplan has evolved. A neural force-
directed placement method, based on the Kohonen self-
organising feature map, was developed for comparison. In
addition, min-cut placement algorithms using simulated
annealing and the Boltzmann machine were also evaluated.
Determining the optimal component values for an analogue
filter of a given specification, is conventionally
performed using a least squares optimization procedure,
where the derivatives are approximated by numerical
evaluations because the objective function, for all but
the simplest filter, is generally too complicated to
derive for an analytic solution to be practical. A
simple neural implementation of gradient descent
optimization was devised, however, least squares
optimization has been shown to be superior to gradient
descent methods, and so another approach is required. A
multi-layer perception network was trained using the
back-propagation algorithm to implement a generalising
of the table of component values. The test and training
data is provided by the component values and
specifications of a number of filters designed using
least squares optimization. The network has been
demonstrated to be able to generate reasonable component
values for novel specifications, however, marginally
better results are obtained from a triangular
interpolation of the component values.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  3841 </NUMBER>
<ORDER>   AAGC504322 </ORDER>
<TITLE> AUTONOMOUS AGENTS AND THE CONCEPT OF CONCEPTS </TITLE>
<AUTHOR> DAVIDSSON, PAUL </AUTHOR>
<YEAR> 1996 </YEAR>
<INSTITUTION> LUNDS UNIVERSITET (SWEDEN); 0899 </INSTITUTION>
<DESCRIPTORS> COMPUTER SCIENCE; ARTIFICIAL INTELLIGENCE 118, 221 00 LUND,  SWEDEN </DESCRIPTORS>
<ADVISER> NIL </ADVISER>
<CLASSIFICATIONS> CONCEPT LEARNING, MACHINE LEARNING, ARTIFICIAL INTELLIGENCE </CLASSIFICATIONS>
<ABSTRACT>
Arguments against both purely reactive and purely
deliberative autonomous agent architectures are
presented in favor for hybrid approaches. A novel hybrid
approach based on the concept of anticipatory systems is
suggested. The basic idea is to let a meta-level
component "run" a world model faster than real time to
make predictions of future states. These predictions are
used to guide the agent's behavior on a high-level,
whereas the low-level behavior is controlled by a
reactive component. A specialization of this
architecture, a linearly quasi-anticipatory agent
architecture, which treats all agents in the domain
(itself included) as being reactive, has been
implemented. Results from both single and multi-agent
experiments indicate that the behavior of such agents is
superior to that of the corresponding reactive agents.
Autonomous agents also provide the framework in which
the representation and the acquisition of concepts are
studied. First, however, the following more fundamental
questions are discussed: What does it mean to have a
concept? What functions do, or should, concepts serve?
What is known about the nature of categories? Thus, by
trying to answer these questions, we investigate the
very concept of concepts. One of the main goals of this
thesis is to pull together different lines of
argumentation that have emerged from the cognitive
sciences in order to establish a solid foundation for
further AI research. It is concluded that none of the
existing approaches to concept representation is able to
serve all the desired functions and that it is
unrealistic to expect that any monolithic representation
would be adequate. Based on this insight, a novel
composite representation scheme is presented in which
each component is motivated by the functions a concept
should serve. Some of the requirements that any
autonomous concept learning system must meet are then
identified and provide the basis for an evaluation of
the existing theories. A method for making any learning
algorithm satisfy one such requirement, namely that of
representing concepts by characteristic descriptions, is
presented together with some promising experimental
results. In contrast to previous methods, it is possible
with this method to control the degree of
generalization.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  3842 </NUMBER>
<ORDER>   AAG9728677 </ORDER>
<TITLE> SIGNAL REPRESENTATION USING FUZZY MORPHOLOGY AND ITS APPLICATIONS  </TITLE>
<AUTHOR> HUANG, CHIN-PAN </AUTHOR>
<YEAR> 1996 </YEAR>
<INSTITUTION> UNIVERSITY OF PITTSBURGH; 0178 </INSTITUTION>
<DESCRIPTORS> ENGINEERING, ELECTRONICS AND ELECTRICAL; ENGINEERING, SYSTEM SCIENCE; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> LUIS F. CHAPARRO </ADVISER>
<CLASSIFICATIONS> IMAGE PROCESSING </CLASSIFICATIONS>
<ABSTRACT>
In this dissertation, new signal representations using
fuzzy morphology are developed. We take advantage of the
optimum fuzzy fitting and the efficient implementation
of morphological operators to extract geometric
information from the signal. The new signal
representations provide results analogous to those given
by the polynomial and the wavelet transforms. The fuzzy
morphological polynomial (FMP) representation is based
on fuzzy morphology and adaptive structuring functions.
The geometrical decomposition is achieved by windowing
and applying fuzzy morphological opening sequentially
with each of the adaptive structuring elements aiming to
fit the signal. The resulting representation is made to
resemble an orthogonal expansion by constraining the
results of opening to equal the adapted structuring
functions. Properties of our geometrical decomposition
are investigated and applied in calculating the
adaptation parameters. Fuzzy morphological interpolation
(FMI) algorithms are then developed. Based on this
interpolation, the fuzzy morphological wavelet (FMW)
representation, analogous to the wavelet transformation,
is then obtained. The FMW allows perfect reconstruction,
uses minimum and maximum operations instead of inner
product or convolution. Properties of the FMI algorithm
moreover permit us to develop fast pyramidal
implementations for analysis and synthesis when the
first and second order interpolators are used. We also
extend our representations to two-dimensions. The
representations are illustrated with one- and two-
dimensional signals in data compression, fractal
dimension estimation, and object recognition. The
results show high performance and compare favorably with
other commonly used methods.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  3843 </NUMBER>
<ORDER>   AAG1380765 </ORDER>
<TITLE> A GRAFTING APPROACH TO NEURAL NETWORK CONSTRUCTION </TITLE>
<AUTHOR> RAYHAN, ABDALLAH MOUSA REZQ </AUTHOR>
<YEAR> 1996 </YEAR>
<INSTITUTION> KING FAHD UNIVERSITY OF PETROLEUM AND MINERALS (SAUDI ARABIA); 1088 </INSTITUTION>
<DESCRIPTORS> COMPUTER SCIENCE; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> NIL </ADVISER>
<CLASSIFICATIONS> NIL </CLASSIFICATIONS>
<ABSTRACT>
The size of a neural network is mostly determined by
trial and error and influenced by the designer's
experience and the anticipated complexity of the
problem. The rising demand for neural network
applications necessitates better structured techniques
to build neural networks than the existing ones. A
review the back-propagation training algorithm and the
main problems and limitations of learning is given in
this thesis. The thesis also includes a survey of the
main techniques reported in the literature, which
dynamically construct or prune feedforward networks. A
new approach to construct feedforward neural networks is
then proposed. This approach is based on grafting the
desired network from several already trained networks.
We present experimental results on artificial and
natural domains comparing the proposed grafting
algorithm to networks with predetermined size, dynamic
node creation, and node pruning. These results suggest
that the proposed grafting algorithm achieves superior
performance over other techniques in most of the tested
domains.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  3844 </NUMBER>
<ORDER>   AAG1380527 </ORDER>
<TITLE> DESIGN OF A FUZZY LOGIC CONTROLLER FOR SWING-DAMPED TRANSPORT OF AN OVERHEAD CRANE PAYLOAD </TITLE>
<AUTHOR> NALLEY, MICHAEL JAMES </AUTHOR>
<YEAR> 1996 </YEAR>
<INSTITUTION> UNIVERSITY OF NEVADA, LAS VEGAS; 0506 </INSTITUTION>
<DESCRIPTORS> ENGINEERING, MECHANICAL; ENGINEERING, ELECTRONICS AND ELECTRICAL; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> NIL </ADVISER>
<CLASSIFICATIONS> NIL </CLASSIFICATIONS>
<ABSTRACT>
Transportation using overhead cranes can excite
undesirable payload swinging. These oscillations have to
be damped before other payload manipulation is done. A
swing-damped motion profile based on the natural
frequency of the payload is used to minimize swing
excitation. In addition, a fuzzy logic controller is
used to move the overhead crane along a desired path
while ensuring that the payload is swing-free at the end
of the motion. The control action is divided between
displacement and swing controllers to simplify
controller tuning for optimal performance. Examples,
along with comparisons with a PD controller, are
included, as well as related experimental development.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  3845 </NUMBER>
<ORDER>   AAG1380513 </ORDER>
<TITLE> PREDICTOR OF OCR ACCURACY USING STATISTICAL TECHNIQUES </TITLE>
<AUTHOR> GONZALEZ, JUAN MANUEL </AUTHOR>
<YEAR> 1996 </YEAR>
<INSTITUTION> UNIVERSITY OF NEVADA, LAS VEGAS; 0506 </INSTITUTION>
<DESCRIPTORS> COMPUTER SCIENCE; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> NIL </ADVISER>
<CLASSIFICATIONS> NIL </CLASSIFICATIONS>
<ABSTRACT>
Systems that predict optical character recognition (OCR)
accuracy of an input image by a given OCR system were
developed. Seven features associated with image defects
were identified and utilized. Two kinds of nonparametric
classification engines, the nearest neighbor rule-based
and neural network-based, were implemented. The
performance of these systems were compared to an old
heuristic-based system using a cost model of a large-
scale document conversion process and a test data set
consisting of 502 pages. The results show that the
performance of new classifiers were better than that of
the heuristic-based system. The neural network-based
system outperformed the nearest-neighbor-based system.
These new systems can be used to reduce the cost of a
large-scale document conversion process by
discriminating good quality pages for OCR from degraded
images for manual data entry.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  3846 </NUMBER>
<ORDER>   AAG1380508 </ORDER>
<TITLE> SIMILARITY BETWEEN POLYGONAL SHAPES </TITLE>
<AUTHOR> FANG, GUORONG </AUTHOR>
<YEAR> 1996 </YEAR>
<INSTITUTION> UNIVERSITY OF NEVADA, LAS VEGAS; 0506 </INSTITUTION>
<DESCRIPTORS> COMPUTER SCIENCE; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> NIL </ADVISER>
<CLASSIFICATIONS> NIL </CLASSIFICATIONS>
<ABSTRACT>
In this thesis we review existing algorithms for
measuring shape similarity between polygons. We present
a new approach to measure similarity based on the notion
of annular profile. We also present the implementation
of three shape measuring algorithms: signature function,
turning function, and annular profile. The
implementation is done by using the Visual C++
programming language. Finally, we discuss the
comparative performances of the above three methods for
capturing shape similarity. Measurement of shape
similarity has applications in pattern recognition and
artificial intelligence.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  3847 </NUMBER>
<ORDER>   AAG1380282 </ORDER>
<TITLE> FUZZY LOGIC AND NETWORK FAULT TOLERANCE </TITLE>
<AUTHOR> PARKS, DENTON AUSTIN </AUTHOR>
<YEAR> 1996 </YEAR>
<INSTITUTION> CALIFORNIA STATE UNIVERSITY, LONG BEACH; 6080 </INSTITUTION>
<DESCRIPTORS> COMPUTER SCIENCE; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> THINH V. NGUYEN </ADVISER>
<CLASSIFICATIONS> NIL </CLASSIFICATIONS>
<ABSTRACT>
The objective of this thesis is to present a preliminary
study of using fuzzy logic in designing a network
routing protocol to increase the fault tolerance of a
generic multinode circuit-switched communication
network. This study will use computer simulations to
compare several baseline deterministic models, a random
based models and several fuzzy logic based models.
The network topologies used for this thesis will be a
mesh connected network and a mesh connected network with
diagonal links.
The system will be simulated to determine if fuzzy logic
will enable a network to operate at a higher usage
before failure and if fuzzy logic will improve network
performance in the presence of node and link failures.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  3848 </NUMBER>
<ORDER>   AAG1380204 </ORDER>
<TITLE> ARTIFICIAL NEURAL NETWORKS AND GENETIC ALGORITHMS: COMPUTATIONAL MODELS </TITLE>
<AUTHOR> CULEVSKI, NIKO </AUTHOR>
<YEAR> 1996 </YEAR>
<INSTITUTION> CALIFORNIA STATE UNIVERSITY, LONG BEACH; 6080 </INSTITUTION>
<DESCRIPTORS> COMPUTER SCIENCE; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> DAR-BIAU LIU </ADVISER>
<CLASSIFICATIONS> NIL </CLASSIFICATIONS>
<ABSTRACT>
Research in the field of artificial neural networks and
genetic algorithms currently is growing at an
unprecedented rate. Theoretical works and practical
applications of the two provinces abound; seldom,
however, are the two illustrated with specific
computational models.
The objective of this thesis is two-fold: first, to
present historical foundation of artificial neural
networks and a brief introduction to a simple genetic
algorithm, and second, to provide representative
examples of both disciplines. The final chapter of this
work contains, among other artificial neural network
examples, heuristic solutions to the Traveling Salesman
Problem by the Nearest Neighbor and a genetic algorithm.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  3849 </NUMBER>
<ORDER>   AAG1380161 </ORDER>
<TITLE> A NEW APPROACH TO NEURAL NETWORK TRAINING AND ITS APPLICATIONS </TITLE>
<AUTHOR> XU, XIANGHAI </AUTHOR>
<YEAR> 1996 </YEAR>
<INSTITUTION> UNIVERSITY OF NEVADA, RENO; 0139 </INSTITUTION>
<DESCRIPTORS> COMPUTER SCIENCE; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> CARL G. LOONEY </ADVISER>
<CLASSIFICATIONS> NIL </CLASSIFICATIONS>
<ABSTRACT>
The thesis presented explores a new approach to neural
network training and its application in pattern
recognition. The focus of our research is on three-
layered feedforward neural networks (FNNs).
Conventionally, three-layered feedfoward neural networks
use sigmoidal activation functions in both the middle
and output layers of neurodes. Knowing the fact that the
computation time related to the sigmoidal functions and
their derivatives is significant, and that the middle
layer plays a more critical role in the non-linear
mapping, a new structure is designed by replacing the
sigmoidal activation functions in the output layer with
simple division functions. Accordingly, a new BP
algorithm is derived on the basis of the changed neural
network structure.
By experimenting on the digit character recognition
problem which is a typical pattern recognition
application, this thesis provides evidence that the
linear activation function at the output layer does not
impair the overall power of the FNNs in nonlinear
mapping. On the contrary, the new approach exhibits
robust learning ability and improved convergence speed,
and applies well to the non-linear mapping problems and
pattern recognition applications.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  3850 </NUMBER>
<ORDER>   AAG1380158 </ORDER>
<TITLE> COMBINING GENETIC ALGORITHM AND CASE-BASED REASONING FOR STRUCTURE DESIGN </TITLE>
<AUTHOR> LIV, XIAOHUA </AUTHOR>
<YEAR> 1996 </YEAR>
<INSTITUTION> UNIVERSITY OF NEVADA, RENO; 0139 </INSTITUTION>
<DESCRIPTORS> COMPUTER SCIENCE; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> SUSHIL J. LOUIS </ADVISER>
<CLASSIFICATIONS> NIL </CLASSIFICATIONS>
<ABSTRACT>
This thesis tests the feasibility of applying case-based
reasoning in the adaptive learning process of genetic
algorithms. When combining genetic algorithms and case-
based reasoning, instead of randomly initializing the
population, we inject appropriate cases from a case
library into the initial population of a genetic
algorithm. Two key issues we address are: how to select
appropriate cases and how to determine the number of
cases to inject. We choose the combinational circuit
design of parity checkers as the test bed for our
research because: (1) they lead to simpler case storage
and retrieval algorithms, and (2) they are easily
scalable in size. This thesis explores the issues
outlined above and indicates the feasibility of
combining genetic algorithms and case-based reasoning to
improve performance. Our preliminary results appear
promising.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  3851 </NUMBER>
<ORDER>   AAG1379974 </ORDER>
<TITLE> A SHARED ONTOLOGY FOR A SCALABLE, DISTRIBUTED CASE ENVIRONMENT </TITLE>
<AUTHOR> KELLY, JIMMIE LEWIS </AUTHOR>
<YEAR> 1996 </YEAR>
<INSTITUTION> THE UNIVERSITY OF TEXAS AT ARLINGTON; 2502 </INSTITUTION>
<DESCRIPTORS> COMPUTER SCIENCE; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> ERIK METTALA </ADVISER>
<CLASSIFICATIONS> NIL </CLASSIFICATIONS>
<ABSTRACT>
A software engineering environment based upon the
scenario-based engineering process and built upon an
open architecture approach that encapsulates a suite of
software tools would provide a solution for the
development of complex software applications. The suite
of tools would be used to define each task and create an
object model, a data flow model, a state transition
model, and an event trace model. As a model is created
or changed, automatic updates to the other corresponding
models would occur. However, in order to propagate these
updates, a shared ontology between the suite of tools is
needed. This thesis defines a ontology to be shared
between a suite of tools integrated into a scaleable and
distributed CASE environment.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  3852 </NUMBER>
<ORDER>   AAGMM10748 </ORDER>
<TITLE> ESTIMATING CONCRETE FORMWORK PRODUCTIVITY </TITLE>
<AUTHOR> PORTAS, JASON BLAIR </AUTHOR>
<YEAR> 1996 </YEAR>
<INSTITUTION> UNIVERSITY OF ALBERTA (CANADA); 0351 </INSTITUTION>
<DESCRIPTORS> ENGINEERING, CIVIL; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> SIMAAN ABOURIZK </ADVISER>
<CLASSIFICATIONS> NIL </CLASSIFICATIONS>
<ABSTRACT>
This research involves the development of a neural
network system to aid in the estimation of labor
productivity for concrete framework. The goal of the
research project is to improve the ability to estimate
labor productivity by studying the factors that affect
it, as well as to develop analytical tools that
implement the findings. The research includes the
construction of a historical project information
collection, storage and retrieval system, the modeling
and implementation of a historical information analysis
model, a study into the factors which affect labor
productivity, and the modeling and implementation of a
neural network system to aid in the estimation of labor
productivity.
The final neural network is a backpropagation,
feedforward neural network. The network uses a sigmoid
transfer function, with a normal cumulative learning
rule. There are approximately 55 input nodes
representing 30 factors, 30 hidden nodes in 1 hidden
layer and 13 output nodes. The input to the network are
factors that were determined to have an effect on
productivity. The output formulation of the model is a
binary output pattern matching technique that predicts
labor productivity. The productivity is predicted as a
set of scores that represent certainty of occurrence
corresponding to subset ranges of productivity values.
The contributions of the investigation include providing
new ways of analyzing historical data so that it can be
used to predict performance for future projects,
enhancement of the accuracy of current labor
productivity estimates and an increased understanding of
construction activities and the factors that affect
labor productivity.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  3853 </NUMBER>
<ORDER>   AAGNN17184 </ORDER>
<TITLE> LIGHT ADAPTATION AND SENSITIVITY CHANGE PROCESSES IN THE HUMAN RETINA: INVESTIGATING OPTO-ELECTRONIC APPLICATIONS </TITLE>
<AUTHOR> WYSOKINSKI, TOMASZ WALDEMAR </AUTHOR>
<YEAR> 1996 </YEAR>
<INSTITUTION> SIMON FRASER UNIVERSITY (CANADA); 0791 </INSTITUTION>
<DESCRIPTORS> ENGINEERING, ELECTRONICS AND ELECTRICAL; ARTIFICIAL INTELLIGENCE; BIOLOGY, NEUROSCIENCE </DESCRIPTORS>
<ADVISER> ANDREW H. RAWICZ </ADVISER>
<CLASSIFICATIONS> NIL </CLASSIFICATIONS>
<ABSTRACT>
Real-world image acquisition systems, such as the charge
coupled device with frame grabber and computer, are
still very limited in overall performance compared with
the biological visual systems. The work done in this
thesis originates from the fact that the solutions
implemented by nature are both elegant and efficient,
and that they should be the inspiration for designers to
enhance the performance of artificial visual systems.
In the first part of this research, we investigate the
phenomena of light adaptation and sensitivity change
processes that allow an eye to operate over 12 decades
of light intensity range. Different adaptation
mechanisms are scrutinised, and a model of those
mechanisms is developed. Next we investigate how the
visual system copes with light intensities beyond its
dynamic range when glare occurs. The signal saturation
in glare phenomena is used to reveal the highly complex
structure of the retina. By applying a developed model
of signal propagation in the Outer Plexiform Layer and
by relating it to the experimental psychophysical data,
we obtain a formula for the density of horizontal cell
connections along the diameter of the human retina.
By studying the architecture, neurology and physiology
of the retina, we develop an equivalent Adaptive
Filter/Photosensitive Device Array system capable of
coping with a wide range of light conditions. The
Adaptive Filter mimics some adaptation mechanisms of the
human eye and offers the possibility of extending the
dynamic range of operation of any image-acquiring system
without affecting the electronic circuitry of the photo-
sensor array.
In the third part, we describe efforts to build one of
the possible implementations of the adaptive filter,
namely an optically addressed Photochromic Adaptive
Filter (PAF), which utilizes photochromic material
embedded in a polymeric environment. We successfully
test the concept of extending the operating range of the
constructed image-acquiring system by using optically-
addressed PAF's. The system is modified to determine a
Transformation Function of these filters using a simple,
fast and easy-to-automate method.
In the appendix we discuss several problems related to
this research program. We estimate the measurement
errors in detail. We also present a new method of
preparing thin-layer silver-halide film and describe
other possible implementations of the adaptive filter
using active opto-electronic devices.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  3854 </NUMBER>
<ORDER>   AAGMM09807 </ORDER>
<TITLE> LEXICAL ANALYSIS USING FUZZY REGULAR EXPRESSIONS </TITLE>
<AUTHOR> REDEKOP, JAMES HEINRICH GREGORY </AUTHOR>
<YEAR> 1996 </YEAR>
<INSTITUTION> THE UNIVERSITY OF WESTERN ONTARIO (CANADA); 0784 </INSTITUTION>
<DESCRIPTORS> COMPUTER SCIENCE; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> SHENG YU </ADVISER>
<CLASSIFICATIONS> NIL </CLASSIFICATIONS>
<ABSTRACT>
One potential avenue for the implementation of a "Do
What I Mean" environment for the parsing of possibly
ambiguous or mistyped input for some computer system
could be the implementation of the system's syntax using
fuzzy formal languages. In order to demonstrate the
viability of this idea, this thesis presents two
approaches to such an implementation, in which the lex
lexical scanner building program is extended to handle
fuzzy regular expressions (FREs) and outlines a third,
which involves profound modifications to lex but
implements FREs more thoroughly. These implementations
demonstrate that FRE and fuzzy language tools can be
easily implemented by modifying existing programs.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  3855 </NUMBER>
<ORDER>   AAG9635539 </ORDER>
<TITLE> FUZZY LOGIC CONTROLS FOR CNC MACHINE TOOLS </TITLE>
<AUTHOR> JEE, SUNGCHUL </AUTHOR>
<YEAR> 1996 </YEAR>
<INSTITUTION> THE UNIVERSITY OF MICHIGAN; 0127 </INSTITUTION>
<DESCRIPTORS> ENGINEERING, MECHANICAL; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> YORAM KOREN </ADVISER>
<CLASSIFICATIONS> SELF ORGANIZING, CROSS COUPLING CONTROLLER </CLASSIFICATIONS>
<ABSTRACT>
To improve the contouring accuracy of CNC systems in a
cost-effective way, great efforts have been made to
develop sophisticated servo-controllers. The objective
of this research has been to develop advanced servo-
controllers to improve the contour tracking accuracy of
machining systems in the presence of large disturbances.
To meet this objective, three rule-based fuzzy logic
controllers for feed drive systems are presented: a
fuzzy logic controller (FLC), a self-organizing fuzzy
logic controller (SOFLC), and a fuzzy logic cross-
coupling controller (FLCCC). These rule-based fuzzy
logic controllers can overcome the drawbacks of
conventional servo-controllers, which utilize model-
based approaches requiring exact process models.
In the proposed FLC, a proportional and derivative type
of fuzzy logic controller is combined with a
conventional integral controller. In addition, to
provide a baseline for the controller design, stability
analyses of fuzzy logic control systems are introduced.
In the proposed SOFLC, the controller parameters are
automatically tuned in real-time according to a
continuous measurement of the performance of the
controller itself and estimated disturbance values. This
capability of self-tuning reduces the complex tuning
procedure needed for each machine when installing fuzzy
logic controllers, and also enables the controllers to
cope with changing operating conditions during
machining. In the proposed FLCCC, fuzzy logic control is
incorporated into a cross-coupling architecture to
overcome the disadvantages of the decoupled axial
controllers and the conventional cross-coupling
controller.
The proposed fuzzy logic controllers, as well as a
conventional PID controller, were simulated and
implemented on a CNC milling machine. Evaluation and
comparison were done in contour milling for various
contour shapes and feedrates. Both the simulations and
the experiments show that the proposed servo-controllers
improve the contour tracking accuracy of machining
systems with large disturbances.
These fuzzy logic controllers do not have an advantage
over conventional controllers for high-end machine tools
which have a fine quality of feed drive systems. On the
other hand, the fuzzy logic controllers can improve the
performance of machine tools which have large and
variable friction in the guideways, large variations in
load, deflection of the leadscrews and backlash in the
gears, and therefore cannot be controlled effectively by
conventional control methods. In addition, the fuzzy
logic controllers are not sensitive to feedrate changes
and fit in high-feedrate machining for high productivity
which usually causes large contour errors especially for
nonlinear contours when conventional controllers, such
as a PID controller, are utilized.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  3856 </NUMBER>
<ORDER>   AAG9635498 </ORDER>
<TITLE> DYNAMICAL SYSTEM REPRESENTATION, GENERATION, AND RECOGNITION OF BASIC OSCILLATORY MOTION GESTURES, AND APPLICATION FOR THE CONTROL OF ACTUATED MECHANISMS </TITLE>
<AUTHOR> COHEN, CHARLES JACOB </AUTHOR>
<YEAR> 1996 </YEAR>
<INSTITUTION> THE UNIVERSITY OF MICHIGAN; 0127 </INSTITUTION>
<DESCRIPTORS> ENGINEERING, ELECTRONICS AND ELECTRICAL; COMPUTER SCIENCE; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> LYNN CONWAY </ADVISER>
<CLASSIFICATIONS> ROBOTICS </CLASSIFICATIONS>
<ABSTRACT>
We present a system for generation and recognition of
oscillatory gestures. Based on the human use of
gestures, the analysis of other gesture recognition
systems, and inspired by gestures used in two
representative human-to-human control areas, we consider
a set of oscillatory motions and refine from them a 24
gesture lexicon. Within the scope of this dissertation,
the word "gesture" is defined as a family of
parametrically delimited oscillatory motions generated
by humans, animals, or machines. Each gesture is modeled
as a linear-in-parameters dynamical system with added
geometric constraints to allow for real time gesture
recognition using a small amount of processing time and
memory. The linear least squares method is used to
determine the parameters which represent each gesture. A
gesture recognition and control architecture is
developed which takes the position measures of a feature
and determines which parameters in a previously defined
set of predictor bins best fits the observed motion. The
gesture classification is then used to create a
reference trajectory to control an actuated mechanism.
Experiments in a real world environment show that our
system can recognize human gestures on the order of 90%
of the time. The gesture lexicon is expanded to include
non-linear "come here" motions. We propose extensions
for use in areas such as mobile robot control and
telerobotics.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  3857 </NUMBER>
<ORDER>   AAG9635297 </ORDER>
<TITLE> ON MODELS OF TEACHING AND GEOMETRIC LEARNING </TITLE>
<AUTHOR> MATHIAS, H. DAVID </AUTHOR>
<YEAR> 1996 </YEAR>
<INSTITUTION> WASHINGTON UNIVERSITY; 0252 </INSTITUTION>
<DESCRIPTORS> COMPUTER SCIENCE; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> SALLY A. GOLDMAN </ADVISER>
<CLASSIFICATIONS> ARTIFICIAL INTELLIGENCE </CLASSIFICATIONS>
<ABSTRACT>
In artificial intelligence, machines that learn are a
long-sought goal. Computational learning theory is the
formal study of methods by which machines learn, with
emphasis on efficient use of time and data. A great
difficulty confronted in learning theory research is
appropriately modeling learning problems such that
careful analysis of data and time requirements is
possible and the underlying problem is adequately
expressed. How should the learner acquire its
information? How much interaction with the environment
is allowed? What is the nature of the environment?
We examine ways in which the environment with which the
learner must interact may help the learner accomplish
its task. Such models of teaching sharply contrast
models of learning in which it is assumed that the
environment is hostile. For many "real-world" learning
problems, hostile environments may not be realistic.
Some problems may be better modeled using a helpful
teacher with whom the learner may interact. This may
significantly reduce the learner's use of resources.
We present the first formal teaching model, within the
learning theory community, that excludes most "unnatural
communication" between the teacher and the learner. We
then improve this model by allowing bi-directional
communication. The addition of interactivity appears to
increase the power of the model: DNF formulas are
teachable in this model while their teachability in the
first model is open.
In addition to models of teaching, we present algorithms
for a general geometric class in established learning
models. The class we consider consists of all labelings
of the regions created by s, $(d-1)$-dimensional
hyperplanes in d-dimensional space. We give an algorithm
for this class, in the query learning model, when the
slopes of the hyperplanes are known to the learner. In
the PAC model of Valiant, we present an algorithm for
this class without the restriction to known slopes. This
is the most general geometric class for which a learning
algorithm is known.
Finally, we perform experiments to gauge the utility of
models of teaching for real-world problems. We have
implemented a simulator for the problem of robot terrain
acquisition. We have obtained empirical results
indicating that in this practical application helpful
teachers are indeed useful.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  3858 </NUMBER>
<ORDER>   AAG9635201 </ORDER>
<TITLE> TOWARDS DESIGNING A KNOWLEDGE-BASED TUTORING SYSTEM: SQL- TUTOR AS AN EXAMPLE </TITLE>
<AUTHOR> ZHOU, GANG </AUTHOR>
<YEAR> 1996 </YEAR>
<INSTITUTION> NEW JERSEY INSTITUTE OF TECHNOLOGY; 0152 </INSTITUTION>
<DESCRIPTORS> COMPUTER SCIENCE; ARTIFICIAL INTELLIGENCE; EDUCATION, TECHNOLOGY </DESCRIPTORS>
<ADVISER> PETER A. NG </ADVISER>
<CLASSIFICATIONS> NIL </CLASSIFICATIONS>
<ABSTRACT>
A Knowledge-Based Tutoring System, also sometimes called
an Intelligent Tutoring System, is a computer-based
instructional system that uses artificial intelligence
techniques to help people learn some subject. The goal
of the system is to provide private tutoring to its
students based on their different backgrounds, requests,
and interests. The system knows what subject materials
it should teach, when and how to teach them, and can
diagnose the mistakes made by the students and help them
correct the mistakes.
The major objective of this dissertation is to
investigate and develop a generic framework upon which
we can build a Knowledge-Based Tutoring System
effectively. As an example, we have focused on
developing SQL-TUTOR, a tutoring system for teaching SQL
concepts and programming skills. The generic
architecture of the system is rooted in the popular view
that a tutoring process between a tutor (either a human
being or a machine) and a student is a knowledge
communication process. This process can be divided into
a series of communication cycles and each communication
cycle consists of four phases, namely, planning,
discussing, evaluating, and remedying phases.
One major feature of the architecture proposed in this
dissertation is its curriculum knowledge base which
contains the knowledge about the course curriculum. We
have developed a representation schema for describing
the goal structure of the course, the prerequisite
relationships among the course materials, and the
multiple views to organize these materials. The
inclusion of the curriculum knowledge in a KBTS allows
the system to create different curricula for each
individual student and to diagnose the student's errors
more effectively.
The system also provides a group of operators for the
students to hand-tailor their curricula when they start
learning the course. Students can use these operators to
select a specific path to go through the course
materials, to pick a specific topic from the curricula
to study, or to remove a particular topic from the
curricula. Since students can construct their own
learning plans by these operators, they are relatively
free to determine how to study the course materials and,
as a result, can become more active in the tutoring
process.
The knowledge about a subject domain is stored in a set
of topics and a sample database. The content of a topic
consists of a set of related domain concepts. Each
concept is described by both natural and formal forms.
The sample database contains a set of sample tables and
an enhanced system catalog which contains the knowledge
about the name and semantic meanings of the database
objects.
The knowledge of writing SQL queries is embodied in a
set of examples attached to the topics. Each example is
carefully designed for one category of SQL query
problems. An example in SQL-TUTOR is a packed knowledge
chunk which can serve several important teaching
purposes, including generating problem descriptions with
different levels of details, formulating various SQL
solutions for the given problem, explaining these
solutions to the student, and evaluating SQL queries
written by the student. (Abstract shortened by UMI.)
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  3859 </NUMBER>
<ORDER>   AAG9634927 </ORDER>
<TITLE> AN EXAMINATION OF BELIEF FUNCTIONS AND OTHER MONOTONE CAPACITIES </TITLE>
<AUTHOR> BLACK, PAUL KEVIN </AUTHOR>
<YEAR> 1996 </YEAR>
<INSTITUTION> CARNEGIE-MELLON UNIVERSITY; 0041 </INSTITUTION>
<DESCRIPTORS> STATISTICS; PHILOSOPHY </DESCRIPTORS>
<ADVISER> WILLIAM F. EDDY </ADVISER>
<CLASSIFICATIONS> NIL </CLASSIFICATIONS>
<ABSTRACT>
The original motivation for this work was brought about
by observations that belief function theory had gained
widespread acceptance, especially in the artificial
intelligence community, as a convenient representation
of uncertainty. Given that belief function theory does
not correspond to Bayesian probability theory, it seemed
natural to want to examine the new theory, from
foundational issues through its potential application to
inference and decision problems, to assess the validity
of its continued use in real world applications. To
obtain sufficient understanding of the belief function
calculus, both static representations of uncertainty,
corresponding to models that represent the current state
of knowledge, and dynamic operations of forming new
belief functions from separate static representations
are considered. Along the way, realization that belief
functions correspond to a subclass of some more general
classes of convex sets of probability distributions led
to consideration of geometric forms of belief functions
and other monotone capacities.
The objectives are, consequently, to understand the
limitations of belief function theory and to provide
insights into the structure of belief functions and
other monotone capacities that might prove useful for
theories based on convex sets of probability
distributions. Other considerations include the
computational complexity of the belief function
calculus, information measures for belief functions, and
decision theoretic consequences of using belief
functions as representations of uncertainty.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  3860 </NUMBER>
<ORDER>   AAG9634905 </ORDER>
<TITLE> LEARNING RANKS FOR PATTERN RECOGNITION </TITLE>
<AUTHOR> AL-GHONEIM, KHALED ABDULAZIZ </AUTHOR>
<YEAR> 1996 </YEAR>
<INSTITUTION> CARNEGIE-MELLON UNIVERSITY; 0041 </INSTITUTION>
<DESCRIPTORS> ENGINEERING, ELECTRONICS AND ELECTRICAL; COMPUTER SCIENCE; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> NIL </ADVISER>
<CLASSIFICATIONS> ARTIFICIAL INTELLIGENCE </CLASSIFICATIONS>
<ABSTRACT>
Statistical pattern recognition has traditionally been
concerned with learning the identity of the most likely
class (among a set of possible classes). In this thesis,
we generalize the traditional statistical pattern
recognition paradigm to include obtaining as well as
using a list of the rankings of the most likely classes
for each input pattern. This generalization is achieved
using either a single class label (which is the more
common case) or using multiple labels for each input
pattern.
For the first case, we propose a hierarchical framework
in order to study the issue of obtaining ranks using a
single class label. We show that the conventional
measure of simply counting errors is not optimal in this
case. Many new alternative measures are proposed. We
then study decision combination as a particular
hierarchical model. We propose a new general combination
method that turns out to be a unifying framework for
most well-known decision combination methods. For the
second case where ranks are provided as labels, we
propose a new measure that will allow training of
classifiers to learn the ranks.
A major theme of this thesis is that the commonly used
mean squared error measure is not appropriate to learn
the ranks in either case. We show the superiority of our
proposed alternatives using Monte Carlo simulations and
two optical character recognition applications.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  3861 </NUMBER>
<ORDER>   AAG9634325 </ORDER>
<TITLE> A FRAMEWORK FOR INTELLIGENT CONTROL OF NONLINEAR SYSTEMS </TITLE>
<AUTHOR> COMMURI, SESHADRI </AUTHOR>
<YEAR> 1996 </YEAR>
<INSTITUTION> THE UNIVERSITY OF TEXAS AT ARLINGTON; 2502 </INSTITUTION>
<DESCRIPTORS> ENGINEERING, ELECTRONICS AND ELECTRICAL; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> FRANK L. LEWIS </ADVISER>
<CLASSIFICATIONS> FUZZY CONTROLLERS, NEURAL NETWORKS </CLASSIFICATIONS>
<ABSTRACT>
Real-time control of nonlinear systems remains a very
challenging area of research. While theoretical aspects
of nonlinear control have progressed, there is a large
gap between the theory and practice of controlling
physical systems. There are two drawbacks that limit the
utility of the existing theoretical developments in
practical control. Firstly, the system may not satisfy
standard assumptions such as well-defined relative
degree, and minimum phase behavior. Secondly, it is
difficult to obtain a model for the system that would
characterize the system behavior under all operating
conditions.
In this thesis, a framework for the control of nonlinear
systems that guarantees system performance under
approximate control is developed. The framework provides
rigorous mathematical formulation that results in
tractable control strategies. It is shown that the
framework results in a multi-level control strategy,
wherein the primary controller is a conventional PID
controller tracking loop and control loops of increasing
sophistication can be added depending on system
complexity. Controllers based on this framework are easy
to implement and fill a void that exists in the lack of
repeatable design techniques for nonlinear systems.
The problem of non-minimum phase behavior is tackled by
utilizing different time-scales in the system and
designing a control that not only guarantees tracking
performance but also stabilizes the internal dynamics.
The problem of stabilizing systems with ill-defined
relative degree is attempted by designing an approximate
control. Both these methods make sense intuitively and
give the controls designer an insight into tradeoffs
between stabilization and tracking performance of
nonlinear systems.
The control of systems with unknown dynamics is
confronted using Neural Networks and Fuzzy logic
controllers. The approximation properties of these
networks are studied and novel update algorithms
developed. The on-line tracking performance, stability
and robustness properties are rigorously proven and the
continuous-time and discrete-time performance verified
through numerical examples. The passivity properties of
the controllers developed are also studied and a
unifying framework is developed that can be used to
control unknown systems whose dynamics satisfy some mild
structural conditions.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  3862 </NUMBER>
<ORDER>   AAG9634083 </ORDER>
<TITLE> REINFORCEMENT LEARNING FOR JOB-SHOP SCHEDULING </TITLE>
<AUTHOR> ZHANG, WEI </AUTHOR>
<YEAR> 1996 </YEAR>
<INSTITUTION> OREGON STATE UNIVERSITY; 0172 </INSTITUTION>
<DESCRIPTORS> COMPUTER SCIENCE; OPERATIONS RESEARCH; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> NIL </ADVISER>
<CLASSIFICATIONS> MACHINE LEARNING, SPACE SHUTTLE PAYLOAD </CLASSIFICATIONS>
<ABSTRACT>
This dissertation studies applying reinforcement
learning algorithms to discover good domain-specific
heuristics automatically for job-shop scheduling. It
focuses on the NASA space shuttle payload processing
problem. The problem involves scheduling a set of tasks
to satisfy a set of temporal and resource constraints
while also seeking to minimize the total length
(makespan) of the schedule.
The approach described in the dissertation employs a
repair-based scheduling problem space that starts with a
critical-path schedule and incrementally repairs
constraint violations with the goal of finding a short
conflict-free schedule. The temporal difference (TD)
learning algorithm TD($lambda$) is applied to train a
neural network to learn a heuristic evaluation function
for choosing repair actions over schedules. This learned
evaluation function is used by a one-step lookahead
search procedure to find solutions to new scheduling
problems.
Several important issues that affect the success and the
efficiency of learning have been identified and deeply
studied. These issues include schedule representation,
network architectures, and learning strategies. A number
of modifications to the TD($lambda$) algorithm are
developed to improve learning performance. Learning is
investigated based on both hand-engineered features and
raw features. For learning from raw features, a time-
delay neural network architecture is developed to
extract features from irregular-length schedules. The
learning approach is evaluated on synthetic problems and
on problems from a NASA space shuttle payload processing
task. The evaluation function is learned on small
problems and then applied to solve larger problems. Both
learning-based schedulers (using hand-engineered
features and raw features respectively) perform better
than the best existing algorithm for this task--Zweben's
iterative repair method.
It is important to understand why TD learning works in
this application. Several performance measures are
employed to investigate learning behavior. We verified
that TD learning works properly in capturing the
evaluation function. It is concluded that TD learning
along with a set of good features and a proper neural
network is the key to this success. The success shows
that reinforcement learning methods have the potential
for quickly finding high-quality solutions to other
combinatorial optimization problems.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  3863 </NUMBER>
<ORDER>   AAGNN17184 </ORDER>
<TITLE> LIGHT ADAPTATION AND SENSITIVITY CHANGE PROCESSES IN THE HUMAN RETINA: INVESTIGATING OPTO-ELECTRONIC APPLICATIONS </TITLE>
<AUTHOR> WYSOKINSKI, TOMASZ WALDEMAR </AUTHOR>
<YEAR> 1996 </YEAR>
<INSTITUTION> SIMON FRASER UNIVERSITY (CANADA); 0791 </INSTITUTION>
<DESCRIPTORS> ENGINEERING, ELECTRONICS AND ELECTRICAL; ARTIFICIAL INTELLIGENCE; BIOLOGY, NEUROSCIENCE </DESCRIPTORS>
<ADVISER> ANDREW H. RAWICZ </ADVISER>
<CLASSIFICATIONS> NIL </CLASSIFICATIONS>
<ABSTRACT>
Real-world image acquisition systems, such as the charge
coupled device with frame grabber and computer, are
still very limited in overall performance compared with
the biological visual systems. The work done in this
thesis originates from the fact that the solutions
implemented by nature are both elegant and efficient,
and that they should be the inspiration for designers to
enhance the performance of artificial visual systems.
In the first part of this research, we investigate the
phenomena of light adaptation and sensitivity change
processes that allow an eye to operate over 12 decades
of light intensity range. Different adaptation
mechanisms are scrutinised, and a model of those
mechanisms is developed. Next we investigate how the
visual system copes with light intensities beyond its
dynamic range when glare occurs. The signal saturation
in glare phenomena is used to reveal the highly complex
structure of the retina. By applying a developed model
of signal propagation in the Outer Plexiform Layer and
by relating it to the experimental psychophysical data,
we obtain a formula for the density of horizontal cell
connections along the diameter of the human retina.
By studying the architecture, neurology and physiology
of the retina, we develop an equivalent Adaptive
Filter/Photosensitive Device Array system capable of
coping with a wide range of light conditions. The
Adaptive Filter mimics some adaptation mechanisms of the
human eye and offers the possibility of extending the
dynamic range of operation of any image-acquiring system
without affecting the electronic circuitry of the photo-
sensor array.
In the third part, we describe efforts to build one of
the possible implementations of the adaptive filter,
namely an optically addressed Photochromic Adaptive
Filter (PAF), which utilizes photochromic material
embedded in a polymeric environment. We successfully
test the concept of extending the operating range of the
constructed image-acquiring system by using optically-
addressed PAF's. The system is modified to determine a
Transformation Function of these filters using a simple,
fast and easy-to-automate method.
In the appendix we discuss several problems related to
this research program. We estimate the measurement
errors in detail. We also present a new method of
preparing thin-layer silver-halide film and describe
other possible implementations of the adaptive filter
using active opto-electronic devices.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  3864 </NUMBER>
<ORDER>   AAG9634069 </ORDER>
<TITLE> A STUDY OF MODEL-BASED AVERAGE REWARD REINFORCEMENT LEARNING  </TITLE>
<AUTHOR> OK, DOKYEONG </AUTHOR>
<YEAR> 1996 </YEAR>
<INSTITUTION> OREGON STATE UNIVERSITY; 0172 </INSTITUTION>
<DESCRIPTORS> COMPUTER SCIENCE; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> NIL </ADVISER>
<CLASSIFICATIONS> MACHINE LEARNING, AUTOMATIC GUIDED VEHICLE </CLASSIFICATIONS>
<ABSTRACT>
Reinforcement Learning (RL) is the study of learning
agents that improve their performance from rewards and
punishments. Most reinforcement learning methods
optimize the discounted total reward received by an
agent, while, in many domains, the natural criterion is
to optimize the average reward per time step. In this
thesis, we introduce a model-based average reward
reinforcement learning method called "H-learning" and
show that it performs better than other average reward
and discounted RL methods in the domain of scheduling a
simulated Automatic Guided Vehicle (AGV).
We also introduce a version of H-learning which
automatically explores the unexplored parts of the state
space, while always choosing an apparently best action
with respect to the current value function. We show that
this "Auto-exploratory H-Learning" performs much better
than the original H-learning under many previously
studied exploration strategies.
To scale H-learning to large state spaces, we extend it
to learn action models and reward functions in the form
of Bayesian networks, and approximate its value function
using local linear regression. We show that both of
these extensions are very effective in significantly
reducing the space requirement of H-learning, and in
making it converge much faster in the AGV scheduling
task. Further, Auto-exploratory H-learning
synergistically combines with Bayesian network model
learning and value function approximation by local
linear regression, yielding a highly effective average
reward RL algorithm.
We believe that the algorithms presented here have the
potential to scale to large applications in the context
of average reward optimization.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  3865 </NUMBER>
<ORDER>   AAG9633673 </ORDER>
<TITLE> APPLICATIONS OF RULE-BASE COVERAGE MEASURES TO EXPERT SYSTEM EVALUATION  </TITLE>
<AUTHOR> BARR, VALERIE B. </AUTHOR>
<YEAR> 1996 </YEAR>
<INSTITUTION> RUTGERS THE STATE UNIVERSITY OF NEW JERSEY - NEW BRUNSWICK; 0190 </INSTITUTION>
<DESCRIPTORS> COMPUTER SCIENCE; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> CASIMIR KULIKOWSKI </ADVISER>
<CLASSIFICATIONS> ARTIFICIAL INTELLIGENCE </CLASSIFICATIONS>
<ABSTRACT>
A rule-base coverage analysis method has been developed
which provides an assessment of both the rule-base under
review and the test set that has been used for
evaluation. Lack of coverage can result from either
incompleteness of the test data or errors in the rule-
base. A series of heuristics have been developed which
use coverage information and meta-knowledge about the
larger population to suggest additional test cases from
the population, in the event that the initial test set
is incomplete. This forms the basis of an incremental
approach which allows us to both increase completeness
of the test suite and improve coverage of the rule-base.
Rule-based system testing usually faces the difficult
dual problems of incompleteness and errors in both the
rule-base and the test data. Performance of a system on
a limited suite of test data is never sufficient to
predict performance on a larger set of data in routine
use without additional assumptions. An important one of
these is the assumption of representative coverage of
the population for which the system is intended. The
heuristic approach to test data selection is
demonstrated using information generated by TRUBAC, a
tool which implements the coverage analysis methods. We
have applied these techniques to analyze a number of
prototype systems for diagnosis of rheumatological
diseases. In addition, we demonstrate the use of
coverage information to identify class dependencies and
guide rule-base pruning. We also introduce a complexity
metric for rule-bases. Finally, we discuss extensions of
the coverage measures for rule-based systems with
dynamic computation of certainty factors.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  3866 </NUMBER>
<ORDER>   AAG9633672 </ORDER>
<TITLE> MODEL-BASED REFINEMENT OF SEARCH HEURISTICS </TITLE>
<AUTHOR> BARLEY, MICHAEL W. </AUTHOR>
<YEAR> 1996 </YEAR>
<INSTITUTION> RUTGERS THE STATE UNIVERSITY OF NEW JERSEY - NEW BRUNSWICK; 0190 </INSTITUTION>
<DESCRIPTORS> COMPUTER SCIENCE; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> L. STEINBERG </ADVISER>
<CLASSIFICATIONS> MACHINE LEARNING, ARTIFICIAL INTELLIGENCE </CLASSIFICATIONS>
<ABSTRACT>
Search is one of the central problem-solving paradigms
in Artificial Intelligence. Unfortunately, search can be
quite expensive. Problem-solvers frequently use
rejection heuristics to lower the cost of their
searches. Unfortunately, these rejection heuristics can
also prevent a problem-solver from solving a problem.
I describe a new learning algorithm, SHAPeS, that
enables the learner to modify both rejection heuristics
implemented explicitly as search control rules and those
implemented implicitly by either being embedded within
the program code or by being incorporated into the
search space generators. The SHAPeS learning algorithm
only requires a solution to be supplied rather than
needing that solution's problem-solving trace. This
frees the system from having to find the solution
itself. The SHAPeS algorithm is generally applicable to
search-based problem-solvers. I discuss both the
conditions for the algorithm's correctness and its
computational complexity.
I implemented a restricted version of SHAPeS, called
Bacall, and in this thesis report on the results of
experiments conducted to assess the utility of the
Bacall learned modifications. The experiments show that
not only can Bacall learned modifications extend a
problem-solver coverage but can also enable it to run
faster. The experiments also compare the utility of the
Bacall learned modifications with the utility of current
approaches to modifying rejection heuristics. The
experiments show that Bacall learned modifications can
improve the problem-solver's performance more than
comparable modifications learned by the alternative
approaches.
Lastly, I identify three types of search control
knowledge interactions that complicate the analysis of
rejection heuristics' effects upon a problem-solver's
coverage. These interactions cause modifications to a
problem-solver's search control knowledge to have
counter-intuitive effects upon the problem-solver's
coverage. For example, removing rejection rules or
specializing their preconditions can cause the problem-
solver to become unable solve some problems. I also
identify conditions that are sufficient to eliminate
these types of interactions and that simplify the
analysis of the effect of modifying a problem-solver's
search control logic upon its coverage.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  3867 </NUMBER>
<ORDER>   AAG9633450 </ORDER>
<TITLE> EFFECT OF LIGHT SOURCE ON THE SORTING PERFORMANCE OF A VISION-BASED ROBOT SYSTEM </TITLE>
<AUTHOR> LI, JOHNNY TIENYI </AUTHOR>
<YEAR> 1996 </YEAR>
<INSTITUTION> UNIVERSITY OF NORTHERN IOWA; 0743 </INSTITUTION>
<DESCRIPTORS> ENGINEERING, INDUSTRIAL; ENGINEERING, ELECTRONICS AND ELECTRICAL; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> AHMED ELSAWY </ADVISER>
<CLASSIFICATIONS> COMPUTER VISION </CLASSIFICATIONS>
<ABSTRACT>
Industries look toward computer vision as a means to
automate materials handling. To make this choice more
appealing, useful and feasible vision applications must
be developed. However, illuminance variation in the
factory environment can undermine the capability and
applicability of vision-based control systems. The
purposes of this study were (a) to design and develop a
vision-based robot material sorting system, (b) to
determine the optimal settings for this system under
fluorescent and incandescent lighting for two different
color parts on a moving conveyor, and (c) to determine
the sorting performance of this system under each light
source.
The main components of this experimental system
consisted of: (a) a robot system with a slide base and a
speed controlled conveyor, (b) a ROBOTVISION plus vision
system, (c) an incandescent lamp light intensity
controller, and (d) two PCs. By integrating these
components, color sorting applications were developed.
This study explored two sorting methods. Method A used
the difference in object descriptors to separate the
dominos. This method worked in a limited range of
illuminance and identification tolerance for both light
sources. Method B used the difference in the observed
"saturation" response of the charge coupled device
camera to separate the dominos. This method worked in a
wide range of illumination with no stipulation on
identification tolerances for both light sources.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  3868 </NUMBER>
<ORDER>   AAG9633359 </ORDER>
<TITLE> REINFORCEMENT LEARNING FOR DYNAMIC ROBOTIC SYSTEMS </TITLE>
<AUTHOR> HU, YENDO </AUTHOR>
<YEAR> 1996 </YEAR>
<INSTITUTION> UNIVERSITY OF CALIFORNIA, SAN DIEGO; 0033 </INSTITUTION>
<DESCRIPTORS> ENGINEERING, ELECTRONICS AND ELECTRICAL; COMPUTER SCIENCE; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> RONALD D. FELLMAN </ADVISER>
<CLASSIFICATIONS> MACHINE LEARNING, ARTIFICIAL INTELLIGENCE </CLASSIFICATIONS>
<ABSTRACT>
Adaptive algorithms are the only solution towards
solving control problems in an unknown or constantly
changing environment. In dynamic robotic control, these
algorithms may offer solutions that will one day bring
laboratory robots into the unpredictable real world.
Three feedback methods exist for adaptive algorithms:
supervised, reinforced, and unsupervised. Of these,
reinforcement feedback balances the trade-off between
learning ability and a priori knowledge. This
dissertation focuses on various issues associated with
reinforcement learning algorithms for dynamic robotic
control.
Reinforcement algorithms differ from each other in their
performance in the three key areas: (1) computational
complexity, (2) learning speed, and (3) flexibility.
This dissertation presents five different reinforcement
algorithms, each originating from research emphasizing
different combinations of these three key areas.
The first algorithm is the result of research
emphasizing both reducing the computational complexity
and increasing the learning speed. This algorithm uses a
state history queue to decouple the computational demand
from the number of quantized states within the input
space. It increases learning speed by associating
neighboring state information, and optimizes memory use
by dynamically allocating memory when needed.
The second algorithm is designed to learn complex tasks
fast. A framework within the algorithm permits the
creation of localized reinforcement rules, enabling one
to break down a complex task into a set of simple tasks.
This algorithm can learn to guide the cartpole balancer
through a cyclic trajectory.
The third algorithm came from research focused on
generalizing the algorithm. It eliminates the need to
prequantize the input state space by adaptively
quantizing a continuous input state space based on the
robot kinematics.
The fourth algorithm presents an alternative adaptive
quantization method that exploits the reset event.
And finally, the last algorithm is the result of
research attempting to address all three key areas. This
algorithm adaptively learns by building a graph. With
this graph structure, the algorithm can store all
observed events. By effectively analyzing the stored
events, it can then derive successful controllers for
the specific application. This algorithm is flexible in
that it assumes no knowledge of an effective state space
quantization setup, goal region, or robot dynamics. This
method can learn to control a puck-on-hill task starting
at sub-optimal positions and rocket landing missions.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  3869 </NUMBER>
<ORDER>   AAG9633331 </ORDER>
<TITLE> NEURAL NETWORK MODELS IN PREDICTING INSURANCE INSOLVENCY AND DETECTING INSURANCE CLAIM FRAUD </TITLE>
<AUTHOR> XIA, XIAOHUA </AUTHOR>
<YEAR> 1996 </YEAR>
<INSTITUTION> THE UNIVERSITY OF TEXAS AT AUSTIN; 0227 </INSTITUTION>
<DESCRIPTORS> OPERATIONS RESEARCH; COMPUTER SCIENCE; ECONOMICS, FINANCE; ECONOMICS, COMMERCE-BUSINESS </DESCRIPTORS>
<ADVISER> PATRICK LEE BROCKETT </ADVISER>
<CLASSIFICATIONS> NIL </CLASSIFICATIONS>
<ABSTRACT>
Operations research is a quantitative method constructed
for solving practical problems in a variety of areas
such as logistics and transportation, job scheduling,
and strategic management. Operations Research has also
enjoyed numerous successful applications in finance.
Risk management and insurance is one of the major fields
in finance which presents many interesting and
challenging issues requiring quantitative thinking and
computational solving. Theoretical studies and practical
solutions in applying operations research methods to
problems in risk management and insurance have been
successfully delivered in the past forty years. In this
thesis, we provide our overview of many of those studies
and applications in effort to shed some light on the
future success in the field as well as provide an
educational tool.
Neural networks is a branch of artificial intelligence
studies. Kohonen's Self-Organizing Feature Maps is one
of the major neural network models which have found
successful applications, while feed-forward and back-
propagation neural networks are apparently the most
commonly used neural network model. Both types of neural
network models are found to be useful tools in attacking
individual problems arising from risk management and
insurance. Specifically, one feed-forward neural network
is used to predict the insolvency of Texas Property and
Casualty insurance companies. This methodology is found
to outperform discriminant analysis, logistic analysis
and some other rating methods in their prediction
accuracy.
Bodily injury (BI) and personal injury protection (PIP)
are two major automobile insurance business coverages
which suffer serious problems of claim buildup and
fraud. We develop a methodology which is a combination
of modified Kohonen's Feature Maps, feature map
partitioning, and utilization of partially available
priori information for the purpose of tackling claim
fraud problems in the above mentioned automobile
insurance coverage areas. The validation by feed-forward
neural networks, used as an approximation, shows that
our methodology outperforms the assessments by claim
professionals in the consistency of evaluating the
suspicion level of insurance claims, and in the quality
of result presentation and interpretation. The data sets
in our study were provided by the Texas Department of
Insurance and the Automobile Insurers Bureau of
Massachusetts.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  3870 </NUMBER>
<ORDER>   AAG9633230 </ORDER>
<TITLE> COMBINING SYMBOLIC AND CONNECTIONIST LEARNING METHODS TO REFINE CERTAINTY-FACTOR RULE-BASES </TITLE>
<AUTHOR> MAHONEY, J. JEFFREY </AUTHOR>
<YEAR> 1996 </YEAR>
<INSTITUTION> THE UNIVERSITY OF TEXAS AT AUSTIN; 0227 </INSTITUTION>
<DESCRIPTORS> COMPUTER SCIENCE; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> RAYMOND J. MOONEY </ADVISER>
<CLASSIFICATIONS> ARTIFICIAL INTELLIGENCE </CLASSIFICATIONS>
<ABSTRACT>
This research describes the system R scAPTURE, which is
designed to revise rule bases expressed in certainty-
factor format. Recent studies have shown that learning
is facilitated when biased with domain-specific
expertise, and have also shown that many real-world
domains require some form of probabilistic or uncertain
reasoning in order to successfully represent target
concepts. R scAPTURE was designed to take advantage of
both of these results.
Beginning with a set of certainty-factor rules, along
with accurately-labelled training examples, R scAPTURE
makes use of both symbolic and connectionist learning
techniques for revising the rules, in order that they
correctly classify all of the training examples. A
modified version of backpropagation is used to adjust
the certainty factors of the rules, ID3's information-
gain heuristic is used to add new rules, and the Upstart
algorithm is used to create new hidden terms in the rule
base.
Results on refining four real-world rule bases are
presented that demonstrate the effectiveness of this
combined approach. Two of these rule bases were designed
to identify particular areas in strands of DNA, one is
for identifying infectious diseases, and the fourth
attempts to diagnose soybean diseases. The results of R
scAPTURE are compared with those of backpropagation,
C4.5, K scBANN, and other learning systems. R scAPTURE
generally produces sets of rules that are more accurate
than these other systems, often creating smaller sets of
rules and using less training time.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  3871 </NUMBER>
<ORDER>   AAG9633111 </ORDER>
<TITLE> ON THE ROLE OF SINGULARITIES IN NEURAL NETWORKS </TITLE>
<AUTHOR> CHAKRAVARTHY, SRINIVASA VADDADI </AUTHOR>
<YEAR> 1996 </YEAR>
<INSTITUTION> THE UNIVERSITY OF TEXAS AT AUSTIN; 0227 </INSTITUTION>
<DESCRIPTORS> ENGINEERING, ELECTRONICS AND ELECTRICAL; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> JOYDEEP GHOSH </ADVISER>
<CLASSIFICATIONS> RADIAL BASIS FUNCTION, CLUSTERING, CUSP </CLASSIFICATIONS>
<ABSTRACT>
The need to convert quantitative information into
qualitative form often arises in neural network design.
Since singularities of a dynamic system mark a sudden,
qualitative change in system behavior, it is proposed
that singularities in neural network dynamics may serve
as conduits between qualitative and quantitative
domains.
The role of singularities in a clustering procedure
based on the Radial Basis Function Network is studied.
The technique performs scale-based clustering, wherein
the number of clusters obtained depends on the width
parameter, which plays the role of a scale. Cluster
centers are obtained as fixed-points of an underlying
dynamic system. Cluster merging, which occurs at
specific scale values as scale is increased, corresponds
to singularities in dynamics. Thus, singularities are
responsible for hierarchical organization of the
clusters. The problem of image enhancement is formulated
as a clustering problem to which the above-mentioned
algorithm is applied. The resulting enhancement scheme
suppresses noise and preserves sharpness of the edges at
the same time. In the neighborhood of an edge, the
network dynamics are singular, which suggests a new
approach to defining an image edge.
While learning an unknown input-output task, humans
first strive to understand the qualitative structure of
the function and subsequently try to improve
(quantitative) accuracy. To implement this idea, we
introduce the concept of function emulation, according
to which the goal of network training is to 'emulate'
the qualitative structure of the target function. The
framework of Catastrophe Theory is used to characterize
the qualitative structure of a smooth function. For a
large class of targets, function emulation produces a
graph-like abstraction of a quantitative input-output
relation.
Cognitive science recognizes the brain operates on
patterns rather than numbers. Patterns are more
appropriately described as topological forms,
qualitative properties rather than numerical quantities.
In any effort to introduce "pattern-thinking", in this
sense, to neural network research, the concepts of
differential topology and Catastrophe theory, could be a
tremendous help.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  3872 </NUMBER>
<ORDER>   AAG9632923 </ORDER>
<TITLE> UNSUPERVISED AND SUPERVISED FUZZY NEURAL NETWORK ARCHITECTURE, WITH APPLICATIONS IN MACHINE VISION FUZZY OBJECT RECOGNITION AND INSPECTION </TITLE>
<AUTHOR> CHEN, BAOSHAN </AUTHOR>
<YEAR> 1996 </YEAR>
<INSTITUTION> OKLAHOMA STATE UNIVERSITY; 0664 </INSTITUTION>
<DESCRIPTORS> ENGINEERING, MECHANICAL; ENGINEERING, ELECTRONICS AND ELECTRICAL; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> LAWRENCE L. HOBEROCK </ADVISER>
<CLASSIFICATIONS> NIL </CLASSIFICATIONS>
<ABSTRACT>
Scope of study. In this research, an unsupervised fuzzy
neural network for fuzzy patterns, termed FUZART, based
on Adaptive Resonance Theory networks has been proposed.
FUZART employs the two stages of self-organization and
decision making. It accepts fuzzy input patterns and
provides output decisions in terms of membership values.
As an extension of FUZART, a new supervised fuzzy neural
network scheme called FUZAMP has been developed that can
quickly and efficiently handle hybrid mixtures of fuzzy
data and numerical data. This fuzzy neural network can
be applied to classification problems with non-linearly
separable fuzzy data, and can also be employed as a
fuzzy inference engine using linguistic knowledge
described by fuzzy rules and numerical data sampled by
measurement instruments. In order to implement this work
in a real vision system, a multilayer multi-input, multi-
output fuzzy logic controller (FLC) has been proposed
and implemented to realize automatic adjustment of the
camera parameters "gain" and "offset" to compensate for
power fluctuation, changes in ambient light, and camera
sensitivity drift. The multilayer FLC yields faster
response with less overshoot than that of a conventional
single layer FLC, and provides excellent camera
performance.
Findings and conclusions. The new unsupervised and
supervised fuzzy neural networks have been evaluated by
simulations and real machine vision applications. FUZART
has the ability to learn on-line using only a few
training epochs and to provide reasonable clustering
decisions for fuzzy patterns. FUZAMP has superior fuzzy
classification and fuzzy inference capability and
stability with fuzzy data. The advantages of FUZAMP
compared with other fuzzy neural networks are that
FUZAMP can realize faster and more efficient training
for fuzzy data and achieve better performances. FUZAMP
has been used to deal with situations where the
available training data from a machine vision system
includes uncertainty. It performs well when used to
recognize different types of fuzzy objects presented at
different locations and orientations in the camera Field
of View. In addition, FUZAMP has been implemented to
correlate human evaluations with machine evaluations of
the cleanliness of dishes. Results are compared to those
obtained using the so-called fuzzy ARTMAP neural
network, with FUZAMP achieving better accuracy than the
fuzzy ARTMAP using the same training exemplars.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  3873 </NUMBER>
<ORDER>   AAG9632732 </ORDER>
<TITLE> DAMAGE DETECTION AND RELIABILITY ASSESSMENT USING ANALYTICALLY BASED ARTIFICIAL INTELLIGENCE </TITLE>
<AUTHOR> LIN, TSANN-YEU </AUTHOR>
<YEAR> 1996 </YEAR>
<INSTITUTION> NORTHWESTERN UNIVERSITY; 0163 </INSTITUTION>
<DESCRIPTORS> ENGINEERING, MECHANICAL; ENGINEERING, AEROSPACE; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> NIL </ADVISER>
<CLASSIFICATIONS> NIL </CLASSIFICATIONS>
<ABSTRACT>
In the pursuit of further improvement of reliability and
safety of dynamic systems, we have developed more
effective and accurate methods for damage detection and
reliability assessment by using analytical and
analytically based artificial intelligence techniques.
Damage detection problems are formulated as inverse
eigenvalue problems. An exact functional relationship
between system eigenvalues and damage parameters are
developed and combined with partial eigenvector method
or system perturbation method to obtain an unique and
exact inverse solution. The damage detection problem is
simplified by decomposing the problem into two stages--
Isolation and Identification. All small or large, single
or multiple damages can be detected precisely.
Based on the observation of the analytical knowledge and
the effectiveness of decomposition, we then design an
analytically based artificial neural network in
modularized architecture for damage detection. The
proposed analytically based neural network, due to the
simple design, can eliminate intensive training and
provide greater performance.
A very effective way to use time-domain data for real-
time system health monitoring is also developed. This
includes a general method for constructing simplified
equivalent dynamic model and an innovative hybrid neural
network architecture, which consists of a recurrent
network for system identification and a multilayer
percetron network for damage parameters identification.
Simulation examples show that the proposed method can
isolate faulty elements rapidly.
The final part of this research deals with reliability
assessment with fuzzy information. Fuzzy-set theory is
extended and applied to the reliability problems. An
unified approach is developed to treat different types
of variables including random, fuzzy, random-fuzzy
hybrid, and random with fuzzy information in reliability
analysis. Neural networks are proposed to construct the
fuzzy membership functions. This fuzzy-neural-based
approach offers a way to incorporate engineer judgments
into reliability analysis, and opens a way to
computerize and to integrate with other AI techniques
for reliability analysis.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  3874 </NUMBER>
<ORDER>   AAGNN16235 </ORDER>
<TITLE> APPLICATION OF ARTIFICIAL NEURAL NETWORKS TO DISTANCE PROTECTION  </TITLE>
<AUTHOR> QI, WEIGUO </AUTHOR>
<YEAR> 1996 </YEAR>
<INSTITUTION> THE UNIVERSITY OF MANITOBA (CANADA); 0303 </INSTITUTION>
<DESCRIPTORS> ENGINEERING, ELECTRONICS AND ELECTRICAL; ARTIFICIAL INTELLIGENCE; ENERGY </DESCRIPTORS>
<ADVISER> G. W. SWIFT </ADVISER>
<CLASSIFICATIONS> PATTERN RECOGNITION, POWER LINES </CLASSIFICATIONS>
<ABSTRACT>
Artificial neural network (ANN) strategy was developed
as a method of using a large number of simple parallel
processors to recognize preprogrammed, or "learned",
patterns. This approach can be adapted to recognizing
learned patterns of behavior in electric power-systems
where exact functional relationships are neither well
defined nor easily computable, and is able to compute
the answer quickly by using associations learned from
previous experience. Certain problems in power systems,
with their inherent nonlinear and complex nature, seem
amenable to solutions through trained ANNs.
A distance relay is an important protective relay with
its excellent performance for transmission line
protection. However, the suitability of conventional
distance relays to adapt to change in source impedance
and to the effect of remote infeed and nonlinear arcing
fault resistance is still unsatisfied. Utilization of
artificial neural networks is a good strategy for those
problems, using pattern recognition, a basic function of
distance relays.
The goal of this thesis is concentrated on creating more
selective ground fault detection by using artificial
neural networks. Two applications of artificial neural
networks to distance protection are presented in this
thesis, one for non-linear arcing fault resistance and
another for remote infeed. At the current stage of
research, only single-line-to-ground faults are
considered because most faults in power system
transmission lines are line-to-ground faults.
In the case concerning the effect of remote source
infeed, research was focused on creating more sensitive
ground fault detection in spite of pre-fault loading in
either direction, variable source impedance and variable
ground fault resistance. A matured power system
simulator named Electromagnetic Transients Simulation
Program (EMTDC), was utilized to create the training and
testing cases with varying system parameters. The
proposed neural network was trained using many load and
fault cases, tested using cases with different system
conditions and run using more detailed fault cases along
the whole transmission line.
In the case concerning the nonlinear nature of arcing
fault resistance, research was focused on creating more
sensitive arcing fault detection, especially for radial
distribution lines where arc resistance can be a
significant part of the zero sequence impedance. A
neural network was trained, tested and run by three sets
of pattern vectors with different system conditions. A
simple power system model and a nonlinear arcing fault
resistance model were used to collect training, testing
and running patterns for the proposed neural network. A
new operating characteristic based on fault voltage
instead of fault resistance was devised.
The prospective ANN distance relays showed very good
performance in detecting a single-line-to-ground fault
with the effect of remote source infeed, or with
nonlinear arcing resistance along the whole transmission
line. Basic principles learned from this investigation
of application of ANN's to power system protection will
be of value to future advances in this direction.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  3875 </NUMBER>
<ORDER>   AAG9632532 </ORDER>
<TITLE> FUZZY LOGIC ADAPTIVE DECOUPLED FLIGHT CONTROLS FOR GENERAL AVIATION AIRPLANES </TITLE>
<AUTHOR> DUERKSEN, NOEL </AUTHOR>
<YEAR> 1996 </YEAR>
<INSTITUTION> WICHITA STATE UNIVERSITY; 0260 </INSTITUTION>
<DESCRIPTORS> ENGINEERING, AEROSPACE; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> NIL </ADVISER>
<CLASSIFICATIONS> NIL </CLASSIFICATIONS>
<ABSTRACT>
It has been hypothesized that a human pilot uses the
same set of generic skills to control a wide variety of
aircraft. If this is true, then it should be possible to
construct an electronic controller which embodies this
generic skill set such that it can successfully control
different airplanes without being matched to a specific
airplane.
In an attempt to create such a system, a fuzzy logic
controller was devised to control throttle position and
another to control elevator position. These two
controllers were used to control flight path angle and
airspeed for both a piston powered single engine
airplane simulation and a business jet simulation.
Overspeed protection and stall protection were
incorporated in the form of expert systems supervisors.
It was found that by using the artificial intelligence
techniques of fuzzy logic and expert systems, a generic
longitudinal controller could be successfully used on
two general aviation aircraft types that have very
different characteristics. These controllers worked for
both airplanes over their entire flight envelopes
including configuration changes. The controllers for
both airplanes were identical except for airplane
specific limits (maximum allowable airspeed, throttle
lever travel, etc.). The controllers also handled
configuration changes without mode switching or
knowledge of the current configuration.
This research validated the fact that the same fuzzy
logic based controller can control two very different
general aviation airplanes. It also developed the basic
controller architecture and specific control parameters
required for such a general controller.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  3876 </NUMBER>
<ORDER>   AAGNN09369 </ORDER>
<TITLE> AN EXPERIMENTAL APPROACH TO ROBOTIC GRASPING USING ARTIFICIAL NEURAL NETWORKS AND REINFORCEMENT FEEDBACK </TITLE>
<AUTHOR> MOUSSA, MEDHAT AHMED </AUTHOR>
<YEAR> 1996 </YEAR>
<INSTITUTION> UNIVERSITY OF WATERLOO (CANADA); 1141 </INSTITUTION>
<DESCRIPTORS> ENGINEERING, ELECTRONICS AND ELECTRICAL; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> NIL </ADVISER>
<CLASSIFICATIONS> ARTIFICIAL INTELLIGENCE </CLASSIFICATIONS>
<ABSTRACT>
During the past two decades, research in robotic
grasping and manipulation has focused on analyzing the
grasp operation and developing analytic or knowledge-
based rules for grasping and manipulating objects. This
approach, while successful for many industrial
applications, suffers from its inability to survive in
uncertain environments or when the underlying
assumptions about grasping rules are not valid.
In this thesis, we present an experimental approach to
robotic grasping that is based on developing a generic
representation of grasping rules which allows these
rules to be learned by experiments. Grasping rules
acquired in this fashion can then be used on different
objects using different grippers. The internal learning
mechanism consists of a hierarchy of neural networks is
grouped into three functional units: a perceptual
schema, a grasp image and a motor schema. The
experimentation strategy applies reinforcement feedback
to minimize the number of experiments and achieve a
better generalization. A theoretical formulation of the
generic grasp representation is provided and then the
system architecture and the learning and experimentation
strategy are discussed. Finally, results of experiments
on a 15 object database are presented. The results show
the ability of the system to learn grasping rules in a
finite set of experiments and to apply grasping
knowledge acquired from experiments on one object to
grasping of another.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  3877 </NUMBER>
<ORDER>   AAGNN09339 </ORDER>
<TITLE> THREE-DIMENSIONAL MODELING USING HIERARCHICAL TOPOGRAPHIC TRIANGULAR MESHES </TITLE>
<AUTHOR> FAYEK, REDA EZZAT </AUTHOR>
<YEAR> 1996 </YEAR>
<INSTITUTION> UNIVERSITY OF WATERLOO (CANADA); 1141 </INSTITUTION>
<DESCRIPTORS> ENGINEERING, SYSTEM SCIENCE; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> ANDREW K. C. WONG </ADVISER>
<CLASSIFICATIONS> NIL </CLASSIFICATIONS>
<ABSTRACT>
Advances in sensing and computing technologies yield
huge amounts of three-dimensional (3D) sensory data.
Real-world 3D modeling applications often avoid using
this data because of its complexity. Sensory data can be
used to automatically synthesize the 3D models which
were traditionally constructed manually.
The objective of this research is to bridge the semantic
gap between large, unorganized numeric 3D range data and
high-level symbolic knowledge on complex scenes
generally assumed to be available a priori in AI
reasoning applications. Most research efforts tend to
address one end of this continuum, focusing either on
signal processing and sensing techniques or on analytic
reasoning and knowledge representations. Assumptions
made on these two ends of the spectrum usually differ
and, therefore, few systems address both sensing and
reasoning.
We present a framework which specifically addresses the
grey area that was often ignored. We build a hierarchy
of irregular triangular meshes to represent 3D range
data and identify its important; surface features. New
multiresolution topographic mesh coarsening and adaptive
improvement algorithms reduce the mesh complexity while
preserving the detected features. Application-
independent labels are automatically assigned to scene
features and used to construct application-dependent
generic symbolic models in the form of attributed
hypergraph representation (AHR). We incrementally
abstract sensory data into quantitative and qualitative
models for remote sensing, outdoor autonomous
navigation, planetary exploration and reverse CAD. Our
hierarchical triangular mesh uniform model elegantly
bridges the gap and our results pave a new research
avenue for automated machine perception.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  3878 </NUMBER>
<ORDER>   AAGNN09066 </ORDER>
<TITLE> USER MODELS FOR INTENT-BASED AUTHORING </TITLE>
<AUTHOR> CSINGER, ANDREW </AUTHOR>
<YEAR> 1996 </YEAR>
<INSTITUTION> THE UNIVERSITY OF BRITISH COLUMBIA (CANADA); 2500 </INSTITUTION>
<DESCRIPTORS> COMPUTER SCIENCE </DESCRIPTORS>
<ADVISER> DAVID POOLE </ADVISER>
<CLASSIFICATIONS> VIDEO AUTHORING, GRAPHICAL USER INTERFACE </CLASSIFICATIONS>
<ABSTRACT>
Authoring is the collection, selection, preparation and
presentation of information to one or more readers by an
author. The thesis takes a new, critical look at
traditional approachers to authoring, by asking what
knowledge is required and at which stages of the
process. From this perspective, traditional authoring is
seen to entrench an early commitment to both form and
content.
Although the late binding of form is now commonplace in
structured document preparation systems, a similar delay
in the binding of content in necessary to achieve user-
tailored interaction. The authoring paradigm we have
developed to service this goal is called intent-based
authoring, because the author supplies at compile-time a
communicative goal, or intent. Just as SGML editors and
HTML browsers defer rendering decisions until run-time
by referring to a local style-sheet, intent-based
authoring systems defer content-selection decisions
until run-time when they refer to models of both author
and reader(s).
This thesis shows that techniques from artificial
intelligence can be developed and used to acquire,
represent and exploit such models. Probabilistic
abduction is used to recognize user models, and cost-
based abduction to design tailored presentations. These
techniques are combined in a single framework for best-
first recognition and design.
These reasoning techniques are further allied with an
interaction paradigm we call scrutability, whereby users
critique the model in pursuit of better presentations;
users see a critical subset of the model determined by
sensitivity analysis and can change values through a
graphical user interface. The interactivity is modelled
to ensure that representations of the user model to the
user are made in the most perceptually salient manner.
A prototype for intent-based video authoring is
described. Video is used as a test medium because it is
a "worst case" temporally linear medium; a viable
solution to video authoring problems should apply easily
to more tractable traditional media.
The primary contribution of this dissertation is to the
field of applied artificial intelligence, specifically
to the emerging field of user modelling. The central
contribution is the intent-based authoring framework for
separating intent from content.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  3879 </NUMBER>
<ORDER>   AAG9635475 </ORDER>
<TITLE> USING NATURAL LANGUAGE IN COMPUTER-AIDED ARCHITECTURAL DESIGN </TITLE>
<AUTHOR> YEH, GEORGE TYE-YAN </AUTHOR>
<YEAR> 1996 </YEAR>
<INSTITUTION> THE UNIVERSITY OF MICHIGAN; 0127 </INSTITUTION>
<DESCRIPTORS> ARCHITECTURE; COMPUTER SCIENCE </DESCRIPTORS>
<ADVISER> JAMES TURNER; HAROLD BORKIN </ADVISER>
<CLASSIFICATIONS> NIL </CLASSIFICATIONS>
<ABSTRACT>
Computer Science, Natural Language Processing and
Artificial Intelligence researchers have developed many
solutions to address computational natural language
understanding issues. Some of the solutions have
potential applications in Computer-Aided Architectural
Design (CAAD).
However, all language processors have limitations in
interpreting English expressions because they cannot
process all conceivable syntactic structures and resolve
all semantic ambiguities with limited representations of
syntactic, semantic and conceptual rules. They also,
because of limited resources, cannot represent all word
meanings with a small number of primitive concepts.
This research has tested the selected solutions,
addressed the above limitations, and investigated a
natural language approach to defining a language for
CAAD applications. The language and the CAAD system are
taken together as the proposed system. The language uses
a subset of natural (American) English expressions. A
prototype of the proposed system is developed to assist
the research.
Addressing the above limitations, this research adopts a
strategy that encourages the use of a simple clear
expression for syntax structure and word meaning. The
prototype informs a user of interpretation problems,
such as a syntax error, semantic ambiguity, or lack of
conceptual definition. The prototype uses a
hierarchical, multiple-inheritance object-oriented data
base of concepts. The hierarchical structure allows
concepts to be referred to by generalization, some of
which represent primitive concepts. The multiple-
inheritance feature enables creating a higher-level
concept with multiple meanings. The usage rules,
conceptual representations and literal meanings of
language tokens are defined in a dictionary. The
dictionary can be modified and expanded, which allows
the work of defining language tokens to be divided, and
done simultaneously.
This research concludes that setting up the proposed
system is feasible and good for many applications. The
prototype is capable of pointing out ambiguous
expressions, which help designers avoid miscommunication
in a collaborative design environment. Other
applications such as extracting design goals, assigning
or interpreting meanings with a geometric object can be
extended with the prototype by writing additional usage
rules for design and geometry concepts. This
dissertation provides the groundwork for other CAAD
researchers who have similar interests in language
processing.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  3880 </NUMBER>
<ORDER>   AAG1379568 </ORDER>
<TITLE> RETRAINING NEURAL NETWORKS FOR THE PREDICTION OF DST IN THE RICE MAGNETOSPHERIC SPECIFICATION AND FORECAST MODEL </TITLE>
<AUTHOR> COSTELLO, KIRT ALLEN </AUTHOR>
<YEAR> 1996 </YEAR>
<INSTITUTION> RICE UNIVERSITY; 0187 </INSTITUTION>
<DESCRIPTORS> PHYSICS, ASTRONOMY AND ASTROPHYSICS; PHYSICS, FLUID AND PLASMA; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> NIL </ADVISER>
<CLASSIFICATIONS> NIL </CLASSIFICATIONS>
<ABSTRACT>
Artificial Neural Networks have been developed at Rice
University for the forecasting of the Dst index from
solar wind and Dst parameters. The one hour Dst index is
an Earth based measurement of variations in the H-
component of the magnetic field that is indicative of
the strength of the ring current, and thus magnetic
storms. Comparison of the neural networks' outputs to
the OMNI dataset values of Dst will be presented. These
results verify the success of the neural networks in
predicting Dst. Network performance when predicting Dst
two or more hours into the future and testing of MSFM
output based on neural net Dst input for the August 1990
storm will be presented. Comparisons between MSFM
equatorial particle fluxes and CRRES satellite
observations show the MSFM 10 keV proton equatorial
fluxes raise interesting questions about the MSFM's use
of the Dst input parameter.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  3881 </NUMBER>
<ORDER>   AAG1379008 </ORDER>
<TITLE> APPLIED FUZZY SYSTEMS THEORY AS A BASIS FOR STRATEGICALLY ENABLING TECHNOLOGIES IN THE 21ST CENTURY </TITLE>
<AUTHOR> NICODEMUS, THOMAS DALE </AUTHOR>
<YEAR> 1996 </YEAR>
<INSTITUTION> UNIVERSITY OF HOUSTON-CLEAR LAKE; 1251 </INSTITUTION>
<DESCRIPTORS> SOCIOLOGY, THEORY AND METHODS; COMPUTER SCIENCE; ENGINEERING, ELECTRONICS AND ELECTRICAL; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> OLIVER W. MARKLEY </ADVISER>
<CLASSIFICATIONS> NIL </CLASSIFICATIONS>
<ABSTRACT>
This study makes a future oriented assessment of the
current and possible future technologies enabled by
Fuzzy Systems Theory. The thesis is that Applied Fuzzy
Systems Theory will in the next decade become an
important basis for new strategically enabling
technologies in the disciplines that include fields of
study dealing with complexity and change.
Conclusions and positions reached in this study include:
(1) fuzzy systems are becoming pervasive; (2) they are
subtly changing our everyday lives; (3) they have
enabled new technologies critical to competitive
advantage in the global economy and will continue to do
so; (4) in the future they may possibly change
transportation and communications as we know them; (5)
in the future they may change war as we know it; (6)
fuzzy systems provide powerful tools for preserving
scarce nonrenewable resources; (7) they enable more
efficient use of existing electrical production; (8)
they may provide technologies that will preserve
millions of American jobs; (9) it appears that some
newly enabled technologies are so advanced that society
is unprepared to accept them and will likely remain so
for many years; (10) and the cultural factors which have
played a crucial role in resistance to fuzzy systems in
the United States and in particular within academia will
remain unchanged for many more years. (Abstract
shortened by UMI.)
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  3882 </NUMBER>
<ORDER>   AAG1378866 </ORDER>
<TITLE> FUZZY LOGIC CONTROL FOR A TWO LINK MANIPULATOR </TITLE>
<AUTHOR> PRATURU, SAI PRASAD </AUTHOR>
<YEAR> 1996 </YEAR>
<INSTITUTION> UNIVERSITY OF ALABAMA IN HUNTSVILLE; 0278 </INSTITUTION>
<DESCRIPTORS> ENGINEERING, ELECTRONICS AND ELECTRICAL; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> NIL </ADVISER>
<CLASSIFICATIONS> NIL </CLASSIFICATIONS>
<ABSTRACT>
Robotic controls have been the area of research for many
years and work is still being done to develop simple,
efficient and robust control methods. The highly
nonlinear nature of the robot makes its control a
difficult task. This thesis develops a mathematical
model for a two link planar manipulator based on Denavit-
Hartenberg representation of coordinate frames and
Newton-Euler formulation of dynamic equations. A fuzzy
logic controller is designed and simulated for this two
link manipulator and its results are compared to a
Linear Quadratic Gaussian Controller.
The concept and use of Fuzzy logic based control for non-
linear systems and the deviation from extensive
mathematical modeling is illustrated with an example for
a two link planar manipulator. Computer simulation of
the Fuzzy logic based controller shows the advantages
and limitations of this control method. Recommendations
for future work are also detailed.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  3883 </NUMBER>
<ORDER>   AAG1378863 </ORDER>
<TITLE> ARTIFICIAL NEURAL SYSTEM EXHIBITING MAPS AND STRIPES </TITLE>
<AUTHOR> MYERS, GERALD LEROY </AUTHOR>
<YEAR> 1996 </YEAR>
<INSTITUTION> UNIVERSITY OF ALABAMA IN HUNTSVILLE; 0278 </INSTITUTION>
<DESCRIPTORS> COMPUTER SCIENCE; BIOLOGY, NEUROSCIENCE; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> NIL </ADVISER>
<CLASSIFICATIONS> NIL </CLASSIFICATIONS>
<ABSTRACT>
Brain visual processing is the most understood neural
function. Artificial neural systems based on visual
system anatomy can broaden the knowledge of the whole
brain. Anatomies and characteristics of the neuron,
retina, and primary visual cortex must be understood. An
important characteristic of the visual system is
mapping. Retinal field of view is mapped onto primary
visual cortex layer 4C. Axons from the two retina
compete for layer 4C neurons. Competition leads to
dominance bands, called stripes, in layer 4C with
alternating bands receiving signals exclusively from one
retina.
A C++ software model of the primary visual system is
presented which uses mapping and competition to generate
stripes. Striped patterns produced by the model
correlate to neuronal striping in some respects and
disagree in others. Low learning rates are required to
allow thorough competition. Spatially related input from
two sources are transformed into a single input
retaining the relationship.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  3884 </NUMBER>
<ORDER>   AAGMM08571 </ORDER>
<TITLE> KNOWLEDGE-BASED APPROACHES FOR QUERY EXPANSION IN INFORMATION RETRIEVAL </TITLE>
<AUTHOR> BODNER, RICHARD CARL </AUTHOR>
<YEAR> 1996 </YEAR>
<INSTITUTION> UNIVERSITY OF GUELPH (CANADA); 0081 </INSTITUTION>
<DESCRIPTORS> INFORMATION SCIENCE; COMPUTER SCIENCE; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> FEI SONG; TOM CAREY </ADVISER>
<CLASSIFICATIONS> NIL </CLASSIFICATIONS>
<ABSTRACT>
Textual information is becoming increasingly available
in electronic forms. Users need tools to sift through
non-relevant information and retrieve only those pieces
relevant to their needs. The traditional methods such as
Boolean operators and key terms have critical
limitations. An emerging trend is to combine the
traditional information retrieval and artificial
intelligence techniques. This thesis explores the
possibility of extending traditional information
retrieval systems with knowledge-based approaches to
automatically expand natural language queries. Two types
of knowledge bases, a domain specific and a general
world knowledge, are used in the expansion process.
Experiments are also conducted using different search
strategies and various combinations of the knowledge-
bases. Our results show that an increase in retrieval
performance can be obtained using certain knowledge-
based approaches.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  3885 </NUMBER>
<ORDER>   AAGC569772 </ORDER>
<TITLE> APPLYING KNOWLEDGE-BASED TECHNIQUES TO HYPERMEDIA SYSTEMS  </TITLE>
<AUTHOR> SRINIVASAN, PARTHASARATHY </AUTHOR>
<YEAR> 1996 </YEAR>
<INSTITUTION> TECHNISCHE UNIVERSITAET GRAZ (AUSTRIA); 5800 </INSTITUTION>
<DESCRIPTORS> COMPUTER SCIENCE; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> NIL </ADVISER>
<CLASSIFICATIONS> SEMANTIC QUERYING, DEDUCTIVE FACILITIES, COURSEWARE </CLASSIFICATIONS>
<ABSTRACT>
Abstract Not Available.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  3886 </NUMBER>
<ORDER>   AAG9631817 </ORDER>
<TITLE> HIGHLY DEGRADED TEXT RECOGNITION IN THE FRAMEWORK OF HIDDEN MARKOV MODELS  </TITLE>
<AUTHOR> YEN, CHINCHING </AUTHOR>
<YEAR> 1996 </YEAR>
<INSTITUTION> COLUMBIA UNIVERSITY; 0054 </INSTITUTION>
<DESCRIPTORS> ENGINEERING, ELECTRONICS AND ELECTRICAL; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> HENRY E. MEADOWS </ADVISER>
<CLASSIFICATIONS> PATTERN RECOGNITION </CLASSIFICATIONS>
<ABSTRACT>
In this dissertation, an optical character recognition
system with new training and recognition approaches is
presented. The goal is to achieve high recognition
performance over highly-degraded and connected document
images. Based on the Pseudo two-dimensional Hidden
Markov Models, this system is built to directly
recognize gray-scale document images. Information loss
caused by the binarization process is thus avoided. Some
issues such as automatic generation of initial models
for new applications and compensation for gray-level
images of different scanning quality have also been
tackled.
Traditionally, the Viterbi decoding process has been a
popular approach to find the optimal match between
observation and models. Various path duration
information can be incorporated during the decoding
process to improve the results. Due to the lack of a
complete path map, the advantage of this incorporation
cannot be fully accessed. We therefore propose the
duration-corrected N-best hypotheses search to improve
the decoding process. It is a backward tree search
initiated upon the completion of the forward Viterbi
process. During this backward search, both the complete
forward path map from the Viterbi pass and the partial
path information incrementally collected during the
backward pass are combined to impose more accurate
duration constraints. The duration-corrected optimal
match at the end of the backward search gives
improvement over the traditional Viterbi result.
Multiple hypotheses are also found through this
procedure for postprocessing to get even higher
recognition rates.
A new training scheme is then introduced with the use of
these N-best hypotheses. It improves models trained by
traditional Maximum Likelihood (ML) criteria. The
objective of the popular ML method is to reach a set of
model parameters such that the likelihood function over
the training set could be maximized. Our new scheme,
however, builds a direct link between error rate and
model parameters. The objective of the parameter
optimization is now to directly minimize the recognition
error rate instead of maximizing the likelihood function
value. It also exposes models with competitive word
hypotheses that do not exist in the original training
set. This new scheme thus improves recognition rates and
model robustness over the traditional ML approach.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  3887 </NUMBER>
<ORDER>   AAG9631801 </ORDER>
<TITLE> CLOSED TERMINOLOGIES AND TEMPORAL REASONING IN DESCRIPTION LOGIC FOR CONCEPT AND PLAN RECOGNITION </TITLE>
<AUTHOR> WEIDA, ROBERT ANTHONY </AUTHOR>
<YEAR> 1996 </YEAR>
<INSTITUTION> COLUMBIA UNIVERSITY; 0054 </INSTITUTION>
<DESCRIPTORS> COMPUTER SCIENCE; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> KATHLEEN MCKEOWN </ADVISER>
<CLASSIFICATIONS> ARTIFICIAL INTELLIGENCE </CLASSIFICATIONS>
<ABSTRACT>
Description logics are knowledge representation
formalisms in the tradition of frames and semantic
networks, but with an emphasis on formal semantics. A
terminology contains descriptions of concepts, such as
scUNIVERSITY, which are automatically classified in a
taxonomy via subsumption inferences. Individuals such as
scCOLUMBIA are described in terms of those concepts.
This thesis enhances the scope and utility of
description logics by exploiting new completeness
assumptions during problem solving and by extending the
expressiveness of descriptions.
First, we introduce a predictive concept recognition
methodology based on a new closed terminology assumption
(CTA). The terminology is dynamically partitioned by
modalities (necessary, optional, and impossible) with
respect to individuals as they are specified. In our
interactive configuration application, a user
incrementally specifies an individual computer system
and its components in collaboration with a configuration
engine. Choices can be made in any order and at any
level of abstraction. We distinguish between abstract
and concrete concepts to formally define when an
individual's description may be considered finished. We
also exploit CTA, together with the terminology's
subsumption-based organization, to efficiently track the
types of systems and components consistent with current
choices, infer additional constraints on current
choices, and appropriately restrict future choices.
Thus, we can help focus the efforts of both user and
configuration engine. This work is implemented in the
scK-REP system.
Second, we show that a new class of complex descriptions
can be formed via constraint networks over standard
descriptions. For example, we model plans as constraint
networks whose nodes represent actions. Arcs represent
qualitative and metric temporal constraints, plus co-
reference constraints, between actions. By combining
terminological reasoning with constraint satisfaction
techniques, subsumption is extended to constraint
networks, allowing automatic classification of a plan
library. This work is implemented in the scT-REX system,
which integrates and builds upon an existing description
logic system (scK-REP or scCLASSIC) and temporal
reasoner (scMATS).
Finally, we combine the preceding, orthogonal results to
conduct predictive recognition of constraint network
concepts. As an example, this synthesis enables a new
approach to deductive plan recognition, illustrated with
travel plans. This work is also realized in scT-REX.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  3888 </NUMBER>
<ORDER>   AAG9631522 </ORDER>
<TITLE> LEARNING TO BE COMPETENT </TITLE>
<AUTHOR> KHARDON, RONI </AUTHOR>
<YEAR> 1996 </YEAR>
<INSTITUTION> HARVARD UNIVERSITY; 0084 </INSTITUTION>
<DESCRIPTORS> COMPUTER SCIENCE; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> LESLIE G. VALIANT </ADVISER>
<CLASSIFICATIONS> REASONING, COGNITION, ARTIFICIAL INTELLIGENCE </CLASSIFICATIONS>
<ABSTRACT>
The thesis presents a new approach for the study of
competent cognitive behavior. The approach, learning to
be competent, suggests that learning phenomena and the
competencies attributed to intelligence should be
studied together. Instead of requiring omniscience or
otherwise optimal performance, we claim that the tasks
and success criteria should be defined behaviorally;
that is, a system is competent if it functions well in
its environment. We further suggest that competent
behavior should only be expected in light of a learning
experience in the same or similar environment, and that
the solutions exhibited should be computationally
efficient. These ideas are presented in a formal
setting, so that the various tasks and their proposed
solutions can be studied and analyzed. Thus, one
contribution of this approach is in formalizing the
problem in a form that is amenable to analysis, while
being cognitively and computationally plausible.
The learning to reason framework is used to study the
problem of logical reasoning in propositional domains.
We consider a variety of possible interfaces for
learning, and describe learning algorithms that interact
with them, thus demonstrating the robustness of this
approach. The results show that learning to reason is
possible even in cases where the traditionally separate
problems, namely concept learning and reasoning by
proving assertions, do not have efficient solutions.
In the course of studying reasoning tasks, we develop a
model based representation, the set of characteristic
models, which supports efficient solutions for several
forms of logical reasoning. This representation is
utilized in the learning to reason framework, and is
also shown to have other applications, in the theory of
relational databases, and in computational tasks that
arise in the design of such databases.
The task of acting in a dynamic world in order to
achieve some goals is studied in the learning to act
framework. We present results on supervised learning of
action strategies in the form of production rule
systems. The framework and the results combine features
from the area of symbolic computation and that of
reactive agents, which have been previously seen as
opposed if not contradictory, and thus advance our
understanding of the problems.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  3889 </NUMBER>
<ORDER>   AAG9631229 </ORDER>
<TITLE> EFFICIENT EXTENDED KALMAN FILTER LEARNING FOR FEEDFORWARD LAYERED NEURAL NETWORKS </TITLE>
<AUTHOR> BENROMDHANE, SAIDA </AUTHOR>
<YEAR> 1996 </YEAR>
<INSTITUTION> MICHIGAN STATE UNIVERSITY; 0128 </INSTITUTION>
<DESCRIPTORS> ENGINEERING, ELECTRONICS AND ELECTRICAL; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> NIL </ADVISER>
<CLASSIFICATIONS> ARTIFICIAL INTELLIGENCE </CLASSIFICATIONS>
<ABSTRACT>
The thesis focuses on the computationally efficient
convergence to satisfactory local minima of the Extended
Kalman Filter Algorithm (EKF) when it is used in the
supervised learning of Artificial Feedforward Neural
Networks. There are two stages to our research work.
In the first stage, the effect of different choices of
the energy parameter or weighting factor $lambda$ on the
convergence of the EKF algorithm is investigated. We
limit our attention to problems related to the
supervised learning of Feedforward Artificial Neural
Networks. Through the simulation of two region
classification problems and the analysis of the results,
we demonstrate that when $lambda$ is chosen slightly
smaller than 1, the algorithm experiences explosive
divergence: The Least Square Error (LSE) grows
indefinitely. However, for a choice of $lambda$ slightly
greater than 1, the algorithm is stable but often
converges to unsatisfactory local minima, from the point-
of-view of performance and computation time.
The second stage of our work is where we propose several
modifications of the algorithm. These modifications area
aimed at improving the efficiency of the algorithm both
in terms of performance and speed of convergence. One
modification in the algorithm is the development of an
update mechanism for the exponential weighting factor
$lambda$ which self-adjusts to the (LSE). The second
modification is an augmentation of the recursion
formulae of the algorithm. Both of these modifications
result in a significant improvement in performance as
well as marked decrease in convergence time when
compared with the original EKF algorithm.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  3890 </NUMBER>
<ORDER>   AAG9631181 </ORDER>
<TITLE> FORWARD ADDITIVE NEURAL NETWORK MODELS </TITLE>
<AUTHOR> AHN, BYUNG-HYUK </AUTHOR>
<YEAR> 1996 </YEAR>
<INSTITUTION> KENT STATE UNIVERSITY; 0101 </INSTITUTION>
<DESCRIPTORS> OPERATIONS RESEARCH; BUSINESS ADMINISTRATION, MANAGEMENT; COMPUTER SCIENCE; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> MING S. HUNG </ADVISER>
<CLASSIFICATIONS> NIL </CLASSIFICATIONS>
<ABSTRACT>
Artificial neural networks have been successfully
applied in pattern recognition and function
approximation. In managerial decision making, pattern
recognition has been used for credit rating, market
segmentation, and prediction of bank failures. Function
approximation has been used in forecasting and mapping
of complex relations between sets of variables.
Neural networks for pattern recognition and function
approximation must be trained. Training is a nonlinear
minimization problem. However, since the problem is apt
to contain multiple local minima, a methodology is
needed to increase the likelihood of finding the global
minimum.
Another problem is how to determine the size of the
network. The generalization capability of a neural
network depends on its size. Many researchers tried to
resolve both network size determination and global
optimization.
The study developed Forward Additive Neural Network
(FANN) models to meet both goals. FANN models increase
the network size by adding a node at a time. Using a
statistical test, FANN models determine the appropriate
size of the network. With some heuristic features, FANN
models can provide a very good solution for neural
network training. The results of experiments with
several benchmark problems show that FANN models are
effective.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  3891 </NUMBER>
<ORDER>   AAG9630819 </ORDER>
<TITLE> A GEOMETRIC FRAMEWORK FOR DYNAMIC VISION </TITLE>
<AUTHOR> SOATTO, STEFANO </AUTHOR>
<YEAR> 1996 </YEAR>
<INSTITUTION> CALIFORNIA INSTITUTE OF TECHNOLOGY; 0037 </INSTITUTION>
<DESCRIPTORS> ENGINEERING, ELECTRONICS AND ELECTRICAL; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> NIL </ADVISER>
<CLASSIFICATIONS> MACHINE VISION, IMAGE ANALYSIS, ARTIFICIAL INTELLIGENCE </CLASSIFICATIONS>
<ABSTRACT>
This thesis explores the problem of inferring
information about the three-dimensional world from its
projections onto a camera (images). Among all visual
cues, we do not address "pictorial" ones, such as
texture or shading. Instead, we concentrate on "dynamic"
cues, which are associated with variations of the image
over time.
In order to eliminate pictorial cues, one may represent
the world as a collection of geometric primitives, such
as points, curves or surfaces in three-dimensional
space. Then, from the two-dimensional motion of the
projection of such primitives onto the image, one can
infer the three-dimensional structure of the world and
its motion relative to the viewer.
"Three-dimensional structure from two-dimensional
images" has now been a central theme in Computer Vision
for over two decades, and tools from Linear Algebra and
Projective Geometry have been widely employed to attack
the problem as a "static" task. It is only in recent
years that the role of time has started to be
recognized, after the influential work of Dickmanns and
his coworkers on vehicle guidance on freeways.
We do not impose restrictions on the structure of the
environment, and we cast the problem of general three-
dimensional structure and motion estimation within the
framework of Dynamical Systems. We show how different
algebraic constraints on the image projections can be
interpreted as nonlinear and implicit dynamical models
whose (unknown) parameters live in peculiar
differentiable manifolds that encode three-dimensional
information. Recovering such three-dimensional
information then amounts to identifying dynamical models
while taking into account the geometry of the parameter
manifolds.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  3892 </NUMBER>
<ORDER>   AAG9630760 </ORDER>
<TITLE> FUZZY MOTION ESTIMATION AND COMPENSATION FOR VIDEO COMPRESSION  </TITLE>
<AUTHOR> KIM, HYUN MUN </AUTHOR>
<YEAR> 1996 </YEAR>
<INSTITUTION> UNIVERSITY OF SOUTHERN CALIFORNIA; 0208 </INSTITUTION>
<DESCRIPTORS> ENGINEERING, ELECTRONICS AND ELECTRICAL; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> BART KOSKO </ADVISER>
<CLASSIFICATIONS> SIGNAL PROCESSING </CLASSIFICATIONS>
<ABSTRACT>
This dissertation shows how fuzzy systems can help
compress image sequences. The fuzzy systems filter noise
and improve motion estimation and compensation. Adaptive
fuzzy systems further improve the compensation accuracy.
The dissertation describes three applications of fuzzy
image-sequence compression: fuzzy filters for impulsive
noise, fuzzy virtual tilings for subband image coding,
and fuzzy motion estimation and compensation.
Fuzzy systems of if-then rules can filter impulsive
noise from signals. An additive fuzzy system learns
ellipsoidal fuzzy rule patches from a new pseudo-
covariation measure of alpha-stable covariation.
Mahalanobis distance gives a joint set function for the
learned if-part fuzzy sets of the if-then rules. The
joint set function preserves input correlations that
standard factored set functions ignore. The fuzzy system
filtered such noise better than did a benchmark radial
basis neural network.
A fuzzy system can improve how subband coding compresses
images. A fuzzy system maps the coefficients of
frequency subbands to virtual tiles of the time-
frequency plane. This prunes the tiling tree and gives a
high-energy subtree. The new tiling subtree shapes the
error spectrum and helps preserve edges in the image.
A fuzzy system can also estimate motion vectors and
increase the compensation accuracy for video
compression. The fuzzy system uses the temporal
correlation of the motion field to estimate the motion
vectors. First and second order statistics of the motion
vectors give ellipsoidal search windows. Our algorithm
reduced the search area and gave clustered motion
fields. We also proposed a fuzzy overlapped block motion
compensator. The fuzzy system uses the motion vectors of
neighboring blocks to map the previous frame's pixel
values to the current pixel value. The rules come from
the previously decoded frame. The fuzzy system updates
its rules as it decodes the image. The fuzzy system also
improved the compensation accuracy.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  3893 </NUMBER>
<ORDER>   AAG9630670 </ORDER>
<TITLE> AUTOMATED REASONING WITH DEFAULT LOGIC </TITLE>
<AUTHOR> CHOLEWINSKI, PAWEL </AUTHOR>
<YEAR> 1996 </YEAR>
<INSTITUTION> UNIVERSITY OF KENTUCKY; 0102 </INSTITUTION>
<DESCRIPTORS> COMPUTER SCIENCE; MATHEMATICS; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> MIROSLAW TRUSZCZYNSKI </ADVISER>
<CLASSIFICATIONS> NONMONOTONIC REASONING, STRATIFICATION </CLASSIFICATIONS>
<ABSTRACT>
The method which we propose is based on partitioning a
given theory into a sequence of smaller theories for
which extensions can be computed faster. This approach
was widely studied in the cases of logic programming and
autoepistemic logic and is known as stratification. We
show that stratification methods can be developed also
for the case of default logic. We show that it is
possible to find extensions for stratified default
theories by considering the theory stratum by stratum.
We describe algorithms for computing extensions for
stratified default theories. It is shown that if a given
default theory can be partitioned into several strata,
the number of calls to provability procedure needed to
compute the extensions can be significantly reduced.
Stratification based reasoning algorithms for computing
extensions were implemented as the central part of a
software package Default Reasoning System (DeReS). The
package is a comprehensive nonmonotonic reasoning system
based on the reasoning mechanism of default logic.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  3894 </NUMBER>
<ORDER>   AAG9630294 </ORDER>
<TITLE> AN INFORMATION THEORETIC APPROACH TO NEURAL NETWORK DESIGN  </TITLE>
<AUTHOR> CUNHA, FERNANDO B. L. </AUTHOR>
<YEAR> 1996 </YEAR>
<INSTITUTION> STANFORD UNIVERSITY; 0212 </INSTITUTION>
<DESCRIPTORS> ENGINEERING, ELECTRONICS AND ELECTRICAL; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> BERNARD WIDROW </ADVISER>
<CLASSIFICATIONS> ARTIFICIAL INTELLIGENCE, TRAINING </CLASSIFICATIONS>
<ABSTRACT>
The traditional design of neural networks follows a two-
step training procedure. In the first step, the initial
weight values of a network are chosen at random. In the
second step, these weight values are modified to make
the network's outputs, in response to a set of input
patterns, match as closely as possible a set of target
output patterns. Despite much success, the traditional
design has presented weaknesses revolving around the
underlying problem of ill-conditioning, which seems to
be intrinsic to neural network training problems.
This dissertation proposes a new network training
procedure that adds an intermediate step to the
traditional two-step training procedure. In this
intermediate step, weight values are modified to
condition the network to become maximally sensitive to
the input patterns used to train the network. This step
is implemented using a performance measure rooted in
information theory, and is capable of minimizing ill-
conditioning prior to the execution of the final step of
training. This step is termed pre-conditioning.
Theoretical and experimental analysis of pre-
conditioning suggests that the procedure lessens
problems with local optima and dramatically reduces
network training time.
In addition, this dissertation introduces layered
learning, which consists of the individualized training
of each layer of a multilayer neural network, and is
shown to have a remarkably positive effect on network
training time. It also introduces two fundamental pseudo
quantities: pseudodeterminant, the determinant of a
rectangular matrix; and pseudoentropy, the amount of
disorder on the output surface of an arbitrary mapping.
Furthermore, it discusses some analytic properties of
neural network layers and provides alternative proofs of
generalized versions of the Pythagorean Theorem and the
Triangle Inequality. Finally, this dissertation proposes
a new non-parametric method of probability density
function estimation that is based on maximum entropy
arguments.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  3895 </NUMBER>
<ORDER>   AAG9630207 </ORDER>
<TITLE> EXTENDING THE PRACTICALITY OF THEORY REVISION SYSTEMS THROUGH THE REVISION OF PRODUCTION SYSTEM RULEBASES </TITLE>
<AUTHOR> MURPHY, PATRICK MICHAEL </AUTHOR>
<YEAR> 1996 </YEAR>
<INSTITUTION> UNIVERSITY OF CALIFORNIA, IRVINE; 0030 </INSTITUTION>
<DESCRIPTORS> COMPUTER SCIENCE; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> DENNIS F. KIBLER </ADVISER>
<CLASSIFICATIONS> EXPERT SYSTEMS </CLASSIFICATIONS>
<ABSTRACT>
This dissertation addresses the problem of automatically
revising production system rulebases using input-output
mappings as the main source of information to guide the
revision process. The main contribution of this work,
the ability to revise production system rulebases, is
important because production system rulebases are used
so widely in industry. An implemented approach, CR2, is
shown analytically and empirically to be able to revise
these rulebases.
One important facet of this approach is an explicitly
defined model, the revision problem space model, that
was used to design CR2, and is used to understand and
empirically analyze it. This model is important because,
relatively speaking, the production system revision task
is very difficult. The model allows for an understanding
of when the revision system should succeed and fail.
Another facet of the approach is a set of techniques,
the RIO techniques, that is used to identify revisions
to the rulebase. These techniques were designed in the
context of the revision problem space model. Unlike most
Horn clause based revision systems, multiple techniques
are needed to identify revisions independent of the
problem with the rulebase and the information available
to identify the problem.
In order to produce a revised rulebase that a domain
expert would find comprehensible, a technique called
rule structure filtering is used to avoid revisions that
would produce "ill-structured" rules. This technique is
shown analytically to produce more comprehensible
revisions and is shown empirically to produce more
accurate rulebases.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  3896 </NUMBER>
<ORDER>   AAGC569642 </ORDER>
<TITLE> NEURAL NETWORK TRAINING FOR MODELLING AND CONTROL </TITLE>
<AUTHOR> MCLOONE, SEAN FRANCIS </AUTHOR>
<YEAR> 1996 </YEAR>
<INSTITUTION> QUEEN'S UNIVERSITY OF BELFAST (NORTHERN IRELAND); 0725 </INSTITUTION>
<DESCRIPTORS> ENGINEERING, ELECTRONICS AND ELECTRICAL; ARTIFICIAL INTELLIGENCE BELFAST, BELFAST, NORTHERN IRELAND </DESCRIPTORS>
<ADVISER> NIL </ADVISER>
<CLASSIFICATIONS> NIL </CLASSIFICATIONS>
<ABSTRACT>
Methods for accelerating off-line training of
feedforward neural networks for nonlinear identification
and control applications are investigated.
A thorough investigation of second-order training
techniques is presented, including ideas for optimizing
performance through intelligent resetting and efficient
line search bracketing. Simulation results demonstrate
the superiority of matrix based Full Memory BFGS
optimization over conjugate gradient methods currently
in favour for modelling and control applications.
Two new training algorithms are developed. The first, a
variable memory BFGS algorithm optimizes performance in
relation to available memory, while the second, a hybrid
technique combining linear and nonlinear optimization,
has vastly superior convergence properties compared to
existing second order methods, especially for Radial
Basis Function network training problems.
The possibilities for parallel implementation of second
order training algorithms are evaluated. The most
promising strategy, deemed to be one based on
partitioning of the training set, is used to develop
parallel versions of the Full Memory and memory-less
BFGS algorithms for two small-scale concurrent (MIMD)
machines, a small network of transporters and a Unix
workstation based Parallel Virtual Machine.
Finally a significant practical case study on the
modelling and control of generating units is described.
This demonstrates the need for powerful training
algorithms and contributes some unique results on the
application of a novel neural network control strategy
to the excitation control of a 3 kVA laboratory
micromachine.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  3897 </NUMBER>
<ORDER>   AAG9630183 </ORDER>
<TITLE> ROTATION CLUSTERING FOR ROBOT VISION </TITLE>
<AUTHOR> DENNEY, BRADLEY SCOTT </AUTHOR>
<YEAR> 1996 </YEAR>
<INSTITUTION> UNIVERSITY OF CALIFORNIA, IRVINE; 0030 </INSTITUTION>
<DESCRIPTORS> ENGINEERING, ELECTRONICS AND ELECTRICAL; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> RUI J. P. DE FIGUEIREDO </ADVISER>
<CLASSIFICATIONS> COMPUTER VISION </CLASSIFICATIONS>
<ABSTRACT>
A robot vision system is presented which estimates the
orientation and position of an arbitrary known object.
The technique relies on signatures approximating the
spatial distributions of edges which are generated from
observed images and a CAD model of the target under
examination. The signature based 3-dimensional vision
system generates a map of cross-correlations between
training signatures and single image signatures on a
domain of rotations. In this dissertation, we treat the
signature correlations as a relative indicator of the a
posteriori distribution of the target rotation given the
correlations. Since the high correlations are subject to
noise in the amplitudes of the peaks, a maximum a
posteriori (MAP) estimate of rotation can generate
incorrect rotation estimates of the target. Instead, we
perform a localized MAP estimate of the rotations which
estimates the rotation of the target given the actual
rotation is in its local neighborhood. The localized map
estimates are obtained through the clustering of
rotations.
To cluster rotations we first examine the theory of
rotations and define a useful algebra, norm, and metric
on the space of rotations. Next we analyze the problem
of averaging rotations through a minimum angle error
metric and by examining the performance of several
popular techniques. Finally we examine several
clustering techniques modified for their use with
rotations. In particular, using a weighted version of
our rotation averaging techniques, we derive modified K-
means and fuzzy c-means clustering algorithms which work
on the non-linear space of rotations.
The clustering techniques are applied to the signature
based robot vision system. We demonstrate a significant
improvement in the estimation of rotation by using the
modified fuzzy c-means clustering. In addition we extend
the system to operate over several images by reapplying
the fuzzy clustering to the set of likely rotations to
find an average of a consistently good set of rotation
results. Experiments show that the multi-image
clustering technique out-performs previous techniques of
3-D target pose estimation with only a small increase in
computational overhead.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  3898 </NUMBER>
<ORDER>   AAG9630169 </ORDER>
<TITLE> APPLICATION OF FUZZY LOGIC AND NEURAL NETWORKS TO STATE ESTIMATION AND PREDICTION </TITLE>
<AUTHOR> SHABANI, FERIDOON </AUTHOR>
<YEAR> 1996 </YEAR>
<INSTITUTION> NEW MEXICO STATE UNIVERSITY; 0143 </INSTITUTION>
<DESCRIPTORS> ENGINEERING, ELECTRONICS AND ELECTRICAL; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> NADIPURAM R. PRASAD </ADVISER>
<CLASSIFICATIONS> NIL </CLASSIFICATIONS>
<ABSTRACT>
Fuzzy logic and neural networks have been successfully
applied to various types of control systems and power
systems problems. A review of current literature
indicates that the state estimation and prediction
problem has not been addressed in the same detail. This
work demonstrates the use of fuzzy logic and neural
networks in state estimation and prediction.
A strategy of using the weighted least squares (WLS) for
state estimation is presented first. The WLS recovers
information from noisy measurement signals, providing
estimates of state variables. The state estimates
produced by the WLS are the inputs to fuzzy state
estimator.
In the second part of this work a fuzzy state estimator
is designed, in which the estimator uses a combination
of weighted least squares and fuzzy-logic-based
techniques to improve the state estimate of power
systems. Significant improvements in state estimates are
achieved by using a hybrid estimator. The approach is
illustrated for two sample systems, namely a 6-bus
network and the IEEE 30-bus test system.
Third, a fuzzy state predictor based on application of
fuzzy logic is presented. The fuzzy predictor uses the
past estimated states and measurement vectors as
entrance parameters, from these it infer the next
estimated states. Results show how the fuzzy predictor
simultaneously detects and rejects bad data while
obtaining an accurate prediction of the state. The
approach is illustrated for two sample systems: a 30-bus
and a 57-bus system.
Finally, a general neural-network model for fuzzy
decision systems is presented (FNN). Such a model can be
trained to develop fuzzy logic rules and in arriving at
optimal membership functions. The learning algorithms
are presented for setting up the FNN model. An example
is presented to illustrate the performance and
applicability of FNN model.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  3899 </NUMBER>
<ORDER>   AAG9630163 </ORDER>
<TITLE> HUMAN BIOMETRIC VERIFICATION AND RECOGNITION BASED ON FEATURE FUSION AND COMPUTER VISION TECHNIQUES </TITLE>
<AUTHOR> MENG, QIANG </AUTHOR>
<YEAR> 1996 </YEAR>
<INSTITUTION> NEW MEXICO STATE UNIVERSITY; 0143 </INSTITUTION>
<DESCRIPTORS> ENGINEERING, ELECTRONICS AND ELECTRICAL; COMPUTER SCIENCE; ENGINEERING, INDUSTRIAL; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> WILEY E. THOMPSON </ADVISER>
<CLASSIFICATIONS> NIL </CLASSIFICATIONS>
<ABSTRACT>
In this dissertation, several techniques and methods are
investigated to solve the human recognition problem. The
major contributions in this dissertation include the
development of a mathematical framework for discovering
human face features, computer vision algorithms to
extract features from wavelet transformation and
statistical evaluation of features in terms of the
feature's ability to discriminate different people. A
fuzzy matched filter algorithm is developed to extract
face component objects in a front face image. Several
neural networks are used to fuse different human
biometric features to improve the computer human
recognition system performance.
The fuzzy matched filter is not dependent on a constant
face template. The very basic relations between the face
components are used as the foundation for the fuzzy
rules. An optimal decision making method in the sense of
maximizing fuzzy membership functions (minimizing
uncertainty) is developed in this dissertation to find
the face components. A wavelet transformation is
introduced as a new method to extract side view face
features. Utilizing the wavelet transformation, a side
view profile is decomposed as high frequency and low
frequency parts. Signal reconstruction, autocorrelation
and energy distribution are used to decide a minimum
decomposition level in the wavelet transformation
without losing side view features. The tie statistic is
employed to evaluate the face feature ability to
distinguish different people. The good features in terms
of discriminating people can be selected by their tie
statistic values. Neural networks are used to transfer
the feature space to a decision space. The recognition
decision can be easily made in decision space when
unknown face features are input to the trained neural
network.
Several biometric features from human face and hand
images are fused to improve computer recognition system
performance. This feature fusion is implemented using a
neural network. The experimental results show that the
algorithms developed in this study achieve satisfactory
recognition accuracy.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  3900 </NUMBER>
<ORDER>   AAG9630117 </ORDER>
<TITLE> APPLICATION OF COMPUTATIONAL INTELLIGENCE TO ELECTROMECHANICAL SYSTEMS  </TITLE>
<AUTHOR> STREIFEL, ROBERT JOHN </AUTHOR>
<YEAR> 1996 </YEAR>
<INSTITUTION> UNIVERSITY OF WASHINGTON; 0250 </INSTITUTION>
<DESCRIPTORS> ENGINEERING, ELECTRONICS AND ELECTRICAL; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> ROBERT J. MARKS, II </ADVISER>
<CLASSIFICATIONS> GENETIC ALGORITHMS, FEATURE EXTRACTION </CLASSIFICATIONS>
<ABSTRACT>
Computational intelligence is defined and the concepts
involved are briefly reviewed. The available literature
on applications of computational intelligence to
electromechanical systems and related topics are also
reviewed. Four topics are then presented in the area of
computational intelligence techniques applied to
electromechanical systems.
The first topic deals with the detection of shorted
turns in the rotors of large generators and the
application of neural networks for feature extraction.
Shorted turns in large machines with windings are
detected by applying the concept of a novelty detector.
The novelty detection method is shown to be highly
effective for windings in transformers. The technique is
also shown to have great promise in the detection of
shorted windings of large generators.
The second topic deals with a method of improving the
effectiveness of genetic algorithms using fuzzy sets and
rules. The coding of floating point parameters into
binary strings is dynamically controlled to allow faster
convergence and more accurate final solutions. The
method is compared to other techniques and shown to be
superior.
The final two topics deal with the identification of
model parameters. The first model provides an emulation
of hydraulic brake system components. The model form and
the resulting parameters identified by the fuzzy
controlled genetic algorithm parameter coding algorithm
are described. The model is shown to accurately emulate
the response of the hydraulic system hardware. The
second model estimates brake torque by modeling the
friction properties of carbon brakes. The primary
purpose for development of the model is to determine
whether the negative damping theory of carbon brake
vibration explains the vibration mechanism. The search
results indicate that there is little correlation
between carbon brake vibration and negative damping. The
fuzzy controlled genetic algorithm coding technique is
again used to identify the parameters.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  3901 </NUMBER>
<ORDER>   AAG9630060 </ORDER>
<TITLE> MEDIATING REPRESENTATIONS AND CONSTRUCTIVIST KNOWLEDGE ACQUISITION  </TITLE>
<AUTHOR> BRADSHAW, JEFFREY M. </AUTHOR>
<YEAR> 1996 </YEAR>
<INSTITUTION> UNIVERSITY OF WASHINGTON; 0250 </INSTITUTION>
<DESCRIPTORS> COMPUTER SCIENCE; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> EARL HUNT </ADVISER>
<CLASSIFICATIONS> REPERTORY GRID, MAPPING </CLASSIFICATIONS>
<ABSTRACT>
In this study, I describe knowledge acquisition research
leading to the development of DDUCKS$sp1,$ a
constructivist knowledge modeling environment. Many of
the ideas are derived from the work of George Kelly's
personal construct theory. I describe important concepts
motivating the theory and introduce its most well known
contribution to knowledge acquisition research: the
repertory grid. I discuss recent efforts to extend
repertory grid techniques and integrate them with ideas
springing from complementary perspectives. New
understandings of relationships between personal
construct theory, semantic networks, decision analysis,
and design methods have formed the underpinnings of
knowledge acquisition tools such as Aquinas, Axotl, and
Canard, designed to overcome previous limitations of
repertory grids. These developments lay the conceptual
foundation for a more general approach.
DDUCKS is a "second generation" constructivist knowledge
acquisition environment that supports general-purpose
user-tailorable mapping facilities between different
mediating representations. These mapping facilities rely
on a three-schema architecture for knowledge
representation, with a concept modeling capability at
its core. Specific groups of conceptual structures
("ontologies") specified within DDUCKS define its
modeling framework. The success of DDUCKS depends on
effectively designing these concepts so they can be
easily reused for a variety of applications and
representation frameworks. A layered architecture
partitioned by theories and contexts, facilitates reuse
of knowledge structures across applications and helps
resolve of ambiguities of reference. A translation
facility to Gruber's Ontolingua is discussed.
The central problem of constructing mediating
representations is one of how to straightforwardly
define a set of model views that are both logically
consistent with the properties of concepts as defined in
the concept model, and subjectively consistent with the
user's concrete ways of visualizing them. Relying on a
conceptualist semantics, we define mappings between
particular conceptual modeling framework and the
repertoire of user-interface interaction paradigms
available in the knowledge representation system. Two
kinds of agents (interpreters and expressors) map
concept model components to syntactic elements of
graphical interaction paradigms. A virtual notebook
allows users to organize instances of resultant
mediating representations as indexed "pages." I conclude
with observations about the past, and speculations on
the future of knowledge acquisition. ftn$sp1$Decision
and Design Utilities for Comprehensive Knowledge
Support. Either the first or the second 'D' in the
acronym is silent, depending on the context in which the
tool is being used.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  3902 </NUMBER>
<ORDER>   AAG9629830 </ORDER>
<TITLE> AUTOMATED REASONING AND MACHINE LEARNING </TITLE>
<AUTHOR> HUANG, GUOXIANG </AUTHOR>
<YEAR> 1996 </YEAR>
<INSTITUTION> UNIVERSITY OF HAWAII; 0085 </INSTITUTION>
<DESCRIPTORS> MATHEMATICS; COMPUTER SCIENCE; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> DALE MYERS </ADVISER>
<CLASSIFICATIONS> LOGIC </CLASSIFICATIONS>
<ABSTRACT>
This dissertation introduces new theorem-proving
strategies and uses these strategies to solve a wide
variety of difficult problems requiring logical
reasoning. It also shows how to use theorem-proving to
solve the problem of learning mathematical concepts.
Our first algorithm constructs formulas called Craig
interpolants from the refutation proofs generated by
contemporary theorem-provers using binary resolution,
paramodulation, and factoring. This algorithm can
construct the formulas needed to learn concepts
expressible in the full first-order logic from examples
of the concept. It can also find sentences which
distinguish pairs of nonisomorphic finite structures.
We then apply case analysis to solve hard problems such
as the zebra problem, the pigeonhole problem, and the
stable marriage problem. The case analysis technique we
use is the first to be fully compatible with resolution
and rewriting and powerful enough to solve these
problems.
Our primary new theorem-proving strategies generate
subgoals and efficient sets of rules. We show how to
divide problems into smaller parts with intermediate
goals by reversing logical implications. We solve these
subdivided parts by discovering efficient subsets of
rules or by generating efficient new rules.
We apply these and other new search strategies to solve
difficult problems such as the 15-puzzle, central
solitaire, TopSpin, Rubik's cube, and masterball. Our
strategies apply universally to all such problems and
can solve them quite efficiently: the 15-puzzle, Rubik's
cube and masterball can all be done in 300 seconds.
Finally we apply our search strategies to solve real-
world problems such as sorting, solving equations and
inverting nonsingular matrices.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  3903 </NUMBER>
<ORDER>   AAG9629431 </ORDER>
<TITLE> STATISTICAL METHODS IN MATERIAL MANUFACTURING AND EVALUATION  </TITLE>
<AUTHOR> GIANARIS, NICHOLAS JAMES </AUTHOR>
<YEAR> 1996 </YEAR>
<INSTITUTION> THE JOHNS HOPKINS UNIVERSITY; 0098 </INSTITUTION>
<DESCRIPTORS> ENGINEERING, MATERIALS SCIENCE; ENGINEERING, INDUSTRIAL </DESCRIPTORS>
<ADVISER> ROBERT E. GREEN, JR. </ADVISER>
<CLASSIFICATIONS> PROCESS CONTROL FEEDBACK, COMPOSITES </CLASSIFICATIONS>
<ABSTRACT>
The implementation of statistical quality and process
control methods in the manufacture and the evaluation of
composite and noncomposite materials is presented.
First, the evolution of modern statistical quality and
process control techniques and philosophies is
discussed. The use of statistical quality and process
control methods in all material and nonmaterial
industries is then presented in detail. Additionally,
the applications of other types of process control
technologies, such as artificial intelligence, both in
conjunction with and in lieu of statistical and process
control in material and nonmaterial manufacturing
sectors is described. The use of statistical methods
with nondestructive evaluation and characterization
techniques, both for defect categorization and process
control feedback, is also presented. Previous work in
the study of the effects of environmental factors on
composite part manufacture and for methodologies for the
implementation of statistical process and quality
control in material and nonmaterial manufacturing
industries is discussed.
Experimental work was then performed to establish the
use of statistical methods for the testing, evaluation,
and analysis of external supplier composite and metal
alloy material parts; material testing, comparison,
evaluation and statistical analysis of both external
supplier and composite part manufacturer composite
material test result data; and the introduction of the
use of risk analysis and variation reduction for the
evaluation of an internal supplier composite part
manufacturing process. Lastly, the application of this
work to cyclic closed-loop statistical quality and
process control on both an internal and an external
supplier basis is discussed with respect to the highest
impact on process improvement and cost reduction.
The results of this work show that statistical methods
can be successfully applied to existing material
manufacturing and evaluation processes for the
improvement of quality and process control. It was also
shown that statistical methods have many potential
applications in the improvement of the robustness of
composite and noncomposite material processes, and in
destructive and nondestructive material evaluation.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  3904 </NUMBER>
<ORDER>   AAG9628259 </ORDER>
<TITLE> MODELING AND REAL-TIME SIMULATION OF TWO-PARTY NEGOTIATIONS: AN INTEGRATED FUZZY LOGIC APPROACH </TITLE>
<AUTHOR> WASFY, AYMAN MOHAMED </AUTHOR>
<YEAR> 1996 </YEAR>
<INSTITUTION> UNIVERSITY OF CENTRAL FLORIDA; 0705 </INSTITUTION>
<DESCRIPTORS> ENGINEERING, INDUSTRIAL; OPERATIONS RESEARCH; BUSINESS ADMINISTRATION, MANAGEMENT; PSYCHOLOGY, INDUSTRIAL; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> YASSER A. HOSNI </ADVISER>
<CLASSIFICATIONS> NIL </CLASSIFICATIONS>
<ABSTRACT>
For forty years, game theoretic models attempted to
predict equilibrium outcomes between negotiators with
limited success. The imprecise character of negotiation
is often altered to fit the game theorist's exacting
approach. Alternative models deviated from the formal
game theoretic approach and attempted to accommodate
concepts such as negotiator power and time pressure.
Quantitative models failed to account for important
parameters that descriptive negotiation theories have
identified, through empirical research and negotiation
experience, as being of importance in the structure and
dynamics of negotiations.
In this dissertation, a new quantitative model of two-
party negotiation that overcomes many of the
shortcomings of game-theoretic and non-game-theoretic
models is developed. The model accounts for important
negotiation parameters that have been identified by
descriptive theories of negotiation. This innovative
model enables the simulation of both structural and
communicative aspects of the process and includes in its
constructs economic and socio-psychological
perspectives. It uses a fuzzy logic approach to
effectively handle imprecise parameters of negotiation
such as negotiator power, concession force, and
resistance force.
The model is the basis for NEGOTIATE, a computer-based,
real-time, generic simulation language which generates
complex and more realistic negotiation scenarios. Such a
language is believed to be a "first". Negotiation
analysts may find this tool extremely useful for
negotiation training and experimentation. The model is
verified through computer simulation runs of multiple-
issue, two-party negotiations and results are consistent
with established negotiation theories. In addition, new
theory is introduced as a result of running complex
scenarios for which no theoretical outcome was ever
suggested. An application of NEGOTIATE that demonstrates
its value as a tool for discovery in experimental
negotiations is presented. The model and the simulation
system are the seed for "Virtual Negotiation" and they
open many avenues for future research.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  3905 </NUMBER>
<ORDER>   AAG9628146 </ORDER>
<TITLE> A REPLANNING SYSTEM FOR TRANSPORTATION/REDISTRIBUTION FOR USE IN A DISTRIBUTED ENVIRONMENT </TITLE>
<AUTHOR> MOORE, LEAH MIRANDA </AUTHOR>
<YEAR> 1996 </YEAR>
<INSTITUTION> THE PENNSYLVANIA STATE UNIVERSITY; 0176 </INSTITUTION>
<DESCRIPTORS> ENGINEERING, INDUSTRIAL; OPERATIONS RESEARCH </DESCRIPTORS>
<ADVISER> SOUNDAR KUMARA </ADVISER>
<CLASSIFICATIONS> NIL </CLASSIFICATIONS>
<ABSTRACT>
A new architecture designed for replanning has been
developed for this research. The replanning
architecture, based on precepts from the field of
Artificial Intelligence (AI), can be used for replanning
in a distributed environment with an existing planning
architecture. Transportation and redistribution problems
associated with the ship cargo configurations exemplify
the replanning concepts. The replanner reacts to plan
changes that are required by user input, discovery of
new goals, parameter changes, or other causes.
With the streamlining of our nations economy, many
organizations, both large and small, are realizing the
importance of using existing models and simulations in
their analysis. Much time, money and research has gone
into building distributed architectures that connect
existing systems and use their results to build a
comprehensive plan. The limitations of such a system are
that the existing systems they rely on are already
developed and not always designed to be reactive, easy
to change, or efficient to execute. A change to the plan
could be costly and inefficient given that the only way
to react is to change model parameters and re-execute.
Yet, little research has gone into developing a
replanning capability for accommodating changes
introduced into the system after the plan is built.
Without this replanning capability, the planning system
is not complete.
The proposed replanning system has the ability to alter
a previously defined plan to achieve a new goal state.
The architecture developed in this thesis is a flexible,
modular, decentralized one that meets the changing needs
of a distributed planning system.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  3906 </NUMBER>
<ORDER>   AAGC569598 </ORDER>
<TITLE> THE INTELLIGENT GENERATION AND ANALYSIS OF CODE FOR PARALLEL PLATFORMS  </TITLE>
<AUTHOR> MCMULLAN, PAUL PATRICK-JOSEPH </AUTHOR>
<YEAR> 1996 </YEAR>
<INSTITUTION> QUEEN'S UNIVERSITY OF BELFAST (NORTHERN IRELAND); 0725 </INSTITUTION>
<DESCRIPTORS> COMPUTER SCIENCE; ARTIFICIAL INTELLIGENCE LIBRARY, CHLORINE GARDENS,  BELFAST BT9 5AG, NORTHERN IRELAND </DESCRIPTORS>
<ADVISER> NIL </ADVISER>
<CLASSIFICATIONS> EXPERT SYSTEMS </CLASSIFICATIONS>
<ABSTRACT>
This thesis addresses the problem of the lack of a
suitable parallel development system for currently
available multiprocessor computer systems. For the
purposes of this work, a suitable development system is
defined as being portable, user-friendly, usable by a
novice or an expert to parallelization, and providing a
general solution to the problem of code migration across
a range of parallel platforms. The Fortport project aims
to provide such a suitable development environment by
using an array of translation and analysis tools to
convert existing "dusty deck" codes to a parallel
equivalent for subsequent execution on parallel
architectures. A knowledge based approach is used, with
an expert system controlling the selection and
application of parallel transformations. The IKBS
selects tools based on source code and execution
performance analysis, with a feedback mechanism for
tuning of parallel code for optimum efficiency.
In order to provide a feasibility study of the Fortport
proposal, a prototype system, Fortport$sb0rm p$ was
developed. This prototype of the full Fortport system
accepts Fortran 77 code and generates CSTools Fortran
for execution on the Meiko M40 distributed memory
multiprocessor. An expert system is used to provide
knowledge based control and the selection of tools
within the prototype, including sequential and parallel
performance analysers, data dependence analysis and
reduction tools, a loop characterizer, data distribution
and partition analysers and a program modeller. The
successful development and subsequent evaluation of the
prototype will demonstrate the validity of the approach
adopted and will enable the development of the full
system. This thesis focuses on one of the core areas of
the work, namely the intelligent generation and analysis
of parallel code.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  3907 </NUMBER>
<ORDER>   AAG0577322 </ORDER>
<TITLE> PARALLEL APPROACHES TO TRAINING FEEDFORWARD NEURAL NETS </TITLE>
<AUTHOR> COETZEE, LOUIS </AUTHOR>
<YEAR> 1996 </YEAR>
<INSTITUTION> UNIVERSITY OF PRETORIA (SOUTH AFRICA); 6004 </INSTITUTION>
<DESCRIPTORS> ENGINEERING, ELECTRONICS AND ELECTRICAL; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> ELIZABETH C. BOTHA; ETIENNE BARNARD </ADVISER>
<CLASSIFICATIONS> NEURAL NETWORKS </CLASSIFICATIONS>
<ABSTRACT>
Neural networks have gained prominence and are used for
the successful solution of many real-world problems.
However, training these networks is difficult and time
consuming. In this thesis we investigate parallel neural-
net training algorithms which reduce the required time
to train large networks. We focus our attention on
feedforward multi-layer perceptron neural nets with
sigmoidal transfer functions which are used extensively
in pattern recognition applications.
We start with a theoretical analysis of block
backpropagation, an established online training
algorithm. With a theoretical analysis and experimental
verification we show that block backpropagation improves
on general backpropagation (the standard online training
algorithm).
Once it is established that block backpropagation is
superior to backpropagation, we propose several parallel
implementations suitable for tightly as well as loosely-
coupled MIMD (multiple instruction multiple data)
architectures. In conjunction with the parallel
implementations, we propose speedup models for each
implementation and architecture which are used to
analyse the performance of the algorithms. We conclude
that online block backpropagation can be successfully
parallelised.
We then present a parallel implementation of a conjugate-
gradient training algorithm using shared-memory
constructs. We implement two versions on a distributed
shared-memory MIMD architecture. One version is
implemented with native code, and the other with P4, a
portable parallel user library. We propose a speedup
model which we use to analyse and compare the different
versions. Our experimental approach, combined with an
analysis of the speedup model, show that both versions
are successful.
Finally, we present a coarse-grain implementation of a
batch-mode conjugate-gradient algorithm, which uses PVM
to combine a distributed network of work-stations into a
virtual parallel architecture. We once again propose a
model of speedup which we use in conjunction with our
experimental approach to investigate the feasibility of
distributed workstations as nodes of a parallel machine.
We conclude that for problems consisting of large
training sets, the use of distributed workstations is a
viable alternative to dedicated MIMD parallel
architectures.
Evaluating all the experimental results we conclude that
parallel neural-net training algorithms are a viable
alternative to sequential training, with the performance
gains outweighing the initial parallel implementation
costs.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  3908 </NUMBER>
<ORDER>   AAG9631851 </ORDER>
<TITLE> CAUSAL THINKING IN THE PRAYER PRACTICES OF TRADITIONAL AND CHRISTIAN SPIRITUAL LEADERS OF THE KANKANAEY </TITLE>
<AUTHOR> GOSSMAN, PAUL </AUTHOR>
<YEAR> 1996 </YEAR>
<INSTITUTION> TRINITY EVANGELICAL DIVINITY SCHOOL; 0641 </INSTITUTION>
<DESCRIPTORS> ANTHROPOLOGY, CULTURAL; RELIGION, GENERAL; THEOLOGY </DESCRIPTORS>
<ADVISER> PAUL G. HIEBERT </ADVISER>
<CLASSIFICATIONS> PHILIPPINES) (ANIMISM </CLASSIFICATIONS>
<ABSTRACT>
The causal thinking of traditional (animistic) and
Christian spiritual leaders of the Kankanaey
(Philippines) was investigated through an intensive
cognitive analysis of statements found in their prayers
and in their explanations of the same. Basic theoretical
assumptions for the research were derived from Robin
Horton's intellectualist theory. An integrative and
interdisciplinary model of universals of causal thought
analysis was developed as a framework for identifying
the essential components of their contrasting causal
systems. Utilizing methods adapted from cognition and
artificial intelligence studies, text analysis produced
graphic representations of the informants' causal
statement networks, from which were identified the
propositional and performative functions of their
prayers, and the prominent features of their causal
thought, namely the universals of causal logics,
analogies, domains, and modes. Findings for
traditionalists and Christians were compared.
Traditionalists and Christians alike acknowledged their
prayers to function propositionally. The public didactic
value of traditional prayers increased with formality.
Christian leaders more strongly affirmed the explanatory
nature of their prayers but offered in them little
explanation of misfortune. The performative function, or
causal efficacy, of traditional prayers varied according
to the supernatural agent addressed, the causal domain
in which influence was sought, and the satisfaction of
ritual requirements. The efficacy of Christian prayers
varied more according to external and internal
antecedents such as the will of God and the faith of the
persons involved. Christian leaders viewed the actual
causal agency of prayer in strikingly different ways.
Traditional spiritual leaders exhibited greater unity of
thought than did Christian leaders. They understood a
wide variety of supernatural agents to effect the events
in their lives, largely with logics of ritual propriety,
reciprocity, external causality, and immediacy. Familiar
domains were explained differently from those
unfamiliar. Christian causal understandings spanned much
of the continuum between traditional and nontraditional
thought, but were generally marked by moral propriety,
internal causality, and intermediacy. Christian
spiritual leaders who utilized more nontraditional
thought distinguished between physical and spiritual,
and tangible and psychological domains. Members of both
groups accommodated for cultural change by adopting
either salient elements, or operational causal logics,
of the other group.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  3909 </NUMBER>
<ORDER>   AAG9628278 </ORDER>
<TITLE> COLOR AND TEXTURE BASED IMAGE ANALYSIS: SEGMENTATION AND CLASSIFICATION  </TITLE>
<AUTHOR> PASCHOS, GEORGE </AUTHOR>
<YEAR> 1996 </YEAR>
<INSTITUTION> UNIVERSITY OF SOUTHWESTERN LOUISIANA; 0233 </INSTITUTION>
<DESCRIPTORS> COMPUTER SCIENCE; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> KIMON P. VALAVANIS </ADVISER>
<CLASSIFICATIONS> COMPUTER VISION </CLASSIFICATIONS>
<ABSTRACT>
Image segmentation and classification are the two main
issues in image processing and computer vision.
Segmentation deals with the problem of separating an
image into a number of distinct regions that correspond
to objects/surfaces in the original scene.
Classification is the process by which an image (or
image region) is identified as being one among a group
of patterns/models known to the system. This
dissertation combines color and texture that are
available in an image, and constructs a unified
framework for answering both of the above questions.
Color in texture analysis has largely been ignored,
while the majority of proposed methods involve only the
intensity information (luminance) of an image. A set of
real-time, computationally efficient and easily
implementable algorithms is designed and implemented for
both segmentation and classification. The segmentation
system processes luminance and chrominance separately
and combines the results. Luminance processing follows a
three-step procedure: (a) filtering, (b) smoothing, and
(c) boundary detection. Chrominance processing involves
two main steps: (a) histogram multi-thresholding, and
(b) Region Of Interest (ROI) expansion. By combining the
results from luminance and chominance, a methodology for
detecting, locating, and measuring image changes in the
ROI is developed. The classification system proceeds in
four stages: (a) computation of autocorrelation and
cross-correlation of both luminance and chrominance, (b)
extraction of directional histogram features, (c)
statistical selection of robust features, and (d) neural
network classification based on the selected features.
The proposed system is based on the xyY color space and
proposes a two channel vision system based on a
chromaticity mapping compression scheme which is
efficient while producing negligible loss of chromatic
(color) information. The system also implemented in the
HIS space. Both spaces are proven to provide
computationally superior systems compared with the RGB
color space. Furthermore, a multiple-threshold
segmentation method, based on the Total Color Difference
(TCD) measure, is also developed. Experimental results
justify and support the use of color in addition to
luminance. The end result of the proposed work is the
design of a complete Visual Monitoring System (VMS) for
automated surveillance, which is capable of detecting
and identifying potential changes in the surveyed
environment over a period of time, with applications in
wetlands monitoring, Autonomous Underwater Vehicles
(AUV), and Geographical Information Systems (GIS).
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  3910 </NUMBER>
<ORDER>   AAG9628122 </ORDER>
<TITLE> INTELLIGENT INTEGRATED DIAGNOSTICS: PROCESS MONITORING AND DIAGNOSIS FOR ON-LINE QUALITY CONTROL OF POWDER INJECTION MOLDING </TITLE>
<AUTHOR> LEE, JINWHAN </AUTHOR>
<YEAR> 1996 </YEAR>
<INSTITUTION> THE PENNSYLVANIA STATE UNIVERSITY; 0176 </INSTITUTION>
<DESCRIPTORS> ENGINEERING, INDUSTRIAL; COMPUTER SCIENCE; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> SOUNDAR R. TIRUPATIKUMARA </ADVISER>
<CLASSIFICATIONS> NIL </CLASSIFICATIONS>
<ABSTRACT>
This thesis addresses the problem of on-line quality
control of the Powder Injection Molding (PIM) process.
Intelligent Integrated Diagnostics (IID), an integrated
paradigm of product and process monitoring, diagnosis,
and control is proposed. This thesis concentrates on
process monitoring and diagnosis, with specific
reference to the PIM process. Process monitoring
involves three steps: selection of process parameters,
sensor data representation, and signal abstraction by
pattern classification. The injection and cavity
pressure profiles during a molding cycle are selected as
the process parameters. Considering the nonoscillatory
nature of the pressure, sensor signals of the process
parameters are represented using spline wavelet
transformation. Nine partitioned 3-layer feedforward
networks perform the abstraction task of the signals
from different time periods during a molding cycle.
Diagnosis involves two steps: representation of the
domain knowledge and diagnostic reasoning to solve a
problem. A computational model representing the domain
knowledge, causality network, is developed. The
causality network represents the structural knowledge of
manufacturing processes efficiently. The proposed
diagnostic reasoning procedure includes the
simplification of the causality network using network
conversion, hypotheses generation using abductive
reasoning, and verification of the hypotheses.
Algorithms for network conversion and verification
procedures are developed. This work presents unique
methods for process monitoring and diagnosis in the PIM
domain. The effectiveness of the developed methods are
validated through real case tests using experimental
data. However, the general methodology is applicable to
any manufacturing process.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  3911 </NUMBER>
<ORDER>   AAG9627748 </ORDER>
<TITLE> INTELLIGENT INFORMATION FILTERING VIA HYBRID TECHNIQUES: HILL CLIMBING, CASE-BASED REASONING, INDEX PATTERNS, AND GENETIC ALGORITHMS  </TITLE>
<AUTHOR> MOCK, KENRICK JEFFERSON </AUTHOR>
<YEAR> 1996 </YEAR>
<INSTITUTION> UNIVERSITY OF CALIFORNIA, DAVIS; 0029 </INSTITUTION>
<DESCRIPTORS> COMPUTER SCIENCE; INFORMATION SCIENCE; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> NIL </ADVISER>
<CLASSIFICATIONS> USENET NEWS, ARTIFICIAL INTELLIGENCE </CLASSIFICATIONS>
<ABSTRACT>
As the size of the Internet increases, the amount of
data available to users has dramatically risen,
resulting in an information overload for users. This
work shows that information overload is a problem, and
that data is organized poorly by existing browsers. To
address these problems, an intelligent information news
filtering system named INFOS (Intelligent News Filtering
Organizational System) was created to reduce the user's
search burden by automatically eliminating Usenet news
articles predicted to be irrelevant. These predictions
are learned automatically by adapting an internal user
model that is based upon features taken from articles
and collaborative features derived from other users. The
features are manipulated through keyword-based
techniques, knowledge-based techniques, and genetic
algorithms to build a user model to perform the actual
filtering. The integration of knowledge-based techniques
for in-depth analysis, statistical and keyword
approaches for scalability, and genetic algorithms for
exploration allows INFOS to achieve better filtering
performance than by using either technique alone.
Experimental results collected from the prototype of
INFOS validate the gain in performance within the domain
of news articles posted to electronic bulletin boards.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  3912 </NUMBER>
<ORDER>   AAG9627637 </ORDER>
<TITLE> ON USING ARTIFICIAL NEURAL NETWORKS AND GENETIC ALGORITHMS TO OPTIMIZE PERFORMANCE OF AN ELECTRIC NOSE </TITLE>
<AUTHOR> KERMANI, BAHRAM GHAFFARZADEH </AUTHOR>
<YEAR> 1996 </YEAR>
<INSTITUTION> NORTH CAROLINA STATE UNIVERSITY; 0155 </INSTITUTION>
<DESCRIPTORS> ENGINEERING, ELECTRONICS AND ELECTRICAL; ENGINEERING, BIOMEDICAL; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> H. TROY NAGLE </ADVISER>
<CLASSIFICATIONS> OLFACTORY </CLASSIFICATIONS>
<ABSTRACT>
In recent years, researchers have tried to mimic the
human nose using an array of gas sensors in a computer-
controlled instrument called the electronic nose
(Bartlett and Ling-Chung, 1989; Shurmer et al., 1990b;
Chandler and Pletcher, 1985; Gardner et al., 1991b;
Heinze, 1990; Miasik et al., 1986; Persaud, 1991;
Stetter et al., 1986; Zaromb and Stetter, 1985; Cranny
and Atkinson, 1992). Commercial electronic nose systems
(AromaScan, 1994; Neotronics, 1994; Alpha MOS, 1994) use
arrays of gas sensors, with wide sensitivities, to
differentiate between various odorants. This
differentiation is based on the uniqueness of the data
fingerprints of each odorant. A data fingerprint is the
accumulative processed response of the array of gas
sensors. In order to achieve a high recognition rate, it
is of paramount importance that the odorprints
(fingerprints) be unique and repeatable for each odorant
substance. In practice, it has been shown that this
uniqueness and repeatability of the data odorprints are
difficult to achieve. In reality, the experiments have
shown that, for odorants with a small number of volatile
molecules such as soft beverages, the current state-of-
the-art gas sensor species do not provide useful
odorprints. This fact is demonstrated for conducting
polymer sensors, which were used in this study.
Therefore, a complex signal processing and pattern
recognition methodology is needed to overcome the
deficit in sensor technology. In this investigation,
artificial neural networks have been employed, in
conjunction with genetic algorithms and traditional
signal processing techniques, to perform pattern
recognition and data classification. In an attempt to
extract more information from the sensor responses, the
transient time response of sensors has been used as well
as their steady-state values. Several case studies have
been performed on a diverse set of families of odorant
sources, e.g., coffees, perfumes, soda beverages and hog
farm samples. The case studies exhibit promising results
in the classification of various substances within each
family of odorants. Sophisticated signal processing
methods have been shown to be capable of compensating
for the deficits in sensor technology.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  3913 </NUMBER>
<ORDER>   AAG9626662 </ORDER>
<TITLE> AN ANALYSIS OF AI RESEARCH AND APPLICATION DEVELOPMENT AT NASA - GODDARD SPACE FLIGHT CENTER </TITLE>
<AUTHOR> DINH, DOMINIQUE MINHBICHHUYEN </AUTHOR>
<YEAR> 1996 </YEAR>
<INSTITUTION> THE GEORGE WASHINGTON UNIVERSITY; 0075 </INSTITUTION>
<DESCRIPTORS> ENGINEERING, SYSTEM SCIENCE; ENGINEERING, AEROSPACE; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> MICHAEL L. DONNELL </ADVISER>
<CLASSIFICATIONS> EXPERT SYSTEMS </CLASSIFICATIONS>
<ABSTRACT>
During the past decade, the increasing level of
complexity in the spacecraft operations environment has
led to the introduction of AI technology at all of the
NASA centers. Some of the AI techniques (e.g., rule-
based expert systems) have shown solid evidence of their
applicability and advantages, while others (e.g.,
genetic algorithms) are still in the research or
prototype stage. This research attempts to explore the
current status of the AI effort at NASA's Goddard Space
Flight Center (GSFC). Data were collected from a sample
of GSFC personnel involved in AI research and
application development, through verbal interviews and
written questionnaires. The results were analyzed using
various statistical techniques. Based on the findings,
the following recommendations were made: (1) management
must realize that technical changes mostly require also
organizational changes. Thus, they must learn how to
adapt to these changes and to effectively lead the
organization in implementing the new technology; (2)
management needs to keep a balance between (a) focusing
on cost and schedule and (b) allowing more risks and
allocating more budget for new technology
implementation; (3) technical personnel need to define a
new methodology to work in a more unified manner within
the organization as a whole. A means for sharing
information among codes and projects must be established
and maintained; and (4) administrative personnel need to
assist the technical work force by finding ways to
improve the educational program by working closely with
the technical personnel and the appropriate academic
institutes or professional organizations.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  3914 </NUMBER>
<ORDER>   AAG9626306 </ORDER>
<TITLE> GENERAL NONLINEAR NETWORK </TITLE>
<AUTHOR> ZHU, MANG </AUTHOR>
<YEAR> 1996 </YEAR>
<INSTITUTION> VANDERBILT UNIVERSITY; 0242 </INSTITUTION>
<DESCRIPTORS> ENGINEERING, ELECTRONICS AND ELECTRICAL; ENGINEERING, BIOMEDICAL; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> JAMES A. CADZOW </ADVISER>
<CLASSIFICATIONS> NEURAL NETWORKS, TRAINING, PATTERN RECOGNITION </CLASSIFICATIONS>
<ABSTRACT>
Neural network modeling techniques have greatly improved
in recent years with their applications in the fields of
detection, estimation, speech and pattern recognition.
In this dissertation, the following associated problems
are investigated (i) development of a general class of
parametrically dependent multi-layer nonlinear networks,
(ii) development of a class of rapidly convergent
algorithms for training the network's parameter, (iii)
development of a global optimization algorithm for
training the network's parameter, and (iii) the use of
these approaches to the application for detection and
estimation.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  3915 </NUMBER>
<ORDER>   AAG9626283 </ORDER>
<TITLE> MAKING THE MOST OF WHAT YOU'VE GOT: USING MODELS AND DATA TO IMPROVE PREDICTION ACCURACY </TITLE>
<AUTHOR> ORTEGA, JULIO </AUTHOR>
<YEAR> 1996 </YEAR>
<INSTITUTION> VANDERBILT UNIVERSITY; 0242 </INSTITUTION>
<DESCRIPTORS> COMPUTER SCIENCE; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> DOUGLAS H. FISHER </ADVISER>
<CLASSIFICATIONS> MACHINE LEARNING, ARTIFICIAL INTELLIGENCE, INDUCTION </CLASSIFICATIONS>
<ABSTRACT>
This dissertation proposes and experimentally evaluates
two techniques that combine knowledge from an imperfect
model of a domain with empirical learning on a set of
available data.
In the first technique the model is used as a feature
generator for induction. With models expressed as
propositional theories, extended features are generated
from the proofs of the intermediate concepts in the
theory. The original data is re-expressed in terms of
these extended features, and the C4.5 decision tree
learning algorithm is run with this set of data. In
addition, a method is provided to flexibly bias
empirical learning towards the existing model. A
preference ordering for the model-derived features is
established, and the C4.5 algorithm is modified to
accept features of lower preference only when there is
statistically significant evidence in the data that
contradicts the choice of prior preference.
In the second technique, the effectiveness of the model
as a predictor is evaluated with the available data. The
data set available for training is divided into two
categories: data on which the model is correct and data
on which the model is incorrect. This divided data set
is used to learn a "Referee" predictor (using C4.5) that
provides a mechanism for deciding when the model should
be used for the prediction of future instances. In cases
where the "Referee" indicates that the model is
incorrect, a separate "Data" predictor, learned using
C4.5 with the original training data, is used instead.
This technique was also extended to an arbitrary number
of existing models and learning algorithms.
Experiments were conducted with some databases
(recognizing DNA promoter sequences, identifying illegal
chess board positions, and diagnosing soybean and
audiology diseases) that are often used in the machine
learning community as benchmarks. In terms of predictive
accuracy, the above techniques outperform both the model
alone and empirical learning alone (with C4.5) on the
available data.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  3916 </NUMBER>
<ORDER>   AAG9626148 </ORDER>
<TITLE> COMPUTER BASED FACE RECOGNITION USING NEURAL NETWORKS: A BIOMETRIC ACCESS CONTROL SYSTEM BASED ON THE HUMAN FACE </TITLE>
<AUTHOR> ALTAF, USAMAH M. S. </AUTHOR>
<YEAR> 1996 </YEAR>
<INSTITUTION> UNIVERSITY OF MISSOURI - ROLLA; 0135 </INSTITUTION>
<DESCRIPTORS> ENGINEERING, ELECTRONICS AND ELECTRICAL; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> CIHAN H. DAGLI </ADVISER>
<CLASSIFICATIONS> MACHINE VISION </CLASSIFICATIONS>
<ABSTRACT>
Fraud is faced on a daily basis in today's society. An
impostor could slip through and access highly sensitive
locations, a child could be released to a stranger from
a daycare center, a welfare recipient could sign up for
benefits under six identities, a voter may vote under
two different names using two different social security
numbers, and a counterfeiter could make copies of and
charges to credit cards. Authentic means of identity
verification are urgently in high demand. Biometrics,
which is the field that incorporates the measurement of
one or more distinctive biological trait(s) in order to
be studied, examined, or used to uniquely identify its
owner, is the most promising solution.
A biometric system that employs the human face for
identity verification and access control was
successfully developed and tested. In the course of
achieving this goal, two different models were developed
and tested. One employs a neural network and the other
uses feature extraction by implementing a novel elastic
template matching approach.
The neural network based model was considered for
further development and modification to build the aimed
system. The developed face based biometric access
control system incorporates more than one access control
technique in order to provide a higher level of
security. The system employs the user's knowledge of a
password or personal identification number (PIN),
possession of a magnetic strip card providing the user's
name, and the user's face as a physiological
characteristic in order to grant or deny access. The
results obtained after rigorous testing of the system
are very encouraging.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  3917 </NUMBER>
<ORDER>   AAGC569339 </ORDER>
<TITLE> MODELLING MUSICAL COGNITION WITH ARTIFICIAL NEURAL NETWORKS </TITLE>
<AUTHOR> TOIVIAINEN, PETRI </AUTHOR>
<YEAR> 1996 </YEAR>
<INSTITUTION> JYVASKYLAN YLIOPISTO (FINLAND); 0979 </INSTITUTION>
<DESCRIPTORS> MUSIC; ARTIFICIAL INTELLIGENCE JYVASKYLA, FINLAND </DESCRIPTORS>
<ADVISER> NIL </ADVISER>
<CLASSIFICATIONS> TIMBRE, MELODY </CLASSIFICATIONS>
<ABSTRACT>
As a highly abstract form of human activity, music is a
challenging realm to study. During the last ten years,
the connectionist paradigm has provided insights into
many domains of human behaviour, including musical
activity and experience. Artificial neural networks, or
connectionist systems, can be characterized as strongly
idealized models of networks formed by biological
neurons: consisting of a bulk of simple interconnected
processing units, they employ parallel distributed
processing and are capable of learning and self-
organizing.
The present study focuses on aspects of musical
cognition such as perceptual learning, self-
organization, feature extraction, sequential processing,
autoassociative recall, and short-term memory. More
specifically, processes related to the classification
and recognition of musical timbre and the learning and
generarion of melodies are modelled using artificial
neural networks.
The results support the view that the connectionist
paradigm provides a plausible alternative for modelling
the dynamics of certain music-related cognitive
processes. Being inherently capable of generalizing,
associating on the basis of content, and tolerating
noisy or distorted input, artificial neural networks
exhibit functions characteristic of the human way of
perceiving, thinking, and acting.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  3918 </NUMBER>
<ORDER>   AAG9626142 </ORDER>
<TITLE> A METHODOLOGY FOR KNOWLEDGE ENGINEERING IN AN INDUSTRIAL ENVIRONMENT FOR AN EXPERT CONTROL ADVISING SYSTEM </TITLE>
<AUTHOR> BURWELL, LISA RENE </AUTHOR>
<YEAR> 1996 </YEAR>
<INSTITUTION> UNIVERSITY OF MISSOURI - ROLLA; 0135 </INSTITUTION>
<DESCRIPTORS> COMPUTER SCIENCE; ENGINEERING, INDUSTRIAL; INFORMATION SCIENCE; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> STEPHEN RAPER </ADVISER>
<CLASSIFICATIONS> NIL </CLASSIFICATIONS>
<ABSTRACT>
This dissertation identifies and addresses the need for
knowledge engineering methodologies for industry. The
lack of successful expert systems in industry was
discussed. The low number of industrial expert systems,
and their general lack of success, was attributed to the
maturity of the technology and the current stage of
evolution. Methodologies developed by knowledge
engineers in research institutions are not likely to be
appropriate for industrial applications and
methodologies that meet the specific needs of industry
do not appear to exit. A case was made for building
knowledge engineering methodologies which address the
specific needs and maturity level of industry.
The industrial environment was defined. A methodology
was introduced which meets the specific needs of
industry and control advising problems in particular.
The suitability of the methodology was evaluated through
application. The results of this application indicate
that the methodology is an effective and productive tool
for implementing expert system projects in industry.
The research was further substantiated through an
informal survey of five computer professionals. The
results indicated that the proposed knowledge
engineering methodology would be a useful tool and guide
for knowledge engineering projects in industry.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  3919 </NUMBER>
<ORDER>   AAG9626141 </ORDER>
<TITLE> INTELLIGENT CONTROL USING RECURRENT NEURAL NETWORKS </TITLE>
<AUTHOR> XU, QUN </AUTHOR>
<YEAR> 1996 </YEAR>
<INSTITUTION> UNIVERSITY OF MISSOURI - ROLLA; 0135 </INSTITUTION>
<DESCRIPTORS> ENGINEERING, MECHANICAL; ENGINEERING, INDUSTRIAL; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> K. KRISHNAMURTHY </ADVISER>
<CLASSIFICATIONS> NIL </CLASSIFICATIONS>
<ABSTRACT>
Control of nonlinear dynamical systems has been a
difficult task due to the lack of system models and the
presence of nonlinearity and uncertainty, and no
systematic and generally applicable design techniques
have yet evolved. The emergence of neural networks in
the realm of modeling, identification, and control of
nonlinear dynamical systems has offered exciting
possibilities to perform intelligent control for
nonlinear systems. In this study, a neural network
control scheme which has on-line learning capability is
developed to control nonlinear dynamical systems in the
presence of uncertainties and environment changes. The
control scheme involves a neural identifier and a neural
controller. The neural identifier is trained to
represent the system to be controlled accurately, and
the neural controller is trained to take appropriate
action according to the desired output and the
environment. Recurrent neural networks are employed for
both the neural identifier and neural controller, and
training is accomplished using a recursive least squares
algorithm. Simulation results as well as experimental
results for the control of cutting force in one-
dimensional end milling operations for validating the
proposed control methodology are presented.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  3920 </NUMBER>
<ORDER>   AAGNN08373 </ORDER>
<TITLE> ARTIFICIAL NEURAL NETWORKS: LINKS WITH STATISTICAL PATTERN RECOGNITION  </TITLE>
<AUTHOR> OSMAN, HOSSAM EL-DIN </AUTHOR>
<YEAR> 1996 </YEAR>
<INSTITUTION> QUEEN'S UNIVERSITY AT KINGSTON (CANADA); 0283 </INSTITUTION>
<DESCRIPTORS> ENGINEERING, ELECTRONICS AND ELECTRICAL; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> MOUSTAFA M. FAHMY </ADVISER>
<CLASSIFICATIONS> BAYESIAN CLASSIFICATION </CLASSIFICATIONS>
<ABSTRACT>
This thesis provides new theoretical links between two
artificial neural network (ANN) classifiers, namely back-
propagation (BP) and radial-basis-function (RBF), and
three fundamental topics in statistical pattern
recognition (SPR), namely the Bayes decision theory,
discriminant analysis, and cluster analysis. The
provided links (i) improve the performance of these ANN
classifiers, (ii) help us better understand their
behavior, (iii) theoretically justify their usage, and
(iv) assist in employing them where they best fit.
First, links with the Bayes decision theory are
established. Consider a linear-output BP or an RBF
network classifier whose training involves the
minimization of the standard mean-square error (MSE). It
is proved that, once training is complete, not only the
output of this network has minimum variance from the
Bayes vector in the limit of an asymptotically large
number of statistically independent training patterns,
but also if the Bayes vector satisfies a linear
constraint, then so will the network output. In
addition, it is shown that a BP or RBF network
classifier whose training involves the minimization of a
class of generalized mean-square errors (GMSEs),
approximates a normalized affine transformation of the
Bayes vector in the MSE sense. Moreover, it is
demonstrated that this network classifier can yield the
Bayes decision rule at its output, and if it has a
linear output layer, then it not only approximates a
normalized transformation, but also yields an output
that is always normalized.
Secondly, new links between BP and RBF network
classifiers and discriminant analysis are provided. It
is proved that, once training is complete, the minimized
value of the standard MSE at the output of a linear-
output BP or an RBF network classifier equals the
difference between a desired and an actual value of the
network discriminatory power. This indicates that the
network classification performance is completely
dependent upon the discriminant capability of its hidden
layers. It is also shown that, in the limit of an
asymptotically large number of statistically independent
training patterns, the reduction of the minimized value
of the standard MSE, the approximation of the Bayes
vector at the network output, and the optimization of
the network discriminatory power, are all equivalent.
Applications are (i) the maximization of a given feature
extraction criterion using a linear-output BP network,
(ii) the definition of a new measure of the
generalization of linear-output BP and RBF neural
classifiers, and (iii) the conjecture of an upper bound
on the number of hidden units needed by RBF network
classifiers to yield an arbitrary value of the standard
MSE.
Finally, a new link between RBF network classifiers and
cluster analysis is developed. Specifically, a new
competitive learning (CL) algorithm that is based upon a
clustering scheme found within the SPR literature is
developed and used to train the hidden layer of RBF
network classifiers. The algorithm is called "the
probabilistic winner-take-all (PWTA)." Its learning rule
is derived for four different cases. Its properties are
discussed and compared to those of two popular CL
algorithms, namely the winner-take-all (WTA) and the
maximum-likelihood soft competition (MLSC). (Abstract
shortened by UMI.)
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  3921 </NUMBER>
<ORDER>   AAG9628980 </ORDER>
<TITLE> REASONING ABOUT INTERNAL CONTROLS AND FRAUD: THE AI PLANNING APPROACH TO MODELING THE BUSINESS PROCESS </TITLE>
<AUTHOR> NATOVICH, JOSEPH </AUTHOR>
<YEAR> 1996 </YEAR>
<INSTITUTION> RUTGERS THE STATE UNIVERSITY OF NEW JERSEY - NEWARK; 0461 </INSTITUTION>
<DESCRIPTORS> BUSINESS ADMINISTRATION, ACCOUNTING; ARTIFICIAL INTELLIGENCE; SOCIOLOGY, CRIMINOLOGY AND PENOLOGY </DESCRIPTORS>
<ADVISER> MIKLOS A. VASARHELYI </ADVISER>
<CLASSIFICATIONS> ARTIFICIAL INTELLIGENCE </CLASSIFICATIONS>
<ABSTRACT>
Many organizations struggle in the battle against fraud.
An understanding of the opportunities that facilitate
its occurrence is essential to fraud control.
Identifying possible ways to defraud the examined system
requires creativity and thorough knowledge of the
system. This paper suggests an automated version of this
analysis--Fraud Simulator with its three parts: ROLEMAN,
GFS and CROOK.
ROLEMAN is a business process model based on the AI
Planning paradigm. ROLEMAN uses a declarative, role
oriented modeling method. In ROLEMAN, business processes
are represented as a set of independent actions with
preconditions and effects rather than a procedure with a
sequence of action in a defined order. Because of its
ability to explicitly represent threats, controls and
deviations from the prescribed process, we argue that
ROLEMAN is useful for business process modeling from the
control perspective.
GFS is a knowledge base of fraud behavior. The main idea
that underlies GFS is that there are only few generic
frauds which appear in many variations. Because fraud
involves circumventing controls, these variations are
affected by the different structures of the relevant
controls. Using a few adaptation strategies, the fraud
perpetrator adapts the generic fraud to the specific
control. We identified four major generic frauds and
five major adaptation strategies, and we performed an
empirical study that supports this view.
CROOK is a multiple-agent fraud planner that generates
hypothetical fraud scenarios in a given business
process. CROOK's algorithm is influenced by case-based
reasoning and schema-based reasoning and consists of
three steps: scheme selection, plan critique and plan
repair. The process of repair and critique is repeated
until either the adapted plan is successful or there are
no more suggestions for repair.
This work is an early attempt, if not the first, to
apply AI planning technology in the audit domain. We
developed Fraud Simulator, examined its feasibility as a
potential tool and evaluated its usefulness. In
addition, besides being a decision aid proposed for
auditing tasks, Fraud Simulator contributes to business
process modeling, knowledge representation of fraud
schemes and multiple-agent planning techniques.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  3922 </NUMBER>
<ORDER>   AAG9626735 </ORDER>
<TITLE> DESIGN AND EVALUATION OF A PC KNOWLEDGE-BASED EXPERT SYSTEM </TITLE>
<AUTHOR> AKPANUMOH, ED DANIEL </AUTHOR>
<YEAR> 1996 </YEAR>
<INSTITUTION> UNIVERSITY OF HOUSTON; 0087 </INSTITUTION>
<DESCRIPTORS> INFORMATION SCIENCE; COMPUTER SCIENCE; EDUCATION, HIGHER </DESCRIPTORS>
<ADVISER> NIL </ADVISER>
<CLASSIFICATIONS> ARTIFICIAL INTELLIGENCE </CLASSIFICATIONS>
<ABSTRACT>
This study addresses the needs of novice researchers who
are usually faced with the ardous task of choosing
appropriate research methodology and correct statistical
analysis techniques. According to Caplovitz (1983) these
important initial steps in research appear to pose some
sort of problem to a large number of novice researchers
to the point of causing them to stall in the process or
becoming a deterrent to their completion of the
research, Steinberg (1981), Balian (1982), Gardner and
Beatty (1980). In some instances an experienced
researcher may sometimes find these processes rather
puzzling, Hall (1977), Gardner and Beatty (1980). An
easy way out for some is the hiring of "statisticians,"
and paying exhorbitantly for data analysis, Gardner and
Beatty (1980).
In this study a knowledge-based expert system that can
assist novice researchers in the choice of both
appropriate research methodology and correct data
analysis techniques is designed and evaluated.
An expert system, a branch of artificial intelligence,
is a computer program that stimulates the problem
solving techniques of human experts and utilizes the
experience of one or more experts in a chosen problem
domain, and applies their problem solving expertise to
make useful inferences for the user of the system,
Waterman (1986) and Haye-Roth (1984). There are three
main components of an expert system: (1) the knowledge-
base, which contains both declarative and procedural
knowledge, (2) the inference machine, which controls how
and when the information in the knowledge-base is
applied, and (3) the user interface, which interacts
with and obtains information from the user, Vassallo and
Lanasa (1990), Godwin and Roa (1991).
Hurd (1988) observed that expert systems and other
artificial intelligence (AI), are becoming increasingly
important in the information processing profession, but
currently only a few educational programs offer enough
specific instruction in this rapidly growing area. This
study sought to enhance the design and use of expert
system in educational research.
Modified versions of expert system development processes
suggested by Siegel (1986), Edmund (1988), Grabinger,
Wilson and Jonassen (1990) were used in the design.
Validation of the criteria of the advisory system were
addressed though a pilot test on a sample of thirty
graduate students and three faculty researchers. The
results of the validation were analyzed and used for
formative evaluation of the system.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  3923 </NUMBER>
<ORDER>   AAG9626143 </ORDER>
<TITLE> DEVELOPMENT OF A SELF-EVALUATION SYSTEM FOR TOTAL QUALITY MANAGEMENT USING THE BALDRIGE CRITERIA </TITLE>
<AUTHOR> WU, HUNG-YI </AUTHOR>
<YEAR> 1996 </YEAR>
<INSTITUTION> UNIVERSITY OF MISSOURI - ROLLA; 0135 </INSTITUTION>
<DESCRIPTORS> BUSINESS ADMINISTRATION, MANAGEMENT; COMPUTER SCIENCE; ENGINEERING, INDUSTRIAL; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> HENRY A. WIEBE </ADVISER>
<CLASSIFICATIONS> NIL </CLASSIFICATIONS>
<ABSTRACT>
Total quality management (TQM) has been increasingly
accepted as a guiding management philosophy by many
organizations and quality criteria such as the Malcolm
Baldrige National Quality Award (MBNQA), are often used
as guidelines for TQM implementation. However, reports
indicate that assessment of TQM implementation efforts
are difficult because of the magnitude of the assessment
task. Furthermore, hiring experts to help with this task
is too expensive for small companies. This research
develops a quick and cost-efficient instrument in the
form of a simple questionnaire to assist organizations
in a self-evaluation of their TQM program.
Initial work consisted of sending out an extremely
comprehensive questionnaire to a selected group of
organizations for which the level of TQM implementation
was precisely measured against the Baldrige criteria.
Two approaches were employed to reduce the number of
questions to a small number and still obtain an accurate
picture of the organization's TQM status. First, an
Artificial Intelligence technique, Artificial Neural
Network (ANN or briefly NN), was used to analyze data
gathered by the comprehensive questionnaire. Different
NN systems were designed to first select key questions
and then evaluate their performance against a complete
Baldrige evaluation of the organization. The results
showed that a two-level NN was best at this task.
Second, a general statistical analysis was used to
approach the questionnaire development task from a
different perspective. The outcomes of both the NN
systems and the statistical analysis are discussed in
detail; and, a set of combined questions selected by the
two approaches are recommended. Finally, limitations of
this study and future research are provided.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  3924 </NUMBER>
<ORDER>   AAGC492623 </ORDER>
<TITLE> CONVERGENCE OF MINIMIZATION ESTIMATORS TRAINED UNDER ADDITIVE NOISE </TITLE>
<AUTHOR> KOISTINEN, PETRI </AUTHOR>
<YEAR> 1996 </YEAR>
<INSTITUTION> TEKNILLINEN KORKEAKOULU (HELSINKI) (FINLAND); 5766 </INSTITUTION>
<DESCRIPTORS> COMPUTER SCIENCE; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> NIL </ADVISER>
<CLASSIFICATIONS> NIL </CLASSIFICATIONS>
<ABSTRACT>
In certain statistical methods the unknown parameters of
a distribution are estimated by minimizing (or
maximizing) a suitable cost function which depends on
the observed sample. Examples of such methods include
maximum likelihood estimators, nonlinear regression
estimators as well as certain methods suggested in the
field of neural networks. This thesis considers what
happens to such an estimator when the cost function to
be minimized is defined by substituting a noisy sample
for the original sample. In the noisy sample each point
of the original sample is replaced by a set of points
obtained by adding noise to the original point. Such
noisy training has been suggested in the context of
neural networks to prevent overfitting. Noisy training
has close connections to certain statistical
regularization methods such as ridge regression. The
thesis presents mathematical results concerning the
large sample properties (consistency and asymptotic
normality) of minimization estimators trained using a
noisy sample.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  3925 </NUMBER>
<ORDER>   AAI1378707 </ORDER>
<TITLE> FUZZY LOGIC-BASED PID SELF-TUNING </TITLE>
<AUTHOR> AL-NEMER, TAHER MOHAMMED TAHER </AUTHOR>
<YEAR> 1996 </YEAR>
<INSTITUTION> KING FAHD UNIVERSITY OF PETROLEUM AND MINERALS (SAUDI ARABIA); 1088 </INSTITUTION>
<DESCRIPTORS> ENGINEERING, SYSTEM SCIENCE; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> NIL </ADVISER>
<CLASSIFICATIONS> NIL </CLASSIFICATIONS>
<ABSTRACT>
A Fuzzy Logic (FL)-based PID self-tuning regulator is
presented in this thesis. The basic concept behind the
new scheme is to combine the classical PID control with
the knowledge-based Fuzzy Logic technology. The PID
controller regulates the process, while the FL part
adjusts the PID gains. The scheme is also extended to
handle processes with long dead times which commonly
exist in many processes. This is accomplished by merging
the proposed FL based self-tuning scheme with a dead-
time compensation algorithm. Finally, the proposed
algorithm will be used to improve the performance of
some of the loops that contain known non-linearities by
combining a Gain Scheduling algorithm with the FL based
PID self-tuning scheme.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  3926 </NUMBER>
<ORDER>   AAI1378643 </ORDER>
<TITLE> KNOWLEDGE-BASED SYSTEM FOR CAPACITY RATING OF STEEL TRUSS AND SKEW BRIDGES </TITLE>
<AUTHOR> PONNUSWAMY, SATTANATHAN </AUTHOR>
<YEAR> 1996 </YEAR>
<INSTITUTION> FLORIDA ATLANTIC UNIVERSITY; 0119 </INSTITUTION>
<DESCRIPTORS> ENGINEERING, CIVIL; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> M. AROCKIASAMY </ADVISER>
<CLASSIFICATIONS> NIL </CLASSIFICATIONS>
<ABSTRACT>
The Knowledge Based System CARAT is developed to rate
any existing steel truss bridge. CARAT is capable of
rating statically determinate and indeterminate truss
bridges. Corrosion, temperature effects and the
remaining fatigue life of the truss members can be
evaluated using CARAT. The other expert system SKEWRAT
is developed to determine the strength of skew bridges.
Skew AASHTO girder and slab bridges can be analyzed
using SKEWRAT. The architecture of both CARAT and
SKEWRAT are based on production system model and set of
IF-THEN rules are developed using EXSYS Professional
Shell editor. The inference mechanism fire rules
according to the built-in reasoning process. The
suggestions given by Bakht and Jaeger (8) are
incorporated to determine the strength characteristics
of skewed AASHTO girder and slab bridges. Programming
Languages FORTRAN and C are used extensively for the
software development. The validity of both the softwares
are verified and illustrated in detail with four
examples.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  3927 </NUMBER>
<ORDER>   AAI1378191 </ORDER>
<TITLE> A CONNECTIONIST APPROACH TO ADAPTIVE REASONING: AN EXPERT SYSTEM TO PREDICT SKID NUMBERS </TITLE>
<AUTHOR> REDDY, MOHAN S. </AUTHOR>
<YEAR> 1996 </YEAR>
<INSTITUTION> FLORIDA ATLANTIC UNIVERSITY; 0119 </INSTITUTION>
<DESCRIPTORS> COMPUTER SCIENCE; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> A. S. PANDYA </ADVISER>
<CLASSIFICATIONS> NIL </CLASSIFICATIONS>
<ABSTRACT>
This project illustrates the neural network approach to
constructing a fuzzy logic decision system. This
technique employs an artificial neural network (ANN) to
recognize the relationships that exit between the
various inputs and outputs. An ANN is constructed based
on the variables present in the application. The network
is trained and tested. Various training methods are
explored, some of which include auxiliary input and
output columns. After successful testing, the ANN is
exposed to new data and the results are grouped into
fuzzy membership sets based membership evaluation rules.
This data grouping forms the basis of a new ANN. The
network is now trained and tested with the fuzzy
membership data. New data is presented to the trained
network and the results form the fuzzy implications.
This approach is used to compute skid resistance values
from G-analyst accelerometer readings on open grid
bridge decks.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  3928 </NUMBER>
<ORDER>   AAGC568399 </ORDER>
<TITLE> ALGORYTMY STEROWANIA ROBOTOW OPARTE NA ZASADZIE UNIWERSALNEGO ADAPTACYJNEGO UKLADU STEROWANIA; ROBOT CONTROL ALGORITHMS BASED ON THE PRINCIPLE OF UNIVERSAL ADAPTIVE CONTROL </TITLE>
<AUTHOR> MAZUR, ALICJA CELINA </AUTHOR>
<YEAR> 1996 </YEAR>
<INSTITUTION> POLITECHNIKA WROCLAWSKA (POLAND); 5999 </INSTITUTION>
<DESCRIPTORS> COMPUTER SCIENCE; ARTIFICIAL INTELLIGENCE; ENGINEERING, INDUSTRIAL; ENGINEERING, MECHANICAL WROCLAW, WROCLAW, POLAND </DESCRIPTORS>
<ADVISER> NIL </ADVISER>
<CLASSIFICATIONS> MANIPULATORS, TRAJECTORY, STABILISATION </CLASSIFICATIONS>
<ABSTRACT>
The problem of joint space trajectory tracking of rigid
manipulators is considered. 5 new stabilizing control
algorithms are introduced. The proposed control
algorithms preserve tracking of a desired trajectory as
well for a case when a model of the robot dynamics is
known as for a case when a model is completely unknown.
The presented algorithms use the universal adaptive
controllers which play a role of "dynamical version" of
the classical controllers. The convergence of every
proposed universal adaptive control algorithms has been
proven.
ftn$sp1$Wyniki przedstawione w rozprawie zostaly
uzyskane w ramach realizacji projektow badawczych KBN
'Roboty osobliwe i nieholonomiczne: modele i algorytmy
sterowania' oraz 'Roboty osobliwe i nieholonomiczne:
modele, sterowanie i planowanie trajektorii.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  3929 </NUMBER>
<ORDER>   AAI1378191 </ORDER>
<TITLE> A CONNECTIONIST APPROACH TO ADAPTIVE REASONING: AN EXPERT SYSTEM TO PREDICT SKID NUMBERS </TITLE>
<AUTHOR> REDDY, MOHAN S. </AUTHOR>
<YEAR> 1996 </YEAR>
<INSTITUTION> FLORIDA ATLANTIC UNIVERSITY; 0119 </INSTITUTION>
<DESCRIPTORS> COMPUTER SCIENCE; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> A. S. PANDYA </ADVISER>
<CLASSIFICATIONS> NIL </CLASSIFICATIONS>
<ABSTRACT>
This project illustrates the neural network approach to
constructing a fuzzy logic decision system. This
technique employs an artificial neural network (ANN) to
recognize the relationships that exit between the
various inputs and outputs. An ANN is constructed based
on the variables present in the application. The network
is trained and tested. Various training methods are
explored, some of which include auxiliary input and
output columns. After successful testing, the ANN is
exposed to new data and the results are grouped into
fuzzy membership sets based membership evaluation rules.
This data grouping forms the basis of a new ANN. The
network is now trained and tested with the fuzzy
membership data. New data is presented to the trained
network and the results form the fuzzy implications.
This approach is used to compute skid resistance values
from G-analyst accelerometer readings on open grid
bridge decks.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  3930 </NUMBER>
<ORDER>   AAI9624878 </ORDER>
<TITLE> APPLICATION OF ARTIFICIAL INTELLIGENCE METHODS TO SOLVE THE PROTEIN FOLDING PROBLEM: THE USE OF NEURAL NETWORKS AND GENETIC ALGORITHMS FOR OPTIMIZATION </TITLE>
<AUTHOR> RABOW, ALFRED ARTHUR </AUTHOR>
<YEAR> 1996 </YEAR>
<INSTITUTION> CORNELL UNIVERSITY; 0058 </INSTITUTION>
<DESCRIPTORS> BIOPHYSICS, GENERAL; CHEMISTRY, PHYSICAL </DESCRIPTORS>
<ADVISER> H. SCHERAGA </ADVISER>
<CLASSIFICATIONS> CRAMBIN </CLASSIFICATIONS>
<ABSTRACT>
One of the most important unsolved problems in
biophysical chemistry is the determination of the three-
dimensional structure of proteins from their amino acid
sequences. It has been shown that finding the
conformation of a protein that minimizes the free energy
globally is equivalent to calculating the native
conformation. Two attempts are presented here to apply
artificial intelligence methods to find the global-
minimum-energy conformation and, hence, to predict the
native structure.
In Chapter I, the lattice neural network minimization
(LNNM) method is described. The method consists of
representing the conformation of a protein as an array
of the amino acid sequence versus position on a three-
dimensional cubic lattice, and using neural networks to
minimizes its energy. The LNNM method successfully found
the global minima for oligopeptides and demonstrated its
superiority over the standard Monte Carlo simulated
annealing method. The LNNM method was applied to the
protein crambin (46 residues), and a compact low-energy
structure was found. The lattice neural network
minimization method was also used to predict the chain-
folding initiation sites of proteins and correctly
predicted the sites for the two proteins examined,
Ribonuclease S and T4 lysozyme.
In Chapter II, a Cartesian combination operator and
coding scheme was devised for improving the performance
of genetic algorithms applied to the protein folding
problem with the genetic code consisting of the
Cartesian coordinates of the protein chain. The
recombination of the genes of the parents is
accomplished by: (i) a rigid superposition of one parent
chain on the other, then, (ii) the children are formed
through a linear combination of the coordinates of their
parents. This new scheme is significantly more efficient
than the standard genetic algorithms for locating the
low-energy conformations of proteins. The considerable
superiority of genetic algorithms over Monte Carlo
optimization methods is also demonstrated. Chapter II
further contains a description of a new dynamic
programming lattice fitting procedure. The procedure
finds excellent fits of real-space chains to the lattice
while satisfying bond-length, bond-angle, and overlap
constraints.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  3931 </NUMBER>
<ORDER>   AAI9624163 </ORDER>
<TITLE> MODEL UPDATING USING NEURAL NETWORKS </TITLE>
<AUTHOR> ATALLA, MAURO JORGE </AUTHOR>
<YEAR> 1996 </YEAR>
<INSTITUTION> VIRGINIA POLYTECHNIC INSTITUTE AND STATE UNIVERSITY; 0247 </INSTITUTION>
<DESCRIPTORS> ENGINEERING, MECHANICAL; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> DANIEL J. INMAN </ADVISER>
<CLASSIFICATIONS> ADAPTIVE CONTROL </CLASSIFICATIONS>
<ABSTRACT>
Accurate models are necessary in critical applications.
Key parameters in dynamic systems often change during
their life cycle due to repair and replacement of parts
or environmental changes. This dissertation presents a
new approach to update system models, accounting for
these changes. The approach uses frequency domain data
and a neural network to produce estimates of the
parameters being updated, yielding a model
representative of the measured data.
Current iterative methods developed to solve the model
updating problem rely on minimization techniques to find
the set of model parameters that yield the best match
between experimental and analytical responses. Since the
minimization procedure requires a fair amount of
computation time, it makes the existing techniques
infeasible for use as part of an adaptive control scheme
correcting the model parameters as the system changes.
They also require either mode shape expansion or model
reduction before they can be applied, introducing errors
in the procedure. Furthermore, none of the existing
techniques has been applied to nonlinear systems.
The neural network estimates the parameters being
updated quickly and accurately without the need to
measure all degrees of freedom of the system. This
avoids the use of mode shape expansion or model
reduction techniques, and allows for its implementation
as part of an adaptive control scheme. The proposed
technique is also capable of updating weakly nonlinear
systems.
Numerical simulations and experimental results show that
the proposed method has good accuracy and generalization
properties, and it is therefore, a suitable alternative
for the solution of the model updating problem of this
class of systems.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  3932 </NUMBER>
<ORDER>   AAI9623848 </ORDER>
<TITLE> GRADED STRUCTURE OF DEFECT CATEGORIES IN AUTOMATED DEFECT CLASSIFICATION  </TITLE>
<AUTHOR> WONG, WAN SANG </AUTHOR>
<YEAR> 1996 </YEAR>
<INSTITUTION> TEXAS TECH UNIVERSITY; 0230 </INSTITUTION>
<DESCRIPTORS> COMPUTER SCIENCE; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> A. KATHLEEN HENNESSEY </ADVISER>
<CLASSIFICATIONS> FUZZY LOGIC, KNOWLEDGE-BASED </CLASSIFICATIONS>
<ABSTRACT>
Graded structures refers to continuum category
representation from the most typical member of a
category through its typical members to those nonmembers
least similar to category member. Graded structure
occurs in any categorization. Two levels of
categorization and therefore two level of graded
structures occur in knowledge-based defect
classification which can adversely affect the
performance of knowledge-based visual classification
systems. The first level of graded structure occurs in
the design of defect knowledge base when the defect
expert describes defect categories in terms of defects'
visual features using linguistic variables. Since the
descriptions of these categories will be assimilated
into the defect knowledge base for use as criteria for
classification, any misrepresentation of them will
likely result in some increase in misclassification
rate. Feature values which are acquired subjectively and
represented in natural language are most subject to the
limitation associated with graded structure. Graded
structure level two occurs in the actual defect
classification where feature similarities between the
actual defect and the categorical defects are compared.
The focus of this research is minimization of the effect
of graded structure in automated defect classification
for patterned semiconductor wafers, which current
research has not dealt. Level one graded structure can
be minimized by standardizing defect features. One way
of standardizing defect features is by representing them
as fuzzy sets and their degrees of membership are
determined by membership functions established by a
defect classification expert. The level two graded
structure can be minimized by utilizing both human-and
machine-based defect features in categorization. Human
generated object features are directly visible and
recognizable to a human observer while machine generated
features are not directly perceptible by humans.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  3933 </NUMBER>
<ORDER>   AAI9623701 </ORDER>
<TITLE> OPTIMIZATION OF WAVELET BASIS CONTROLLERS FOR NONLINEAR SYSTEMS WITH APPLICATIONS TO LEARNING CONTROL SYSTEMS </TITLE>
<AUTHOR> DIREEN, HARRY GEORGE, JR. </AUTHOR>
<YEAR> 1996 </YEAR>
<INSTITUTION> UNIVERSITY OF COLORADO AT COLORADO SPRINGS; 0892 </INSTITUTION>
<DESCRIPTORS> ENGINEERING, ELECTRONICS AND ELECTRICAL; ENGINEERING, SYSTEM SCIENCE; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> PIETER A. FRICK </ADVISER>
<CLASSIFICATIONS> FUZZY LOGIC </CLASSIFICATIONS>
<ABSTRACT>
A learning control system may be defined as a system
that improves its performance with experience. This is a
common trait of systems that use humans as the main
control element: automobiles, aircraft, children
balancing a broom on their hand... Ascribing this
characteristic to inanimate controllers is a nontrivial
task. This thesis examines methods of improving control
of general nonlinear systems with experience, where
"experience" is gained through monitoring normal
operation of the given system. The primary contribution
of this thesis is the development of local conditions
for improvement of the control law based on a given
objective function. The application of these conditions
leads to an optimized control law in a limited sense.
Improvements of the control law are made only in regions
of the state space where the system is known to be
asymptotically stable. The conditions of improvement
contain conditions that guarantee the "improved system"
remains asymptotically stable.
The learning control system relies on being able to make
local changes to the control law. Due to their localized
support and orthogonal structure, wavelet
multiresolution analysis is turned to for the basis
functions used to represent the control law. The
multiresolution structure provides a mechanism for
starting with a coarse level of control and adding
detail to the control law as required. Wavelet
multiresolution analysis is reviewed and shown to map
into a popular neural network topology which provides a
massively parallel structure for implementing the
controller.
Practical methods of applying the control law
improvement theory are addressed and examples provided.
Finally, methods of expanding the region of asymptotic
stability are proposed.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  3934 </NUMBER>
<ORDER>   AAI9623528 </ORDER>
<TITLE> TRAINING INSTRUCTABLE AGENTS THROUGH PLAUSIBLE VERSION SPACE LEARNING  </TITLE>
<AUTHOR> HIEB, MICHAEL RAY </AUTHOR>
<YEAR> 1996 </YEAR>
<INSTITUTION> GEORGE MASON UNIVERSITY; 0883 </INSTITUTION>
<DESCRIPTORS> COMPUTER SCIENCE; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> GHEORGHE TECUCI </ADVISER>
<CLASSIFICATIONS> AGENT DISCIPLE SYSTEM, ARTIFICIAL INTELLIGENCE, MACHINE LEARNING </CLASSIFICATIONS>
<ABSTRACT>
Agents assist users with performing tasks in computer-
based applications. The current practice of building an
agent involves a developer programming it for each task
it must perform, but agents constructed in this manner
are difficult to modify and cannot be trained by a user.
This dissertation presents Agent-Disciple--a system for
training instructable agents through user-agent
interaction. In Agent-Disciple a user trains an
instructable agent through the interface of the user's
application by providing specific examples of tasks and
their solutions, explanations of these solutions and
supervises the agent as it performs new tasks.
The Agent-Disciple system integrates apprenticeship
learning, multistrategy learning, knowledge acquisition
and programming by demonstration techniques. Agent-
Disciple is based upon the Disciple system (Tecuci,
1988), using plausible version space learning methods
that learn from a limited number positive and negative
examples, and explanations of these examples. The Agent-
Disciple system is constructed as a toolkit of software
modules to separate the task of building an agent from
the task of building a tool for the instruction of the
agent. The toolkit approach is general and thus can be
applied to build instructable agents for a wide range of
applications.
Several contributions were made to interactive plausible
version space learning methods: user-guided scalable
search; user-guided explanation-generation techniques;
splitting the plausible version space; and consistency-
driven knowledge elicitation. These methods make the
search space utilized in learning scalable, and make the
general version space approach more interactive and
efficient.
A case study in implementing a prototype instructable
agent concludes the thesis. An instructable Company
Commander Agent is developed for the Modular Semi-
Automated Forces (ModSAF) simulation--a state-of-the-
art, real-time, distributed interactive military
simulation currently utilized in large-scale training
exercises. A ModSAF user can interactively train the
Company Commander Agent, using the ModSAF interface, to
perform various military missions. A training session
with the agent illustrates the different types of
learning interactions available in Agent-Disciple. The
result of this research demonstrates how to construct
and efficiently train an instructable agent for a
complex application.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  3935 </NUMBER>
<ORDER>   AAI9623233 </ORDER>
<TITLE> A VLSI IMPLEMENTABLE LEARNING ALGORITHM </TITLE>
<AUTHOR> RUIZ, LAURA V. </AUTHOR>
<YEAR> 1996 </YEAR>
<INSTITUTION> FLORIDA ATLANTIC UNIVERSITY; 0119 </INSTITUTION>
<DESCRIPTORS> ENGINEERING, ELECTRONICS AND ELECTRICAL; COMPUTER SCIENCE; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> ABHIJIT S. PANDYA </ADVISER>
<CLASSIFICATIONS> STOCHASTIC NEURAL NETWORK </CLASSIFICATIONS>
<ABSTRACT>
A top-down design methodology using hardware description
languages (HDL's) and powerful design, analysis,
synthesis and layout software tools for electronic
circuit design is described and applied to the design of
a single layer artificial neural network that
incorporates on-chip learning. Using the perception
learning algorithm, these simple neurons learn a
classification problem in 10.55 microseconds in one
application. The objective is to describe a methodology
by following the design of a simple network. This
methodology is later applied in the design of a novel
architecture, a stochastic neural network. All issues
related to algorithmic design for VLSI implementability
are discussed and results of layout and timing analysis
given over software simulations. A top-down design
methodology is presented, including a brief introduction
to HDL's and an overview of the software tools used
throughout the design process. These tools make it
possible now for a designer to complete a design in a
relative short period of time. In-depth knowledge of
computer architecture, VLSI fabrication, electronic
circuits and integrated circuit design is not
fundamental to accomplish a task that a few years ago
would have required a large team of specialized experts
in many fields. This may appeal to researchers from a
wide background of knowledge, including computer
scientists, mathematicians, and psychologists
experimenting with learning algorithms. It is only in a
hardware implementation of artificial neural network
learning algorithms that the true parallel nature of
these architectures could be fully tested. Most of the
applications of neural networks are basically software
simulations of the algorithms run on a single CPU
executing sequential simulations of a parallel, richly
interconnected architecture. This dissertation describes
a methodology whereby a researcher experimenting with a
known or new learning algorithm will be able to test it
as it was intentionally designed for, on a parallel
hardware architecture.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  3936 </NUMBER>
<ORDER>   AAI9623215 </ORDER>
<TITLE> A DISTRIBUTED ARTIFICIAL INTELLIGENCE BASED SYSTEM FOR MANUFACTURING SYSTEM CONTROL IN SURFACE MOUNT PWB ASSEMBLY  </TITLE>
<AUTHOR> SHIH, WURONG </AUTHOR>
<YEAR> 1996 </YEAR>
<INSTITUTION> STATE UNIVERSITY OF NEW YORK AT BINGHAMTON; 0792 </INSTITUTION>
<DESCRIPTORS> ENGINEERING, INDUSTRIAL; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> K. SRIHARI </ADVISER>
<CLASSIFICATIONS> EXPERT SYSTEMS </CLASSIFICATIONS>
<ABSTRACT>
Surface mount Printed Wiring Board (PWB) assembly
requires a variety of assembly processes and automated
machinery to manufacture a range of PWB types.
Throughput in PWB assembly can be improved by
effectively exploiting the utilization and integration
of the assembly equipment and processes. The global
objective of this research was to exploit the
integration and coordination that is possible in a
surface mount PWB assembly facility through the use of
DAI technology. The developed DAI prototype system helps
to provide real-time responses to manufacturing related
problems. This DAI based system allows for the design
and implementation of an efficient mechanism to deal
with dynamic production and process planning for PWB
assembly.
DAI technology in the manufacturing domain, especially
in the field of surface mount technology, has not been
widely explored. This research, which focuses on a DAI
framework to solve production planning problems by using
multiple expert systems, takes the first step in this
direction. This system is unique as it not only utilizes
the data transmission techniques existing in the
traditional distributed manufacturing systems approach
but also incorporates multiple knowledge based systems
that work together to solve problems in the domain of
interest.
The prototype DAI system utilizes a group of problem
solvers (intelligent agents) to form a problem solving
team which implements dynamic production planning and
production control in the problem domain. This prototype
system was developed and implemented on a Local Area
Network (LAN) where Personal Computers (PCS) are
connected using bus topology. Each PC is considered as
an intelligent agent in the DAI system. The DAI system
was developed using Object Oriented Programming (OOP)
concept which consider each intelligent agent to be an
object in the software. The overall implementation of
the system was then achieved by the manipulation of the
individual objects/agents. This design concept allows
further enhancement of the system by adding new objects
(agents) to the system. An OOP development tool, Borland
C++, was used for encoding all the reasoning,
calculation, and communication processes required by the
DAI system. This development tool incorporates the
Microsoft Windows graphical user interface, thus
providing a user friendly environment.
The prototype system consists of six intelligent agents
which are used to implement the dynamic production
planning task. The planning task is divided into sub-
tasks which can be solved by the individual intelligent
agents with respect to their knowledge domains. The
communication and cooperation between the intelligent
agents is achieved by exchanging the messages and
information within the blackboard communication
framework. To resolve the conflict between various
knowledge domains of the intelligent agents, a fuzzy
coordination technique was used to negotiate the various
solutions generated by the intelligent agents. This
distributed processing capability allows intelligent
agents to solve problems independently and concurrently,
simplifying complex problems and providing instant
decision support. (Abstract shortened by UMI.)
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  3937 </NUMBER>
<ORDER>   AAGC564551 </ORDER>
<TITLE> COMPUTER-ASSISTED GENERATION OF PARAMETERS FOR RESISTANCE SPOT WELDING  </TITLE>
<AUTHOR> GUENDOUZE, CHEIKH </AUTHOR>
<YEAR> 1996 </YEAR>
<INSTITUTION> UNIVERSITY OF NOTTINGHAM (UNITED KINGDOM); 0616 </INSTITUTION>
<DESCRIPTORS> ENGINEERING, INDUSTRIAL; ARTIFICIAL INTELLIGENCE NOTTINGHAM, UNITED KINGDOM  N67 2RD </DESCRIPTORS>
<ADVISER> NIL </ADVISER>
<CLASSIFICATIONS> EXPERT SYSTEM </CLASSIFICATIONS>
<ABSTRACT>
The ultimate goal of today's manufacturing research is
to achieve fully integrated manufacturing systems. This
goal can only be realized with the integration of
automated process planning systems. The application of
intelligent computer systems, such as expert systems, to
process planning is regarded as one of the principal
means to make possible complete integration of design
and manufacture.
In resistance spot welding, the quality of the weld is
closely linked to the parameters adopted in the welding
process plan. Therefore, the generation of welding
process plans based on optimized welding conditions will
indeed lead to higher quality weld. Besides, incorrect
selection of welding parameters in resistance spot
welding could lead to catastrophic failure of the weld
joints. Therefore, there is a need for rapid and
accurate guidance in selecting welding parameters.
The aim of this present research is two-fold. Firstly,
the development of a one-dimensional numerical heat
transfer model that assists the welding engineer to
obtain the optimum welding conditions which in turn,
lead to higher quality welds. The model is validated
against an experimental work which was carried out in a
local company, as well as against a simulated model
using a heat flow simulated package (FLUENT).
Secondly, the development of a prototype PC-based expert
system, which interfaces with the external numerical
program. The system is called Computer-Assisted Welding
Procedure (CAWP); it is built using Xi Plus expert
system shell. The fully integrated system, is capable of
automating the process of generating welding procedures
and hence contribute to the automated process planning.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  3938 </NUMBER>
<ORDER>   AAI9623215 </ORDER>
<TITLE> A DISTRIBUTED ARTIFICIAL INTELLIGENCE BASED SYSTEM FOR MANUFACTURING SYSTEM CONTROL IN SURFACE MOUNT PWB ASSEMBLY  </TITLE>
<AUTHOR> SHIH, WURONG </AUTHOR>
<YEAR> 1996 </YEAR>
<INSTITUTION> STATE UNIVERSITY OF NEW YORK AT BINGHAMTON; 0792 </INSTITUTION>
<DESCRIPTORS> ENGINEERING, INDUSTRIAL; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> K. SRIHARI </ADVISER>
<CLASSIFICATIONS> EXPERT SYSTEMS </CLASSIFICATIONS>
<ABSTRACT>
Surface mount Printed Wiring Board (PWB) assembly
requires a variety of assembly processes and automated
machinery to manufacture a range of PWB types.
Throughput in PWB assembly can be improved by
effectively exploiting the utilization and integration
of the assembly equipment and processes. The global
objective of this research was to exploit the
integration and coordination that is possible in a
surface mount PWB assembly facility through the use of
DAI technology. The developed DAI prototype system helps
to provide real-time responses to manufacturing related
problems. This DAI based system allows for the design
and implementation of an efficient mechanism to deal
with dynamic production and process planning for PWB
assembly.
DAI technology in the manufacturing domain, especially
in the field of surface mount technology, has not been
widely explored. This research, which focuses on a DAI
framework to solve production planning problems by using
multiple expert systems, takes the first step in this
direction. This system is unique as it not only utilizes
the data transmission techniques existing in the
traditional distributed manufacturing systems approach
but also incorporates multiple knowledge based systems
that work together to solve problems in the domain of
interest.
The prototype DAI system utilizes a group of problem
solvers (intelligent agents) to form a problem solving
team which implements dynamic production planning and
production control in the problem domain. This prototype
system was developed and implemented on a Local Area
Network (LAN) where Personal Computers (PCS) are
connected using bus topology. Each PC is considered as
an intelligent agent in the DAI system. The DAI system
was developed using Object Oriented Programming (OOP)
concept which consider each intelligent agent to be an
object in the software. The overall implementation of
the system was then achieved by the manipulation of the
individual objects/agents. This design concept allows
further enhancement of the system by adding new objects
(agents) to the system. An OOP development tool, Borland
C++, was used for encoding all the reasoning,
calculation, and communication processes required by the
DAI system. This development tool incorporates the
Microsoft Windows graphical user interface, thus
providing a user friendly environment.
The prototype system consists of six intelligent agents
which are used to implement the dynamic production
planning task. The planning task is divided into sub-
tasks which can be solved by the individual intelligent
agents with respect to their knowledge domains. The
communication and cooperation between the intelligent
agents is achieved by exchanging the messages and
information within the blackboard communication
framework. To resolve the conflict between various
knowledge domains of the intelligent agents, a fuzzy
coordination technique was used to negotiate the various
solutions generated by the intelligent agents. This
distributed processing capability allows intelligent
agents to solve problems independently and concurrently,
simplifying complex problems and providing instant
decision support. (Abstract shortened by UMI.)
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  3939 </NUMBER>
<ORDER>   AAI9622330 </ORDER>
<TITLE> INTROSPECTIVE MULTISTRATEGY LEARNING: CONSTRUCTING A LEARNING STRATEGY UNDER REASONING FAILURE </TITLE>
<AUTHOR> COX, MICHAEL THOMAS </AUTHOR>
<YEAR> 1996 </YEAR>
<INSTITUTION> GEORGIA INSTITUTE OF TECHNOLOGY; 0078 </INSTITUTION>
<DESCRIPTORS> COMPUTER SCIENCE; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> ASHWIN RAM </ADVISER>
<CLASSIFICATIONS> MACHINE LEARNING, PROBLEM SOLVING </CLASSIFICATIONS>
<ABSTRACT>
The thesis put forth by this dissertation is that
introspective analyses facilitate the construction of
learning strategies. Furthermore, learning is much like
nonlinear planning and problem solving. Like problem
solving, it can be specified by a set of explicit
learning goals (i.e., desired changes to the reasoner's
knowledge); these goals can be achieved by constructing
a plan from a set of operators (the learning algorithms)
that execute in a knowledge space. However, in order to
specify learning goals and to avoid negative
interactions between operators, a reasoner requires a
model of its reasoning processes and knowledge. With
such a model, the reasoner can declaratively represent
the events and causal relations of its mental world in
the same manner that it represents events and relations
in the physical world. This representation enables
introspective self-examination, which contributes to
learning by providing a basis for identifying what needs
to be learned when reasoning fails. A multistrategy
system possessing several learning algorithms can decide
what to learn, and which algorithm(s) to apply, by
analyzing the model of its reasoning. This introspective
analysis therefore allows the learner to understand its
reasoning failures, to determine the causes of the
failures, to identify needed knowledge repairs to avoid
such failures in the future, and to build a learning
strategy (plan). Thus, the research goal is to develop
both a content theory and a process theory of
introspective multistrategy learning and to establish
the conditions under which such an approach is fruitful.
Empirical experiments provide results that support the
claims herein. The theory was implemented in a
computational model called Meta-AQUA that attempts to
understand simple stories. The system uses case-based
reasoning to explain reasoning failures and to generate
sets of learning goals, and it uses a standard non-
linear planner to achieve these goals. Evaluating Meta-
AQUA with and without learning goals generated results
indicating that computational introspection facilitates
the learning process. In particular, the results lead to
the conclusion that the stage that posts learning goals
is a necessary stage if negative interactions between
learning methods are to be avoided and if learning is to
remain effective.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  3940 </NUMBER>
<ORDER>   AAI9622245 </ORDER>
<TITLE> MONOCHROME AND MULTICHROME IMAGE PROCESSING: APPLICATION TO COMMUNICATIONS AND BIOMEDICINE </TITLE>
<AUTHOR> LI, HUAI DONG </AUTHOR>
<YEAR> 1996 </YEAR>
<INSTITUTION> UNIVERSITY OF SOUTH FLORIDA; 0206 </INSTITUTION>
<DESCRIPTORS> ENGINEERING, ELECTRONICS AND ELECTRICAL; ARTIFICIAL INTELLIGENCE; ENGINEERING, BIOMEDICAL; HEALTH SCIENCES, RADIOLOGY </DESCRIPTORS>
<ADVISER> VIJAY K. JAIN </ADVISER>
<CLASSIFICATIONS> NEURAL NETWORKS, ARTIFICIAL INTELLIGENCE </CLASSIFICATIONS>
<ABSTRACT>
Advanced techniques are developed for (a) low bit rate
coding of monochrome and multichrome images, (b) neural
network based restoration for nuclear medicine images,
and (c) automated analysis of mammograms. For low bit
rate coding, an optimal technique is developed for the
design of Quadrature Mirror Filters used in the subband
analysis/synthesis filterbanks. The flexibility of this
technique coupled with the superior performance of the
resulting filters in subband coding makes this a
valuable tool in the field of signal and image
processing. Further, a new approach for subband coding
of images, based on the recent vector subband and
entropy constrained vector quantization (ECVQ) together
with a new concept, namely an activity map, is proposed.
Application to both monochrome and multichrome (color)
images indicates its superiority in bit rate reduction
over other contemporary techniques.
Two neural network (NN) based image restoration methods
are developed and tested on planar gamma camera images
of pure $beta$-emitting radionuclides used in
radioimmunotheraphy, resulting in smoother images with
regions of interest and source boundaries better
defined. Finally, a technique for detection of tumors in
digital mammograms is developed. Segmentation is
performed by the modified Markov random field model-
based method, followed by a fuzzy binary decision tree
classification. The method could be used in a breast-
screening environment for near real-time detection of
suspicious area, thus assisting the radiologist in the
early diagnosis of cancer.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  3941 </NUMBER>
<ORDER>   AAI9621711 </ORDER>
<TITLE> A COMPUTATIONAL MODEL OF THE CORTICAL MECHANISMS INVOLVED IN PRIMATE GRASPING </TITLE>
<AUTHOR> FAGG, ANDREW HOWARD </AUTHOR>
<YEAR> 1996 </YEAR>
<INSTITUTION> UNIVERSITY OF SOUTHERN CALIFORNIA; 0208 </INSTITUTION>
<DESCRIPTORS> COMPUTER SCIENCE; BIOLOGY, NEUROSCIENCE; PSYCHOLOGY, PHYSIOLOGICAL; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> MICHAEL A. ARBIB </ADVISER>
<CLASSIFICATIONS> COMPUTATIONAL NEUROSCIENCE </CLASSIFICATIONS>
<ABSTRACT>
The act of reaching out, grasping, and manipulating an
object involves the integration of information from a
variety of sources--from vision of the object of
interest, to task requirements, to tactile and
proprioceptive information as the grasp is executed. In
this thesis, we investigate the cortical mechanisms
involved in (1) the translation of a visual description
of an object and a representation of the task into an
appropriate hand configuration, and (2) the unfolding of
this description in time in order to execute the
preshape, enclose, grasp, and ungrasp phases of
movement. On the basis of behavioral, cell recording,
and anatomical data from human and monkey, a
computational model of the grasping process is proposed.
This model focuses on the roles of the intra-parietal
areas (AIP, PIP, and VIP), inferior premotor cortex (F4
and F5), pre-SMA (F6), frontal cortex (area 46),
inferiotemporal cortex (IT), and the secondary
somatosensory cortex (SII).
In the model, AIP serves a dual role of first computing
a set of affordances that are appropriate for the object
being attended, and then maintaining an active memory of
the single affordance as the corresponding grasp is
executed. F5 integrates visual, task and memory
information in order to select one of the several
possible grasps. This brain region then drives the high-
level execution of the grasp and monitors its
progression. Based upon the hypothesized computational
roles of AIP and F5, the model make several key
predictions about the encoding of grasp and object
information at both the single unit and population
levels.
In addition, we present results of a PET (positron
emission tomography) study that (1) compares brain
activity during the performance of the precision and
power grasps, and (2) examines the brain regions
responsible for processing an abstract instruction
stimulus. Through a technique referred to as Synthetic
PET Imaging, we are able to compare the human PET
results to the global behavior of the model. We show
that this technique can also be used to further
constrain the model structure.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  3942 </NUMBER>
<ORDER>   AAI9621558 </ORDER>
<TITLE> STUDIES ON NONLINEAR ACTIVITY AND CROSS-ENTROPY CONSIDERATIONS IN NEURAL NETWORKS </TITLE>
<AUTHOR> ABUSALAH, SALAHALDDIN TAWFIQ </AUTHOR>
<YEAR> 1996 </YEAR>
<INSTITUTION> FLORIDA ATLANTIC UNIVERSITY; 0119 </INSTITUTION>
<DESCRIPTORS> ENGINEERING, ELECTRONICS AND ELECTRICAL; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> PERAMBUR S. NEELAKANTA </ADVISER>
<CLASSIFICATIONS> NIL </CLASSIFICATIONS>
<ABSTRACT>
The objectives of this research as deliberated in this
dissertation are two-folded: (i) To study the nonlinear
activity in the neural complex (real and artificial) and
(ii) to analyze the learning processe(s) pertinent to an
artificial neural network in the information-theoretic
plane using cross-entropy error-metrics.
The research efforts envisaged enclave the following
specific tasks: (i) Obtaining a general solution for the
Bernoulli-Riccati equation to represent a single
parameter family of S-shaped (sigmoidal) curves
depicting the nonlinear activity in the neural network.
(ii) Analysis of the logistic growth of output versus
input values in the neural complex (real and artificial)
under the consideration that the boundaries of the sets
constituting the input and output entities are crisp
and/or fuzzy. (iii) Construction of a set of cross-
entropy error-metrics (known as Csiszar's measures)
deduced in terms of the parameters pertinent to a
perceptron topology and elucidation of their relative
effectiveness in training the network optimally towards
convergence. (iv) Presenting the methods of symmetrizing
and balancing the aforesaid error-entropy measures (in
the information-theoretic plane) so as to make them
usable as error-metrics in the test domain. (v)
Description and analysis of the dynamics of neural
learning process in the information-theoretic plane for
both crisp and fuzzy attributes of input values.
Relevant to these topics portraying the studies on
nonlinear activity and cross-entropy considerations vis-
a-vis neural networks, newer and/or exploratory
inferences are made, logical conclusions are enumerated
and relative discussions are presented along with the
scope for future research to be pursued.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  3943 </NUMBER>
<ORDER>   AAI9620979 </ORDER>
<TITLE> INVARIANCE TRANSFORMATIONS FOR PROCESSING NDE SIGNALS </TITLE>
<AUTHOR> MANDAYAM, SHREEKANTH AMMANJI </AUTHOR>
<YEAR> 1996 </YEAR>
<INSTITUTION> IOWA STATE UNIVERSITY; 0097 </INSTITUTION>
<DESCRIPTORS> ENGINEERING, ELECTRONICS AND ELECTRICAL; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> LALITA UDPA </ADVISER>
<CLASSIFICATIONS> NONDESTRUCTIVE TESTING, PATTERN RECOGNITION, WAVELETS, ARTIFICIAL INTELLIGENCE </CLASSIFICATIONS>
<ABSTRACT>
The ultimate objective in nondestructive evaluation
(NDE) is the characterization of materials, on the basis
of information in the response from energy/material
interactions. This is commonly referred to as the
"inverse problem." Inverse problems are in general ill-
posed and full analytical solutions to these problems
are seldom tractable. Pragmatic approaches for solving
them employ a constrained search technique by limiting
the space of all possible solutions. A more modest goal
is therefore to use the received signal for
characterizing defects in objects in terms of the
location, size and shape. However, the NDE signal
received by the sensors is influenced not only by the
defect, but also by the operational parameters
associated with the experiment. This dissertation deals
with the subject of invariant pattern recognition
techniques that render NDE signals insensitive to
operational variables, while at the same time, preserve
or enhance defect related information. Such techniques
are comprised of invariance transformations that operate
on the raw signals prior to interpretation using
subsequent defect characterization schemes. Invariance
transformations are studied in the context of the
magnetostatic flux leakage (MFL) inspection technique,
which is the method of choice for inspecting natural gas
transmission pipelines buried underground.
The magnetic flux leakage signal received by the
scanning device is very sensitive to a number of
operational parameters. Factors that have a major impact
on the signal include those caused by variations in the
permeability of the pipe-wall material and the velocity
of the inspection tool. This study describes novel
approaches to compensate for the effects of these
variables.
Two types of invariance schemes, feature selection and
signal compensation, are studied. In the feature
selection approach, the invariance transformation is
recast as a problem in interpolation of scattered, multi-
dimensional data. A variety of interpolation techniques
are explored, the most powerful among them being feed-
forward neural networks. The second parametric variation
is compensated by using restoration filters. The filter
kernels are derived using a constrained, stochastic
least square optimization technique or by adaptive
methods. Both linear and non-linear filters are studied
as tools for signal compensation.
Results showing the successful application of these
invariance transformations to real and simulated MFL
data are presented.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  3944 </NUMBER>
<ORDER>   AAI0577170 </ORDER>
<TITLE> VISUAL MAP-MAKING AND GUIDED REINFORCEMENT LEARNING FOR MOBILE ROBOT NAVIGATION: A NEUROCOMPUTATIONAL APPROACH </TITLE>
<AUTHOR> BACHELDER, IVAN ANDREW </AUTHOR>
<YEAR> 1996 </YEAR>
<INSTITUTION> MASSACHUSETTS INSTITUTE OF TECHNOLOGY; 0753 </INSTITUTION>
<DESCRIPTORS> COMPUTER SCIENCE; ENGINEERING, ELECTRONICS AND ELECTRICAL; BIOLOGY, NEUROSCIENCE; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> ALLEN M. WAXMAN; NATHANIEL I. DURLACH </ADVISER>
<CLASSIFICATIONS> COMPUTATIONAL NEUROSCIENCE, COMPUTER VISION </CLASSIFICATIONS>
<ABSTRACT>
A mobile robot that quickly constructs and adapts an
environment map from visual input, and uses this map to
evaluate the utility of places and routes from rewards
and penalties received over time, offers distinct
advantages for navigation. It can not only recognize its
current place and predict the outcome of locomotive
actions, but also learn to avoid penalizing, and favor
rewarding, places and actions. A map and an associated
evaluation constitute a navigation strategy, which
provides a substrate for dynamically planning safe,
efficient routes to desirable places, or for generating
behavioral policies.
This thesis develops a neurocomputational sub-system for
learning navigation strategies within 3D environments
defined by spatially distributed sets of visual
landmarks. The development exemplifies a cognitivist
emulation of cognitive mapping and reinforcement
learning in the rat hippocampus. The map-making
component, inspired by analogy between learning 3D
objects and environment layouts, forms maps similar to
aspect graphs using hierarchical, relational, view-based
learning principals. It comprises two architectures. The
first performs unsupervised place (local region)
learning by combining "What" with "Where", namely
through conjunctions of landmark identity, pose, and
egocentric gaze direction within local, restricted views
of the environment. The second associatively learns
action consequences by incorporating "When", namely
through conjunctions of learned places and coarsely-
coded motions. The map-evaluation component of the sub-
system consists of a reinforcement learning
architecture, which associatively evaluates the utility
of each place and action in the learned map. Together,
the map and an evaluation constitute a navigation
strategy reminiscent of a partially observable Markov
decision process, and provide a substrate for intra-
place localization, place prediction, environment
recognition, route planning, and exploration.
The proposed sub-system and supporting sub-systems for
featural grouping, gaze control, object vision, and path
planning constitute a fully integrated navigation
system. Through a framework called teletraining, wherein
an operator selectively guides the exploratory behavior
of the robot and issues reinforcement, this system may
be trained in an entirely unsupervised fashion to a
level of competence appropriate for supervisory control.
Results from implementing most of these sub-systems on
the mobile robot called MAVIN (the Mobile Adaptive
VIsual Navigator) demosntrate the potential for these
capabilities. (Copies available exclusively from MIT
Libraries, Rm. 14-0551, Cambridge, MA 02139-4307. Ph.
617-253-5668; Fax 617-253-1690.)
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  3945 </NUMBER>
<ORDER>   AAI9623908 </ORDER>
<TITLE> COMPLEX GROUP DECISION-MAKING: A PSYCHOMETRIC/ARTIFICIAL INTELLIGENCE APPROACH </TITLE>
<AUTHOR> EASLEY, ROBERT FUMIO </AUTHOR>
<YEAR> 1996 </YEAR>
<INSTITUTION> INDIANA UNIVERSITY; 0093 </INSTITUTION>
<DESCRIPTORS> BUSINESS ADMINISTRATION, MANAGEMENT; PSYCHOLOGY, SOCIAL </DESCRIPTORS>
<ADVISER> NIL </ADVISER>
<CLASSIFICATIONS> DECISION SUPPORT </CLASSIFICATIONS>
<ABSTRACT>
Groups often face complex decisions: decisions in which
the decision alternative are not clearly defined and the
criteria for choosing an alternative are subject to
dispute within the group. The objective of the
dissertation is to develop and evaluate a Group Decision
Support System (GDSS) which will allow decision makers
to visualize their decision problem in a probabilistic
geometric space. The geometric representations are
developed from probabilistic models of preference
formation and choice in the psychometric literature.
The developmental focus of the dissertation involves
overcoming obstacles to the real-time implementation of
the GDSS. This requires developing a method to rapidly
estimate model parameters by solving a global
optimization problem. Two approaches are developed for
evaluating the probability density functions on which
the optimization function is based--a non-parametric
kernel density estimation method and an artificial
neural network method. Genetic search procedures and
polar coordinate representation are also evaluated as
methods for improving the quality and efficiency of the
optimization process.
The evaluation focus of the dissertation addresses the
efficacy of the methods developed, and the question of
whether the geometric representation in fact does
contribute to the group decision process. Preliminary
research is presented which demonstrates that geometric
representations of this type can help groups better
understand their perception of the decisions they face.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  3946 </NUMBER>
<ORDER>   AAI9623042 </ORDER>
<TITLE> THE APPLICATION OF NEURAL NETWORKS TO PRODUCTION PROCESS CONTROL  </TITLE>
<AUTHOR> HAMBURG, JAMES HENRY </AUTHOR>
<YEAR> 1996 </YEAR>
<INSTITUTION> KENT STATE UNIVERSITY; 0101 </INSTITUTION>
<DESCRIPTORS> BUSINESS ADMINISTRATION, MANAGEMENT; ENGINEERING, INDUSTRIAL; ENGINEERING, NUCLEAR; ARTIFICIAL INTELLIGENCE; ENERGY; OPERATIONS RESEARCH </DESCRIPTORS>
<ADVISER> DAVID E. BOOTH; G. JAY WEINROTH </ADVISER>
<CLASSIFICATIONS> NUCLEAR INDUSTRY </CLASSIFICATIONS>
<ABSTRACT>
The goal of this dissertation was to develop a neural
network that can be used to control real-time production
processes. In production and nuclear processes, the
monitoring of product quality and the safeguarding of
materials are crucial due to today's business climate
and world events. Complexities in dealing with these two
aspects arise because of observation interdependency and
the influence of process disturbances, i.e. outliers.
Unfortunately, the independent and identically
distributed assumption of traditional control chart
methods isn't always applicable. Therefore, the
importance of this research in achieving its goal lies
in its ability to apply the neural network algorithm
with simulation approach enhancement to various process
control applications especially those which are
autocorrelated.
In achieving this goal certain objectives were met. The
first objective was to select an appropriate neural
network architecture for this research. The second
objective was to investigate the neural network's
ability to interpret control chart data. The third
objective was to determine the neural network's ability
to detect process disturbances, i.e. outliers. The
fourth objective was to compare the neural network
method against other process control methods based on
the same process data sets. The results of meeting these
objectives indicate the strong potential of implementing
the neural network algorithm with the simulation
approach enhancement to real-time on-line applications.
Nuclear industry applications were first examined in the
research because it is of critical importance to monitor
and safeguard nuclear materials. In Scientific
American's January 1996 issue, the cover story indicated
that approximately two hundred instances of smuggling
nuclear materials out of the former Soviet Union have
occurred. The actual data sets chosen for this research
came from a study at the AGNS Barnwell Nuclear Fuels
plant and a report done by the Energy Research and
Development Administration. The neural network algorithm
with the simulation approach enhancement was applied to
these data sets. The results were compared against the
results of other control methods (Joint Estimation, Data
Bounding, and Polynomial Smoothing) based on these data
sets. The neural network algorithm with the simulation
approach enhancement was found to be equivalent or
better than current methods in the detection of outliers
and the recognition of terminal points.
Production process applications were next reviewed. The
actual data sets chosen for this section of the research
came from a process of dyeing woolen yarn, a process in
which pump bore holes are cut into automobile diesel
engine blocks, a continuous sheet-like process, and a
transmission parts manufacturing process. The neural
network method with the simulation approach enhancement
was applied to these data sets and the results were
compared against the results of the other methods also
applied to these data sets. Again, the neural network
algorithm with the simulation approach enhancement was
found to be equivalent or better than current methods in
the detection of outliers and the recognition of
terminal points. (Abstract shortened by UMI.)
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  3947 </NUMBER>
<ORDER>   AAI9622265 </ORDER>
<TITLE> ANALYSIS OF ERRORS INVOLVING FRACTIONS MADE BY MIDDLE SCHOOL, HIGH SCHOOL, AND COLLEGE STUDENTS FOR PURPOSES OF DEVELOPING ELEMENTS OF DIAGNOSTIC MODULES FOR INTELLIGENT TUTORING SYSTEMS </TITLE>
<AUTHOR> SOASH, DON EUGENE </AUTHOR>
<YEAR> 1996 </YEAR>
<INSTITUTION> UNIVERSITY OF SOUTH FLORIDA; 0206 </INSTITUTION>
<DESCRIPTORS> EDUCATION, MATHEMATICS; EDUCATION, TECHNOLOGY; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> ANDRIA TROUTMAN </ADVISER>
<CLASSIFICATIONS> NIL </CLASSIFICATIONS>
<ABSTRACT>
Many studies identify errors students make when dealing
with rational numbers in fraction form. None have
attempted to identify concepts misunderstood or unknown
to students that contribute to the errors. Curriculum
materials, whether manual or software oriented, were
based upon sequentially arranging skills by order of
difficulty. Remediation of frequently occurring errors
treated the symptoms rather than the cause of the
mistakes.
The purpose of this study was to identify and organize a
set of key concepts for rational numbers in order to
construct operational statements that could be used for
the development of the diagnostic module of an
intelligent tutoring system (ITS). Three hundred seventy
students at the middle school, high school, and junior
college levels completed the exercise sets. Expert
judges organized errors into distinct conceptually based
classes or "key" concepts. The error class/key concept
model is an alternative to the traditional model that is
based on an intuitive logical sequence of objectives
generally derived from algorithmic procedures.
Significant correlations among error classes were used
to identify any relationships existing between key
concepts. These data were used to develop a set of
operational statements that could be used for building
an inference engine in an ITS for diagnosing levels of
student performance with respect to related key concepts
in order to plan or deliver prescriptive instruction.
The results of this study could be useful in
constructing computerized tutorials on performing
mathematical operations using rational numbers in
fraction form. Its methods may also be used to develop
error profiles for other mathematics objectives. The
ways in which error profiles and error frequencies can
be modified by particular types of instruction also can
be used to assess their effectiveness when introducing
or remediating rational number skills and operations.
The study also provides a foundation for re-evaluating
teaching practices and the structure of textbooks about
concepts and operations involving rational numbers in
fraction form.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  3948 </NUMBER>
<ORDER>   AAGC547485 </ORDER>
<TITLE> BATCH SCHEDULING WITHIN THE CONTEXT OF INTELLIGENT SUPERVISORY PROCESS CONTROL </TITLE>
<AUTHOR> TERPSTRA, VICTOR JAN </AUTHOR>
<YEAR> 1996 </YEAR>
<INSTITUTION> TECHNISCHE UNIVERSITEIT TE DELFT (THE NETHERLANDS); 0951 </INSTITUTION>
<DESCRIPTORS> ENGINEERING, INDUSTRIAL; OPERATIONS RESEARCH </DESCRIPTORS>
<ADVISER> NIL </ADVISER>
<CLASSIFICATIONS> INTELLIGENT CONTROL, SCHEDULING </CLASSIFICATIONS>
<ABSTRACT>
Scheduling is about profit. It is concerned with the
optimal use of a production facility.
The current-day process industry faces the necessity for
a continuous increase in productivity to remain
competitive. Simultaneously, there is an increased
market demand for more flexibility, which implies the
need for a wide variety of products to be produced in
small amounts, short and guaranteed delivery times (just-
in-time production), fast introduction of new products
and frequent change of production goals. For the process
industry, this implies an increased interest in batch-
wise production.
In general, the control of a production facility can be
viewed as a hierarchy of control problems, ranging from
low-level, direct control up to logistics and corporate
management. We aim at plant-wide control. At this level,
plants are viewed as a collection of units,
interconnected via transportation media (e.g. pipes).
Scheduling problems arise in all these structures where
a set of activities has to be processed by a limited
number of resources. This thesis focuses on batch or
mixed-batch/continuous plants and thus on batch
scheduling as a high-level control task.
Scheduling belongs to the set of combinatorial
optimization problems that are infamous for their huge
complexity. It is shown that the complexity of
combinatorial optimization problem is related to
knowledge about the problem that is available. We
propose to tackle the complexity by exploiting three
types of knowledge. First, mathematical and AI
(artificial intelligence) techniques using 'hard' models
of the plant. Second, AI techniques exploiting uncertain
knowledge in terms of heuristics and preferences. Third,
man-machine interfacing to incorporate on-line user
knowledge and insight. In order to fuse them into one
system, they have been developed integrally.
This research resulted in a theoretical framework that
views scheduling as a combinatorial optimization
problem, a detailed proposal for an interactive
scheduling tool and a working prototype of a scheduling
tool that particularly aims at solving detailed, short-
term and highly constrained scheduling problems as they
appear in on-line scheduling in the process industry.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  3949 </NUMBER>
<ORDER>   AAI9620598 </ORDER>
<TITLE> LINEAR AND NON-LINEAR PREPROCESSING OF WAVEFRONT SENSOR SLOPE MEASUREMENTS FOR IMPROVED ADAPTIVE OPTICS PERFORMANCE </TITLE>
<AUTHOR> MONTERA, DENNIS ANTHONY </AUTHOR>
<YEAR> 1996 </YEAR>
<INSTITUTION> AIR FORCE INSTITUTE OF TECHNOLOGY; 0002 </INSTITUTION>
<DESCRIPTORS> ENGINEERING, ELECTRONICS AND ELECTRICAL; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> BYRON M. WELSH </ADVISER>
<CLASSIFICATIONS> NEURAL NETWORKS, ARTIFICIAL INTELLIGENCE </CLASSIFICATIONS>
<ABSTRACT>
New methods for preprocessing wavefront sensor (WFS)
slope measurements are presented. Methods are developed
to improve the accuracy of WFS slope measurements, as
well as estimating key atmospheric and system parameters
from the slope signals. Both statistical and artificial
neural network solutions are investigated. Also, new
atmospheric models for generating slope and phase data
with the proper spatial and temporal statistics are
developed. The experiments in improving the accuracy of
WFS slope measurements include reducing the WFS slope
measurement error and compensating for adaptive optics
system time delay through temporal slope prediction. The
experiments in key parameter estimation include
estimating the Fried coherence length, $rsb0$, the wind
speed profile, the strengths of the atmospheric
turbulence layers, and the WFS mean square slope
estimation error. Results of the experiments are used to
make generalized conclusions in several key areas:
first, the types of useful information that can be
extracted from the WFS slope measurements; second, a
comparison of linear or non-linear methods; and third,
the possibility of methods that can be developed which
operate over useful ranges of seeing conditions.
Overall, we find that the WFS slope measurements do
contain useful information which can be extracted
through various techniques. Simple transformations
(either by neural network or statistical solution) on
slope measurements can yield significant improvements is
system accuracy without major changes to the adaptive
optics system. Also, we find that both neural networks
and statistical methods perform well when seeing
conditions are fixed, and that viable solutions can be
developed that operate over broad ranges of seeing
conditions. While developed to operate under variable
seeing conditions, these solutions still provide
significant performance in improving the accuracy of WFS
slope measurements and in estimating key atmospheric and
system parameters. In general, neural networks are much
more robust when operating under variable seeing
conditions than are the statistical solutions.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  3950 </NUMBER>
<ORDER>   AAI9620597 </ORDER>
<TITLE> A GENERIC INTELLIGENT ARCHITECTURE FOR COMPUTER-AIDED TRAINING OF PROCEDURAL KNOWLEDGE </TITLE>
<AUTHOR> KILPATRICK, FREEMAN ALEXANDER, JR. </AUTHOR>
<YEAR> 1996 </YEAR>
<INSTITUTION> AIR FORCE INSTITUTE OF TECHNOLOGY; 0002 </INSTITUTION>
<DESCRIPTORS> ENGINEERING, ELECTRONICS AND ELECTRICAL; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> GREGG H. GUNSCH </ADVISER>
<CLASSIFICATIONS> TUTORING, ARTIFICIAL INTELLIGENCE </CLASSIFICATIONS>
<ABSTRACT>
Intelligent Tutoring System (ITS) development is a
knowledge-intensive task, suffering from the same
knowledge-acquisition bottleneck that plagues most
Artificial Intelligence (AI) systems. This research
presents an architecture that requires knowledge only in
the form of a shallow knowledge base and a simulation to
produce a training system. The knowledge base provides
the basic procedural knowledge while the simulation
provides context. The remainder of the knowledge
required for training is learned through the interaction
of these components in a state-space scenario
exploration process and inductive machine learning.
These knowledge components are used only at the
interface level, allowing the internal representation to
take any form that meets interface requirements. A
prototype of this architecture is implemented as a proof-
of-concept to illustrate the viability of the key
knowledge acquisition techniques.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  3951 </NUMBER>
<ORDER>   AAI9620524 </ORDER>
<TITLE> MEDICAL APPLICATIONS OF ARTIFICIAL NEURAL NETWORKS: CONNECTIONIST MODELS OF SURVIVAL </TITLE>
<AUTHOR> OHNO-MACHADO, LUCILA </AUTHOR>
<YEAR> 1996 </YEAR>
<INSTITUTION> STANFORD UNIVERSITY; 0212 </INSTITUTION>
<DESCRIPTORS> COMPUTER SCIENCE; HEALTH SCIENCES, PUBLIC HEALTH; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> MARK A. MUSEN </ADVISER>
<CLASSIFICATIONS> MACHINE LEARNING, IMMUNE DEFICIENCY </CLASSIFICATIONS>
<ABSTRACT>
Although neural networks have been applied to medical
problems in recent years, their applicability has been
limited for a variety of reasons. One of those barriers
has been the problem of recognizing rare categories. In
this dissertation, I demonstrate, and prove the utility
of, a new method for tackling this problem. In
particular, I have developed a method that allows the
recognition of rare categories with high sensitivity and
specificity, and will show that it is practical and
robust. This method involves the construction of
sequential neural networks.
Rare categories occur and must be learned if practical
application of neural-network technology is to be
achieved. Survival analysis is one area in which this
problem appears. In this work, I test the hypotheses
that (1) sequential systems of neural networks produce
results that are more accurate (in terms of calibration
and resolution) than nonhierarchical neural networks;
and (2) in certain circumstances, sequential neural
networks produce more accurate estimates of survival
time than Cox proportional hazards and logistic
regression models. I use two sets of data to test the
hypotheses: (1) a data set of HIV+ patients (AIDS Time-
Oriented Health Outcome Study--ATHOS data set); and (2)
a data set of patients followed prospectively for the
development of cardiac conditions (Framingham data set).
Using the ATHOS data set, I show that a neural network
model can predict death due to AIDS more accurately than
a Cox proportional hazards model. Furthermore, I show
that a sequential neural network model is more accurate
than a standard neural network model. Using the
Framingham data set, I show that the predictions of
logistic regression and neural networks are not
significantly different, but that any of these models
used sequentially is more accurate than its standard
counterpart.
The sequential use of predictive models for survival
analysis is advantageous because it makes better use of
the available information. It often increases resolution
with no sacrifice of calibration, as I demonstrate in
this study. It also helps to delineate patterns of
disease progression for individuals, rather than for
groups of patients.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  3952 </NUMBER>
<ORDER>   AAI9620509 </ORDER>
<TITLE> SCALED STOCHASTIC METHODS FOR TRAINING NEURAL NETWORKS </TITLE>
<AUTHOR> LEHR, MICHAEL ALAN </AUTHOR>
<YEAR> 1996 </YEAR>
<INSTITUTION> STANFORD UNIVERSITY; 0212 </INSTITUTION>
<DESCRIPTORS> ENGINEERING, ELECTRONICS AND ELECTRICAL; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> BERNARD WIDROW </ADVISER>
<CLASSIFICATIONS> NIL </CLASSIFICATIONS>
<ABSTRACT>
The performance surfaces of large neural networks
contain ravines, "flat spots," non-convex regions, and
other features that make weight optimization difficult.
Although a variety of sophisticated alternatives are
available, the simple on-line backpropagation procedure
remains the most popular method for adapting the weights
of these systems. This approach performs stochastic (or
incremental) steepest descent, and is significantly
hampered by the character of the performance surface.
Backpropagation's principal advantage over alternate
methods rests in its ability to perform an update after
each pattern presentation, while maintaining time and
space demands that grow only linearly with the number of
adaptive weights.
In this dissertation, we explore new stochastic methods
that improve on the learning speed of the
backpropagation algorithm, while retaining its linear
complexity. We begin by examining the convergence
properties of two deterministic steepest descent
methods. Corresponding scaled stochastic algorithms are
then developed from an analysis of the neural network's
Expected Mean Square Error (EMSE) sequence in the
neighborhood of a local minimum of the performance
surface. To maintain stable behavior under broad
conditions, this development uses a general statistical
model for the neural network's instantaneous Hessian
matrix. For theoretical performance comparisons,
however, we require a more specialized statistical
framework. The corresponding analysis helps reveal the
complementary convergence properties of the two updates--
a relationship we exploit by combining the updates to
form a family of dual-update procedures.
Effective methods are established for generating a
slowly varying sequence of search direction vectors and
all required scaling information. The result is a
practical algorithm which performs robustly when the
weight vector of a large neural network is placed at
arbitrary initial positions. The two weight updates are
scaled by parameters computed from recursive estimates
of five scalar sequences: the first and second moments
of the trace of the instantaneous Hessian matrix, the
first and second moments of the instantaneous gradient
vector's projection along the search direction, and the
first moment of the instantaneous Hessian's "projection"
along the same direction.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  3953 </NUMBER>
<ORDER>   AAI9619939 </ORDER>
<TITLE> NEURAL NETWORK MODELING OF UNIPOLAR DEPRESSION: PATTERNS OF RECOVERY AND PREDICTION OF OUTCOME </TITLE>
<AUTHOR> LUCIANO, JOANNE SYLVIA, JR. </AUTHOR>
<YEAR> 1996 </YEAR>
<INSTITUTION> BOSTON UNIVERSITY; 0017 </INSTITUTION>
<DESCRIPTORS> HEALTH SCIENCES, MENTAL HEALTH; BIOLOGY, NEUROSCIENCE; ARTIFICIAL INTELLIGENCE; PSYCHOLOGY, CLINICAL </DESCRIPTORS>
<ADVISER> MICHAEL A. COHEN </ADVISER>
<CLASSIFICATIONS> ARTIFICIAL INTELLIGENCE </CLASSIFICATIONS>
<ABSTRACT>
Neural network methods were used in two studies of
unipolar depression. Study 1 explored the dynamics of
recovery and revealed different clinical symptom
recovery patterns for desipramine (DMI), a tricyclic
antidepressant drug therapy, and cognitive behavioral
therapy (CBT), a psychotherapy. The methods included
statistical tests of patient's response times and
parameter fits based on methods derived from optimal
control theory. Study 2 predicted therapeutic outcome at
highly significant levels ($p <$ 0.005) from pre-
treatment clinical symptoms and compared the performance
of backpropagation, a nonlinear regression technique,
with multiple linear and quadratic regression. The
results of both studies demonstrate the usefulness of
nonlinear methods in clinical depression research.
Study 1. To explore recovery patterns, a linear second
order system and a nonlinear shunting neural network
were used. The linear second order model gave
statistically superior results. We modeled changes in
overall severity (HDRS total) and severity of, and
interactions among, seven symptoms derived from the
Hamilton Depression Rating Scale during the initial six
weeks of treatment in two patient groups. The two groups
were six patients who responded to CBT and six patients
who responded to DMI. There was no difference in
response time for overall severity. In both groups mood
was the first symptom to improve and middle/late sleep
was the last. Symptom improvements clustered differently
by treatment. Mood and cognitions (sad mood, anxious
mood, thoughts of guilt or suicide) improved
significantly earlier ($p <$ 0.05, two-tailed) in CBT
than in DMI.
Study 2. To look for nonlinear predictive relationships
among pre-treatment symptoms, treatment, and outcome,
several backpropagation studies were performed on raw
and transformed data from 99 patients. This study
investigated whether linear and nonlinear methodologies
could reliably predict percent improvement of clinically
depressed individuals exposed to fluoxetine,
desipramine, or cognitive behavioral therapy. The linear
model performed at chance levels with no factor
statistically significant. However, both nonlinear
models, backpropagation and quadratic regression,
predicted outcome at statistically significant levels.
This suggests that symptoms can significantly predict
treatment outcome if nonlinear effects are included.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  3954 </NUMBER>
<ORDER>   AAI9619460 </ORDER>
<TITLE> THREE-DIMENSIONAL RECONSTRUCTION UNDER VARYING CONSTRAINTS ON CAMERA GEOMETRY FOR ROBOTIC NAVIGATION SCENARIOS  </TITLE>
<AUTHOR> ZHANG, ZHONGFEI </AUTHOR>
<YEAR> 1996 </YEAR>
<INSTITUTION> UNIVERSITY OF MASSACHUSETTS; 0118 </INSTITUTION>
<DESCRIPTORS> COMPUTER SCIENCE; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> ALLEN R. HANSON </ADVISER>
<CLASSIFICATIONS> VISUAL SERVOING CONTROL, COMPUTER VISION </CLASSIFICATIONS>
<ABSTRACT>
3D reconstruction is an important research area in
computer vision. With the wide spectrum of camera
geometry constraints, a general solution is still open.
In this dissertation, the topic of 3D reconstruction is
addressed under several special constraints on camera
geometry, and the 3D reconstruction techniques developed
under these constraints have been applied to a robotic
navigation scenario. The robotic navigation problems
addressed include automatic camera calibration, visual
servoing for navigation control, obstacle detection, and
3D model acquisition and extension.
The problem of visual servoing control is investigated
under the assumption of a structured environment where
parallel path boundaries exist. A visual servoing
control algorithm has been developed based on geometric
variables extracted from this structured environment.
This algorithm has been used for both automatic camera
calibration and navigation servoing control. Close to
real time performance is achieved.
The problem of qualitative and quantitative obstacle
detection is addressed with a proposal of three
algorithms. The first two are purely qualitative in the
sense that they only return yes/no answers. The third is
quantitative in that it recovers height information for
all the points in the scene. Three different constraints
on camera geometry are employed. The first algorithm
assumes known relative pose between cameras; the second
algorithm is based on completely unknown camera relative
pose; the third algorithm assumes partial calibration.
Experimental results are presented for real and
simulated data, and the performance of the three
algorithms under different noise levels are compared in
simulation.
Finally the problem of model acquisition and extension
is studied by proposing a 3D reconstruction algorithm
using homography mapping. It is shown that given four
coplanar correspondences, 3D structures can be recovered
up to two solutions and with only one uniform scale
factor, which is the distance from the camera center to
the 3D plane formed by the four 3D points corresponding
to the given four correspondences in the two camera
planes. It is also shown that this algorithm is optimal
in terms of the number of minimum required
correspondences and in terms of the assumption of
internal calibration.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  3955 </NUMBER>
<ORDER>   AAI9619409 </ORDER>
<TITLE> NEW DIGITAL STRUCTURE DESIGNS OF NEURAL NETWORKS AND FILTER BANKS </TITLE>
<AUTHOR> LIU, XIAOZHOU </AUTHOR>
<YEAR> 1996 </YEAR>
<INSTITUTION> UNIVERSITY OF MASSACHUSETTS; 0118 </INSTITUTION>
<DESCRIPTORS> ENGINEERING, ELECTRONICS AND ELECTRICAL; COMPUTER SCIENCE; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> LEWIS E. FRANKS </ADVISER>
<CLASSIFICATIONS> NIL </CLASSIFICATIONS>
<ABSTRACT>
The rapid development of modern industry and technology
has dramatically increased the demands on the signal
information system. The performance of a signal system
is measured by its accuracy, speed and cost for a signal
process. In implementation of a digital system such as a
digital computer or a micro-processor, the basic
computational operations are multiplication, addition
and delay. It is well known that, among these
operations, multiplication is the slowest and the most
complex. Thus, the existence of multipliers in hardware
implementation and multiplications in software coding
are often the bottleneck of an efficient design.
Therefore, it is desired to implement a signal system
which is multiplier-free or multiplier-minimized.
This dissertation studies some structure design for the
Multi-layer Neural Network (MNN) and Cellular Neural
Network (CNN). The designs are based on the Differential
Digital Analyzer (DDA) technique, the CORDIC algorithm
and the Convergence Computation Method (CCM). These
designs have the desired multiplier-free feature and low
complexity and are suitable for VLSI implementation.
Efficient design of the M-channel QMF bank has also been
investigated and proposed in the dissertation. The
design proposed is based on the Interpolated FIR design
approach, in conjunction with a cosine-modulated QMF
bank system. Compared with conventional design approach,
our new design reduces the number of multiplications for
the filter bank and can achieve more than 50% saving of
computation depending on the choice of the interpolation
rate and this computational saving becomes more
significant when the number of channels in a filter bank
is large.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  3956 </NUMBER>
<ORDER>   AAI9619388 </ORDER>
<TITLE> DESIGN-TO-TIME REAL-TIME SCHEDULING </TITLE>
<AUTHOR> GARVEY, ALAN JAMES </AUTHOR>
<YEAR> 1996 </YEAR>
<INSTITUTION> UNIVERSITY OF MASSACHUSETTS; 0118 </INSTITUTION>
<DESCRIPTORS> COMPUTER SCIENCE; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> VICTOR R. LESSER </ADVISER>
<CLASSIFICATIONS> ARTIFICIAL INTELLIGENCE </CLASSIFICATIONS>
<ABSTRACT>
Design-to-time real-time scheduling is an approach to
solving time-sensitive problems where multiple solution
methods are available for many subproblems. The design-
to-time approach involves designing a solution plan
(i.e., an ordered schedule of solution methods)
dynamically at runtime such that the solution plan uses
the time available as productively as possible to try to
maximize solution quality. The problem to be solved is
modeled as a set of interrelated computational tasks,
with alternative ways of accomplishing the overall task.
There is not a single "right" answer, but a range of
possible solution plans of different qualities, where
the overall quality of a problem solution is a function
of the quality of individual subtasks. The act of
scheduling such pre-specified task structures that
contain alternatives requires both deciding "what" to do
and deciding "when" to do it. One major focus of our
design-to-time work is on taking interactions among
subproblems into account when building solution plans,
both "hard" interactions that must be satisfied to find
correct solutions (e.g., hard precedence constraints),
and "soft" interactions that can improve (or hinder)
performance. Another recent focus of our work has been
on adding to the problem model the notion of uncertainty
in the duration and quality of methods, and in the
presence and power of soft interactions. Scheduling with
uncertain information requires additions to the
scheduling algorithm and the monitoring of method
performance to allow dynamic reaction to unexpected
situations.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  3957 </NUMBER>
<ORDER>   AAI9619377 </ORDER>
<TITLE> A GENERALIZABLE ARTIFICIAL INTELLIGENCE MODEL FOR SIMULATING DUCK NEST DEPREDATION IN THE NORTHERN PRAIRIE REGION OF NORTH AMERICA  </TITLE>
<AUTHOR> CARTER, JACOBY </AUTHOR>
<YEAR> 1996 </YEAR>
<INSTITUTION> UNIVERSITY OF MASSACHUSETTS; 0118 </INSTITUTION>
<DESCRIPTORS> AGRICULTURE, FORESTRY AND WILDLIFE; BIOLOGY, ZOOLOGY; BIOLOGY, ECOLOGY; PHYSICAL GEOGRAPHY; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> JOHN T. FINN </ADVISER>
<CLASSIFICATIONS> EXPERT SYSTEMS, VULPES VULPES </CLASSIFICATIONS>
<ABSTRACT>
Nest predation on dabbling duck nests is an important
problem in the prairie pothole region of North Dakota.
There are many factors that contribute to the high
predation rates. One of them is landscape composition
and physiognomy. Many authors have reported that
different landscape attributes such as patch size and
cover density affect predation rates. However, the data
often conflict as to what landscape attributes are
important and when. I created MOAB, a generalizable
model of animal behavior to examine the interaction of
predator foraging behavior and landscape attributes.
MOAB is a spatially explicit individual-based model.
MOAB is generalizable because it uses the artificial
intelligence technology of expert systems to create the
rule sets animals use to determine their behavior. To
change the behavior of a species or create a new species
you change the rules and use the graphical user
interface to change the species parameters. MOAB has
been tested on both the Macintosh and Windows computer
platforms. MOAB can import and export habitat type and
food distribution files.
Of the many nest predators in the prairie pothole
region, red foxes are considered the most damaging. MOAB
was used to simulate red fox nest depredation with a
variety of food densities and distributions and various
habitat configurations. Results of red fox nest
predation revealed the following: (1) Nest predation is
most strongly affected by, and is inversely proportional
to, alternative food density. (2) Nest predation is
inversely proportional to nest density. (3) Patch size
or patches laid out in long habitat strips do not
significantly affect predation. (4) Predation is higher
in predator preferred habitat. (5) Predation rate is
affected by habitat configuration. When habitat is laid
out in such a way as to block animal movement, predation
rates are lower. (6) Animal home range size is affected
by habitat configuration as well as food density. (7)
Observed habitat preference may be affected by food
density. The higher the food density the less habitat
preference is observed.
The expert system approach will be especially useful for
the creation of multispecies models.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  3958 </NUMBER>
<ORDER>   AAI9619372 </ORDER>
<TITLE> A KNOWLEDGE-BASED SYSTEM FOR THE CONCEPTUAL DESIGN OF GAS AND LIQUID SEPARATION SYSTEMS </TITLE>
<AUTHOR> BEILSTEIN, JAMES RALPH, JR. </AUTHOR>
<YEAR> 1996 </YEAR>
<INSTITUTION> UNIVERSITY OF MASSACHUSETTS; 0118 </INSTITUTION>
<DESCRIPTORS> ENGINEERING, CHEMICAL; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> JAMES M. DOUGLAS </ADVISER>
<CLASSIFICATIONS> DISTILLATION, EXPERT SYSTEMS, ARTIFICIAL INTELLIGENCE </CLASSIFICATIONS>
<ABSTRACT>
Most recent research in the synthesis of separation
systems has been focused on the development of more
rigorous procedures for the design and synthesis of
specific unit operations, rather than the synthesis of
these units as a part of the overall flowsheet.
Furthermore, many of the chemical process used in the
production of commodity and specialty chemicals are
characterized by many reaction steps with separations
required between each step. The coupling of the reaction
and separation steps has a significant impact on the
recycle and separation system structures. A completely
integrated hierarchical procedure has been developed for
the conceptual design of vapor-liquid separation systems
found in multiple reaction step processes.
A new decomposition procedure is presented for
determining the general structure of the separation
system for processes involving reactions which occur in
vapor-liquid-liquid-solid phase mixtures. The
interactions of the separation subsystems for; vapor
recovery, solid recovery, and liquid separations are
identified, including process recycles between
subsystems. The vapor recovery system and distillation
sequence are then synthesized, the dominant process
design variables are identified, the size and cost of
the process units are determined, and the economic
potential is calculated. Alternatives can then be
quickly compared and ranked. Design procedures have been
implemented in an expert system environment for the
synthesis of gas membrane, condensation (high pressure
or low temperature), and complex distillation columns
(sidestream, side rectifier, and side stripper columns)
separations.
Finally, a procedure is presented for assessing the
incentive for the combining of distillation systems in
multiple step reaction processes. Dilute mixture
separations generally represent the highest separation
costs in the distillation system. The pooling of plant
distillation separations can lead to better separations
by reducing flow imbalances and dilute mixtures in the
separation system feed.
A hybrid of object-oriented and rule-based techniques
has been used in the development and implementation of
the procedure in PIPII, a computer-aided design tool
which can rapidly generate process flowsheet
alternatives and estimate the optimum range of the
process conditions. The hierarchical nature of the
procedure quickly prunes the number of viable
alternatives which must be examined for a given process.
The procedures, reasoning, and methods are thoroughly
discussed within.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  3959 </NUMBER>
<ORDER>   AAGC546833 </ORDER>
<TITLE> THE DEVELOPMENT AND IMPLEMENTATION OF EXPERT SYSTEMS IN ORGANISATIONS  </TITLE>
<AUTHOR> ASHOURI, FARAHNAZ </AUTHOR>
<YEAR> 1996 </YEAR>
<INSTITUTION> UNIVERSITY OF SOUTHAMPTON (UNITED KINGDOM); 5036 </INSTITUTION>
<DESCRIPTORS> BUSINESS ADMINISTRATION, MANAGEMENT; ARTIFICIAL INTELLIGENCE; ENGINEERING, INDUSTRIAL; ENGINEERING, SYSTEM SCIENCE </DESCRIPTORS>
<ADVISER> NIL </ADVISER>
<CLASSIFICATIONS> PROJECT CONTRACTS </CLASSIFICATIONS>
<ABSTRACT>
Expert Systems are potentially valuable to
organisations, but this potential is not always
realised. Published literature tends to focus on
theoretical and technical issues rather than practical
and implementation related ones. This thesis argues
that, when organisations are considering how to apply
expert systems, practical issues of building and
implementing expert systems need to be considered from
the outset, and insight may be gained by studying the
practical implementation of experts systems; an action
research approach. The literature is examined to assess
how it can inform an expert system practitioner, and
areas in which it fails to do this are identified. A
number of practical aspects of developing expert systems
in organisations are examined. Amongst these are the
possible relationship between expert systems and
organisational structure, and the utilisation of project
contracts for expert system construction. Further
practical issues are examined through the development of
a major expert system in an organisation. The thesis
concludes by presenting a set of guidelines, which would
assist an expert system practitioner.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  3960 </NUMBER>
<ORDER>   AAI9618591 </ORDER>
<TITLE> CONCEPT LEARNING WITH GAZE SELECTED SAMPLE SPACE </TITLE>
<AUTHOR> KERBAUGH MCGRATH, SUSAN P. </AUTHOR>
<YEAR> 1996 </YEAR>
<INSTITUTION> RUTGERS THE STATE U. OF N.J. - NEW BRUNSWICK AND U.M.D.N.J.; 0801 </INSTITUTION>
<DESCRIPTORS> ENGINEERING, BIOMEDICAL; HEALTH SCIENCES, RADIOLOGY; ARTIFICIAL INTELLIGENCE; HEALTH SCIENCES, DENTISTRY </DESCRIPTORS>
<ADVISER> STANLEY M. DUNN </ADVISER>
<CLASSIFICATIONS> NIL </CLASSIFICATIONS>
<ABSTRACT>
This thesis describes an approach for learning visual
concepts using gaze selected sample space. A computer-
based technique for concept learning with
characteristics modeled after the biological visual
processing system is presented. The focus of the study
was to determine if computer-based concept learning
could be accomplished using a subspace of the image
defined by fixation data gathered from experts. The
domain selected for concept learning was dental
radiology. The fixation information was gathered from
expert dental radiologists who viewed images which were
examples of the concepts. The concepts were dental
images which were either normal or contained one of
three different types of periapical disease: widened
periodontal ligament space, destruction of the lamina
dura, or resorption of bone.
The sample space used for concept classification was
determined from areas on which an expert fixated while
examining the image. Features computed for each fixation
site were based on visual feature extraction including
multiscale analysis and edge orientation detection.
Quantized feature values were presented to the
classifier as a property set. The classification
algorithm was based on an indexing and matching scheme
which used a hypothesis generation and confirmation
methods to select the output class. Concepts were
represented internally as a set of property-weight
pairs, where weights indicate the relative importance of
each property for a particular class. During concept
learning, input instances and the correct class name
were provided to the system. After the classifier
determined the output class, learning occurred by
adjustment of the property list and associated weights
for each class.
Experiments were performed using thirty-two images
(eight examples of each concept) and eye position data
from six observers. The analysis of the computer-based
concept learning system performance was accomplished by
comparison with human observer performance. The results
suggest that fixation information can provide a
sufficient sampling of the image for concept learning
and that the computer-based learning system is robust
enough to learn various concept definitions.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  3961 </NUMBER>
<ORDER>   AAI9618586 </ORDER>
<TITLE> REAL-TIME CONTROL OF NONLINEAR DYNAMIC SYSTEMS USING NEURO-FUZZY CONTROLLERS </TITLE>
<AUTHOR> JANA, AMITAVA </AUTHOR>
<YEAR> 1996 </YEAR>
<INSTITUTION> NEW JERSEY INSTITUTE OF TECHNOLOGY; 0152 </INSTITUTION>
<DESCRIPTORS> ENGINEERING, MECHANICAL; ENGINEERING, ELECTRONICS AND ELECTRICAL; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> RAJESH N. DAVE; DAVID M. AUSLANDER </ADVISER>
<CLASSIFICATIONS> INTELLIGENT CONTROL </CLASSIFICATIONS>
<ABSTRACT>
The problem of real time control of a nonlinear dynamic
system using intelligent control techniques is
considered. The current trend is to incorporate neural
networks and fuzzy logic into adaptive control
strategies. The focus of this work is to investigate the
current neuro-fuzzy approaches from literature and adapt
them for a specific application. In order to achieve
this objective, an experimental nonlinear dynamic system
is considered. The motivation for this comes from the
desire to solve practical problems and to create a test-
bed which can be used to test various control
strategies. The nonlinear dynamic system considered here
is an unstable balance beam system that contains two
fluid tanks, one at each end, and the balance is
achieved by pumping the fluid back and forth from the
tanks.
A popular approach, called ANFIS (Adaptive Networks-
based Fuzzy Inference Systems), which combines the
structure of fuzzy logic controllers with the learning
aspects from neural networks is considered as a basis
for developing novel techniques, because it is
considered to be one of the most general framework for
developing adaptive controllers. However, in the
proposed new method, called Generalized Network-based
Fuzzy Inferencing Systems (GeNFIS), more conventional
fuzzy schemes for the consequent part are used instead
of using what is called the Sugeno type rules. Moreover,
in contrast to ANFIS which uses a full set of rules,
GeNFIS uses only a limited number of rules based on
certain expert knowledge. GeNFIS is tested on the
balance beam system, both in a real-time actual
experiment and the simulation, and is found to perform
better than a comparable ANFIS under supervised
learning. Based on these results, several modifications
of GeNFIS are considered, for example, synchronous
defuzzification through triangular as well as bell
shaped membership functions. Another modification
involves simultaneous use of Sugeno type as well as
conventional fuzzy schemes for the consequent part, in
an effort to create a more flexible framework. Results
of testing different versions of GeNFIS on the balance
beam system are presented.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  3962 </NUMBER>
<ORDER>   AAI9618562 </ORDER>
<TITLE> NEURAL NETWORK APPLICATIONS IN BRIDGE MANAGEMENT SYSTEMS </TITLE>
<AUTHOR> WANG, CHIN T. </AUTHOR>
<YEAR> 1996 </YEAR>
<INSTITUTION> RUTGERS THE STATE UNIVERSITY OF NEW JERSEY - NEW BRUNSWICK; 0190 </INSTITUTION>
<DESCRIPTORS> ENGINEERING, CIVIL; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> TREFOR P. WILLIAMS </ADVISER>
<CLASSIFICATIONS> ARTIFICIAL INTELLIGENCE </CLASSIFICATIONS>
<ABSTRACT>
About 42 percent of the bridges on the highway system of
the United States are classified as structurally
deficient or functionally obsolete by the federal
government. Almost half of the bridge inventory was
built before 1940. Maintenance, rehabilitation, and
replacement are in great need. The bridge management
system is implemented to give the optimal resource
allocation in setting priority for preventive and
remedial actions. This study proposes an artificial
intelligence approach to model the deterioration of
bridges. Specifically, neural network models were
created to predict the future condition rating of
bridges.
The research was designed based on the knowledge of the
bridge inventory information and biennial inspection
report of the New York State Department of
Transportation. With the formulation and creation of
neural network models, predictions of bridge component
deterioration were simulated. Furthermore, bridge
information of specific regions was applied to
statistical models from the State Departments of
Transportation of New York and Pennsylvania. Together,
prediction results were compared. As a result of
modeling process and comparison, Neural Networks are
concluded as a simpler and more accurate AI approach for
local governments to study the deterioration process of
bridges in their own jurisdictions. A new deterioration
modeling strategy was also proposed to further take
advantage of the imaging pattern recognition ability of
a neural network system.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  3963 </NUMBER>
<ORDER>   AAI9618536 </ORDER>
<TITLE> STATISTICAL PHYSICS OF VISUAL PERCEPTION </TITLE>
<AUTHOR> KUMARAN, KRISHNAN </AUTHOR>
<YEAR> 1996 </YEAR>
<INSTITUTION> RUTGERS THE STATE UNIVERSITY OF NEW JERSEY - NEW BRUNSWICK; 0190 </INSTITUTION>
<DESCRIPTORS> COMPUTER SCIENCE; BIOLOGY, NEUROSCIENCE; PHYSICS, OPTICS; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> DAVI GEIGER </ADVISER>
<CLASSIFICATIONS> PATTERN RECOGNITION, ARTIFICIAL INTELLIGENCE </CLASSIFICATIONS>
<ABSTRACT>
Human visual perception can be viewed as a neural
information processing task of considerable complexity
and robustness. Like most other brain functions, it
involves a very large number of neurons with complex
interconnections. Statistical physics, which offers an
arsenal of techniques developed to analyze physical
systems with many degrees of freedom, has been
extensively applied to model such complex systems.
In this work, we attempt to study and model the process
of Visual Organization. We propose that this process
involves the representation of image information in
terms of piecewise smooth surfaces. In particular, we
consider the phenomena of illusory surface perception
and reconstruction of partially hidden (occluded)
surfaces, both of which vividly depict such visual
organization. We postulate that, during early vision,
raw optical information obtained from the retinal image
is represented as a field of 'surface-states', which
assign various image locations to surfaces. This
information is initially available only at sparse image
locations, mainly in regions suggesting occlusions.
These regions are usually marked by the occurrence of
features such as junctions, corners and line-endings. We
discuss possible means by which this initial data can be
acquired, and propose a statistical model to reconstruct
a dense field of assignment probabilities from it.
Further, each of these features could be interpreted in
several ways, leading to a large number of possible
visual organizations. Thus, a given image could have
many different interpretations, of which the most likely
one(s) must be inferred. We define an entropy measure to
pick out the favoured image organizations. During this
process, several distinct regions of the image are often
"grouped" together as belonging to the same surface or
object, while in other cases, regions with similar
properties on the image are assigned to different
surfaces or objects. These organizations provide
surfaces whose boundaries correspond to illusory
contours (modal completion) and reconstructions of
partially hidden contours (amodal completion). The model
reproduces various qualitative and quantitative aspects
of visual perception and has been supported by a series
of simulations and experiments.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  3964 </NUMBER>
<ORDER>   AAI9618237 </ORDER>
<TITLE> REINFORCEMENT LEARNING WITH SELECTIVE PERCEPTION AND HIDDEN STATE </TITLE>
<AUTHOR> MCCALLUM, ANDREW KACHITES </AUTHOR>
<YEAR> 1996 </YEAR>
<INSTITUTION> THE UNIVERSITY OF ROCHESTER; 0188 </INSTITUTION>
<DESCRIPTORS> COMPUTER SCIENCE; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> DANA BALLARD </ADVISER>
<CLASSIFICATIONS> NIL </CLASSIFICATIONS>
<ABSTRACT>
Reinforcement learning is a formal framework in which an
agent manipulates its environment through a series of
actions, and in response to each action, receives a
reward value. The agent stores its knowledge about how
to choose reward-maximizing actions as a function that
maps agent internal states to actions.
Agents often struggle with two opposite, yet
intertwined, problems regarding their internal state
space. First, the agent's state space may have "too many
distinctions"--meaning that an abundance of perceptual
data has resulted in a state space so large that it
overwhelms the agent's limited resources for
computation, storage and learning experience. This
problem can often be solved if the agent uses selective
perception to focus its attention on only certain
distinctions, by pruning away other unnecessary ones.
Second, even though there are "too many distinctions,"
the agent's state space may also contain "too few
distinctions"--meaning that perceptual limitations, such
as field of view, acuity and occlusions, have
temporarily hidden crucial features of the environment
from the agent. This problem, called hidden state, can
often be solved by using memory of features from
previous views to augment the agent's perceptual inputs.
This dissertation presents algorithms that use selective
perception and short-term memory to simultaneously prune
and augment the state space provided by the agent's
perceptual inputs. During learning, the agent selects
task-relevant state distinctions with a utile
distinction test that uses robust statistics to
determine when a distinction helps the agent predict
reward. The dissertation also advocates using instance-
based (or "memory-based") learning for making efficient
use of accumulated experience, and using a tree
structure to hold variable-length memories. Four new
algorithms are shown to perform a variety of tasks well--
in some cases with more than an order-of-magnitude
better performance than previous algorithms.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  3965 </NUMBER>
<ORDER>   AAI0577147 </ORDER>
<TITLE> ENSEMBLE OPTIMISED PRIOR KNOWLEDGE TRANSFER IN NEURAL NETWORKS </TITLE>
<AUTHOR> DUNSTONE, EDWARD SIMON </AUTHOR>
<YEAR> 1996 </YEAR>
<INSTITUTION> UNIVERSITY OF WOLLONGONG (AUSTRALIA); 0727 </INSTITUTION>
<DESCRIPTORS> COMPUTER SCIENCE; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> NIL </ADVISER>
<CLASSIFICATIONS> NIL </CLASSIFICATIONS>
<ABSTRACT>
This thesis investigates methods by which the prior
knowledge that is encoded in groups or ensembles of
trained artificial neural networks can be used to assist
in the learning of new tasks. Standard methods for
training neural networks use only the observed (a-
posteriori) data, ignoring any other prior (a-priori)
knowledge which may be available for a particular task.
One form of this prior knowledge is the representations
that have been learnt by other networks trained on
similar problems. The use of such knowledge can improve
both training times and generalisation by appropriately
biasing the representational ability of the neural
network for the new learning task.
Previous research on the transfer of knowledge between
neural networks has concentrated largely on its direct
or literal transfer from a single source network to a
single target network. It is shown in this thesis that
the knowledge encoded by multiple neural networks
trained within the same problem "environment" can be
used in preference to single source transfer to improve
the biasing of the search space. This is known as
ensemble transfer.
This neural network prior knowledge can be likened to
points on a map of the representation space. Each
trained neural network in the prior knowledge defines
the location of a neural network solution that is
appropriate for the learner's environment. The goal of
an ensemble transfer algorithm is to efficiently use the
prior knowledge from this map to bias the learning of
the internal representation for any new tasks. An
appropriate form for the storage of the prior knowledge
that allows reliable optimisation is thus essential.
This aspect is considered in detail with reference to
transformation invariance in the network representations
and symmetric regions in the representation space.
An ensemble optimised transfer algorithm is developed
based on a compact version of the solution space without
network symmetries. It is then tested in three different
problem domains: character recognition; spoken digit
identification; and image approximation. Advantages both
in training speed and stability are demonstrated in all
of these situations over an algorithm which uses literal
transfer from the lowest error network in the prior
knowledge (ensemble literal transfer).
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  3966 </NUMBER>
<ORDER>   AAI9617986 </ORDER>
<TITLE> ADAPTIVE REFINEMENT OF MULTIPLE EXPERT SYSTEMS </TITLE>
<AUTHOR> OTTO, JAMES ROBERT </AUTHOR>
<YEAR> 1996 </YEAR>
<INSTITUTION> UNIVERSITY OF KENTUCKY; 0102 </INSTITUTION>
<DESCRIPTORS> COMPUTER SCIENCE; BUSINESS ADMINISTRATION, MANAGEMENT; ARTIFICIAL INTELLIGENCE; INFORMATION SCIENCE </DESCRIPTORS>
<ADVISER> CLYDE HOLSAPPLE; ANITA LEE-POST </ADVISER>
<CLASSIFICATIONS> ARTIFICIAL INTELLIGENCE, MACHINE LEARNING </CLASSIFICATIONS>
<ABSTRACT>
This dissertation research develops and tests the
feasibility of a new concept for refining multiple
expert systems by exploiting performance feedback and
machine learning techniques to improve their
performance.
This dissertation investigates a new concept for
refining multiple (i.e., one or more) expert systems
that support individuals making repetitive binary
classification decisions based on information in large
databases. An example of such an application would be a
group of individuals exploring a large database for
candidate stocks to purchase. The binary classification
decision made by such researchers would be whether or
not a given stock should be classified as "buy" or "do
not buy."
In general terms, the concept for the refinement of
expert systems operates in the following way. One or
more expert systems compete based on their strengths to
provide their recommendation to a user. The user
responds as to whether the winning recommendation is
correct or incorrect. The rules that contributed to a
correct recommendation are increased in strength while
the rules that contributed to an incorrect
recommendation are decreased in strength. A credit
assignment algorithm is used to determine which rules to
increase or decrease in strength and by how much.
As correct rules grow in strength and incorrect rules
lose strength a higher percentage of correct
recommendations are presented to the user because the
correct rules have higher strengths associated with
them.
The general approach to testing the concept is to
evaluate an unrefined set of expert systems against a
test database. Their performance is measured by how well
they can place correct recommendations at the front of a
queue and incorrect recommendations at the back (pre-
test). The expert systems are then refined (treatment)
and tested (post-test). Pre-test performance is compared
to post-test performance.
This dissertation research is important because it can
directly impact the dynamism, correctness, and
usefulness of expert systems. This research makes
several significant contributions to the expert system
field. These contributions include: (1) Improving expert
systems performance; (2) Adapting expert systems to
Changing Environments; (3) Integrating the Outputs of
multiple expert systems.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  3967 </NUMBER>
<ORDER>   AAI9617853 </ORDER>
<TITLE> SIMBA: BELIEF ASCRIPTION BY WAY OF SIMULATIVE REASONING </TITLE>
<AUTHOR> CHALUPSKY, HANS </AUTHOR>
<YEAR> 1996 </YEAR>
<INSTITUTION> STATE UNIVERSITY OF NEW YORK AT BUFFALO; 0656 </INSTITUTION>
<DESCRIPTORS> COMPUTER SCIENCE; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> STUART C. SHAPIRO </ADVISER>
<CLASSIFICATIONS> INCOMPLETE AGENTS, ARTIFICIAL INTELLIGENCE </CLASSIFICATIONS>
<ABSTRACT>
A key cognitive faculty that enables humans to
communicate with each other is their ability to
incrementally construct and use models describing the
mental states of others, in particular, models of their
beliefs. Not only do humans have beliefs about the
beliefs of others, they can also reason with these
beliefs even if they do not hold them themselves. If we
want to build an artificial or computational cognitive
agent that is similarly capable, we need a formalism
that is fully adequate to represent the beliefs of other
agents, and that also specifies how to reason with them.
Standard formalizations of knowledge or belief, in
particular the various epistemic and doxastic logics,
seem to be not very well suited to serve as the formal
device upon which to build an actual computational
agent. They neglect either representation problems, or
the reasoning aspect, or the defeasibility that is
inherent in reasoning about somebody else's beliefs, or
they use idealizations which are problematic when
confronted with realistic agents.
Our main result is the development of S scIMBA, an
implemented belief-reasoning engine that uses simulative
reasoning to reason with and about the beliefs of other
agents. S scIMBA is built upon SL, a fully intensional,
subjective, nonmonotonic logic of belief which is
representationally and inferentially adequate to serve
as one of the main building blocks of an artificial
cognitive agent. SL can handle agents that do not
believe the consequential closure of their base beliefs;
it is adequate to model introspection; it facilitates
belief maintenance and revision; and it has a more
intuitive semantics than standard formalizations of
belief.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  3968 </NUMBER>
<ORDER>   AAI9617584 </ORDER>
<TITLE> ON GROWING BETTER DECISION TREES FROM DATA </TITLE>
<AUTHOR> MURTHY, KOLLURU VENKATA SREERAMA </AUTHOR>
<YEAR> 1996 </YEAR>
<INSTITUTION> THE JOHNS HOPKINS UNIVERSITY; 0098 </INSTITUTION>
<DESCRIPTORS> COMPUTER SCIENCE; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> STEVEN L. SALZBERG </ADVISER>
<CLASSIFICATIONS> MACHINE LEARNING, ARTIFICIAL INTELLIGENCE </CLASSIFICATIONS>
<ABSTRACT>
This thesis investigates the problem of growing decision
trees from data, for the purposes of classification and
prediction.
After a comprehensive, multi-disciplinary survey of work
on decision trees, some algorithmic extensions to
existing tree growing methods are considered. The
implications of using (1) less greedy search and (2)
less restricted splits at tree nodes are systematically
studied. Extending the traditional axis-parallel splits
to oblique splits is shown to be practical and
beneficial for a variety of problems. However, the use
of more extensive search heuristics than the traditional
greedy heuristic is argued to be unnecessary, and often
harmful.
Any effort to build good decision trees from real-world
data involves "massaging" the data into a suitable form.
Two forms of data massaging, domain-independent and
domain-specific, are distinguished in this work. A new
framework is outlined for the former, and the importance
of the latter is illustrated in the context of two new,
complex classification problems in astronomy. Highly
accurate and small decision tree classifiers are built
for both these problems through a collaborative effort
with astronomers.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  3969 </NUMBER>
<ORDER>   AAI9613935 </ORDER>
<TITLE> FIBER OPTIC NEURAL NETWORK </TITLE>
<AUTHOR> FERNANDES, JUVENAL GREGORIO </AUTHOR>
<YEAR> 1996 </YEAR>
<INSTITUTION> THE UNIVERSITY OF TEXAS AT DALLAS; 0382 </INSTITUTION>
<DESCRIPTORS> PHYSICS, OPTICS; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> CYRUS D. CANTRELL </ADVISER>
<CLASSIFICATIONS> PATTERN RECOGNITION, ARTIFICIAL INTELLIGENCE </CLASSIFICATIONS>
<ABSTRACT>
Optical neural networks offer favorable features
compared to their counterpart digital implementations
for pattern recognition purposes, such as signal
throughput; they also provide technological challenges,
such as optical to electronic interfaces, as well as
practical considerations, such as cost. A fiber optic
neural network is proposed here which can be implemented
with readily available optical components; namely, laser
diodes, laser amplifiers, erbium doped fiber amplifiers,
and photodiodes. The neural network modelled here is
configured arbitrarily with four inputs, four outputs,
and one hidden layer. Supervised training has been
accomplished via the feedforward error backpropagation
scheme. The artificial neural network program JETNET 2.0
has been adapted at the computational facilities of the
Center for Applied Optics at UTD in order to simulate
the performance of the fiber optic neural network under
investigation. Results obtained show that the proposed
construction is capable of attaining full convergence
with various training sets, thereby exhibiting
flexibility and learning capacity to perform as a
pattern recognition instrument.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  3970 </NUMBER>
<ORDER>   AAG9728674 </ORDER>
<TITLE> TIME SERIES PREDICTION USING A MULTIRESOLUTION DYNAMIC PREDICTOR  </TITLE>
<AUTHOR> TSUI, FU-CHIANG </AUTHOR>
<YEAR> 1996 </YEAR>
<INSTITUTION> UNIVERSITY OF PITTSBURGH; 0178 </INSTITUTION>
<DESCRIPTORS> ENGINEERING, ELECTRONICS AND ELECTRICAL; ENGINEERING, BIOMEDICAL; COMPUTER SCIENCE; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> NIL </ADVISER>
<CLASSIFICATIONS> NEURAL NETWORK, WAVELET TRANSFORM </CLASSIFICATIONS>
<ABSTRACT>
There are great demands for long term prediction of time
series in many practical applications. Classical linear
predictors, such as the Wiener, least-mean-square, and
recursive-least-square predictors, provide one-step
short-term prediction only. Artificial neural networks,
especially, the recurrent neural network whose output is
fed back to the input layer can provide longer term
multi-step predictions, however, a large network size is
often needed and its training generally requires an
excessively long history of input. To reduce the
computational complexity in the recurrent neural network
and to increase the long-term prediction accuracy, we
have utilized the wavelet transform in a set of
recurrent neural networks at several scales to construct
a long-term nonlinear-predictor via the prediction of
wavelet coefficients. An efficient training has been
achieved by means of these wavelet coefficients.
To extend its applicability to nonstationary processes
via piecewise stationary prediction, the structure of
our neural network predictor is designed to provide
periodic switching in the feedback path so that the
recurrent neural networks give predictions during the
"on" mode, while the feedforward structure undergoes an
one-step retraining during the "off" mode. This is
performed by windowing the data and taking its discrete
wavelet transform based on which the connection weights
are updated. In the next windowed interval, new
prediction is performed by the updated network. Because
of this adaptive behavior, we name our adaptive
predictor a "multiresolution dynamic predictor".
Both the semi-orthogonal and compactly supported
biorthogonal wavelet transforms have been investigated
for the multiresolution dynamic predictor. The semi-
orthogonal wavelet transform defined in the Sobolev
space (the function space of finite energy signals with
bounded integral of the second order derivative) can be
computed from coarse scale levels to fine scale levels,
greatly reducing the computational burden during the
long-term prediction process.
The compactly supported biorthogonal wavelet transform
has many desirable properties, and can be realized
precisely using an efficient algorithm. This
investigation has shown an important decorrelation
property for the compactly supported biorthogonal
wavelet transform. Based on this property, the neural
network for long-term prediction may use a smaller
number of weights and fewer training data, while
achieving a better performance. In cases where the
coarse scales are of the primary interest, the use of
the semi-orthogonal wavelet transform requires fewer
computational steps than other types of wavelet
transforms.
The least-mean-square and recursive-least-square
predictors have been experimentally compared with the
recurrent neural networks for prediction of intracranial
pressure data acquired in a Neuro Intensive Care Unit.
The results have shown that our recurrent neural network
outperforms the other two predictors on the prediction
of wavelet coefficients.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  3971 </NUMBER>
<ORDER>   AAI9613186 </ORDER>
<TITLE> SELF-ORGANIZING NEURAL NETWORKS FOR VISUAL NAVIGATION AND ADAPTIVE CONTROL </TITLE>
<AUTHOR> CAMERON, SETH ANDREW </AUTHOR>
<YEAR> 1996 </YEAR>
<INSTITUTION> BOSTON UNIVERSITY; 0017 </INSTITUTION>
<DESCRIPTORS> COMPUTER SCIENCE; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> FRANK H. GUENTHER </ADVISER>
<CLASSIFICATIONS> COMPUTER VISION </CLASSIFICATIONS>
<ABSTRACT>
This dissertation describes two self-organizing neural
networks that learn to convert perceptual information
into representations useful for planning and performing
action. The first network converts optic flow into
heading estimation, scene depth estimation, and moving
object localization. Network weights are trained during
an action-perception cycle in which self-generated eye
and body movements produce optic flow. The confounding
effect of eye movement during translation is suppressed
by learning the relationship between eye movement
outflow commands and the optic flow signals they induce.
The remaining optic flow field is due only to observer
translation and independent motion of objects in the
scene. A self-organizing feature map encodes heading by
categorizing normalized translational flow patterns.
Cells in the map that respond maximally to movement
along a certain heading simultaneously learn the average
translational flow signals induced by that motion.
Comparing these learned averages to instantaneous flow
fields yields a relative depth estimate across the
entire visual field. Active heading map cells also learn
expected optic flow directions. These expected patterns
are subtracted from normalized flow patterns to detect
objects moving independently of the observer. All
learning processes take place concurrently and require
no external "teachers." The network will automatically
adapt to the sensor geometry and other opto-mechanical
properties of robotic vision systems. Simulations verify
its visual navigation performance using both noise-free
and noisy optic flow information.
The second neural architecture is a general-purpose
adaptive controller based on the DIRECT model of
movement control. The function approximation technique
used in DIRECT is replaced with a more efficient
adaptive radial basis function (RBF) network.
Specifically, the network is a variant of a Gaussian
normalized RBF network with linear mapping coefficients
at each basis. Learning laws are derived that allow the
widths and centers of the bases to adapt to unknown
mappings. The result is a network that is more memory
efficient and can learn inverse control problems with
many fewer training movements than the original DIRECT
model. Simulations illustrate kinematic control of a
planar 3-joint arm and a 7-dimensional articulatory
speech synthesizer.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  3972 </NUMBER>
<ORDER>   AAI9613088 </ORDER>
<TITLE> AN INTELLIGENT COMPUTER VISION CONTROL AND TARGET TRACKING SYSTEM DESIGN OF AN AGRICULTURAL GRAPEVINE PRUNING ROBOT </TITLE>
<AUTHOR> LEE, MIN-FAN </AUTHOR>
<YEAR> 1996 </YEAR>
<INSTITUTION> CORNELL UNIVERSITY; 0058 </INSTITUTION>
<DESCRIPTORS> ENGINEERING, AGRICULTURAL; ENGINEERING, MECHANICAL; ENGINEERING, ELECTRONICS AND ELECTRICAL; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> NIL </ADVISER>
<CLASSIFICATIONS> NIL </CLASSIFICATIONS>
<ABSTRACT>
The performance of a grapevine pruning robot module was
improved by adding a target tracking system which
contains an altitude estimation process and compensation
law. The grapevine pruning robot module's performance
was measured under simulated field conditions.
The design and construction of a motion simulator, the
design of an electrohydraulic servo system to power the
simulator, and the design of a digital fuzzy logic
controller to control the simulator are presented. The
purpose of the simulator is to duplicate the response of
a carrier supporting a grapevine pruning robot module
traveling along uneven vineyard terrain. The grapevine
pruning robot is automatically positioned by finding the
location of the vine's cordon (Gunkel and Throop, 1992).
The simulator offers four degrees-of-freedom, two
rotational and two translational. The two rotational
motions allow simulation of pitch and yaw of the carrier
while the two translation motions simulate the movement
of the carrier vertically up and down. The fuzzy logic
controller allows computer control of the simulator's
motion. This enables actual field data measurements of
vineyard terrain roughness and slope to be programmed
and duplicated by the simulator.
Node counting is an important step needed for the
determination of pruning severity. Therefore a
mathematical morphological detection algorithm was
designed to determine the location and number of nodes.
The advantage and disadvantage of using mathematical
morphology will also be discussed. The main purpose of
the approach is to enable the current block-pruning type
robotic grapevine pruner to selectively-prune.
A pattern recognition algorithm is developed to update
the block-pruning type grapevine pruner to selective-
pruning type grapevine pruner. Two mathematical
grayscale morphological operations were successfully
implemented, open and close, to achieve the goal. All
the images were preprocessed to be smoothed out. Two
disk elements with radius 4 and radius 3 were used for
the node finding and eight line structure elements with
0$spcirc$, 27$spcirc$, 45$spcirc$, 63$spcirc$,
90$spcirc$, 117$spcirc$, 135$spcirc$ and 153$spcirc$
were used for branch extraction. The rectangular
structure element with width 20 and length 30 was used
for post extraction. The pixel value of all the
structure elements were uniformly set as 3.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  3973 </NUMBER>
<ORDER>   AAI9612901 </ORDER>
<TITLE> LEARNING HALFSPACES FROM BAD EXAMPLES </TITLE>
<AUTHOR> BARBER, TIMOTHY PAUL </AUTHOR>
<YEAR> 1996 </YEAR>
<INSTITUTION> PRINCETON UNIVERSITY; 0181 </INSTITUTION>
<DESCRIPTORS> MATHEMATICS; COMPUTER SCIENCE; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> HALE F. TROTTER </ADVISER>
<CLASSIFICATIONS> ARTIFICIAL INTELLIGENCE, NEURAL NETWORKS, PERCEPTRONS </CLASSIFICATIONS>
<ABSTRACT>
Suppose f is the characteristic function of an unknown
halfspace in n-dimensional real space, and we are given
the value of f at each of m "example" points. The
examples are "bad" in the sense that each is wrong with
some fixed probability. Given any new point z, we show
how to guess f(z) efficiently and accurately. If all
points are chosen uniformly on the sphere, then the
probability of error is at most the square root of
O(n/m). The algorithm runs in O(mn) computational steps.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  3974 </NUMBER>
<ORDER>   AAI0577054 </ORDER>
<TITLE> MODEL-BASED IDENTIFICATION AND CONTROL OF NONLINEAR DYNAMIC SYSTEMS USING NEURAL NETWORKS </TITLE>
<AUTHOR> YU, SSU-HSIN </AUTHOR>
<YEAR> 1996 </YEAR>
<INSTITUTION> MASSACHUSETTS INSTITUTE OF TECHNOLOGY; 0753 </INSTITUTION>
<DESCRIPTORS> ENGINEERING, MECHANICAL; ENGINEERING, SYSTEM SCIENCE; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> ANURADHA M. ANNASWAMY </ADVISER>
<CLASSIFICATIONS> THETA ADAPTIVE NEURAL NETWORKS </CLASSIFICATIONS>
<ABSTRACT>
The difficulties in identification and control of
engineering systems are due to several factors including
the presence of several types of nonlinearities, and
significant and unknown sources of variations in the
operating conditions of the system. In many of these
problems, the underlying physics that contributes to the
nonlinear system characteristics can be modeled using
physical laws. However, due to analytical tractability,
the traditional approach has not always made effective
use of available physically based models.
In this thesis, new parameter estimation and control
techniques, which take advantage of prior physical
knowledge of dynamic systems, are presented. The tools
used are artificial neural networks (ANN). For parameter
estimation problems, the scheme denoted as $theta$-
adaptive neural networks (TANN) is developed. TANN is
useful for systems where the unknown parameters occur
nonlinearly. For control problems, we consider two
classes of nonlinear stabilization problems including
systems with unknown parameters and systems with unknown
controller structures. TANN is implemented on the former
class to adjust the controller parameters so that
stabilization can be achieved in the presence of
parametric uncertainty. For systems with unknown
controller structures, ANN are trained off-line to
generate nonlinear controllers that contribute to the
decrease of specified positive definite functions of
state variables. Conditions under which these two
controllers result in stable closed-loop systems are
given.
The framework introduced in this thesis naturally lends
itself to a mathematically tractable problem formulation
and can be applied to general nonlinear systems. The
neural network training procedure, whether it is for the
purpose of parameter estimation or control, also permits
the use of more efficient training algorithms and leads
to a larger region of stability for a wide class of
dynamic systems. (Copies available exclusively from MIT
Libraries, Rm. 14-0551, Cambridge, MA 02139-4307. Ph.
617-253-5668; Fax 617-253-1690.)
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  3975 </NUMBER>
<ORDER>   AAI1377170 </ORDER>
<TITLE> DESIGN AND IMPLEMENTATION OF AN ALTITUDE FLIGHT CONTROLLER FOR THE FAU OCEAN VOYAGER II </TITLE>
<AUTHOR> WHITE, KEVIN ANDREW </AUTHOR>
<YEAR> 1996 </YEAR>
<INSTITUTION> FLORIDA ATLANTIC UNIVERSITY; 0119 </INSTITUTION>
<DESCRIPTORS> ENGINEERING, MARINE AND OCEAN; ENGINEERING, MARINE; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> SAMUEL SMITH </ADVISER>
<CLASSIFICATIONS> NIL </CLASSIFICATIONS>
<ABSTRACT>
Autonomous underwater vehicle (AUV) missions are
generally of a multi-tasked nature, i.e., there are
usually several criteria which need to be met
concurrently during the course of a mission. An example
is the bottom altitude tracking mission proposed by the
University of South Florida. They have developed a
bottom classification and albedance package (BCAP) which
will be used to record data to ground-truth
oceanographic satellites. Two criteria needed for this
mission are vehicle safety and motion stability of the
recording sensors. This thesis will respectively compare
the results of three bottom altitude tracking
controllers: a linear modification of an existing depth
controller, a TSK fuzzy logic controller, and a behavior
based decision controller. Aspects analyzed for meeting
the criteria were the ability of the auv to avoid
collisions with bottom, the ability of the auv to
maintain a desired altitude above the sea floor, and the
ability of the auv to keep the amount of blur in a
picture taken by a downward looking camera under one
pixel. From simulation and real world testing, final
results indicate the behavioral based decision
controller was proven to be the most robust and the only
controller tested to be able to handle multi-criteria.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  3976 </NUMBER>
<ORDER>   AAI9612058 </ORDER>
<TITLE> LEARNING PROBABILISTIC RELATIONAL CONCEPT DESCRIPTIONS </TITLE>
<AUTHOR> ALI, KAMAL MAHMOOD </AUTHOR>
<YEAR> 1996 </YEAR>
<INSTITUTION> UNIVERSITY OF CALIFORNIA, IRVINE; 0030 </INSTITUTION>
<DESCRIPTORS> COMPUTER SCIENCE; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> MICHAEL J. PAZZANI </ADVISER>
<CLASSIFICATIONS> CLASSIFICATION, ARITIFICAL INTELLIGENCE </CLASSIFICATIONS>
<ABSTRACT>
This dissertation presents methods for increasing the
accuracy of probabilistic classification rules learned
from noisy, relational data. It addresses the problem of
learning probabilistic rules in noisy, "real-world" data
sets, the problem of "small disjuncts" in which rules
that apply to rare subclasses have high error rates, and
the problems that arise in domains in which the learning
algorithm is forced to pick from many rules that appear
to be equally good.
It is shown that learning a class description for each
class in the data--the one-per-class approach--and
attaching probabilistic estimates to the learned rules
allows accurate classifications to be made on real-world
data sets. The thesis presents the system HYDRA which
implements this approach. It is shown that the resulting
classifications are often more accurate than those made
by three major methods for learning from noisy,
relational data. Furthermore, the learned rules are
relational and so are more expressive than the attribute-
value rules learned by most induction systems.
Several results are also presented in the arena of
multiple models. The multiple models approach is
relevant to the problem of making accurate
classifications in "real-world" domains since it
facilitates evidence combination which is needed to
accurately learn on such domains.
The most important result of the multiple models
research is that the amount of error reduction afforded
by the multiple models approach is linearly correlated
with the degree to which the individual models make
errors in an uncorrelated manner. It is shown that it is
possible to learn models that make less correlated
errors in domains in which there are many gain ties. The
third major result of the research on multiple models is
the realization that models should be learned that make
errors in a negatively-correlated manner rather than
those that make errors in an uncorrelated manner.
Finally, results are presented on the small-disjuncts
problem in which rules that apply to rare subclasses
have high error rates. It is shown that the one-per-
class approach reduces error rates for such rare rules
while not sacrificing the error rates of the other
rules.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  3977 </NUMBER>
<ORDER>   AAI9612028 </ORDER>
<TITLE> EXPERIMENTS IN MANIPULATION AND ASSEMBLY BY TWO-ARM, FREE-FLYING SPACE ROBOTS </TITLE>
<AUTHOR> RUSSAKOW, JEFFREY STEVEN </AUTHOR>
<YEAR> 1996 </YEAR>
<INSTITUTION> STANFORD UNIVERSITY; 0212 </INSTITUTION>
<DESCRIPTORS> ENGINEERING, MECHANICAL; COMPUTER SCIENCE; ENGINEERING, AEROSPACE; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> STEPHEN M. ROCK </ADVISER>
<CLASSIFICATIONS> OPERATIONAL SPACE CONTROL FRAMEWORK </CLASSIFICATIONS>
<ABSTRACT>
Research in advanced manipulation by robotic systems has
led to interest in multi-arm/dynamic base manipulator
systems--robots in which two or more manipulators extend
from a common macro-manipulator or vehicle. These
systems possess characteristics that are inherently
beneficial to dexterous manipulation, such as
redundancy, multiple arms, and macro-mini dynamic
properties.
Free-flying space robots are one example where the use
of multiple manipulators stemming from a single mobile
vehicle offer unprecedented capability. A mobile base
enables the robot to work over an unlimited workspace;
multiple end-effectors enable either the execution of
several tasks simultaneously or the cooperative
manipulation of cumbersome objects; and redundant
degrees of freedom and macro-mini dynamic properties
enable the robot to achieve fast, precise manipulation
at the end-effectors even though the robot body may be
dominated by slower dynamic behavior.
While previous research has been conducted to control
multi-arm/dynamic-base systems, an approach has never
been pursued in which the redundancy of these systems
has been exploited fully to focus on just the
manipulative task. Past efforts have attempted to
control with equal priority both the manipulative task
executed at the robot hands and the control of the
redundant degrees of freedom associated with the robot
body and posture.
This thesis investigation proposes a new, dynamically-
partitioned control framework for multi-arm/dynamic-base
manipulator systems, in which the performance of a robot
at the manipulative task is deemed paramount. Pursuant
to this goal, the entire redundant system works in
concert to achieve the best possible dynamic performance
at the robot end-effectors. Control of the redundant
degrees of freedom of the robot are controlled using
only dynamically consistent combinations of forces and
torques that will not introduce undesired accelerations
at the task.
The novel control framework has been developed by
extending the Operational Space Control Framework for
single-arm and cooperating single-arm manipulators to
the larger class of multi-arm/dynamic-base manipulators.
The new Extended Operational Space Framework has been
experimentally validated on two-arm, free-flying space
robot proto-types. These robots have been programmed to
perform object acquisition, transport, and assembly
tasks in a free-floating space environment under the new
control framework.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  3978 </NUMBER>
<ORDER>   AAI9611989 </ORDER>
<TITLE> WRAPPERS FOR PERFORMANCE ENHANCEMENT AND OBLIVIOUS DECISION GRAPHS  </TITLE>
<AUTHOR> KOHAVI, RON </AUTHOR>
<YEAR> 1996 </YEAR>
<INSTITUTION> STANFORD UNIVERSITY; 0212 </INSTITUTION>
<DESCRIPTORS> COMPUTER SCIENCE; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> YOAV SHOHAM </ADVISER>
<CLASSIFICATIONS> LEARNING ALGORITHMS, SUPERVISED CLASSIFICATION, ARTIFICIAL INTELLIGENCE </CLASSIFICATIONS>
<ABSTRACT>
In this doctoral dissertation, we study three basic
problems in machine learning and two new hypothesis
spaces with corresponding learning algorithms. The
problems we investigate are: accuracy estimation,
feature subset selection, and parameter tuning. The
latter two problems are related and are studied under
the wrapper approach. The hypothesis spaces we
investigate are: decision tables with a default majority
rule (DTMs) and oblivious read-once decision graphs
(OODGs).
For accuracy estimation, we investigate cross-validation
and the.632 bootstrap. We show examples where they fail
and conduct a large scale study comparing them. We
conclude that repeated runs of five-fold cross-
validation give a good tradeoff between bias and
variance for the problem of model selection used in
later chapters.
We define the wrapper approach and use it for feature
subset selection and parameter tuning. We relate
definitions of feature relevancy to the set of optimal
features, which is defined with respect to both a
concept and an induction algorithm. The wrapper approach
requires a search space, operators, a search engine, and
an evaluation function. We investigate all of them in
detail and introduce compound operators for feature
subset selection. Finally, we abstract the search
problem into search with probabilistic estimates.
We introduce decision tables with a default majority
rule (DTMs) to test the conjecture that feature subset
selection is a very powerful bias. The accuracy of
induced DTMs is surprisingly powerful, and we concluded
that this bias is extremely important for many real-
world datasets. We show that the resulting decision
tables are very small and can be succinctly displayed.
We study properties of oblivious read-once decision
graphs (OODGs) and show that they do not suffer from
some inherent limitations of decision trees. We describe
a general framework for constructing OODGs bottom-up and
specialize it using the wrapper approach. We show that
the graphs produced are useless features than C4.5, the
state-of-the-art decision tree induction algorithm, and
are usually easier for humans to comprehend.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  3979 </NUMBER>
<ORDER>   AAI9611955 </ORDER>
<TITLE> APPLICATIONS OF REGENERATIVE FEEDBACK IN INTEGRATED CIRCUITS  </TITLE>
<AUTHOR> DOBBELAERE, IVO JOHAN </AUTHOR>
<YEAR> 1996 </YEAR>
<INSTITUTION> STANFORD UNIVERSITY; 0212 </INSTITUTION>
<DESCRIPTORS> ENGINEERING, ELECTRONICS AND ELECTRICAL; ARTIFICIAL INTELLIGENCE; COMPUTER SCIENCE </DESCRIPTORS>
<ADVISER> ABBAS EL GAMAL </ADVISER>
<CLASSIFICATIONS> SIGNAL PROPAGATION </CLASSIFICATIONS>
<ABSTRACT>
This thesis presents the use of regenerative feedback
repeaters to speed up the signal propagation along RC
lines and transmission lines on or at the periphery of
integrated circuits. Such regenerative feedback
repeaters locally regenerate the new level after
detecting a transition. The local regeneration shorts
out the resistive path from the input, and speeds up the
transition on further nodes. This operating principle is
similar to the signal propagation in nerve axons, and
offers advantages in performance, power consumption, and
use of resources.
The example of bidirectional, programmable
interconnections through MOS transistors in Field
Programmable Gate Arrays is used to introduce
precharged, postcharged and complementary regenerative
feedback repeaters. Through circuit simulations and
measurements on a 1.2$mu$m CMOS test chip, it is shown
that regenerative feedback repeaters are faster and
smaller than conventional repeaters. It is also shown
that there are limitations on the types of signals that
can be propagated by feedback repeaters. Precharged
repeaters require monotonic signals. Postcharged
repeaters require pulses. Complementary repeaters can
propagate both rising and falling transitions, but, to
avoid metastability, require glitch-free signals. As a
result, it is not possible to simply replace the
inserted repeaters in a conventional FPGA by feedback
repeaters, without compromising the zero error rate.
Instead, non-conventional FPGA architectures in which
only the correct signal types appear on the
interconnection networks must be used. These
architectures are more complex in hardware, and some of
them require retiming of the logic implementation, which
may have a considerable impact. On an equal area basis,
the performance improvement of these alternative
architectures is substantial, even after taking into
account a large penalty factor for retiming.
It is also shown that the fast signal propagation
through MOS transistors with precharged regenerative
feedback repeaters can be combined with complementary
pass transistor logic and elements of Domino logic, to
obtain a dynamic CMOS logic family that is faster than
Domino logic.
Finally, it is shown that by using a complementary
regenerative feedback repeater at the receiving end of a
transmission line, the driver impedance range of
reliable first incidence switching can be extended
compared to source-matching.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  3980 </NUMBER>
<ORDER>   AAI9611322 </ORDER>
<TITLE> ABDUCTIVE INFERENCE OF EVENTS: DIAGNOSING CARDIAC ARRHYTHMIAS  </TITLE>
<AUTHOR> GUERTIN, MARGARET E. </AUTHOR>
<YEAR> 1996 </YEAR>
<INSTITUTION> BOSTON UNIVERSITY; 0017 </INSTITUTION>
<DESCRIPTORS> COMPUTER SCIENCE; ARTIFICIAL INTELLIGENCE; HEALTH SCIENCES, MEDICINE AND SURGERY </DESCRIPTORS>
<ADVISER> WILLIAM H. HENNEMAN </ADVISER>
<CLASSIFICATIONS> TEMPORAL REASONING, CONSTRAINTS, ARTIFICIAL INTELLIGENCE </CLASSIFICATIONS>
<ABSTRACT>
The ability to reason abductively, to infer a set of
causes from their observed effects, is an essential
component of human intelligence, and is used to
construct explanations in such diverse areas as
archaeology, criminal investigation, and medicine.
Automating this process is, therefore, an important
problem in artificial intelligence, but also an
extremely challenging one. Its main difficulty lies in
the exponential number of explanations for even the
simplest set of observations. Abductive inference for
real-world problems has been shown to be NP-hard.
We offer a new approach to this problem--that of
controlling the combinatoric explosion of possible
explanations by means of temporal constraint
propagation. To show the effectiveness of this approach,
we have chosen to generate causal explanations of a
cardiac arrhythmia appearing on an electrocardiogram
(ECG) Explanations in this domain are constrained by
well-understood temporal constraints from the ECG, as
well as more subtle ones imposed by the underlying model
of the heart.
We demonstrate this approach with H scOLMES, an
abductive reasoning system augmented by a method for
propagating temporal constraints, which yields early
refutation of inconsistent hypotheses. While H scOLMES
is designed as a general-purpose system, it is used here
to generate causes of cardiac arrhythmia. Though other
arrhythmia diagnostic systems discover more arrhythmias
than H scOLMES, they do so at a cost, in that they
incorporate huge amounts of domain knowledge into their
code, requiring a considerable investment of time and
expertise. H scOLMES, on the other hand, provides very
detailed explanations from a network of components
embodying sparse amounts of domain knowledge and
constrained by a weak set of temporal constraints.
While H scOLMES generates more detailed explanations
than are achieved in comparable diagnostic systems, its
principal contribution lies in the alternative it offers
to the traditional expert system/knowledge engineering
approach to diagnostic problems. Many problems formerly
thought to require immense amounts of domain-specific
knowledge can, in fact, be solved efficiently by loosely
connected networks of not very knowledgeable agents,
provided that they are grounded in a good causal model
of the problem.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  3981 </NUMBER>
<ORDER>   AAG9728576 </ORDER>
<TITLE> NOISY RECURRENT NEURAL NETWORKS </TITLE>
<AUTHOR> DAS, SOUMITRA </AUTHOR>
<YEAR> 1996 </YEAR>
<INSTITUTION> GEORGE MASON UNIVERSITY; 0883 </INSTITUTION>
<DESCRIPTORS> ENGINEERING, ELECTRONICS AND ELECTRICAL; STATISTICS; BIOLOGY, NEUROSCIENCE; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> OLUSEYI OLUROTIMI </ADVISER>
<CLASSIFICATIONS> WHITE NOISE </CLASSIFICATIONS>
<ABSTRACT>
The classical stochastic analog of the deterministic
linear system in engineering is the linear system driven
by white noise. This model is the basis of many
important engineering methodologies in stochastic
control, system identification, and signal estimation
and classification. As the promise of artificial neural
networks in modeling nonlinear systems continues to
grow, the need for a stochastic analog with quantitative
foundations for analysis and synthesis will increase.
This dissertation represents recent work in this
direction, examining recurrent neural networks driven by
white noise.
We began our investigation with discrete-time form of
recurrent neural networks. First, we performed
qualitative analysis establishing the boundedness of
moments of the neuron states over time. We subsequently
considered the RNN as an estimator of noisy dynamic
patterns and derived bias and variance measures for this
estimator. This has significant practical implications,
since neural network design is nonminimal in the sense
that several different networks can be constructed to
solve the same problem. The results in this dissertation
allow the user to quantitatively evaluate given RNN's
noise performance. In addition, the designer can use
these results to constrain the design space so that the
achieved design satisfies performance specifications
whenever possible.
In order to illustrate the results of noisy discrete-
time RNN, we considered an example of system
identification and control well known in the neural
network control literature. We designed ten feedforward
and recurrent neural networks so that a nonlinear plant
had similar outputs for each of these neural network
controllers in the absence of noise. We presented a
simulation result that showed a large deviation in the
responses of the plant for different neural network
controllers in a noisy environment. Based on the
theoretical results of noisy discrete-time RNN, we
predicted the stochastic performance of the plant with
relative success.
Then, we analyzed the stochastic behavior of the
continuous-time form of RNN's and established similar
results as in the discrete-time case. We also considered
the applications of the results of noisy continuous-time
RNN to the design and evaluation of temporal pattern
generation. Learning and recalling temporal patterns in
the presence of noise is relevant for such applications
as system identification and modeling. We presented a
guideline to design and evaluate RNN operating in a
noisy environment. We trained three RNNs with similar
deterministic performance and used our theoretical
results to predict their performance in a noisy
environment. Subsequent simulations corroborated the
predictions.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  3982 </NUMBER>
<ORDER>   AAI9611322 </ORDER>
<TITLE> ABDUCTIVE INFERENCE OF EVENTS: DIAGNOSING CARDIAC ARRHYTHMIAS  </TITLE>
<AUTHOR> GUERTIN, MARGARET E. </AUTHOR>
<YEAR> 1996 </YEAR>
<INSTITUTION> BOSTON UNIVERSITY; 0017 </INSTITUTION>
<DESCRIPTORS> COMPUTER SCIENCE; ARTIFICIAL INTELLIGENCE; HEALTH SCIENCES, MEDICINE AND SURGERY </DESCRIPTORS>
<ADVISER> WILLIAM H. HENNEMAN </ADVISER>
<CLASSIFICATIONS> TEMPORAL REASONING, CONSTRAINTS, ARTIFICIAL INTELLIGENCE </CLASSIFICATIONS>
<ABSTRACT>
The ability to reason abductively, to infer a set of
causes from their observed effects, is an essential
component of human intelligence, and is used to
construct explanations in such diverse areas as
archaeology, criminal investigation, and medicine.
Automating this process is, therefore, an important
problem in artificial intelligence, but also an
extremely challenging one. Its main difficulty lies in
the exponential number of explanations for even the
simplest set of observations. Abductive inference for
real-world problems has been shown to be NP-hard.
We offer a new approach to this problem--that of
controlling the combinatoric explosion of possible
explanations by means of temporal constraint
propagation. To show the effectiveness of this approach,
we have chosen to generate causal explanations of a
cardiac arrhythmia appearing on an electrocardiogram
(ECG) Explanations in this domain are constrained by
well-understood temporal constraints from the ECG, as
well as more subtle ones imposed by the underlying model
of the heart.
We demonstrate this approach with H scOLMES, an
abductive reasoning system augmented by a method for
propagating temporal constraints, which yields early
refutation of inconsistent hypotheses. While H scOLMES
is designed as a general-purpose system, it is used here
to generate causes of cardiac arrhythmia. Though other
arrhythmia diagnostic systems discover more arrhythmias
than H scOLMES, they do so at a cost, in that they
incorporate huge amounts of domain knowledge into their
code, requiring a considerable investment of time and
expertise. H scOLMES, on the other hand, provides very
detailed explanations from a network of components
embodying sparse amounts of domain knowledge and
constrained by a weak set of temporal constraints.
While H scOLMES generates more detailed explanations
than are achieved in comparable diagnostic systems, its
principal contribution lies in the alternative it offers
to the traditional expert system/knowledge engineering
approach to diagnostic problems. Many problems formerly
thought to require immense amounts of domain-specific
knowledge can, in fact, be solved efficiently by loosely
connected networks of not very knowledgeable agents,
provided that they are grounded in a good causal model
of the problem.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  3983 </NUMBER>
<ORDER>   AAI9609834 </ORDER>
<TITLE> NEURAL NETWORKS FOR SUPERVISED LEARNING AND PREDICTION, WITH APPLICATIONS TO CHARACTER RECOGNITION AND MEDICAL DATABASE ANALYSIS  </TITLE>
<AUTHOR> MARKUZON, NATALYA </AUTHOR>
<YEAR> 1996 </YEAR>
<INSTITUTION> BOSTON UNIVERSITY; 0017 </INSTITUTION>
<DESCRIPTORS> COMPUTER SCIENCE; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> GAIL A. CARPENTER </ADVISER>
<CLASSIFICATIONS> ARTMAP, ARTIFICIAL INTELLIGENCE </CLASSIFICATIONS>
<ABSTRACT>
ARTMAP is a class of neural network architectures that
perform incremental supervised learning of recognition
categories and multidimensional maps in response to
input vectors presented in arbitrary order. The fuzzy
ARTMAP neural network achieves a synthesis of fuzzy
logic and adaptive resonance theory (ART) by exploiting
a formal similarity between the computations of fuzzy
subsethood and ART category choice, resonance, and
learning. On a benchmark task of recognition of
distorted letters of various fonts, fuzzy ARTMAP
performance is compared to that of genetic algorithm
systems. Fuzzy ARTMAP has an error rate that is
consistently less than one third that of the best
performing genetic algorithm classifiers.
A more difficult handwritten digit recognition task
requires the identification of real, noisy digits from
ZIP codes. Two preprocessing algorithms, based on
positional or orientational information extracted from
the image, are tested. The orientation selective
algorithm proves to be more successful. Showing high
recognition accuracy, fuzzy ARTMAP performance is
improved by a modified learning rule, which enables the
"forgetting" of insignificant information. The K-Nearest
Neighbor (KNN) classifier evaluated in the study
outperforms fuzzy ARTMAP but requires more memory and
recognition time.
The last part of the dissertation introduces the ARTMAP-
PI (Probabilistic Inference) neural network, which
extends the capabilities of fuzzy ARTMAP to provide
probabilistic outcome estimates. Two features
distinguish ARTMAP-PI from fuzzy ARTMAP: distributed
activity during performance, and a new layer in the
architecture. The activity of the new instance-counting
layer diminishes the influence of statistically less-
significant information on probabilistic predictions
made by the network. Also, the introduction of these new
features allows for the incorporation of inconsistent
data in the learning process. Fuzzy ARTMAP, ART-EMAP,
and ARTMAP-PI performance is evaluated on databases that
(a) differentiate malignant and benign tumors based on
fine needle aspiration, (b) diagnose heart disease for
cardiac patients, (c) predict the occurrence of
complications after cholecystectomy, and (d) determine
whether a patient will develop diabetes. The performance
of the KNN classifier and the logistic regression model
is evaluated and compared to that of ARTMAP-based
classifiers. ARTMAP-based classifiers demonstrate
similar or better performance compared to these other
approaches.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  3984 </NUMBER>
<ORDER>   AAINN02711 </ORDER>
<TITLE> MEASUREMENT-THEORETIC FRAMEWORKS FOR FUZZY SET THEORY WITH APPLICATIONS TO PREFERENCE MODELLING </TITLE>
<AUTHOR> BILGIC, TANER </AUTHOR>
<YEAR> 1996 </YEAR>
<INSTITUTION> UNIVERSITY OF TORONTO (CANADA); 0779 </INSTITUTION>
<DESCRIPTORS> ENGINEERING, INDUSTRIAL; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> I. B. TURKSEN </ADVISER>
<CLASSIFICATIONS> AXIOMATIZATION, VAGUENESS </CLASSIFICATIONS>
<ABSTRACT>
There are three objectives in this thesis: (i) to
provide a suitable axiomatization of the fuzzy set
theory, (ii) to investigate the appropriateness of those
axiomatizations to modelling the vagueness in
preferences of decision makers and finally (iii) to
apply these findings to real world situations.
It is proposed that one should use frameworks provided
by measurement theory in order to understand what fuzzy
set theory can meaningfully represent. Two different but
complementary measurement problems are formulated and
critically analyzed. This distinction in formulating the
measurement problems highlights some discussions in the
foundations of the fuzzy set theory. In order to obtain
a complete axiomatization of fuzzy set theory, these two
problems must be combined. Three alternative ways of
combining the two problems are proposed. Each model
results in a possible axiomatization of fuzzy set
theory.
Recent research interest on representing vague
preferences in fuzzy set theory is critically reviewed
in the light of an impossibility result. The vagueness
of preferences is defined concisely and a resolution to
this problem is proposed using the concept of interval-
valued fuzzy sets. Relationships of various transitivity
conditions are demonstrated and a new transitivity
condition with the interval-valued preference structures
is proposed.
The concept of rationality and scalability of observed
choice behaviour is also addressed. It is shown that
vague preferences can be viewed as being
probabilistically generated from imperfect rankings of
human decision makers.
The techniques developed in the earlier chapters are
applied to the problem of model-based localization of a
mobile robot equipped with sonar sensors. Here, the
vagueness arises from noisy sonar sensors. A search
procedure is suggested in which the preference structure
is used as a conflict resolver.
In summary, the axiomatizations suggest that fuzzy set
theory mostly captures the ordinal aspects of vagueness
and this purely ordinal view is adopted in the rest of
the thesis. The interval-valued preference structures
are shown to be consistent in a well defined sense. It
is claimed that the noise associated with sonar sensors
defies a probabilistic analysis and using fuzzy set
theory based approaches is justified.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  3985 </NUMBER>
<ORDER>   AAI9608536 </ORDER>
<TITLE> MULTIPURPOSE ADVERSARY PLANNING IN THE GAME OF GO </TITLE>
<AUTHOR> HU, SHUI </AUTHOR>
<YEAR> 1996 </YEAR>
<INSTITUTION> GEORGE MASON UNIVERSITY; 0883 </INSTITUTION>
<DESCRIPTORS> COMPUTER SCIENCE; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> PAUL E. LEHNER </ADVISER>
<CLASSIFICATIONS> GAME THEORY </CLASSIFICATIONS>
<ABSTRACT>
A heuristic adversary planning method is developed to
address the problem of multipurpose planning in the game
of Go. Static analysis and dynamic look ahead on both
strategic and tactical levels are used to generate
possible goals and identify the achievability of, and
interactions among, these various goals. Multipurpose
goals are composed by subtle intersection of individual
goals. An evaluation of alternative strategies is
performed, where a strategy is defined as a set of
selected goals and interactions.
The formalization of Go is outlined in the appendix in
this dissertation.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  3986 </NUMBER>
<ORDER>   AAI9608296 </ORDER>
<TITLE> AN INTELLIGENT CONSULTANT SYSTEM FOR CHESS </TITLE>
<AUTHOR> LAZZERI, SANTOS GERARDO </AUTHOR>
<YEAR> 1996 </YEAR>
<INSTITUTION> THE GEORGE WASHINGTON UNIVERSITY; 0075 </INSTITUTION>
<DESCRIPTORS> COMPUTER SCIENCE; RECREATION; EDUCATION, TECHNOLOGY; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> RACHELLE SILVERMAN HELLER </ADVISER>
<CLASSIFICATIONS> FUZZY LOGIC, TUTORING </CLASSIFICATIONS>
<ABSTRACT>
This study presents a new approach for an interactive
chess consultant that combines the techniques of fuzzy
logic and case-based reasoning in order to produce high
level advice for specific chess positions. The
implementation focuses on chess middlegames, although
the approach may be applied to other types of positions
and even other domains. The Interactive Consultant for
Chess Middlegames (ICONCHESS), implemented in this
study, produces advice either by evaluating relevant
features of the specific position or by comparing the
position to a case base of well-studied chess positions.
The advice provided for a position can be presented in
different formats--summary, textual, and visual.
ICONCHESS uses a similarity metric based on high-level
features in order to retrieve relevant cases from the
case base. This similarity metric combines several
important chess features to characterize a chess
position. Fuzzy logic techniques are used to compute
some of the features that make up this metric and also
to combine those features into one final similarity
metric. Once a similar case is retrieved, a case
adaptation procedure is used to determine the sections
of the advice obtained from that case that can be
applied to the chess position under study.
In order to test the unique consultant environment
implement in ICONCHESS, an experiment was conducted to
determine its usefulness on different subjects. The main
results of the experiment follow: (1) the evaluation of
ICONCHESS given by the users was positive, particularly
the visual advice and the advice obtained from similar
cases; (2) the sessions with ICONCHESS helped most users
to improve their evaluation of chess positions; (3)
subjects profited from ICONCHESS at different levels;
and (4) subjects who had more than one session with
ICONCHESS had an easy time remembering how to use the
program in subsequent sessions. These results give a
preliminary indication that the approach used in
ICONCHESS is feasible and useful in a tutoring
environment for chess.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  3987 </NUMBER>
<ORDER>   AAI9607958 </ORDER>
<TITLE> NEURAL NETWORKS FOR NOISE-TOLERANT CATEGORY DISCRIMINATION WITH APPLICATION TO CONTINUOUS SPEECH SEGMENTATION </TITLE>
<AUTHOR> WILSON, FRANK D. M. </AUTHOR>
<YEAR> 1996 </YEAR>
<INSTITUTION> BOSTON UNIVERSITY; 0017 </INSTITUTION>
<DESCRIPTORS> ENGINEERING, ELECTRONICS AND ELECTRICAL; PSYCHOLOGY, EXPERIMENTAL; COMPUTER SCIENCE; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> GAIL A. CARPENTER </ADVISER>
<CLASSIFICATIONS> SPEECH RECOGNITION </CLASSIFICATIONS>
<ABSTRACT>
This dissertation develops neural networks to
distinguish similar categories in a noisy environment,
and shows how a hierarchy of neural network classifiers
can learn a long sequence as a series of smaller chunks.
These networks are applied to speech recognition
problems.
The word-level segmentation problem is to determine the
location of word boundaries, given a continuous speech
stream of words that have previously been learned in
isolation. This problem is addressed by a newly-
developed neural network that employs a hierarchy of
classification modules to recognize increasingly large
chunks of input (phonemes, syllables and words),
starting with segmented phonemes. The network employs
fast learning, top-down expectation, and a spatial
representation of temporal order. Since there are no
standard inter-word silences in continuous speech, and
since several syllables may be needed to disambiguate a
segmentation (e.g., "myself", "my selfish" and "I sell
fish"), the on-line segmentation problem is challenging.
When a temporally ordered stream of inputs is
represented as a spatial pattern, similar sequences are
hard to distinguish in a noisy environment. More
generally, small differences between similar inputs are
often important for correct classification in a
supervised learning environment. A new class of neural
networks is developed to address this problem, by
focussing attention on differences between ambiguous
categories, while ignoring common features. Several
architectural variants within this class are compared,
using different problems and noise profiles.
Improvements over existing supervised neural network
classifiers are demonstrated.
The final problem considered is to convert a speech
signal into a sequence of phonemes that form the input
to the word-level segmentation network. Noise and other
sources of variability in the signal make this a
difficult task. The approach to this problem commences
with preprocessing that divides the digitized speech
signal into a series of speech frames of fixed length
and computes a vector based on the information in each
frame. The vector may include, for example, a power
spectrum for the frame. Neural network models that learn
to predict the phoneme uttered during each frame are
explored.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  3988 </NUMBER>
<ORDER>   AAI9601719 </ORDER>
<TITLE> NEURAL NETWORKS FOR IMAGE PROCESSING, CLASSIFICATION, AND UNDERSTANDING </TITLE>
<AUTHOR> WILLIAMSON, JAMES ROY </AUTHOR>
<YEAR> 1996 </YEAR>
<INSTITUTION> BOSTON UNIVERSITY; 0017 </INSTITUTION>
<DESCRIPTORS> COMPUTER SCIENCE; ENGINEERING, SYSTEM SCIENCE; ENGINEERING, ELECTRONICS AND ELECTRICAL; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> ENNIO MINGOLLA </ADVISER>
<CLASSIFICATIONS> NIL </CLASSIFICATIONS>
<ABSTRACT>
Automatic processing of visual scenes by computers often
begins by detecting regions of an image with common
values of simple local features, such as brightness and
texture, and mapping the pattern of feature activation
into a predicted region label. Neural architectures for
extracting such local features, and for learning noisy
multidimensional mappings, are developed and combined
into a general purpose region classification system,
which is applied to real-world image classification
problems. These architectures include a network to
extract multiple-scale orientational contrast features,
which represent the local variations in image
intensities which make up image texture. Next, a
multiple-scale Boundary Contour System for boundary
segmentation and Feature Contour System for surface
representation are developed to process synthetic
aperture radar (SAR) images. The multi-scale BCS/FCS
locally normalizes image intensities and smooths over
noise while maintaining informative structures, at three
spatial scales. The scales are combined to produce a
multi-scale surface brightness representation that
improves image appearance for examination by human
observers.
A system for classifying image regions is then created
to operate on large-scale BCS/FCS features and multiple-
scale orientational contrast features. The
classification network, called Gaussian ARTMAP, learns
multidimensional mappings in real time. Gaussian ARTMAP
is shown to perform favorably in comparison to fuzzy
ARTMAP, particularly on noisy classification tasks, and
achieves a high accuracy on two challenging real-world
problems: classifying the region types of SAR images and
classifying Brodatz textures.
Another task for scene understanding is to recover 3-D
properties of objects based on their 2-D form cues. A
neural architecture called the Graph of Relations And
Form (GRAF) network is developed to perform 3-D shape
recovery by coding structural descriptions of objects.
In the GRAF network, neurons coding local form
attributes correspond to graph nodes, and neurons coding
relationships between them correspond to graph arcs.
Competitive linking of attributes, and subsequent depth
segmentation of linked structures, are demonstrated in
computer simulations.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  3989 </NUMBER>
<ORDER>   AAI9601695 </ORDER>
<TITLE> NEURAL NETWORK MODELS OF MOTOR TIMING AND COORDINATION </TITLE>
<AUTHOR> FIALA, JOHN CLIFFORD </AUTHOR>
<YEAR> 1996 </YEAR>
<INSTITUTION> BOSTON UNIVERSITY; 0017 </INSTITUTION>
<DESCRIPTORS> BIOLOGY, NEUROSCIENCE; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> DANIEL BULLOCK </ADVISER>
<CLASSIFICATIONS> NIL </CLASSIFICATIONS>
<ABSTRACT>
Purposive motor behavior in an animal or robot requires
simultaneous coordination of many degrees of freedom in
time and space. Due to continual changes in actor and
environment, such coordinative functions are adaptive.
This dissertation describes how networks of neurons
provide adaptive motor timing in response to predictive
stimuli, and adaptive coordination of multiple degrees
of freedom during visually-guided reaching.
The cerebellum adaptively times motor responses such
that conditioned responses (CRs) match external
constraints like the delivery of aversive unconditioned
stimuli (US). A neural model of this brain circuit
reproduces key physiological and behavioral features of
the conditioned nictitating membrane response in
rabbits, such as: The observed CR topography at the
nucleus interpositus (NI) with the NI response preceding
and the CR peak amplitude occurring at the expected US
onset time. During training, CR onset latency decreases,
CR amplitude increases, and climbing fiber activity
decreases. Maximal conditioning occurs at interstimulus
intervals (ISIs) of 200-400ms. The CR peak tracks ISI
changes, and mixed training at two ISIs produces a
double-peaked CR.
The cerebellar timing model suggests that Purkinje
neuron hyperpolarizing responses are timed by the
metabotropic glutamate receptor second messenger system.
Calcium dependency of the inositol trisphosphate
(IP$sb3$) receptor in the model generates characteristic
responses observed in phosphoinositide response systems,
as in invertebrate photoreceptors. Slow IP$sb3$
generation yields a delayed intracellular calcium signal
which drives a calcium-dependent potassium conductance
and releases NI from inhibition, allowing a timed CR for
ISIs of 80-4000ms. Conditioning occurs through the
phosphorylation/dephosphorylation processes of long-term
depression (LTD) and potentiation (LTP) at parallel
fiber-Purkinje synapses.
The straight lines of primate visually-guided reaches
are learned behaviors. Straight line trajectories
require the brain to transform the visually perceived
line into a nonlinear set of motor commands. An adaptive
network for learning the transformation from visual
space velocities to joint space velocities is obtained
by a gradient descent learning law. The learned mapping
is a singularity-robust pseudoinverse of the arm
Jacobian. A reaching model including this network
reproduces primate/human straight-line hand trajectories
with bell-shaped velocity profiles.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  3990 </NUMBER>
<ORDER>   AAI9536842 </ORDER>
<TITLE> COMPUTATIONAL LEARNING ALGORITHMS FOR GEOMETRIC AND ALGEBRAIC OBJECTS  </TITLE>
<AUTHOR> CHEN, ZHIXIANG </AUTHOR>
<YEAR> 1996 </YEAR>
<INSTITUTION> BOSTON UNIVERSITY; 0017 </INSTITUTION>
<DESCRIPTORS> COMPUTER SCIENCE; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> STEVEN HOMER </ADVISER>
<CLASSIFICATIONS> MACHINE LEARNING </CLASSIFICATIONS>
<ABSTRACT>
The goal of this thesis is to study the efficient
learnability of basic geometric and algebraic objects in
on-line learning models. Computational learning
algorithms for rectangles and unions of rectangles over
the domain $00,...,n-1sp0d$ are designed and analyzed.
We develop a bounded version of the powerful and
dominant design technique in recursion theory, the
finite injury priority method, and use it to construct
several concrete algorithms for learning unions of
rectangles. We design an algorithm for properly learning
rectangles over the domain (0, n $-$ 1) $sp0d$ with
$O(dsp2 log n)$ equivalence queries. For the problem of
learning unions of two rectangles, we design three
efficient algorithms. The first algorithm learns unions
of two disjoint rectangles over the domain (0, n $-$ 1)
$sp0d$ with equivalence queries and uses unions of two
rectangles as hypotheses. The second algorithm properly
learns unions of two rectangles over the domain (0, n $-
$ 1) $sp2$ with $O(logsp2 n)$ equivalence queries. The
third algorithm properly learns unions of two rectangles
over the domain (0, n $-$ 1) $sp0d$ with both
equivalence and membership queries. The query complexity
of this algorithm is optimal. We also design an
efficient algorithm for learning unions of rectangles
whose projections on some unknown dimension are pairwise
disjoint. When d is a constant, we show that unions of
rectangles over the domain (0, n $-$ 1) $sp0d$ are
efficiently learnable with equivalence queries.
Next we study the problem of learning DNF formulas with
equivalence queries and incomplete membership queries.
We show that there is a subclass of k-term DNF formulas
for nonconstant k such that one can learn any formula in
this class with high probability.
Finally we study the problem of learning disjunctions of
counting functions with modulus q over the domain
$Zsbsp0q0n$. We show that for any prime q, one can learn
disjunctions of counting functions over the domain
$Zsbsp0q0n$ with at most n + 1 queries. We prove that
the problem of learning disjunctions of negated counting
functions is in general harder than learning DNF
formulas. However, we also show that efficient
algorithms exist for this problem when the modulus is a
constant prime, or when the modulus is a prime and the
number of negated functions is bounded.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  3991 </NUMBER>
<ORDER>   AAG9725655 </ORDER>
<TITLE> FUZZY MODELING AND CONTROL: A CHARACTERISTIC-POINT APPROACH  </TITLE>
<AUTHOR> YIN, TANG-KAI </AUTHOR>
<YEAR> 1996 </YEAR>
<INSTITUTION> PURDUE UNIVERSITY; 0183 </INSTITUTION>
<DESCRIPTORS> ENGINEERING, ELECTRONICS AND ELECTRICAL; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> C. S. G. LEE </ADVISER>
<CLASSIFICATIONS> STABILITY ANALYSIS </CLASSIFICATIONS>
<ABSTRACT>
This thesis proposes fuzzy inference systems (FISs) as a
systematic method to model the input-output relationship
of complex systems and their control. Characteristic
points (CPs) which are a subset of given input-output
data pairs can be used for establishing fuzzy rules of
the system. With the CPs, a characteristic-point-based
fuzzy inference system (CPFIS) is proposed to
systematically construct FISs with two distinct
features: maximum and minimum fuzzy rules which are
related to the interpolation property of human
reasoning, and their employment for the interpolation
property, resulting in a small fuzzy-rule base for high-
dimensional systems.
Employing the CPFIS, a characteristic-point-based fuzzy
control system (CPFCS) is proposed to control time-
invariant, multi-input-multi-output plants. The CPFCS
emulates the learning control of human operators in
performing repetitive control operations with gradual
improvement in the control performance. Besides the
employment of CPFISs, the desired highest derivatives
are synthesized to make the CPFCS perform as a
generalized proportional-integral-derivative controller.
If some conservative bounds can be established on the
approximation errors of the constructed CPFIS, the
controller can be further designed to have ultimate
boundedness of the output tracking via a variable-
structure-control method. A novel desired-highest-
derivative-assignment controller, which is constructed
on the forward-inverse-function-approximation error
bounds, integrates fuzzy modeling and control to provide
stability analysis of the overall system. Computer
simulations were conducted on many examples to
demonstrate the operations of the proposed CPFIS, CPFCS,
and the integrated-fuzzy-modeling-and-control scheme.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  3992 </NUMBER>
<ORDER>   AAG9725619 </ORDER>
<TITLE> A DYNAMIC NEURAL NETWORK FOR NONLINEAR PROCESS MODELING AND CONTROL </TITLE>
<AUTHOR> SHAW, ANDRE MCARTHUR </AUTHOR>
<YEAR> 1996 </YEAR>
<INSTITUTION> PURDUE UNIVERSITY; 0183 </INSTITUTION>
<DESCRIPTORS> ENGINEERING, CHEMICAL; ENGINEERING, MECHANICAL; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> FRANCIS J. DOYLE, III </ADVISER>
<CLASSIFICATIONS> NIL </CLASSIFICATIONS>
<ABSTRACT>
A novel approach, which uses intrinsically dynamic
neurons inspired from biological control systems, is
presented in this work for input/output modeling of
nonlinear dynamical processes. The network structure
containing these dynamic nodes, with nonlinear weights
in a feedback architecture, is called the Recurrent
Dynamic Neuron Network (RDNN).
For SISO applications the RDNN is shown to have
arbitrary dynamic order $n le N$ (where N is the number
of neurons) and relative degree $r = 1$. CSTR case
studies show that the RDNN does an excellent job of
predicting nonlinearities such as asymmetric dynamic
response and significantly outperforms linear models and
more traditional neural network models in open-loop
simulations. Input-output linearization (IOL) techniques
are used to globally linearize the RDNN for use within
the internal model control (IMC) framework. Closed-loop
simulations with these CSTR examples show that the RDNN
performs robustly when used within this control
framework.
For MIMO applications the RDNN is shown to have
arbitrary dynamic order $n le N$, vector relative degree
$underbrace0(1cdots1)limitssb010timesM$ (where M is the
number of outputs), and is able to represent systems
with input multiplicities. A binary distillation column
case study demonstrates that the RDNN performs well in
both open- and closed-loop simulations. For this 2 x 2
MIMO application, open-loop simulations show that the
RDNN predicts the asymmetric nonlinear output responses.
The RDNN is shown to be easily implemented in MIMO model-
based control applications including model predictive
control (MPC) and IOL/IMC. Simulations show that a
combination of closed-loop and open-loop identification
for the RDNN model results in a model-based controller
which achieves robust control performance. Linearized
optimal control and nonlinear optimal control MPC
applications are implemented, with both performing
comparably.
Finally, the RDNN is used to model and control the
reactor/regenerator section of the Amoco model IV FCCU.
For this 4 x 4 control problem, the RDNN model performed
well in both open- and closed-loop simulations. For
closed-loop simulations the linearized optimal MPC
approach is implemented. The performance is excellent
for both disturbance rejection and setpoint tracking
simulations.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  3993 </NUMBER>
<ORDER>   AAG9725617 </ORDER>
<TITLE> A FUZZY SYSTEMS APPROACH TO STRUCTURAL DAMAGE DETECTION AND IDENTIFICATION </TITLE>
<AUTHOR> SAWYER, JAMES PATRICK </AUTHOR>
<YEAR> 1996 </YEAR>
<INSTITUTION> PURDUE UNIVERSITY; 0183 </INSTITUTION>
<DESCRIPTORS> ENGINEERING, MECHANICAL; ENGINEERING, AEROSPACE; ENGINEERING, CIVIL; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> S. S. RAO </ADVISER>
<CLASSIFICATIONS> FRACTURE </CLASSIFICATIONS>
<ABSTRACT>
Although improved design methodologies have
significantly enhanced the reliability and safety of
structures in recent years, it is still not possible to
build structures that are infallible. There is an
increasing interest in the development of smart
structures with built-in fault detection systems that
would provide failure warnings. This thesis presents
general methodologies for structural damage detection
and assessment using fuzzy systems theory. The approach
to damage detection is based on monitoring various
system responses to determine the health status of a
structure or machine. Fuzzy logic rules encoded in a
fuzzy associative memory are used to identify the
location and extent of the damage in terms of stiffness
reduction. The use of both global and local responses,
including eigenvalues, static displacements and strain
measurements are investigated. The damage detection
methodology is demonstrated through examples including a
simple fixed-free beam, truss structures and an aircraft
wing model. Once damage is detected, it must be
identified and assessed. Fuzzy computational methods for
translating fuzzy stiffness reduction into fuzzy
geometric damage parameters are presented. These methods
are based on fracture mechanics for crack damage and a
simple hole damage model for more general forms of
damage. Several examples of determining a fuzzy crack
length for a given fuzzy reduction in local stiffness
are presented, including edge cracked beams and plates.
The application of the hole damage model is demonstrated
in the analysis if damaged flat rectangular and
cylindrical shell membrane components. Damage tolerance
techniques based on fuzzy parameters are developed for
damage assessment. The criticality of fuzzy fractures is
evaluated through comparisons of fuzzy stress
intensities and fracture toughness measures. Similarly,
the residual strength of damaged structures are assessed
through comparisons of fuzzy stress and strength values.
The notion of a fuzzy factor of safety is also
introduced. The proposed methodologies represent unique
approaches to damage detection, identification and
assessment that can be applied to a variety of
structures used in mechanical, aerospace and civil
engineering applications.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  3994 </NUMBER>
<ORDER>   AAG9725555 </ORDER>
<TITLE> PROBABILISTIC FEATURE EXTRACTION FOR OBJECT RECOGNITION </TITLE>
<AUTHOR> HENSTOCK, PETER VAUGHAN </AUTHOR>
<YEAR> 1996 </YEAR>
<INSTITUTION> PURDUE UNIVERSITY; 0183 </INSTITUTION>
<DESCRIPTORS> ENGINEERING, ELECTRONICS AND ELECTRICAL; COMPUTER SCIENCE; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> DAVID M. CHELBERG </ADVISER>
<CLASSIFICATIONS> EDGE EVALUATION, OPTICAL CHARACTER RECOGNITION </CLASSIFICATIONS>
<ABSTRACT>
In most object recognition systems, features are
extracted from an image, grouped into hypotheses, and
matched against a model database. The constructed
hypotheses are usually formed in a multi-level hierarchy
of features from the lower level pixels into higher
level geometric features. Many existing systems include
a statistical or heuristic measure of the hypothesized
features formed at a given level but do not consider the
measure of the underlying features of lower levels in
the hierarchy. By incorporating a statistical likelihood
measure at each level of the hierarchy from the lower
level to higher level features, the overall accuracy and
speed of the system can be improved. The system can also
provide a final measure representing the strength of a
match between the image and a given model object that
cannot be calculated accurately in other systems. The
feature extraction task has been divided into several
steps. The first step extracts a set of edge pixel
hypotheses from an image using a statistical model of
edges. The edge pixel hypotheses are then grouped into
straight line edge hypotheses, or curves represented by
splines using a unified statistical model. Using the
edge model, the features can not only be evaluated but
can also be improved to increase the accuracy of the
system. The benefits of statistically measuring the
features at each step is demonstrated with a OCR program
for Korean Hangul.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  3995 </NUMBER>
<ORDER>   AAGMM19256 </ORDER>
<TITLE> MACHINE LEARNING AS A QUALITY IMPROVEMENT TOOL </TITLE>
<AUTHOR> HOUSER, DAVID ALLAN </AUTHOR>
<YEAR> 1996 </YEAR>
<INSTITUTION> UNIVERSITY OF TORONTO (CANADA); 0779 </INSTITUTION>
<DESCRIPTORS> ENGINEERING, CHEMICAL; ENGINEERING, INDUSTRIAL; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> W. R. CLUETT </ADVISER>
<CLASSIFICATIONS> NIL </CLASSIFICATIONS>
<ABSTRACT>
This thesis presents an improved methodology for
developing quality improvement suggestions from
production rule models developed by a machine learning
algorithm, specifically C4.5. First a search through all
of the models developed in a cross-validation is
performed to extract all of the rules which predict the
desired condition of the quality variable. These models
have been constructed to minimize the error of the rules
for predicting the desired condition, as opposed to the
overall model error. The individual rules are then
ranked to determine their usefulness for quality
improvement. This procedure is applied to an industrial
emulsion manufacturing process to develop quality
improvement suggestions for producing a higher, more
consistent finished product viscosity.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  3996 </NUMBER>
<ORDER>   AAG9725544 </ORDER>
<TITLE> IMAGE COMPRESSION AND SIGNAL CLASSIFICATION BY NEURAL NETWORKS AND PROJECTION PURSUIT </TITLE>
<AUTHOR> FARDANESH, MANSOUR </AUTHOR>
<YEAR> 1996 </YEAR>
<INSTITUTION> PURDUE UNIVERSITY; 0183 </INSTITUTION>
<DESCRIPTORS> ENGINEERING, ELECTRONICS AND ELECTRICAL; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> OKAN K. ERSOY </ADVISER>
<CLASSIFICATIONS> NIL </CLASSIFICATIONS>
<ABSTRACT>
In this thesis, two applications of neural networks are
investigated. The first one is low bit rate image
compression by using neural networks and projection
pursuit. The second one is improving the classification
accuracy of neural network classifiers by using
unlabeled data.
In the first part, a novel approach for low bit rate
image coding is presented. The image is compressed by
first quadtree segmenting the image into blocks of
different sizes based on two activity measures, and then
constructing a distinct code for each block by invoking
the theory of projection pursuit. The two activity
measures used in this work are the block variance and
the peak signal to noise ratio (PSNR) of the
reconstructed block. It is shown that the projection
pursuit coding algorithm can adaptively construct a
better approximation for each block until the desired
signal to noise ratio or bit rate is achieved. This
method also adaptively finds the optimum network
configuration. Experimental values for the objective
measure of performance using PSNR are superior to the
JPEG decoded images. The subjective quality of the
encoded images with the proposed algorithm are also
superior to the JPEG encoded images.
In the second part, classification accuracy improvement
of neural network classifiers using unlabeled testing
data is presented. In order to fully utilize the
information contained in high dimensional data, training
samples are needed from all classes. In order to
increase classification accuracy without increasing the
number of training samples, the network makes use of
testing data along with training data for learning.
However, the testing data are unlabeled whereas the
training data are labeled. It was shown previously for
the case of parametric classifiers that decision rules
which use both labeled (training) and unlabeled
(testing) samples have a lower expected error than those
which use labeled samples only. Since the output of a
neural network such as backpropagation network
approximates the a posteriori probabilities, the same
result applies to neural network classifiers. It is
shown that including unlabeled samples from under-
represented classes in the training set improves the
classification accuracy of some of the classes during
supervised-unsupervised learning.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  3997 </NUMBER>
<ORDER>   AAG9725535 </ORDER>
<TITLE> DKIT: A BLACKBOARD-BASED, DISTRIBUTED, MULTI-EXPERT ENVIRONMENT FOR ABNORMAL SITUATION MANAGEMENT </TITLE>
<AUTHOR> DINKAR, MYLARASWAMY </AUTHOR>
<YEAR> 1996 </YEAR>
<INSTITUTION> PURDUE UNIVERSITY; 0183 </INSTITUTION>
<DESCRIPTORS> ENGINEERING, CHEMICAL; ARTIFICIAL INTELLIGENCE; ENGINEERING, INDUSTRIAL </DESCRIPTORS>
<ADVISER> V. VENKATASUBRAMANIAN </ADVISER>
<CLASSIFICATIONS> FAULT DIAGNOSIS, FLUID CATALYTIC CRACKING, NEURAL NETWORK </CLASSIFICATIONS>
<ABSTRACT>
Abnormal situation management (ASM) involves timely
detection, diagnosis and correction of abnormal process
conditions. Industrial statistics estimate the economic
impact due to abnormal situations to be about $10
billion per year in the petrochemical industries in the
U.S. alone. Process fault diagnosis, which forms the
first step in ASM, deals with detection and analysis of
root causes of abnormal behavior. Most diagnostic
methods studied in literature tend to be restricted in
their scope of application leading to the inadequacy of
a single diagnostic method in meeting all the
requirements of a good diagnostic system. Designing a
hybrid framework based on collective problem solving is
the theme of this thesis. A blackboard-based,
distributed diagnostic tool kit called DKit was
developed in this thesis for online real time process
fault diagnosis and abnormal situation management in
general.
First, a set of desirable features is identified for a
good diagnostic system. Different diagnostic methods are
compared based on the form of process knowledge used.
The inadequacy of a single method to meet all the
features is the motivation for designing collective
problem solving-based strategies. Second, a blackboard-
based framework (DKit) is proposed and developed as an
attractive alternative to individual diagnostic methods.
DKit is possibly the first concrete realization of
integration concepts for large scale process fault
diagnosis. Key components of DKit, namely, the
diagnostic methods and a scheduler which coordinates the
function of different diagnostic experts are discussed
in detail. A hierachical design for the scheduler with
model-based digraph diagnosis at the bottom is proposed
in the current design of DKit. Third, a fluid catalytic
cracking unit-based testbed (called CATSIM) is developed
for comprehensive testing of the proposed framework. The
utility of DKit is shown through simulation runs. A
hybrid neural network which combines process model
information with history data for better fault diagnosis
is proposed as a general framework for enhancing
diagnosis by using all available process knowledge.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  3998 </NUMBER>
<ORDER>   AAG9724796 </ORDER>
<TITLE> AUTOMATIC LANGUAGE IDENTIFICATION WITH SEQUENCES OF LANGUAGE-INDEPENDENT PHONEME CLUSTERS </TITLE>
<AUTHOR> BERKLING, KAY MARGARETHE </AUTHOR>
<YEAR> 1996 </YEAR>
<INSTITUTION> OREGON GRADUATE INSTITUTE OF SCIENCE & TECHNOLOGY; 0284 </INSTITUTION>
<DESCRIPTORS> COMPUTER SCIENCE; ARTIFICIAL INTELLIGENCE; ENGINEERING, ELECTRONICS AND ELECTRICAL; LANGUAGE, LINGUISTICS </DESCRIPTORS>
<ADVISER> ETIENNE BARNARD </ADVISER>
<CLASSIFICATIONS> SPEECH RECOGNITION, FEATURE EXTRACTION, LINGUISTIC </CLASSIFICATIONS>
<ABSTRACT>
Automatic Language Identification involves analyzing
language-specific features in speech to determine the
language of an utterance without regard to topic,
speaker or length of speech. Although much progress has
been made in recent years, language identification
systems have not been built on detailed underlying
theory or linguistically meaningful design criteria.
This thesis is motivated by the belief that features
used to discriminate between languages should be
linguistically sound; the result is a unique combination
of design, theory and implementation.
In this thesis a "word-spotting" algorithm is introduced
motivated by a perceptual study (82) reporting that
human subjects use language-dependent phonemes and short
sequences to identify languages. In order to find an
optimal set of phoneme-like tokens to represent speech
in a linguistically meaningful way, a mathematical model
of the discrimination between two languages is
developed. This model permits the automatic design of a
token representation of speech by selecting a list of
discriminating "words" in a data-driven manner. The
resulting system has the flexibility to automatically
take into account the inherent structure of the
Languages to be discriminated. A second mathematical
model is developed to measure the impact of inaccurate
automatic alignment of tokens on language
discrimination. This model indicates why some algorithms
aiming to compensate for these inaccuracies have not
been successful. The theoretical models and the "word"-
spotting algorithm have been implemented and validated
on both generated and real-world speech data.
This dissertation makes several significant
contributions: the design of a simple and linguistically
sound language-identification module; a flexible
automatic feature extraction algorithm; a mathematical
model to estimate the discriminability of two languages;
and a mathematical model to capture the impact of
inaccurate alignment on the discriminability of two
languages.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  3999 </NUMBER>
<ORDER>   AAG0597956 </ORDER>
<TITLE> COMMUNICATIVE HUMANOIDS: A COMPUTATIONAL MODEL OF PSYCHOSOCIAL DIALOGUE SKILLS </TITLE>
<AUTHOR> THORISSON, KRISTINN RUNAR </AUTHOR>
<YEAR> 1996 </YEAR>
<INSTITUTION> MASSACHUSETTS INSTITUTE OF TECHNOLOGY; 0753 </INSTITUTION>
<DESCRIPTORS> COMPUTER SCIENCE; ARTIFICIAL INTELLIGENCE; LANGUAGE, LINGUISTICS </DESCRIPTORS>
<ADVISER> JUSTINE CASSELL </ADVISER>
<CLASSIFICATIONS> FACE TO FACE </CLASSIFICATIONS>
<ABSTRACT>
Face-to-face interaction between people is generally
effortless and effective. We exchange glances, take
turns speaking and make facial and manual gestures to
achieve the goals of the dialogue. Endowing computers
with such an interaction style marks the beginning of a
new era in our relationship with machines--one that
relies on communication, social convention and dialogue
skills. This thesis presents a computational model of
psychosocial dialogue expertise, bridging between
perceptual analysis of multimodal events and multimodal
action generation, supporting the creation of interfaces
that afford full-duplex, real-time face-to-face
interaction between a human and autonomous computer
characters. The architecture, called Ymir, has been
implemented in software, and a prototype humanoid
created. The humanoid, named Gandalf, commands a
graphical model of the solar system, and can interact
with people using speech, manual and facial gesture.
Gandalf has been tested in interaction with users and
has been shown capable of fluid face-to-face dialogue.
The prototype demonstrates several new ideas in the
creation of communicative computer agents, including
perceptual integration of multimodal events, distributed
processing and decision making, layered input analysis
and motor control, and the integration of reactive and
reflective perception and action. Applications of the
work presented in this thesis can be expected in such
diverse fields as education, psychological and social
research, work environments, and entertainment. (Copies
available exclusively from MIT Libraries, Rm. 14-0551
Cambridge, 02139-4307. Ph. 617-253-5668; Fax 617-253-
1690.)
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  4000 </NUMBER>
<ORDER>   AAG9726848 </ORDER>
<TITLE> A LONGITUDINAL STUDY OF NETWORK AND INDIVIDUAL PERFORMANCE IN DISTRIBUTED DESIGN GROUPS </TITLE>
<AUTHOR> AHUJA, MANJU K. </AUTHOR>
<YEAR> 1996 </YEAR>
<INSTITUTION> UNIVERSITY OF PITTSBURGH; 0178 </INSTITUTION>
<DESCRIPTORS> BUSINESS ADMINISTRATION, MANAGEMENT; INFORMATION SCIENCE; ENGINEERING, INDUSTRIAL </DESCRIPTORS>
<ADVISER> NIL </ADVISER>
<CLASSIFICATIONS> EMAIL </CLASSIFICATIONS>
<ABSTRACT>
Distributed groups, that use email to communicate and
coordinate their work toward a common goal, are growing
in popularity. In this longitudinal field study, the
linkages among task uncertainty (routineness), network
structure and network performance in such distributed
groups are examined. Also analyzed here is the mediating
effect of individual centrality on the relationship
between individual characteristics (role, status, and
information flow) and (individual) performance.
The research site is a distributed group engaged in
research and design of a general purpose artificial
intelligence architecture. A framework was developed to
analyze email messages sent and received in the summers
of 1989 and 1993. Messages were classified by task,
information flow, senders, and receivers.
A social networks of view of structure is adopted. Email
exchange among the group members is analyzed to
determine network structure. Structure is measured in
terms of network measures of degree of hierarchy,
centralization and hierarchical levels.
Results show that in a distributed group, a fit between
degree of hierarchy and organizational task routineness
is associated with perceived performance. The fit
between network centrality and organizational task
routineness is also associated with perceived
performance. The linkage between communication task
routineness and network structure was associated with
objective performance measures.
Individual centrality had a partial mediating effect on
the relationship between individual characteristics and
individual performance. Centrality completely mediated
the relationship between information flow and
performance. The study concludes that as distributed
groups become more hierarchical, the mediating effect of
centrality becomes more prominent in predicting
performance of individuals in the group.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  4001 </NUMBER>
<ORDER>   AAG9724348 </ORDER>
<TITLE> DESIGN OF MAN-MACHINE DECISION SYSTEMS: AN APPLICATION OF CASE-BASED REASONING TO PORTFOLIO MANAGEMENT </TITLE>
<AUTHOR> MORTAGY, YEHIA K. </AUTHOR>
<YEAR> 1996 </YEAR>
<INSTITUTION> THE CLAREMONT GRADUATE SCHOOL; 0047 </INSTITUTION>
<DESCRIPTORS> INFORMATION SCIENCE; ARTIFICIAL INTELLIGENCE; BUSINESS ADMINISTRATION, MANAGEMENT </DESCRIPTORS>
<ADVISER> NIL </ADVISER>
<CLASSIFICATIONS> NIL </CLASSIFICATIONS>
<ABSTRACT>
This dissertation investigates the hypothesis that
supporting decision makers by complementing imperfect
cognitive processes will result in better decisions, and
in turn in better Decision Support Systems. Results
strongly supported the hypothesis.
Prior research has questioned the degree of success of
Decision Support Systems. This dissertation suggests
that some of the failure may be due to the present
design philosophy of simplifying the problem
representation in order to use rational and mathematical
problem solving techniques. This approach results in two
disadvantages: (1) It solves a problem different than
the actual problem. (2) It forces the decision maker to
implement a problem solving method different than that
(s)he would have commonly utilized, i.e. analogical
decision making.
Analogical decision making has evolved over years of
human development and has proven successful in keeping
humans from extinction. As such, supporting this
approach instead of replacing it is a logical approach.
Analogical decision making has its own disadvantages,
and weaknesses. Psychologists, AI researchers and
political scientists have identified many of these
weaknesses. For example, satisficing, Heuristics and the
attribution theory. This research identifies these
weaknesses and designs a Decision Support System that
complements analogical decision making, and implements
it in the portfolio management domain.
Portfolio management proved to be an excellent domain
for the research. It is the same domain considered in
pioneering work in DSS. There are several portfolio
management implementations using different decision
approaches, and since there are objective measures used
in gauging success it is possible to compare these
approaches. The domain is time dependent. The temporal
dimension was utilized in this research. Finally, there
is a wealth of historical data that can be used.
Three variables were measured in this dissertation: The
decision outcome, the quality of the decision making
process, and the user satisfaction with the tool, i.e.,
the decision support system. The findings are extremely
encouraging. The decision making approach proved
superior to the other approaches (by a factor of two).
The quality of the decision making process, both
objectively and subjectively, proved better than an
identical decision support system without the analogical
decision making support module. Finally, users were more
satisfied with the proposed decision support system.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  4002 </NUMBER>
<ORDER>   AAG1383776 </ORDER>
<TITLE> EXPERT SYSTEM FOR MONITORING AND DIAGNOSIS OF NETWORKED UNIX WORKSTATIONS </TITLE>
<AUTHOR> LEWIS, JAMES EUGENE </AUTHOR>
<YEAR> 1996 </YEAR>
<INSTITUTION> UNIVERSITY OF LOUISVILLE; 0110 </INSTITUTION>
<DESCRIPTORS> COMPUTER SCIENCE; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> JAMES H. GRAHAM </ADVISER>
<CLASSIFICATIONS> NIL </CLASSIFICATIONS>
<ABSTRACT>
Because of the growth of network computing, there is s a
high demand for System Administrators for these
networks. In the field of UNIX workstations there are
many variants of the UNIX operating system. In order to
assist System Administrators, the Sys$sb-$Admin$sb-$Tool
was created. The Sys$sb-$Admin$sb-$Tool is a monitoring
system, diagnosis system and a guidance system for UNIX
workstations, particularly workstations with the Hewlett-
Packard UNIX (HP-UX) operating system. The design and
development of this tool began in 1996 at the University
of Louisville in Louisville, KY. The graphical user
interface, the monitoring system, and the intelligent
system presented in this thesis are the underlying parts
to the Sys$sb-$Admin$sb-$Tool.
The intelligent system uses a CLIPS expert system and a
knowledge base of CLIPS rules. The graphical user
interface was written in the C programming language,
using the Motif version 1.2 C library functions. The
monitoring system was written in a combination of C and
UNIX scripts. The principles and implementation of the
graphical user interface, the monitoring system and the
intelligent system are presented in this thesis. Also
presented are: a user's manual, and the proper way to
embed CLIPS function calls in a C program.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  4003 </NUMBER>
<ORDER>   AAG1383197 </ORDER>
<TITLE> ARTIFICIAL INTELLIGENCE IN AUTOMATIC DIMENSIONING LAYOUT </TITLE>
<AUTHOR> PABON IRIZARRY, ISRAEL ULISES </AUTHOR>
<YEAR> 1996 </YEAR>
<INSTITUTION> UNIVERSITY OF PUERTO RICO, MAYAGUEZ (PUERTO RICO); 0553 </INSTITUTION>
<DESCRIPTORS> ENGINEERING, MECHANICAL; ENGINEERING, SYSTEM SCIENCE; COMPUTER SCIENCE; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> FERNANDO BENITEZ </ADVISER>
<CLASSIFICATIONS> NIL </CLASSIFICATIONS>
<ABSTRACT>
Sophisticated computer aided design and drafting (CADD)
systems can automatically generate dimensioning
information yet still require user intervention for
proper positioning of the dimensions in the drawing
layout. The dimension generation and location process is
in average a two steps process. This becomes an
inefficient use of the designer's time specially when a
drawing has several hundred objects.
This thesis main goal was to investigate how
dimensioning layout is performed in CADD systems and
ways to improve it. From this research the general rules
for the automatization of the dimensioning layout
process were determined. These rules serve as basis for
an intelligent, automatic dimensioning layout (ADL)
method. Such a method uses knowledge based optimization
to find proper dimension locations in a well organized
position with respect to the drawing layout. This method
saves time and makes computer based design and drafting
process a more productive and user friendly activity.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  4004 </NUMBER>
<ORDER>   AAG9723520 </ORDER>
<TITLE> INTEGRATING CASE-BASED AND RULE-BASED REASONING IN KNOWLEDGE-BASED SYSTEMS DEVELOPMENT </TITLE>
<AUTHOR> MARLING, CYNTHIA ROBIN </AUTHOR>
<YEAR> 1996 </YEAR>
<INSTITUTION> CASE WESTERN RESERVE UNIVERSITY; 0042 </INSTITUTION>
<DESCRIPTORS> COMPUTER SCIENCE; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> LEON STERLING </ADVISER>
<CLASSIFICATIONS> EXPERT SYSTEMS, ARTIFICIAL INTELLIGENCE </CLASSIFICATIONS>
<ABSTRACT>
Case-based reasoning (CBR) and rule-based reasoning
(RBR) are two paradigms for building knowledge-based
systems. They represent distinct approaches to knowledge-
based systems development and distinct cognitive models
of human problem solving. To date, they have been viewed
as competing, rather than complementary, paradigms. This
research shows that combining CBR with RBR leads to a
stronger approach to knowledge-based systems
development.
The research approach is to construct, compare and
contrast two expert systems, one case-based and one rule-
based, to perform the same task. While claims have been
made as to the relative advantages of each approach,
this is the first systematic comparison of independent
CBR and RBR systems built in the same domain. Strengths
and weaknesses of each system are identified, and the
best of both systems are combined in a hybrid system.
The domain of study is nutritional menu planning. This
domain: (1) presents an AI challenge. Human experts
consistently outperform computer systems in planning
nutritious and appetizing menus. (2) poses a difficult
problem. Unsuccessful attempts to build computer-
assisted menu planners date back thirty years. (3) has
supportive experts available to assist with system
construction and evaluation.
Contributions of the dissertation are: (1) a new
approach to CBR/RBR hybridization, in which cases
contribute toward constraint satisfaction and rules
contribute toward achievement of personal preference
goals; (2) a new CBR metric for identifying and
retrieving reusable cases, based on ease of adaptation;
(3) a public domain nutritional menu planning system,
accessible via the World Wide Web; (4) a framework for
building special purpose therapeutic menu planning
systems for use in the prevention and treatment of
disease; (5) a case base of menus meeting guidelines for
sound nutrition and aesthetic standards for color,
texture, temperature and taste; (6) a new adaptation
strategy for adjusting serving sizes in menus; (7) a
deeper understanding of the distinctions between CBR and
RBR and the relative strengths and weaknesses of the two
paradigms.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  4005 </NUMBER>
<ORDER>   AAG9722929 </ORDER>
<TITLE> VLSI IMPLEMENTATION OF CELLULAR NEURAL NETWORKS </TITLE>
<AUTHOR> CRUZ-MORENO, JOSE MARIA </AUTHOR>
<YEAR> 1996 </YEAR>
<INSTITUTION> UNIVERSITY OF CALIFORNIA, BERKELEY; 0028 </INSTITUTION>
<DESCRIPTORS> ENGINEERING, ELECTRONICS AND ELECTRICAL; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> LEON O. CHUA </ADVISER>
<CLASSIFICATIONS> CHARACTER RECOGNITION, MACHINE VISION, CHIP ARCHITECTURE </CLASSIFICATIONS>
<ABSTRACT>
This dissertation studies the implementation of cellular
neural networks (CNNs) in a very large scale integration
(VLSI) technology.
This dissertation is divided into seven chapters.
Chapter 1 presents the ideal models of the following
architectures: (a) fixed template CNN; (b) universal CNN
with programmable weights and local memory and logic;
and (c) higher-order CNN.
Chapter 2 presents a procedure for the implementation of
fixed template CNN cells in a VLSI technology. We
illustrate the procedure by a case design of a CNN cell
to perform connected component detection, an image
operation with application in machine character
recognition.
Chapter 3 presents two complete fixed template CNN
chips. One of the chips, with 48 cells, was the world-
first working CNN chip. The other, with 550 cells, is
optimized for speed. It has a time constant as low as 64
ns, and it is currently the world-fastest CNN chip.
Experimental results are included for both chips.
Chapter 4 presents the implementation of a universal CNN
chip. The chip contains a 16 x 16 array of cells with
analog inputs and analog outputs. It is the world-first
implementation that can perform processing of gray-scale
images. In this chapter we also present the architecture
of cache memory chips.
Chapter 5 provides a detailed description of the
operation of the universal CNN chip presented in Chapter
4, including the pinout, the operation sequence, and
experimental results.
Chapter 6 presents the implementation of a third-order
CNN cell based on Chua's circuit, which can be used as a
basic element for future CNN arrays with complex
dynamics. The cell can exhibit a broad spectrum of
nonlinear dynamical phenomena, including bifurcation and
chaos. Experimental results are included.
Chapter 7 gives some concluding remarks and gives areas
of future work related to this research.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  4006 </NUMBER>
<ORDER>   AAGMM18578 </ORDER>
<TITLE> EXPERT-SYSTEM AIDED CONTROLLER DESIGN: USER INTERFACE TO THE BAILEY INFI 90 </TITLE>
<AUTHOR> SERES, PAVOL </AUTHOR>
<YEAR> 1996 </YEAR>
<INSTITUTION> THE UNIVERSITY OF NEW BRUNSWICK (CANADA); 0823 </INSTITUTION>
<DESCRIPTORS> ENGINEERING, ELECTRONICS AND ELECTRICAL; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> M. E. KAYE; J. H. TAYLOR </ADVISER>
<CLASSIFICATIONS> NIL </CLASSIFICATIONS>
<ABSTRACT>
This report presents a new approach for controller
design and test using the complex and powerful control
system implementation environment scINFI 90. An expert
system, called the Design Advisor for Implementing
Systems (DAIS), was developed to collect information
about the system to be controlled from the user, and
then build an appropriate internal model. An option of
system identification from measured step response is
also provided. According to the user's specifications on
the control system behaviour (e.g. overshoot the user
would tolerate, or desired relative stability margins)
the expert system then selects the appropriate control
algorithm or a set of possible controllers available
from the scINFI 90 and sets the controller parameters.
DAIS gives warning messages in case the implementation
constraints are violated. The user can fine-tune the
controller, based on immediate simulation results. The
system was successfully tested on a laboratory setup of
a temperature control system.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  4007 </NUMBER>
<ORDER>   AAG9722679 </ORDER>
<TITLE> A GRAMMAR-BASED TECHNIQUE FOR GENETIC SEARCH AND OPTIMIZATION  </TITLE>
<AUTHOR> JOHNSON, CLAYTON MATTHEW </AUTHOR>
<YEAR> 1996 </YEAR>
<INSTITUTION> THE COLLEGE OF WILLIAM AND MARY; 0261 </INSTITUTION>
<DESCRIPTORS> COMPUTER SCIENCE; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> STEFAN FEYOCK </ADVISER>
<CLASSIFICATIONS> ARTIFICIAL INTELLIGENCE </CLASSIFICATIONS>
<ABSTRACT>
The genetic algorithm (GA) is a robust search technique
which has been theoretically and empirically proven to
provide efficient search for a variety of problems. Due
largely to the semantic and expressive limitations of
adopting a bitstring representation, however, the
traditional GA has not found wide acceptance in the
Artificial Intelligence community. In addition, binary
chromosones can unevenly weight genetic search, reduce
the effectiveness of recombination operators, make it
difficult to solve problems whose solution schemata are
of high order and defining length, and hinder new schema
discovery in cases where chromosome-wide changes are
required.
The research presented in this dissertation describes a
grammar-based approach to genetic algorithms. Under this
new paradigm, all members of the population are strings
produced by a problem-specific grammar. Since any
structure which can be expressed in Backus-Naur Form can
thus be manipulated by genetic operators, a grammar-
based GA strategy provides a consistent methodology for
handling any population structure expressible in terms
of a context-free grammar.
In order to lend theoretical support to the development
of the syntactic GA, the concept of a trace schema--a
similarity template for matching the derivation traces
of grammar-defined rules--was introduced. An analysis of
the manner in which a grammar-based GA operates yielded
a Trace Schema Theorem for rule processing, which states
that above-average trace schemata containing relatively
few non-terminal productions are sampled with increasing
frequency by syntactic genetic search. Schemata thus
serve as the "building blocks" in the construction of
the complex rule structures manipulated by syntactic
GAs.
As part of the research presented in this dissertation,
the GEnetic Rule Discovery System (GERDS) implementation
of the grammar-based GA was developed. A comparison
between the performance of GERDS and the traditional GA
showed that the class of problems solvable by a
syntactic GA is a superset of the class solvable by its
binary counterpart, and that the added expressiveness
greatly facilitates the representation of GA problems.
To strengthen that conclusion, several experiments
encompassing diverse domains were performed with
favorable results.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  4008 </NUMBER>
<ORDER>   AAG9722596 </ORDER>
<TITLE> A GENERALIZED ANN-BASED MODEL FOR SHORT-TERM LOAD FORECASTING  </TITLE>
<AUTHOR> DREZGA, IRISLAV </AUTHOR>
<YEAR> 1996 </YEAR>
<INSTITUTION> VIRGINIA POLYTECHNIC INSTITUTE AND STATE UNIVERSITY; 0247 </INSTITUTION>
<DESCRIPTORS> ENGINEERING, ELECTRONICS AND ELECTRICAL; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> SAIFUR RAHMAN </ADVISER>
<CLASSIFICATIONS> NEURAL NETWORK </CLASSIFICATIONS>
<ABSTRACT>
Short-term load forecasting (STLF) deals with
forecasting of hourly system demand with a lead time
ranging from one hour to 168 hours. The basic objective
of the STLF is to provide for economic, reliable and
secure operation of the power system.
This dissertation establishes a new approach to
artificial neural network (ANN) based STLF. It first
decomposes the prediction problem into representation
and function approximation problems. The representation
problem is solved using phase-space embedding which
identifies time delay variables from load time series
that are used in forecasting. The concept is inherently
different from the methods used so far because it does
not use correlated variables for forecasting.
Temperature variables are included as well using
identified embedding parameters. Function approximation
problem is approached using ANN ensemble and active
selection of a training set. Training set is selected
based on predicted weather parameters for a prediction
horizon. Selection is done applying the k-nearest
neighbors technique in a temperature-based vector space.
A novel approach of pilot set simulation is used to
determine the number of hidden units for every forecast
period. Ensemble consists of two ANNs which are trained
and cross validated on complementary training sets.
Final prediction is obtained by a simple average of two
trained ANNs.
The described technique is used for predicting one
week's load in four selected months in summer peaking
and winter peaking US utilities. Mean absolute percent
errors (MAPEs) for 24-hour lead time predictions are
slightly greater than 2% for all months. For 120-hour
lead time (weekday) predictions, MAPEs are around 2.3%.
MAPEs for 48-hour lead time (weekend) predictions are
around 2.5%. Maximal errors for these cases are around
7%. Predictions for one-hour lead time are slightly
higher than 1% for all months, with maximal errors not
exceeding 4.99%. Peak load MAPEs are 2.3% for both
utilities. Maximal peak-load errors do not exceed 6%.
The technique shows very good performance faced with
sudden and large changes in weather. For changes in
temperature larger than 20$spcirc$F for two consecutive
days, forecasting error is smaller than 3.58%.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  4009 </NUMBER>
<ORDER>   AAG9722343 </ORDER>
<TITLE> APPLICATION OF ARTIFICIAL NEURAL NETWORKS, REPEATED CROSS-VALIDATION AND SIGNAL PROCESSING IN CHEMOMETRICS </TITLE>
<AUTHOR> LI, YU-WU </AUTHOR>
<YEAR> 1996 </YEAR>
<INSTITUTION> UNIVERSITAIRE INSTELLING ANTWERPEN (BELGIUM); 0314 </INSTITUTION>
<DESCRIPTORS> CHEMISTRY, ANALYTICAL; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> PIERRE J. M. VAN ESPEN </ADVISER>
<CLASSIFICATIONS> PATTERN RECOGNITION, DISCRIMINANT ANALYSIS, AUTOENCODING, SPLINES, PCA, SMOOTHING </CLASSIFICATIONS>
<ABSTRACT>
The research work covered several topics within the
field of artificial neural networks, discriminant
analysis, multivariate calibration and signal processing
in chemometrics, which constitute the three parts of the
thesis.
Part one consists of two chapters. Chapter 1 emphasizes
the investigation of the influence of multi-layered feed-
forward neural network parameters on the performance
characteristics in supervised pattern recognition In
Chapter 2, autoencoding networks and Kohonen networks
are used to reduce the dimensionality of multivariate
data sets, producing a two-dimensional display of the
data. The plots obtained by these two networks are
compared with results from two conventional methods,
principal component analysis and non-linear mapping.
Advantages and drawbacks of these four methods are
discussed.
A large part of the work is devoted to the application
of repeated cross-validation in discriminant analysis
and multivariate calibration with a quantitative
comparison between repeated cross-validation, repeated
evaluation set, single cross-validation and single
evaluation set procedures. Several different pre-
processing steps for NIR spectral data, three types of
discriminant analysis methods and several regression
methods are also compared based on repeated cross-
validation, This work appears in Chapters 3 to 5.
The last part of this thesis is centred around smoothing
of noisy data by principal component analysis and least-
squares splines. In Chapter 6, details of a new PCA
filter are described. The effectiveness of the PCA
filter is verified by simulated and real data sets.
Chapter 7 is devoted to application of least-squares
splines for smoothing noisy data. A new scheme for the
automatic selection of smoothing parameters used in
fitting experimental curves is proposed.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  4010 </NUMBER>
<ORDER>   AAG9721780 </ORDER>
<TITLE> INTELLIGENT ASSISTANCE AND POLYMORPHISM IN A VISUAL PROGRAMMING LANGUAGE BASED ON APPLICABILITY CHECKING </TITLE>
<AUTHOR> WANG, GUIJUN </AUTHOR>
<YEAR> 1996 </YEAR>
<INSTITUTION> UNIVERSITY OF KANSAS; 0099 </INSTITUTION>
<DESCRIPTORS> COMPUTER SCIENCE; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> NIL </ADVISER>
<CLASSIFICATIONS> INVOCATION POLYMORPHISM </CLASSIFICATIONS>
<ABSTRACT>
Visual programming offers programmers potential benefits
including visual representation, direct manipulation,
and immediate feedback. Visual representations of
structured objects can help programmers visualize
multiple views of data objects, spatial relationships
among objects, and spatial relationships among
components of an object. However, most programming
languages today force a programmer to deal with
structures on an element-by-element basis rather than by
larger regions as the programmer may conceive of
algorithms. Studies by other researchers have shown that
people use mental images in intermediate problem
modeling. Such mental images are often expressed as
graphical sketches. Actual programming, however, is made
hard by requiring the programmer to transform such
general sketches into tedious computation steps. To
allow programmers to transform intermediate mental
images directly into visual programs, visual programming
languages must allow programmers to directly manipulate
components of visual data objects at a conceptual level.
In this dissertation, we achieve component-level visual
manipulation by automatic applicability checking and
intelligent assistance.
Applicability checking determines the applicability of a
function to the given arguments which may be data
components. If not directly applicable, applicability
checking tries to determine how to subdivide arguments
into multiple applicable regions such that the function
is applicable to each applicable region. It also tries
to determine how to arrange the results from multiple
function invocations into a single result region. A rule-
based approach is used to solve the applicability
checking problem. A set of applicability constraints are
imposed by tbe applicability checking rules.
An intelligent assistance system is developed to resolve
ambiguities in general visual expressions and fill in
details. It makes inferences based on constraints
imposed by applicability checking. Both constraint
satisfaction techniques and plausible inference
techniques are employed by the intelligent assistance
system. Automatic assumption validation and candidate
testing mechanisms are used for reducing interruptions
to the program construction process. Applicability
details are deduced so that a general visual expression
can be evaluated by the evaluation engine. The
intelligent assistance system also provides assistance
to the programmer to facilitate abstracting concrete
manipulations into general functions.
By automatic applicability checking and intelligent
assistance, we achieve another level of abstraction:
abstraction over function invocations on data
components. The ambiguity of function invocations over
data components in various shapes and sizes is called
invocation polymorphism. Invocation polymorphism reduces
the need for defining functions over various structures.
The current hierarchy of polymorphism is extended.
An incremental applicability checking approach is
developed to reduce the amount of work required for
applicability re-checking in an interactive visual
programming environment.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  4011 </NUMBER>
<ORDER>   AAG9720680 </ORDER>
<TITLE> INTELLIGENT CONTROL OF AUTONOMOUS ROCK EXCAVATION: THEORY AND EXPERIMENTATION </TITLE>
<AUTHOR> SHI, XIAOBO </AUTHOR>
<YEAR> 1996 </YEAR>
<INSTITUTION> THE UNIVERSITY OF ARIZONA; 0009 </INSTITUTION>
<DESCRIPTORS> ENGINEERING, MINING; ENGINEERING, ELECTRONICS AND ELECTRICAL; ENGINEERING, MECHANICAL; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> PAUL J. A. LEVER </ADVISER>
<CLASSIFICATIONS> EARTHMOVING, RESISTANCE, FUZZY LOGIC, NEURAL NETWORKS, ROBOTIC </CLASSIFICATIONS>
<ABSTRACT>
Earthmoving is a common activity at mines, construction
sites, hazardous waste cleanup locations, and road
works. Expensive and sophisticated machines such as
front-end-loaders (FEL), backhoe loaders, LHD loaders
and front shovels are used for these excavation tasks.
Autonomous excavation control for these machines has
gained considerable attention in order to remove human
operators from hazardous environments, improve
productivity and utilization, reduce machine abuse, as
well as decrease machine operating costs. However,
automatic control of excavation tasks for many sites
that require digging in rock cannot be implemented using
existing factory-based automation techniques. For
example, control of bucket motions by simply
partitioning the terrain into a set of volumes where
each equals the bucket capacity often does not work.
Planning in this way is possible only when digging in
the materials such as loose soils where bucket motion
resistance through the media can be predicted.
Resistance predictions are impossible and/or infeasible
to generate for excavation in the environments which
consists mainly of irregular rigid objects such as rock
piles with oversized particles, since no means exists to
predetermine subsurface bucket/material interactions
that are required to preplan the bucket trajectory. As a
result, bucket actions must be determined through on-
line decision making based on sensory feedback of the
current excavation status in the unpredictable,
unstructured and dynamic rock excavation environment.
This research proposes a control method for autonomous
rock excavation. The control architecture is designed
following the behavior-based control concept. That is,
the rock excavation control problem is solved by
decomposition of the complicated task into a variety of
simple elements that can be implemented by excavation
behaviors. However, this control approach presents a new
structure and operational paradigm that is developed
based on, but different from the traditional behavior
control method. Here, the behaviors are chosen using
fuzzy excavation situation assessment with guidance of
excavation task planning which embodies excavation
heuristics and human strategies. Task plans are
formulated using finite state machines which integrate
neural networks for decision making. This organizational
structure has the capability to include more excavation
goals and to adapt to different environments via
learning. Excavation behaviors are performed by
primitive and machine executable actions or action
sequences structured using finite state machines and
simple action arbitration rules. The actions of human
FEL operators were observed and analyzed to extract
basic bucket actions and define rules of arbitration for
different actions or action sequences under particular
excavation environments. Fuzzy logic is applied to
implement each excavation action where fuzzy rules
represent the human experience and heuristics that are
intrinsically linguistic, and bucket excavation motions
are evaluated based on insufficient and inaccurate input
sensory data.
A variety of experiments were performed to test the
ability of the proposed control algorithm. The
laboratory-based experimental autonomous excavation
system consists of a robotic arm, an excavation testbed,
a force/torque sensor mounted between the robot arm
wrist and the excavation bucket, and a control computer.
Various rock piles to simulate realistic excavation
environments and conditions were generated in the
testbed. With these experiments, the control algorithm
has demonstrated the ability to execute real-time
automated loading cycles effectively and efficiently in
complex excavation environments and under difficult
digging conditions, through the use of the flexible
excavation behaviors.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  4012 </NUMBER>
<ORDER>   AAG9720674 </ORDER>
<TITLE> HIGH PERFORMANCE SIMULATION-BASED OPTIMIZATION ENVIRONMENT FOR LARGE SCALE SYSTEMS </TITLE>
<AUTHOR> MOON, YOON KEON </AUTHOR>
<YEAR> 1996 </YEAR>
<INSTITUTION> THE UNIVERSITY OF ARIZONA; 0009 </INSTITUTION>
<DESCRIPTORS> ENGINEERING, ELECTRONICS AND ELECTRICAL; ARTIFICIAL INTELLIGENCE; HYDROLOGY; BIOLOGY, ECOLOGY </DESCRIPTORS>
<ADVISER> BERNARD P. ZEIGLER </ADVISER>
<CLASSIFICATIONS> DEVS, OBJECT- ORIENTED, FUZZY, GENETIC ALGORITHMS, WATERSHED </CLASSIFICATIONS>
<ABSTRACT>
Modelling large scale systems with natural and
artificial components requires storage of voluminous
amounts of knowledge/information as well as computing
speed for simulations to provide reliable answers in
reasonable time. Computing technology is becoming
powerful enough to support such high performance
modelling and simulation. This dissertation proposes a
high performance simulation based optimization
environment to support the design and modeling of large
scale systems with high levels of resolution.
The proposed environment consists of three layers--
modeling, simulation and searcher layer. The modeling
layer employs the Discrete Event System Specification
(DEVS) formalism and shows how it provides efficient and
effective representation of both continuous and discrete
processes in mixed artificial/natural systems necessary
to fully exploit available computational resources.
Focusing on the portability of DEVS across
serial/parallel platforms, the simulation layer adopts
object-oriented technology to achieve it. DEVS is
implemented in terms of a collection of classes, called
containers, using C++. The searcher layer employs
Genetic Algorithms to provide generic, robust search
capability. In this layer, a class of parallel Genetic
Algorithms, called Distributed Asynchronous Genetic
Algorithm (DAGA), is developed to provide the speed
required for simulation based optimization of large
scale systems.
This dissertation presents an example of DEVS modeling
for a watershed, which is one of the most complex
ecosystems. The example shows a well-justified process
of abstraction from traditional differential equation
models to DEVS representation. An approach is proposed
for valid aggregation of spatially distributed systems
to reduce the simulation time of watershed models. DEVS
representation and spatial aggregation assure relative
validity and realism with feasible computational
constraints. Throughout the dissertation, several
examples of GA optimization are presented to demonstrate
the effectiveness of the proposed optimization
environment in modeling large scale systems.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  4013 </NUMBER>
<ORDER>   AAG9720444 </ORDER>
<TITLE> A FRAMEWORK FOR THE ANALYSIS OF EVOLUTIONARY ALGORITHMS </TITLE>
<AUTHOR> PICARDO, LESLIE D. </AUTHOR>
<YEAR> 1996 </YEAR>
<INSTITUTION> CASE WESTERN RESERVE UNIVERSITY; 0042 </INSTITUTION>
<DESCRIPTORS> COMPUTER SCIENCE; ENGINEERING, SYSTEM SCIENCE; ENGINEERING, GENERAL; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> RANDALL BEER </ADVISER>
<CLASSIFICATIONS> GENETIC ALGORITHMS, COST FUNCTION </CLASSIFICATIONS>
<ABSTRACT>
Evolutionary algorithms are being used as a tool for
function optimization. Several algorithms have been
proposed differing in their genome representation,
reproduction operators and selection procedures. These
algorithms are nonlinear, discrete, stochastic dynamical
systems and we need practical guidance to select the
best algorithm for any given problem. This thesis
describes a common framework for the analysis of
evolutionary algorithms. We propose a useful metric to
compare the performance of evolutionary algorithms on
any given cost function. We introduce a sequence of
simple evolutionary algorithms and derive analytical
expressions that allow us to compute the performance of
these algorithms on any cost function. We present
results for the performance of this sequence of
algorithms on two families of multimodal one-dimensional
cost functions. We also present a useful software
toolbox of C++ classes that allow the construction of a
variety of evolutionary algorithms.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  4014 </NUMBER>
<ORDER>   AAG9720278 </ORDER>
<TITLE> CONVERGENCE OF BACKWARD-ERROR-PROPAGATION LEARNING IN PHOTOREFRACTIVE CRYSTALS </TITLE>
<AUTHOR> PETRISOR, GREGORY C. </AUTHOR>
<YEAR> 1996 </YEAR>
<INSTITUTION> UNIVERSITY OF SOUTHERN CALIFORNIA; 0208 </INSTITUTION>
<DESCRIPTORS> ENGINEERING, ELECTRONICS AND ELECTRICAL; PHYSICS, OPTICS; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> NIL </ADVISER>
<CLASSIFICATIONS> NEURAL NETWORKS, ARTIFICIAL INTELLIGENCE </CLASSIFICATIONS>
<ABSTRACT>
We analytically determine that the backward-error-
propagation learning algorithm has a well defined region
of convergence in neural learning-parameter space for
two classes of photorefractive-based optical neural
network architectures. The first class uses electric
field amplitude encoding of signals and weights in a
fully coherent system, whereas the second class uses
intensity encoding of signals and weights in an
incoherent/coherent system. The computed photorefractive-
based neural-space weight updates for both classes of
architecture contain two neural learning parameters: a
learning rate coefficient and a weight decay
coefficient. We show that these learning parameters are
directly related to two important design parameters:
system gain and exposure energy. We show for both
classes of architecture that convergence is guaranteed
(assuming no spurious local minima in the error
function) by using a sufficiently high system gain and a
sufficiently low exposure energy.
We compute the optimum ratio (in terms of maximizing the
detected energy and therefore minimizing the detection
noise) of the exposure energy used during forward and
backward propagation to the exposure energy used during
the weight updates, under the assumption that these two
energies are constant throughout learning. Using
simulation results of the XOR sample problem, we show
that photon noise and detection-system noise induces
noise on the neural-space signals that (for sufficiently
high levels) can prevent a network from converging even
if the derived convergence condition is satisfied. This
is because the derived convergence condition does not
account for noise. We conclude that for a given optical
system it may not be possible to simultaneously satisfy
the convergence condition while maintaining neural-space
signal variances that are sufficiently small to allow
the learning algorithm to converge. We then use this
result to estimate the scaling properties of
photorefractive-based neural networks.
We evaluate the effects of spatial-light-modulator
contrast ratio on network convergence. We also present a
novel neural network model and learning algorithm which
can functionally implement bipolar-output neuron units
with unipolar neuron activation functions and unipolar
physical outputs. Finally, we present an experimental
system for evaluation of these photorefractive-based
optical interconnection architectures.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  4015 </NUMBER>
<ORDER>   AAG9720193 </ORDER>
<TITLE> CONTROLLER VALIDATION, IDENTIFICATION AND LEARNING </TITLE>
<AUTHOR> BROZENEC, THOMAS FRANK </AUTHOR>
<YEAR> 1996 </YEAR>
<INSTITUTION> UNIVERSITY OF SOUTHERN CALIFORNIA; 0208 </INSTITUTION>
<DESCRIPTORS> ENGINEERING, ELECTRONICS AND ELECTRICAL; ENGINEERING, AEROSPACE; OPERATIONS RESEARCH; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> NIL </ADVISER>
<CLASSIFICATIONS> ROBUST CONTROL </CLASSIFICATIONS>
<ABSTRACT>
Controller validation is presented as an approach for
evaluating the capability of a given control law to meet
a given closed-loop system performance criterion. With
this approach, experimental measurements of plant input-
output data can sometimes be used to prove that a
feedback controller is incapable of meeting a given
closed-loop performance specification--even without the
aid of a plant model or any assumptions about the plant.
By focusing attention on what can be determined from
data alone, controller validation provides a
mathematical, non-conservative filter for potential
control laws which can be used to eliminate those which
have been proven inadequate to meet desired performance
objectives. Thus experimental data can be used to
directly examine in one step the ability of controllers
to meet a given performance criterion. The two-step
process of model validation followed by robust control
synthesis is proven to be unnecessarily conservative. In
this framework, controller identification is introduced
as a generalization of robust-control-oriented system
identification. Feedback controllers (rather than plant
models) can be identified from an allowable class by
performing the controller validation test on each one.
Assumptions about the plant and other a priori knowledge
may be used to construct the "model set" from which the
controllers are identified. The result is a non-
conservative approach to learning and intelligent
control. Several analysis and design examples illustrate
the procedure.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  4016 </NUMBER>
<ORDER>   AAGNN15322 </ORDER>
<TITLE> ATTRIBUTED HYPERGRAPH REPRESENTATION AND MANIPULATION IN STRUCTURAL PATTERN RECOGNITION </TITLE>
<AUTHOR> LI, CHUN WANG </AUTHOR>
<YEAR> 1996 </YEAR>
<INSTITUTION> UNIVERSITY OF WATERLOO (CANADA); 1141 </INSTITUTION>
<DESCRIPTORS> COMPUTER SCIENCE; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> ANDREW WONG </ADVISER>
<CLASSIFICATIONS> COMPUTER VISION, ARTIFICIAL INTELLIGENCE </CLASSIFICATIONS>
<ABSTRACT>
The representation of structural patterns is the central
task of structural pattern recognition. It determines
the characteristics of the manipulation and recognition
process. The need to represent the structural patterns
in generic and computable mathematical forms is
ubiquitous in theory and practice. Many efforts have
been devoted on the representation theories. Among them,
is Attributed Hypergraph Representation (AHR) which
provides an effective and generic approach.
The objective of this research is to establish a
mathematical framework of the AHR theory and examine it
from the mathematical engineering perspective. It is
expected that the establishment of such framework can
clarify certain theoretical issues in AHR, such as, the
representation of a class of structural patterns, the
manipulations of AHR, and the representation of
recursive structures, etc. This thesis consists of two
parts. The first part uses topology, algebra and fiber
bundle to present a general mathematical implication and
its impact on structural pattern recognition in
particular. Specifically, we introduce an operation of
AHR known as visual transformation to resolve some
problems encountered in 3-D objects recognition from 2-D
images. We also define the compressed form of AHR to
represent the recursive structure explicitly. In the
second part, we apply the general concepts defined in
the theoretical framework to 3-D objects and elaborate
on visual transformation and its application. To apply
this theory in computer vision, a model based computer
vision system which can recognize an object with a
single view is prototyped. Through discussing both the
theory and application of the mathematical framework, we
effectively demonstrate the elegance and robustness of
the AHR theory.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  4017 </NUMBER>
<ORDER>   AAGMM18568 </ORDER>
<TITLE> ARTIFICIAL INTELLIGENCE APPLICATION IN FACILITY MANAGEMENT AND COST PREDICTION </TITLE>
<AUTHOR> PANDEYA, AMAR NATH </AUTHOR>
<YEAR> 1996 </YEAR>
<INSTITUTION> THE UNIVERSITY OF NEW BRUNSWICK (CANADA); 0823 </INSTITUTION>
<DESCRIPTORS> ENGINEERING, SYSTEM SCIENCE; ENGINEERING, INDUSTRIAL </DESCRIPTORS>
<ADVISER> A. J. CHRISTIAN </ADVISER>
<CLASSIFICATIONS> NIL </CLASSIFICATIONS>
<ABSTRACT>
Facility management is a multi-faceted job. It includes
tasks such as life-cycle costs determination,
development of maintenance plans and space management.
The accomplishment of these tasks require detailed
knowledge about various fields of endeavor. In this
research, an attempt was made to create a decision-
support system to assist the facility managers in the
execution of some of their tasks.
Twenty-two facilities were investigated by the
Construction Engineering Group at the University of New
Brunswick. Knowledge about historical operating and
maintenance costs, operating and maintenance activities,
schedules, responsibilities and many other aspects of
facility management was elicited through various
sources. The operating and maintenance costs were
analyzed using three methods; namely: regression
analysis, neural network and random deviation detection.
A decision-support system, named TOCAP, was then created
using the analytical results and knowledge acquired from
various sources. The system provides information on
various aspects of facility management. The system has,
however, been developed for only two types of
facilities.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  4018 </NUMBER>
<ORDER>   AAGNN15040 </ORDER>
<TITLE> MINIMAL FORWARD CHECKING--A LAZY CONSTRAINT SATISFACTION SEARCH ALGORITHM: EXPERIMENTAL AND THEORETICAL RESULTS </TITLE>
<AUTHOR> DENT, MICHAEL JAMES </AUTHOR>
<YEAR> 1996 </YEAR>
<INSTITUTION> THE UNIVERSITY OF WESTERN ONTARIO (CANADA); 0784 </INSTITUTION>
<DESCRIPTORS> COMPUTER SCIENCE </DESCRIPTORS>
<ADVISER> R. E. MERCER </ADVISER>
<CLASSIFICATIONS> NIL </CLASSIFICATIONS>
<ABSTRACT>
Many problems that occur in Artificial Intelligence and
Operations Research can be naturally represented as
Constraint Satisfaction Problems (CSPs). One of the most
popular backtracking search algorithms used to solve
CSPs is called Forward Checking (FC). FC performs a
limited amount of lookahead during its search attempting
to detect future inconsistencies thereby avoiding
inconsistent parts of the search tree. In this thesis we
describe a new backtracking search algorithm called
Minimal Forward Checking (MFC) which maintains FC's
ability to detect inconsistencies but which is lazy in
is method of doing so. We prove that MFC is sound and
complete. We also prove the MFC and FC visit the same
nodes in the search tree. Most significantly, we prove
that MFC's worst case performance in terms of number of
constraint checks performed (the common measure of
performance of these algorithms) is the number of
constraint checks performed by FC. We then describe how
the MFC algorithm can be seen as one algorithm in a
family of lazy CSP search algorithms.
As theoretical results on the average case complexity
for CSP search algorithms are extremely difficult to
derive, empirical comparisons need to be performed. A
commonly used testbed is randomly generated problems
drawn from a standard model of binary CSPs at a specific
location known to contain problems that are relatively
hard to solve. We generalize the standard model of
binary CSPs and show how to find problems in this model
that are relatively hard to solve. We also show that
these "hard problems" are of similar hardness or harder
than hard problems drawn from the standard model
especially as the problem size grows and the problem has
a relatively sparse structure. We perform large
empirical studies of many CSP search algorithms
including variants of MFC and FC with non-chronological
backtracking and variants of the Fail First heuristic on
two testbeds of hard random problems, each drawn from
one of the two models. Our empirical comparisons on both
testbeds indicate that the average case performance of
algorithms based on MFC are better than all the other
algorithms in the comparison in terms of the number of
constraint checks performed.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  4019 </NUMBER>
<ORDER>   AAG9720552 </ORDER>
<TITLE> USING NEURAL NETWORKS FOR THREE-DIMENSIONAL MEASUREMENT IN STEREO VISION SYSTEMS </TITLE>
<AUTHOR> TIEN, FANG-CHIH </AUTHOR>
<YEAR> 1996 </YEAR>
<INSTITUTION> UNIVERSITY OF MISSOURI - COLUMBIA; 0133 </INSTITUTION>
<DESCRIPTORS> ENGINEERING, INDUSTRIAL; ENGINEERING, ELECTRONICS AND ELECTRICAL; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> ALEC C. CHANG </ADVISER>
<CLASSIFICATIONS> COMPUTER VISION </CLASSIFICATIONS>
<ABSTRACT>
This study presents a three-dimensional computer vision
inspection and measurement system, in which stereo
vision and neural networks are incorporated measurement
tasks. The main objective of this proposed research is
to automatically measure an industrial part in three-
dimensions by using parallel stereo vision. Two major
problems, stereo matching and measurement error
correction, are solved.
Matching conjugate features is a significant problem in
using a stereo vision system. A feature-based matching
method is proposed to solve this problem. The proposed
algorithm includes: selecting significant feature
points, matching conjugate feature points by a "0-1"
integer programming problem, and removing false targets
according to suggested rules. An energy function is
created and minimized by using an asynchronous Hopfield
neural network with a derived activation rule. The
disparities of conjugate feature points are the derived
results.
A triangulation-based camera calibration model is used
to derive the focal length and correct the X-Y ratio of
the cameras. An operational process is proposed to
collect the data and derive the focal length. Boundary
representation is used to identify and decompose the
feature of interest, and then initial measurements are
made. A neural network based error correction procedure
is proposed to solve the measurement error correction
problem. By means of a backpropagation neural network,
the mapping of the influential factors and correction
ratios is established. The derived correction ratios are
used to correct the initial measurements. Three
processes--training, testing and operational procedures--
are proposed to facilitate the error correction process.
A comparison with Nascrabadi's approach shows that the
proposed stereo matching algorithm has superior matching
performance in speed, storage, and correctness. The
derived initial measurements demonstrate that the focal
lengths are accurately estimated by the proposed
calibration method. Also, the proposed error correction
model further improves the accuracy and precision of the
measurements.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  4020 </NUMBER>
<ORDER>   AAG9720248 </ORDER>
<TITLE> BOUNDING THE COST OF LEARNED RULES: A TRANSFORMATIONAL APPROACH  </TITLE>
<AUTHOR> KIM, JIHIE </AUTHOR>
<YEAR> 1996 </YEAR>
<INSTITUTION> UNIVERSITY OF SOUTHERN CALIFORNIA; 0208 </INSTITUTION>
<DESCRIPTORS> COMPUTER SCIENCE; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> NIL </ADVISER>
<CLASSIFICATIONS> EXPLANATION-BASED LEARNING, MACHINE LEARNING </CLASSIFICATIONS>
<ABSTRACT>
Efficiency is a major concern for all problem solving
systems. One way of achieving efficiency is the
application of learning techniques to speed up problem
solving. However, many speed-up learning systems suffer
from the utility problem: the cost of using the learned
knowledge often overwhelms its benefit, so that the
problem solving time after learning is greater than the
problem solving time before learning. Assuring that
learned knowledge will in fact speed up system
performance has been a focus of research in explanation-
based learning (EBL).
One way of finding a solution which can guarantee the
cost boundedness is to analyze all the sources of cost
increase in the learning process and then eliminate
these sources. This thesis demonstrates how the cost
increase of a learned rule in an EBL system can be
analyzed by characterizing the learning process as a
sequence of transformations. The learning process is
decomposed into a sequence of transformations that go
from a problem solving episode, through a sequence of
intermediate problem solving/rule hybrids, to a learned
rule.
Such an analysis has been performed on Soar (a problem
solving system with a variant of EBL). By decomposing
the learning process into a sequence of transformations,
and analyzing these transformations, the causes which
can make the output rule expensive have been identified.
This analysis has also pointed the way toward a set of
modifications of the transformational sequence that
could potentially eliminate these causes.
These modifications have been applied to Soar, and the
original sequence of transformations has been converted
into a new sequence of transformations. The experimental
results, at least for the domains investigated, indicate
that the time after learning is consistently less than
the time before learning with the new learning
algorithm.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  4021 </NUMBER>
<ORDER>   AAG9720247 </ORDER>
<TITLE> GAIT-ER-AID: A THREE LEVEL DIAGNOSTIC KNOWLEDGE-BASED SYSTEM FOR GAIT ANALYSIS </TITLE>
<AUTHOR> KIM, JOUNG-WOO JOHN </AUTHOR>
<YEAR> 1996 </YEAR>
<INSTITUTION> UNIVERSITY OF SOUTHERN CALIFORNIA; 0208 </INSTITUTION>
<DESCRIPTORS> COMPUTER SCIENCE; ARTIFICIAL INTELLIGENCE; HEALTH SCIENCES, PHYSICAL THERAPY; HEALTH SCIENCES, MEDICINE AND SURGERY </DESCRIPTORS>
<ADVISER> GEORGE A. BEKEY </ADVISER>
<CLASSIFICATIONS> EXPERT SYSTEM, PHYSIOLOGY, WALKING </CLASSIFICATIONS>
<ABSTRACT>
Human walking is a complex process, which requires the
coordination of numerous muscles in the legs and trunk
to allow for both forward progression and the
maintenance of a stable posture. When one or more of
these muscles are damaged by disease or injury, the
result may be an abnormal gait pattern. Gait analysis is
a diagnostic procedure concerned with inferring which
muscles are responsible for a given pathological gait
pattern. This pattern represents the symptoms. These
symptoms are provided in the forms of motion of the leg
joints, electrical signals emitted by leg muscles and
foot-floor contact pattern of both feet. This
dissertation is concerned with the development of a
knowledge-based system for performing this inference
task.
The problems associated with simple associational, i.e.,
rule-based, systems are reviewed, leading to the
formulation of a novel three-level architecture for
diagnostic systems. This architecture represents
knowledge at three levels: the associational, the causal
and the principle levels. The architecture is then
instantiated in the gait domain, where the principle
level provides a qualitative description of the
physiology of gait. Failure of the associational level
to provide a diagnosis leads the system to the principle
level, where the physiological basis of the given
symptoms is analyzed, cause-effect chains are
constructed, and compiled into new associational rules.
The resulting system, Gait-ER-Aid, is evaluated by
comparing its diagnostic accuracy with that of a human
expert at a major gait laboratory and with that of a
previous state-of-the-art gait expert system, QUAWDS.
The differences between the mean diagnostic accuracies
of the two systems are evaluated statistically and found
to be statistically significant. It is shown that Gait-
ER-Aid provides a higher level mean diagnostic accuracy
than its predecessor QUAWDS.
The major contributions of the work lie in the
development of a novel architecture for diagnostic
systems capable of learning to automatically expand its
knowledge base, its application to gait analysis, and
the systematic demonstration of the superiority of the
Gait-ER-Aid system over the best previously available
gait analysis system.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  4022 </NUMBER>
<ORDER>   AAG9720246 </ORDER>
<TITLE> SIMULATION AND MODELING OF NEUROBIOLOGICAL NETWORKS WITH APPLICATIONS TO CEREBELLAR NETWORKS IMPLICATED IN CLASSICAL CONDITIONING OF THE EYEBLINK RESPONSE </TITLE>
<AUTHOR> KHADEMI, PEYVAND MARK </AUTHOR>
<YEAR> 1996 </YEAR>
<INSTITUTION> UNIVERSITY OF SOUTHERN CALIFORNIA; 0208 </INSTITUTION>
<DESCRIPTORS> COMPUTER SCIENCE; BIOLOGY, NEUROSCIENCE; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> NIL </ADVISER>
<CLASSIFICATIONS> SYNAPTIC PLASTICITY, COMPARTMENTAL, PURKINJE </CLASSIFICATIONS>
<ABSTRACT>
Classical conditioning of the eyeblink response in
rabbit consists of repeated pair-wise presentations of a
tone, and an airpuff blown into the eye. The airpuff
always elicits an eyeblink. Eventually, conditioning
takes place, i.e., the rabbit learns to blink in
response to the tone alone. Neurobiological studies have
implicated the cerebellar cortex and the cerebellar
nuclear region, the interpositus, as neuronal substrates
where the memory trace for eyeblink conditioning
resides. Synaptic plasticity in the same cerebellar
areas is implicated as the mechanism for learning.
The central proposition of this thesis is that through
simulations of neural network models, it is possible to
determine with a high degree of likelihood the sites of
synaptic plasticity in the implicated neural circuitry,
and further to predict the direction of plasticity
(i.e., whether the synapse is strengthened or weakened)
in each case. Our models are based on the neural
circuitry in the cerebellar cortex and nuclei, and are
free of built-in predisposition regarding the sites of
plasticity.
Two approaches to neural network modeling are pursued.
The first involves a network of leaky integrator
neurons, and is based on using a system identification
algorithm to learn the weights that result in a close
match between model outputs and target data. The
comparison of the weights resulting from the network
matching first before-conditioning data, and then after-
conditioning data yields the model's predictions of
plasticity sites in the network. The likelihood of the
prediction is increased by means of plasticity site
identification using the duplex network, a combination
of the before- and after-conditioning networks that
provides for a method of selective clamping of weights
that avoids pre-assignment of values.
The second approach consists of compartmental modeling
using the neural network simulator CAJAL. A parameter
estimation method is used in conjunction with the SIBN
simulation environment to likewise match before- and
after-conditioning data and to produce plasticity
hypotheses. Our models strongly suggest parallel fiber-
Purkinje and pontine nucleus-interpositus synapses as
the sites as plasticity.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  4023 </NUMBER>
<ORDER>   AAG9720238 </ORDER>
<TITLE> LEARNING EFFECTIVE AND ROBUST KNOWLEDGE FOR SEMANTIC QUERY OPTIMIZATION  </TITLE>
<AUTHOR> HSU, CHUN-NAN </AUTHOR>
<YEAR> 1996 </YEAR>
<INSTITUTION> UNIVERSITY OF SOUTHERN CALIFORNIA; 0208 </INSTITUTION>
<DESCRIPTORS> COMPUTER SCIENCE; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> NIL </ADVISER>
<CLASSIFICATIONS> DATABASES, MACHINE LEARNING </CLASSIFICATIONS>
<ABSTRACT>
Optimizing queries to heterogeneous, distributed
multidatabases is an important problem. Due to the query
complexity and the heterogeneity of databases, it is
difficult for conventional optimization approaches to
solve the problem satisfactorily. Semantic Query
Optimization (SQO) can complement conventional
approaches to overcome the heterogeneity and
considerably reduce redundant data transmission. SQO
optimizers use rules about data regularities to yield
significant cost reduction. However, hand coding useful
rules for SQO is impracticable. This dissertation
presents a machine learning approach to this knowledge
bottleneck problem.
Unlike search control rules or classification rules
studied extensively in machine learning, two roughly
correlated measures must be maximized in the learning of
high utility rules for SQO. The first measure is the
effectiveness. Effective rules must be applicable in
many different queries and yield high cost reduction.
The second measure is the robustness against database
changes. That is, they must remain valid regardless of
database changes. This dissertation presents a new
inductive learning approach to learning effective and
robust rules. The learning approach considers both
applicability and cost-reduction in rule induction to
learn effective rules. The learned rules are robust
because the learner is able to guide the learning for
robust rules with an approach to estimating the
probabilities of database changes.
To evaluate the utility of the learning approach, this
dissertation also describes an extended SQO approach for
query plans that retrieve data from heterogeneous
multidatabases. The experimental results show that the
learned rules produce significant savings while being
robust against database changes. The learning and
optimization approaches provide a complete solution for
multidatabase information systems to effectively
optimize queries using SQO that does not require an
expensive coding effort to produce useful rules.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  4024 </NUMBER>
<ORDER>   AAG9720225 </ORDER>
<TITLE> A MACHINE LEARNING APPROACH TO MULTILINGUAL PROPER NAME RECOGNITION </TITLE>
<AUTHOR> GALLIPPI, ANTHONY FRANK </AUTHOR>
<YEAR> 1996 </YEAR>
<INSTITUTION> UNIVERSITY OF SOUTHERN CALIFORNIA; 0208 </INSTITUTION>
<DESCRIPTORS> COMPUTER SCIENCE; ARTIFICIAL INTELLIGENCE; LANGUAGE, LINGUISTICS </DESCRIPTORS>
<ADVISER> GERARD MEDIONI </ADVISER>
<CLASSIFICATIONS> NIL </CLASSIFICATIONS>
<ABSTRACT>
The development of natural language processing (NLP)
systems that perform machine translation (MT) and
information retrieval (IR) has highlighted the need for
the automatic recognition of proper names. While various
name recognizers have been developed, they suffer from
being too limited: some only recognize one class of
proper names, and all are language specific. This thesis
develops an approach to multilingual name recognition
that allows a system optimized for one language to be
ported to another with little additional effort and
resources. An initial core set of linguistic features,
useful for name recognition in most languages, is
identified. When porting to a new language, these
features have to be converted (partly by hand, partly by
on-line lists), after which point machine learning
techniques build decision trees that map features to
name classes. A system initially optimized for English
has been successfully ported to Spanish and Japanese.
The performance of this multilingual system is
comparable to the best known systems in existence today,
which recognize names in one language only. Issues of
multilinguality addressed include porting effort,
necessary resources, and performance. Results of this
work have opened the door for future work in the
following areas: improving performance, reducing
necessary human effort, and further exploring language-
based phenomena. This research represents a new
application of learning theory.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  4025 </NUMBER>
<ORDER>   AAG9720208 </ORDER>
<TITLE> PREDICTING FREEWAY TRAFFIC INCIDENT DURATION IN AN EXPERT SYSTEM CONTEXT USING FUZZY LOGIC </TITLE>
<AUTHOR> CHOI, HOI-KYUN </AUTHOR>
<YEAR> 1996 </YEAR>
<INSTITUTION> UNIVERSITY OF SOUTHERN CALIFORNIA; 0208 </INSTITUTION>
<DESCRIPTORS> ENGINEERING, CIVIL; URBAN AND REGIONAL PLANNING; OPERATIONS RESEARCH; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> JAMES E. MOORE </ADVISER>
<CLASSIFICATIONS> NIL </CLASSIFICATIONS>
<ABSTRACT>
Incident management is significant for the traffic
management systems. The management of incidents
determines the smoothness of freeway operations. The
dynamic nature of incidents and the uncertainty
associated with them require solutions based on the
incident operator's judgment. Fuzzy systems attempt to
adapt such human expertise and are designed to replicate
the decision making capability of an operator. Fuzzy
systems process complex traffic information, and
transmit it in a simplified, understandable form to
human traffic operators.
In this study, fuzzy rules were developed based on data
from real incidents on Santa Monica Freeway in Los
Angeles. The fuzzy rules are linguistic based, and
hence, user-friendly. A comparison of the results from
the linguistic model with the real incident durations
indicate that the outputs from the model reliably
correspond to real incident duration conditions. The
model reliably predicts the freeway incident duration.
The model can thus be used as an effective management
tool for freeway incident response systems. This
approach could be applied to other problems regarding
dispatch systems in transportation.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  4026 </NUMBER>
<ORDER>   AAG9719869 </ORDER>
<TITLE> COMPLEXITY ASPECTS OF KNOWLEDGE REPRESENTATION </TITLE>
<AUTHOR> GOGIC, GORAN </AUTHOR>
<YEAR> 1996 </YEAR>
<INSTITUTION> UNIVERSITY OF CALIFORNIA, SAN DIEGO; 0033 </INSTITUTION>
<DESCRIPTORS> COMPUTER SCIENCE; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> RUSSELL IMPAGLIAZZO; CHRISTOS PAPADIMITRIOU </ADVISER>
<CLASSIFICATIONS> ARTIFICIAL INTELLIGENCE, HORN FORMULAS </CLASSIFICATIONS>
<ABSTRACT>
The ultimate goal of Artificial Intelligence (to come up
with a machine that is able to reason as humans do) is
still a long term one; developing schemes for knowledge
representation and common-sense reasoning are important
and widely accepted tactical goals. This thesis is about
the application of the methods of the theory of
computational complexity in order to choose among the
possible approaches towards an effective mathematical
model of common sense.
We develop a methodology for comparing knowledge
representation formalisms in terms of their
"representational succinctness," and use this framework
for comparing many important formalisms for knowledge
representation. We also show that adding new variables
improves the effective expressibility of certain
knowledge representation formalisms.
Approximating a general formula from above and below by
Horn formulas was proposed by Kautz and Selman as a form
of "knowledge compilation," supporting rapid approximate
reasoning; as we point out, this scheme is static in
that it supports no updates, and has certain complexity
drawbacks. In our work we propose a new, very efficient
scheme, incremental recompilation, which combines Horn
approximation and model-based updates.
Finally, we look closer at two knowledge representation
formalisms that have the same expressive power--Horn
formulas and characteristic model--and try to tell which
one is better to use for representing knowledge in
various contexts.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  4027 </NUMBER>
<ORDER>   AAG9719571 </ORDER>
<TITLE> NEURAL NETWORK MODELING AND CONTROL: CASE STUDIES IN CHEMICAL ENGINEERING  </TITLE>
<AUTHOR> EIKENS, BERNHARD </AUTHOR>
<YEAR> 1996 </YEAR>
<INSTITUTION> COLORADO STATE UNIVERSITY; 0053 </INSTITUTION>
<DESCRIPTORS> ENGINEERING, CHEMICAL; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> NIL </ADVISER>
<CLASSIFICATIONS> FEEDFORWARD </CLASSIFICATIONS>
<ABSTRACT>
This thesis analyzes the capabilities of neural networks
to model unknown nonlinear dynamic processes based on
observed input-output data. Two classes of neural
networks are investigated: global feedforward neural
networks (multilayer perceptron (MLP)) and local
feedforward neural networks (radial basis function
network (RBFN)). Training algorithms and structure
optimization methods for these networks are described
and evaluated for identification and control purposes.
The primary objective of this thesis is to improve
traditional neural network models by incorporating prior
knowledge. Three approaches to combining neural networks
and a priori knowledge are examined. First, a fuzzy
neural network controller is developed which captures
the advantages of both fuzzy logic and neural networks.
The controller is transparent since the linguistic
variables of the fuzzy methodology make the control
action interpretable. At the same time, a learning
algorithm can be applied to adjust the controller on-
line since the controller possesses a neural network
structure. Second, a multimodel approach is presented
which allows the combination of various modeling
techniques. A priori knowledge is used to decompose the
input domain. The resulting regimes are modeled
separately by neural networks. The decomposition based
on prior knowledge is compared to unsupervised learning
methods and to nonlinear gated experts. Third,
combinations of prior knowledge in the form of first
principle models and neural networks are explored for
both global and local model structures.
These model structures and algorithms are evaluated by
simulating various processes common in chemical
engineering, namely a laboratory scale waste water
neutralization process, a continuous pulping process,
and a fed-batch fermentation process.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  4028 </NUMBER>
<ORDER>   AAGMM18543 </ORDER>
<TITLE> STIMULUS ARTIFACT REDUCTION IN SOMATOSENSORY EVOKED POTENTIAL MEASUREMENTS USING NEURAL NETWORK BASED ADAPTIVE FILTERS </TITLE>
<AUTHOR> GRIEVE, RICHARD CHARLES WILLIAM </AUTHOR>
<YEAR> 1996 </YEAR>
<INSTITUTION> THE UNIVERSITY OF NEW BRUNSWICK (CANADA); 0823 </INSTITUTION>
<DESCRIPTORS> ENGINEERING, ELECTRONICS AND ELECTRICAL; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> P.A. PARKER; B. S. HUDGINS </ADVISER>
<CLASSIFICATIONS> NIL </CLASSIFICATIONS>
<ABSTRACT>
Somatosensory evoked potentials (SEPs) are very useful
in diagnostic and intraoperative procedures. The SEP
suffers from poor signal-to-noise ratio (SNR). Time
coherent averaging, which reduces random noise and tends
to bring out the deterministic components, such as SEP
and stimulus artifact. The stimulus artifact comes about
as a result of the relatively large voltage applied to
the body, and tends to mask or at least distort the SEP.
This thesis studied the possibility of using adaptive
interference cancelling techniques based on a neural
network to reduce the stimulus artifact in SEP
measurements. The performance of the neural network-
based adaptive noise canceller was compared to the
performances of both an LMS driven linear adaptive noise
canceller and an RLS driven nonlinear adaptive noise
canceller. The SEP measurements were taken from the
median nerve in the wrist and the various filters were
used to separate stimulus artifact and SEP in situations
where they overlapped significantly. The different
filter structures were evaluated based on (1) the
ability to cancel without using a test set to evaluate
performance: (2) the ability to generalize from a
training set to a test set, and (3) the ability to
generalize from the initial section of a record where
only artifact is present to the section where SEP and
artifact overlap. The work showed that the linear filter
was unable to model the relationship between primary and
reference, and that the neural network outperformed the
nonlinear RLS with respect to generalization, resulting
in better SEP extraction. (Abstract shortened by UMI.)
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  4029 </NUMBER>
<ORDER>   AAG9719487 </ORDER>
<TITLE> SEARCH IN SAT/CSP:  PHASE TRANSITIONS, ABSTRACTION, AND COMPILATION  </TITLE>
<AUTHOR> SCHRAG, ROBERT CARL </AUTHOR>
<YEAR> 1996 </YEAR>
<INSTITUTION> THE UNIVERSITY OF TEXAS AT AUSTIN; 0227 </INSTITUTION>
<DESCRIPTORS> COMPUTER SCIENCE; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> DANIEL P. MIRANKER </ADVISER>
<CLASSIFICATIONS> ARTIFICIAL INTELLIGENCE </CLASSIFICATIONS>
<ABSTRACT>
Constraint satisfaction problems (CSPs) are central in
artificial intelligence, including propositional
satisfiability (SAT) as a special case. We investigate
three approaches improving on the efficiency of
backtracking search for solving CSPs: "nogood
techniques" to prune parts of the search space; "domain
abstraction" to reduce the size of the search space
itself; and "knowledge compilation" (KC) to skirt the
need for backtracking in propositional deduction. We
evaluate each approach with reference to an appropriate
parameterized space of random CSPs, and we introduce new
KC techniques.
In Part I, we describe profiles of implicates and prime
implicates in the Random 3SAT problem space. (Prime)
implicates correspond directly to (minimal) nogoods.
Using the implicate profiles, we predict where CSP
techniques which rely on the existence of small nogoods
will be effective. Using the prime implicate profiles,
we predict the effectiveness of some approaches to
knowledge compilation. We also show how the well-known
satisfiability "phase transition" behavior in Random
3SAT generalizes when we consider implicates and prime
implicates of non-zero length.
In Part II, we find that the effectiveness of domain
abstraction drops off suddenly as degree of abstraction
is increased. The abstraction tends to loosen
constraints, resulting in a shifted phase transition
boundary for the problem space. Qualitatively, the
boundary restricts effectiveness to very tight input
constraints. Quantitatively, we develop and verify a
series of analytical approximations predicting the phase
transition location for abstraction's effectiveness. Of
possible independent interest, we include corrections to
a standard formula approximating the phase transition
surface.
In Part III, we describe a framework for KC based on
both prime implicates and prime implicants. We show that
many "critically constrained" Random 3SAT knowledge
bases (KBs) can be compiled into disjunctive normal form
easily by using a variant of the "Davis-Putnam" proof
procedure. From these compiled KBs we can answer all
queries about entailment of conjunctive normal formulas,
also easily. We develop an aggressive hybrid approach--
"bootstrapped KC"--which falls back to approximate
compilation if specified resources are exhausted and
handles all the KBs with an order of magnitude's
savings.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  4030 </NUMBER>
<ORDER>   AAG9719417 </ORDER>
<TITLE> SPATIAL SEMANTIC HIERARCHY FOR A PHYSICAL MOBILE ROBOT </TITLE>
<AUTHOR> LEE, WAN YIK </AUTHOR>
<YEAR> 1996 </YEAR>
<INSTITUTION> THE UNIVERSITY OF TEXAS AT AUSTIN; 0227 </INSTITUTION>
<DESCRIPTORS> COMPUTER SCIENCE; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> BENJAMIN J. KUIPERS </ADVISER>
<CLASSIFICATIONS> MAPPING, SENSORIMOTOR, NAVIGATION, MACHINE LEARNING, ARTIFICIAL INTELLIGENCE </CLASSIFICATIONS>
<ABSTRACT>
This dissertation describes research to extend and
improve the Spatial Semantic Hierarchy (SSH) approach to
robot exploration and mapping, and to demonstrate and
evaluate its effectiveness in controlling physical
mobile robots.
The SSH approach for robot exploration and mapping was
first developed in the context of a simulated robot, NX,
and tested in simulated environments with very simple
models of sensorimotor error. Physical implementations
of aspects of the SSH approach have been built by other
researchers but they do not provide adequate
demonstration of its strengths or adequate analysis of
its conditions of applicability.
The dissertation work extended and improved the SSH
mapping theory from its original prototype to a version
capable of handling real sensorimotor interaction with a
real (office) environment. The underlying goal of this
research is to demonstrate how symbolic, representations
and symbol-based behaviors of an autonomous robot can be
grounded in non-symbolic, continuous sensorimotor
interaction with a real environment through the SSH
approach. The extended theory is implemented on a
physical robot to explore a previously unknown
environment, and to create an SSH spatial description of
the environment. This dissertation describes the
improved SSH mapping theory, the details of its
implementation on a physical robot, and a demonstration
and evaluation of several features of the
implementation.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  4031 </NUMBER>
<ORDER>   AAG9719402 </ORDER>
<TITLE> REFINING IMPRECISE MODELS AND THEIR BEHAVIORS </TITLE>
<AUTHOR> KAY, HERBERT </AUTHOR>
<YEAR> 1996 </YEAR>
<INSTITUTION> THE UNIVERSITY OF TEXAS AT AUSTIN; 0227 </INSTITUTION>
<DESCRIPTORS> COMPUTER SCIENCE; ENGINEERING, GENERAL; ENGINEERING, CHEMICAL; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> BENJAMIN J. KUIPERS </ADVISER>
<CLASSIFICATIONS> ORDINARY DIFFERENTIAL EQUATIONS, MACHINE LEARNING, QUALITATIVE REASONING, ARTIFICIAL INTELLIGENCE </CLASSIFICATIONS>
<ABSTRACT>
This dissertation describes methods for simulating and
refining imprecisely-defined Ordinary Differential
Equation (ODE) systems. When constructing a model of a
physical process, a modeler must cope with uncertainty
due to incomplete knowledge of the process. For tasks
such as design and diagnosis, the effects of this
uncertainty must be considered. However, predicting the
behavior of an imprecisely-defined model is not easy
since the model covers a space of many precise
instances, each of which behaves differently.
While model uncertainty cannot be completely eliminated,
it is possible to reduce it. Model refinement uses
observations of a physical process to rule out portions
of the model space that could not have produced the
observations. As more experience with the physical
process is gained, the imprecision in the model is
further reduced.
This dissertation describes three methods for reasoning
with imprecise ODE models. SQ sc SIM is a simulator that
produces a guaranteed bound on the behavior of an
imprecise ODE model. By using a multiple-level
representation and inference methods that span the
qualitative-to-quantitative spectrum, SQ sc SIM produces
predictions whose uncertainty is consistent with model
imprecision. We demonstrate SQ sc SIM on a complex,
nonlinear chemical process and compare it to other
methods for simulating imprecise ODE models.
MSQUID is a function estimator for fitting (and
bounding) noisy data that is known to be monotonic. It
uses a neural-network inspired model and nonlinear
constrained optimization to search a space of monotonic
functions. We prove that MSQUID can estimate any
monotonic function and show that it produces better
estimates than does unconstrained optimization.
SQUID, which uses SQ sc SIM and MSQUID as components, is
a system identification method that refines an imprecise
model using a stream of observations from a physical
process. SQUID uses refutation to rule out portions of
the model space that are inconsistent with the
observations. We show that this approach to refinement
is significantly more efficient than parameter
estimation for models with functional uncertainty and
that it provides greater robustness in the face of
uninformative observations.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  4032 </NUMBER>
<ORDER>   AAG9719315 </ORDER>
<TITLE> A MIXTURE-OF-EXPERTS APPROACH TO ADAPTIVE ESTIMATION </TITLE>
<AUTHOR> CHAER, WASSIM SAMIR </AUTHOR>
<YEAR> 1996 </YEAR>
<INSTITUTION> THE UNIVERSITY OF TEXAS AT AUSTIN; 0227 </INSTITUTION>
<DESCRIPTORS> ENGINEERING, AEROSPACE; ENGINEERING, SYSTEM SCIENCE; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> ROBERT H. BISHOP </ADVISER>
<CLASSIFICATIONS> KALMAN FILTER, INTERPLANETARY, GENETIC ALGORITHM, NAVIGATION </CLASSIFICATIONS>
<ABSTRACT>
The mathematical model and model parameters we use to
describe a physical system generally do not match
reality. The models are a mathematical approximation of
the real world. The Kalman filter assumes that the model
and model parameters perfectly describe the physical
system. Also, when the model parameters are time-
varying, the variation is assumed to be known exactly.
In real-world problems uncertainties always exist. To
address the problem of filtering in the presence of
uncertainty, a new approach to adaptive filtering is
developed and investigated for application to
interplanetary spacecraft navigation.
A modular and flexible approach to adaptive Kalman
filtering using the framework of a mixture-of-experts
regulated by a gating network is proposed. Each expert
is a Kalman filter modeled with a different realization
of the unknown system parameters. The gating network
performs on-line adaptation based on filter performance.
The proposed scheme compares very favorably with the
classical Magill filter bank (which is based on a
Bayesian technique) in terms of (i) estimation accuracy,
(ii) response to changing external environments, and
(iii) numerical stability and computational demands. The
on-line weight assignment performed by the gating
network is accomplished utilizing an instantaneous
gradient ascent learning algorithm. The expectation-
maximization algorithm is also shown to be an applicable
learning strategy in the proposed framework.
The proposed filter bank is further enhanced by
periodically using a search algorithm in a feedback
loop. Two search algorithms are considered. The first
algorithm uses a recursive quadratic programming
approach which extremizes a modified maximum likelihood
function to update the parameters of the best performing
filter in the bank. The second algorithm uses a genetic
algorithm to search for the parameter vector.
The proposed adaptive Kalman filtering framework is also
extended to a hierarchical architecture which involves
multiple levels of gating. This particular architecture
provides a multi-level hypothesis testing capability by
allowing the examination of parameter variations in
isolation, as well as in combination with other
parameters.
The workings and power of the filtering architectures
are illustrated using a simulated Mars Pathfinder
mission. The obtained results demonstrate the
effectiveness of the adaptive Kalman filtering schemes.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  4033 </NUMBER>
<ORDER>   AAG9718674 </ORDER>
<TITLE> PATTERN RECOGNITION OF TRAFFIC SIGNS WITH A PERSONAL COMPUTER </TITLE>
<AUTHOR> DOUVILLE, PHILIP LAVERN </AUTHOR>
<YEAR> 1996 </YEAR>
<INSTITUTION> THE UNIVERSITY OF DAYTON; 0327 </INSTITUTION>
<DESCRIPTORS> COMPUTER SCIENCE; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> NIL </ADVISER>
<CLASSIFICATIONS> PC)  (IMAGE PROCESSING, GABOR, TEMPLATE MATCHING, ARTIFICIAL INTELLIGENCE </CLASSIFICATIONS>
<ABSTRACT>
A challenging pattern recognition problem is to develop
a rotation, scale, and translation invariant recognition
system without high computational expense. This
dissertation attempts to develop an integrated software
program to recognize monochrome images of traffic signs.
The test images were recorded using a video camcorder at
different times of day, season, weather, angles, and
range.
An integrated workstation in a Windows environment has
been used to perform image processing and pattern
recognition functions. The image processing functions
considered herein include the Fourier Transform, noise
addition, linear and morphological filters, and Gabor
feature analysis while the pattern recognition functions
are template matching, statistical pattern recognition,
and the multi-layer perceptron. The software design
objective was to demonstrate the advantage of using self-
similar Gabor wavelet features in statistical pattern
matching and a multi-layer perceptron over whole image
template matching. A database of 540 training images and
50 test images of signs and backgrounds supports the
software.
The result is a unique software capability for image
pattern recognition on a Personal Computer which allows
Windows interaction and real-time results. New
understanding of visual pattern recognition and its
limitations and usage was achieved. The images were not
segmented. An attempt was made to show that the features
of the sign would dominate the non-stationary clutter. A
truncated Gabor wavelet feature was developed to
demonstrate rotation, scale, and translation invariance
with bandpass wavelets using linear Fourier techniques.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  4034 </NUMBER>
<ORDER>   AAG9718533 </ORDER>
<TITLE> MODULARITY AND COMMUNICATION IN MULTIAGENT PLANNING </TITLE>
<AUTHOR> BRIGGS, WILLIAM SAXTON </AUTHOR>
<YEAR> 1996 </YEAR>
<INSTITUTION> THE UNIVERSITY OF TEXAS AT ARLINGTON; 2502 </INSTITUTION>
<DESCRIPTORS> COMPUTER SCIENCE; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> DIANE J. COOK </ADVISER>
<CLASSIFICATIONS> MACHINE LEARNING </CLASSIFICATIONS>
<ABSTRACT>
Machine planning could save a great deal of programmer
time if it were tractable, and could help robots design
their own plans when human help is not available.
Planning with multiple agents faces significantly more
severe costs than single-agent planning, in that inter-
agent communication is even costlier than planning
itself. The intractable cost of communication is even
costlier than planning itself. The intractable cost of
communication must be reduced if multiagent planning is
to be practical. Social laws, by constraining action,
reduce the possibilities a planner must consider and
thus reduce communication, but at the cost of optimality
or even soundness. We propose a method by which agents
may reduce both planning and communication costs by
planning with stringent social laws, relaxing the laws
as needed to find a solution, and show that the cost is
at worst not significantly worse than with no law. We
analyze methods of sharing the planning task between
cooperative agents, and show what form of sharing (if
any) produces the greatest savings in communication. We
provide and implement a practical model for representing
social laws, and show a method for learning laws in
minimal time; we also present a method for generating
and relaxing exclusive resource allocations in specific
planning situations, and show that the method performs
significantly better than random in the average case.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  4035 </NUMBER>
<ORDER>   AAG9718311 </ORDER>
<TITLE> THE HIERARCHICAL STRUCTURE OF NEURAL NETWORK FOR THE COMPLICATED DATA SET CLASSIFICATION PROBLEMS </TITLE>
<AUTHOR> CHANG, JOONGHO </AUTHOR>
<YEAR> 1996 </YEAR>
<INSTITUTION> TEXAS A&M UNIVERSITY; 0803 </INSTITUTION>
<DESCRIPTORS> COMPUTER SCIENCE; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> N. C. GRISWOLD </ADVISER>
<CLASSIFICATIONS> ARTIFICIAL INTELLIGENCE, OVERLAPPED, MLP, LICENSE PLATE, CORK QUALITY, PATTERN RECOGNITION </CLASSIFICATIONS>
<ABSTRACT>
The area of the neural networks is getting more and more
attention in the hope that it will narrow the gap
between a human being's intelligence and intelligence
built into a computer. Especially in the classification
of patterns, the area of neural networks has already had
many applications and good results. However for the
complicated data set classification, neural networks
still remain with many weak points compared to a human
being's intelligence. The main reason for this big
difference between a human and a neural network can be
said to be the analysis ability for patterns in a
hierarchical manner.
This dissertation proposes two different styles of
Hierarchical Multilayer Perceptron (HMLP) neural network
as the improved classifiers. The complicated data set
classification problems can be represented as two
different types, (1) the large sized classification and
(2) the highly overlapped classification problems. In
the case of large sized classification problem, the
conventional single stage of a MLP classifier is
insufficient and causing the overtraining problem to
build up complicated decision boundaries for all classes
at one stage. HMLP is built up by hierarchically
stacking the small MLP subnetworks that work as local
classifiers in the feature space. Each subnetwork is
trained so as not to cause overtraining. The
generalization and overtraining problems of neural
networks were reduced by this method. Also in the case
of a highly overlapped data set, the Bayesian
classification rule is implemented with several sub-MLP
neural networks. This scheme and its relation to
overtraining and generalization problems are discussed.
The test results for both classification problems showed
that the HMLP had better classification ability with the
smaller network size and computation burden. These two
different styles of HMLP classifiers were implemented
for the automobile license plate number recognition
system and the cork quality classification system.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  4036 </NUMBER>
<ORDER>   AAG9718310 </ORDER>
<TITLE> IDENTIFICATION OF HUMAN CORTICAL STRUCTURES IN MAGNETIC RESONANCE IMAGING BY ENCAPSULATING EXPERT ANATOMICAL KNOWLEDGE IN FUZZY LOGIC  </TITLE>
<AUTHOR> CHANG, CHIH-WEI </AUTHOR>
<YEAR> 1996 </YEAR>
<INSTITUTION> TEXAS A&M UNIVERSITY; 0803 </INSTITUTION>
<DESCRIPTORS> COMPUTER SCIENCE; ARTIFICIAL INTELLIGENCE; ENGINEERING, BIOMEDICAL </DESCRIPTORS>
<ADVISER> JOHN YEN </ADVISER>
<CLASSIFICATIONS> CLASSIFICATION, ARTIFICIAL INTELLIGENCE, FCM </CLASSIFICATIONS>
<ABSTRACT>
Magnetic Resonance Imaging (MRI) is an important non-
invasive technique to examine the human brain. The
identification of different brain components and
structures is a necessary precursor to conduct both
qualitative and quantitative measurements. Because of
the extreme complexity and variability of human cortical
structures from person to person, knowledge of
anatomical and neurological structure is needed to
analyze the acquired brain images. To handle the
uncertainty due to the complexity and variability of
human cortical structures, fuzzy logic and rules are
applied to encapsulate the expert anatomical knowledge
into a computer system.
Three major techniques have been developed in this
research. The first technique is a fuzzy knowledge-based
system that encapsulates expert knowledge to identify
the human cortical structures. Because the major
cortical structures, such as sulci and gyri, are located
on the brain surface, a two-dimensional brain surface
map has been constructed. In this research, this system
successfully identified the central sulci and lateral
sulci. Then, according to the position of these sulci,
the system can label the location of the frontal lobe.
The second technique is a hybrid fuzzy image
segmentation system that is used to conduct both
qualitative and quantitative measurements on the brain
MRI. This system combines the advantages of both
supervised learning system, which is a fuzzy knowledge-
based system, and unsupervised learning method, which is
a fuzzy classification algorithm. A self-adaptive
membership justification method has been invented to
automatically identify the parameters of the fuzzy
rules. Both normal brain image classification and lesion
detection have been conducted and confirmed by medical
experts. The last technique is a new multi-prototype
fuzzy c-means (MFCM) algorithm that extends the fuzzy c-
means (FCM) algorithm by allowing each class to have
more than one prototype. The original FCM algorithm has
been widely used in medical image segmentation. We have
evaluated the MFCM algorithm using Fisher's IRIS data
set. The new algorithm achieves a better performance
than FCM in terms of both accuracy and speed.
In these new techniques, fuzzy logic has been widely
used. The major advantage of using fuzzy logic is that
the fuzzy rules encapsulate the expert knowledge in
linguistic form. This research not only demonstrates a
promising alternative approach to the human cortical
structure identification, but also introduces several
new techniques for both medical image segmentation and
fuzzy classification. Most of these new techniques are
sufficiently general to be applied to other problem
areas.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  4037 </NUMBER>
<ORDER>   AAG9717850 </ORDER>
<TITLE> BIPED DYNAMIC WALKING USING REINFORCEMENT LEARNING </TITLE>
<AUTHOR> BENBRAHIM, HAMID </AUTHOR>
<YEAR> 1996 </YEAR>
<INSTITUTION> UNIVERSITY OF NEW HAMPSHIRE; 0141 </INSTITUTION>
<DESCRIPTORS> ENGINEERING, ELECTRONICS AND ELECTRICAL; COMPUTER SCIENCE; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> W. THOMAS MILLER, III </ADVISER>
<CLASSIFICATIONS> ARTIFICIAL INTELLIGENCE </CLASSIFICATIONS>
<ABSTRACT>
This thesis presents a study of biped dynamic walking
using reinforcement learning. A hardware biped robot was
built. It uses low gear ratio DC motors in order to
provide free leg movements. The Self Scaling
Reinforcement learning algorithm was developed in order
to deal with the problem of reinforcement learning in
continuous action domains. A new learning architecture
was designed to solve complex control problems. It uses
different modules that consist of simple controllers and
small neural networks. The architecture allows for easy
incorporation of modules that represent new knowledge,
or new requirements for the desired task. Control
experiments were carried out using a simulator and the
physical biped. The biped learned dynamic walking on
flat surfaces without any previous knowledge about its
dynamic model.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  4038 </NUMBER>
<ORDER>   AAG9720335 </ORDER>
<TITLE> A CASE-BASED REASONING APPROACH TO BANKRUPTCY PREDICTION MODELING  </TITLE>
<AUTHOR> BRYANT, STEPHANIE MATTOX </AUTHOR>
<YEAR> 1996 </YEAR>
<INSTITUTION> THE LOUISIANA STATE UNIVERSITY AND AGRICULTURAL AND MECHANICAL COL.; 0107 </INSTITUTION>
<DESCRIPTORS> BUSINESS ADMINISTRATION, ACCOUNTING; ARTIFICIAL INTELLIGENCE; BUSINESS ADMINISTRATION, GENERAL </DESCRIPTORS>
<ADVISER> BARBARA A. APOSTOLOU </ADVISER>
<CLASSIFICATIONS> ARTIFICIAL INTELLIGENCE, MACHINE LEARNING </CLASSIFICATIONS>
<ABSTRACT>
This study examines the usefulness of an artificial
intelligence method, case-based reasoning (CBR), in
predicting corporate bankruptcy. Based on prior
research, CBR is believed to be a viable method of
predicting bankruptcy. Hypotheses are developed to test
the usefulness of a CBR system and to compare the
accuracy of such a system to the model considered to be
the benchmark model in bankruptcy prediction, Ohlson's
(1980) nine-factor logistic regression (logit) model.
Sample data consisting of manufacturing and industrial
firms is drawn from the Compustat database in a 20:1
ratio of nonbankrupt to bankrupt firms, consistent with
Ohlson's (1980) proportions. Three CBR models
representing one, two, and three years before bankruptcy
are designed and developed using a CBR development tool,
ReMind. Cross-validation is done using a 10% in-period
holdout sample as well as a holdout sample of firms from
outside the period from which the model is constructed.
Three logit models based on Ohlson (1980) representing
one, two, and three years before bankruptcy are
constructed. The usefulness of the CBR system is
determined by examination of type I and type II error
rates. Chi-square statistics are used to compare the
predictive accuracy of the three CBR models with the
three logit models.
The results indicate that the CBR method using ReMind is
not useful in predicting corporate bankruptcy. It is
believed that the small sample of bankrupt firms
(relative to the sample size of nonbankrupt firms)
contributes to the failure of these CBR models to
accurately predict bankruptcy. Compared with two other
studies that also use ReMind as development tools, there
is evidence that the algorithm in ReMind does not
accommodate small sample sizes. The results also
indicate that CBR is not more accurate than the Ohlson
(1980) logit model. Ohlson's (1980) logit models attain
a much higher accuracy rate than the CBR models and
appear to be more stable over time than the CBR models.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  4039 </NUMBER>
<ORDER>   AAG9737844 </ORDER>
<TITLE> IDENTIFICATION OF NONLINEAR DYNAMIC SYSTEMS USING THE VOLTERRA NETWORK  </TITLE>
<AUTHOR> FARROKHI, MOHAMMAD </AUTHOR>
<YEAR> 1996 </YEAR>
<INSTITUTION> SYRACUSE UNIVERSITY; 0659 </INSTITUTION>
<DESCRIPTORS> ENGINEERING, ELECTRONICS AND ELECTRICAL; ARTIFICIAL INTELLIGENCE; COMPUTER SCIENCE </DESCRIPTORS>
<ADVISER> NIL </ADVISER>
<CLASSIFICATIONS> RECURRENT NEURAL NETWORKS </CLASSIFICATIONS>
<ABSTRACT>
Identification and control of nonlinear dynamic systems
are typically established on a case-by-case basis, since
there are no general methods for, at least, a large
class of such systems. Recurrent Neural networks (RNNs)
have the potential to model nonlinear dynamic systems
due to the fact that: (1) they have the ability to learn
the nonlinear relationship between the input and the
output of the system, (2) the information at the output
is fed hack to the input, thus creating a non-linear
dynamic mapping. This dissertation presents a new RNN
especially useful for system identification of highly
nonlinear dynamic systems such as robot manipulators.
This RNN is composed of a linear dynamic network,
cascaded with a nonlinear static network. It is
analytically proved that this network is capable of
modeling a large class: of single-input as well as multi-
input nonlinear dynamic systems by showing its
equivalence to the Volterra series expansion of such
systems. Therefore this new RNN possesses the
approximation power of the Volterra series, and is
called the Volterra Network. A two-method learning
scheme is proposed for the Volterra network. For the
linear dynamic network a new learning algorithm is
proposed, based on Prony analysis. The nonlinear static
network can be trained using any method appropriate for
feedforward networks, such as the back-propagation
algorithm. The operation of the Volterra Network is
demonstrated using examples of single-input as well as
multi-input nonlinear dynamic systems. The advantage of
the proposed RNN is that there exist well-known
mathematical tools to analyze the behavior of the
subnetworks of the Volterra network. Moreover, due to
the proposed training schemes the nonlinear dynamic
system can be considered as a black-box, hence there is
no need for a priori knowledge of the system under
investigation. The simulation results clearly
demonstrate the efficiency of the Volterra network,
since the error between the desired and actual outputs
is very small, and remains virtually constant even
during the testing phase of the Volterra network.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  4040 </NUMBER>
<ORDER>   AAGC543002 </ORDER>
<TITLE> PARALLELIZATION OF BACKPROPAGATION TRAINING FOR FEEDFORWARD NEURAL NETWORKS </TITLE>
<AUTHOR> TORRESEN, JIM </AUTHOR>
<YEAR> 1996 </YEAR>
<INSTITUTION> NORGES TEKNISKE HOGSKOLE (NORWAY); 5714 </INSTITUTION>
<DESCRIPTORS> COMPUTER SCIENCE; ARTIFICIAL INTELLIGENCE NTNU, N-7034  TRONDHEIM-NTH, NORWAY </DESCRIPTORS>
<ADVISER> NIL </ADVISER>
<CLASSIFICATIONS> NIL </CLASSIFICATIONS>
<ABSTRACT>
The main objective of the work presented in this
dissertation is to speed up artificial neural network
training using parallel processing. The back propagation
trained feed-forward neural network was selected for
this research, since it has attracted most interest
among neural network researchers.
This thesis proposes both fixed and flexible
implementations. The former uses a static assignment,
which is independent of the network structure and
training set. The latter uses an assignment strategy
where the partitioning of the training set and neural
network is based on the given application. As such, the
parallel program can execute efficiently for a large
range of neural applications.
Several real neural applications have been used in this
work to test the implemented parallel algorithms. The
results show that it is beneficial to use a flexible
mapping. For small parallel systems, many parallel
implementations can train efficiently. However, the
importance of a flexible job assignment is more
prominent as the number of processors increases. Thus,
to gain the full benefit of a large parallel system the
multiple inherent degrees of parallelism in the training
algorithm must be combined. Also the method of combining
the parallel aspects of the training algorithm should be
adaptable according to the given neural application.
Two tests on convergence of back propagation trained
neural network are also reported. The results indicate
that if training set partitioning is used, in the
parallel scheme, a larger number of iterations is needed
for convergence. However, still the total training time
required, by using a parallel computer, is reduced from
hours to minutes with respect to a sequential computer.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  4041 </NUMBER>
<ORDER>   AAGC540658 </ORDER>
<TITLE> AUFBAU PLANERISCHER INFORMATIONSSYTEME AM BEISPIEL DER RICHTPLANUNG GEMAESS DEM SCHWEIZERISCHEN BUNDESGESETZ UEBER DIE RAUMPLANUNG; STRUCTURE OF PLANNING INFORMATION SYSTEMS ACCORDING TO THE "GUIDING PLANNING" OF THE SWISS FEDERAL LAW OF SPATIAL PLANNING </TITLE>
<AUTHOR> VON ROTZ, ROBERT </AUTHOR>
<YEAR> 1996 </YEAR>
<INSTITUTION> EIDGENOESSISCHE TECHNISCHE HOCHSCHULE ZUERICH (SWITZERLAND); 0663 </INSTITUTION>
<DESCRIPTORS> URBAN AND REGIONAL PLANNING; INFORMATION SCIENCE; ARTIFICIAL INTELLIGENCE ZURICH, SWITZERLAND </DESCRIPTORS>
<ADVISER> NIL </ADVISER>
<CLASSIFICATIONS> NIL </CLASSIFICATIONS>
<ABSTRACT>
Physical Planning and spatial organization have to
assure a continuous coordination of all spatially
relevant activities. For that, coordination of
information on spatially relevant intentions is an
irrevocable prerequisite. Planning Information Systems
do support this task in a decisive way.
It is well known that the subjects of interest to the
planning agencies are not finally definable. This leads
usually to a large amount of various and often
inconsistent data. From the point of view of a given
(mostly complex) planning problem, it is often not
possible to get the appropriate data from conventional
information systems (e.g. databases). To begin with, an
experimental prototype has been developed to examine
questions of suitable support of planning argumentation.
P.I.A. (Planning Information Assistant) is an
experimental shell at the disposition of the planner,
fulfilling the duty as personal assistant. The main
issue is to realize a user-centered view of information-
handling and to allow an integrated view at different
kinds of information, treated with different methods. In
the center stands a so-called "document of reasoning".
From there the user will have access to a three-
dimensional advisory support: (1) support by
administrative helps, (2) support by planning methods
and (3) support for the management of versions and
variants.
To begin with, the thesis explains methodological and
operational fundamentals of the "guiding planning"
according to the Swiss Federal Law on Spatial Planning.
Existing implementations of Planning Information Systems
are inspected to get a comprehensive standard of
comparison to the proposal described above. Case-studies
with the developed experimental shell (P.I.A.)
demonstrate the usefulness of the system, but also some
remaining lacks. Therefore, the thesis closes with
general restrictions on the intention of Planning
Information Systems and their usefulness.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  4042 </NUMBER>
<ORDER>   AAGC539964 </ORDER>
<TITLE> EDGE DETECTION USING NEURAL NETWORK ARBITRATION </TITLE>
<AUTHOR> RAMALHO, MARIO ANTONIO DA SILVA NEVES </AUTHOR>
<YEAR> 1996 </YEAR>
<INSTITUTION> UNIVERSITY OF NOTTINGHAM (UNITED KINGDOM); 0616 </INSTITUTION>
<DESCRIPTORS> ENGINEERING, ELECTRONICS AND ELECTRICAL; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> NIL </ADVISER>
<CLASSIFICATIONS> IMAGE PROCESSING </CLASSIFICATIONS>
<ABSTRACT>
A human observer is able to recognise and describe most
parts of an object by its contour, if this is properly
traced and reflects the shape of the object itself. With
a machine vision system this recognition task has been
approached using a similar technique. This prompted the
development of many diverse edge detection algorithms.
The work described in this thesis is based on the visual
observation that edge maps produced by different
algorithms, as the image degrades, display different
properties of the original image. Our proposed objective
is to try and improve the edge map through the
arbitration between edge maps produced by diverse (in
nature, approach and performance) edge detection
algorithms. As image processing tools are repetitively
applied to similar images we believe the objective can
be achieved by a learning process based on sample
images.
It is shown that such an approach is feasible, using an
artificial neural network to perform the arbitration.
This is taught from sets extracted from sample images.
The arbitration system is implemented upon a parallel
processing platform. The performance of the system is
presented through examples of diverse types of image.
Comparisons with a neural network edge detector (also
developed within this thesis) and conventional edge
detectors show that the proposed system presents
significant advantages.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  4043 </NUMBER>
<ORDER>   AAGC539817 </ORDER>
<TITLE> NEURAL NETWORK BASED BANK-TO-TURN AUTOPILOTS </TITLE>
<AUTHOR> MCDOWELL, DAVID MATTHEW </AUTHOR>
<YEAR> 1996 </YEAR>
<INSTITUTION> QUEEN'S UNIVERSITY OF BELFAST (NORTHERN IRELAND); 0725 </INSTITUTION>
<DESCRIPTORS> ENGINEERING, ELECTRONICS AND ELECTRICAL; ENGINEERING, AEROSPACE; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> NIL </ADVISER>
<CLASSIFICATIONS> NIL </CLASSIFICATIONS>
<ABSTRACT>
This thesis investigates the application of artificial
neural networks to the development of bank-to-turn (BTT)
autopilots for a command-to-line-of-sight (CLOS) missile
system. The autopilot is required to take into
consideration the nonlinear effects of time-varying
dynamics, control surface constraints and cross-
coupling, in order to achieve a consistent performance
throughout the flight envelope.
A detailed analysis of neural networks is presented
which concentrates on the multi-layer Perceptron (MLP)
network and the Radial Basis Function (RBF) network and
their application to nonlinear control. An MLP network
is then trained off-line as the basis for a neural gain
scheduled autopilot. This work includes an extensive
appraisal of first- and second-order gradient descent
training algorithms for the MLP.
A novel hybrid adaptive BTT missile autopilot is
proposed which employs a Gaussian RBF network, in
parallel with a fixed-gain controller, to adaptively
compensate for the nonlinearities. The hybrid scheme is
extended to the coupled dynamics and a multivariable
neural autopilot is derived which uses rudder action to
regulate the sideslip acceleration.
A robust adaptive pitch plane autopilot is developed,
using Lyapunov's Direct method to prove stability. Here,
sliding mode control (SMC) is used in conjunction with a
RBF network to produce an adaptive control law which
forces the tracking errors to converge asymptotically to
a neighbourhood of zero.
The new neural BTT autopilots proposed are all evaluated
in simulation studies against realistic demand profiles
generated from a typical CLOS guidance scenario, and
their performances compared with constant parameter and
gain scheduled autopilots. The results clearly
demonstrate the potential advantages for using neural
networks in missile autopilot design in terms of
acceleration tracking accuracy and reduction in cross-
coupling effects.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  4044 </NUMBER>
<ORDER>   AAGC539776 </ORDER>
<TITLE> ARTIFICIAL NEURAL NETWORKS IN THE PROCESS INDUSTRY: CONCEPTS AND APPLICATIONS </TITLE>
<AUTHOR> CATFOLIS, THIERRY YVES </AUTHOR>
<YEAR> 1996 </YEAR>
<INSTITUTION> KATHOLIEKE UNIVERSITEIT LEUVEN (BELGIUM); 5605 </INSTITUTION>
<DESCRIPTORS> ENGINEERING, CHEMICAL; ENGINEERING, INDUSTRIAL; ARTIFICIAL INTELLIGENCE CAMPUSBIBLIOTHEEKDIENST,  CELESTIJNENLAAN 300 A, B-3001 LEUVEN (HEVERLEE), BELGIUM WETENSCHAPPEN,  ARENBERGKASTEEL, B-3001 HEVERLEE, BELGIUM </DESCRIPTORS>
<ADVISER> NIL </ADVISER>
<CLASSIFICATIONS> RTRL, CONTROL </CLASSIFICATIONS>
<ABSTRACT>
This thesis presents three key concepts on the use of
artificial neural networks in the process industry.
Starting from the point of view that standard neural
networks are not able to solve the heavy requirements of
real-world problems, an analysis of possible
improvements is performed. Three characteristics of the
process industry were selected as causing major problems
to basic neural networks: these characteristics are that
most processes are dynamic, complex and unknown systems.
The use of simple feedforward neural networks is not
adequate for solving dynamic problems. Complex recurrent
neural networks on the other hand have the drawback that
temporal knowledge about the process (e.g. residence
times, time-delays, etc.) is difficult to use. In this
thesis the clear impact principle is developed for using
temporal knowledge in the RTRL (Real-Time Recurrent
Learning) algorithm. The main advantage of this
technique is a reduction of the training time for RTRL
networks. This technique is applied to a dynamic pattern
recognition task and to the prediction of the average
chain length in a polymethylmethacrylate reactor.
The complexity of most processes causes that stand-alone
neural networks are not sufficient for solving real-
world problems. For that reason different hybridisation
and specialisation techniques for recurrent networks are
proposed. Many applications of these techniques are
proposed: PID tuning, adaptive modeling, multi-step
modelling and process control. Some of the hybridisation
and specialisation techniques are applied to a process
monitoring problem.
Due to the need of system models in many applications
(model-based diagnosis, model-based control, etc.), the
use of different techniques for system identification
and modelling has been investigated. That most processes
are not well known makes the use of structured modeling
techniques very difficult. In this thesis a recurrent
neural NARMAX (Non-linear AutoRegressive Moving Average
with eXogeneous inputs) modelling technique is
developed. This technique applies recurrent neural
networks to classical modelling methods and is tested in
the modelling of an industrial distillation column.
All three techniques are applied in an overall
application: the control of a highly non-linear
bioreactor.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  4045 </NUMBER>
<ORDER>   AAGC539124 </ORDER>
<TITLE> INTEGRACION DE LA PERCEPCION SENSORIAL Y LAS REDES NEURONALES EN UN ROBOT PARA LA MANIPULACION CON INCERTIDUMBRE; INTEGRATION OF SENSORY PERCEPTION AND NEURAL NETWORKS IN A ROBOT FOR MANIPULATION WITH UNCERTAINTY </TITLE>
<AUTHOR> MARTA IDDE, EDWARD </AUTHOR>
<YEAR> 1996 </YEAR>
<INSTITUTION> UNIVERSIDAD DE NAVARRA (SPAIN); 5864 </INSTITUTION>
<DESCRIPTORS> ENGINEERING, INDUSTRIAL; ENGINEERING, MECHANICAL; ARTIFICIAL INTELLIGENCE INGENIEROS INDUSTRIALES,  UNIVERSIDAD DE NAVARRA 20009, SAN SEBASTIAN, SPAIN </DESCRIPTORS>
<ADVISER> NIL </ADVISER>
<CLASSIFICATIONS> GRASPING </CLASSIFICATIONS>
<ABSTRACT>
A key problem in task planning is the unavoidable
presence of uncertainty. For a given design, once the
assembly parts and operations are selected, the
resources needed for each task have been planned, and
the order of the operations are established, a sequence
of subtasks has to be determined for each operation.
Each particular subtask requires, in its turn, a lower
level plan that may involve gross motion, fine motion,
or grasping actions. For robots working under real-world
conditions, all these motions are affected by
uncertainty.
In contrast with gross motion planning, fine motion
planning deals with small clearances and contact, for
which the existence of uncertainty may render useless a
synthesized plan. The use of sensors--mainly force and
torque sensors--is necessary to get information about
the actual situation of the process. A similar problem
arises in motions involving grasps.
This thesis addresses the problem of uncertainty in
robot assembly and assembly--like tasks involving fine
motion and grasping operations. A solution based on
unsupervised neural networks and force/torque sensing is
proposed. The technique is oriented toward applications
in real-world manufacturing environments, for which a
geometric analytical model may not be feasible. In these
cases the relations between the six sensor signals and
the contact states are very complex. The network will
learn to distinguish the different contact states,
without the need of a teacher, and will be used to
monitor the execution of the plans. In addition, due to
the short time required for the learning process and its
simplicity, it allows for a great flexibility.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  4046 </NUMBER>
<ORDER>   AAGC538870 </ORDER>
<TITLE> INDUSTRIAL ROBOT PROGRAMMING </TITLE>
<AUTHOR> NILSSON, KLAS INGEMAR </AUTHOR>
<YEAR> 1996 </YEAR>
<INSTITUTION> LUNDS UNIVERSITET (SWEDEN); 0899 </INSTITUTION>
<DESCRIPTORS> ENGINEERING, INDUSTRIAL; ARTIFICIAL INTELLIGENCE; COMPUTER SCIENCE 1010, S-221 03 LUND, SWEDEN </DESCRIPTORS>
<ADVISER> NIL </ADVISER>
<CLASSIFICATIONS> NIL </CLASSIFICATIONS>
<ABSTRACT>
Abstract Not Available.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  4047 </NUMBER>
<ORDER>   AAGC538179 </ORDER>
<TITLE> ALGORITHMS OF HUMAN MOTOR CONTROL AND THEIR IMPLEMENTATION IN ROBOTICS  </TITLE>
<AUTHOR> BURDET, ETIENNE </AUTHOR>
<YEAR> 1996 </YEAR>
<INSTITUTION> EIDGENOESSISCHE TECHNISCHE HOCHSCHULE ZUERICH (SWITZERLAND); 0663 </INSTITUTION>
<DESCRIPTORS> COMPUTER SCIENCE; ARTIFICIAL INTELLIGENCE; ENGINEERING, MECHANICAL TECHNOLOGY, ETH ZURICH,  SWITZERLAND </DESCRIPTORS>
<ADVISER> NIL </ADVISER>
<CLASSIFICATIONS> ARTIFICIAL INTELLIGENCE, MACHINE LEARNING, VISUOMOTOR COORDINATION </CLASSIFICATIONS>
<ABSTRACT>
There are many ways to learn how human beings control
their hand movements. One of the best is certainly the
constructive way. Using mathematics, computer science,
electronic and mechanical hardware, one has to design
algorithms and build machines which mimic human
behaviour. In other words, robotics can be used as a
tool in the investigation of human motor control. In
turn, one can examine which features of human motor
control are useful to robotics, and how they can be
implemented. Sometimes the biological models can even be
directly implemented to produce such human-like
behaviours.
We used this interdisciplinary approach to investigate
the problem of motion planning. By motion planning we
mean the preparation of arm movements appropriate for
the task to be accomplished, and its execution. We
examine how humans plan hand movements using sensory
information from vision and proprioception. We also
study how their robotic counterpart, a manipulator
guided by a vision system, deals with this problem.
To grasp an object, both a human and a robot have to
perform a reaching movement towards this object. It was
shown in previous works that simple reaching movements
are invariant under kinematic and dynamic
transformations. We therefore assume that human arm
movements are planned in extrinsic Cartesian coordinates
(corresponding to visual coordinates) and executed by a
nonlinear adaptive controller (expressed in intrinsic
joint coordinates). For planning we use the hypothesis
(consistent with recent observations) that the movement
is the superposition of discretely generated smooth
submovements. Each submovement aims to correct a
visually detected error and has some random variability
in its amplitude. Finally, the overall movement
maximixes smoothness and precision. In this way, the
motion is fully determined, and we can generate pseudo-
natural manoeuvres on the computer. Motor adaptation
(i.e. the adaptation to dynamic perturbations), the
speed/accuracy trade off, reactions to sudden changes in
the visual field and the variability of motions, are all
included in this one model. The kinematics of the
manoeuvres simulated on the computer and of measured
human movements are qualitatively and quantitatively
similar.
The aim of adaptive control is to develop motor
adaptation properties for robotic systems. We introduce
some tools to simplify the implementation of nonlinear
adaptive control schemes, evaluate currently proposed
schemes, and test experimentally the best algorithms to
find their sensitivity to noise and their ability to
compensate for friction.
Children learn to coordinate their movements with their
vision during infancy. In analogy, we designed and
implemented methods for learning to achieve the visuo
motor coordination for a robot guided by a vision
system. The robot also optimises its movements during
practice. An active vision (designed according to the
results of a mathematical analysis) enables precise real
time processing. The geometrical transformation between
the image and joint coordinates, the reaction time due
to vision and motion processing, and the optimal
velocity, are learned on-line during specified motions.
This is obtained by identifying the parameters critical
for visuo motor coordination and optimising them
stepwise, using cost functions for motion planning and
execution similar to the cost functions used in the
human model. After one hour, the robot has learned to
perform smooth and accurate motions, and is able to
track fast moving objects. The algorithms can be used as
a generalised calibration procedure for most robots
guided by vision. (Abstract shortened by UMI.)
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  4048 </NUMBER>
<ORDER>   AAGC538173 </ORDER>
<TITLE> COMPARISON OF CLASSIC AND HYBRID HMM APPROACHES TO SPEECH RECOGNITION OVER TELEPHONE LINES </TITLE>
<AUTHOR> HUTTER, HANS-PETER </AUTHOR>
<YEAR> 1996 </YEAR>
<INSTITUTION> EIDGENOESSISCHE TECHNISCHE HOCHSCHULE ZUERICH (SWITZERLAND); 0663 </INSTITUTION>
<DESCRIPTORS> COMPUTER SCIENCE; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> NIL </ADVISER>
<CLASSIFICATIONS> NEURAL NETWORKS, ARTIFICIAL INTELLIGENCE, SPEAKER INDEPENDENCE, GERMAN DIGITS, PERCEPTRONS </CLASSIFICATIONS>
<ABSTRACT>
The subject of this dissertation is the automatic speech
recognition over the public telephone network. Different
classic and hybrid HMM approaches are compared on the
speaker-independent recognition of isolated German
digits.
The first part of the thesis summarizes the theoretical
foundations of HMMs in general and discrete density HMMs
in particular. After that, different hybrid HMM
approaches are discussed with special emphasis on the so-
called connectionist-SCHMM approach based on
semicontinuous HMMs, which has been proposed by the
other.
The second part goes into the details of the design of
the experimental system RECO based on discrete density
HMMs. It covers all experiments that have led to the
high performance of this system which equals, on a
speaker-independent test set, the performance of a
computationally much more expensive reference system
based on continuous density HMMS.
In the last part, different hybrid approaches discussed
in the first part of the dissertation are compared with
each other and with the classic HMM approaches. The
comparison demonstrates, on the one hand, the
superiority of the proposed connectionist-SCHMM approach
over the other hybrid and classic HMM approaches. The
proposed approach uses a multilayer perceptron with
three feature vectors input context as a posteriori
probability estimator of phonetic element classes.
Finally, different concepts for incorporating multiple
features into the connectionist-SCHMM system are
investigated. Moreover, it is shown that the combination
of a connectionist-SCHMM system with a classic HMM
approach entails a considerable reduction of the
recognition errors of either system.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  4049 </NUMBER>
<ORDER>   AAG1383484 </ORDER>
<TITLE> SEEKING PARALLELISM IN DISCOVERY PROGRAMS </TITLE>
<AUTHOR> POTTS, JOSEPH TAYLOR </AUTHOR>
<YEAR> 1996 </YEAR>
<INSTITUTION> THE UNIVERSITY OF TEXAS AT ARLINGTON; 2502 </INSTITUTION>
<DESCRIPTORS> COMPUTER SCIENCE; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> DIANE J. COOK </ADVISER>
<CLASSIFICATIONS> NIL </CLASSIFICATIONS>
<ABSTRACT>
Automated discovery is a subfield of Machine Learning in
the field of Artificial Intelligence which attempts to
discern concepts or classifications from merely
examining examples or observations. As with other AI
programs, discovery programs often involve intensive
utilization of computer resources. Discovery programs
that run faster or are able to analyze larger sets of
data would be helpful to other researchers desiring to
utilize discovery programs in their own work.
This research explores ways to improve the performance
of discovery systems by enabling their execution on
parallel architectures. Two approaches to parallelizing
these programs are offered. Potential obstacles to
parallelization of discovery programs are discussed.
Finally, results of successful parallelizations of two
well known discovery programs, AutoClass and SUBDUE, are
presented.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  4050 </NUMBER>
<ORDER>   AAIC431557 </ORDER>
<TITLE> APPLICATIONS OF NEURAL NETWORKS FOR ENGINE AIR-FUEL RATIO CONTROL </TITLE>
<AUTHOR> O'REILLY, PAUL GERARD </AUTHOR>
<YEAR> 1994 </YEAR>
<INSTITUTION> QUEEN'S UNIVERSITY OF BELFAST (NORTHERN IRELAND); 0725 </INSTITUTION>
<DESCRIPTORS> ENGINEERING, AUTOMOTIVE; ARTIFICIAL INTELLIGENCE LIBRARY, CHLORINE GARDENS,  BELFAST BT9 5AG, NORTHERN IRELAND </DESCRIPTORS>
<ADVISER> NIL </ADVISER>
<CLASSIFICATIONS> NIL </CLASSIFICATIONS>
<ABSTRACT>
This thesis presents a study of three applications of
artificial neural networks to the AFR control problem in
four-stroke I.C. engines. The aim of engine control is
to maintain stoichiometry during transients. This is
desirable for efficient catalyst behaviour.
A simulator is developed, using an already existing
phenomenological engine model. To attain real-time
simulation, a network of five Inmos T800 transputers is
used. These are programmed to simulate the engine, using
a novel technique that itself simulates the operation of
a hybrid computer. This provides the basis for the
simulator, on which the development described in the
remainder of the thesis is based.
After a brief introduction to backpropagation neural
networks, the use of such networks in system
identification is described. ANNs are used in an attempt
to predict or, preferably, estimate AFR. This study
showed that accurate prediction was possible with a
moderately sized network, but that the networks required
for estimation are very large, and do not capture the
essential dynamics of the manifold.
The use of ANNs in control is studied. Two approaches
were taken: direct control and internal model control.
The former approach uses the available measurements from
the simulator to calculate the fuel command. In
comparison to the equivalent model-based direct
controller, the NN-based one is unsatisfactory, giving
insufficiently good control over transients. The latter
approach uses an SISO manifold model in an internal
model control scheme. The comparison with the model-
based equivalent was made, and in this case the NN-based
controller gave superior performance.
Finally, the four controllers are compared; the neural
network IMC compares favourably to the model-based
direct controller, with the advantage that no a priori
knowledge is necessary. Suggestions for further work are
proposed, which would improve the control, and be able
to be implemented on an actual engine.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  4051 </NUMBER>
<ORDER>   AAI1362476 </ORDER>
<TITLE> THE TIRESIAS SWITCH. </TITLE>
<AUTHOR> SHEFTALL, MORDECAI GEORGE </AUTHOR>
<YEAR> 1994 </YEAR>
<INSTITUTION> CALIFORNIA STATE UNIVERSITY, DOMINGUEZ HILLS; 0582 </INSTITUTION>
<DESCRIPTORS> LITERATURE, AMERICAN; BIOLOGY, NEUROSCIENCE; COMPUTER SCIENCE </DESCRIPTORS>
<ADVISER> NIL </ADVISER>
<CLASSIFICATIONS> ORIGINAL WRITING </CLASSIFICATIONS>
<ABSTRACT>
The revolutionary advances in recent years evident in
the fields of bio-engineering, medical technology,
communications, electronic data/information systems and
artificial intelligence, while notable and even laudable
milestones of human endeavor, also raise the specter of
a future in which, as the machines and artificially
sentient entities of our own creation become
increasingly human in nature, we will proportionately
lose our humanity and come to resemble machines. It is
possible that, as a logical development of this trend, a
somewhat more distant future may find the human race
physically extinct, but living on as entities suspended
in electronic, or, "cyber" space, having long hence
abandoned our bodies, mortal, disease-prone and
inefficient as they are. The Tiresias Switch explores
these issues and the possibilities and dangers inherent
in them in a tale of two brothers and of the healing
power of love--something that can never be digitalized.
</ABSTRACT>
</THESIS>

<THESIS>
<NUMBER>  4052 </NUMBER>
<ORDER>   AAIMM97107 </ORDER>
<TITLE> APPLICATION DES RESEAUX DE NEURONES ARTIFICIELS A LA VERIFICATION DYNAMIQUE DES SIGNATURES </TITLE>
<AUTHOR> LALONDE, MARC </AUTHOR>
<YEAR> 1994 </YEAR>
<INSTITUTION> ECOLE POLYTECHNIQUE, MONTREAL (CANADA); 1105 </INSTITUTION>
<DESCRIPTORS> COMPUTER SCIENCE; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER> JEAN-JULES BRAULT </ADVISER>
<CLASSIFICATIONS> FRENCH TEXT </CLASSIFICATIONS>
<ABSTRACT>
This dissertation reports the results of studies that
have been carried out in order to show how the problem
of authentifying a signature by analysis of its dynamics
can be dealt with using neural approaches.
The document is divided into five chapters: chapter one
introduces preliminary concepts useful to the
understanding of the following sections; chapter two
reports a review of the literature about the use of ANNs
in signature verification; chapter three discusses the
nature of the data to be processed as well as various
preprocessing steps (including signature segmentation);
chapter four constitutes the main body of this work and
it describes the design of a neural automatic signature
verification (ASV) system based on the use of a specific
ANN, namely Kohonen's Self-Organizing Feature Faps; the
last chapter is a collection of thoughts and
recommendations about the use of spatiotemporal neural
networks in signature verification.
The novel approach that is put forward in chapter four
processes a test signature according to the following
steps: segmentation of the traced signature into
portions (called "elbows") by means of a dual
partitioning technique involving computation of speed
minima and evaluation by a specialized ANN of the
perceptual importance of a point; extraction of features
that characterize each "elbow" and construction of
spatial and temporal feature vectors; submission of
these vectors to the (spatial and temporal) maps
previously trained with the feature vectors obtained
from the processing of the reference signatures;
comparison between the sequences appearing at the
surface of the maps and reference sequences and
computation of dissimilarity indices for each
comparison; decision on the validity of the test
signature by comparing the dissimilarity indices to
predetermined thresholds.
Experiments for the system evaluation have been carried
out in two stages. (Abstract shortened by UMI.)
</ABSTRACT>
</THESIS>
