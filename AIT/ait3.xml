<THESIS>
<NUMBER> 4053 </NUMBER>
<ORDER>   AAGT-32332 </ORDER>
<TITLE>   INVESTIGATION OF THE APPLICATION OF ARTIFICIAL NEURAL NETWORKS IN MEDICAL IMAGING AND DECISION-MAKING </TITLE>
<AUTHOR>   WU, YUZHENG </AUTHOR>
<YEAR>   1993 </YEAR>
<INSTITUTION>   THE UNIVERSITY OF CHICAGO; 0330 </INSTITUTION>
<DESCRIPTORS>   HEALTH SCIENCES, RADIOLOGY; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER>   NIL </ADVISER>
<CLASSIFICATIONS>   NIL </CLASSIFICATIONS>
<ABSTRACT>
</ABSTRACT>
</THESIS>
<THESIS>
<NUMBER> 4054 </NUMBER>
<ORDER>   AAGT-32281 </ORDER>
<TITLE>   USING INTERACTIVE RECURSIVE PARTITIONING TO IMPROVE RULE- BASED EXPERT SYSTEMS </TITLE>
<AUTHOR>   MEYER, PETER MICHAEL </AUTHOR>
<YEAR>   1993 </YEAR>
<INSTITUTION>   THE UNIVERSITY OF CHICAGO; 0330 </INSTITUTION>
<DESCRIPTORS>   COMPUTER SCIENCE; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER>   NIL </ADVISER>
<CLASSIFICATIONS>   NIL </CLASSIFICATIONS>
<ABSTRACT>
</ABSTRACT>
</THESIS>
<THESIS>
<NUMBER> 4055 </NUMBER>
<ORDER>   AAG9724574 </ORDER>
<TITLE>   A CONSTRUCTION ENGINEERING PLATFORM FOR THE INTEGRATION OF CONSTRUCTABILITY CONCEPTS AND LESSONS LEARNED AT THE POINT OF DESIGN </TITLE>
<AUTHOR>   PATTY, ROBERT MICHAEL </AUTHOR>
<YEAR>   1993 </YEAR>
<INSTITUTION>   PURDUE UNIVERSITY; 0183 </INSTITUTION>
<DESCRIPTORS>   ENGINEERING, CIVIL; ARTIFICIAL INTELLIGENCE; INFORMATION SCIENCE </DESCRIPTORS>
<ADVISER>   BOB G. MCCULLOUCH </ADVISER>
<CLASSIFICATIONS>   NIL </CLASSIFICATIONS>
<ABSTRACT>
To improve constructability, experienced design and
construction engineers often select processes and
develop details that require less labor, equipment, or
management resources to build. These innovative ideas,
enabling circumstances, and their effect on the
construction process are not usually recorded in a
reusable format. Without such a mechanism, recalling
this experience under the appropriate circumstances, or
transferring the technology to new management has
generally not happened. Further, civil engineers are
generally educated to optimize cost by minimizing the
material quantity. Through experience gained after
graduation, they are expected to pick up options for
engineering impact on the labor, equipment, and overhead
expense. This school of experience extracts too high a
price in trial and error, and the need for redevelopment
of lessons learned by others.
Presented is a constructability concept and lesson-
learned storage and retrieval platform. This case based
technical assistant has been ergonomically designed to
employ natural problem-solving heuristic methods used by
human experts. Within this platform, the process of
locating an appropriate lesson learned matches closely
the storage and retrieval mechanisms of the human long
term memory. The result is lessons learned which are
easy to find.
Once found, the circumstances and construction processes
are presented in a multimedia format that can represent
all factors affecting construction cost. Human factors
research was again applied to the development of this
presentation system. It involves the learner, and
deepens the understanding, elaborately relating the
lesson to prior knowledge, which will further improve
the memory recall mechanism created during the search
process.
DICEP (Design Integrated Construction Engineering
Platform) is presented herein to effectively involve the
human design engineer in the application of
constructability at the right time during design.
</ABSTRACT>
</THESIS>
<THESIS>
<NUMBER> 4056 </NUMBER>
<ORDER>   AAGC540000 </ORDER>
<TITLE>   LA GESTION COMERCIAL: TOMA DE DECISIONES EN UN ENTORNO DE INCERTIDUMBRE; COMMERCIAL MANAGEMENT: FUZZY DECISION </TITLE>
<AUTHOR>   BACHS FERRER, JORGE </AUTHOR>
<YEAR>   1993 </YEAR>
<INSTITUTION>   UNIVERSITAT DE BARCELONA (SPAIN); 1129 </INSTITUTION>
<DESCRIPTORS>   ECONOMICS, COMMERCE - BUSINESS; ECONOMICS, COMMERCE- BUSINESS; BUSINESS ADMINISTRATION, MANAGEMENT; ARTIFICIAL INTELLIGENCE CORTS CATALANES, 585 E-08007 BARCELONA, SPAIN </DESCRIPTORS>
<ADVISER>   NIL </ADVISER>
<CLASSIFICATIONS>   NIL </CLASSIFICATIONS>
<ABSTRACT>
Active corporate managers must assume concern for
innovation and application of new techniques and ideas
as a discipline in the area of management. A high
percentage of corporate decisions about production,
administration, commerce, human resources, etc., are
subject to and largely made on the basis of qualitative
information and shifting conditions.
It might be an act of vanity to talk about executive
solitude, but experience shows that final decisions are
made personally and solely by the ultimate decision
maker.
Economics conditions, corporate internal as well as
external environments and personal circumstances are the
most relevant elements confirming an uncertain reality,
ever-changing facts full of impacts and in constant
evolution, with no crystal-clear perspectives.
These instances result in a change of mentality as far
as corporate management is concerned.
Future policies, strategic planning, necessary
strengthening of certain areas and product development
are main managerial factors and must comprehend the
sometimes total lack of formalisation and of a
simplified structure of necessary data.
Shumper's innovating manager must be complemented by the
implementation of techniques capable of offering
entrepreneurs and/or decision-making agents tools strong
enough to control the circumstances in which decisions
are made. This doctoral thesis means to provide adequate
tools and mechanisms for an inspired commercial
management through versatile logical instruments.
</ABSTRACT>
</THESIS>
<THESIS>
<NUMBER> 4057 </NUMBER>
<ORDER>   AAGC522026 </ORDER>
<TITLE>   DESENVOLUPAMENT D'UN SISTEMA BASAT EN EL CONEIXEMENT PER AL CONTROL I SUPERVISIO DE PLANTES DEPURADORES D'AIGUES RESIDUALS URBANES; DEVELOPMENT OF A KNOWLEDGE-BASED SYSTEM FOR CONTROL AND SUPERVISION OF URBAN WASTEWATER TREATMENT PLANTS </TITLE>
<AUTHOR>   SERRA I PRAT, PAU </AUTHOR>
<YEAR>   1993 </YEAR>
<INSTITUTION>   UNIVERSITAT AUTONOMA DE BARCELONA (SPAIN); 5852 </INSTITUTION>
<DESCRIPTORS>   ENGINEERING, SANITARY AND MUNICIPAL; ARTIFICIAL INTELLIGENCE BARCELONA, EDIFICI RECTORAT, APARTAT POSTAL 20, E-08193 BELLATERRA (BARCELONA), SPAIN </DESCRIPTORS>
<ADVISER>   NIL </ADVISER>
<CLASSIFICATIONS>   NIL </CLASSIFICATIONS>
<ABSTRACT>
The development of a knowledge-based system for real-
time control and supervision of wastewater treatment
plants has been the work of this thesis. The system
doesn't try to substitute for the numeric control
algorithms when they perform correctly, but is a help in
plant operation as a supervisor, and in diagnosing what
happens in the process. The goal is the integration of
numeric handling and heuristic knowledge in order to
optimize the process management.
The work has advanced in two directions:
1. Process modelling, to describe the phenomena taking
place there. The work has focused on Manresa's WWTP
(activated sludge, 30.000 m3/day). The model predicts
the bad distribution of flow to the different basins,
and how the turbines stop/start affects the process.
The clarifier has also been modelled, allowing the
description of an unusual effect that takes place in
Manresa's plant. Under specific conditions of the
clarifiers, to face higher organic loadings
recirculation flow must be reduced.
2. KB elaboration, to diagnose under which situation the
plant is running. The most common situations have been
defined (bulking, foaming, toxics, overloading),
operation faults (bad aeration) and accidents. Another
set of rules detect situations that can lead to future
problems, to try to prevent them (such temperature or pH
variations, or sulfur presence in the inflow).
A supervision area decides when the numeric control is
valid and when it is not. When the process would be
uncontrolled, a set of rules give the heuristic control
actions an expert would give.
During the rules elaboration process, automatic rule
generation techniques, based on classification, have
been tested (Linneo+).
The work has been done in permanent contact with the
plant and a lot of experimental campaigns have been
carried out to confirm the hypothesis that appeared. A
prototype has been created, implemented in a real time
shell. It can be useful for WWTP control and operation,
giving control actions in every case (normal or
unusual).
</ABSTRACT>
</THESIS>
<THESIS>
<NUMBER> 4058 </NUMBER>
<ORDER>   AAGC519493 </ORDER>
<TITLE>   HEURISTICA PER A LA COOPERACIO DE SISTEMES EXPERTS: APLICACIO AL CONTROL DE PROCESSOS; HEURISTICS FOR COOPERATION OF EXPERT SYSTEMS: APPLICATION TO PROCESS CONTROL </TITLE>
<AUTHOR>   DE LA ROSA I ESTEVA, JOSEP LLUIS </AUTHOR>
<YEAR>   1993 </YEAR>
<INSTITUTION>   UNIVERSITAT AUTONOMA DE BARCELONA (SPAIN); 5852 </INSTITUTION>
<DESCRIPTORS>   COMPUTER SCIENCE; ARTIFICIAL INTELLIGENCE BARCELONA, EDIFICI RECTORAT, APARTAT POSTAL 20, E-08193 BELLATERRA (BARCELONA), SPAIN </DESCRIPTORS>
<ADVISER>   NIL </ADVISER>
<CLASSIFICATIONS>   NIL </CLASSIFICATIONS>
<ABSTRACT>
El coneixement sobre un proces pot venir donat per
diversos models, bases de coneixement obteses d'experts
(enginyers i operadors). Es dificil introduir, sota un
mateix sistema expert, coneixements que poden esser
parcialment inconsistents. En aquest treball ens
proposem mostrar que la cooperacio entre sistemes
experts independents es possible i aporta un guany
mitjancant un model heuristic de comunicacio de certeses
que pondera les informacions i decisions de cada
sistema. A mes, l'estrudura d'aquestes interconnexions
se sembla a una xarxa neuronal, i per tant pot
beneficiar-se dels mecanismes d'aprenentatge propis de
les xarxes neuronals.
Aquest es un treball en el camp de la intelligencia
artificial, a on s'hi empren els sistemes experts com a
eines utils pel control de processos. Quan son multiples
els coneixements que s'implementen en diferents sistemes
experts, aplicant-t'hi conceptes de cooperacio, aquests
s'anomenen sistemes experts cooperants. En la
introduccio es comenta quina es la problematica
d'utilitzar-los al control de processos.
El model heuristic de comunicacio de certesa d'aquesta
tesi es desenvolupat per fer cooperar qualsevol sistema
que empri logica aproximada, en particular la logica
fuzzy, per mesurar la certesa de qualsevol informacio
externa a un sistema cooperant. Es veu que sistemes que
classicament no aplicaven certesa per la informacio que
usaven en realitat assumien certeses al 100%, el que fa
que el model heuristic proposat sigui eficac a l'evitar
aquestes assumpcions. Aquest model es basat en dos
parametres, el prestigi i la necessitat d'informacio,
com a dues mesures de confianca de la informacio externa
a tot sistema. Per la implementacio de les idees
d'aquest model, a un exemple de planta depuradora
d'aigues residuals, s'empra el llenguatge de programacio
orientat a objectes C++, tenint en compte que l'enfoc
objecte es molt idoni per al desenvolupament de sistemes
cooperants. En aquest exemple del control de processos
s'exposa una aproximacio al control expert predictiu
(cerca heuristica basada en multiples models de
simulacio) i una pura aplicacio de diverses bases de
coneixement implementades en sistemes experts
independents (encara que cooperants) que desenvolupen
una millor accio que les respectives bases de
coneixement monolitiques equivalents (implementades en
un sol sistema expert no cooperant). En aquestes
aplicacions es veu com la varietat en el coneixement sol
ser millor, i que encara es millor si es combinada
mitjancant esquemes cooperants.
</ABSTRACT>
</THESIS>
<THESIS>
<NUMBER> 4059 </NUMBER>
<ORDER>   AAIMM05516 </ORDER>
<TITLE>   COMPUTER RECOGNITION OF RHYTHMIC PATTERNS: THE APPLICABILITY OF NEURAL NETWORK ARCHITECTURES FOR MODELLING MUSICAL RHYTHM </TITLE>
<AUTHOR>   HOGAN, KHARIM MANUELLE </AUTHOR>
<YEAR>   1993 </YEAR>
<INSTITUTION>   MCGILL UNIVERSITY (CANADA); 0781 </INSTITUTION>
<DESCRIPTORS>   MUSIC; COMPUTER SCIENCE; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER>   BRUCE PENNYCOOK </ADVISER>
<CLASSIFICATIONS>   NIL </CLASSIFICATIONS>
<ABSTRACT>
Modelling a listener's perception of musical rhythm
requires both an understanding of rhythm as a whole as
well as a definition of its constituent elements. The
hypothesis is that once we can adequately define rhythm,
we can then begin to design and implement models to gain
insight into the perceptual processes which occur when
listening to rhythmic sequences. This research outlines
studies which have attempted to define and outline both
the structure and the perception of rhythm. Based on the
conclusions of these investigations, a computer model is
designed and implemented using connectionist techniques.
The emphases on this model are to arrive at a viable
solution for extracting rhythmic material from performed
input, and to implement time-scale invariance. Time-
scale invariance allows the system to recognize
(categorize) similar patterns played at different tempos
as being the same pattern. The performance of this model
is evaluated against earlier models designed with
similar neural network architectures as well as in
relation to the conclusions drawn by music theorists and
psychologists.
</ABSTRACT>
</THESIS>
<THESIS>
<NUMBER> 4060 </NUMBER>
<ORDER>   AAI9619072 </ORDER>
<TITLE>   RECSAM: AN EXPERT SYSTEM FOR RESOURCE-CONSTRAINED SCHEDULING PROBLEMS WITH ALTERNATIVE PERFORMANCE MODES </TITLE>
<AUTHOR>   ZONG, YOUPENG </AUTHOR>
<YEAR>   1993 </YEAR>
<INSTITUTION>   UNIVERSITY OF HOUSTON; 0087 </INSTITUTION>
<DESCRIPTORS>   ENGINEERING, INDUSTRIAL; OPERATIONS RESEARCH; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER>   NIL </ADVISER>
<CLASSIFICATIONS>   ARTIFICIAL INTELLIGENCE </CLASSIFICATIONS>
<ABSTRACT>
In this dissertation, the author discusses the
development and performance of the ReCSAM system--an
expert system scheduler--for the Resource-Constrained
Scheduling problem with Altemative performance Modes.
The objective of the ReCSAM system is to minimize the
makespan of all the jobs (or project duration), with
general resource constraints being considered, such that
a wide range of subset problems are included in this
problem domain. The knowledge base of the ReCSAM system
is based upon the Intelligent Exchange Heuristic (IEH),
which occupies the properties of intelligently
identifying the most admissible search direction and
learning capabilities. IEH takes an initial schedule and
improves upon it via exchanging and rearranging
operations, while continually maintaining feasibility.
IEH has been proved to be very efficient for both single-
and alternative-mode problems through experiments. In
the ReCSAM system, a forward chaining strategy is used
as the inference process. The production system language
OPS83 with external C-language links is utilized as the
system-development tool. In addition, many advanced
software development techniques were utilized to reduce
computer memory requirements and to increase the search
speed.
In order to evaluate the performance of the ReCSAM
system, an evaluation was conducted conceding the
knowledge base, inference engine and the system
comprehensive performance respectively. The system was
compared with an earlier developed heuristic program
which uses the original exchange heuristic. The
experiment results shows that the ReCSAM system has
superior performance. It generates better solutions,
reduces CPU times up to 85%, doubly increases the
maximum problem size, and can solve both single and
alterative performance-mode problems.
</ABSTRACT>
</THESIS>
<THESIS>
<NUMBER> 4061 </NUMBER>
<ORDER>   AAIMM03551 </ORDER>
<TITLE>   UNE COMMANDE NEURONIQUE APPLIQUEE A UN ROBOT: ETUDE ET REALISATION </TITLE>
<AUTHOR>   BIGRAS, PASCAL </AUTHOR>
<YEAR>   1993 </YEAR>
<INSTITUTION>   ECOLE DE TECHNOLOGIE SUPERIEURE (CANADA); 1246 </INSTITUTION>
<DESCRIPTORS>   ENGINEERING, ELECTRONICS AND ELECTRICAL; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER>   LOUIS A. DESSAINT </ADVISER>
<CLASSIFICATIONS>   FRENCH TEXT, NEURAL NETWORK, ARTIFICIAL INTELLIGENCE </CLASSIFICATIONS>
<ABSTRACT>
Dans ce travail, une commande par reseaux de neurones
est etudiee, simulee et implantee en temps reel sur un
robot SCARA a deus degres de liberte. Cette commande
neuronique est comparable a une commande adaptative
indirecte classique parce qu'elle consiste a utiliser un
estimateur du modele inverse da systeme pour calculer un
terme de prediction servant d'element cle dans !a loi de
controle. Cependant, pour le controleur neuronique,
l'estimateur du modele inverse du systeme est non
parametrique; le modele du systeme n'a donc pas a etre
connu comme c'est le cas pour la commande adaptative
indirecte classique. De plus, cet estimateur non
parametrique est obtenu par apprentissage d'un reseau de
neurones.
La commande neuronique est ensuite etudiee et appliquee
au robot SCARA a l'aide d'un processeur de signaux de
type DSP 96002 de Motorola. D'abord, un controleur
Arimoto, avec une consigne aleatoire, est ulilise pour
generer un grand nombre d'entrees-sorties de la
dynamique du robot. Puis, ces entrees-sorties sont
utilisees pour entrai ner le controleur neuronique en
temps differe. Finalement, la loi de controle, obtenue
par apprentissage, est implantee a l'aide du DSP 96002.
Pour valider ce controleur, les erreurs de poursuite
d'une trajectoire polynomiale et d'une trajectoire
sinusoidale sont evaluees et comparees. Enfin, le
controleur neuronique est compare a un controleur
adaptatif de type indirect. Il en ressort que les deux
controleurs offrent des erreurs de poursuite
comparables.
</ABSTRACT>
</THESIS>
<THESIS>
<NUMBER> 4062 </NUMBER>
<ORDER>   AAIMM01128 </ORDER>
<TITLE>   CONCEPTUAL CLUSTERING AND CONCEPT HIERARCHIES IN KNOWLEDGE DISCOVERY </TITLE>
<AUTHOR>   HU, XIAOHUA </AUTHOR>
<YEAR>   1993 </YEAR>
<INSTITUTION>   SIMON FRASER UNIVERSITY (CANADA); 0791 </INSTITUTION>
<DESCRIPTORS>   COMPUTER SCIENCE; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER>   NICK CERCONE </ADVISER>
<CLASSIFICATIONS>   NIL </CLASSIFICATIONS>
<ABSTRACT>
Knowledge discovery is the nontrivial extraction of
implicit, previously unknown, and potentially useful
information from data. Knowledge discovery from a
database is a form of machine learning where the
discovered knowledge is represented in a high-level
language. The growth in the size and number of existing
databases far exceeds human abilities to analyse the
data, which creates both a need and an opportunity for
extracting knowledge from databases. In this thesis, I
propose two algorithms for knowledge discovery in
database systems. One algorithm finds knowledge rules
associated with concepts in the different levels of the
conceptual hierarchy; the algorithm is developed based
on earlier attribute-oriented conceptual ascension
techniques. The other algorithm combines a conceptual
clustering technique and machine learning. It can find
three kinds of rules, characteristic rules, inheritance
rules, and domain knowledge, even in the absence of a
conceptual hierarchy. Our methods are simple and
efficient.
</ABSTRACT>
</THESIS>
<THESIS>
<NUMBER> 4063 </NUMBER>
<ORDER>   AAG9420357 </ORDER>
<TITLE>   A METHODOLOGY FOR FORMULATING, FORMALIZING, VALIDATING, AND EVALUATING A REAL-TIME PROCESS CONTROL ADVISOR </TITLE>
<AUTHOR>   SCHMIDT, DOUGLAS CLARK </AUTHOR>
<YEAR>   1993 </YEAR>
<INSTITUTION>   RENSSELAER POLYTECHNIC INSTITUTE; 0185 </INSTITUTION>
<DESCRIPTORS>   ENGINEERING, INDUSTRIAL; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER>   JORGE HADDOCK </ADVISER>
<CLASSIFICATIONS>   NEURAL NETWORKS </CLASSIFICATIONS>
<ABSTRACT>
For processes where improving quality is achieved by
improving the consistency of a product, quality can be
improved by using better process control. Conventional
process control cannot include the theoretical
knowledge, experimental knowledge, and expert knowledge
available concerning the product. A hybrid intelligent
process control (IPC) combining a continuous simulation
(CS) and an artificial neural network (ANN) can make
this knowledge available to the operator for process
control. A methodology is given to combine the CS and
ANN to achieve real-time control. A human-machine
interface (HMI) is included to aid in communication
between the operator and the CS/ANN hybrid IPC. The
result is a real-time process control advisor (RTPCa). A
case example for the methodology of formulating,
formalizing, validating, and evaluating the RTPCa is
given. The case study is galvanizing continuous sheet
steel at the Bethlehem Steel plant in Lackawana, NY. The
CS is written in SIMAN, and the ANN is written in C. The
RTPCa is validated and evaluated using plant data,
simulation output, and surface validation by plant
personnel. It was concluded that the benefits of the
RTPCa over other forms of IPC included better
communication to the operator, robustness to moderate
changes in system parameters, flexibility to retrain
should conditions dramatically change, and the speed in
calculations necessary for real-time process control.
This methodology could be applied to other continuous
processes where quality is determined by consistency of
the product, such as the pulp paper industry and the
film processing industry.
</ABSTRACT>
</THESIS>
<THESIS>
<NUMBER> 4064 </NUMBER>
<ORDER>   AAG9420334 </ORDER>
<TITLE>   A FUZZY APPROACH TO PERCEPTUAL ORGANIZATION FOR OBJECT RECOGNITION </TITLE>
<AUTHOR>   KANG, HANG-BONG </AUTHOR>
<YEAR>   1993 </YEAR>
<INSTITUTION>   RENSSELAER POLYTECHNIC INSTITUTE; 0185 </INSTITUTION>
<DESCRIPTORS>   ENGINEERING, ELECTRONICS AND ELECTRICAL; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER>   ELLEN L. WALKER </ADVISER>
<CLASSIFICATIONS>   NIL </CLASSIFICATIONS>
<ABSTRACT>
This thesis discusses a fuzzy approach to perceptual
organization for extracting structure from a single
grayscale image. Perceptual organization generally
refers to the human visual ability to find structure and
groupings from image data. In the context of computer
vision, it involves partitioning of image data and
describing the associations among the various parts in
terms of primitive image elements. For perceptual
organization to be effective, it must be stable,
regardless of small perturbations, and must explain the
observed structures in the image data.
Even though those requirements are developed well in
some computer vision systems, there still exist some
limitations in performing perceptual organization on
image elements (or tokens). The limitations are: (1)
image tokens are only classified into completely true or
completely false with respect to given grouping
criteria, (2) grouping is usually performed by bottom-up
processing in finding structure, (3) an uncertainty
computation method for evaluating extracted structures
is not developed, (4) higher level groupings based on
high-level geometric features are not exploited, and (5)
a rich structural description is not maintained during
grouping.
To eliminate the limitations, our approach to perceptual
organization is based on fuzzy set theory, which is the
generalization of the usual Boolean logic. In our fuzzy
approach, a grade membership value (or goodness value)
with respect to given grouping criteria is measured for
every image token. Using a goodness value, we can
control the degree of approximation in grouping based on
high-level knowledge. The control of the degree of
approximation enables top-down processing in performing
grouping. Furthermore, we derive a formula to compute
the uncertainty in extracted geometric structures. The
formula deals with unknown and incompatible parts
between grouped image tokens, and an accidental
viewpoint for grouped image tokens. The uncertainty
value in extracted geometric structures will be useful
in reliable higher level reasoning.
In addition to those advantages inherited from fuzzy set
theory, we add two features to our grouping system: a
higher level grouping performed on primitive grouping
results, and the maintenance of structural description.
The higher level grouping is used for extracting complex
geometric structures because most images usually have
complex objects. The extracted complex structures will
be useful in efficiently reducing search space for
object recognition.
Another feature is the maintenance of a rich structural
description. All information acquired from grouping,
including emergent features, the characteristics of
image tokens, and the information about grouped tokens,
is stored within a frame- based knowledge representation
scheme. This rich information provides a good basis for
knowledge-based image understanding systems.
Furthermore, this makes our grouping system robust
because re-grouping or un-grouping is possible when the
grouping result is not desirable.
</ABSTRACT>
</THESIS>
<THESIS>
<NUMBER> 4065 </NUMBER>
<ORDER>   AAG9420319 </ORDER>
<TITLE>   AN ANALOG COMPUTING APPROACH TO STRUCTURAL ANALYSIS AND OPTIMAL DESIGN THROUGH ARTIFICIAL NEURAL NETWORKS </TITLE>
<AUTHOR>   FU, BIAO </AUTHOR>
<YEAR>   1993 </YEAR>
<INSTITUTION>   RENSSELAER POLYTECHNIC INSTITUTE; 0185 </INSTITUTION>
<DESCRIPTORS>   ENGINEERING, MECHANICAL; ENGINEERING, AEROSPACE; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER>   PRABHAT HAJELA </ADVISER>
<CLASSIFICATIONS>   NEURAL NETWORKS </CLASSIFICATIONS>
<ABSTRACT>
There has been significant research activity in the
general area of neural computing, or more specifically,
artificial neural networks. This thesis investigates the
applicability of distinctly different architectures of
neural networks in structural analysis and optimal
design. Specific topics investigated in this work
include: (1) Adaptive Resonance Theory (ART) based
neural networks in automated conceptual design of
structural systems; (2) Hopfield neural networks and a
variant of this network referred to as the deformable
template model in the solution of combinatorial
optimization problems; (3) Development of a measure
referred to as generalized cross validation for
determining the quality of a function approximation
obtained through the use of regularization neural
networks; and (4) The use of regularization networks in
structural damage monitoring.
The results of these studies clearly demonstrate the
usefulness of the neural network based computing
paradigm in problems of structural engineering and
design. In addition to this demonstrated potential in
providing acceptable solutions to genetically difficult
optimization problems, neural networks offer a
significant function approximation capability for
reducing the computational effort in an iterative design
environment. The approach presented in this thesis
provides a rational approach for controlling the quality
of function approximations from the regularization
network. Another important contribution of the present
work is to show how the pattern recognition feature of
neural networks, particularly the ART network, can be
used to create the framework for a conceptual design
system, in a manner similar to that available in the
rule-based expert systems.
</ABSTRACT>
</THESIS>
<THESIS>
<NUMBER> 4066 </NUMBER>
<ORDER>   AAG9420315 </ORDER>
<TITLE>   ANALOG CMOS VLSI DESIGN OF NEURAL NETWORKS </TITLE>
<AUTHOR>   DUNDAR, GUNHAN </AUTHOR>
<YEAR>   1993 </YEAR>
<INSTITUTION>   RENSSELAER POLYTECHNIC INSTITUTE; 0185 </INSTITUTION>
<DESCRIPTORS>   ENGINEERING, ELECTRONICS AND ELECTRICAL; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER>   KENNETH ROSE </ADVISER>
<CLASSIFICATIONS>   NIL </CLASSIFICATIONS>
<ABSTRACT>
A review of existing implementations for neural networks
is made. Although the focus is on hardware, software
implementations are also mentioned, including ANNS, a
software package developed at RPI CIE. Among the
hardware implementations, most of the discussion is on
analog hardware although some digital hardware
implementations are cited for comparison purposes. The
effects of biasing, quantization in weight storage, non-
linear synapses, loss of some of the weights, device
mismatches, and noise are investigated. Theoretical
methods for predicting these effects are derived. The
success of prediction of system performance, especially
for the case of quantization and nonlinearity is shown.
Some algorithms to alleviate these effects are proposed.
Circuits for synapses and various types of neurons are
designed. Among the neuron types designed are sharp
threshold, soft threshold, and Gaussian neuron circuits.
Smaller synapse circuits than in the existing literature
are proposed. The behavior of these circuits is
investigated. The behavior of the standard Gilbert
multiplier as implemented by MOS technology is discussed
and the results compared with the smaller synapse
circuits designed. The design of support circuitry for
CMOS VLSI neural networks is discussed. Double-poly
EAROM transistors for the storage of weights in the
neural network are designed and their behavior is
modeled. The success of this model is evaluated by
comparison with experiment. Various applications using
backpropagation neural networks are studied, the most
interesting among these applications being electronic
process modeling; namely, the modeling of the SRO
deposition process.
</ABSTRACT>
</THESIS>
<THESIS>
<NUMBER> 4067 </NUMBER>
<ORDER>   AAG9420177 </ORDER>
<TITLE>   FROM BELIEFS AND GOALS TO INTENTIONS AND ACTIONS: AN AMALGAMATED MODEL OF INFERENCE AND ACTING </TITLE>
<AUTHOR>   KUMAR, DEEPAK </AUTHOR>
<YEAR>   1993 </YEAR>
<INSTITUTION>   STATE UNIVERSITY OF NEW YORK AT BUFFALO; 0656 </INSTITUTION>
<DESCRIPTORS>   COMPUTER SCIENCE; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER>   STUART C. SHAPIRO </ADVISER>
<CLASSIFICATIONS>   NIL </CLASSIFICATIONS>
<ABSTRACT>
The behavior of computational rational agents should be
driven by their beliefs, desires, and intentions. A
survey of AI systems reveals that it is somewhat awkward
to do planning and acting in systems designed for
reasoning about beliefs and that it is similarly awkward
to study representational and reasoning issues in
planning/acting systems. This is an investigation of the
relationships among beliefs, plans, effective acts, and
between reasoning and acting, in the context of a
rational cognitive agent. It turns out that one can
establish a closer relationship between inference and
acting if one views inference as a kind of mental
acting; i.e., a deduction rule is a propositional
connective that, when applied, constitutes the mental
act of believing the rule's consequents. This suggests
that one only needs a single module for reasoning and
acting. Once integrated in such a way, it is also
possible to visualize connectives that transform beliefs
into an intention to do something in reaction to some
new beliefs or in the quest to answer some query. These
ideas have been formalized by defining the notion of a
transformer and results in a model of a cognitive agent
that is able to achieve the posted goals in a unified
fashion. The investigation leads to the design of an
architecture called the Object-based Knowledge Belief-
Desire-Intention (OK BDI) architecture. It is comprised
of a representational formalism called the OK Formalism
and a module called the OK Rational Engine. The OK
Formalism is designed using object-oriented principles.
As an implementation, we have extended the SNePS
semantic network processing system into what we call the
SNePS BDI architecture, which includes representations
for various transformers and a rational engine, called
SNePS Rational Engine (SNeRE), that is responsible for
integrated reasoning and acting.
</ABSTRACT>
</THESIS>
<THESIS>
<NUMBER> 4068 </NUMBER>
<ORDER>   AAG9419932 </ORDER>
<TITLE>   RECONSTRUCTABILITY THEORY FOR GENERAL SYSTEMS AND ITS APPLICATION TO AUTOMATED RULE LEARNING </TITLE>
<AUTHOR>   TRIVEDI, SUDHIR KUMAR </AUTHOR>
<YEAR>   1993 </YEAR>
<INSTITUTION>   THE LOUISIANA STATE UNIVERSITY AND AGRICULTURAL AND MECHANICAL COL.; 0107 </INSTITUTION>
<DESCRIPTORS>   COMPUTER SCIENCE; ENGINEERING, SYSTEM SCIENCE; MATHEMATICS; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER>   J. BUSH JONES </ADVISER>
<CLASSIFICATIONS>   MACHINE LEARNING </CLASSIFICATIONS>
<ABSTRACT>
The two problems in reconstructability analysis,
abbreviated as RA, are referred to as the
reconstructability problem and the identification
problem. The former relates to the process of
reconstructing a given system under a given criterion
from the knowledge of its subsystems and, during this
process, identifying those subsystems that are important
in the reconstruction. The latter allows the
identification of an unknown system from the knowledge
of its subsystems. The advent of RA has intensified the
research efforts on system studies. The objective of
this research is to study the process of system
reconstruction for general systems and apply it in the
context of automated knowledge acquisition from
databases.
First, we describe basic concepts in reconstructability
theory and machine learning. We then modify existing
results in reconstructability theory for probabilistic
and selection systems in order to generate better
algorithms for determining the unbiased reconstruction
and reconstruction families in the wake of new
developments such as k-systems and the use of
independent information. Further, we extend RA
methodology for possibilistic systems using only partial
information. An algorithm is proposed to compute the
unbiased reconstruction, and the reconstruction families
are identified as a set of max-min fuzzy relation
equations.
Furthermore, we define a new measure of the cognitive
contents of a rule, referred to as the K-measure. Based
on the K-measure, we introduce a new approach for
automated knowledge acquisition from databases. Based on
RA, the reconstructability approach to generalized rule
induction from databases should work for most data
covered by the framework of RA and k-systems. In
particular, this approach is appropriate for expert-
systems-like domains where the data is intrinsically
nominal. Finally, we summarize our results and discuss
the potentials for further research.
</ABSTRACT>
</THESIS>
<THESIS>
<NUMBER> 4069 </NUMBER>
<ORDER>   AAG9419908 </ORDER>
<TITLE>   DEVELOPMENT AND EVALUATION OF AN EXPERT SYSTEM APPROACH TO UNEVEN-AGED MANAGEMENT OF LOBLOLLY-SHORTLEAF PINE STANDS IN THE WEST GULF REGION </TITLE>
<AUTHOR>   LORENZO, ALFREDO BAPTISTA </AUTHOR>
<YEAR>   1993 </YEAR>
<INSTITUTION>   THE LOUISIANA STATE UNIVERSITY AND AGRICULTURAL AND MECHANICAL COL.; 0107 </INSTITUTION>
<DESCRIPTORS>   AGRICULTURE, FORESTRY AND WILDLIFE; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER>   QUANG V. CAO </ADVISER>
<CLASSIFICATIONS>   NIL </CLASSIFICATIONS>
<ABSTRACT>
Forest managers expend significant time and effort
seeking, organizing, and synthesizing information
relevant to making effective forestry decisions.
Oftentimes, they must rely on the knowledge and
experience of human experts, a resource that is in short
supply, requires many years to acquire, and is
concentrated in a few individuals. This research task
suggests expert systems as one viable solution to the
problems of technology transfer and automating and
maintaining expertise in consistent and usable form.
Expert systems are practical computer programs which
solve problems that were previously considered only
solvable by human expertise. The expert system developed
in this research, named FOREX, was written in ProLog.
FOREX is primarily a second-generation expert system for
prescribing silvicultural systems. Aside from human
expertise stored in its knowledge base, FOREX is linked
with growth and yield and optimization models to
complement the search for optimal recommendation.
A methodology was developed for transforming available
literature/research information and the private
knowledge of human experts into decision rules. Factors
pertinent to prescribing silvicultural systems were
identified. English-like decision rules were developed,
and human experts were then asked to verify and confirm
these rules. The process of encoding these rules into
ProLog format was an important phase of the development
process.
In a modified Turing test, nine human evaluators rated
prescriptions from four other human experts, FOREX, and
another computer-based model. FOREX's scores were found
comparable to the research foresters and superior to the
industrial foresters and the other computer model. These
results indicate that human expertise, in uneven-aged
management of loblolly-shortleaf pine stands, has been
captured by an expert system. Success in this project
should encourage other researchers to apply this
approach for other forestry problems.
</ABSTRACT>
</THESIS>
<THESIS>
<NUMBER> 4070 </NUMBER>
<ORDER>   AAG9419676 </ORDER>
<TITLE>   NONLINEAR TRANSFORMATION OF NEURONAL INPUTS IN MULTI- LAYER PERCEPTRON NETWORKS </TITLE>
<AUTHOR>   NARAYAN, SRIDHAR </AUTHOR>
<YEAR>   1993 </YEAR>
<INSTITUTION>   CLEMSON UNIVERSITY; 0050 </INSTITUTION>
<DESCRIPTORS>   COMPUTER SCIENCE; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER>   EDWARD W. PAGE </ADVISER>
<CLASSIFICATIONS>   ENSEMBLE ENCODING </CLASSIFICATIONS>
<ABSTRACT>
The field of neural networks has seen a resurgence of
interest in recent years. Among myriad models, the Multi-
Layer Perceptron (MLP) model has emerged as a viable
neural paradigm with applications in pattern
recognition, classification and forecasting.
In the MLP model, neuronal inputs are transformed
linearly, a process that often imposes limitations on
MLP networks. The focus of this dissertation is upon
studying the effects of certain nonlinear
transformations on neuronal inputs in MLP networks. One
approach examines the efficacy of ensemble encoding, a
data representation approach that is biologically
inspired. A second approach introduces ExpoNet, a new
paradigm that is a generalization of the MLP model.
Ensemble encoding uses multiple, overlapping receptive
fields to generate a distributed representation for
network inputs. The encoding scheme possesses several
desirable attributes including the capacity for local
learning. In addition, the parameters governing ensemble
encoding can be tuned to optimize local learning. The
use of a genetic algorithm to seek suitable receptive
field parameters provides a simple and effective
technique for optimizing locality of representation.
Application to some well-known problems in neural
learning demonstrates that optimizing representation for
locality can accelerate learning in MLP networks.
The ExpoNet model introduces a generalization of the MLP
model in which the choice of an appropriate nonlinear
transformation of neuronal inputs is integral to the
learning process. The model is motivated by the idea
that allowing a network to view a problem in a
transformed space can enhance learning. Application of
the ExpoNet model to problems in classification and
chaotic time series prediction demonstrates that
incorporating adaptive, nonlinear links into the MLP
model can enhance learning at a relatively modest
increase in computational cost.
</ABSTRACT>
</THESIS>
<THESIS>
<NUMBER> 4071 </NUMBER>
<ORDER>   AAG9419662 </ORDER>
<TITLE>   IMAGE PROCESSING AND NEURAL NETWORK BASED ANALYSIS OF CELL KINETIC BEHAVIOR </TITLE>
<AUTHOR>   SOLIMAN, ABDEL-WAHAB AHMED </AUTHOR>
<YEAR>   1993 </YEAR>
<INSTITUTION>   CLEMSON UNIVERSITY; 0050 </INSTITUTION>
<DESCRIPTORS>   ENGINEERING, BIOMEDICAL; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER>   LARRY DOOLEY </ADVISER>
<CLASSIFICATIONS>   NIL </CLASSIFICATIONS>
<ABSTRACT>
Quantifying the cellular responses to controlled in
vitro chemical and morphological environments requires
sophisticated image processing and analysis techniques.
Current methods, which generally extract only a small
part of the information presented by the cell behavior,
are inadequate to quantify cellular responses fully.
This study presents an image processing and neural
network based pattern recognition system which provides
a quantitative description of the kinetic behavior and
permits the classification of individual cells and cell
populations. For this system, an edge tracing algorithm
was developed that allows the precise detection of low
contrast cellular edges. A new set of features,
including acceleration, angular velocity, and features
computed from the elliptic Fourier transform, was
introduced.
Both statistical and neural network techniques were used
to determine the most discriminating features. These
features were used then for the classification of
individual cells and cell populations. The performance
of the neural network classifiers is superior to that of
the statistical classifiers. The results of
classification reveal that both surface chemistry and
morphology have significant effects on cellular
behavior. Moreover, there are significant interaction
effects between these surface properties.
The angular velocity of cells is shown to be a good
feature for classification and analysis since this
velocity is strongly dependent on both surface chemistry
and morphology in data derived from a pair of
experiments utilizing smooth and grooved polystyrene
surfaces. Adding grooves decreases angular velocities
while adding the styrene monomer to the bulk polymer or
decreasing the wettability of the surface increases
angular velocities.
The level of noncollagenous products associated with
cells and the matrix strongly depends on morphology and
chemistry, while the collagenous protein production
depends only on chemistry. Morphology produces an
amplitude modulation of the production of noncollagenous
products that increases with the addition of the
grooves.
The morphology has an amplitude modulation effect on
cell parameters, while chemistry has a frequency
modulation which in turn affects the amplitude of any
cellular features. This frequency modulation of cellular
features in response to chemistry suggests a new
procedure for in vitro biocompatibility testing.
</ABSTRACT>
</THESIS>
<THESIS>
<NUMBER> 4072 </NUMBER>
<ORDER>   AAG9419639 </ORDER>
<TITLE>   NEURAL NETWORK DYNAMICAL SYSTEMS FOR ASSOCIATIVE MEMORY AND CONTROL </TITLE>
<AUTHOR>   COPELAND, MARK ALAN </AUTHOR>
<YEAR>   1993 </YEAR>
<INSTITUTION>   CLEMSON UNIVERSITY; 0050 </INSTITUTION>
<DESCRIPTORS>   MATHEMATICS; COMPUTER SCIENCE; ENGINEERING, INDUSTRIAL; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER>   CLARK JEFFRIES </ADVISER>
<CLASSIFICATIONS>   MATHEMATICAL CONTROL </CLASSIFICATIONS>
<ABSTRACT>
This dissertation presents neural network dynamical
system approaches to problems in three areas of
mathematical control. The areas are storage and
retrieval of appropriate control actions, processing the
control signal, and synthesis of a controller. The
neural network dynamical system approaches are: the
Spherical Classifier Neural Network (SC), the High Order
Conversion Neural Network (HOCNN), and the Spherical
Classifier Feedforward (SCFF) neural network controller.
The SC is an artificial neural network dynamical system
for associative content addressable memory (ACAM). It is
capable of storing real-valued vectors as asymptotically
stable equilibria of the dynamical system. The constant
attractors for the spherical classifier are prespecified
unit vectors.
The HOCNN is a high order neural network for analog-to-
digital (AD) conversion implemented in digital control
systems. The signal conversion process is a simple
example of how high order neural networks can be
constructed to solve a variety of set selection and set
domination problems. The model is a difference equation
dynamical system. It is shown to have a single,
asymptotically stable equilibrium for a given analog
input. A comparison with other neural network approaches
to a signal matching process is given.
The SCFF is a hybrid neural network control system
consisting of a neural network dynamical system and a
multi-layer neural network. The control scheme is used
for on-line identification and adaptive control of
nonlinear dynamical systems. The neural network
dynamical system, called the spherical classifier,
serves as a memory device while the weights or
parameters of the multi-layer network serve as the
content associated with a memory. The capability of this
technique is demonstrated by building a neurocontroller
for the two-link robot manipulator and the truck backer-
upper.
</ABSTRACT>
</THESIS>
<THESIS>
<NUMBER> 4073 </NUMBER>
<ORDER>   AAG9419634 </ORDER>
<TITLE>   A FOURIER SERIES NEURAL NETWORK AND ITS APPLICATION TO INTELLIGENT SYSTEM IDENTIFICATION AND CONTROL </TITLE>
<AUTHOR>   ZHU, CHAOYING </AUTHOR>
<YEAR>   1993 </YEAR>
<INSTITUTION>   CLEMSON UNIVERSITY; 0050 </INSTITUTION>
<DESCRIPTORS>   ENGINEERING, SYSTEM SCIENCE; ENGINEERING, MECHANICAL; COMPUTER SCIENCE; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER>   FRANK PAUL </ADVISER>
<CLASSIFICATIONS>   NEURAL NETWORKS </CLASSIFICATIONS>
<ABSTRACT>
This work develops a distinctive neural network concept
called the Fourier Series Neural Network (FSNN) and
addresses intelligent identification and control of
unstructured and time varying systems using the FSNN
technology. The evaluation of the FSNN design and the
application methodologies for dynamic system estimation
and adaptive control is performed through computer
simulation and experiments.
The FSNN models a relationship of variables through
asymptotical learning with the resulting FSNN model
approximating the Fourier transformation of that
relationship. The FSNN learning is free of local minima
because of FSNN's hyperparabolic energy function. The
FSNN has a parallel and differentiable computational
structure, and may model linear and nonlinear Multi-
Input Multi-Output (MIMO) systems as long as the system
input-output map is piecewise continuous. The FSNN model
is robust when trained using sufficient information with
the modeling accuracy increased with the FSNN size.
The FSNN identification schemes are proposed for
estimating the nonlinear and MIMO time variant
functions, frequency spectrums of the time series
signals, transfer functions and describing functions.
The applicability of the FSNN technique to adaptive
control is also investigated through simulations and
experiments. An advanced experimental system possessing
the capability of parallel computation is designed and
built by combining a 486 Personal Computer (PC), a C30
Digital Signal Processing (DSP) board and two i860
parallel processor based Transputer Modules (TRAM's) for
this evaluation study. Two neural adaptive control
strategies, the Neural Self-Tuning Regulator (NSTR) and
Neural Model-Reference Adaptive System (NMRAS), are
developed by integrating FSNN modeling intelligence and
evaluated. Unlike traditional adaptive controllers, the
NSTR and NMRAS do not need a predefined system
structural model because the FSNN modeling is
nonparametric. The controller modification is based on
an understanding of the system dynamics. Furthermore,
the FSNN's computational parallelism nature allows the
use of parallel computer hardware to approach faster
adaption to the change of the system dynamics. All these
studies theoretically and experimentally demonstrate a
very significant potential for applying the FSNN
technology to create a Neural Network Spectrum Analyzer
(NNSA) and to establish truly robust control mechanisms
with built-in learning intelligence.
</ABSTRACT>
</THESIS>
<THESIS>
<NUMBER> 4074 </NUMBER>
<ORDER>   AAG9419502 </ORDER>
<TITLE>   TOPICS IN COMPUTATIONAL LEARNING THEORY </TITLE>
<AUTHOR>   BALIGA, GANESH RAMDAS </AUTHOR>
<YEAR>   1993 </YEAR>
<INSTITUTION>   UNIVERSITY OF DELAWARE; 0060 </INSTITUTION>
<DESCRIPTORS>   COMPUTER SCIENCE; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER>   JOHN CASE </ADVISER>
<CLASSIFICATIONS>   LANGUAGE LEARNING, MACHINE LEARNING </CLASSIFICATIONS>
<ABSTRACT>
Gold-style computational learning theory, which consists
of function learning and language learning, is a formal
theory of learning from examples by algorithmic devices
called learning machines. Language learning, motivated
by child language learning, features the limiting
synthesis of grammars for formal languages from texts
for these languages. Function learning, motivated by
scientific inference, features the limiting synthesis of
programs for functions from their input graphs.
A generator program for a function generates an infinite
sequence of programs all but finitely many of which
compute that function. We investigate the learning of
generator programs for functions. A motivation is that
there are interesting global properties for computable
functions, such as monotonicity, which can be proved
from suitable generator programs for some such
functions; whereas, these properties can not be proved
from any ordinary programs for those functions.
In traditional Gold-style language learning theory,
learning machines are not provided with negative
information, i.e., information about the complements of
the input languages. We investigate two methods for
providing small amounts of negative information and
demonstrate a strong increase in ensuing learning power.
Finally, we show that small packets of negative
information lead to increased speed in learning. This
result corroborates a psycholinguistic theory of McNeill
which correlates the availability of parental expansions
with the speed of child language development.
Finally, we propose a notion of admissibility in
language learning. A language L is admissible into a
learnable class of languages ${cal C}$ whenever ${cal
C}$ augmented by L is also a learnable class. We present
a surprising characterization of Post's hypersimple sets
in terms of admissibility.
</ABSTRACT>
</THESIS>
<THESIS>
<NUMBER> 4075 </NUMBER>
<ORDER>   AAG9419415 </ORDER>
<TITLE>   A NEURAL NETWORK APPROACH TO SINGLE AND MULTIDIMENSIONAL MODEL BASED ADAPTIVE CONTROL </TITLE>
<AUTHOR>   MEGAN, LAWRENCE </AUTHOR>
<YEAR>   1993 </YEAR>
<INSTITUTION>   THE UNIVERSITY OF CONNECTICUT; 0056 </INSTITUTION>
<DESCRIPTORS>   ENGINEERING, CHEMICAL; ENGINEERING, SYSTEM SCIENCE; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER>   NIL </ADVISER>
<CLASSIFICATIONS>   NIL </CLASSIFICATIONS>
<ABSTRACT>
Stricter environmental regulations and a greater need
for waste minimization have increased the importance of
process control to chemical plant operations. However,
the standard PID controller common to most plants often
does not offer sufficient performance as the controller
is not designed to account for the nonlinear or
nonstationary behavior of most processes. The desire to
improve controller performance has led to a growing
interest in adaptive control. Adaptive controllers
typically operate in a model based fashion, where
process data is used to update the parameters of a
simple linear process model so that the model remains
descriptive of the process dynamic behavior. The
controller parameters are then related to the model
parameters in a manner which allows the controller to
maintain robust performance.
This research investigates a pattern recognition
approach to adaptive control. Pattern recognition
techniques analyze the input and output process response
following dynamic events such as set point changes and
significant disturbances. They then translate these
responses into descriptive pattern features. Past
pattern recognition techniques have used a rule based or
expert system approach, where a series of rules
translate features such as overshoot and damping into
controller parameter updates. This work uses Artificial
Neural Networks (ANN) for the pattern analysis task due
to their inherent ability to analyze the entire pattern
as opposed to particular features, making them less
susceptible to measurement noise and other
irregularities. The ANN's are used to translate dynamic
input/output responses into a measure of the
multiplicative mismatch between a present model
parameter and the value of the model parameter which is
descriptive of the process. By focusing on parameter
mismatches as opposed to actual parameter values, the
adaptive strategies maintain process independence.
Focusing on model parameters as opposed to controller
parameters allows the methods to be applied to a number
of model based control algorithms, including an IMC
based PID structure and Dynamic Matrix Control. This
work implements the adaptive techniques on a variety of
challenging single and multivariable processes in an
effort to determine the strengths, weaknesses and limits
of the pattern recognition approach.
</ABSTRACT>
</THESIS>
<THESIS>
<NUMBER> 4076 </NUMBER>
<ORDER>   AAG9418115 </ORDER>
<TITLE>   SELF-ORGANIZING NEURAL NETWORK AND ITS APPLICATIONS TO VISION-GUIDED ROBOT MOTION COORDINATION </TITLE>
<AUTHOR>   YANG, AN-JEN </AUTHOR>
<YEAR>   1993 </YEAR>
<INSTITUTION>   CLEVELAND STATE UNIVERSITY; 0466 </INSTITUTION>
<DESCRIPTORS>   ENGINEERING, MECHANICAL; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER>   PAUL P. LIN </ADVISER>
<CLASSIFICATIONS>   NIL </CLASSIFICATIONS>
<ABSTRACT>
Artificial neural networks have been investigated in
almost all aspects of robotic theories and
implementations, such as robotic kinematics, path
planning, robot arm dynamics, and position and force
control problems. A new idea for vision-motor controlled
robots to learn the vision-robot coordination using self-
organizing neural network (SONN) has been recently
explored, where a robot learns by observing its trial
movements without external supervisor. Although this
approach is still in the introductory stage, it has
demonstrated the potential to develop a flexible, self-
organizing robot neural controller.
The main objective of this study is to improve the SONN
learning algorithm for vision-guided robot coordination.
A new strategy to improve the adaptability and
convergence of the Kohonen self-organizing neural
network is proposed and a new learning algorithm to
acquire the desired coordination among multiple mappings
based on SONN is presented. With the proposed
adaptability improvement algorithm, the network can
adapt to the change of robot workspace or the vision
system. With the new learning strategy of SONN, the
desired robot coordination maps, such as for obstacle
and singularity free robot motion, can be obtained.
Another SONN application, neural trajectory interpolator
based on coordination map, is proposed, which provided
better performance than the incremental trajectory
interpolator based on resolved motion rate control
method. The computer simulations and analysis for the
proposed algorithms are included.
The significance of this study is the development of a
different method in obtaining the vision-machine
coordination, and an alternate approach to the
traditional machine dependant tedious calibration
process. A vision-guided machine can learn how to
perform difficult tasks using solely two cameras
(equivalent to two human eyes). More importantly, a
pretrained machine system can properly function in real
time.
</ABSTRACT>
</THESIS>
<THESIS>
<NUMBER> 4077 </NUMBER>
<ORDER>   AAGNN86309 </ORDER>
<TITLE>   FUZZY EXPERT SYSTEM WITH APPLICATION TO PRODUCTION MANAGEMENT </TITLE>
<AUTHOR>   TIAN, YUNYAN </AUTHOR>
<YEAR>   1993 </YEAR>
<INSTITUTION>   UNIVERSITY OF TORONTO (CANADA); 0779 </INSTITUTION>
<DESCRIPTORS>   ENGINEERING, INDUSTRIAL; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER>   I. B. TURKSEN </ADVISER>
<CLASSIFICATIONS>   NIL </CLASSIFICATIONS>
<ABSTRACT>
Fuzzy expert systems related issues, i.e., rule
representation and reasoning, are investigated with a
particular application to production management.
Firstly, bounds of multiple antecedent fuzzy implication
and reasoning are developed for one rule based on
Interval Valued Fuzzy Sets. Based on the bounds
analysis, a linkage is established between two classes
of inference methods, i.e., Compositional Rule of
Inference and Approximate Analogical Reasoning.
Secondly, the issue of combination of multiple rules or
their consequences in a fuzzy expert system is studied
based on an analysis of inference results. In this
regard, implication operators and inference processes
are classified as Expansion, Reduction, and other types.
A method is proposed to select combination operators for
both Expansion and Reduction type inference processes.
This method can be used as a guidance to select proper
operators in the design of a fuzzy expert system.
Thirdly, search schemes in a fuzzy expert system are
investigated. Computation of an overall similarity
measure value is investigated between the antecedent of
a rule and a system observation for a class of
similarity measure models. A new search scheme called
two level tree search is proposed to save search cost in
a fuzzy expert system based on an analysis of the
relationship between the overall similarity measure
value between, on the one hand, the antecedent of a rule
and a system observation and, on the other hand, the
individual similarity measure values between the
linguistic terms of linguistic variables and the
observations of the corresponding linguistic variables
in the rule. Finally, a case study is described for the
management of a repair service centre of spare parts. A
fuzzy expert system is designed and implemented for the
repair service centre in the framework of fuzzy logic
and approximate reasoning. This case study shows a
general methodology to build fuzzy expert systems for a
class of applications in production management. The
system is also used as the test-bed of experiments for
the proposed two-level tree search scheme. Future
research directions are pointed out.
</ABSTRACT>
</THESIS>
<THESIS>
<NUMBER> 4078 </NUMBER>
<ORDER>   AAG9422424 </ORDER>
<TITLE>   THE APPLICATION OF EXPERT SYSTEMS TECHNOLOGY TO COMBAT LAND DEGRADATION </TITLE>
<AUTHOR>   BALACHANDRAN, CHANDRA SHEKHAR </AUTHOR>
<YEAR>   1993 </YEAR>
<INSTITUTION>   KENT STATE UNIVERSITY; 0101 </INSTITUTION>
<DESCRIPTORS>   GEOGRAPHY; COMPUTER SCIENCE; ENVIRONMENTAL SCIENCES; ARTIFICIAL INTELLIGENCE; AGRICULTURE, GENERAL </DESCRIPTORS>
<ADVISER>   SURINDER M. BHARDWAJ </ADVISER>
<CLASSIFICATIONS>   INDIA </CLASSIFICATIONS>
<ABSTRACT>
Land degradation, defined as the diminution of
productivity of land under a specific use, is an
insidious problem in many parts of the world. Many types
of human activities aggravate and accelerate many
natural processes of degradation. In combating land
degradation, it is recognized that much knowledge exists
about the processes, problems and solutions at various
geographic scales, among people with various levels and
types of expertise. For meaningfully combating the
degradation problem, integration of these knowledge
types and sources is essential. In this dissertation,
such an integration is attempted using a type of
computer program called expert systems (programs which
can offer advice in ways similar to a human expert). The
application of the expert systems technique to
integration of knowledge to combat land degradation
raises several issues which are also discussed in this
dissertation, using Landex (Land Degradation Expert), an
expert system built to help field advisors in
Vilathikulam Taluk (akin to a U.S. county)--located in
Chidambaranar District, Tamil Nadu, India--provide
conservation recommendations at the level of the
individual plot to farmers. Landex represents one stage
in an on-going research endeavor.
</ABSTRACT>
</THESIS>
<THESIS>
<NUMBER> 4079 </NUMBER>
<ORDER>   AAG9419283 </ORDER>
<TITLE>   A HYBRID NEURAL NETWORK METHODOLOGY FOR STUDYING THE DEVELOPMENT OF EXTERNAL MEMORY STRATEGIES IN PROBLEM- SOLVING </TITLE>
<AUTHOR>   ANUMOLU, VIVEK </AUTHOR>
<YEAR>   1993 </YEAR>
<INSTITUTION>   UNIVERSITY OF ALABAMA AT BIRMINGHAM; 0005 </INSTITUTION>
<DESCRIPTORS>   COMPUTER SCIENCE; PSYCHOLOGY, DEVELOPMENTAL; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER>   NIL </ADVISER>
<CLASSIFICATIONS>   NIL </CLASSIFICATIONS>
<ABSTRACT>
Neural networks among other artificial intelligence
methods offer advantages of learning to adapt to novel
and nonstationary environments. The operation of robots
in such environments is facilitated if they can learn
new strategies appropriate to the situation. To address
this situation, we turn to the field of cognitive
development for guidelines on how humans construct and
use strategies to solve problems. An object-target
matching task devised by N. W. Bray and his associates
to investigate the differences in the use of external
memory strategies in children is seen as a
representative case. This task involves matching a
subset of objects with a subset of targets, in a
specified temporal order and according to relations
defining positions. In studying this situation, a hybrid
neural network methodology is followed that involves the
integration of neural components and mechanisms based on
the instar, the outstar, a sequencer and shunting
excitation into a single neural network to mediate
desired behavior.
A hybrid neural network, known as the "sequence-
associator," is constructed to solve the matching
task and consists of a serial learning module and a
series of associators. The influences of postsynaptic
threshold on serial learning and of a nonspecific
arousal on object-target matching are examined.
The sequence-associator is extended to incorporate
novelty bias and accuracy factors, modeled after those
postulated by R. S. Siegler and his associates; these
factors are responsible for strategy evolution. The
resultant model, known as the "novelty bias neural
network," demonstrates the phenomena of strategy
diversity and advancement observed in the object-target
matching task and other problems.
A variation of the novelty bias model known as the
"components neural network" model discards the
notion of novelty bias and introduces a notion of
strategy components. The latter model is based on the
assumption that accuracy feedback information is
selectively encoded, first for objects, next for targets
and ultimately for prepositions. The assumption is
motivated in part by the work of R. J. Sternberg, which
established that children spend less time than adults on
encoding a given problem. The components model exhibits
not only the phenomena of strategy diversity and
advancement but also strategy discovery. We conclude
that this model offers a plausible explanation in a
neural network framework for strategy discovery, a very
difficult problem which existing information processing
theories in cognitive development as well as neural
networks have yet to address in a fully satisfactory
way.
</ABSTRACT>
</THESIS>
<THESIS>
<NUMBER> 4080 </NUMBER>
<ORDER>   AAG9419189 </ORDER>
<TITLE>   AN ARCHITECTURALLY-BASED THEORY OF HUMAN SENTENCE COMPREHENSION </TITLE>
<AUTHOR>   LEWIS, RICHARD LAWRENCE </AUTHOR>
<YEAR>   1993 </YEAR>
<INSTITUTION>   CARNEGIE-MELLON UNIVERSITY; 0041 </INSTITUTION>
<DESCRIPTORS>   COMPUTER SCIENCE; PSYCHOLOGY, GENERAL; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER>   JILL FAIN LEHMAN </ADVISER>
<CLASSIFICATIONS>   PSYCHOLINGUISTICS </CLASSIFICATIONS>
<ABSTRACT>
This thesis presents NL-Soar, a detailed computational
model of human sentence comprehension that accounts for
a broad range of psycholinguistic phenomena. NL-Soar
provides in-depth accounts of structural ambiguity
resolution, garden path effects, unproblematic
ambiguities, parsing breakdown on difficult embeddings,
acceptable embeddings, immediacy of interpretation, and
the time course of comprehension. The model explains a
variety of both modular and interactive effects, and
shows how learning can affect ambiguity resolution
behavior. In addition to accounting for the qualitative
phenomena surrounding parsing breakdown and garden path
effects, NL-Soar explains a wide range of contrasts
between garden paths and unproblematic ambiguities, and
difficult and acceptable embeddings: the theory has been
applied in detail to over 100 types of structures
representing these contrasts, with a success rate of
about 90%. The account of real-time immediacy includes
predictions about the time course of comprehension and a
zero-parameter prediction about the average rate of
skilled comprehension. Finally, the theory has been
successfully applied to a suggestive range of cross-
linguistic examples, including constructions from head-
final languages such as Japanese.
NL-Soar is based on the Soar theory of cognitive
architecture, which provides the underlying control
structure, memory structures, and learning mechanism.
The basic principles of NL-Soar are a result of applying
these architectural mechanisms to the task of
efficiently comprehending language in real-time. Soar is
more than an implementation language for the system: it
plays a central theoretical role and accounts for many
of the model's novel empirical predictions.
</ABSTRACT>
</THESIS>
<THESIS>
<NUMBER> 4081 </NUMBER>
<ORDER>   AAG9419184 </ORDER>
<TITLE>   MODELING EVOLVING INFORMATION ABOUT ENGINEERING DESIGN PRODUCTS: AN OBJECT-CENTERED APPROACH COMBINING DESCRIPTION LOGIC AND OBJECT-ORIENTED MODELING </TITLE>
<AUTHOR>   HAKIM, MOHAMMED MAHER </AUTHOR>
<YEAR>   1993 </YEAR>
<INSTITUTION>   CARNEGIE-MELLON UNIVERSITY; 0041 </INSTITUTION>
<DESCRIPTORS>   COMPUTER SCIENCE; ENGINEERING, GENERAL; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER>   NIL </ADVISER>
<CLASSIFICATIONS>   NIL </CLASSIFICATIONS>
<ABSTRACT>
Engineering design is one of the most challenging
application areas for computer-based systems.
Engineering design requires the creation of, and the
manipulation of, complex entities that are linked by
various semantic relationships. The descriptions of
these design entities and the relationships between them
change throughout the design process. A computer-aided
design environment that assists with the design of
engineering products should not only support the
representation of the end product model and the
relationships among its components, but also the
evolution of these components and relationships during
the design process. In addition, several different views
of a design product must be generated and maintained. A
representation of design product models should be
flexible enough to allow the incremental generation and
manipulation of these views. Various data types and
knowledge formalisms are usually used by designers to
describe the products of their designs. The diversity of
the data types that describe design products and the
knowledge sources that reason with this data creates the
need for a flexible environment that supports various
data types and multiple knowledge representation
paradigms. The design product must also be modeled and
viewed at multiple levels of abstraction. Finally, since
the design process is mainly driven by design
constraints which play an essential role in the
evolution of design products, a flexible constraint
representation mechanism which allows for instance-
specific constraints as well as class-defined
constraints should be incorporated in a semantic
representation of design product models.
This document presents an object-centered approach for
representing engineering design product models based on
combining description logic with object-oriented
techniques. The object-centered approach is superior to
its counterpart, the class-centered approach, in that
objects can be created and manipulated independently
from the schema classes, and are automatically
classified under appropriate concept classes for which
they satisfy membership sufficiency conditions. I
demonstrate how the object-centered approach overcomes
the limitations which render the class-centered approach
inadequate for representing evolving design product
models. These limitations include the lack of mechanisms
for object evolution, schema evolution, representing
partial information about objects, classification,
recognition of objects, and constraint management. In
the proposed object-centered approach, an evolving model
of a design product is represented as a collection of
interrelated design entities and design aspects that
describe the various characteristics of this design
product. The various views of a design product are
represented as one or several hierarchies of design
aspects. Design aspects from different views are grouped
together by various semantic relationships to form
design entities which are used as building blocks for
the design product model. Description logic was chosen
to implement the object-centered approach because it
provides important services for design product modelers
such as: data definition language, data manipulation
language, incomplete data representation, subsumption of
concepts, instance recognition, and integrity constraint
checking. A modeling environment called SHADES which
combines description logic and object-oriented modeling
for representing engineering design product models was
developed and is described in this document. The object-
centered approach for modeling design products is
demonstrated through illustrative examples and its
advantages are discussed in detail.
</ABSTRACT>
</THESIS>
<THESIS>
<NUMBER> 4082 </NUMBER>
<ORDER>   AAG9419044 </ORDER>
<TITLE>   EVENT-BASED MOTION PLANNING AND CONTROL FOR ROBOTIC SYSTEMS </TITLE>
<AUTHOR>   XI, NING </AUTHOR>
<YEAR>   1993 </YEAR>
<INSTITUTION>   WASHINGTON UNIVERSITY; 0252 </INSTITUTION>
<DESCRIPTORS>   ENGINEERING, AUTOMOTIVE; ENGINEERING, ELECTRONICS AND ELECTRICAL; ENGINEERING, SYSTEM SCIENCE; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER>   T. J. TARN; A. K. BEJCZY </ADVISER>
<CLASSIFICATIONS>   NIL </CLASSIFICATIONS>
<ABSTRACT>
This thesis focuses on the issues related to the
integration of event-based task space planning and real-
time control of robotic systems. First, the theory of
event-based planning and control is discussed. The key
step is introducing the concept of motion reference
variable. The equivalence of the event-based and time-
based representations of nonlinear feedback has been
shown. In addition, the overall system stability
criterion has been obtained. The event-based planning
and control scheme is exemplified by considering the
single arm tracking problem. The time and energy optimal
motion plans integrated with nonlinear feedback control
are derived. The benefits of event-based planning and
control scheme are further demonstrated by its ability
to deal with unexpected obstacle. Furthermore, the event-
based planning and control scheme is extended to multi-
arm coordination. The event-based motion reference for
multi-arm robotic system is introduced to drive the
system so that it achieves the best possible
coordination. Based on the combination of general task
space with nonlinear feedback technique, hybrid
position/force controllers are also designed. To improve
the force control performance, the dynamics of joint
motors is also considered in the force control. In the
multi-arm coordination scheme, for a given task a task
projection operator can be found for each robot with the
consideration of redundancy management. The
computational aspects of event-based planning and
control, in particular for multi-arm systems, and
several other important issues related to practical
implementation are also addressed. Finally, the
theoretical results are illustrated by experiments.
</ABSTRACT>
</THESIS>
<THESIS>
<NUMBER> 4083 </NUMBER>
<ORDER>   AAG9418720 </ORDER>
<TITLE>   PAD-BASED: PROTOTYPES AND DELEGATION BASED APPROACH TO KNOWLEDGE ORGANIZATION IN EXPERT SYSTEM DESIGN </TITLE>
<AUTHOR>   LIMSUPAVANICH-MITRPANONT, JARERNSRI </AUTHOR>
<YEAR>   1993 </YEAR>
<INSTITUTION>   OKLAHOMA STATE UNIVERSITY; 0664 </INSTITUTION>
<DESCRIPTORS>   COMPUTER SCIENCE </DESCRIPTORS>
<ADVISER>   K. M. GEORGE </ADVISER>
<CLASSIFICATIONS>   NIL </CLASSIFICATIONS>
<ABSTRACT>
Scope and method of study. The object-oriented
approaches to computing provide major contributions in
most computer research including artificial
intelligence. This rapid growth is attributed to its
four significant properties: the principles of program
modularity, information hiding, data abstraction, and
code reusability. The concept of modularity has been
widely introduced into expert system design and
development. Various techniques have been developed by
incorporating class/subclass, inheritance, delegation,
and polymorphism concepts to knowledge base structure
and knowledge representation techniques. Although these
approaches are successfully used in expert system
design, the issues of extensive development time, and
limited knowledge sharing and re-use among expert
systems are still open problems, particularly when
developing expert systems in small computer environment
with limited memory. The scope of the study is to
develop an expert system development methodology to
address the above problems.
Findings and conclusions. The object-oriented approach
based on the concepts of prototype and delegation
mechanism is used to develop a new model (PAD-BASED
model) serving as the knowledge organization technique
in expert system design. Its prototype structure
provides a high structurability in knowledge base
organization. The delegation mechanism allows dynamic
interactions among prototypes contributing to an
alternate memory management scheme in small computer
system as well as a high opportunity for knowledge
sharing and re-use among structured expert systems.
Agricultural applications are implemented based on the
PAD-BASED model. The PAD-BASED development life cycle
model is used to support the management of complex
interactions among the experts during the expert system
development. The advantages of the PAD-BASED model are
described fully as well.
</ABSTRACT>
</THESIS>
<THESIS>
<NUMBER> 4084 </NUMBER>
<ORDER>   AAG9418694 </ORDER>
<TITLE>   ESTIMATING SOIL WATER CONTENT USING SOIL TEMPERATURES AND A NEURAL NETWORK </TITLE>
<AUTHOR>   ALTENDORF, CHRISTINE THERESA </AUTHOR>
<YEAR>   1993 </YEAR>
<INSTITUTION>   OKLAHOMA STATE UNIVERSITY; 0664 </INSTITUTION>
<DESCRIPTORS>   ENGINEERING, AGRICULTURAL; ENGINEERING, CIVIL; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER>   RONALD L. ELLIOTT </ADVISER>
<CLASSIFICATIONS>   NIL </CLASSIFICATIONS>
<ABSTRACT>
Scope of study. Knowledge of soil water content is an
important consideration in many agricultural,
environmental and structural applications. There are a
number of methods for the measurement of soil water
content, but all techniques possess certain limitations
and shortcomings. This research involves the development
of a system for measuring soil water content accurately
and inexpensively based on soil thermal properties,
mainly temperature. Automated monitoring stations were
placed at three sites, each consisting of a different
soil type, to collect soil and weather data to be used
as input parameters in a neural network. The neural
network then used this field data to estimate soil water
content. A neural network was utilized because of the
uncertain, non-linear interrelationships between soil
water content and soil thermal properties. Several
different neural network strategies were developed and
tested until a "final" model which uses only
soil temperatures and a soil coefficient value
(dependent on soil type) was selected. The soil water
content values were determined at depths of 15, 30, 60
and 120 cm. The neural network was trained using
temperature data above and below these depths and
measured soil moisture values from two of the locations.
Once trained to a desired tolerance, the network model
was tested using independent data from each of the three
sites.
Findings and conclusions. The overall performance of the
neural network model was good. All of the general trends
in soil water content for the three sites were predicted
well. The largest root mean square error (RMSE) for all
locations and depths was 2.34% volumetric moisture
content. The correlation coefficient (r$sp2$) values
ranged from 0.452 to 0.993. A residual analysis
indicated that the mean of the errors was very close to
zero. The model has a tendency to underpredict higher
moisture content values and overpredict the lower
moisture values. The neural network is in a form which
is easily transportable and can estimate soil water
contents given the easily measured soil temperatures,
once the soil coefficient for the specific site is
calibrated.
</ABSTRACT>
</THESIS>
<THESIS>
<NUMBER> 4085 </NUMBER>
<ORDER>   AAG9418511 </ORDER>
<TITLE>   FUZZY NEURAL NETWORK MODELS FOR DESIGN/CONSTRUCTION PROCESSES </TITLE>
<AUTHOR>   SOEMARDI, BIEMO WOERJANTO </AUTHOR>
<YEAR>   1993 </YEAR>
<INSTITUTION>   UNIVERSITY OF KENTUCKY; 0102 </INSTITUTION>
<DESCRIPTORS>   ENGINEERING, CIVIL; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER>   NIL </ADVISER>
<CLASSIFICATIONS>   NEURAL NETWORKS </CLASSIFICATIONS>
<ABSTRACT>
The decision making process for a construction project
has become a more difficult task. Stricter regulations
as well as higher demand for more efficient use of
resources has forced the decision makers in the
construction industry (i.e., designers, construction
managers, contractors) to look for ways to improve their
decision making processes. One way to improve the
decision making process is by forming a project team. A
decision making tool that is capable of enhancing the
mechanism of this group to make joint decisions would be
very beneficial. Such a decision making tool must be
implemented in a computer-based system. This system
should be capable of imitating the human decision making
process, both at the individual or the group levels.
This research investigated the feasibility of
integrating artificial neural network technology with
the fuzzy concept, as a way to capture the human (group)
decision making process. Two fuzzy neural network
models, the Fuzzy Back-Propagation (FBP) and the Fuzzy
Cognitive Map (FCM), are proposed to solve group
decision making under multiple criteria problems. A
problem of selecting a wall system design is presented
as an example of the feasible application of such models
in the construction industry. Two computer programs were
developed to illustrate the computer implementation of
such models for the wall system design selection
problem.
</ABSTRACT>
</THESIS>
<THESIS>
<NUMBER> 4086 </NUMBER>
<ORDER>   AAG9418279 </ORDER>
<TITLE>   SYMBOLIC RULE EXTRACTION FROM ARTIFICIAL NEURAL NETWORKS </TITLE>
<AUTHOR>   YOO, JAE HUNG </AUTHOR>
<YEAR>   1993 </YEAR>
<INSTITUTION>   WAYNE STATE UNIVERSITY; 0254 </INSTITUTION>
<DESCRIPTORS>   COMPUTER SCIENCE; ENGINEERING, ELECTRONICS AND ELECTRICAL; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER>   ISHWAR K. SETHI </ADVISER>
<CLASSIFICATIONS>   NEURAL NETWORKS </CLASSIFICATIONS>
<ABSTRACT>
The primary aim of this research is to investigate a
general optimal algorithm of rule extraction from a
neural network and then to apply this rule extraction
method to the neural tree net and the SIR (simultaneous
induction of rules) net. The neural tree net is a
multifeature split, decision tree based network. The SIR
is a new neural network based learning methodology. This
rule extraction process translates knowledge from an
internal representation of a neural network system to
symbolic production rules. The proposed rule extraction
method yields production rules or concept descriptions
that are syntactically similar to the rules generated by
the symbolic learning approach. This allows for a better
understanding of neural network learning and an easier
integration of neural network technology with the expert
systems. The individual rules of the proposed
methodology are formed on the basis of high-level
attributes which are automatically discovered during the
neural learning process.
The neural tree net builds the decision tree by finding
the best hyperplanes in a top-down manner and by using
either the modified pocket algorithm or the AMIG
(average mutual information gain) delta rule. The SIR
net builds the decision tree by finding the hyperplanes
in a parallel manner by using the backpropagation
algorithm and the "winner-takes-all" strategy.
Both systems incorporate the best features of the
symbolic and neural learning approaches. Furthermore, in
the SIR system, the use of neural learning permits the
simultaneous induction of rules because of the
parallelism inherent in the neural networks. This
provides for a faster degree of learning in the SIR net.
The simultaneous induction of rules also avoids the
problem of under or over learning that is typically
present in the sequential, top-down inductive methods.
The proposed rule extraction method can apply to any
feedforward neural networks designed for symbolic rule
extraction. Thus, this research provides an important
step in removing the "opaqueness" of neural
networks which has "bottlenecked" the neural
network research in the past.
</ABSTRACT>
</THESIS>
<THESIS>
<NUMBER> 4087 </NUMBER>
<ORDER>   AAG9418278 </ORDER>
<TITLE>   DATA MODEL AND QUERY OPTIMIZATION OF A DEDUCTIVE OBJECT ORIENTED DATABASE </TITLE>
<AUTHOR>   XING, JUNYING </AUTHOR>
<YEAR>   1993 </YEAR>
<INSTITUTION>   WAYNE STATE UNIVERSITY; 0254 </INSTITUTION>
<DESCRIPTORS>   COMPUTER SCIENCE </DESCRIPTORS>
<ADVISER>   WILLIAM I. GROSKY </ADVISER>
<CLASSIFICATIONS>   DATABASES </CLASSIFICATIONS>
<ABSTRACT>
To support a wide range of complex applications, such as
computer aided engineering design, software engineering
and artificial intelligence, representation and querying
of complex objects have become important issues to the
field of database system design. Recently, two new
approaches, object orientation and logic deduction, have
been developed to address these issues. However, these
approaches have both advantages and disadvantages. This
motivation leads to the design of Deductive Object
Oriented Database (DOOD).
Data model design and query performance are among some
of the main considerations regarding designing new
database systems. This dissertation focuses on the data
model representation, and on the rewriting query
optimization algorithm of DOOD.
The two areas of deductive database and object oriented
technology are brought together closely. The data model
of DOOD provides object identity, object inheritance and
object sharing, which make the data model resemble real
world entities and exhibit rich functionality. The
schema and query language of DOOD are presented by a
uniform first order logic which provides a more readable
schema and deductive program as well as a good
foundation for the query optimization process.
In addition, the regular magic sets query transformation
algorithm is extended to support new sideways
information passing, sets and aggregation functions. A
class of adornment that describes inheritance
relationships between the terms of ground predicates is
introduced. DMS (DOOD's magic sets) shows how the
existing optimization approaches can be modified to deal
with a new data model. Analytical results indicate that
DMS has better performance than some similar approaches
in certain experiments.
</ABSTRACT>
</THESIS>
<THESIS>
<NUMBER> 4088 </NUMBER>
<ORDER>   AAG9418187 </ORDER>
<TITLE>   NEURAL NETWORK APPROACH TO SYSTEM REALIZATION AND NETWORK DESIGN </TITLE>
<AUTHOR>   KIM, JIN SOO </AUTHOR>
<YEAR>   1993 </YEAR>
<INSTITUTION>   WAYNE STATE UNIVERSITY; 0254 </INSTITUTION>
<DESCRIPTORS>   ENGINEERING, ELECTRONICS AND ELECTRICAL; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER>   HARPREET SINGH </ADVISER>
<CLASSIFICATIONS>   NIL </CLASSIFICATIONS>
<ABSTRACT>
Neural networks are currently being used for a variety
of disciplines. In this dissertation neural network
approach has been exploited for the problem of system
realization and network design. In the area of system
realization, the following algorithms have been
proposed: (1) realizing Markov-parameters from input-
output data using neural network. (2) realization of
state-space matrices from Markov-parameters using neural
network. (3) realizing constrained state-space matrices
from input-output data using neural network. Constrained
state-space realization means that some of the
parameters are constrained to have some arbitrarily
assigned values and the algorithm determines the
remaining parameters. If there is no solution because of
constraints, the algorithm does not go below certain
error level. In the area of network design, algorithm
for the determination of passive RLCT network from a
given hybrid positive real transfer function matrix has
been proposed. The algorithm can realize the RLCT
network by satisfying the passivity and reciprocity
conditions at the same time. A neural network algorithm
for determination of transfer function from unit step
response with contaminated noise has also been proposed.
The algorithm was implemented for the realization of air-
fuel-ratio sub system on a real data obtained from FORD.
It is hoped that more research in this field will be
able to solve several new problems in the area of
controller design, system realization and analog VLSI
design.
</ABSTRACT>
</THESIS>
<THESIS>
<NUMBER> 4089 </NUMBER>
<ORDER>   AAG9418141 </ORDER>
<TITLE>   COMPUTER EXPERIMENTS ON EVOLUTIONARY LEARNING IN A MULTILEVEL NEUROMOLECULAR ARCHITECTURE </TITLE>
<AUTHOR>   CHEN, JONG-CHEN </AUTHOR>
<YEAR>   1993 </YEAR>
<INSTITUTION>   WAYNE STATE UNIVERSITY; 0254 </INSTITUTION>
<DESCRIPTORS>   COMPUTER SCIENCE; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER>   MICHAEL CONRAD </ADVISER>
<CLASSIFICATIONS>   MEMORY </CLASSIFICATIONS>
<ABSTRACT>
An artificial worlds model of the brain has been
developed that integrates memory, intraneuronal
dynamics, and multilevel evolutionary learning. The
model includes two major subsystems. The first is a
memory-manipulation scheme, called the reference neuron
system, that serves to orchestrate a repertoire of
neurons with different input-output capabilities.
Signals impinging on these neurons are integrated by a
cytoskeletal structure that is simulated as a cellular
automaton. The second subsystem is an evolutionary
learning scheme, called the selection circuits system,
that serves to train the neurons in the repertoire by
varying the cytoskeletal proteins that control signal
flow or readouts. The integrated system comprises two
layers of cytoskeletally controlled neurons and two
layers of reference neurons. Evolution can occur at the
level of readout enzymes in neurons, at the level of
proteins that control the flow of signals in the
cytoskeleton, and at the level of reference neurons that
orchestrate the repertoire. The integrated system
controls the motion of a modelled organism that is
embedded in an artificial environment consisting of
barriers, food, and a target. The organism effectively
learns to use patterns of barriers in its local
environment to find the target, using food as a reward.
Extensive simulation experiments have been performed
with the model. The integrated system effectively
employs synergies among the different levels of
processing and learning to acquire pathfinding
capabilities in a complicated environment. The
experimental results demonstrate that increasing the
dimensionality of the neurons by adding more types of
components and more weak interactions substantially
boosts the problem solving power of the system.
</ABSTRACT>
</THESIS>
<THESIS>
<NUMBER> 4090 </NUMBER>
<ORDER>   AAG9418133 </ORDER>
<TITLE>   NEURAL NETWORKS FOR IMAGE MODELING BY TWO DIMENSIONAL RANDOM FIELDS WITH APPLICATIONS TO IMAGE COMPRESSION </TITLE>
<AUTHOR>   BHAMA, SATYENDRA </AUTHOR>
<YEAR>   1993 </YEAR>
<INSTITUTION>   WAYNE STATE UNIVERSITY; 0254 </INSTITUTION>
<DESCRIPTORS>   ENGINEERING, ELECTRONICS AND ELECTRICAL; COMPUTER SCIENCE; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER>   HARPREET SINGH </ADVISER>
<CLASSIFICATIONS>   NIL </CLASSIFICATIONS>
<ABSTRACT>
This dissertation investigates the use of neural network
techniques for modeling with one-dimensional and two-
dimensional data, based on a gradient descent learning
algorithm for training a single layer neural network.
The algorithms have been developed to identify the
parameters of the unknown systems using three types of
data in one dimension: (i) the states and the output
response data of a continuous-time system (ii) the input
output response data of a continuous-time linear system,
and (iii) the input output-response of a discrete-time
linear system.
A new technique to model monochromatic stationary images
by two-dimensional random fields in the form of an
autoregressive (AR) process driven by white gaussian
noise (WGN) with known mean and correlation is
introduced. The image modeling technique consists of two
stages: (i) estimating the parameters of the image model
formulated in the form of two-dimensional random fields
represented in the form of an autoregressive moving
average process, (ii) reconstruction of the image with
the parameters of the model and the initial conditions
of the original image. During the first stage, the
parameters are estimated by optimizing the energy
function formulated by the mean square error (MSE) of a
single layer neural network using a gradient descent
learning algorithm. The output error is used to
construct the energy surface. In the second stage, the
image is regenerated recursively with appropriate region
of support using the neural model with its learned
weights as the parameters of the model and the initial
conditions of the original image.
Several computer simulations involving real image data
are given to illustrate the usefulness of the technique.
As the image is regenerated using only a few pixel
values of the original image, and the parameters of the
model, very effective image compression is achieved. The
results have been compared with similar results
described by Habibi using a linear system theory method,
and by Kashyap using an autoregressive model. The
results show that the proposed technique performs better
than linear system theory method and is comparable with
conventional AR technique.
</ABSTRACT>
</THESIS>
<THESIS>
<NUMBER> 4091 </NUMBER>
<ORDER>   AAG9418121 </ORDER>
<TITLE>   ADAPTIVE KNOWLEDGE ACQUISITION SYSTEMS IN EDUCATIONAL ENVIRONMENTS </TITLE>
<AUTHOR>   AKBAR, A-HAMID MOHD </AUTHOR>
<YEAR>   1993 </YEAR>
<INSTITUTION>   WAYNE STATE UNIVERSITY; 0254 </INSTITUTION>
<DESCRIPTORS>   ENGINEERING, ELECTRONICS AND ELECTRICAL; COMPUTER SCIENCE; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER>   FRANKLIN H. WESTERVELT </ADVISER>
<CLASSIFICATIONS>   KNOWLEDGE AQUISITION </CLASSIFICATIONS>
<ABSTRACT>
Contemporary adaptive systems typically require a priori
detailed specification of the subject application area
and the queries to which the system must respond. The
design of the system then depends on skilled input
assistance from experts in the subject area to
demonstrate convergent adaptive behavior before the
system can be used by novices. This dissertation
presents an adaptive knowledge acquisition algorithm
that can build a knowledge base from the beginning by
interaction with novice and expert users of the system,
but without other external assistance. The adaptive
system algorithm exhibits robust, convergent behavior
over multiple subject application areas. This is
achieved by introducing an additional level of recursion
in the adaptive system design process. The algorithm has
been implemented as part of a complete package in a
system that can be used to assist student learning in
educational environments. This new system in the field
of Artificial Intelligence (AI) should enhance
traditional classroom instruction and can provide
insight that an instructor may be unable to during
conventional lecture instruction. Prototype results have
encouraged exploration of the use of this adaptive
system algorithm in a variety of knowledge acquisition
and representation system applications.
</ABSTRACT>
</THESIS>
<THESIS>
<NUMBER> 4092 </NUMBER>
<ORDER>   AAG9418118 </ORDER>
<TITLE>   MACHINE LEARNING WITH RULE EXTRACTION BY GENETIC ASSISTED REINFORCEMENT </TITLE>
<AUTHOR>   ABU ZITAR, RAED ABDULLAH </AUTHOR>
<YEAR>   1993 </YEAR>
<INSTITUTION>   WAYNE STATE UNIVERSITY; 0254 </INSTITUTION>
<DESCRIPTORS>   COMPUTER SCIENCE; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER>   MOHAMAD H. HASSOUN </ADVISER>
<CLASSIFICATIONS>   REGAR): APPLICATION TO NONLINEAR CONTROL (NEUROCONTROLLER </CLASSIFICATIONS>
<ABSTRACT>
This dissertation proposes a novel system for rule
extraction of nonlinear control problems and presents a
new way of designing neurocontrollers. The system
employs a hybrid genetic search and reinforcement
learning strategy for extracting the rules. The learning
strategy requires no supervision and no reference model.
The extracted rules are weighted micro rules that
operate on small neighborhoods of the admissable control
space. A further refinement of the extracted rules can
be achieved by applying additional genetic search and
reinforcement in order to reduce the number of extracted
micro rules. This process results in a smaller set of
macro rules which can be used to train a feedforward
multilayer perceptron neurocontroller. The macro rules
may also be utilized in a table look-up fashion for
retrievals. As an example of the macro rules-based
neurocontroller, we chose five bench mark applications.
In the first application we verify the capability of our
system to learn optimal linear control strategies. The
other four applications are highly nonlinear, unstable,
and may include noise and delays in the plant dynamics.
They are the trailer-truck backer-upper control, the
engine idle speed control, the bioreactor process
control, and the two poles on a moving cart control. In
terms of retrievals, the neurocontrollers out-perform
the controllers using table look-up method. Both
controllers, though, show robustness against high noise
levels and parameter variations in the original plant.
</ABSTRACT>
</THESIS>
<THESIS>
<NUMBER> 4093 </NUMBER>
<ORDER>   AAG9418036 </ORDER>
<TITLE>   DEVELOPMENT OF AN INTELLIGENT AUTOMATED HIGH PERFORMANCE LIQUID CHROMATOGRAPHY SYSTEM. </TITLE>
<AUTHOR>   MEDLIN, STEPHEN VANCE </AUTHOR>
<YEAR>   1993 </YEAR>
<INSTITUTION>   MICHIGAN STATE UNIVERSITY; 0128 </INSTITUTION>
<DESCRIPTORS>   CHEMISTRY, ANALYTICAL; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER>   S. R. CROUCH </ADVISER>
<CLASSIFICATIONS>   VOLUMES I AND II) (EXPERT SYSTEM </CLASSIFICATIONS>
<ABSTRACT>
Methods development for high performance liquid
chromatography (HPLC) is a complex process. An expert
system has been created to assist in choosing an
appropriate column, detector, and mobile phase. The HPLC
instrument has been automated to provide the ability to
perform column switching for samples of sufficient
complexity that multiple columns may be required to
separate the solutes.
The expert system uses a first principle approach to
deduce a method(s). The expert system queries the user
with respect to the chemical and physical nature of the
solute(s). The expert system proposes a method based on
the possible chemical interactions between analyte(s)
and stationary phases. After recommendation of a column,
the expert system recommends an appropriate detector and
mobile phase.
The expert system uses confidence factors to rank the
different recommendations. Validation studies are
presented to demonstrate the first level of suggesting
appropriate methods and providing a numerical ranking of
the expected success via the use of confidence factors.
The HPLC instrument has been automated via a combination
of hardware and software. A modular software system has
been written which allows the user to create a method
for separating the sample. The software provides the
ability to perform column switching based upon time
criteria or the elution of sample. Column switching is
achieved through the automation of two six-port valves
and a six-position column selection valve.
Results are presented which demonstrate the ability to
develop a method from consultation with the expert
system and then programming the HPLC instrument to
perform the experiment. Preliminary results are also
presented which demonstrate the ability to perform
reproducible and complex column switching.
</ABSTRACT>
</THESIS>
<THESIS>
<NUMBER> 4094 </NUMBER>
<ORDER>   AAG9417334 </ORDER>
<TITLE>   AN ANALYSIS OF A CONNECTIONIST INTERNAL REPRESENTATION: DO RAAM NETWORKS PRODUCE TRULY DISTRIBUTED REPRESENTATIONS? </TITLE>
<AUTHOR>   BALOGH, IMRE LASZLO </AUTHOR>
<YEAR>   1993 </YEAR>
<INSTITUTION>   NEW MEXICO STATE UNIVERSITY; 0143 </INSTITUTION>
<DESCRIPTORS>   COMPUTER SCIENCE; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER>   JOHN BARNDEN </ADVISER>
<CLASSIFICATIONS>   NEURAL NETWORKS </CLASSIFICATIONS>
<ABSTRACT>
The use of a concatenative composition function for
structured representations is ubiquitous in symbolic
systems. This dominating prevalence has lead some
researchers to believe that any system that can perform
complex cognitive tasks must use a representational
system based on this type of composition. This view has
been challenged of late by connectionists. They have
developed systems that do not appear to use a
concatenative representation, but are able to do tasks
that it was claimed could only be done with
concatenative representations. A significant number of
these works have been based on the Recursive Auto
Associative Memory (RAAM) model introduced by Pollack
(1988, 1990). The work presented in this dissertation
investigates the validity of these claims by analyzing
the internal representations of one of the systems on
which these claims are based. The results presented
indicate that these internal representations do not have
the holistic characteristic that is claimed for them. In
fact, they are very close in nature to the localist
representation used by traditional symbolic systems. It
is shown that the representation used by these RAAM
based systems can be manipulated in a manner very
similar to the ones used in symbolic systems.
</ABSTRACT>
</THESIS>
<THESIS>
<NUMBER> 4095 </NUMBER>
<ORDER>   AAG9417291 </ORDER>
<TITLE>   NAIVE MECHANICS: A COMPUTATIONAL MODEL FOR REPRESENTING AND REASONING ABOUT SIMPLE MECHANICAL DEVICES </TITLE>
<AUTHOR>   HODGES, JOHN BARNETT, JR. </AUTHOR>
<YEAR>   1993 </YEAR>
<INSTITUTION>   UNIVERSITY OF CALIFORNIA, LOS ANGELES; 0031 </INSTITUTION>
<DESCRIPTORS>   COMPUTER SCIENCE; APPLIED MECHANICS; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER>   MICHAEL G. DYER </ADVISER>
<CLASSIFICATIONS>   BEHAVIORAL PRIMITIVES </CLASSIFICATIONS>
<ABSTRACT>
A symbolic theory for representing mechanical device
behavior, function and use for commonsense reasoning is
presented. Individual objects are described as a
collection of states which represent property values and
appearance. Object combinations are described by
orientation, placement, and connectivity. Mechanical
behavior describes the causal dependencies between
objects which produce changes in state. Five behavioral
primitives comprise a taxonomy of mechanical behavior.
The behavioral primitives combine to describe complex
behavior. Device function describes behavioral sequences
which have observable initial and terminal states.
Eleven machine primitives are proposed for describing
objects which are associated with a single function.
Machine primitives are used as building blocks for
representing complex device functions. Object use
describes the problem-solving context in which an object
function is applied. Object use is represented with
device-use plans, which associate object behavior and
function to a set of mechanical subgoals.
The combined representation theory is called FONM: A
Functional Ontology for Naive Mechanics. FONM is
designed to support high-level reasoning models
requiring access to knowledge at multiple abstraction
levels, particularly naive problem solving,
improvisation, and invention. FONM representations
address issues in representation breadth and
combinatorics, by providing a finite set of
representation primitives which are integrated to
describe device structure, behavior, function and use.
FONM device representations are used here in two
demonstration models: (1) device experimentation through
mutation of mechanical features, and (2) comprehension
of English device descriptions.
</ABSTRACT>
</THESIS>
<THESIS>
<NUMBER> 4096 </NUMBER>
<ORDER>   AAG9417156 </ORDER>
<TITLE>   A NEURAL NETWORK APPROACH TO BOX-JENKINS MODEL IDENTIFICATION </TITLE>
<AUTHOR>   REYNOLDS, STEVEN BAILEY </AUTHOR>
<YEAR>   1993 </YEAR>
<INSTITUTION>   THE UNIVERSITY OF ALABAMA; 0004 </INSTITUTION>
<DESCRIPTORS>   OPERATIONS RESEARCH; BUSINESS ADMINISTRATION, MANAGEMENT; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER>   JOSEPH M. MELLICHAMP </ADVISER>
<CLASSIFICATIONS>   ARIMA, FORECASTING </CLASSIFICATIONS>
<ABSTRACT>
Box-Jenkins ARIMA forecasting models have been shown to
produce better forecasts than other time series
forecasting methods. However, practitioners have been
reluctant to use ARIMA models, in part, because the
model identification task is complex and generally
requires a good deal of experience. Recent efforts to
resolve this dilemma have largely focused on
applications of expert systems technology.
In this research, the ARIMA model identification problem
for nonseasonal time series was solved using three-layer
backpropagation artificial neural networks. Two neural
networks were constructed to accomplish the task. The
first was designed to determine the number of regular
differences required to render a time series stationary.
The network was trained via the backpropagation
algorithm. Training examples consisted of
autocorrelation function values derived from stationary
and nonstationary simulated time series. Tests of
alternative network structures indicated that a network
with a single hidden node perfectly classified 60
simulated time series.
A second neural network was designed to identify
appropriate ARIMA models for stationary series indicated
by the first network. The network was trained with a
combination of autocorrelation (ACF) and partial
autocorrelation (PACF) values derived from simulated
time series and manufactured ACF/PACF inputs based on
known theoretical patterns. Tests of alternative network
structures revealed that a network with 12 inputs, 18
hidden layer neurons and 6 outputs produced appropriate
ARIMA model mappings.
Finally, the networks were tested with actual time
series from business and industry. The tests were
conducted in two phases. First, time series which were
of similar length as those used to train the networks
were tested. In the second phase, the ability of the
networks to generalize was assessed by testing with time
series which were twice and three times longer than
those used for training.
The results of the research indicated that neural
networks were very effective in identifying appropriate
ARIMA models for nonseasonal time series. Tests of the
networks' performance in identifying appropriate ARIMA
models for series of various lengths confirmed that the
models recommended were consistently better in terms of
quality and fit than those indicated by a commercially
available expert system package.
</ABSTRACT>
</THESIS>
<THESIS>
<NUMBER> 4097 </NUMBER>
<ORDER>   AAG9416877 </ORDER>
<TITLE>   APNEA RECOGNITION USING NEURAL NETWORKS </TITLE>
<AUTHOR>   ANAGUN, AHMET SERMET </AUTHOR>
<YEAR>   1993 </YEAR>
<INSTITUTION>   CLEVELAND STATE UNIVERSITY; 0466 </INSTITUTION>
<DESCRIPTORS>   ENGINEERING, INDUSTRIAL; ENGINEERING, BIOMEDICAL; COMPUTER SCIENCE; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER>   YING-HSIN A. LIOU </ADVISER>
<CLASSIFICATIONS>   BACKPROPAGATION, PATTERN RECOGNITION </CLASSIFICATIONS>
<ABSTRACT>
Apnea is defined as an absence of respiratory effort of
20 seconds for larger infants and five seconds for
smaller infants. Due to its effect on brain cells, apnea
is considered as a life threatening event. In this
dissertation, neural networks were used as a tool to
recognize apnea, and to determine the length and
frequency of apnea. The networks, Madaline,
BackPropagation (BP), and Adaptive Bidirectional
Associative Memory (ABAM), were chosen based on the
advantages of layered networks. Respiratory efforts of
infants who had apneic episodes were used to train the
networks. Two sensors, transthoracic electrical
impedance sensor and strain gauge compliant sensor, were
used to record respiratory efforts. The data were
presented to the networks in two ways; direct and
histogram representations. A pilot study was performed
to select proper neural network structure for apnea
recognition. The BP trained with the data which was
introduced by histogram representation was found to be a
proper neural network due to the high recognition
accuracy obtained in training and testing stages. Then,
several designed experiments were conducted to find a
combination of parameters to optimize the BP. In these
experiments, the number of hidden neurons, the learning
rate, and the momentum term were considered as major
factors which affect the overall performance. The
results showed that the BP trained with eight hidden
neurons, a learning rate of 0.85, and a momentum term of
0.9 was able to provide a recognition accuracy of 96.8%
in training.
After determining the optimum parameters for the BP, the
network was retrained with a total set of 460 training
patterns consisted of a wide variety of respiratory
efforts, and obtained a recognition accuracy of 99.8% in
training. A sequential testing procedure was employed to
provide useful information based on the length of apnea
and the frequency of apnea. Recognition accuracies of
96.7% for the electrical impedance, and 93.6% for the
strain gauge patterns were obtained.
</ABSTRACT>
</THESIS>
<THESIS>
<NUMBER> 4098 </NUMBER>
<ORDER>   AAG9413939 </ORDER>
<TITLE>   PRETRAINING AND SHELVING OF NEURAL NETWORKS BY FOURIER ANALYSIS AND THEIR USE FOR TARGET CLASSIFICATION </TITLE>
<AUTHOR>   MELENDEZ, GERARDO JAVIER </AUTHOR>
<YEAR>   1993 </YEAR>
<INSTITUTION>   DREXEL UNIVERSITY; 0065 </INSTITUTION>
<DESCRIPTORS>   ENGINEERING, ELECTRONICS AND ELECTRICAL; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER>   STANISLAV B. KESLER </ADVISER>
<CLASSIFICATIONS>   BACK PROPAGATION </CLASSIFICATIONS>
<ABSTRACT>
This effort was motivated by a problem of present and
practical interest, namely, the classification of
targets using radar data. The multi layer perceptron
(MLP) neural network and its associated Back Propagation
Algorithm (BPA) were proposed as a solution because of
the expected payoff in robustness to some radar
parameters such as dwell time. In so doing, the
limitations associated with the BPA, such as the well
documented long training time, had to be dealt with.
The method proposed to reduce the training time of the
BPA partitioned the training process in 2 steps,
pretraining and final training. A network was first
pretrained using one of four approaches. Final training
then consisted of: (1) changing the topology of the
pretrained network to accommodate the requirements of
the specific target classification problem and; (2)
training the network to classify the targets using the
BPA.
The final training step departed from the typical
practice of initializing the weights of the MLP
randomly. Instead, initial weights for the final
training were obtained at the end of the pretraining
process. The pretraining process trained a network to
recognize a set of basic signal components that form the
target's signature. If the basic signal components are
selected independent of any specific target set, then
the pretrained network can be shelved for future use
against different target classification problems.
For the specific problem of target classification by
radar, the Fourier basis was proposed as the set of
basic signal components. components. The objective of
the pretraining process was to train the network to
recognize sinusoids. Four pretraining approaches were
developed to perform the spectrum estimation function.
The algorithms for two of those approaches were tested
against simulated signals. One of the two algorithms was
used to classify aircraft using radar data. The
performance of that one approach was compared to the
performances of the baseline BPA and of an enhanced
baseline that augmented the BPA by initializing the
weights in a different fashion. The results indicate
that the pretraining approach was effective at reducing
the training time. Other benefits were also noted.
</ABSTRACT>
</THESIS>
<THESIS>
<NUMBER> 4099 </NUMBER>
<ORDER>   AAG9408730 </ORDER>
<TITLE>   LEARNING LANGUAGE ABOUT OBJECTS AND USING THIS LANGUAGE TO LEARN FURTHER: THE CHILDLIKE SYSTEM </TITLE>
<AUTHOR>   MANI, GANESH </AUTHOR>
<YEAR>   1993 </YEAR>
<INSTITUTION>   THE UNIVERSITY OF WISCONSIN - MADISON; 0262 </INSTITUTION>
<DESCRIPTORS>   COMPUTER SCIENCE; LANGUAGE, LINGUISTICS; PSYCHOLOGY, DEVELOPMENTAL; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER>   LEONARD UHR </ADVISER>
<CLASSIFICATIONS>   NIL </CLASSIFICATIONS>
<ABSTRACT>
Artificial intelligence and cognitive science have
traditionally adopted the modular approach to
intelligence: vision, language and action have been
analyzed separately and systems have been developed that
demonstrate competence in each of these areas. It is
only recently that integrated systems that span multiple
modalities and performance abilities have begun to gain
attention. This thesis describes an integrated,
computational model of learning--implemented as a
program, called the CHILDLIKE system. CHILDLIKE starts
by combining language and vision, and attempts to
include actions and needs in the same framework. The
system learns names for simple objects and their
qualities from input experiences that consist of small
visual feature arrays and short language strings. Using
this as a foundation, the system is able to learn
spatial relations and also acquire knowledge related to
the effect of actions on external perceptual states and
internal need levels. CHILDLIKE employs an interacting
set of hybrid symbolic-connectionist learning
mechanisms: extraction, aggregation, generation, re-
weighting, de-generation and generalization. Since the
current version of the system is a first step towards
building a realistic integrated system that combines
vision, language and action, arguments as to the
scalability and generality of the approach are also
presented.
</ABSTRACT>
</THESIS>
<THESIS>
<NUMBER> 4100 </NUMBER>
<ORDER>   AAGNN85474 </ORDER>
<TITLE>   SELF-ORTHOGONALIZING STRATEGIES FOR ENHANCING HEBBIAN LEARNING IN RECURRENT NEURAL NETWORKS </TITLE>
<AUTHOR>   DAVENPORT, MICHAEL RICHARD </AUTHOR>
<YEAR>   1993 </YEAR>
<INSTITUTION>   THE UNIVERSITY OF BRITISH COLUMBIA (CANADA); 2500 </INSTITUTION>
<DESCRIPTORS>   COMPUTER SCIENCE; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER>   GEOFFREY HOFFMANN </ADVISER>
<CLASSIFICATIONS>   NIL </CLASSIFICATIONS>
<ABSTRACT>
A neural network model is presented which extends
Hopfield's model by adding hidden neurons. The resulting
model remains fully recurrent, and still learns by
prescriptive Hebbian learning, but the hidden neurons
give it power and flexibility which were not available
in Hopfield's original network. The key to the success
of the model is that it uses the emerging structure of
its own memory space to establish a pattern in the
hidden neurons such that each new memory is optimally
orthogonal to all previous memories. As a result, the
network actually learns a memory set which is "near-
orthogonal", even though the visible components of
the memories are randomly selected.
The performance of the new network is evaluated both
experimentally, using computer simulations, and
analytically, using mathematical tools derived from the
statistical mechanics of magnetic lattices. The
simulation results show that, in comparison with
Hopfield's original model, the new network can (a) store
more memories of a given size, (b) store memories of
different lengths at the same time, (c) store a greater
amount of information per neuron, (d) retrieve memories
from a smaller prompt, and (e) store the XOR set of
associations. It is also shown that the memory recovery
process developed for the new network can be used to
greatly expand the radius of attraction of standard
Hopfield networks for "incomplete" (as opposed
to "noisy") prompts.
The mathematical analysis begins by deriving an
expression for the free energy of a Hopfield network
when a near-orthogonal memory set has been stored. The
associated mean-field equations are solved for the zero
temperature, single-recovered-memory case, yielding an
equation for the memory capacity as a function of the
level of orthogonality. A separate calculation derives a
statistical estimate of the level of orthogonality that
can be achieved by the roll-up process. When this is
combined with the memory capacity-vs-orthogonality
result, it yields a reasonable estimate of the memory
capacity as a function of the number of hidden neurons.
Finally, the theoretical maximum information content of
sets of near-orthogonal memories is calculated as a
function of the level of orthogonality, and is compared
to the amount of information that can be stored in the
new network.
</ABSTRACT>
</THESIS>
<THESIS>
<NUMBER> 4101 </NUMBER>
<ORDER>   AAGNN85435 </ORDER>
<TITLE>   IMPRECISE PROBABILITY AND DECISION IN CIVIL ENGINEERING: DEMPSTER-SHAFER THEORY AND APPLICATION </TITLE>
<AUTHOR>   LUO, WUBEN </AUTHOR>
<YEAR>   1993 </YEAR>
<INSTITUTION>   THE UNIVERSITY OF BRITISH COLUMBIA (CANADA); 2500 </INSTITUTION>
<DESCRIPTORS>   ENGINEERING, CIVIL </DESCRIPTORS>
<ADVISER>   W. F. CASELTON </ADVISER>
<CLASSIFICATIONS>   NIL </CLASSIFICATIONS>
<ABSTRACT>
Over the last three decades, Bayesian theory has been
widely adopted in civil engineering for dealing with
uncertainty and for purposes of decision making under
uncertainty. However the Bayesian approach is not
without criticisms. One major concern has been that
information or knowledge, no matter how weak or sparse,
must necessarily be represented by conventional,
precisely specified, probabilities. This has led to the
development of statistical methods which allow for more
flexible expressions of both information inputs, and
inferred results. More recently a general concept,
called imprecise probability, which embraces a number of
these methods, has been described (Walley, 1991).
Weak information is often encountered in civil
engineering. This is especially true in decision making
as major decisions are often dominated by random, but
infrequent, extreme natural events. For these rare
events the sample record is usually short and the
relevant subjective knowledge based on human experience
is also likely to be very limited. The imprecise
probability concept therefore has potential relevance to
some important civil engineering decision problems.
Among the existing imprecise probability schemes,
Dempster-Shafer (D-S) theory is prominent. This theory
has attracted considerable attention in the Artificial
Intelligence (AI) field, but the applications are
different from those considered here. This has largely
overshadowed the relevance of the theory to the more
conventional inference and decision making types of
problems encountered in civil engineering.
In this thesis, some applications of the D-S theory
primarily to water resources engineering decision
problems are developed. The engineering examples
presented throughout the thesis provide some indications
of the impact of implementing imprecise probabilities on
engineering decision analysis. In most instances a
closest equivalent Bayesian analysis is performed and
the results compared with those obtained from the D-S
scheme.
The concept of imprecise probability is philosophically
important to the research and is briefly reviewed. The
theoretical ingredients of D-S theory which are
necessary to support engineering applications are then
introduced. This is followed by presentation of several
different procedures for translating weak sampling
information inputs into D-S inference results. The
elicitation of subjective prior inputs for the D-S
scheme is also discussed and includes representing some
typical engineering expressions of subjective knowledge.
Two civil engineering models, one in hydrologic design
and the other in reliability analysis, are also
developed, and they demonstrate how the scheme can be
applied in more complex engineering situations.
When presented with weak information input, the D-S
decision analysis yields upper and lower expected
utilities. This reduces the ability to choose between
the best decision alternatives, especially when the
expected utility intervals for different decisions
overlap. But this reduction in resolution is believed to
more realistically reflect the true decision making
situation. The factors governing the size of the
expected utility interval are also discussed.
</ABSTRACT>
</THESIS>
<THESIS>
<NUMBER> 4102 </NUMBER>
<ORDER>   AAG9412922 </ORDER>
<TITLE>   IMPROVISATION IN TWENTIETH-CENTURY SOLO PIANO REPERTOIRE, AS REPRESENTED IN ALVIN CURRAN'S FIRST PIANO PIECE </TITLE>
<AUTHOR>   PAUL, ROBERT CHRISTIAN </AUTHOR>
<YEAR>   1993 </YEAR>
<INSTITUTION>   UNIVERSITY OF MIAMI; 0125 </INSTITUTION>
<DESCRIPTORS>   MUSIC </DESCRIPTORS>
<ADVISER>   J. ROBERT FLOYD </ADVISER>
<CLASSIFICATIONS>   1967) AND PIECES SELECTED FROM "SQUARES" (1978) AND FOUR NORTH AMERICAN BALLADS (1978-1979), BY FREDERIC RZEWSKI (CURRAN ALVIN, RZEWSKI FREDERIC, PIANO, TWENTIETH CENTURY </CLASSIFICATIONS>
<ABSTRACT>
The focal point of this study is an examination of
improvisational problems encountered by the mature
performer. The subject of improvisation is addressed
generally on several levels, then from several more
specific points of view. The general discussion includes
historical surveys across a broad stylistic spectrum,
and models of improvisation taken from the fields of
psychology and artificial intelligence. The second part
of the study addresses more specific problems:
considerations specific to the solo improviser,
considerations specific to improvisation within a
composed context, the development of vocabulary,
analyses of the selected works and improvisational
problems specifically related to these works, and a
discussion of intangible factors in improvisation. The
purpose of the study is twofold: first, to discuss in
detail the problems encountered in preparing and
performing the improvisational elements in the selected
works; and secondly, to abstract a general insight into
the problem of improvisation across a broad stylistic
spectrum.
</ABSTRACT>
</THESIS>
<THESIS>
<NUMBER> 4103 </NUMBER>
<ORDER>   AAGNN85438 </ORDER>
<TITLE>   AN EXPERIMENTAL INVESTIGATION OF THE USE OF EXPLANATIONS PROVIDED BY KNOWLEDGE-BASED SYSTEMS </TITLE>
<AUTHOR>   DHALIWAL, JASBIR SINGH </AUTHOR>
<YEAR>   1993 </YEAR>
<INSTITUTION>   THE UNIVERSITY OF BRITISH COLUMBIA (CANADA); 2500 </INSTITUTION>
<DESCRIPTORS>   BUSINESS ADMINISTRATION, MANAGEMENT; COMPUTER SCIENCE; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER>   IZAK BENBASAT </ADVISER>
<CLASSIFICATIONS>   NIL </CLASSIFICATIONS>
<ABSTRACT>
Ever since MYCIN introduced the idea of computer-based
explanations to the artificial intelligence community,
it has come to be taken for granted that all knowledge-
based systems (KBS) need to provide explanations.
The first part of this dissertation proposes a cognitive
learning theory based model that both clarifies the
reasons as to why KBS need to provide explanations and
serves as the basis for conceptualizing the provision of
KBS explanations. Using the concepts of the feedforward
and feedback operators of cognitive learning it develops
strategies for providing KBS explanations and uses them
to classify the various types of explanations found in
current KBS applications. The roles of feedforward and
feedback explanations within the context of the theory
of cognitive skill acquisition and a model of expert
judgment are also analyzed. These, together with past
studies of KBS explanations, suggest that user
expertise, the types of explanations provided, and the
level of user agreement are significant factors that
influence the explanation seeking behavior of users. The
dissertation also explores the effects of the use of KBS
explanations in judgmental decision making situations
supported by a KBS. It identifies and considers four
distinct categories of potential effects of the use of
explanations--learning effects, perceived effects,
behavioral effects, and effects on judgmental decision
making.
The second part of the dissertation empirically
evaluates the explanation provision strategies in a
laboratory experiment in which 80 novice and expert
subjects used a KBS for financial analysis to make
judgments under conditions of uncertainty. The
experiment was designed specifically to investigate the
following fundamental research questions: (1) To what
extent are the various kinds of explanations used? (2)
How does user expertise, the feedforward and feedback
provision of explanations, and the level of user
agreement influence the amount and the types of
explanations that are used? and (3) Does the use of
explanations affect the accuracy of judgmental decision-
making and user perceptions of usefulness?
Some of the major results relating to the determinants
of the use of KBS explanations include: (1) user
expertise is not a determinant of the proportion of
explanations used but influences the types of
explanations that are used, (2) explanation provision
strategy is a critical determinant of the use of KBS
explanations with feedback explanations being used
significantly more than feedforward explanations, and
(3) the three types of explanations are used in
different proportions with the Why and How explanations
being used significantly more that the Strategic
explanations. (Abstract shortened by UMI.)
</ABSTRACT>
</THESIS>
<THESIS>
<NUMBER> 4104 </NUMBER>
<ORDER>   AAG1355912 </ORDER>
<TITLE>   AN INTELLIGENT THREAT ASSESSMENT MODEL FOR LOW ALTITUDE AIR DEFENSE SYSTEMS </TITLE>
<AUTHOR>   HOWELL, MARC LAMOINE </AUTHOR>
<YEAR>   1993 </YEAR>
<INSTITUTION>   UNIVERSITY OF ALABAMA IN HUNTSVILLE; 0278 </INSTITUTION>
<DESCRIPTORS>   ENGINEERING, INDUSTRIAL; COMPUTER SCIENCE </DESCRIPTORS>
<ADVISER>   L. D. INTERRANTE </ADVISER>
<CLASSIFICATIONS>   NIL </CLASSIFICATIONS>
<ABSTRACT>
Selective attention is a growing area of artificial
intelligence. It is concerned with the challenges of
focusing limited system resources on the important
situations perceived by a system through sensor data.
The purpose of this study was to investigate the
usefulness of one aspect of selective attention,
selective monitoring, in concert with the data intensive
sensor requirements of low altitude air defense systems.
A discussion of the important domain characteristics for
air defense environments is presented. A selective
monitoring model for an intelligent agent was developed
as a threat assessment aid to the system operator. An
implementation of the model was developed to compare
with an existing system via simulation. The evaluation
of the simulation results shows that selective
monitoring benefits the defense system by improving
sensor utilization. The model was implemented as a
computer program in Ada using list structures.
</ABSTRACT>
</THESIS>
<THESIS>
<NUMBER> 4105 </NUMBER>
<ORDER>   AAG1355881 </ORDER>
<TITLE>   APPLICATION OF NEURAL NETWORKS TO THE POST-TEST DETECTION OF SPACE SHUTTLE MAIN ENGINE ANOMALIES </TITLE>
<AUTHOR>   WHITLEY, MICHAEL ROSS </AUTHOR>
<YEAR>   1993 </YEAR>
<INSTITUTION>   UNIVERSITY OF ALABAMA IN HUNTSVILLE; 0278 </INSTITUTION>
<DESCRIPTORS>   COMPUTER SCIENCE; ENGINEERING, AEROSPACE; ENGINEERING, MECHANICAL; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER>   NIL </ADVISER>
<CLASSIFICATIONS>   NIL </CLASSIFICATIONS>
<ABSTRACT>
This thesis provides an overview of detection methods
for Space Shuttle Main Engine (SSME) anomalous behavior
and provides rational for the incorporation of neural
network empirical models into the current anomaly
detection methodology.
A primary method of monitoring the health of the SSME's
is to evaluate the sensor data from the engines after
each firing. Since the time available to the experts for
data evaluation is limited, the optimal reliability of
the anomaly detection method cannot be guaranteed.
Therefore, more automation needs to be incorporated into
the SSME post firing data evaluation process.
Automation of the SSME post firing data evaluation
process will require an automated means of determining
nominal SSME behavior under various operating
conditions. This thesis demonstrated the feasibility of
neural network empirical models to modeling nominal SSME
behavior, even when the SSME experiences frequent line-
replaceable-unit (LRU) changeouts.
This thesis demonstrated the benefit of using a neural
network empirical model in SSME anomaly detection
procedures by comparing the reliability of detecting
anomalous behavior in a SSME test series by the current
method and by the current method with the empirical
model incorporated. The current method with the
empirical model incorporated detected a progressive
anomaly one test earlier than by the current method
alone. (Abstract shortened by UMI.)
</ABSTRACT>
</THESIS>
<THESIS>
<NUMBER> 4106 </NUMBER>
<ORDER>   AAG9416646 </ORDER>
<TITLE>   EVOLUTION OF EXPERT SYSTEMS </TITLE>
<AUTHOR>   PALACIOS CULEBRO, JOAQUIN MARCOS </AUTHOR>
<YEAR>   1993 </YEAR>
<INSTITUTION>   TEXAS TECH UNIVERSITY; 0230 </INSTITUTION>
<DESCRIPTORS>   COMPUTER SCIENCE; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER>   JAMES E. ARCHER </ADVISER>
<CLASSIFICATIONS>   SCHEDULING </CLASSIFICATIONS>
<ABSTRACT>
Expert systems are computer programs for providing
expertise emulative of that which might be expected from
human experts in solving complex problems for which
analytical solutions are not available. Evolution of an
expert system refers to the initial development of the
system and its continuing modification in order to
improve its performance. Any modifications made to an
expert system have the potential of producing
undesirable logical errors and side-effects that are
difficult to find or prevent. Although much research has
focused on facilitating the evolution of expert systems,
most of the limitations still exist.
This dissertation proposes an approach for structuring
and evolving expert systems for applications in which
the provision of the desired expertise is beyond the
reach of either analytical or traditional heuristic
approaches, but in which the knowledge domain is
causally connected and the relevant causality can be
expressed in procedural form.
The research vehicle used is that of a hypothetical
manufacturing system in which products of different
types use some of the same workstations, and some of the
product types loop back to workstations that they have
previously used. The expertise sought is that of
scheduling starts of products into the first stage of
production so as to yield a stream of output that
satisfies a user-specified balance among a variety of
business performance measures including timeliness of
production output.
An approach for structuring and evolving expert systems
is introduced. The main system elements are: A
simulation model of the causal relations of the
knowledge domain; a collection of heuristic algorithms,
each guaranteed to produce a feasible solution to any
problem lying within the scope of the system's
expertise; and a module that determines, from user-
supplied criteria, the best of the alternative
solutions. The evolution approach is based on adding new
heuristic algorithms rather than modifying existing
ones.
That approach is used to develop, and evolve through
several steps of evolution, an expert system for the
subject application. The experimental results assess the
expert system's initial capability, and demonstrate the
evolution of the system's expertise through addition of
more heuristic algorithms.
</ABSTRACT>
</THESIS>
<THESIS>
<NUMBER> 4107 </NUMBER>
<ORDER>   AAG9416631 </ORDER>
<TITLE>   MAPPING THE TEAM DECISION THEORY PROBLEM TO HOPFIELD- LIKE NEURAL NETWORKS </TITLE>
<AUTHOR>   RAO, GIRIDHAR </AUTHOR>
<YEAR>   1993 </YEAR>
<INSTITUTION>   TEXAS TECH UNIVERSITY; 0230 </INSTITUTION>
<DESCRIPTORS>   COMPUTER SCIENCE; STATISTICS; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER>   WILLIAM J. B. OLDHAM </ADVISER>
<CLASSIFICATIONS>   NIL </CLASSIFICATIONS>
<ABSTRACT>
Team Decision Theory is a statistical discipline that
has several applications in areas such as decentralized
control and distributed computing. In the middle to late
1970's, this area was studied quite extensively.
However, there were several limitations to the scope of
the study due to the inherent mathematical
intractability of the problem. There were severe
restrictions on the nature of the system inputs and
their probability distribution functions. Unless the
underlying probability density functions of the system
parameters were Gaussian, it was not possible to derive
analytical solutions to the problems.
In recent years, neural networks have become
increasingly popular as a means to solve large
optimization problems. The high interconnectivity and
the nature of neuron layouts and interactions have led
to success in mapping large optimization problems to
neural networks. In particular the Hopfield-Tank Network
and some derivations thereof have been successful for
these problems. Neural networks are not sensitive to the
underlying probability distributions of the systems they
are trying to solve.
With the advent of cheaper hardware and faster networks,
distributed processing in a networked system has become
increasingly popular. One of the key areas of study in
distributed computing is the load balancing discipline;
determining an optimal balancing of tasks or jobs among
the various nodes in the system to maximize system
performance and throughput. Several schemes have been
studied with varying degrees of success.
This work ties these vastly different areas of research
together by mapping the team decision theory problem to
the Hopfield neural network, then a modified Hopfield
network. Several examples of team decision theory
problems ranging from a small two-person two-decision
problem, to a more theoretical team decision problem,
then finally a practical "real-world"
application: load balancing in a distributed computing
environment. In all cases, the neural networks were able
to converge to at least a good, if not the best
solution. For the two-person two-decision problem, the
network solution was compared against the best solution
found by exhaustive search; for the theoretical team
decision problem, the network solution was compared to
the solution of the nearest neighbor states; and for the
load balancing problem, the network solution's
"goodness" was measured through simulation.
</ABSTRACT>
</THESIS>
<THESIS>
<NUMBER> 4108 </NUMBER>
<ORDER>   AAG9416625 </ORDER>
<TITLE>   AN INTEGRATED ADAPTIVE FUZZY CLUSTERING MODEL FOR PATTERN RECOGNITION </TITLE>
<AUTHOR>   KIM, YONG SOO </AUTHOR>
<YEAR>   1993 </YEAR>
<INSTITUTION>   TEXAS TECH UNIVERSITY; 0230 </INSTITUTION>
<DESCRIPTORS>   ENGINEERING, ELECTRONICS AND ELECTRICAL; COMPUTER SCIENCE; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER>   SUNANDA MITRA </ADVISER>
<CLASSIFICATIONS>   NEURAL NETWORKS, CLUSTERING ALGORITHMS, FUZZY LOGIC </CLASSIFICATIONS>
<ABSTRACT>
The goal of clustering algorithms is to partition a data
set into clusters such that the data in a cluster are
more similar to each other than the data in other
clusters. Among pattern recognition systems, neural
networks and fuzzy models are used most frequently
nowadays. The neural network is powerful in processing
numerical data because of its computational capability.
On the other hand, fuzzy logic represents uncertainty
that we encounter in human thought processes. Recently,
a lot of interest has been shown in interfacing between
fuzzy logic and neural networks. One trend is the
incorporation of fuzzy logic into neural network
architectures. This trend has focused on integrating
fuzzy learning rules into neural networks. Existing
fuzzy neural networks suffer from either restrictions in
the shape of the clusters formed or the requirement of
large memory capacity. The Integrated Adaptive Fuzzy
Clustering (IAFC) Model solves the above-mentioned
problems by incorporating a new fuzzy learning rule and
a new similarity measure into a neural network
architecture that is similar to the Adaptive Resonance
Theory neural network. The new learning rule utilizes a
fuzzy membership value, an intra-cluster membership
value, and a function of the number of iterations
instead of the arbitrary learning rate in the
incremental learning rule. The new similarity measure
incorporates a fuzzy membership value into the Euclidean
distance. This incorporation gives more flexibility to
the shape of the clusters formed. The performance of the
IAFC model was evaluated via classification of real data
and compared with other recent neuro-fuzzy or fuzzy
clustering algorithms.
</ABSTRACT>
</THESIS>
<THESIS>
<NUMBER> 4109 </NUMBER>
<ORDER>   AAG9415794 </ORDER>
<TITLE>   MODELING OF DISTILLATION COLUMN AND REACTOR DYNAMICS USING ARTIFICIAL NEURAL NETWORKS </TITLE>
<AUTHOR>   PARK, JUN-KU </AUTHOR>
<YEAR>   1993 </YEAR>
<INSTITUTION>   NORTHWESTERN UNIVERSITY; 0163 </INSTITUTION>
<DESCRIPTORS>   ENGINEERING, CHEMICAL; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER>   R. S. H. MAH; J. S. DRANOFF </ADVISER>
<CLASSIFICATIONS>   NEURAL NETWORKS </CLASSIFICATIONS>
<ABSTRACT>
Artificial neural networks (ANN's) have recently
attracted much attention from the chemical engineers
because of their potential advantages as follows: ANN's
are inherently parallel and can learn nonlinear
relations from sets of data. The application of ANN's to
the modeling of dynamic chemical engineering processes
has recently been discussed in several papers, however
the applications were limited to some specifically
selected examples. In this thesis, several typical
chemical engineering processes are classified according
to their degree of nonlinearity and dynamics, and
representative examples in each of four classes are
selected, i.e. distillation column, isothermal CSTR,
nonisothermal CSTR, and batch reactor. The dynamic
modeling of the selected processes using ANN's, mainly
recurrent networks, is studied. Some basic research
about the various parameters of ANN's is also discussed
in the beginning of the thesis.
As a result of basic research, some of the rules for the
structural simplification of ANN's are verified. Noise
filtering ability of ANN is also discussed. Several
variations of the fully recurrent network for better
applications are proposed. Through the study of
application of ANN to a distillation column, the
importance of considering the process dynamics is
emphasized. Through the dynamic modeling of an
isothermal CSTR using recurrent nets, the relation
between the physical parameters and the ANN parameters
are discussed. Various dynamic behaviors of a
nonisothermal CSTR are modeled using recurrent nets, and
a training strategy to overcome the convergence problem
of ANN for difficult examples is proposed. Also a
control method based on the developed ANN models is
proposed. Finally, ANN model for the early on-line
runaway prediction of a batch reactor is developed and
its robustness to noise and process changes is
demonstrated.
</ABSTRACT>
</THESIS>
<THESIS>
<NUMBER> 4110 </NUMBER>
<ORDER>   AAG9415760 </ORDER>
<TITLE>   AN LVQ-TRAINED HIDDEN MARKOV MODEL FOR AUTOMATIC SPEECH RECOGNITION </TITLE>
<AUTHOR>   KUO, YU-CHUN </AUTHOR>
<YEAR>   1993 </YEAR>
<INSTITUTION>   NORTHWESTERN UNIVERSITY; 0163 </INSTITUTION>
<DESCRIPTORS>   ENGINEERING, ELECTRONICS AND ELECTRICAL; COMPUTER SCIENCE; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER>   JANET C. RUTLEDGE </ADVISER>
<CLASSIFICATIONS>   LEARNING VECTOR QUANTIZATION, NEURAL NETWORK </CLASSIFICATIONS>
<ABSTRACT>
In recent years, hidden Markov models (HMM's) have
evolved to become the most popular technique for the
application of speech recognition. However, individual
HMM's have a weak discriminating power such that input
observations might be mis-represented by the wrong HMM
for isolated-word recognition. Thus, the main objective
in this research is to find a way to enhance the
discriminating power of HMM's, which in return will also
lead to the reduction of errors in continuous speech
recognition.
In order to enhance the performance of HMM, this
dissertation attempts to apply a secondary training
process from neural networks to adjust the HMM
parameters. A supervised learning technique, namely
learning vector quantization (LVQ), is used for the
additional training procedure. However, there are two
major difficulties that lie in front of the joint
training of HMM and LVQ. First, LVQ has to process the
input observation in real time with the knowledge of the
input pattern. Unfortunately, input signals like speech
are usually composed of a sequence of observations whose
state sequence is not determined until the whole input
sequence has entered the HMM. Secondly, LVQ is
memoryless and is not able to preserve the temporal
information within the speech signals, which is crucial
to signals like speech.
To solve the above two difficulties impeding the joint
application of HMM and LVQ, a sequential learning vector
quantizer (SLVQ) is proposed in this research. During
the training process, each HMM is regarded as a
sequential LVQ codebook which can preserve the temporal
information of speech signals. SLVQ allows the real-time
processing of input speech which travels through each
HMM. Experiments of speech recognition for both the
isolated-word and the connected-word cases using the
SLVQ training procedure have shown improvement of
correct recognition.
</ABSTRACT>
</THESIS>
<THESIS>
<NUMBER> 4111 </NUMBER>
<ORDER>   AAG9415758 </ORDER>
<TITLE>   FLEXIBLE LEARNING IN A MULTI-COMPONENT PLANNING SYSTEM </TITLE>
<AUTHOR>   KRULWICH, BRUCE TEPPER </AUTHOR>
<YEAR>   1993 </YEAR>
<INSTITUTION>   NORTHWESTERN UNIVERSITY; 0163 </INSTITUTION>
<DESCRIPTORS>   COMPUTER SCIENCE; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER>   LAWRENCE BIRNBAUM </ADVISER>
<CLASSIFICATIONS>   MACHINE LEARNING, DECISION-MAKING, CASTLE </CLASSIFICATIONS>
<ABSTRACT>
People are able to learn a wide range of lessons from a
given experience, depending on which of their cognitive
abilities seem to need improvement. A theory of learning
to plan should account for how and why an intelligent
agent can learn such a diversity of lessons. Such a
theory must address not only how and when an agent
learns, but also what the agent should learn, because
lessons must be formulated appropriately for the skills
being improved. This thesis argues that a machine
learning system must be able to dynamically determine
what to learn from an experience. Making this
determination requires that the system posses explicit
knowledge of its own decision-making procedures, and be
able to apply this knowledge in learning.
This thesis describes the scCASTLE system, which learns
new rules for a variety of cognitive tasks in the domain
of competitive games, in particular chess. C scASTLE's
tasks include detection of threats and opportunities,
plan recognition, goal generation, planning,
counterplanning, and plan selection. C scASTLE uses
knowledge of its planning procedures to determine which
of its decision-making components are responsible for
expectation failures, and uses an abstract model of
planning to appropriately formulate new rules.
</ABSTRACT>
</THESIS>
<THESIS>
<NUMBER> 4112 </NUMBER>
<ORDER>   AAG9415747 </ORDER>
<TITLE>   INTERVAL-BASED BAYESIAN BELIEF NETWORKS FOR MEDICAL IMAGE RECOGNITION </TITLE>
<AUTHOR>   HWANG, CHEIN-SHUNG </AUTHOR>
<YEAR>   1993 </YEAR>
<INSTITUTION>   NORTHWESTERN UNIVERSITY; 0163 </INSTITUTION>
<DESCRIPTORS>   COMPUTER SCIENCE; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER>   WEI-CHUNG LEI </ADVISER>
<CLASSIFICATIONS>   IMAGE RECOGNITION </CLASSIFICATIONS>
<ABSTRACT>
How to formulate a reasoning module to integrate all the
relevant evidence from diverse sources is an issue
central to the design of knowledge-based systems.
Various artificial intelligence (AI) techniques have
been adopted for constructing the reasoning modules to
represent and propagate uncertainties in knowledge-based
systems. Among them, Bayesian belief networks have
become popular in AI-uncertainty community. In many
applications, it is usually difficult to provide
reliable point estimates for probability values due to
weak evidence and insufficient information. In this
dissertation, we propose a mechanism for performing
probability reasoning in tree-structured Bayesian belief
networks using intervals rather than point values. A
feasible interval space is defined to avoid processing
undesirable interval estimates. The probability
distributions of a feasible interval space are specified
by a set of corners which convey the boundary
information of the interval space. The propagation
scheme of the interval-based tree-structured Bayesian
belief networks is then derived by incorporating the
contributions of those corners in each interval space
and taking the minimum and maximum values.
We first apply our method to an existing medical
recognition system for building the reasoning module.
The goal of this system is to recognize the major
anatomical structures of human brain by using the images
from different imaging modalities. The blackboard system
is selected as the framework to integrate various kinds
of knowledge from sensor characteristics, anatomical
structures, evidence acquisition and propagation, and
image processing and analysis techniques. In this
system, we construct one Bayesian belief network for the
integration of evidence from multiple sensors and the
other for opportunistic control in a blackboard
architecture based on the relationships between
anatomies and the model slices. To show the strength and
the flexibility of our proposed approach, we develop
another expert vision system based on the interval-based
Bayesian belief networks to recognize the muscle
boundaries in a series of cross-sectional magnetic
resonance images of the human thigh region. In this
system, we build a belief network for integrating the
information from the feature space of each anatomy
(muscle) to localize the images.
</ABSTRACT>
</THESIS>
<THESIS>
<NUMBER> 4113 </NUMBER>
<ORDER>   AAG9409122 </ORDER>
<TITLE>   ON GENERALIZED ADAPTIVE NEURAL FILTERS </TITLE>
<AUTHOR>   ZHANG, ZHIQIANG </AUTHOR>
<YEAR>   1993 </YEAR>
<INSTITUTION>   NEW JERSEY INSTITUTE OF TECHNOLOGY; 0152 </INSTITUTION>
<DESCRIPTORS>   ENGINEERING, ELECTRONICS AND ELECTRICAL; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER>   NIRWAN ANSARI </ADVISER>
<CLASSIFICATIONS>   NEURAL NETWORKS, IMAGE PROCESSING </CLASSIFICATIONS>
<ABSTRACT>
Linear filters have historically been used in the past
as the most useful tools for suppressing noise in signal
processing. It has been shown that the optimal filter
which minimizes the mean square error (MSE) between the
filter output and the desired output is a linear filter
provided that the noise is additive white Gaussian noise
(AWGN). However, in most signal processing applications,
the noise in the channel through which a signal is
transmitted is not AWGN; it is not stationary, and it
may have unknown characteristics.
To overcome the shortcomings of linear filters,
nonlinear filters ranging from the median filters to
stack filters have been developed. They have been
successfully used in a number of applications, such as
enhancing the signal-to-noise ratio of the
telecommunication receivers, modeling the human vocal
tract to synthesize speech in speech processing, and
separating out the maternal and fetal electrocardiogram
signals to diagnose prenatal ailments. In particular,
stack filters have been shown to provide robust noise
suppression, and are easily implementable in hardware,
but configuring an optimal stack filter remains a
challenge. This dissertation takes on this challenge by
extending stack filters to a new class of nonlinear
adaptive filters called generalized adaptive neural
filters (GANFs). The objective of this work is to
investigate their performance in terms of the mean
absolute error criterion, to evaluate and predict the
generalization of various discriminant functions
employed for GANFs, and to address issues regarding
their applications and implementation. It is shown that
GANFs not only extend the class of stack filters, but
also have better performance in terms of suppressing non-
additive white Gaussian noise.
Several results are drawn from the theoretical and
experimental work: stack filters can be adaptively
configured by neural networks; GANFs encompass a large
class of nonlinear sliding-window filters which include
stack filters; the mean absolute error (MAE) of the
optimal GANF is upper-bounded by that of the optimal
stack filter; a suitable class of discriminant functions
can be determined before a training scheme is executed;
VC dimension (VCdim) theory can be applied to determine
the number of training samples; the algorithm presented
in configuring GANFs is effective and robust.
</ABSTRACT>
</THESIS>
<THESIS>
<NUMBER> 4114 </NUMBER>
<ORDER>   AAGNN85196 </ORDER>
<TITLE>   EXPLANATION-AIDED DIAGNOSIS: COMBINING CASE-BASED AND MODEL-BASED REASONING FOR THE DIAGNOSIS OF COMPLEX DEVICES </TITLE>
<AUTHOR>   FERET, MICHAEL PIERRE </AUTHOR>
<YEAR>   1993 </YEAR>
<INSTITUTION>   QUEEN'S UNIVERSITY AT KINGSTON (CANADA); 0283 </INSTITUTION>
<DESCRIPTORS>   COMPUTER SCIENCE </DESCRIPTORS>
<ADVISER>   JANICE I. GLASGOW </ADVISER>
<CLASSIFICATIONS>   NIL </CLASSIFICATIONS>
<ABSTRACT>
This thesis presents a novel approach to model-based
diagnosis. This approach, called Explanation-Aided
diagnosis, addresses the two problems--computational
complexity and partially incorrect device models--that
have prevented model-based diagnostic techniques from
being more widely used. A formal model is defined that
combines deduction for ruling-out hypotheses, abduction
to generate hypotheses, and induction to recall past
experiences and account for potential errors in the
device models. The main idea is to use the model of the
device and the results of diagnostic tests to index and
match cases representing past diagnostic situations.
These cases are used to help the diagnostic process for
later situations. A general architecture for the model
is presented, followed by a description of the initial
diagnostic methodology used while applying this
methodology to two real-world devices. The incorporation
of a case-based reasoning system, as a means for
induction, is then described in detail. Experimental
results show the effectiveness of both the indexing
schema and the matching algorithm. The thesis also
discusses how and why these results can be generalized
to a multiple fault situation, to other types of device
models and to other applications in the field of
artificial intelligence.
</ABSTRACT>
</THESIS>
<THESIS>
<NUMBER> 4115 </NUMBER>
<ORDER>   AAG9415973 </ORDER>
<TITLE>   CASE-BASED COGNITIVE MODELING: A STUDENT MODELING METHODOLOGY FOR AN INTELLIGENT TUTORING SYSTEM </TITLE>
<AUTHOR>   KIM, JOONG HAN </AUTHOR>
<YEAR>   1993 </YEAR>
<INSTITUTION>   THE UNIVERSITY OF NEBRASKA - LINCOLN; 0138 </INSTITUTION>
<DESCRIPTORS>   EDUCATION, TECHNOLOGY; BUSINESS ADMINISTRATION, MANAGEMENT; ARTIFICIAL INTELLIGENCE; EDUCATION, BUSINESS </DESCRIPTORS>
<ADVISER>   SANG M. LEE </ADVISER>
<CLASSIFICATIONS>   COGNITIVE MODELING </CLASSIFICATIONS>
<ABSTRACT>
In contrast with conventional computer-aided instruction
(CAI) systems, intelligent tutoring systems (ITS) can
provide adaptive instruction for individual students by
diagnosing the student's current understanding during a
tutoring session and fitting the instruction according
to the student model. The student modeling task can be
considered a design problem which involves a process for
constructing and manipulating a data structure
representing the student's current understanding of the
domain knowledge being delivered.
Focusing on the student diagnosis component, this
dissertation investigates whether or not the case-based
reasoning (CBR) technique can be utilized to improve the
effectiveness and efficiency of diagnosis ability for an
intelligent tutoring system.
Case-based diagnosis (CBD), unlike prevailing rule-based
reasoning approaches, does not require a complete
library of every possible faulty behavior at the
beginning. Instead, highlighting experience as the
central feature of diagnostic expertise, CBD starts with
a minimal set of unsatisfactory situations and increases
its diagnostic capability by adapting the prior cases
(experiences) to new situations. This study explores
case-based student diagnosis issues, such as choices of
indexes to be used for organizing prior cases, methods
for choosing the most relevant cases, and general
formulations of adaptation heuristics used to modify
previous cases to fit the new case.
For this study, a cognitive diagnosis system, called
Case-Based Cognitive Modeling (CBCM) system, has been
implemented in Common LISP. The system has been
experimentally evaluated by applying to the goal
programming model formulation task. It has been found
that once the system trained with enough number of
cases, the system's diagnosing performance is comparable
to that of human tutors.
</ABSTRACT>
</THESIS>
<THESIS>
<NUMBER> 4116 </NUMBER>
<ORDER>   AAG1355874 </ORDER>
<TITLE>   LEARNING TO PLAY GAMES FROM EXPERIENCE: AN APPLICATION OF ARTIFICIAL NEURAL NETWORKS AND TEMPORAL DIFFERENCE LEARNING </TITLE>
<AUTHOR>   OLSON, DANIEL KENNETH </AUTHOR>
<YEAR>   1993 </YEAR>
<INSTITUTION>   PACIFIC LUTHERAN UNIVERSITY; 6200 </INSTITUTION>
<DESCRIPTORS>   COMPUTER SCIENCE; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER>   RICHARD SPILLMAN </ADVISER>
<CLASSIFICATIONS>   NIL </CLASSIFICATIONS>
<ABSTRACT>
Computer programs exist for playing many sorts of games,
often at and beyond expert human levels. Still, most are
static in nature, unable to learn from their mistakes.
In this thesis, the beginnings of a somewhat general
learning architecture (i.e. algorithms and guidelines)
are pieced together from ideas developed in the fields
of game theory and artificial neural networks. By
including Richard Sutton's Temporal Difference (TD)
method, the resulting architecture is essentially a game
tree search algorithm with an adaptive static evaluator
that improves its performance through playing experience
alone. The architecture is explored by building programs
which learn to play three different games--Maze Mapping,
Blackjack, and Tic-Tac-Toe. In each instance, decent
playing ability is achieved. In addition, a number of
fundamental issues are investigated including a problem
known as state space exploration.
</ABSTRACT>
</THESIS>
<THESIS>
<NUMBER> 4117 </NUMBER>
<ORDER>   AAG1355568 </ORDER>
<TITLE>   BICMOS IMPLEMENTATION OF AN ARTIFICIAL NEURAL NETWORK A/D CONVERTER </TITLE>
<AUTHOR>   CHEN, CHIEN-CHANG </AUTHOR>
<YEAR>   1993 </YEAR>
<INSTITUTION>   TEXAS A&M UNIVERSITY-KINGSVILLE; 1187 </INSTITUTION>
<DESCRIPTORS>   ENGINEERING, ELECTRONICS AND ELECTRICAL; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER>   TIAN-SHEN TANG </ADVISER>
<CLASSIFICATIONS>   NIL </CLASSIFICATIONS>
<ABSTRACT>
The main objective of this thesis is to study
possibility of implementing an Artificial Neural Network
(ANN) A to D converter with Bipolar--CMOS (BiCMOS)
technique. The ANN structure of this 4-bit continuously
output A/D converter was proposed in Available (1) and
implemented with discrete resistors and operational
amplifiers (OP-AMP's). This simple structure can be
easily extended to an n-bit A/D converter. The increase
in the number of OPAMP's needed makes this circuit
impractical to be physically implemented. In this paper,
we propose two BiCMOS circuits to replace the OPAMP's.
These BiCMOS circuits not only reduce the number of
devices so that the designs are suitable for VLSI
implementation, but also improve the converter's speed
performance, as indicated by Spice simulation. Some
design issues are also discussed in this thesis.
</ABSTRACT>
</THESIS>
<THESIS>
<NUMBER> 4118 </NUMBER>
<ORDER>   AAG1355565 </ORDER>
<TITLE>   NEURAL NETWORKS: THE MODELING OF A DISTILLATION COLUMN </TITLE>
<AUTHOR>   AMIRPOUR, MARY LEE </AUTHOR>
<YEAR>   1993 </YEAR>
<INSTITUTION>   TEXAS A&M UNIVERSITY-KINGSVILLE; 1187 </INSTITUTION>
<DESCRIPTORS>   ENGINEERING, CHEMICAL; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER>   WILLIAM HEENAN </ADVISER>
<CLASSIFICATIONS>   NIL </CLASSIFICATIONS>
<ABSTRACT>
Traditional methods for problem solving in chemical
engineering have needed time and a basic understanding
of the process. NeuroShell, an artificial neural network
program, allows the engineer to model a unit which could
be tedious and difficult without explaining the dynamics
or the mathematical foundation of the process. In this
thesis, NeuroShell was used in an attempt to simulate an
ethane-ethylene distillation column based on first
principles. It was also used in an attempt to discover
the robustness of the model in which noisy data was used
for its training. One can conclude, that NeuroShell
models a distillation column well and the introduction
of noise does not adversely affect the convergence of
the network.
</ABSTRACT>
</THESIS>
<THESIS>
<NUMBER> 4119 </NUMBER>
<ORDER>   AAGMM84809 </ORDER>
<TITLE>   AN ANALYSIS AND SYNTHESIS OF GENETIC ALGORITHMS AND GENETIC INVARIANCE </TITLE>
<AUTHOR>   DEPAEPE-BEALS, SANDRA LISA ANN </AUTHOR>
<YEAR>   1993 </YEAR>
<INSTITUTION>   UNIVERSITY OF GUELPH (CANADA); 0081 </INSTITUTION>
<DESCRIPTORS>   COMPUTER SCIENCE; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER>   DEBORAH A. STACEY </ADVISER>
<CLASSIFICATIONS>   NIL </CLASSIFICATIONS>
<ABSTRACT>
This thesis presents a comparison of genetic algorithms
(GA's), genetic invariant algorithms (GI's) and a
combination of the two (CA's). It also analyzes the
performance of the CA for various convergence levels
with different GA:GI ratios.
The experimental GA incorporated cross-over, mutation
and reproduction. The GI included specialized cross-over
(using a population ranked by each gene's fitness value)
and reproduction. The objective function for both
algorithms achieved the same purpose.
Comparing the three algorithms according to convergence
requirements, the CA appeared to outperform the GA and
GI. Furthermore, the CA's performance indicated that
superior results might continue at higher convergence
requirements. When comparing the mixtures of GA to GI,
for the CA, optimal performance appeared to occur when
each individual algorithm provided 50% of the overall
required convergence.
</ABSTRACT>
</THESIS>
<THESIS>
<NUMBER> 4120 </NUMBER>
<ORDER>   AAGMM84796 </ORDER>
<TITLE>   A DEDUCTIVE DATABASE FOR HANDLING UNCERTAINTY IN THE FIELDS OF MEDICAL DIAGNOSIS AND HIGH LEVEL VLSI SYNTHESIS </TITLE>
<AUTHOR>   MUKHERJEE, SANJOY KUMAR </AUTHOR>
<YEAR>   1993 </YEAR>
<INSTITUTION>   UNIVERSITY OF GUELPH (CANADA); 0081 </INSTITUTION>
<DESCRIPTORS>   COMPUTER SCIENCE; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER>   MARY DEUTSCH-MCLEISH </ADVISER>
<CLASSIFICATIONS>   NIL </CLASSIFICATIONS>
<ABSTRACT>
An expert system has been developed that diagnoses the
disease of a patient of pediatric age group with
convulsion. This expert system has been transformed and
integrated with a deductive database which can handle
uncertain information. The entire system has been
encoded in Prolog to provide a rich query interface to
it. In order to provide a uniform query interface to the
deductive database, a fuzzy SQL-like (a subset of SQL)
query interface to the system was developed. The scheme
adopted provides a framework for combining different
uncertainty management mechanisms to suit any particular
application. This query interface to the database can be
used to identify correlations among different symptoms
and/or clinical or investigational findings among groups
of patients which may suggest possible new rules.
The ideas of fuzzy deductive databases have also been
applied to the domain of high level vlsi synthesis. The
fuzzy SQL interface developed, can be used to query the
database of uncertain schedules in the dataflow graph,
which can be used to arrive at an estimate of the number
of functional units required to carry out all the
operations. This information can be made use of by the
main software performing scheduling, allocation and
binding.
</ABSTRACT>
</THESIS>
<THESIS>
<NUMBER> 4121 </NUMBER>
<ORDER>   AAGMM84625 </ORDER>
<TITLE>   A FORMAL METHOD FOR PARTIALLY TOLERATING INCOMPLETENESS IN SPECIFICATIONS: A PROPOSAL </TITLE>
<AUTHOR>   KOURKOPOULOS, DIMITRIOS </AUTHOR>
<YEAR>   1993 </YEAR>
<INSTITUTION>   CONCORDIA UNIVERSITY (CANADA); 0228 </INSTITUTION>
<DESCRIPTORS>   COMPUTER SCIENCE </DESCRIPTORS>
<ADVISER>   V. S. ALAGAR </ADVISER>
<CLASSIFICATIONS>   NIL </CLASSIFICATIONS>
<ABSTRACT>
Completeness is usually listed as a desirable attribute
of specifications; incompleteness, as a reason for the
failure of software to satisfy its intended
requirements. Unfortunately, these terms are rarely
given anything but intuitive definitions, making it
unclear how to achieve the former or, alternatively,
avoid the latter. This thesis begins by examining
various notions of (in)completeness in specifications,
and introduces a pragmatic definition of incompleteness:
a classification based on its potential sources. From
this, it observes that completeness, though needed to
properly reason about, and capture the behaviour of, the
system, is undesirable in some cases. To reconcile these
conflicting needs, this thesis proposes a novel formal
method for (partially) tolerating incompleteness in
specifications.
The method focuses on one of the classes. A connection
is drawn between this class and a group of related
problems involved in reasoning about time and action in
artificial intelligence: the qualification, frame, and
ramification problems. Both endeavors must contend with
incomplete information. Since the techniques employed to
deal with these problems usually involve non-monotonic
logics, a number of such logics are considered, but most
rejected. Shoham's logic of chronological ignorance,
however, shows promise. Its shortcomings are addressed,
and an extension of it defined. This serves as the
formal basis for the specification language KAT, which
is intended for real-time, concurrent systems. The
thesis concludes with a description of the language, a
discussion of pragmatic issues, including how it permits
fairly easy modification of specifications, and a
specification of a telephone system demonstrating its
use.
</ABSTRACT>
</THESIS>
<THESIS>
<NUMBER> 4122 </NUMBER>
<ORDER>   AAGMM84522 </ORDER>
<TITLE>   CLOSING THE DOOR ON SEARLE'S CHINESE ROOM </TITLE>
<AUTHOR>   SCHULT, DAVID GREGORY </AUTHOR>
<YEAR>   1993 </YEAR>
<INSTITUTION>   UNIVERSITY OF WATERLOO (CANADA); 1141 </INSTITUTION>
<DESCRIPTORS>   PHILOSOPHY; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER>   JIM VAN EVRA </ADVISER>
<CLASSIFICATIONS>   JOHN SEARLE </CLASSIFICATIONS>
<ABSTRACT>
This thesis reviews John Searle's Chinese Room thought
experiment and his attempt to 'prove' the premise that
"instantiating a computer program is never by
itself a sufficient conditions of intentionality"
(Searle, 1980, 417). At first glance, the Chinese Room
thought experiment appears intuitively correct; however,
sufficient tampering casts doubt on the strength of his
claim. Searle's thought experiment is not as counter-
intuitive as he would like us to believe, but is
actually nonetheless acceptable, albeit in an odd sort
of way. Thought experiments by Leibnitz and David Cole
will be important and altered to show that Searle
commits the same fallacy of composition as Leibnitz.
Although Searle's argument from 'the Chinese Room'
eventually fails, it would be erroneous to conclude from
that, that the functionalist version of strong AI is
correct.
</ABSTRACT>
</THESIS>
<THESIS>
<NUMBER> 4123 </NUMBER>
<ORDER>   AAGMM84108 </ORDER>
<TITLE>   DISC: A FRAMEWORK FOR COORDINATION IN A DISTRIBUTED ARTIFICIAL INTELLIGENCE SYSTEM </TITLE>
<AUTHOR>   LI, XIAO-DONG </AUTHOR>
<YEAR>   1993 </YEAR>
<INSTITUTION>   CARLETON UNIVERSITY (CANADA); 0040 </INSTITUTION>
<DESCRIPTORS>   ENGINEERING, SYSTEM SCIENCE </DESCRIPTORS>
<ADVISER>   NIL </ADVISER>
<CLASSIFICATIONS>   NIL </CLASSIFICATIONS>
<ABSTRACT>
This thesis presents a new approach to the design of a
distributed artificial intelligence (DAI) system for
efficient coordination and communication in complicated
problem scenarios. In this approach the coordinator
paradigm was incorporated into a DAI system to provide
an interaction mechanism for coordinating agents in
distributed problem solving. A framework, named DISC,
was implemented in a local area network to experiment
with such an approach, and to provide a vehicle which
allows different DAI systems to be modeled. This
framework has been used to build a demonstration
distributed diagnostic system for diagnosing multiple
faults in a simplified communication network.
Simulations indicate that this system is capable of
correlating multiple, simultaneous faults and suggesting
the likely fault sources when the evidence of faults are
uncertain.
</ABSTRACT>
</THESIS>
<THESIS>
<NUMBER> 4124 </NUMBER>
<ORDER>   AAGC347748 </ORDER>
<TITLE>   CONCEPTUAL MODELLING OF PHYSICAL SYSTEMS </TITLE>
<AUTHOR>   TOP, JAN LUBERTUS </AUTHOR>
<YEAR>   1993 </YEAR>
<INSTITUTION>   UNIVERSITEIT TWENTE (THE NETHERLANDS); 0237 </INSTITUTION>
<DESCRIPTORS>   COMPUTER SCIENCE </DESCRIPTORS>
<ADVISER>   NIL </ADVISER>
<CLASSIFICATIONS>   ARTIFICIAL INTELLIGENCE </CLASSIFICATIONS>
<ABSTRACT>
The aim of this thesis is to advance automated modelling
of physical systems in order to reduce the engineering
bottleneck in the development of technical systems. Our
work integrates and extends ideas and methods from both
Artificial Intelligence (AI) and conventional
engineering.
We postulate that modelling is a form of design. The
task can be decomposed into, specification of
assumptions, construction of model structure and
assessment of the model in terms of explicit
assumptions. It is in particular the central role of the
specification task that puts our approach in contrast
with other approaches in AI. The proposed generic task
description of modelling is extended to physical systems
engineering. We define four ontological viewpoints:
functional components, physical processes, mathematical
relations and model data. This provides a structural
framework for organizing libraries of reusable physical
models, e.g. for design. The fact that we build on well
established methods from engineering further
distinguishes our work from the typical AI approach. Our
method is implemented in a knowledge based system called
QuBA, which can be viewed as a demonstrator for
automated modelling of physical systems.
The second issue is causality. We show that there is no
real conceptual difference between a number of
approaches in AI and engineering: they merely reflect
different aspects of a general, common (but naive)
notion of causality. We assert that bond graphs provide
a proper representation of physical causality, and
extend the existing causal analysis techniques in a
number of ways. We show that switching essentially
entails changing causality: causal directions change due
to the changing system structure, giving rise to
discontinuous behaviour. We define an ideal physical
switching element and its control structure. This solves
a number of problems that were inherent to conventional
ways of handling abrupt changes in an otherwise
continuous world.
</ABSTRACT>
</THESIS>
<THESIS>
<NUMBER> 4125 </NUMBER>
<ORDER>   AAGC347366 </ORDER>
<TITLE>   THE ART OF ANALYSIS: LOGIC AND HISTORY OF PROBLEM- SOLVING </TITLE>
<AUTHOR>   MAENPAA, PETRI HEIKKI MIKAEL </AUTHOR>
<YEAR>   1993 </YEAR>
<INSTITUTION>   TEKNILLINEN KORKEAKOULU (HELSINKI) (FINLAND); 5766 </INSTITUTION>
<DESCRIPTORS>   PHILOSOPHY HELSINKI, P.O. BOX 24, SF-00014 HELSINKI, FINLAND </DESCRIPTORS>
<ADVISER>   NIL </ADVISER>
<CLASSIFICATIONS>   NIL </CLASSIFICATIONS>
<ABSTRACT>
This study develops a general method of problem-solving
on the basis of the analytic method conceived by ancient
Greek geometers. Their method of solving a geometric
problem was to analyse a figure, seeking to uncover the
functional interdependencies of its constituents. This
determined the sought constructions in terms of the
given ones. Around 1600, Viete and Descartes generalized
the Greek method into the algebraic method of analysis
that pervades modern exact sciences. However, their
reduction of geometry to algebra did not preserve
geometric content. This study generalizes Greek
geometric analysis into a general analytic method of
problem-solving that preserves mathematical content. To
this end, it uses a logical language, the constructive
type theory developed by Martin-Lof since the 1970's.
Constructive type theory lets one express the analysis
and synthesis of constructions of any type naturally as
functional decomposition and composition. Kolmogorov
suggested developing a logic for problem solving in
1932, but no-one seems to have taken up the task.
Predicate logic has proved unsatisfactory for solving
programming problems. Its forms of expression do not
suffice for a logic of problem solving, because it
cannot express the composition and decomposition of
constructions naturally.
Programming requires generalizing the Greek method to
inductively defined problems. The generalized method
conceived in this study should systematize problem
solving, particularly in programming, in a heuristically
useful way. It is applied also to geometric, algebraic,
and logical problems.
The systematic part of this study finishes by explaining
Lakatos' theory of mathematical discovery in terms of
the general method of problem solving devised here.
Then, the theory developed in the systematic part serves
as a means of understanding several outstanding
historical instances of analytic problem-solving. The
objects of investigation include the ancient Greeks'
application of analysis to geometry, arithmetic and
astronomy; Pappus' methodological account of analysis;
Viete's and Descartes' generalization of their method;
Newton's extension of their method from geometric to
empirical configurations; program construction by top-
down methods; and the method of goal reduction in
artificial intelligence. Applied to programming in
particular, the method serves to construct programs from
their specifications hand-in-hand with their correctness
proofs.
</ABSTRACT>
</THESIS>
<THESIS>
<NUMBER> 4126 </NUMBER>
<ORDER>   AAGC346278 </ORDER>
<TITLE>   A KNOWLEDGE-BASED COMPUTATIONAL APPROACH TO ARCHITECTURAL PRECEDENT ANALYSIS </TITLE>
<AUTHOR>   FANG, NAN </AUTHOR>
<YEAR>   1993 </YEAR>
<INSTITUTION>   TECHNISCHE UNIVERSITEIT TE DELFT (THE NETHERLANDS); 0951 </INSTITUTION>
<DESCRIPTORS>   ARCHITECTURE THE NETHERLANDS </DESCRIPTORS>
<ADVISER>   NIL </ADVISER>
<CLASSIFICATIONS>   NIL </CLASSIFICATIONS>
<ABSTRACT>
The dissertation is generally concerned with the
question: How can precedent knowledge be used in
architectural design computation? Specifically, it
presents an approach to the use of precedent knowledge
through investigation of the computational theory of
ARPRAN (ARchitectural PRecedent ANalyst), an intelligent
system capable of analyzing plans of architectural
precedents in order to represent their characteristics
of spatial organization and to provide useful
information for generating new designs.
The investigation is focused on three basic issues
concerning the general structure of ARPRAN: (1) the
domain problem it deals with, (2) its computation task,
and (3) its knowledge representation system. These
issues are investigated through the study of a real
architectural design case and the reconstruction of the
precedent analysis process observed from the case study.
The case selected for study is the design of the
"new courtyard house" in Beijing's old city,
in which the major problem was to generate a new
dwelling prototype to replace the decaying traditional
courtyard houses. In this case, the new design was
required to keep the historical continuity of urban
structure while to comply with contemporary living
standards; and this design task was fulfilled
successfully by the designer through his adequately
analyzing and representing several architectural
precedents.
ARPRAN is intended to reconstruct the precedent analysis
process emerging out of the case study; and the
reconstruction is based on several machine learning
paradigms founded in Artificial Intelligence (AI) and
some cognitive theories regarding spatial
representation. Based on a case study, the dissertation
has suggested several prominent directions in
architectural design computation research.
</ABSTRACT>
</THESIS>
<THESIS>
<NUMBER> 4127 </NUMBER>
<ORDER>   AAGC343385 </ORDER>
<TITLE>   MODULAR REASONING: A NEW APPROACH TOWARDS INTELLIGENT CONTROL </TITLE>
<AUTHOR>   KOCH, GION GEORG </AUTHOR>
<YEAR>   1993 </YEAR>
<INSTITUTION>   EIDGENOSSISCHE TECHNISCHE HOCHSCHULE ZUERICH (SWITZERLAND); 0663 </INSTITUTION>
<DESCRIPTORS>   COMPUTER SCIENCE CH-8092 ZURICH, SWITZERLAND </DESCRIPTORS>
<ADVISER>   NIL </ADVISER>
<CLASSIFICATIONS>   ARTIFICIAL INTELLIGENCE </CLASSIFICATIONS>
<ABSTRACT>
This work focuses on the automation of technical
systems, where normal operation is not attended by a
human operator. Most small and mid-sized supply
facilities fall into this category. Heating, ventilation
and air-conditioning (HVAC) plants are taken as examples
to examine the problems of complex highly-automated
unattended technical systems. A main shortcoming of
today's commercial automation systems is their lack of
understanding about the purpose, functionality and
mechanism of the technical system and its environment.
Without knowing the intentions of the technical system,
the automation system cannot decide whether the observed
behavior of the technical system corresponds with its
intended one. Consequently, at least with HVAC-plants,
often faults, defects and mistakes that an expert human
operator supervising the plant would notice are not
detected by the automation system during operation.
Thus, the question treated in this work is: how can the
designer's and the expert operator's qualitative
knowledge, understanding, and reasoning about the
technical system be automated?
Some of the main characteristics of human reasoning
about technical systems are identified from different
studies presented in the literature. The results of
these studies indicate the importance of so-called
"mental models" for the part of human
performance that takes place on a higher conceptual
level (such as conscious reasoning, especially in
unfamiliar situations). The research area which deals
with a computer-adequate realization of human reasoning
about technical systems is a subfield of artificial
intelligence, known as "Qualitative Physics"
or "Qualitative Reasoning". A short summary of
the original paradigms that initiated research in this
area is given and includes a report on the state of the
art. None of these original paradigms is suited to
represent all the characteristics of human reasoning
identified.
A new approach is presented which extends and combines
these paradigms. This so-called "modular reasoning
approach" is based on the ideas of object-oriented
programming and is explained by an analogy to the
engineer's use of block-diagrams. The approach leads to
the definition of "reasoning modules" which
divide a reasoning task into sub-tasks. This is
illustrated by some elements of a prototype which was
built to extend the commercial process management system
of a scale model of a heating and ventilation plant.
Based on the same knowledge representation, different
reasoning modules were implemented to perform the
acquisition of process information, monitoring, fault
detection and the coordination of active diagnostic
tests.
</ABSTRACT>
</THESIS>
<THESIS>
<NUMBER> 4128 </NUMBER>
<ORDER>   AAG9415863 </ORDER>
<TITLE>   SOCIETAL SIMULATION: AN ARTIFICIAL INTELLIGENCE APPROACH </TITLE>
<AUTHOR>   HUGHES, LUCIAN PARKE </AUTHOR>
<YEAR>   1993 </YEAR>
<INSTITUTION>   YALE UNIVERSITY; 0265 </INSTITUTION>
<DESCRIPTORS>   COMPUTER SCIENCE; ANTHROPOLOGY, PHYSICAL; SOCIOLOGY, GENERAL; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER>   NIL </ADVISER>
<CLASSIFICATIONS>   GLOBAL MODELING, CHIMPANZEES </CLASSIFICATIONS>
<ABSTRACT>
The physical sciences have come across complex systems
for which global behaviors are difficult to model by
traditional mathematical means. For example, it has been
difficult to find global equations by which to model
turbulence, or predict the weather. Increasingly,
scientists have turned to computer-based simulations
that model the local rules of behavior of individual
elements of the systems. Global phenomena emerge from
these local interactions. For example, for turbulence
each individual air molecule is modeled and the overall
turbulence pattern emerges from their simple local
interactions.
Clearly, social systems are at least as complex. And
similarly social scientists have found it difficult to
discover global equations for social systems. And while
some social scientists have taken the opposite tack of
writing essays--not equations!--that reveal the local
complexity of social systems, these efforts fall short
in precision. A computational societal simulator offers
an opportunity for formal precision while still
embracing the complexity of social agents and the
relations and rituals that bind them.
This thesis describes the construction and use of such a
simulator: ChimpWorld. ChimpWorld is a general
architecture for societal simulation that has been
applied to a particular domain: chimpanzee societies.
The individual elements of the system are independent
yet socially-linked AI-based agents--in this case
chimpanzees. Their socially guided actions and
motivations create dynamic societies.
Thus, ChimpWorld is a "wind tunnel for the social
and organizational sciences": it allows different
social organizations, individuals, and physical
environments to be dynamically tested so that the
results can be compared to real societies. Via such
comparisons scientists can build, test, and refine their
societal and organizational theories. Hence, this thesis
is intended for social scientists interested in a new
technology and what has been learned from it about
social agents and societies, as well as for cognitive
scientists and AI researchers interested in the nature
of social minds.
</ABSTRACT>
</THESIS>
<THESIS>
<NUMBER> 4129 </NUMBER>
<ORDER>   AAG9415462 </ORDER>
<TITLE>   ADIS: AN ARTIFICIAL INTELLIGENCE/DATABASE INTEGRATED SYSTEM </TITLE>
<AUTHOR>   WU, JIANG </AUTHOR>
<YEAR>   1993 </YEAR>
<INSTITUTION>   ILLINOIS INSTITUTE OF TECHNOLOGY; 0091 </INSTITUTION>
<DESCRIPTORS>   COMPUTER SCIENCE </DESCRIPTORS>
<ADVISER>   MARTHA EVENS; ROBERT CARLSON </ADVISER>
<CLASSIFICATIONS>   DATABASES, QUERY SYSTEMS </CLASSIFICATIONS>
<ABSTRACT>
The primary goal of the Artificial Intelligence/Database
Integrated System (ADIS) project is to propose a
comprehensive database design and query system, which
adopts an object-oriented approach and can be used by
different levels of users, that supports a more general
data model in terms of the classes of data objects, and
built-in intelligence in terms of the design/query
process, to supply a "point and click"
solution to most database problems. The ADIS project
includes three subprojects: VDD, DB-EXPERT, and SUPER-
QUERY.
VDD is the user interface used for both database designs
and queries by database designers and end-users. The
current version of VDD maps its underlying Universal
Data Object Model (UDM) to a normalized relational
model. It supports homogeneous/heterogeneous data
objects; simple/complex data objects; named/indexed/set
identifications; and number definitions. It maintains a
VDD-Object-Hierarchy Tree to keep track of different VDD
object definitions, and keeps track of the information
needed to connect the tree with its corresponding
database definitions.
DB-EXPERT is designed for database schema definition to
solve Data Definition problems. DB-EXPERT accepts
multiple user views of the database in the form of FD
information and implements the Bernstein Algorithm to
maintain a 3rd normal form. It re-accepts the users'
view definition and checks the supportability of the
views. It generates SQL DDL statements and saves them
into named files for different uses. It generates the
appropriate SQL ALTER TABLE statements whenever the user
modifies the database.
SUPER-QUERY is designed to solve Data Manipulation
problems. SUPER-QUERY has an inference engine that
implements the Multi-Star Search Algorithm and the
Maximal Object Search Algorithm for formulating database
queries against a database system that may contain the
Split-Key Join Problem. The database user selects an
arbitrary number of attributes and arbitrary selection
criteria in the whole database, then SUPER-QUERY is
responsible for finding all valid paths and generating
corresponding SQL DML statements to produce the query.
The ADIS project makes conceptual, theoretical, and
engineering contributions to database design/query
systems. Various algorithms and rules have been worked
out, such as the Multi-Star Search Algorithm; the
Maximal Object Search Algorithm; the Iterative
Broadening Search Algorithm; and the key deducing rules
for VDD.
</ABSTRACT>
</THESIS>
<THESIS>
<NUMBER> 4130 </NUMBER>
<ORDER>   AAG9415445 </ORDER>
<TITLE>   APPLICATION OF FUZZY SETS TO POWER SYSTEMS OPERATION AND PLANNING </TITLE>
<AUTHOR>   ABDUL-RAHMAN, KHALED HUSNI </AUTHOR>
<YEAR>   1993 </YEAR>
<INSTITUTION>   ILLINOIS INSTITUTE OF TECHNOLOGY; 0091 </INSTITUTION>
<DESCRIPTORS>   ENGINEERING, ELECTRONICS AND ELECTRICAL; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER>   S. M. SHAHIDEHPOUR </ADVISER>
<CLASSIFICATIONS>   DANTZIG WOLFE DECOMPOSITION, BENDERS DECOMPOSITION </CLASSIFICATIONS>
<ABSTRACT>
A fuzzy linear programming (LP) approach to optimal
power flow (OPF) is formulated for power systems
operation and planning. The fuzzy LP formulation is
based on Dantzig-Wolfe decomposition (operation problem)
and Benders decomposition (allocation problem). In
addition, system security is considered as a conflicting
objective in the fuzzy set formulation to ensure an
adequate supply of electric energy as economically as
possible with a reasonable level of quality and
continuity. In optimizing the real power generation with
uncertain load representation, the mitigation of
electromagnetic field in the proximity of residential
areas and the reduction of emission from power plants
are considered as additional objectives. In this study,
the ability of fuzzy sets to discriminate between
different values of variables within a given range is
utilized to model the conflicting objectives such as
minimum operation cost, minimum emission requirements
and maximum static security levels. The fuzzy set
approach to optimal power planning indicates that the
fuzzy modeling of system variables enables power system
operators to operate the system more efficiently in an
uncertain environment. The artificial intelligence (AI)
approach to real-time operation is also considered in
which the uncertainty in defining load limits are
treated by fuzzy sets. Different categories of loads are
defined, and artificial neural networks are trained to
apply the pattern matching scheme for identifying the
closest solution. To assure the feasibility of the
solution, an expert system is used to adjust control
variables accordingly. Numerical results have indicated
that the proposed AI approach is a viable option for the
real-time control of reactive power flow in a large
power system.
</ABSTRACT>
</THESIS>
<THESIS>
<NUMBER> 4131 </NUMBER>
<ORDER>   AAG9415083 </ORDER>
<TITLE>   MODEL PREDICTIVE CONTROL BASED ON NONLINEAR AUTOREGRESSIVE AND NEURAL NETWORK MODELS </TITLE>
<AUTHOR>   PROLL, THOMAS </AUTHOR>
<YEAR>   1993 </YEAR>
<INSTITUTION>   COLORADO STATE UNIVERSITY; 0053 </INSTITUTION>
<DESCRIPTORS>   ENGINEERING, CHEMICAL; ENGINEERING, ELECTRONICS AND ELECTRICAL; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER>   NIL </ADVISER>
<CLASSIFICATIONS>   NIL </CLASSIFICATIONS>
<ABSTRACT>
This research was dedicated to investigating the
feasibility of using nonlinear autoregressive with
exogenous inputs (NARX) models and artificial neural
networks (ANN) for the identification and the closed-
loop control of chemical processes. Within this
research, the existing theory of NARX models was
extended by incorporating measured disturbance terms to
the model structure thereby increasing the flexibility
and applicability of NARX models for a wide range of
processes. For selecting parsimonious submodels, the
modified Gram-Schmidt orthogonalization procedure was
adapted. The concept of a pointer vector was introduced.
With this concept it is possible to fully automate the
identification and closed-loop control algorithm.
For the closed-loop control, an adaptive model
predictive control (MPC) approach was selected,
resulting in a novel solution to the nonlinear
programming problem. Since the extended NARX model is
linear in the parameters, a recursive constant trace
identification algorithm could be applied to adapt the
model to possible time-variations of the process which
guarantees offset-free set point tracking.
As a comparative study, the application in the
aforementioned context of a special case of artificial
neural networks, feedforward neural networks (FNN), was
investigated. The feasibility of applying different FNN
topologies within a MPC algorithm was discussed
(multiple predictions with one network or repeated
networks with one-step-ahead predictions). Since FNN
models can not be adapted on-line the estimated
plant/model mismatch was used to correct the model
predictions used for the MPC portion. The modified
Marquardt algorithm for solving the nonlinear
programming problem can be applied without changes.
For the verification of the proposed nonlinear
identification and control structures, the model of a
MIMO bioreactor and a model as well as an experimental
set-up of a waste water neutralization process were
available.
By numerous identification experiments it was shown that
the extended NARX model is very suitable for
approximating nonlinear process dynamics and suggested a
better performance than the FNN model. The closed-loop
control results are more comparable and show only slight
advantages of the NARX model based MPC approach compared
to the slightly different MPC structure used for the FNN
based approach.
</ABSTRACT>
</THESIS>
<THESIS>
<NUMBER> 4132 </NUMBER>
<ORDER>   AAG9414975 </ORDER>
<TITLE>   A NOVEL TECHNIQUE FOR PROVIDING A HIGHLY EFFECTIVE ARRANGEMENT OF MULTIAPERTURE VISION SYSTEM EYELETS FOR A PARTICULAR TASK </TITLE>
<AUTHOR>   WILLIAMS, ROY ELMORE, JR. </AUTHOR>
<YEAR>   1993 </YEAR>
<INSTITUTION>   MEMPHIS STATE UNIVERSITY; 0124 </INSTITUTION>
<DESCRIPTORS>   ENGINEERING, ELECTRONICS AND ELECTRICAL; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER>   CARL E. HALFORD </ADVISER>
<CLASSIFICATIONS>   NEURAL NETWORKS </CLASSIFICATIONS>
<ABSTRACT>
The optical engineer is very competent in the design of
vision systems based on the human visual system--that of
a single optical aperture with multiple detectors. The
design of artificial multiaperture vision systems, based
on the insect's visual system, with many optical
apertures coupled to very few detectors, is still in its
infancy. The objective of this dissertation effort was
to develop a technique which allows the optical design
engineer to position multiaperture eyelets in an imaging
system to most effectively address a certain imaging
task.
The eyelet placement technique developed in this study
addresses target location and target tracking imaging
applications. It is inspired by the evolution of the
insect and, therefore, is based on genetic algorithms.
Genetic algorithms, founded in biological genetic
progression, are used to effectively search the
multiaperture eyelet placement solution space. Three
genetic algorithm operators are used: crossover,
inversion, and mutation. Probabilistic neural networks
are used to process the multiaperture eyelet information
and provide the evaluation criteria required for the
genetic algorithm. A user friendly interface is provided
allowing the engineer to select target field-of-view
(FOV), create target distributions and provide genetic
algorithm parameters.
The technique is effectively demonstrated by applying it
to target location and target tracking tasks. For the
target location task, seventy-three experiments, ranging
from small, simple FOVs to large, complex FOVs, are
performed. Several practical FOV geometries are
implemented varying from square to rectangular to
triangular illustrating the adaptability of the
technique. Various realistic target distributions are
implemented in the user-defined FOV including random
uniform distributions, Gaussian distributions and
combinations of the two. For the target tracking task,
eighteen experiments, including both horizontal
traveling tracks and diagonal traveling tracks, are
implemented. For each target tracking task, simple
rectangular FOVs and two target speeds are considered.
In every target location and target tracking experiment,
it is shown that the eyelet placement technique is
always better in a statistical sense than manual or
intuitive eyelet placement.
</ABSTRACT>
</THESIS>
<THESIS>
<NUMBER> 4133 </NUMBER>
<ORDER>   AAG9414853 </ORDER>
<TITLE>   TECHNIQUES FOR IMPROVING THE EFFICIENCY OF HEURISTIC SEARCH </TITLE>
<AUTHOR>   DILLENBURG, JOHN FRED </AUTHOR>
<YEAR>   1993 </YEAR>
<INSTITUTION>   UNIVERSITY OF ILLINOIS AT CHICAGO; 0799 </INSTITUTION>
<DESCRIPTORS>   COMPUTER SCIENCE; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER>   PETER C. NELSON </ADVISER>
<CLASSIFICATIONS>   AGENDA DATA STRUCTURES, ISLAND SEARCH, CYCLE CHECKING, PERIMETER SEARCH </CLASSIFICATIONS>
<ABSTRACT>
Four techniques are presented which improve the
efficiency of heuristic search algorithms: agenda data
structures, island search, cycle checking and perimeter
search. Both theoretical and experimental results are
presented which show how these techniques improve the
time complexity of heuristic search for certain
problems.
The first step towards improving the efficiency of a
heuristic search algorithm is to use the fastest
possible data structure for storing unexplored nodes in
the search space. Several candidate data structures are
reviewed and a new type of data structure is presented
which is both space and time efficient.
Islands are shown to be a generalization of subgoals.
Two new algorithm are presented which make use of
islands to improve search efficiency. Test results are
presented which compare the performance of the island
search algorithms to the performance of A$sp*.$ The test
results cover two problem domains, a grid search problem
and a route planning problem. Island search is shown to
be superior for these problems when island information
is available.
A technique for improving the efficiency of depth-first
search on graphs is presented. This technique is
referred to as cycle checking since it prevents the
generation of duplicate nodes caused by cycles in the
search space. Two types of cycle checking are compared
and test results are presented for the grid search and
route planning problems. Simple guidelines are presented
showing which type of cycle checking to use on a given
problem.
Perimeter search can be viewed as a new type of
bidirectional search. Unlike other bidirectional search
algorithms, perimeter search avoids the pitfalls
involved in trying to perform two simultaneous searches.
Analytical and experimental results are presented to
show how the perimeter search technique improves the
time complexity of A$sp*$ and IDA$sp*$ on two types of
problems. Also presented are near-optimal and parallel
versions of the perimeter search algorithms.
</ABSTRACT>
</THESIS>
<THESIS>
<NUMBER> 4134 </NUMBER>
<ORDER>   AAG9414755 </ORDER>
<TITLE>   A GAME-LEARNING MACHINE </TITLE>
<AUTHOR>   GHERRITY, MICHAEL </AUTHOR>
<YEAR>   1993 </YEAR>
<INSTITUTION>   UNIVERSITY OF CALIFORNIA, SAN DIEGO; 0033 </INSTITUTION>
<DESCRIPTORS>   COMPUTER SCIENCE; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER>   PAUL R. KUBE </ADVISER>
<CLASSIFICATIONS>   CHESS, NEURAL NETWORKS, MACHINE LEARNING </CLASSIFICATIONS>
<ABSTRACT>
This dissertation describes a program which learns good
strategies for two-person, deterministic, zero-sum board
games of perfect information. The program learns by
simply playing the game against either a human or
computer opponent. The results of the program's learning
the games of tic-tac-toe, connect-four, and chess are
reported.
The program consists of a game-independent kernel and a
game-specific move generator module. Only the move
generator is modified to reflect the rules of the game
to be played. The kernel remains unchanged for different
games. The kernal uses a temporal difference procedure
combined with a backpropagation neural network to learn
good evaluation functions for the game being played.
Central to the performance of the program is the
consistency search procedure. This is a game-independent
generalization of the capture tree search used in most
successful chess playing programs. It is based on the
idea of using search to correct errors in evaluations of
positions. This procedure is described, analyzed,
tested, and implemented in the game-learning program.
Both the test results and the performance of the program
confirm the results of the analysis which indicate that
consistency search improves game playing performance for
sufficiently accurate evaluation functions.
</ABSTRACT>
</THESIS>
<THESIS>
<NUMBER> 4135 </NUMBER>
<ORDER>   AAG9414393 </ORDER>
<TITLE>   A VIRTUAL REALITY BASED POINT-AND-DIRECT TELEROBOTIC SURFACE FLAW INSPECTION SYSTEM USING A NEURAL NETWORK </TITLE>
<AUTHOR>   WANG, GUANG-SHIAH COLLIN </AUTHOR>
<YEAR>   1993 </YEAR>
<INSTITUTION>   THE PENNSYLVANIA STATE UNIVERSITY; 0176 </INSTITUTION>
<DESCRIPTORS>   COMPUTER SCIENCE; ENGINEERING, ELECTRONICS AND ELECTRICAL; ENGINEERING, INDUSTRIAL; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER>   DAVID J. CANNON </ADVISER>
<CLASSIFICATIONS>   NIL </CLASSIFICATIONS>
<ABSTRACT>
This dissertation explores a point-and-direct flexible
inspection paradigm featuring a generic concept using
the skeleton transform to produce sub-skeletons whose
pixel counts are inputs to a neural network for
workpiece surface flaw identification. This approach
involves both material handling and vision processing
components, both of which were made more flexible by
this work.
The virtual reality based PAD telerobotic system allows
manufacturers to quickly set up new tasks without
allotting time and resources to special fixturing and
tight structuring of the environment. Toward this
objective, a human-machine interface has been
successfully demonstrated for interweaving virtual
reality (graphic) tools with live video scenes to direct
robot activities using an instrumented glove. A virtual
(graphic) robot gripper was configured and graphically
interjected into a live videographic cyberspace
controlled by the operator to quickly determine
locations for robot picking and placement tasks.
Since a human operator using the PAD concept directs a
telerobot to place a workpiece in a desired location
(position and orientation) for inspection, the
inspection method using skeleton pixel counts as neural
network inputs was developed to be invariant with regard
to workpiece position and orientation. From skeletons
produced using our own slightly improved disk shaped
structuring elements, and classifications made using
neural network training that we have incorporated,
workpiece skeletons are recognized independent of
position and orientation constraints. Computer memory
requirements for storing image characteristics are
trivial in this approach because a workpiece is
represented as a simple array of pixel counts per
skeleton iteration rather than as a whole image to be
painstakingly correlated. The sub-skeleton pixel counts,
corresponding to the quantity of pixels for each sub-
skeleton iteration, provides inputs to a supervised
neural network that is trained to use these pixel counts
to recognize both unflawed and randomly flawed
workpieces.
The combined virtual reality based point-and-direct
flexible inspection system, including material handling
and image interpretation, gives all the components
necessary to accomplish flexible placement and
inspection of workpieces in manufacturing.
</ABSTRACT>
</THESIS>
<THESIS>
<NUMBER> 4136 </NUMBER>
<ORDER>   AAG9414388 </ORDER>
<TITLE>   STUDY OF THE GRAY SCALE, POLYCHROMATIC, DISTORTION INVARIANT NEURAL NETWORKS USING THE IPA MODEL </TITLE>
<AUTHOR>   UANG, CHII-MAW </AUTHOR>
<YEAR>   1993 </YEAR>
<INSTITUTION>   THE PENNSYLVANIA STATE UNIVERSITY; 0176 </INSTITUTION>
<DESCRIPTORS>   ENGINEERING, ELECTRONICS AND ELECTRICAL; COMPUTER SCIENCE; PHYSICS, OPTICS; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER>   FRANCIS T. S. YU </ADVISER>
<CLASSIFICATIONS>   NIL </CLASSIFICATIONS>
<ABSTRACT>
Research in the optical neural network field is
primarily motivated by the fact that humans recognize
objects better than the conventional digital computers
and the massively parallel inherent nature of optics.
This research represents a continuous effort during the
past several years in the exploitation of using
neurocomputing for pattern recognition. Based on the
interpattern association (IPA) model and Hamming net
model, many new systems and applications are introduced.
A gray level discrete associative memory that is based
on object decomposition/composition is proposed for
recognizing gray-level patterns. This technique extends
the processing ability from the binary mode to gray-
level mode, and thus the information capacity is
increased.
Two polychromatic optical neural networks using color
liquid crystal television (LCTV) panels for color
pattern recognition are introduced. By introducing a
color encoding technique in conjunction with the
interpattern associative algorithm, a color associative
memory was realized. Based on the color decomposition
and composition technique, a color exemplar-based
Hamming net was built for color image classification.
A shift-invariant neural network is presented through
use of the translation invariant property of the modulus
of the Fourier transformation and the hetero-associative
interpattern association (IPA) memory. To extract the
main features, a quadrantal sampling method is used to
sampled data and then replace the training patterns.
Using the concept of hetero-associative memory to recall
the distorted object.
A shift and rotation invariant neural network using an
interpattern hetero-association (IHA) model is
presented. To preserve the shift and rotation invariant
properties, a set of binarized-encoded circular harmonic
expansion (CHE) functions at the Fourier domain is used
as the training set. We use the shift and symmetric
properties of the modulus of the Fourier spectrum to
avoid the problem of centering the CHE functions.
Almost all neural networks have the positive and
negative weights, which increases the difficulty of
optical implementation. A method to construct a unipolar
IPA IWM is discussed. By searching the redundant
interconnection links, an effective way that removes all
negative links is discussed.
</ABSTRACT>
</THESIS>
<THESIS>
<NUMBER> 4137 </NUMBER>
<ORDER>   AAG9414306 </ORDER>
<TITLE>   NEURAL NETWORK-BASED DECISION SUPPORT FOR INCOMPLETE DATABASES </TITLE>
<AUTHOR>   JIN, BO </AUTHOR>
<YEAR>   1993 </YEAR>
<INSTITUTION>   THE PENNSYLVANIA STATE UNIVERSITY; 0176 </INSTITUTION>
<DESCRIPTORS>   COMPUTER SCIENCE; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER>   A. R. HURSON; S. PAKZAD </ADVISER>
<CLASSIFICATIONS>   FUZZY LOGIC </CLASSIFICATIONS>
<ABSTRACT>
The idea of applying neural network techniques to
handling large databases containing incomplete
information is presented. In an incomplete relational
database model, maybe algebra operations are introduced
to provide the user the opportunity to investigate the
potential set of data values in order to draw his/her
own conclusions. While such a set of operations allows a
better information utilization, it can be the source of
problems which should be taken into consideration. In a
large database system, the data generated by maybe
algebra operations can be enormous in size, erroneous in
semantics, and less informative. To allow the maybe
algebra operations to be practical, it is desired to
develop a mechanism to increase the quality and
integrity of the results, i.e., to filter out the
erroneous and less informative data.
A neural network-based decision support system is
proposed to improve database performance in the presence
of missing/incomplete information, provide intelligent
assistance to the end-user, and explore the learning
capability of a neural network-based system. The
proposed system has a strong learning capability and
adjusts itself according to the specific characteristics
of the underlying database and the user special
requirements. To support the automated training pair
generation, the fuzzy logic technique is incorporated
into the knowledge acquisition module to oversee, guide,
and update the quality status of each training pattern.
By approximate reasoning, the fuzzy controller works in
a fashion that automatically incorporates the intrinsic
ambiguities, imprecision, and undecidabilities
associated with the quality status of each training
pattern. Issues of enhancing the functionality of the
decision support system are studied with a concentration
on data representation for the decision-making network
and multi-network configurations.
</ABSTRACT>
</THESIS>
<THESIS>
<NUMBER> 4138 </NUMBER>
<ORDER>   AAG9414259 </ORDER>
<TITLE>   PROCESS DESIGN, DIAGNOSTICS, AND CONTROL IN MANUFACTURING THROUGH FUZZY LOGIC AND NEURAL NETWORKS </TITLE>
<AUTHOR>   CHEN, YU-TO </AUTHOR>
<YEAR>   1993 </YEAR>
<INSTITUTION>   THE PENNSYLVANIA STATE UNIVERSITY; 0176 </INSTITUTION>
<DESCRIPTORS>   ENGINEERING, INDUSTRIAL; ENGINEERING, MECHANICAL; COMPUTER SCIENCE; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER>   SOUNDAR R. T. KUMARA </ADVISER>
<CLASSIFICATIONS>   NIL </CLASSIFICATIONS>
<ABSTRACT>
To produce quality products for the purpose of coping
with the global manufacturing competition, it is
essential to automate the design practice, diagnose
faults, and control the process. In this study, a
generic scheme to establish the norms for automation of
design, diagnostics, and control by employing fuzzy
logic and neural networks for continuous processes is
proposed. First, design of a grinding process is
accomplished by initial determination of a set of
optimal design variables in order to achieve a set of
desired process variables. Next, process diagnostics is
identified as a pattern matching task so that it can be
processed by neural networks/fuzzy systems to match
sensor readings of system parameters to a pre-defined
abnormal scenario. The research results are applied to
the real life example of the TMI-2 nuclear reactor.
Then, a hierarchical control structure is proposed for a
turning process. By utilizing the adaptation/learning
ability of both fuzzy logic and neural nets, the control
algorithm automatically tunes PID (Proportional-Integral-
Derivative) gains for the SISO (Single-Input-Single-Out)
turning system. That is, the control action is carried
out through the manipulation of the feedrate in order to
maintain the cutting force at a reference point.
Moreover, a generic scheme has been proposed to serve as
the first step towards full integration of neuro-fuzzy
systems; not only fuzzy inference has been applied to
speed up the learning process of neural nets, but also
the advantage of the learning ability of neural nets has
been taken to fine tune the fuzzy decision table.
Performance evaluation and comparison between neural
networks and fuzzy logic theories are analyzed so that
conclusions can be drawn about pros and cons between
neural and fuzzy systems. In short, the main
contribution of this study is to explore the potential
usefulness and fitness of fuzzy logic and neural
networks in the domain of manufacturing. In addition,
the analytical tools developed in this study are
generalizable for construction of other larger scale,
complex systems. The applicability and validity of this
study will be demonstrated via the simulation of
designing a surface grinding model, of diagnosing the
TMI-2 nuclear reactor, and of controlling an
experimental turning model, respectively.
</ABSTRACT>
</THESIS>
<THESIS>
<NUMBER> 4139 </NUMBER>
<ORDER>   AAG9414093 </ORDER>
<TITLE>   EXPERT SYSTEM SHELLS IN CHEMISTRY: CHIRULE - A CHIRAL CHROMATOGRAPHIC COLUMN SELECTION SYSTEM USING SIMILARITY SEARCHING AND PERSONAL CONSTRUCT THEORY. </TITLE>
<AUTHOR>   STAUFFER, SCOTT TIMOTHY </AUTHOR>
<YEAR>   1993 </YEAR>
<INSTITUTION>   VIRGINIA POLYTECHNIC INSTITUTE AND STATE UNIVERSITY; 0247 </INSTITUTION>
<DESCRIPTORS>   CHEMISTRY, ANALYTICAL; COMPUTER SCIENCE; CHEMISTRY, PHARMACEUTICAL; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER>   RAYMOND E. DESSY </ADVISER>
<CLASSIFICATIONS>   VOLUMES I AND II </CLASSIFICATIONS>
<ABSTRACT>
The current process of selecting a column to perform a
chiral separation can be characterized as more of an art
than a science. This dissertation describes CHIRULE, a
"chromatographic assistant" to aid in
developing chiral separations.
CHIRULE constructs an n-dimensional information space
from a large number of known chiral separations by
fragmenting the molecules at their chiral center,
producing four molecular fragments. Molecular properties
are calculated for each of these fragments. The
properties are the axes used to place known separations
into the information space.
To suggest a column, the target molecule is added to the
information space. Similarity property searching is used
to select all known separations similar to the target
molecule. The chemistry-based expert system shell CHESS
used to develop CHIRULE also includes features such as
functional group recognition and automated knowledge
extraction techniques based on Personal Construct
Theory.
The results suggest that fragment property values are a
route to enhanced understanding and improved selection
of chiral separation methods.
</ABSTRACT>
</THESIS>
<THESIS>
<NUMBER> 4140 </NUMBER>
<ORDER>   AAG9414077 </ORDER>
<TITLE>   INCORPORATING CONCURRENT ENGINEERING AND DESIGN ECONOMICS IN A DECISION SUPPORT SYSTEM </TITLE>
<AUTHOR>   LEE, PUI MUN </AUTHOR>
<YEAR>   1993 </YEAR>
<INSTITUTION>   VIRGINIA POLYTECHNIC INSTITUTE AND STATE UNIVERSITY; 0247 </INSTITUTION>
<DESCRIPTORS>   ENGINEERING, INDUSTRIAL; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER>   WILLIAM G. SULLIVAN </ADVISER>
<CLASSIFICATIONS>   NIL </CLASSIFICATIONS>
<ABSTRACT>
Concurrent engineering is a philosophy for improving
design communication and aiding the process of
recognizing and resolving design conflicts. Design
economics is an integrated part of the concurrent
engineering process, since cost-effective product design
is at the root of many design conflicts. However, the
bulk of research on concurrent engineering focuses on
deriving better methods for coordinating both product
and process designs with respect to functionality and
manufacturability issues. The issue of implementing
design economics via the concurrent engineering process
at the conceptual design stage has not been adequately
addressed.
This research explores the development of a structural
framework for incorporating concurrent engineering and
design economics into a prototype decision support
system that supports the conceptual phase of the product
design process. The dissertation has three major tasks:
(1) To formulate a concurrent engineering framework for
use during the conceptual design stage, (2) To develop
an activity-based cost estimation model for estimating
product cost at the conceptual level of product design,
and (3) To integrate and demonstrate the concurrent
engineering framework and the activity-based cost
estimation model together in a prototype decision
support system.
To accomplish the objective of this research,
electronics manufacturing is used as an application
setting. The design of printed circuit board assemblies
is the domain for establishing a structural framework
for incorporating concurrent engineering and activity-
based cost estimation.
</ABSTRACT>
</THESIS>
<THESIS>
<NUMBER> 4141 </NUMBER>
<ORDER>   AAG9413900 </ORDER>
<TITLE>   DIAGNOSTIC REASONING AND PLANNING IN EXPLORATORY- CORRECTIVE DOMAINS </TITLE>
<AUTHOR>   RYMON, RON </AUTHOR>
<YEAR>   1993 </YEAR>
<INSTITUTION>   UNIVERSITY OF PENNSYLVANIA; 0175 </INSTITUTION>
<DESCRIPTORS>   COMPUTER SCIENCE; HEALTH SCIENCES, MEDICINE AND SURGERY; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER>   BONNIE L. WEBBER </ADVISER>
<CLASSIFICATIONS>   NIL </CLASSIFICATIONS>
<ABSTRACT>
I have developed a methodology for knowledge
representation and reasoning for agents working in
exploratory-corrective domains. Working within the field
of Artificial Intelligence in Medicine, I used the
specific problem of diagnosis-and-repair in multiple
trauma management as both motivation and testbed for my
work.
A reasoning architecture is proposed in which
specialized diagnostic reasoning and planning components
are integrated in a cycle of reasoning and
action/perception: (1) A Goal-Directed Diagnostic (GDD)
reasoner which is predicated on the view that diagnosis
is only worthwhile to the extent that it can affect
repair decisions and that goals can be used to focus on
such. Rather than focusing on a diagnosis object as the
primary purpose of the diagnostic process, the GDD
reasoner is tasked primarily with generating goals for
the planner and with reasoning about whether these goals
have been satisfied. (2) A Progressive Horizon Planner
(PHP) which works by constructing intermediate plans via
a combination of plan sketching and
selection/optimization sub-processes, and then adapting
these plans to reflect new information and goals. For
the plan sketching sub-part, I propose a selection-and-
ordering planning/scheduling paradigm, taking advantage
of the limited interaction between goals.
I have implemented this architecture and reasoning
components in TraumAID 2.0--a consultation system for
the trauma management domain. In a blinded comparison,
out of 97 real trauma cases, three trauma surgeons have
judged management plans proposed by TraumAID 2.0
preferable to the actual care by a ratio of 64:17 and to
plans generated by its predecessor TraumAID 1.0 by a
ratio of 62:9.
</ABSTRACT>
</THESIS>
<THESIS>
<NUMBER> 4142 </NUMBER>
<ORDER>   AAG9413894 </ORDER>
<TITLE>   SELECTION AND INFORMATION: A CLASS-BASED APPROACH TO LEXICAL RELATIONSHIPS </TITLE>
<AUTHOR>   RESNIK, PHILIP STUART </AUTHOR>
<YEAR>   1993 </YEAR>
<INSTITUTION>   UNIVERSITY OF PENNSYLVANIA; 0175 </INSTITUTION>
<DESCRIPTORS>   COMPUTER SCIENCE; LANGUAGE, LINGUISTICS; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER>   ARAVIND JOSHI </ADVISER>
<CLASSIFICATIONS>   NATURAL LANGUAGE </CLASSIFICATIONS>
<ABSTRACT>
Selectional constraints are limitations on the
applicability of predicates to arguments. For example,
the statement "The number two is blue" may be
syntactically well formed, but at some level it is
anomalous-- scBLUE is not a predicate that can be
applied to numbers.
In this dissertation, I propose a new, information-
theoretic account of selectional constraints. Unlike
previous approaches, this proposal requires neither the
identification of primitive semantic features nor the
formalization of complex inferences based on world
knowledge. The proposed model assumes instead that
lexical items are organized in a conceptual taxonomy
according to class membership, where classes are defined
simply as sets--that is, extensionally, rather than in
terms of explicit features or properties. Selection is
formalized in terms of a probabilistic relationship
between predicates and concepts: the selectional
behavior of a predicate is modeled as its distributional
effect on the conceptual classes of its arguments,
expressed using the information-theoretic measure of
relative entropy. The use of relative entropy leads to
an illuminating interpretation of what selectional
constraints are: the strength of a predicate's selection
for an argument is identified with the quantity of
information it carries about that argument.
In addition to arguing that the model is empirically
adequate, I explore its application to two problems. The
first concerns a linguistic question: why some
transitive verbs permit implicit direct objects
("John ate $emptyset$") and others do not
("*John brought $emptyset$"). It has often
been observed informally that the omission of objects is
connected to the ease with which the object can be
inferred. I have made this observation more formal by
positing a relationship between inferability and
selectional constraints, and have confirmed the
connection between selectional constraints and implicit
objects in a set of computational experiments.
Second, I have explored the practical applications of
the model in resolving syntactic ambiguity. A number of
authors have recently begun investigating the use of
corpus-based lexical statistics in automatic parsing;
the results of computational experiments using the
present model suggest that often lexical relationships
are better viewed in terms of underlying conceptual
relationships such as selectional preference and concept
similarity. Thus the information-theoretic measures
proposed here can serve not only as components in a
theory of selectional constraints, but also as tools for
practical natural language processing.
</ABSTRACT>
</THESIS>
<THESIS>
<NUMBER> 4143 </NUMBER>
<ORDER>   AAG9413822 </ORDER>
<TITLE>   UNDERSTANDING NATURAL LANGUAGE INSTRUCTIONS: A COMPUTATIONAL APPROACH TO PURPOSE CLAUSES </TITLE>
<AUTHOR>   DI EUGENIO, BARBARA </AUTHOR>
<YEAR>   1993 </YEAR>
<INSTITUTION>   UNIVERSITY OF PENNSYLVANIA; 0175 </INSTITUTION>
<DESCRIPTORS>   COMPUTER SCIENCE; LANGUAGE, LINGUISTICS; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER>   BONNIE LYNN WEBBER </ADVISER>
<CLASSIFICATIONS>   NIL </CLASSIFICATIONS>
<ABSTRACT>
Human agents are extremely flexible in dealing with
Natural Language instructions. I argue that most
instructions don't exactly mirror the agent's knowledge,
but are understood by accommodating them in the context
of the general plan the agent is considering; the
accommodation process is guided by the goal(s) that the
agent is trying to achieve. Therefore a NL system which
interprets instructions must be able to recognize and/or
hypothesize goals; it must make use of a flexible
knowledge representation system, able to support the
specialized inferences necessary to deal with input
action descriptions that do not exactly match the stored
knowledge.
The data that support my claim are Purpose Clauses
(PCs), infinitival constructions as in $Do alpha to do
beta$, and Negative Imperatives. I present a pragmatic
analysis of both PCs and Negative Imperatives.
Furthermore, I analyze the computational consequences of
PCs, in terms of the relations between actions PCs
express, and of the inferences an agent has to perform
to understand PCs.
I propose an action representation formalism that
provides the required flexibility. It has two
components. The Terminological Box (TBox) encodes
linguistic knowledge about actions, and is expressed by
means of the hybrid system CLASSIC. To guarantee that
the primitives of the representation are linguistically
motivated, I derive them from Jackendoff's work on
Conceptual Structures. The Action Library encodes
planning knowledge about actions. The action terms used
in the plans are those defined in the TBox.
Finally, I present an algorithm that implements
inferences necessary to understand $Do alpha to do
beta$, and supported by the formalism I propose. In
particular, I show how the TBox classifier is used to
infer whether $alpha$ can be assumed to match one of the
substeps in the plan for $beta$, and how expectations
necessary for the match to hold are computed.
</ABSTRACT>
</THESIS>
<THESIS>
<NUMBER> 4144 </NUMBER>
<ORDER>   AAG9413609 </ORDER>
<TITLE>   A MECHANIZED FRAMEWORK FOR SPECIFYING PROBLEM DOMAINS AND VERIFYING PLANS </TITLE>
<AUTHOR>   SUBRAMANIAN, SAKTHIKUMAR </AUTHOR>
<YEAR>   1993 </YEAR>
<INSTITUTION>   THE UNIVERSITY OF TEXAS AT AUSTIN; 0227 </INSTITUTION>
<DESCRIPTORS>   COMPUTER SCIENCE </DESCRIPTORS>
<ADVISER>   ROBERT S. BOYER </ADVISER>
<CLASSIFICATIONS>   BOYER MOORE LOGIC </CLASSIFICATIONS>
<ABSTRACT>
This dissertation presents a framework for modeling
problem domains in the Boyer-Moore logic so that we can
verify mechanically solutions to various problems using
the Boyer-Moore theorem prover. A problem domain is
given by a set of states of the physical world and a set
of actions that can be executed sequentially to change
state. A problem is given by an initial condition and a
goal condition. A solution is a plan that when executed
in a state satisfying the initial condition will bring
about a goal state. We are mainly interested in
verifying plans that involve conditional and repetitive
actions for solving problems in domains such as the
blocks world. Such domains arise in both artificial
intelligence and software engineering.
Our main contribution is a method of specifying problem
domains in the Boyer-Moore logic for verifying plans
interactively. We illustrate our method by verifying
plans for solving problems in some variations of the
blocks world. We show how solutions to problems in a
class of domains can be verified using the n x n
mutilated checkerboard problem. Our method of specifying
domains does not suffer from many of the limitations of
current approaches such as the need for stating
explicitly a large number of separate frame axioms and
state constraints necessary for reasoning about actions
with side-effects. Our formalization also allows us to
express many other properties of plans such as
efficiency requirements. Because both specifications and
plans are executable, we can prove properties about them
in logic as well as test them on concrete data.
Our method can also be used to obtain a formalization
that would enable a program to verify plans depending on
changes to domain specifications received as input at
various times. Non-monotonic formalisms have generally
been used for this purpose but have proven difficult to
implement. We illustrate our approach by mechanizing
reasoning about actions described in the language ${cal
A}$.
</ABSTRACT>
</THESIS>
<THESIS>
<NUMBER> 4145 </NUMBER>
<ORDER>   AAG9413458 </ORDER>
<TITLE>   NEURAL INFORMATION PROCESSING APPROACH TO IMPROVEMENTS OF PRODUCTIVITY AND ACCURACY OF CNC TURNING PROCESS </TITLE>
<AUTHOR>   CHANG, WEI-REN </AUTHOR>
<YEAR>   1993 </YEAR>
<INSTITUTION>   THE UNIVERSITY OF TEXAS AT AUSTIN; 0227 </INSTITUTION>
<DESCRIPTORS>   ENGINEERING, MECHANICAL; COMPUTER SCIENCE; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER>   BENITO FERNANDEZ-RODRIGUEZ; MICHAEL D. BRYANT </ADVISER>
<CLASSIFICATIONS>   NIL </CLASSIFICATIONS>
<ABSTRACT>
This research uses a neural information processing
approach to improve the machining precision of the
computer numerical control (CNC) turning process. One of
the main problems that affects the manufacturing
accuracy of the turning process is workpiece deflection
during cutting. It is shown in this dissertation that
the inaccuracy caused by the workpiece flexibility can
be solved in a unified way.
Artificial neural networks, which are known for the
capability of good function approximation through
learning, are utilized as the main tool. The
"actual" workpiece diameters are used as the
inputs to a neural network, and the
"commanded" diameters are used as desired
network outputs. The "inverse" relationship is
learned by a network governed by a supervised learning
rule. After training, the "desired" diameters
of a new workpiece are input to the trained network, the
network then predicts the "corrective
commanded" diameters to be used as CNC commands.
The corrective commands drive the cutting in a way that
the workpiece deflection is compensated.
An analytical-numerical solution was developed for
simulating the lathe cutting. The change of the
workpiece shape during cutting was considered and the
workpiece deflection was calculated. The workpiece
diameters produced by the original and the corrective
commands were compared. The corrected pieces have better
accuracy. Static and dynamic neural networks were used
in the simulations and the results are compared. Dynamic
networks generated better corrective commands.
Experiments were performed on a CNC lathe to produce a
batch of parts. Single-pass cutting was used for making
the parts. The diameters of these parts were measured.
Neural networks were used in training and generating
compensated commands. The parts produced by using one-
pass corrective cutting have much better dimensional
accuracy in the dimensions than the one using
uncorrected one-pass cutting. The maximum error in the
diameter was reduced to one third (or less) of the
original value. The production rate of the turning
process is increased by reducing the number of passes
for cutting. In conclusion, both the results from
simulations and experiments showed satisfactory
improvements of machining accuracy using the proposed
innovative approach.
</ABSTRACT>
</THESIS>
<THESIS>
<NUMBER> 4146 </NUMBER>
<ORDER>   AAG9413343 </ORDER>
<TITLE>   TEMPORAL CONNECTIONIST EXPERT SYSTEMS USING A TEMPORAL BACKPROPAGATION ALGORITHM </TITLE>
<AUTHOR>   CIVELEK, FERDA NUR </AUTHOR>
<YEAR>   1993 </YEAR>
<INSTITUTION>   UNIVERSITY OF NORTH TEXAS; 0158 </INSTITUTION>
<DESCRIPTORS>   COMPUTER SCIENCE; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER>   KATHLEEN M. SWIGGER </ADVISER>
<CLASSIFICATIONS>   NIL </CLASSIFICATIONS>
<ABSTRACT>
A temporal feedforward neural network model that can be
applied to a number of neural network application areas
has been introduced. Also, a temporal backpropagation
algorithm which supports this model has been developed.
The algorithm was tested using a medical connectionist
expert system. The system, first, was trained using a
pattern that was encoded from the expert system
knowledge base rules. A series of experiments then were
carried out using the temporal model and the temporal
backpropagation algorithm.
The first series of experiments were done to determine
if the training process worked as predicted. In the
second series of experiments, the weight matrix in the
trained system was defined as a function of time
intervals before presenting the system with the learned
patterns. The result of the two experiments indicate
that both approaches produce correct results. The only
difference between the two results was that compressing
the weight matrix required more training epochs to
produce correct results. To get a measure of the
correctness of the results, an error measure which is
the value of the error squared was summed over all
patterns to get a total sum of squares.
The temporal connectionist model introduced in this
research provides the user with greater flexibility to
represent time in the neural networks. The model along
with the temporal backpropagation algorithm makes it
extremely practical to define any artificial neural
network application.
</ABSTRACT>
</THESIS>
<THESIS>
<NUMBER> 4147 </NUMBER>
<ORDER>   AAG9413295 </ORDER>
<TITLE>   NEURAL NETWORK PROCESSING OF LINGUISTIC SYMBOLS USING MULTI-LEVEL GRADING RULE </TITLE>
<AUTHOR>   PARK, JONG JOON </AUTHOR>
<YEAR>   1993 </YEAR>
<INSTITUTION>   THE FLORIDA STATE UNIVERSITY; 0071 </INSTITUTION>
<DESCRIPTORS>   COMPUTER SCIENCE; BIOLOGY, NEUROSCIENCE; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER>   ABRAHAM KANDEL; L. W. HAWKES </ADVISER>
<CLASSIFICATIONS>   NIL </CLASSIFICATIONS>
<ABSTRACT>
We are used to describing our activities and environment
with words rather than with numbers. Linguistic
Processing (LP) accepts linguistic inputs (such as
"small", "medium", or
"large") and generates linguistic outputs
rather than numeric values. The purpose of linguistic
processing (LP) is to provide the computer with a tool
for processing inexact or imprecise but rational
knowledge to the computer.
The greatest advantage of linguistic processing is that
it allows for small errors in the input to cause only
corresponding small changes in the output. Linguistic
processing can reduce the computation time by setting an
appropriate system error dependent on the number of
levels assigned to the linguistic terms.
In this dissertation we propose a procedure for
imbedding linguistic processing in a neural network and
investigate a method of representing and coding
linguistic terms for processing by a neural network
scheme. We also propose the multi-level grading rule
(MLGR) for the conversion of linguistic symbols into
numeric values. The MLGR method has been applied to two
examples, and their results are given with analyses and
interpretations of the outputs.
We demonstrate that the sigmoidal activation function
can be applied successfully to the linguistic processing
scheme to obtain reasonable outputs. From the results of
the two examples, we find that the system produces
better outputs when there is a smaller effective range
for linguistic terms and a larger percentage of training
data. Among the produced outputs, which were not given
the sample training data, some have extremely reasonable
meanings. The system's output results for the modulo 10
problem show that the system gives a high rate of
correctness (greater than 60%) even though it trained
with a small set of sample data (20%).
</ABSTRACT>
</THESIS>
<THESIS>
<NUMBER> 4148 </NUMBER>
<ORDER>   AAG9413132 </ORDER>
<TITLE>   MODELLING LEARNING TO BECOME AN EXPERT LOGIC CIRCUIT DEBUGGER </TITLE>
<AUTHOR>   WINCHESTER, SALLY JANE </AUTHOR>
<YEAR>   1993 </YEAR>
<INSTITUTION>   THE UNIVERSITY OF CONNECTICUT; 0056 </INSTITUTION>
<DESCRIPTORS>   COMPUTER SCIENCE </DESCRIPTORS>
<ADVISER>   KEITH BARKER </ADVISER>
<CLASSIFICATIONS>   NIL </CLASSIFICATIONS>
<ABSTRACT>
This dissertation explores the process of transforming a
novice into an expert. The domain selected was that of
combinational logic circuit debugging. Extensive studies
of both novice and expert circuit debuggers' behaviors
led to the formation of a computational theory of
acquiring expertise. This theory is rooted in the
Artificial Intelligence technique called case-based
reasoning in which past experiences (cases) are used to
help understand new similar situations.
The theory presented here extends the case-based model
in several ways. First, a theory is presented to account
for the acquisition of an understander's first cases.
Second, a theory of the amount of exposure the
understander must have before past experiences can be
used is proposed. The empirical data collected indicates
that there is a critical threshold which must be reached
before cases are available for use. When this critical
threshold is reached, the novice has been transformed
into an expert with regard to a particular type of
error. Third, two new heuristic search procedures for
locating and identifying errors in circuits are
proposed. These procedures partition the search space
(circuit representations) so that search time is
decreased. Fourth, a preference rating based upon the
success or failure of retrieved cases in locating errors
is proposed. This rating is used to model an learner's
preferences in selecting one past experience over
another as being the most likely to succeed in a given
situation. It also models the process of forgetting as
cases which do not lead to successful debugging
experiences will have increasingly lower preference
ratings as they are tried and fail. The theory presented
here is implemented in the Bayakoa system, a case-based
reasoner which acquires expertise as a logic circuit
debugger.
</ABSTRACT>
</THESIS>
<THESIS>
<NUMBER> 4149 </NUMBER>
<ORDER>   AAG9413041 </ORDER>
<TITLE>   NEURAL NETWORKS FOR CONGESTION CONTROL IN COMMUNICATION NETWORKS </TITLE>
<AUTHOR>   PARK, YOUNG-KEUN </AUTHOR>
<YEAR>   1993 </YEAR>
<INSTITUTION>   UNIVERSITY OF MINNESOTA; 0130 </INSTITUTION>
<DESCRIPTORS>   ENGINEERING, ELECTRONICS AND ELECTRICAL; COMPUTER SCIENCE; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER>   VLADIMIR CHERKASSKY; GYUNGHO LEE </ADVISER>
<CLASSIFICATIONS>   NIL </CLASSIFICATIONS>
<ABSTRACT>
In this thesis, the congestion problems of the switching
networks will be extensively studied. We will propose
the neural network-based various congestion control
schemes and an omega network based ATM switch with
bypass queues.
Telecommunication services are evolving from
conventional telephone to broadband and multimedia
services to meet the diversified needs of users. With
the advent of fiber optics and high-speed network
technology, the communication channel bandwidth is
remarkably increased. While many high-performance
switching fabrics and control algorithms are being
proposed, there are still many important problems to
overcome for implementation of high-performance
switching networks, switch architecture, traffic control
and internetworking with existing networks, etc. Among
those, congestion control is one of the most active
areas of research in high-speed communication networks.
The major goal is to increase the network throughput by
avoiding congestion in an efficient and cost-effective
way.
In spite of the fact that modern digital computers have
made great leaps in both speed and processing power,
there are certain tasks such as solving optimization
problem that may not be performed sufficiently well by
computers due to the complexities associated with
programming a computer to perform the tasks. The 1980's
witnessed a resurgence of interest in neural networks.
This new interest is due to the development of new
network topologies, algorithms, and new analog VLSI
implementations. Neural networks can solve the
optimization problems more easily than conventional
computers. They can be used to solve the congestion
problems in switching networks by optimizing the network
characteristics. A high degree of parallelism and the
hardware level fast congestion control can be achieved
through the use of neural networks. Solving optimization
problems requires minimization of certain cost functions
subject to a set of constraints imposed by the problems.
These cost functions will be represented as energy
functions, and the neural network will produce optimal
solutions by minimizing the energy functions to satisfy
the constraints. The functional behaviors of all of the
proposed neural networks are verified by the software
simulations.
</ABSTRACT>
</THESIS>
<THESIS>
<NUMBER> 4150 </NUMBER>
<ORDER>   AAG9412356 </ORDER>
<TITLE>   A MORPHOLOGICAL APPROACH TO LEARNING </TITLE>
<AUTHOR>   KIM, MICHAEL WOONKYUNG </AUTHOR>
<YEAR>   1993 </YEAR>
<INSTITUTION>   HARVARD UNIVERSITY; 0084 </INSTITUTION>
<DESCRIPTORS>   ENGINEERING, ELECTRONICS AND ELECTRICAL; COMPUTER SCIENCE; MATHEMATICS; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER>   PETROS MARAGOS </ADVISER>
<CLASSIFICATIONS>   CONCEPT SET LEARNING </CLASSIFICATIONS>
<ABSTRACT>
We consider in this thesis a geometrical approach
towards concept set learning. In formulating such a
geometrical approach we utilize tools and results from
Set Theory, and Mathematical Morphology in particular,
to model relevant entities (such as background
knowledge) and operations (such as example-driven
deduction) as sets and set-operations in euclidean
spaces, respectively. The general paradigm we pursue is
one of background knowledge (modelled as a set)
undergoing evolution (modelled as a morphological
transformation) as new information is accumulated.
We make the manipulations and measurements of sets more
analytically tractable by abstracting the sets as the
cross-sections of measurable functions. In contrast to
most known learning methods, we attach a fundamental
emphasis not on the functions themselves but instead on
their cross-sections.
In formulating a useful and generally applicable class
of learning algorithms, we appeal to the familiar
Dynamical System paradigm and propose the employment of
Set Processing Automaton (SPA) as the formalism with
which to study discrete-time evolutions of sets
interpreted as geometrical entities.
One natural application of the SPA is as a rigorous
paradigm for supervised learning. In such context, the
state of knowledge, initially the background (apriori)
knowledge about the concept set to be learned, can be
generally modelled as a set in euclidean space. With the
Bayesian criterion as the model of evolution, the set
representing the background knowledge can be seen to
undergo annihilation/growth-type (Darwinian) of
transformation which can be efficiently formulated as
(simple) morphological operations.
We concentrate in this thesis on a particular network-
SPA, generically called the Smoothing Automaton (SA),
that rigorously model the notion of smoothing. Some
elementary SA's are analyzed to rigorously establish
some desirable and expected duality between learning and
smoothing. In particular, we find that smoothing, is
both a well-formulated learning procedure in the sense
of probably-approximately-correct (pac-) Learnability
Theory, and also a robust procedure with respect to the
choice of hidden parameters. Towards developing some
unified theory of applicability of SA's, we present some
fundamental results that reveal certain algebraic
closure properties obeyed generally by some SA-
approximatable concept sets. Two particular SA's, which
are intrinsically isomorphic to the familiar Nearest-
Neighbor algorithms, are also empirically tested on a
database of handwritten character sets towards
establishing their surprising tolerance with respect to
large dimension size. (Abstract shortened by UMI.)
</ABSTRACT>
</THESIS>
<THESIS>
<NUMBER> 4151 </NUMBER>
<ORDER>   AAG9407452 </ORDER>
<TITLE>   INTELLIGENT CONTROL BASED ON FUZZY ALGORITHMS AND GENETIC ALGORITHMS </TITLE>
<AUTHOR>   HWANG, WEN-RUEY </AUTHOR>
<YEAR>   1993 </YEAR>
<INSTITUTION>   NEW MEXICO STATE UNIVERSITY; 0143 </INSTITUTION>
<DESCRIPTORS>   COMPUTER SCIENCE; ENGINEERING, ELECTRONICS AND ELECTRICAL </DESCRIPTORS>
<ADVISER>   WILEY E. THOMPSON </ADVISER>
<CLASSIFICATIONS>   NIL </CLASSIFICATIONS>
<ABSTRACT>
The design of intelligent control systems has become an
area of intense research interest. The development of an
effective methodology for the design of such control
systems undoubtedly requires the synthesis of many
concepts from artificial intelligence. A promising
direction in the design of intelligent systems involves
the use of fuzzy algorithms and genetic algorithms to
intensify the abilities of intelligent control systems
to learn from experience via rule-based knowledge and to
adapt via genetic evolution. This thesis develops a
methodology for combining fuzzy logic based systems with
genetic algorithms to achieve a significant learning
capability.
Many applications using fuzzy logic algorithms for
industrial process control systems have been
successfully demonstrated in Japan and Europe. These
applications show that fuzzy logic based systems have
the potential for mimicking decision-making ability of a
skilled human operator. Two applications of fuzzy logic
based systems are developed in this dissertation: a
simulation design procedure for fuzzy controllers for
position control systems is presented in chapter 4 and a
five-step design method for fuzzy logic controllers for
nonlinear control problems is presented in chapter 5. A
crucial point is that mathematical models of the plant
and the controller are not required for the design
procedure.
The techniques of genetic algorithms have been proposed
as an alternative means of tuning digital PID
controllers. The application of genetic algorithms as a
means of finding optimal solutions over a parameter
space in the controller design of a control system is
presented in chapter 6. A key point is that the
simulated digital PID controller is designed without any
mathematical model and the proportional feedback is
based upon the error, the integral feedback is based
upon the sum of the errors, and the differential
feedback is based upon the change of the error. Finally,
the application of genetic algorithms to the learning of
the optimal rules of fuzzy logic controllers (FLC) is
presented in chapter 7. Using genetic algorithms as an
unsupervised learning method for designing an FLC
greatly reduces the effort of the traditional method
based on human operators' experience.
</ABSTRACT>
</THESIS>
<THESIS>
<NUMBER> 4152 </NUMBER>
<ORDER>   AAG0574426 </ORDER>
<TITLE>   PLANNING AND SCHEDULING OF SOFTWARE MANUFACTURING PROJECTS </TITLE>
<AUTHOR>   SAFAVI, ALI </AUTHOR>
<YEAR>   1993 </YEAR>
<INSTITUTION>   UNIVERSITY OF SOUTHERN CALIFORNIA; 0208 </INSTITUTION>
<DESCRIPTORS>   COMPUTER SCIENCE </DESCRIPTORS>
<ADVISER>   LES GASSER </ADVISER>
<CLASSIFICATIONS>   NIL </CLASSIFICATIONS>
<ABSTRACT>
In today's highly competitive and constantly growing
market for software products, planning and scheduling of
large software projects has become a bottleneck to
increasing production productivity. This work is to
investigate the mechanisms required to support software
project planning and scheduling (SPPS).
Our approach is to (1) define SPPS as a reactive process
that involves human negotiation, and (2) develop a
heuristic search model, that is consistent with the
negotiation process, to improve an existing schedule by
incrementally revising it.
The main contribution of this thesis is that it
represents the first major effort in building a problem
solving model for SPPS that accommodates the dominant
characteristics of SPPS. Our problem solving model is
based on the previous results in social analysis of
computing, operations research in manufacturing,
artificial intelligence in manufacturing planning and
scheduling, and the traditional approaches to planning
in artificial intelligence, and extends the techniques
that have been developed by them in dealing with SPPS.
We demonstrate the sufficiency of the model that has
been developed on specific test cases that reflect
actual software project planning and scheduling
circumstances. A program called NEGOPRO that uses our
basic model to support SPPS in large software projects
has been implemented. (Copies available exclusively from
Micrographics Department, Doheny Library, USC, Los
Angeles, CA 90089-0182.)
</ABSTRACT>
</THESIS>
<THESIS>
<NUMBER> 4153 </NUMBER>
<ORDER>   AAG9415604 </ORDER>
<TITLE>   A FUZZY NEURAL ARCHITECTURE WITH BINARY AND ANALOG INPUTS FOR SUPERVISED LEARNING THROUGH INFERENCING </TITLE>
<AUTHOR>   HAN, GABSOO </AUTHOR>
<YEAR>   1993 </YEAR>
<INSTITUTION>   FLORIDA INSTITUTE OF TECHNOLOGY; 0473 </INSTITUTION>
<DESCRIPTORS>   EDUCATION, SCIENCES; EDUCATION, TECHNOLOGY; ENGINEERING, ELECTRONICS AND ELECTRICAL; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER>   F. M. HAM </ADVISER>
<CLASSIFICATIONS>   NEURAL NETWORKS, ERROR CORRECTION </CLASSIFICATIONS>
<ABSTRACT>
LAPART (laterally primed adaptive resonance theory), a
neural network architecture for logical inferencing and
supervised learning, has been adapted with match
tracking capability, fuzzy ART modules, and slow
learning. Fuzzy LAPART consists of interconnected fuzzy
adaptive resonance theory (ART) networks, originated by
Carpenter and Grossberg for pattern classification
through unsupervised learning to enhance the network's
capability for analog inputs. The interconnections
enable fuzzy LAPART to infer one pattern class from
another to form a predictive pattern class. Slow
learning with fast-commit and slow-recode options have
been incorporated. For efficient coding of noisy input
sets, it is useful to use fast commitment and slow
recoding training capability. Fuzzy LAPART also realizes
a minimax learning rule that conjointly minimizes
predictive error and maximizes code compression, or
generalization. This is achieved by a match tracking
process that increases the ART vigilance parameter by
the minimum amount needed to correct a predictive error.
Also, several geometric interpretations are presented in
two and three dimensional spaces. Fuzzy LAPART offers
the ability to form input and output objects through
generalization on specific examples.
Comparing with ART2, and counterpropagation, which are
popular clustering networks, fuzzy LAPART shows
outstanding performance in benchmark tests with
comparably more efficient ability of clustering.
Separation of spirals is used to perform benchmark tests
with four different neural networks. Another application
is the determination of primitive polynomials, or the
linear shift register tap locations that generates a
known length sequence which is maximal, given the binary
sequence as the input to the classifier. Fuzzy LAPART is
used to classify primitive polynomial coefficients,
given only the pseudo-random binary sequence in the
presence of Gaussian and correlated white noise.
</ABSTRACT>
</THESIS>
<THESIS>
<NUMBER> 4154 </NUMBER>
<ORDER>   AAG9415167 </ORDER>
<TITLE>   AN APPLICATION OF EXPECTANCY THEORY TO EXAMINE MOTIVATION TO USE AN EXPERT SYSTEM IN A BANK LOAN DECISION CONTEXT: AN ARTIFICIAL NEURAL NETWORK MODEL APPROACH </TITLE>
<AUTHOR>   LEE, YONGJIN </AUTHOR>
<YEAR>   1993 </YEAR>
<INSTITUTION>   MISSISSIPPI STATE UNIVERSITY; 0132 </INSTITUTION>
<DESCRIPTORS>   BUSINESS ADMINISTRATION, MANAGEMENT; COMPUTER SCIENCE; ARTIFICIAL INTELLIGENCE; BUSINESS ADMINISTRATION, BANKING </DESCRIPTORS>
<ADVISER>   KIRK P. ARNETT </ADVISER>
<CLASSIFICATIONS>   NIL </CLASSIFICATIONS>
<ABSTRACT>
Historically, the end-users' acceptance of the expert
systems (ES) have generally been used as a proxy for the
ES' implementation success by both practitioners and
academicians. However, with regard to bank loan
decisions, most loan officers approach the acquisition
of an ES with apprehension.
In order to overcome this skepticism, more research
should focus on the behavioral aspects related to
systems acquisition and usage. This research applied
Vroom's (1964) expectancy theory in an effort to predict
end-users' motivation to use an ES in a bank loan
decision context.
Because human behaviors and judgements are nonlinear
rather than linear functions, accurately predicting
human behavior is very difficult. To increase the
prediction power for end-users' motivation to use an ES
in a bank loan decision context, this research used an
artificial neural network (ANN) model.
Because many managers are reluctant to provide the
needed cooperation in experimental settings, research
conducted in behavioral accounting and Management
Information System (MIS) have heavily relied on students
acting as surrogates for industry managers. In this
research, an attempt was made to evaluate adequacy of
the surrogates by analyzing differences between real
bank loan officers and student surrogates in applying
expectancy theory to estimate bank loan officers'
motivation to use ES in a bank loan decision context.
</ABSTRACT>
</THESIS>
<THESIS>
<NUMBER> 4155 </NUMBER>
<ORDER>   AAG9413526 </ORDER>
<TITLE>   INTELLIGENT ELECTRONIC MARKETS FOR COMMODITY AUCTION: AN INTEGRATED APPROACH OF ECONOMIC THEORY AND SOCIAL CHOICE THEORY </TITLE>
<AUTHOR>   LEE, HO GEUN </AUTHOR>
<YEAR>   1993 </YEAR>
<INSTITUTION>   THE UNIVERSITY OF TEXAS AT AUSTIN; 0227 </INSTITUTION>
<DESCRIPTORS>   BUSINESS ADMINISTRATION, MANAGEMENT; COMPUTER SCIENCE; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER>   RONALD M. LEE; ELEANOR W. JORDAN </ADVISER>
<CLASSIFICATIONS>   NIL </CLASSIFICATIONS>
<ABSTRACT>
Commodity exchanges provide potential market structures
for electronic trading because commodity products like
cotton and grain have simple and well standardized
product descriptions. Existing electronic market systems
execute commodity trades through bilateral matching of
one buy order against another sell order on a first-come
first-serve basis. Intelligent electronic markets are
proposed which allow multilateral matching of buy and
sell orders, rather than bilateral matching, in order to
optimize realization of buying and selling intentions of
market participants. Intelligent electronic markets
accumulate buy and sell orders over time and match those
aggregated orders in a way that (1) not only maximizes
total exchanged volume within bid and ask prices (2) but
also satisfies the qualitative preferences of buyers and
sellers.
This research combines economic theory with social
choice theory in order to design the trade matching
mechanism of intelligent electronic markets. Economic
theory offers the concept of market equilibrium, the
point at which total exchanged volume is maximized: this
determines optimal trade volumes between buyers and
sellers together with their optimal transaction pricing
based on bid/ask prices and demands/supplies.
Quantitative measures such as price and quantity are
important, but only represent part of traders' utility
in commodity markets. Commodity traders may also have
qualitative preferences over product attributes or
delivery conditions. When preferences are involved, the
trade match resulting from economic theory is not a
Pareto-optimal solution. We can further improve the
trade match by satisfying qualitative preferences of
traders. Social choice theory is employed to satisfy
these qualitative preferences.
Constraint Logic Programming, which combines the
complementary strengths of AI and OR, is investigated as
a new information technology to structure and implement
the trade matching mechanism. Market simulations
performed by a prototype of intelligent electronic
markets validate that its trade matching mechanism
yields Pareto-optimal trade matching between aggregated
buy and sell orders. This research extends market
functions of electronic trading to optimize realization
of traders' utilities in markets, thus significant to
trading system developers of commodity products such as
cotton, rice, wheat, corn, tea, coffee, sugar and cut
flowers.
</ABSTRACT>
</THESIS>
<THESIS>
<NUMBER> 4156 </NUMBER>
<ORDER>   AAG9413369 </ORDER>
<TITLE>   A HEURISTIC PROCEDURE FOR SPECIFYING PARAMETERS IN NEURAL NETWORK MODELS FOR SHEWHART X-BAR CONTROL CHART APPLICATIONS </TITLE>
<AUTHOR>   NAM, KYUNGDOO T. </AUTHOR>
<YEAR>   1993 </YEAR>
<INSTITUTION>   UNIVERSITY OF NORTH TEXAS; 0158 </INSTITUTION>
<DESCRIPTORS>   BUSINESS ADMINISTRATION, GENERAL; COMPUTER SCIENCE; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER>   VICTOR R. PRYBUTOK </ADVISER>
<CLASSIFICATIONS>   NIL </CLASSIFICATIONS>
<ABSTRACT>
This study develops a heuristic procedure for specifying
parameters for a neural network configuration (learning
rate, momentum, and the number of neurons in a single
hidden layer) in Shewhart X-bar control chart
applications. Also, this study examines the
replicability of the neural network solution when the
neural network is retrained several times with different
initial weights. As an illustration of the appropriate
use of the developed heuristic procedure, this study
compares the performance of neural networks with that of
Shewhart X-bar control charts. To determine neural
network configurations in Shewhart X-bar control chart
applications the performance of neural networks in
discriminant analysis applications was investigated.
Normally distributed populations with equal and unequal
covariances were used in these simulation studies of
configurations. The following heuristic procedure for
specifying parameters was developed for determining the
number of neurons in a single hidden layer, the learning
rate, and the momentum: (1) Avoid too small a number of
hidden neurons. (2) Selecting a number of hidden neurons
falling near the total number of input and output layer
neurons is an effective compromise. (3) If the pattern
of the training data is clear, use the default values
for a learning rate of 0.6 and a momentum of 0.9. (4) A
learning rate of 0.01 and a momentum of 0.9 are
recommended when the pattern of the training data is
noisy. (5) A momentum of 0.9 is recommended to avoid the
local minimum problems.
Simulation data from normal populations with equal
standard deviation were generated to compute the average
run lengths (ARL) for neural network control charts.
comparison of the ARLs showed that the neural networks
are more sensitive to shifts in the mean as compared to
the Shewhart X-bar control charts without supplementary
runs rules but that neural networks perform less
effectively than Shewhart X-bar control charts with
supplementary runs rules for detection of small shifts.
However, both types of charts tend to detect small
shifts quickly relative to the Shewhart X-bar control
charts without supplementary runs rules.
</ABSTRACT>
</THESIS>
<THESIS>
<NUMBER> 4157 </NUMBER>
<ORDER>   AAG9409927 </ORDER>
<TITLE>   FACTORS MEDIATING LEARNING FROM EXPERT SYSTEM JOB AIDS: DISPLAY FORMAT AND JOB AID CHARACTERIZATION </TITLE>
<AUTHOR>   FORD, JOHN MARCUS </AUTHOR>
<YEAR>   1993 </YEAR>
<INSTITUTION>   BRIGHAM YOUNG UNIVERSITY; 0022 </INSTITUTION>
<DESCRIPTORS>   EDUCATION, PSYCHOLOGY; COMPUTER SCIENCE; PSYCHOLOGY, GENERAL; ARTIFICIAL INTELLIGENCE; EDUCATION, TECHNOLOGY </DESCRIPTORS>
<ADVISER>   LARRY E. WOOD </ADVISER>
<CLASSIFICATIONS>   NIL </CLASSIFICATIONS>
<ABSTRACT>
Expert systems, computer programs which model the
reasoning of human experts, can be seen as the natural
technological extension of printed job aids such as
flowcharts. There is evidence that users of both expert
systems and flowcharts learn the content of these job
aids as they use them. These learning effects may be
mediated by the visual display format of these job aids
and by whether the job aids are characterized as complex
expert systems or as simple flowcharts.
A 2 x 2 factorial multivariate study addresses the
influence of these two issues on learning from the use
of expert systems. No statistically significant findings
resulted from this study. Two possible reasons for the
nonsignificance of the results are the unexpectedly
large individual differences between participants and
the fact that learning was measured after a relatively
brief period of job aid use. The author also believes
that the several learning measures used as dependent
variables have different learning curves. This issue
should be explored in future research which uses several
strategies to account for individual differences in a
more satisfactory manner than the present study.
</ABSTRACT>
</THESIS>
<THESIS>
<NUMBER> 4158 </NUMBER>
<ORDER>   AAG9412886 </ORDER>
<TITLE>   MULTIRESOLUTION AND COMPACT SUPPORT IN NEURAL NETWORK SIMULATIONS </TITLE>
<AUTHOR>   BOUBEZ, TOUFIC I. </AUTHOR>
<YEAR>   1993 </YEAR>
<INSTITUTION>   RUTGERS THE STATE U. OF N.J. - NEW BRUNSWICK AND U.M.D.N.J.; 0801 </INSTITUTION>
<DESCRIPTORS>   ENGINEERING, BIOMEDICAL; COMPUTER SCIENCE; MATHEMATICS; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER>   RICHARD L. PESKIN </ADVISER>
<CLASSIFICATIONS>   NIL </CLASSIFICATIONS>
<ABSTRACT>
Neurocomputing and the Neural Networks paradigm,
especially the feed-forward (FFNN) model, have recently
emerged as popular computing tools for the supervised
learning of classifications and function approximations.
The task typically requires the network to induce an
input-output map from a set of labeled examples in an
attempt to correctly classify input features that are
not part of the original training set. The current
model, however, suffers several shortcomings. First, the
number of units that are necessary in the hidden
layer(s) cannot be easily estimated before attempting to
solve a problem, and is generally dependent on the
problem structure, resulting in a long process of trial
and error. Another problem lies with the back-
propagation training method, which is a variant of
gradient descent, and therefore susceptible to local
minima, flatspots and numerical instabilities. Finally,
the hyperplane classification inherent in most network
models can be limiting and lacks a solid theoretical
framework.
</ABSTRACT>
</THESIS>
<THESIS>
<NUMBER> 4159 </NUMBER>
<ORDER>   AAG9412680 </ORDER>
<TITLE>   FOUNDATIONS OF RECURRENT NEURAL NETWORKS </TITLE>
<AUTHOR>   SIEGELMANN, HAVA (EVE) TOVA </AUTHOR>
<YEAR>   1993 </YEAR>
<INSTITUTION>   RUTGERS THE STATE UNIVERSITY OF NEW JERSEY - NEW BRUNSWICK; 0190 </INSTITUTION>
<DESCRIPTORS>   COMPUTER SCIENCE; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER>   EDUARDO D. SONTAG </ADVISER>
<CLASSIFICATIONS>   NIL </CLASSIFICATIONS>
<ABSTRACT>
"Artificial neural networks" provide an
appealing model of computation. Such networks consist of
an interconnection of a number of parallel agents, or
"neurons." Each of these receives certain
signals as inputs, computes some simple function, and
produces a signal as output, which is in turn broadcast
to the successive neurons involved in a given
computation. Some of the signals originate from outside
the network, and act as inputs to the whole system,
while some of the output signals are communicated back
to the environment and are used to encode the end result
of computation. In this dissertation we focus on the
"recurrent network" model, in which the
underlying graph is not subject to any constraints.
We investigate the computational power of neural nets,
taking a classical computer science point of view. We
characterize the language recognition power of networks
in terms of the types of numbers (constants) utilized as
weights. From a mathematical viewpoint, it is natural to
consider integer, rational, and real numbers. From the
standpoint of computer science, natural classes of
formal languages are regular, recursive, and "all
languages." We establish a precise correspondence
between the mathematical and computing choices.
Furthermore, when the computation time of the network is
constrained to be polynomial in the input size, the
classes recognized by the respective networks are:
regular, P, and Analog-P, i.e. P/poly. Among other
results described in this thesis are a proper hierarchy
of networks using Kolmogorov-complexity
characterizations, the imposition of space constraints,
and a proposed "Church's thesis of analog
computing."
</ABSTRACT>
</THESIS>
<THESIS>
<NUMBER> 4160 </NUMBER>
<ORDER>   AAG9412629 </ORDER>
<TITLE>   SPEAKER RECOGNITION USING THE MODIFIED NEURAL TREE NETWORK </TITLE>
<AUTHOR>   FARRELL, KEVIN ROBERT </AUTHOR>
<YEAR>   1993 </YEAR>
<INSTITUTION>   RUTGERS THE STATE UNIVERSITY OF NEW JERSEY - NEW BRUNSWICK; 0190 </INSTITUTION>
<DESCRIPTORS>   ENGINEERING, ELECTRONICS AND ELECTRICAL; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER>   RICHARD J. MAMMONE </ADVISER>
<CLASSIFICATIONS>   NEURAL TREE NETWORK </CLASSIFICATIONS>
<ABSTRACT>
A new classifier is presented for text-independent
speaker recognition. The new classifier is called the
modified neural tree network (MNTN). The MNTN is a
hierarchical classifier that combines the properties of
decision trees and feed-forward neural networks. The
MNTN is different from the standard NTN in both the new
learning rule used and the pruning criteria. The MNTN
uses discriminant learning, which minimizes the
classification error as opposed to a norm of the
approximation error. The MNTN also uses forward pruning
instead of the more common backward pruning approaches.
The MNTN is evaluated for several speaker recognition
experiments. These include closed and open set speaker
identification and speaker verification. The database
used is a subset of the TIMIT database consisting of 38
speakers from the same dialect region. The MNTN is
compared to nearest neighbor classifiers, full-search
(FSVQ) and tree-structured vector quantization (TSVQ)
classifiers, multi-layer perceptrons (MLPs), and
decision trees. For closed set speaker identification
experiments, the FSVQ classifier and MNTN demonstrate
comparable performance. Both methods perform
significantly better than the other classifiers for this
task. The MNTN and FSVQ classifiers are also compared
for several speaker verification and open set speaker
identification experiments. The MNTN is found to
outperform the FSVQ classifier for both of these
applications, in addition to providing a logarithmic
saving in retrieval time.
</ABSTRACT>
</THESIS>
<THESIS>
<NUMBER> 4161 </NUMBER>
<ORDER>   AAG9412337 </ORDER>
<TITLE>   SHAPE RECOGNITION USING METRICS ON THE SPACE OF SHAPES </TITLE>
<AUTHOR>   FRY, DAVID SPOTTS </AUTHOR>
<YEAR>   1993 </YEAR>
<INSTITUTION>   HARVARD UNIVERSITY; 0084 </INSTITUTION>
<DESCRIPTORS>   COMPUTER SCIENCE; PSYCHOLOGY, PSYCHOMETRICS; MATHEMATICS; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER>   DAVID MUMFORD </ADVISER>
<CLASSIFICATIONS>   TRANSPORT METRIC </CLASSIFICATIONS>
<ABSTRACT>
This dissertation discusses the notion that two-
dimensional shapes can be viewed as points in an
infinite dimensional space of shapes. Furthermore, we
can place a metric on this space, giving a mathematical
meaning to the idea that two shapes are similar, or
"close." A variety of metrics are possible,
each having its own strengths and weaknesses, each
constructing a different topology on the shape space.
The dimensions of the space represent features inherent
in the shapes. We believe that these features are what
enable humans to recognize shapes, and to partition them
into classes by their common qualities. This thesis
discusses results from psychological tests involving
humans and pigeons that indicate our sense of similarity
corresponds to a metric-like view of shape space. A
neural network model is presented that tackles the same
problems given to the humans and pigeons. Its results
give some clues about how to construct a real metric to
successfully discriminate planar objects.
We briefly discuss some common metrics that can be used,
and highlight some metric successes other researches
have had. However, this thesis mainly deals with the
development and implementation of the transport metric.
The transport metric, having its roots in operation
research, acts on shapes as if their boundaries were
collections of tiny line segments. We can imagine the
segments from one shape moving into place to form a
second shape. The metric uses a user-definable cost
function to place penalties on these motions; the cost
of the most economical rearrangement is the distance
between the two shapes in shape space. A cost function
that places adjustable penalties on translational and
rotational movement is featured.
This is applied to a database of 365 leaves drawn from
16 common New England species. Five leaves from each
species are used as prototypes and the remaining 285
leaves are classified by an algorithm that uses several
copies of the transport metric. The thesis concludes
with the results from this experiment, a discussion of
their meaning, and directions for possible future work.
</ABSTRACT>
</THESIS>
<THESIS>
<NUMBER> 4162 </NUMBER>
<ORDER>   AAG9412253 </ORDER>
<TITLE>   HANDWRITTEN DIGIT RECOGNITION USING BINARY NEURAL NETWORK </TITLE>
<AUTHOR>   HAM, BYUNGWOON </AUTHOR>
<YEAR>   1993 </YEAR>
<INSTITUTION>   UNIVERSITY OF SOUTHWESTERN LOUISIANA; 0233 </INSTITUTION>
<DESCRIPTORS>   COMPUTER SCIENCE; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER>   JUNG H. KIM </ADVISER>
<CLASSIFICATIONS>   NIL </CLASSIFICATIONS>
<ABSTRACT>
Due to the needs of massive number of neurons which may
be satisfied with multichip, and simple data and signal
transmission between BNN and existing digital hardware
in real-world application, ANN needs to be implemented
on current digital VLSI technology.
The handwritten digit recognition problem is one of the
major applications of Artificial Neural Networks. Three
different light receptor models, which mimic an animal's
vision system, are considered for the feature
extraction. The role of the light receptor models is to
transform an $Ntimes N$ matrix, which represents an
image, to M-bit vectors while preserving the special
features of an image. By transforming a matrix to a
vector, resources required for the learning are reduced,
and learning speed is improved.
Because of inherent drawbacks of traditional learning
algorithm such as uncertainty of convergence and slow
learning speed, a new learning algorithm for a BNN which
guarantees convergence for any binary-to-binary mapping
problem is developed. For the BNN which employs an
integer threshold and integer weights, the developed ETL
also learns much faster than Backpropagation learning.
</ABSTRACT>
</THESIS>
<THESIS>
<NUMBER> 4163 </NUMBER>
<ORDER>   AAIMM01023 </ORDER>
<TITLE>   AUTONOMOUS UNDERWATER VEHICLE CONTROL THROUGH SITUATION IDENTIFICATION </TITLE>
<AUTHOR>   WOLTER, DARRIN K. </AUTHOR>
<YEAR>   1993 </YEAR>
<INSTITUTION>   SIMON FRASER UNIVERSITY (CANADA); 0791 </INSTITUTION>
<DESCRIPTORS>   ENGINEERING, ELECTRONICS AND ELECTRICAL; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER>   JOHN S. BIRD </ADVISER>
<CLASSIFICATIONS>   NIL </CLASSIFICATIONS>
<ABSTRACT>
This thesis sets the stage for development of an
autonomous-vehicle control theory. Control of autonomous
vehicles is not an artificial intelligence dilemma, but
is a control problem where the control environment is
often under-sensed. In this thesis we hypothesize that
machines are only capable of applying a law given to
them by their designers. As the possessors of a law,
machines do not understand the environment in which they
exist, but simply react to that environment as they were
built, or programmed to react. We present the new ideas
of sensor and actuator space as a mathematical framework
for describing under-sensed control problems in terms of
environmental situations that sensors are able to
differentiate. We also show that computer-based control
systems have a lookup-table equivalent, referred to as a
Q-SAM. Each sensor-differentiable situation is
associated with a single location in the Q-SAM.
We use Q-SAMs to explore the potential of situation-
based control and show that they can accept many
different forms of control laws. When control
environments are under-sensed, we have found that the
definitions associated with differentiable environmental
situations are a function of the entire vehicle as well
as the environment in which the vehicle exists, which is
not the case for critically sensed control environments.
We describe a design methodology for autonomous systems
that results in systems which are robust to disturbances
in their environments. We use the methodology to
determine the sonar parameters required by an autonomous
underwater vehicle for the task of obstacle avoidance in
an unknown obstacle field. Limitations of the vehicle
are discussed.
</ABSTRACT>
</THESIS>
<THESIS>
<NUMBER> 4164 </NUMBER>
<ORDER>   AAIMM97872 </ORDER>
<TITLE>   SYSTEME HYBRIDE DE RECONNAISSANCE DE CIBLES </TITLE>
<AUTHOR>   EUSTACHE, ERIK </AUTHOR>
<YEAR>   1993 </YEAR>
<INSTITUTION>   UNIVERSITE LAVAL (CANADA); 0726 </INSTITUTION>
<DESCRIPTORS>   ENGINEERING, ELECTRONICS AND ELECTRICAL; REMOTE SENSING; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER>   DENIS POUSSART; DENIS GINGRAS </ADVISER>
<CLASSIFICATIONS>   FRENCH TEXT </CLASSIFICATIONS>
<ABSTRACT>
Cette recherche vise la mise en oeuvre d'un systeme
electro-optique pour la reconnaiesance automatique de
cibles utilisant des methodes de calcul neuronales. Le
systeme se compose de trois modules. Le premier module
effectue le pretraitement des images provenant de la
scene. Il s'agit d'un module hybride combinant le
parallelisme inherent a l'optique avec l'electronique de
haute vitesse d'un systeme DATACUBE$sp{rm MD}$. Le
second module effectue l'extraction de characteristiques
de la cible permettant une mesure invariante en
translation, en rotation et sous chagement d'echelle. Le
troisieme module est constitue d'un reseau de neurones
effectuant la classification de la cible. Le
classificateur neuronal utilise les proprietes
d'adaptation des reseaux de neurones pour se faire une
representation de chaque classe dans l'espace
multidimensionnel des caracteristiques de la cible.
Les algorithmes utilises pour le pretraitement,
l'extraction des caracteristiques et la classification
sont presentes, ainsi qu'une analyse des performances du
systeme.
</ABSTRACT>
</THESIS>
<THESIS>
<NUMBER> 4165 </NUMBER>
<ORDER>   AAIMM97619 </ORDER>
<TITLE>   MONITORING AND CONTROL OF HVDC TRANSMISSION SYSTEMS USING NEURAL NETWORKS </TITLE>
<AUTHOR>   KANDIL, NAHI </AUTHOR>
<YEAR>   1993 </YEAR>
<INSTITUTION>   CONCORDIA UNIVERSITY (CANADA); 0228 </INSTITUTION>
<DESCRIPTORS>   ENGINEERING, ELECTRONICS AND ELECTRICAL; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER>   NIL </ADVISER>
<CLASSIFICATIONS>   NIL </CLASSIFICATIONS>
<ABSTRACT>
In this thesis, Neural Networks (NNs) have been used in
a novel application in the monitoring and control of
High Voltage Direct Current (HVDC) Transmission systems.
In the first part, the possibility of using a NN to
identify faults that may have occurred in an ac-dc
system is explored. Based on the ability of these
networks to distinguish reliably between different types
of faults, appropriate control measures can be taken to
improve the dynamic performance of the ac-dc power
system. Depending on the inputs used, three different
Counter Propagation Network (CPN) architectures are
studied. Comparison between these architectures and
their performances is made.
In the second part, NNs are used as a current regulator
for the rectifier terminal of an HVDC system.
Traditionally, a PI regulator is used for this purpose
to provide a fast and robust controller. However, such
regulators are optimal only over a limited range of
operation and have no self-learning capability. In
contrast, NNs are adaptive, can learn from previous
experience, and they do not need prior knowledge of the
system dynamics. In this thesis, three NN regulators are
investigated. Comparisons between the PI and NN
regulators have been made to demonstrate the
capabilities of these NN regulators.
</ABSTRACT>
</THESIS>
<THESIS>
<NUMBER> 4166 </NUMBER>
<ORDER>   AAI9538237 </ORDER>
<TITLE>   THE DEVELOPMENT AND VALIDATION OF AN EXERCISE COUNTERMEASURE PROTOCOL MANAGEMENT EXPERT SYSTEM BASED ON AUTHENTIC METHODS OF REASONING </TITLE>
<AUTHOR>   WEBSTER, LAURIE </AUTHOR>
<YEAR>   1993 </YEAR>
<INSTITUTION>   UNIVERSITY OF HOUSTON; 0087 </INSTITUTION>
<DESCRIPTORS>   ENGINEERING, INDUSTRIAL; ENGINEERING, BIOMEDICAL; COMPUTER SCIENCE; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER>   JEN-GWO CHEN </ADVISER>
<CLASSIFICATIONS>   NIL </CLASSIFICATIONS>
<ABSTRACT>
Experiments conducted during NASA's Skylab missions
using treadmills and bicycles clearly demonstrated that
inflight exercise provides some degree of protection
against deconditioning. Exercises will be used as a
primary countermeasure against deconditioning on
extended Space Station flights to prevent muscle
atrophy, cardiovascular deconditioning and bone
demineralization resulting from prolonged exposures to a
microgravity environment. An expert system has been
developed to tailor exercise prescriptions to each crew
member based on the crew member's past performances with
a prescribed regime and expected
Intravehicular/Extravehicular activity (IVA/EVA). This
expert system provides initial exercise prescriptions
based on a subject's preflight stress test data and
his/her response to a questionnaire that extracts
information regarding the subject's current fitness
level and exercise modality preference. Additionally,
the expert system also adjusts the exercise prescription
based on complaints of the prescription being either too
difficult or too easy.
This dissertation develops a methodology for validating
the performance of authentic reasoning expert systems
that is based on comparing the expert system's reasoning
processes and use of reasoning factors to that of the
experts (i.e., using several experts to solve the same
problem that the authentic reasoning expert system
solved). We also established a mathematical process that
includes the use of rough set theory as a means of
capturing and quantifying the reasoning factors and
reasoning processes of the experts. Additionally, a
generalized entropy criterion for measuring consensus
effectiveness based on Dempster-Shafer's theory of
mathematical evidence is used in conjunction with rough
set theory to quantify the problem-solving performance
of the experts. This is used for ascertaining whether or
not the the expert system's way of solving a given set
of test cases is evident in the way the experts solve
the same test cases, which is an essential task in
validating authentic reasoning expert systems.
</ABSTRACT>
</THESIS>
<THESIS>
<NUMBER> 4167 </NUMBER>
<ORDER>   AAI9538232 </ORDER>
<TITLE>   A DECISION SUPPORT MODEL INTEGRATING NEURAL NETWORKS AND AN EXPERT SYSTEM FOR CONSTRUCTION MODULARIZATION </TITLE>
<AUTHOR>   MURTAZA, MIRZA BASHIR </AUTHOR>
<YEAR>   1993 </YEAR>
<INSTITUTION>   UNIVERSITY OF HOUSTON; 0087 </INSTITUTION>
<DESCRIPTORS>   ENGINEERING, INDUSTRIAL; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER>   NIL </ADVISER>
<CLASSIFICATIONS>   NIL </CLASSIFICATIONS>
<ABSTRACT>
Modular construction is a method for constructing units
of a project remote from the final project site. It
brings the advantage of the manufacturing processes to
the construction industry. It presents an opportunity to
improve a variety of performance parameters relating to
the project, such as, reduction of construction time,
reduced labor costs, increased quality and efficiency,
and simultaneous construction.
The research performed has addressed the following
issues of modularization, acquiring and structuring the
knowledge of the experts in the field through knowledge
engineering procedures, developing a decision model for
modularization feasibility (pre-screening, detailed
analysis and economic analysis), and developing a neural
network system for modularization feasibility decision
support.
The original prototype system used a pure expert system
approach. Based on various decision factors, it
recommends an appropriate degree of construction
modularization. If modularization is recommended, it
also provides the user with an approximate change in
costs and schedule due to modularization. The system is
then trained using neural network approach, utilizing
multi-layered unsupervised learning. This trained
version of the system has some advantages over the
initial expert system, such as the ability to
generalize, performing better under incomplete
information, and improving the basis of the initial
expert system.
</ABSTRACT>
</THESIS>
<THESIS>
<NUMBER> 4168 </NUMBER>
<ORDER>   AAI0576363 </ORDER>
<TITLE>   METHODS FOR CONFIGURING MANUFACTURING SYSTEMS </TITLE>
<AUTHOR>   LEE, MOSHIN </AUTHOR>
<YEAR>   1993 </YEAR>
<INSTITUTION>   MASSACHUSETTS INSTITUTE OF TECHNOLOGY; 0753 </INSTITUTION>
<DESCRIPTORS>   ENGINEERING, SYSTEM SCIENCE; ENGINEERING, AUTOMOTIVE; OPERATIONS RESEARCH; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER>   GEORGE CHRYSSOLOURIS </ADVISER>
<CLASSIFICATIONS>   NEURAL NETWORK, PERFORMANCE INDEX </CLASSIFICATIONS>
<ABSTRACT>
By describing a manufacturing system with the help of a
vector of numerical decision variables x, and the
system's performance by a scalar performance index y,
the manufacturing system configuration problem can be
defined as the problem of finding x such that it y(x) is
maximized. A general performance index y and decision
variables x suitable for the configuration of an actual
high-volume machining system from industry were defined.
These decision variables specify the machines types, the
assignment of machining operations to machines, and the
buffer capacities and locations of a manufacturing
system configuration. Although the industrial problem
studied involved only two machine types, the decision
variables were generalized to cover problems with an
arbitrary number of machine types. The performance index
accounts for the flexibility that is required of the
system to be configured.
Two broad solution approaches to this problem were
investigated. In the forward approach, a forward model
f(x) $approx$ y(x) is constructed. Then, an enumeration
procedure is used to iterate through the space of
solutions x, and the solution with the best value of
f(x) is prescribed. In the inverse approach, an inverse
model $fsp{-1}(y)approx$ x is given a goal performance
index value $ysb{goal}$, and the configuration $fsp{-
1}(ysb{goal})$ is prescribed. Regression and neural
network forward models and neural network inverse models
were investigated. These computationally efficient
empirical models were fit to (x,y) data generated via
accurate but computationally expensive discrete-event
simulation. The topography of the x $rightarrow y$
mapping was evaluated via roughness measures based on
finite-difference approximations of integrated first and
second derivatives and compared to that of known
analytical functions.
The performance of manufacturing system configurations
prescribed via the empirical models were compared to
that of configurations prescribed via analytical and
simulation forward models. Given sufficient simulation
data, forward and inverse network-prescribed
configurations are superior to those prescribed via
regression, simulation plus hill-climbing and analytical
models. Beyond a further number of simulation data,
simulation plus hill-climbing-prescribed configurations
attain performance comparable to that of network-
prescribed configurations. (Copies available exclusively
from MIT Libraries, Rm. 14-0551, Cambridge, MA 02139-
4307. Ph. 617-253-5668; Fax 617-253-1690.)
</ABSTRACT>
</THESIS>
<THESIS>
<NUMBER> 4169 </NUMBER>
<ORDER>   AAIMM96885 </ORDER>
<TITLE>   A TIRS/AIX IMPLEMENTATION OF A POWER DISTRIBUTION EXPERT SYSTEM </TITLE>
<AUTHOR>   COOK, CHARLES HAROLD </AUTHOR>
<YEAR>   1993 </YEAR>
<INSTITUTION>   THE UNIVERSITY OF NEW BRUNSWICK (CANADA); 0823 </INSTITUTION>
<DESCRIPTORS>   COMPUTER SCIENCE; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER>   ROD COOPER </ADVISER>
<CLASSIFICATIONS>   NIL </CLASSIFICATIONS>
<ABSTRACT>
Computer systems have proven themselves to be very
useful in assisting operations in the power industry.
The goal of this project is to take an existing
Distribution Operations Planning System prototype, and
implement it in a UNIX (AIX) environment. The prototype
consists of an expert system reasoning component, a
Geographical Information System (GIS) user interface,
and a data storage and retrieval facility.
The focus of this thesis is to take the prototype expert
system, written using KnowledgeTool on an IBM Mainframe,
and implement it using The Integrated Reasoning Shell
(TIRS) in an IBM AIX environment. This includes the
ability to pass data and messages back and forth between
the expert system, the GIS system, and the data storage
and retrieval facility. This thesis also explores the
differences between the two expert system shells and
between the two operating systems, and the ensuing
design and implementation issues that arise from these
differences.
</ABSTRACT>
</THESIS>
<THESIS>
<NUMBER> 4170 </NUMBER>
<ORDER>   AAI9531250 </ORDER>
<TITLE>   A MASSIVELY PARALLEL SIMD PROCESSOR FOR NEURAL NETWORK AND MACHINE VISION APPLICATIONS </TITLE>
<AUTHOR>   GLOVER, MICHAEL A. </AUTHOR>
<YEAR>   1993 </YEAR>
<INSTITUTION>   UNIVERSITY OF NEW HAMPSHIRE; 0141 </INSTITUTION>
<DESCRIPTORS>   ENGINEERING, ELECTRONICS AND ELECTRICAL; COMPUTER SCIENCE; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER>   W. THOMAS MILLER, III </ADVISER>
<CLASSIFICATIONS>   NIL </CLASSIFICATIONS>
<ABSTRACT>
This thesis describes the MM32k, a massively parallel
SIMD computer which is easy to program, high in
performance, low in cost and effective for implementing
highly parallel neural network architectures. The MM32k
has 32768 bit serial processing elements, each of which
has 512 bits of memory, and all of which are
interconnected by a switching network. The entire system
resides on a single PC-AT compatible card. It is
programmed from the host computer using a C++ language
class library which supports variable precision vector
arithmetic. The MM32k also supports direct video input
and output for machine vision applications.
</ABSTRACT>
</THESIS>
<THESIS>
<NUMBER> 4171 </NUMBER>
<ORDER>   AAINN95730 </ORDER>
<TITLE>   EXPRESSION DE LA LOCALISATION TEMPORELLE DANS UN GENERATEUR DE TEXTE </TITLE>
<AUTHOR>   GAGNON, MICHEL </AUTHOR>
<YEAR>   1993 </YEAR>
<INSTITUTION>   ECOLE POLYTECHNIQUE, MONTREAL (CANADA); 1105 </INSTITUTION>
<DESCRIPTORS>   COMPUTER SCIENCE; LANGUAGE, GENERAL; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER>   GUY LAPALME </ADVISER>
<CLASSIFICATIONS>   GRAMMAR, SYNTAX, FRENCH TEXT </CLASSIFICATIONS>
<ABSTRACT>
Dans cette these, nous presentons une solution au
probleme de l'expression de la localisation temporelle
en generation de texte. Cette solution repose sur une
decomposition du processus en deux etapes: une premiere
etape de structuration, ou les faits temporels a relater
sont organises selon un certain point de vue, et une
etape de redaction, ou chaque element de la structure de
discours produite lors de la premiere etape est exprime
par une phrase.
Nous avons concentre notre attention sur l'etape de
redaction, en realisant un generateur, appele Pretexte,
qui utilise les principes de la theorie de la grammaire
systemique. En utilisant cette theorie, nous proposons
une methode pour generer, de facon independante, les
locutions adverbiales temporelles et les temps de verbe.
La grammaire developpee offre une plus grande couverture
que les autres generateurs developpes auparavant.
En ce qui concerne les locutions adverbiales
temporelles, nous proposons une grammaire qui reflete
directement la diversite semantique de celles-ci. On
obtient ainsi une methode plus adaptee a la generation
de texte, ou la donnee est de nature semantique. De
plus, on met ainsi en evidence des aspects qui sont
occultes lorsqu'on utilise une methode centree sur la
diversite syntaxique des locutions adverbiales
temporelles. Les adverbes ayant ete peu etudies
auparavant, il a fallu elaborer un formalisme semantique
permettant de solutionner le probleme de la
representation des dates.
Pour les temps de verbe, Pretexte utilise une grammaire
basee sur la Theorie des Representations Discursives
(DRT), integree a la theorie systemique, permettant
ainsi d'obtenir une grammaire simple tenant compte des
particularites des temps de verbe en francais.
Toute la demarche proposee repose sur une representation
du temps qui prend, comme notion primitive, non pas les
intervalles ou les points, mais les occurrenccs, c'est-a-
dire des faits se produisant dans le temps. Les
resultats que nous avons obtenus montrent que ce choix
s'avere valable.
Nous montrons donc qu'en utilisant la DRT et la theorie
de la grammaire systemique, il est possible d'implanter
le processus de redaction de facon efficace, tout en
obtenant un systeme tres expressif en ce qui concerne la
localisation temporelle. De plus, la pertinence des
choix effectues pour l'implantation de ce processus est
mise en evidence par une discussion d'une methode de
structuration qui permet de produire la donnee utilisee
par le module de redaction. La structuration n'ayant pas
ete implantee, elle sera l'objet de travaux futurs.
</ABSTRACT>
</THESIS>
<THESIS>
<NUMBER> 4172 </NUMBER>
<ORDER>   AAINN95720 </ORDER>
<TITLE>   OPTIMISATION D'UNE REGLE D'APPRENTISSAGE POUR RESEAUX DE NEURONES ARTIFICIELS </TITLE>
<AUTHOR>   BENGIO, SAMY </AUTHOR>
<YEAR>   1993 </YEAR>
<INSTITUTION>   ECOLE POLYTECHNIQUE, MONTREAL (CANADA); 1105 </INSTITUTION>
<DESCRIPTORS>   COMPUTER SCIENCE; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER>   JAN GECSEI; JOCEYLN CLOUTIER </ADVISER>
<CLASSIFICATIONS>   NEURAL NETWORKS, LEARNING RULES, CONNECTIONIST MODELS, FRENCH TEXT </CLASSIFICATIONS>
<ABSTRACT>
Les reseaux de neurones artificiels sont des modeles de
calcul paralleles et distribues bases, par analogie avec
le fonctionnement du cerveau, sur une interconnexion
forte et ponderee d'unites de traitement simples
appelees neurones. Ces modeles ont la meme puissance
qu'une machine de Turing, et peuvent donc resoudre tout
probleme calculable, a condition cependant de trouver
une architecture convenable et des poids satisfaisants.
La recherche dans l'espace des poids d'un reseau de
neurones artificiels s'effectue a l'aide d'une regle
d'apprentissage. Plusieurs regles ont ete developpees
recemment mais on eprouve encore beaucoup de problemes
quant au choix des divers parametres qui regissent le
fonctionnement de ces regles. De plus, les regles
actuelles sont souvent impuissantes devant la resolution
de taches difficiles.
Plutot que de chercher a developper une regle
d'apprentissage universelle, nous proposons dans cette
these une nouvelle methode permettant la recherche de
nouvelles regles d'apprentissage parametriques
specialisees dans la resolution d'une classe restreinte
de taches. Cette recherche s'effectue a l'aide de
methodes d'optimisation traditionnelles telles que la
descente du gradient, les algorithmes genetiques et le
recuit simule.
La theorie sur la capacite des systemes d'apprentissage,
telle qu'etendue dans cette these au cas des regles
d'apprentissage parametriques, permet de nous guider
dans le design de telles regles, notamment par
l'utilisation de connaissances sur le domaine des taches
a resoudre pour contraindre la capacite de la regle
parametrique. Elle fournit en effet une borne maximale
sur l'erreur de generalisation obtenue par une regle
d'apprentissage sur des taches qui n'etaient pas
utilisees pour l'optimisation des parametres de la
regle. Cette borne est fonction du nombre de taches
utilisees pendant la phase d'optimisation et de la
capacite de la regle d'apprentissage.
Les experiences realisees et presentees ici montrent
tout d'abord qu'il est effectivement possible de trouver
par optimisation une regle d'apprentissage capable de
resoudre des taches complexes. Ces experiences
confirment de plus les resultats theoriques sur la
capacite des regles d'apprentissage parametriques.
Une comparaison entre une regle trouvee par optimisation
et la regle la plus populaire dans la litterature montre
qu'il existe, a l'interieur d'un cadre defini, de
meilleures regles d'apprentissage specialisees.
Notons finalement qu'une des contributions importantes
de ce travail consiste a fournir une methode permettant
l'exploration systematique de l'espace des regles
d'apprentissage pour reseaux de neurones artificiels.
</ABSTRACT>
</THESIS>
<THESIS>
<NUMBER> 4173 </NUMBER>
<ORDER>   AAG9411898 </ORDER>
<TITLE>   EVOLUTIONARY ALGORITHMS AND EMERGENT INTELLIGENCE </TITLE>
<AUTHOR>   ANGELINE, PETER JOHN </AUTHOR>
<YEAR>   1993 </YEAR>
<INSTITUTION>   THE OHIO STATE UNIVERSITY; 0168 </INSTITUTION>
<DESCRIPTORS>   COMPUTER SCIENCE; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER>   JORDAN B. POLLACK </ADVISER>
<CLASSIFICATIONS>   TASK ENVIRONMENT, NEURAL NETWORKS </CLASSIFICATIONS>
<ABSTRACT>
In order to perform adequately, knowledge-based
artificial intelligence techniques rely on internal
representations of the task environment. The requirement
that this "explicit task knowledge" must be
inside the agent leads to classic problems in AI:
scaling, brittleness, learnability, knowledge
acquisition, memory indexing and credit assignment.
These problems are reduced or removed when the agent is
allowed to interact with the task environment directly.
In emergent intelligence, task specific knowledge
emerges from the interaction of a simple agent and the
original task environment. In effect, the task
environment serves as a more efficient representation of
the "explicit task knowledge," removing the
need to represent it inside the agent. In this
dissertation, evolutionary algorithms, computations that
are modeled after natural selection, are analyzed and
proposed to be a novel form of weak method that provide
an ideal medium for implementing emergent intelligence.
This dissertation also describes several experiments
that demonstrate emergent intelligence during the
acquisition of recurrent neural networks, finite state
machines and modular LISP programs using a variety of
evolutionary algorithms.
</ABSTRACT>
</THESIS>
<THESIS>
<NUMBER> 4174 </NUMBER>
<ORDER>   AAG9411794 </ORDER>
<TITLE>   CASE-BASED MULTIATTRIBUTE STRUCTURAL DESIGN AND OPTIMIZATION </TITLE>
<AUTHOR>   SUN, RUOFEI </AUTHOR>
<YEAR>   1993 </YEAR>
<INSTITUTION>   UNIVERSITY OF ILLINOIS AT URBANA-CHAMPAIGN; 0090 </INSTITUTION>
<DESCRIPTORS>   ENGINEERING, CIVIL; COMPUTER SCIENCE; OPERATIONS RESEARCH; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER>   DEBORAH L. THURSTON </ADVISER>
<CLASSIFICATIONS>   MACHINE LEARNING </CLASSIFICATIONS>
<ABSTRACT>
Since engineering design usually involves a lot of trade-
off and decision making, it is a complicated and time
consuming process. To augment engineer's creativity, a
case-based multiattribute structural design and
optimization methodology is developed in this study.
This new methodology is aimed to solve the problems in
computer aided structural design in customizing user
(designer) knowledge and preferences, machine learning,
automatic creation of design prototypes based on the
previous design cases, and the incorporation of design
evaluation and optimization in the design process.
Utility analysis has also been used in structural design
evaluation and optimization with consideration of
earthquake uncertainty.
The methodology is an integration of artificial
intelligence technology and decision theory, e.g. case-
based reasoning, expert system technique, and
multiattribute utility analysis. Especially, a two-step
case selection algorithm and a design evaluation and
optimization algorithm are developed by using utility
theory. The methodology is implemented into a computer
prototype called CMASDOS (Case-based MultiAttribute
Structural Design and Optimization System) with object-
oriented programming. The feasibility and creativity of
the methodology are verified through design examples.
</ABSTRACT>
</THESIS>
<THESIS>
<NUMBER> 4175 </NUMBER>
<ORDER>   AAG9411741 </ORDER>
<TITLE>   ANTI-UNIFICATION IN CONSTRAINT LOGICS: FOUNDATIONS AND APPLICATIONS TO LEARNABILITY IN FIRST-ORDER LOGIC, TO SPEED-UP LEARNING, AND TO DEDUCTION </TITLE>
<AUTHOR>   PAGE, CHARLES DAVID, JR. </AUTHOR>
<YEAR>   1993 </YEAR>
<INSTITUTION>   UNIVERSITY OF ILLINOIS AT URBANA-CHAMPAIGN; 0090 </INSTITUTION>
<DESCRIPTORS>   COMPUTER SCIENCE; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER>   ALAN M. FRISCH </ADVISER>
<CLASSIFICATIONS>   NIL </CLASSIFICATIONS>
<ABSTRACT>
Unification is central to automated reasoning.
Unification comes in a variety of forms, all of which
compute (roughly stated) the greatest lower bound, or
all maximal lower bounds, of any two or more syntactic
objects in a partially-ordered set of such objects. The
dual of unification is an operation called
generalization, or anti-unification, which computes
least or minimal upper bounds. As with unification, anti-
unification comes in a variety of forms. The thesis of
this dissertation is: anti-unification in its various
forms is, like unification, a powerful tool for
automated reasoning. In defense of the thesis, several
forms of anti-unification in constraint logic, anti-
unification relative to background information, are
defined, and their semantic and computational properties
are studied. It is shown that these forms of anti-
unification are applicable to inductive logic
programming (inductive learning of logic programs),
speed-up learning, and knowledge base vivification (an
approach to efficient deduction).
</ABSTRACT>
</THESIS>
<THESIS>
<NUMBER> 4176 </NUMBER>
<ORDER>   AAG9411427 </ORDER>
<TITLE>   DIAGNOSTIC TECHNIQUE FOR POWER SYSTEMS UTILIZING INFRARED THERMAL IMAGING </TITLE>
<AUTHOR>   MERRYMAN, STEPHEN ARNOLD </AUTHOR>
<YEAR>   1993 </YEAR>
<INSTITUTION>   AUBURN UNIVERSITY; 0012 </INSTITUTION>
<DESCRIPTORS>   ENGINEERING, ELECTRONICS AND ELECTRICAL; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER>   R. M. NELMS </ADVISER>
<CLASSIFICATIONS>   NIL </CLASSIFICATIONS>
<ABSTRACT>
A real-time diagnostic and control technique has been
developed for use in electronic circuits whose thermal
signature can be correlated to their operating status.
Successful implementation of this diagnostic scheme in
proof-of-concept experiments required the incorporation
of several technological issues into a complete system
that has the capability to detect potential fault modes
in the system under observation. Included was the
ability to: (1) use infrared fiber optics to view
components within enclosures and complex geometries, (2)
obtain the thermal profile of the system, (3) process
and analyze thermal data, (4) implement a simulated
artificial neural network to determine the particular
condition or fault corresponding to the thermal
signature, and (5) perform any necessary corrective
action in a timely manner. Infrared optical fibers,
routed from individual components to an external array
of connectors, were used to collect and transmit energy
radiated from those components. An infrared thermal
imaging camera was utilized to scan the fiber array and
produce an image corresponding to the thermal profile;
thus, the thermal signature was obtained in a manner
which was neither thermally nor electrically intrusive.
Temperature data was then transmitted via an interface
bus from the camera system to the control computer where
information was converted into a form suitable for input
into a trained artificial neural network.
Backpropagation was the neural network algorithm chosen
for this application, and it was simulated in software
to detect the probable operating condition or fault mode
responsible for generating a given thermal image. Inputs
to the backpropagation algorithm were the changes in
component temperature from a prescribed
"normal" operating mode, while the outputs
defined the most likely corresponding operating
condition. If the system determines that an undesirable
fault has occurred, an option could automatically be
chosen to modify the operating conditions of the circuit
such that component temperatures return to normal and
safe values.
The concept was implemented on a capacitor-charging
power supply which was adapted to allow implementation
of the thermal diagnostic system. For demonstration
purposes, twenty component temperatures were monitored
via infrared optical fibers, and they were used to
detect and distinguish between a total of eleven
different fault modes and operating conditions. The
diagnostic system successfully detected each of the
eleven modes which were generated during the testing
phase of the experiments. Requirements for adapting this
technique to large-scale systems with hundreds or
thousands of components and possibly a hundred different
fault modes is also discussed.
</ABSTRACT>
</THESIS>
<THESIS>
<NUMBER> 4177 </NUMBER>
<ORDER>   AAG9411216 </ORDER>
<TITLE>   LEARNING TO INVERT MANY-TO-ONE MAPPINGS </TITLE>
<AUTHOR>   DEMERS, DAVID EDWARD </AUTHOR>
<YEAR>   1993 </YEAR>
<INSTITUTION>   UNIVERSITY OF CALIFORNIA, SAN DIEGO; 0033 </INSTITUTION>
<DESCRIPTORS>   COMPUTER SCIENCE; ENGINEERING, SYSTEM SCIENCE; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER>   KENNETH KREUTZ-DELGADO; GARRISON COTTRELL </ADVISER>
<CLASSIFICATIONS>   ROBOTICS </CLASSIFICATIONS>
<ABSTRACT>
Many important problems can be cast as inverse problems,
such as the robot inverse kinematics problem, the
problem of scene disambiguation in computer vision, and
many problems of inference. General methods for solving
low dimensional nonlinear inverse problems are therefore
of great interest.
In general, nonlinear inverse problems for forward
systems which are continuous and smooth, such as the
inverse kinematics problem for manipulators with
redundant degrees of freedom, are ill-posed in two
distinct senses. First, they are globally ill-posed,
because of the existence of multiple solution branches.
Second, they are locally ill-posed, because the solution
branches are typically manifolds with dimension equal to
the number of redundant degrees of freedom.
Such problems can be solved if they can be regularized;
if there exist principled ways of (1) selecting from the
discrete set of solution branches and (2) choosing a
particular solution along the branch. These global and
local regularizations yield an invertible system. In
general, it is not possible to regularize a nonlinear
inverse problem such that it is invertible for every
point in the output space.
This dissertation shows that maximal, singularity-free
regions of the output space are invertible. The inverse
image of these regions has a topological structure of a
fiber bundle. A representation of the fibers which is
consistent across the region allows construction of a
family of inverse functions, parameterized by the
redundancy.
These invertible regions can be identified from measured
input-output data, without knowledge of the functional
form of the forward system. Furthermore, by properly
exploiting topological knowledge about nonlinear
systems, unsupervised learning algorithms are developed
for identifying the separate solution branches for the
invertible regions, and for constructing a natural
representation of the system's redundancy. As a result,
the ill-posed nonlinear inverse problem can be
regularized by these learning methods and direct inverse
functions constructed over each invertible region.
Consequently all possible inverse solutions can be
obtained at runtime. Search for a globally optimal
solution for an arbitrary side constraint is reduced to
a search in a space of dimension equal to the
redundancy, rather than in the full input space.
</ABSTRACT>
</THESIS>
<THESIS>
<NUMBER> 4178 </NUMBER>
<ORDER>   AAG9410990 </ORDER>
<TITLE>   EMERGENT BEHAVIOR IN SOCIETIES OF INTELLIGENT AGENTS: ALLIANCES AND NORMS </TITLE>
<AUTHOR>   MALYANKAR, RAPHAEL </AUTHOR>
<YEAR>   1993 </YEAR>
<INSTITUTION>   ARIZONA STATE UNIVERSITY; 0010 </INSTITUTION>
<DESCRIPTORS>   COMPUTER SCIENCE; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER>   NIL </ADVISER>
<CLASSIFICATIONS>   NIL </CLASSIFICATIONS>
<ABSTRACT>
The main aim of the research described here is to
demonstrate the feasibility of a generalized procedure-
oriented approach to explaining and understanding of
emergent behavior in societies of intelligent agents. A
secondary aim is to describe generalized computational
methods for two forms of emergent behavior: alliance
formation and norms. An alliance is a temporary group
formed by agents who have decided to cooperate in order
to achieve a common goal. Norms are constraints that
bound the space of possible goals and actions. The
underlying objective is to contribute towards defining
areas of investigation and to identify fundamental
concepts in the nascent fields of distributed
intelligent systems and societal simulation.
Two kinds of frameworks, a mathematically oriented one
and a mechanism-based one, were investigated and
evaluated for their utility in studying distributed
intelligent systems. With this in mind, a two-step
approach was adopted in the research described herein.
First, the factors that constitute the essence of
intelligent behavior in societies of intelligent agents
were identified. Mathematically oriented approaches
based on these factors were proposed and their utility
for studying alliances and norms was evaluated. Second,
separate computational procedures for two forms of
emergent behavior, alliance and norms, were described.
The application of the procedures to two real-life
situations was then studied.
The results indicate that the generalized procedure-
oriented approach can be used to explain the formation
of alliances and the evolution of norms that cannot be
explained by game theoretic techniques. The
mathematically oriented framework is better suited for
representing distributed intelligent system behavior
than for constructing prescriptive and explicatory
theories, at least for the phenomena of interest in this
dissertation.
</ABSTRACT>
</THESIS>
<THESIS>
<NUMBER> 4179 </NUMBER>
<ORDER>   AAG9410961 </ORDER>
<TITLE>   MULTI-AGENT COORDINATION AND COOPERATION IN A DISTRIBUTED DYNAMIC ENVIRONMENT WITH LIMITED RESOURCES: SIMULATED AIR WARS </TITLE>
<AUTHOR>   ELDER, GREGORY DEAN </AUTHOR>
<YEAR>   1993 </YEAR>
<INSTITUTION>   ARIZONA STATE UNIVERSITY; 0010 </INSTITUTION>
<DESCRIPTORS>   COMPUTER SCIENCE; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER>   NIL </ADVISER>
<CLASSIFICATIONS>   NIL </CLASSIFICATIONS>
<ABSTRACT>
Coordination and cooperation are two major issues of
concern in Distributed Artificial Intelligence (DAI)
systems. How can a group of geographically distributed
agents properly allocate a set of tasks among
themselves? Also, in an environment of limited
resources, how can agents resolve resource conflicts so
as to effectively accomplish tasks? This research has
examined these two problems and has implemented
techniques to promote multi-agent coordination and
cooperation. A method of negotiation allows agents to
bid for tasks based upon the agents' capabilities.
Furthermore, the use of a threshold value ensures that
only the best agents for a task become task commanders,
as well as allowing some tasks to be re-negotiated as
agents improve their bids. To resolve resource
conflicts, a technique known as Hierarchical Iterative
Conflict Resolution has been used. This technique allows
conflicts to be resolved in an iterative manner, based
upon a hierarchy of task priorities. Agents with higher
priority tasks have preference for borrowing resources
from agents with lower priority tasks. This ensures that
higher priority tasks will be solved before those of
lower priority.
These two techniques were employed in a DAI testbed
which simulates an air war environment. Empirical
studies were conducted using the testbed. The studies
consisted of air war simulations between two opposing
forces. During the simulations, tasks (air missions) had
to be accomplished. Various decision making entities
were examined in this study--human decision makers,
distributed computer agents with resource sharing,
distributed computer agents without resource sharing,
and a single computer agent. The results of the studies
indicate that within a dynamic and volatile environment,
distributed agents sharing resources can achieve a
higher level of task accomplishment than the other
decision making entities.
</ABSTRACT>
</THESIS>
<THESIS>
<NUMBER> 4180 </NUMBER>
<ORDER>   AAG9410263 </ORDER>
<TITLE>   A MODEL OF RECURRENT NEURAL NETWORK WITH HIGH CAPACITY </TITLE>
<AUTHOR>   CHEN, CHANG-JIU </AUTHOR>
<YEAR>   1993 </YEAR>
<INSTITUTION>   THE UNIVERSITY OF OKLAHOMA; 0169 </INSTITUTION>
<DESCRIPTORS>   COMPUTER SCIENCE; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER>   NIL </ADVISER>
<CLASSIFICATIONS>   NEURAL NETWORKS </CLASSIFICATIONS>
<ABSTRACT>
A recurrent neural network is a one-layer network with
lateral-connection. It feedbacks the output vector to
the input during processing and stops when the output
vector is stable. A recurrent neural network can act as
an associative memory, and the capacity is an important
criterion in this kind of memory. Therefore, the study
of the capacity of recurrent neural network attracted
many researchers.
In our study of the capacity of recurrent neural
networks, we find an upper bound of the network, which
is a function of r, the minimum attraction radius of all
attraction regions. Many works focused on the topic of
the capacity of recurrent neural network. However, there
is a big gap between the capacity of those works and the
upper bound.
In this dissertation, we propose a High Capacity (HC)
model which explores the capacity, $${nchoose
lfloor{nover2}rfloor},$$of recurrent neural network. It
is the high capacity. The HC model reduces the benefit
of noise tolerance to obtain a high capacity. We analyze
the properties resulted from the proposed model.
The comparisons of the proposed model with other works
are discussed in terms of the number of capacity and the
behavior of the network. We also discuss several methods
regarding the intersection and subtraction of two HC
models.
Hopfield neural network is one of the most widely
studied model among the recurrent neural networks. We
propose an efficient simulation model for Hopfield
neural networks based on the condition that the number
of memorized vectors, m, is smaller than the number of
neurons, n, in the network.
</ABSTRACT>
</THESIS>
<THESIS>
<NUMBER> 4181 </NUMBER>
<ORDER>   AAG9410224 </ORDER>
<TITLE>   AN EXPERT SYSTEM APPROACH TO DESIGN FOR EASE OF ASSEMBLY IN SPACE </TITLE>
<AUTHOR>   ROMAN, RAMON LUIS </AUTHOR>
<YEAR>   1993 </YEAR>
<INSTITUTION>   WEST VIRGINIA UNIVERSITY; 0256 </INSTITUTION>
<DESCRIPTORS>   ENGINEERING, MECHANICAL; COMPUTER SCIENCE; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER>   SUREN N. DWIVEDI </ADVISER>
<CLASSIFICATIONS>   RIMS II </CLASSIFICATIONS>
<ABSTRACT>
NASA studies on the development of artificial
intelligence technologies needed for space station
automation have concluded that very little research is
currently being done in the area of expert systems, and
that development of new and the reverification of old
expert systems for space-based applications is
important. This study presents a design for ease of
assembly in the space environment advisor, a prototype
expert system containing space-based design expertise as
well as a set of rules to facilitate assembly of
mechanical components in space.
The methodology selected for part analysis is based on
the development of tables which assign design efficiency
values depending the designer's selection from a variety
of options relating to specific questions on part
orientation, adjustments, compliances and various
assembly construction methods. The construction and
syntax for the solution of the problem are made possible
with the application of rule-based sensitivity analysis
at the decision stage of the design for assembly
process. Based on this, the tables are transformed into
a computer-oriented formulation, written in a production-
rule format and constructed in an object-oriented
language.
Studies performed on the RIMS II inertial guidance
platform assembly, with the use of this prototype
artificial intelligence tool, resulted in a decreased
number of parts, increased standardization, and
characteristic features that facilitate assembly in
space.
The work as presented not only presents the particulars
for the improvement of the selected case study, but also
provides designers of space-based equipment with a
single source containing the latest information on a
variety of subjects relating to the development of
expert systems for assembly and the applicability of
these systems to the design for ease of assembly problem
in space.
</ABSTRACT>
</THESIS>
<THESIS>
<NUMBER> 4182 </NUMBER>
<ORDER>   AAG9409771 </ORDER>
<TITLE>   CIRCA: THE COOPERATIVE INTELLIGENT REAL-TIME CONTROL ARCHITECTURE </TITLE>
<AUTHOR>   MUSLINER, DAVID JOHN </AUTHOR>
<YEAR>   1993 </YEAR>
<INSTITUTION>   THE UNIVERSITY OF MICHIGAN; 0127 </INSTITUTION>
<DESCRIPTORS>   COMPUTER SCIENCE; ARTIFICIAL INTELLIGENCE; ENGINEERING, ELECTRONICS AND ELECTRICAL </DESCRIPTORS>
<ADVISER>   KANG G. SHIN; EDMUND H. DURFEE </ADVISER>
<CLASSIFICATIONS>   CONTROL, ARCHITECTURE </CLASSIFICATIONS>
<ABSTRACT>
The Cooperative Intelligent Real-time Control
Architecture (CIRCA) is a novel architecture for
intelligent real-time control that can guarantee to meet
hard deadlines while still using unpredictable,
unrestricted AI methods. CIRCA includes a real-time
subsystem used to execute reactive control plans that
are guaranteed to meet the domain's real-time deadlines,
keeping the system safe. At the same time, CIRCA's AI
subsystem performs higher-level reasoning about the
domain and the system's goals and capabilities, to
develop future reactive control plans. CIRCA thus aims
to be intelligent $underline{about}$ real-time: rather
than requiring the system's AI methods to meet
deadlines, CIRCA isolates its reasoning about which time-
critical reactions to guarantee from the actual
execution of the selected reactions.
The formal basis for CIRCA's performance guarantees is a
state-based world model of agent/environment
interactions. Borrowing approaches from real-time
systems research, the world model provides the
information required to make real-time performance
guarantees, but avoids unnecessary complexity. Using the
world model, the AI subsystem develops reactive control
plans that restrict the world to a limited set of safe
and desirable states, by guaranteeing the timely
performance of actions to preempt transitions that lead
out of the set of states. By executing such
"safe" and "stable" plans, CIRCA's
real-time subsystem is able to keep the system safe (in
the world as modeled) for an indeterminate amount of
time, while the parallel AI subsystem develops the next
appropriate plan.
We have applied a prototype CIRCA implementation to a
simulated Puma robot arm performing multiple tasks with
real-time deadlines, such as packing parts off a
conveyor belt and responding to asynchronous interrupts.
Our experimental results show how the system can
guarantee to accomplish these tasks under a given set of
domain conditions (e.g., conveyor belt speed) and
resource limitations (e.g., robot arm speed).
Furthermore, because CIRCA reasons explicitly about its
own predictable, guaranteed behaviors, the system can
recognize when its resources are insufficient for the
desired behaviors (e.g., parts are arriving too quickly
to be packed carefully), and can then make principled
modifications to its performance (e.g., temporarily
stacking parts on a table) to maintain system safety.
</ABSTRACT>
</THESIS>
<THESIS>
<NUMBER> 4183 </NUMBER>
<ORDER>   AAG9409596 </ORDER>
<TITLE>   ARTIFICIAL NEURAL-NETWORK FOR IDENTIFICATION AND TRACKING CONTROL OF A FLEXIBLE JOINT ROBOT </TITLE>
<AUTHOR>   KIM, HUN-MO </AUTHOR>
<YEAR>   1993 </YEAR>
<INSTITUTION>   THE UNIVERSITY OF ALABAMA; 0004 </INSTITUTION>
<DESCRIPTORS>   ENGINEERING, MECHANICAL; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER>   JOEY K. PARKER </ADVISER>
<CLASSIFICATIONS>   NIL </CLASSIFICATIONS>
<ABSTRACT>
This dissertation presents an Artificial Neural Network
(ANN) which can be used effectively for identification
and tracking control of a flexible joint robot. Tracking
control is complicated due to the joint flexibility,
nonlinearity, and coupling. We show that the ANN is a
significantly more attractive controller design than
previous traditional forms of control systems for the
tracking control of a flexible joint robot. The ANN is
used to obtain an emulation of a flexible joint robot to
be controlled. Once the ANN has learned the emulation,
another ANN is designed for tracking control. Both of
these tasks are completed using the BackPropagation (BP)
neural network. The simulation results reveal that the
identification and tracking control of a flexible joint
robot by using an ANN are practically feasible and
realizable.
</ABSTRACT>
</THESIS>
<THESIS>
<NUMBER> 4184 </NUMBER>
<ORDER>   AAG9407821 </ORDER>
<TITLE>   HIERARCHICAL NEURAL NETWORK FOR VISUAL PATTERN REPRESENTATION, RECOGNITION, AND COMPLETION </TITLE>
<AUTHOR>   WAN, LIQUN </AUTHOR>
<YEAR>   1993 </YEAR>
<INSTITUTION>   UNIVERSITY OF CINCINNATI; 0045 </INSTITUTION>
<DESCRIPTORS>   ENGINEERING, ELECTRONICS AND ELECTRICAL; COMPUTER SCIENCE; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER>   W. G. WEE </ADVISER>
<CLASSIFICATIONS>   NIL </CLASSIFICATIONS>
<ABSTRACT>
One of the most promising applications for the
artificial neural network (ANN) research is the
development of new visual information processing
paradigms which are parable to the human visual system.
Among many organizational principles in the human visual
system, three are most distinctive, the hierarchical
structure, the lateral inhibitory effect, and the
dynamical behavior. A new neural network model, the
hierarchical neural network, is proposed in this
dissertation. The hierarchical neural network entails
all of the above three principles. The hierarchical
structure is introduced in the network by arranging
units in a series of layers and restricting the
connections of units in each layer within the local
regions on both adjacent layers. The lateral inhibitory
effect is achieved by adopting a recurrent on-center off-
surround architecture for lateral interaction. The
dynamical behavior is described by a set of first order
differential equations which specify the activation
values of the units in the network. Some quantitative
analysis on the proposed hierarchical neural network is
performed in the dissertation. Some important results of
this research include: (1) the asymptotic stability
proof of the network, (2) the ranking preserving
property proof of the lateral inhibitory dynamics and
the winner-take-all condition derivation, (3) the
extension of the competitive learning algorithm for the
hierarchical neural network training and the convergence
proof of the learning algorithm, and (4) the
introduction of a new associative memory model,
hierarchical associative memory, and the fixed point
proof of the hierarchical associative memory.
</ABSTRACT>
</THESIS>
<THESIS>
<NUMBER> 4185 </NUMBER>
<ORDER>   AAG0574339 </ORDER>
<TITLE>   THE USE OF FUNCTIONAL AGGREGATES TO SIMPLIFY REASONING QUALITATIVELY ABOUT COMPLEX PHYSICAL SYSTEMS </TITLE>
<AUTHOR>   LEE, HEE-YOUN </AUTHOR>
<YEAR>   1993 </YEAR>
<INSTITUTION>   UNIVERSITY OF SOUTHERN CALIFORNIA; 0208 </INSTITUTION>
<DESCRIPTORS>   ENGINEERING, ELECTRONICS AND ELECTRICAL </DESCRIPTORS>
<ADVISER>   GEORGE A. BEKEY </ADVISER>
<CLASSIFICATIONS>   ARTIFICIAL INTELLIGENCE </CLASSIFICATIONS>
<ABSTRACT>
Qualitative physics, a subfield of Artificial
Intelligence (AI), is concerned with reasoning
qualitatively about physical systems. In particular,
qualitative simulation determines the qualitative
behavior of a physical system from its structural
description by reasoning from first principles using
domain model. However, qualitative simulation of complex
physical systems poses difficult problems. Reasoning is
slow because it is exponential to the number of
parameters in a physical system, and there are many
ambiguities due to the qualitative nature of the
reasoning. In addition, the resultant behavioral
description is large and difficult to interpret.
In this thesis, we show how reformulation of the
physical system in terms of functional aggregates can
greatly simplify its qualitative analysis. A functional
aggregate is a particular configuration of devices that
achieves a specific function. We describe a method
called the RFA method that consists of three principal
steps: (a) finding functional aggregates within the
given system, (b) reformulating the given system into an
aggregated physical system, and (c) model-based
reasoning with the aggregated system. Reformulation
based on functional aggregates simplifies the given
system by: (a) abstracting away the internal structures
of the functional aggregate, and (b) focusing on the
important functional constraints imposed by the
configuration of devices comprising a functional
aggregate.
The method has been implemented and demonstrated on
twenty examples from the electronics domain and five
examples from the refrigeration domain. The results are:
(a) For simple systems, direct qualitative analysis is
better. (b) Beyond a critical level of complexity, the
RFA method is better. For systems much more complex than
the critical level, the improvement is significant. (c)
The method may be bootstrapped using multiple levels of
functional aggregates of increasing complexity to
analyze even more complex physical systems. (Copies
available exclusively from Micrographics Department,
Doheny Library, USC, Los Angeles, CA 90089-0182.)
</ABSTRACT>
</THESIS>
<THESIS>
<NUMBER> 4186 </NUMBER>
<ORDER>   AAG0574337 </ORDER>
<TITLE>   LOGIC VERIFICATION AND SYNTHESIS USING FUNCTION GRAPHS </TITLE>
<AUTHOR>   LAI, YUNG-TE </AUTHOR>
<YEAR>   1993 </YEAR>
<INSTITUTION>   UNIVERSITY OF SOUTHERN CALIFORNIA; 0208 </INSTITUTION>
<DESCRIPTORS>   ENGINEERING, ELECTRONICS AND ELECTRICAL </DESCRIPTORS>
<ADVISER>   SARMA SASTRY; MASSOUD PEDRAM </ADVISER>
<CLASSIFICATIONS>   VLSI </CLASSIFICATIONS>
<ABSTRACT>
As scale of integration in scVLSI chips increases,
designers are paying more attention to the computational
efficiency of the scCAD tools. The key to developing
efficient algorithms is a concise, yet effective,
representation of functions. This function
representation must satisfy two important attributes:
canonicity and compactness. A canonical representation
simplifies the detection of function properties such as
unateness and symmetry checking. A compact
representation ensures the efficiency of function
manipulation.
Ordered Binary-Decision Diagram (scOBDD) is a compact,
canonical, graphical representation of Boolean
functions. scOBDDs have been used in many tasks
encountered in computer aided design, combinatorial
optimization, mathematical logic, and artificial
intelligence. While scOBDDs are very effective for
problems which can be solved through symbolic Boolean
manipulation, they are not so effective for those
requiring arithmetic operations in the integer domain.
This thesis presents a new data structure called Edge-
Valued Binary-Decision Diagram (scEVBDD) which can
represent and manipulate integer functions more
efficiently than the scOBDD representation. Because
Boolean functions are special cases of arithmetic
functions, scEVBDDs can also be used to represent
Boolean functions. With this property, scEVBDDs are
particularly useful for applications which require both
Boolean and integer operations. This thesis also
contains a number of applications which demonstrate the
effectiveness of the scEVBDDs and scOBDDs. These
applications include the following: showing the
equivalence between a Boolean function and an arithmetic
function, solving integer linear programming problems,
showing the equivalence between two Boolean functions
modulo input/output permutation, and function
decomposition for the synthesis of multilevel circuits
and look-up table based field programmable gate arrays.
(Copies available exclusively from Micrographics
Department, Doheny Library, USC, Los Angeles, CA 90089-
0182).
</ABSTRACT>
</THESIS>
<THESIS>
<NUMBER> 4187 </NUMBER>
<ORDER>   AAG0574285 </ORDER>
<TITLE>   A KNOWLEDGE-BASED PROGRAM FOR SELECTING PROBLEM SOLVING PARADIGMS </TITLE>
<AUTHOR>   WU, PENG </AUTHOR>
<YEAR>   1993 </YEAR>
<INSTITUTION>   MASSACHUSETTS INSTITUTE OF TECHNOLOGY; 0753 </INSTITUTION>
<DESCRIPTORS>   COMPUTER SCIENCE; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER>   RANDALL DAVIS </ADVISER>
<CLASSIFICATIONS>   NIL </CLASSIFICATIONS>
<ABSTRACT>
Knowledge based systems have been built for a wide
variety of application domains, but few areas of AI
itself have been explored in this manner. We are
building an expert system whose expertise is selecting
an appropriate problem solving paradigm (PSP) for a
task. It is capable of recommending a total of 1095
different variations of problem solving paradigms.
We use the phrase problem solving paradigm for any
identifiable problem solving process or its definition
at the task level in a sense similar to generic tasks.
For example, we consider that model-based diagnosis is a
PSP.
We believe PSP selection has a major impact on problem
solving, but has not been adequately addressed to date
in AI research. Most problem reformulation methods are
targeted to particular PSPs, thus leaving the PSP
selection issue virtually untouched. On the other hand,
AI research has been accumulating PSPs, usually
accompanied by informal statements as to the kind of
problems for which they are suitable.
In the thesis, we discuss PSP selection as part of
problem solving, describe a representation for PSPs, and
document the design and implementation of a knowledge
based system for selecting PSPs. We believe systems like
this will encourage PSP designers to be more precise
about the kind of problems for which their PSPs are
designed and will assist others in selecting appropriate
paradigms.
We also report work on PSP comparison and on relevance
analysis for PSP selection. (Copies available
exclusively from MIT Libraries, Rm. 14-0551, Cambridge,
MA 02139-4307. Ph. 617-253-5668; Fax 617-253-1690.)
</ABSTRACT>
</THESIS>
<THESIS>
<NUMBER> 4188 </NUMBER>
<ORDER>   AAG0574267 </ORDER>
<TITLE>   THEORETICAL ELEMENTS OF HIERARCHICAL CONTROL IN VERTEBRATE MOTOR SYSTEMS </TITLE>
<AUTHOR>   SANGER, TERENCE D. </AUTHOR>
<YEAR>   1993 </YEAR>
<INSTITUTION>   MASSACHUSETTS INSTITUTE OF TECHNOLOGY; 0753 </INSTITUTION>
<DESCRIPTORS>   COMPUTER SCIENCE; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER>   EMILIO BIZZI </ADVISER>
<CLASSIFICATIONS>   NEURAL NETWORKS </CLASSIFICATIONS>
<ABSTRACT>
The complexity of the control problem for vertebrate
movement may lead investigators to assume that the
controller which solves it must be similarly complex.
This assumption implies that electrophysiological
measurements from intermediate points in the functioning
controller may be difficult to interpret due to their
involvement in poorly understood computations. However,
if it can be shown that a controller based on simple
principles is capable of solving the problem, then
simpler models of the biological computation can be
proposed which may help to guide physiological research.
In this thesis, I describe models which use artificial
neural networks to learn certain computations involved
in the adaptive control of large-scale nonlinear
systems. These models find compact intermediate
representations of motor and sensory variables which
allow the creation of a hierarchy of subunits. Such a
hierarchy can divide the control problem into smaller
pieces that can be learned efficiently. Central to these
ideas is the concept of optimal unsupervised motor
learning, which specifies criteria for choosing an
internal representation. I develop algorithms which can
compute the optimal internal representation using only
observations of sensory and motor variables.
The purpose of the theoretical work is to demonstrate
the existence of simple algorithms which share some of
the impressive motor learning behaviors of vertebrate
motor systems. The feasibility of these algorithms is
demonstrated using simulations as well as a real two-
joint planar robot arm. (Copies available exclusively
from MIT Libraries, Rm. 14-0551, Cambridge, MA 02139-
4307. Ph. 617-253-5668; Fax 617-253-1690.)
</ABSTRACT>
</THESIS>
<THESIS>
<NUMBER> 4189 </NUMBER>
<ORDER>   AAGNN84037 </ORDER>
<TITLE>   ON PARALLEL DATA STRUCTURES AND PARALLEL GEOMETRIC APPLICATIONS FOR MULTICOMPUTERS </TITLE>
<AUTHOR>   RAU-CHAPLIN, ANDREW </AUTHOR>
<YEAR>   1993 </YEAR>
<INSTITUTION>   CARLETON UNIVERSITY (CANADA); 0040 </INSTITUTION>
<DESCRIPTORS>   COMPUTER SCIENCE </DESCRIPTORS>
<ADVISER>   NIL </ADVISER>
<CLASSIFICATIONS>   NIL </CLASSIFICATIONS>
<ABSTRACT>
This thesis focuses on the application of parallelism to
data structuring and geometric problems.
Data structure abstractions have played a vital role in
the development of efficient sequential algorithms. We
show that for a wide range of problems, parallel
versions of standard sequential data structures can be
constructed to yield highly efficient parallel
algorithms for distributed memory multicomputers. In the
context of parallel data structures, we study problems
from computational geometry, artificial intelligence,
image processing and solid modeling.
Geometric problems are of considerable importance in
robotics, solid modeling, vision, image processing, and
pattern recognition. In many cases, due to the
computationally intensive nature of these problems the
application of parallelism is of both practical and
theoretical interest. In this thesis we study geometric
problems including planar visibility, dominance, nearest
neighbor and convex hull problems and both uni-
directional and multi-dimensional geometric separability
problems. We also study optical clustering and the
construction and manipulation of multidimensional binary
images.
Our focus is on algorithms for distributed memory
multicomputers. In particular we give algorithms for
mesh, hypercube and coarse-grained architectures. PRAM
algorithms are also given when they arise from
distributed memory algorithms. In addition to standard
asymptotic analysis, this thesis also reports on
implementations of several of the proposed algorithms.
</ABSTRACT>
</THESIS>
<THESIS>
<NUMBER> 4190 </NUMBER>
<ORDER>   AAG9412367 </ORDER>
<TITLE>   CONCEPTUAL STRUCTURE: A MULTIPLE INHERITANCE CLASSIFICATION AND DESIGN SYSTEM </TITLE>
<AUTHOR>   MARK, EARL JONATHAN </AUTHOR>
<YEAR>   1993 </YEAR>
<INSTITUTION>   HARVARD UNIVERSITY; 0084 </INSTITUTION>
<DESCRIPTORS>   ARCHITECTURE; ARTIFICIAL INTELLIGENCE; COMPUTER SCIENCE </DESCRIPTORS>
<ADVISER>   NIL </ADVISER>
<CLASSIFICATIONS>   CLASSIFICATION SYSTEM, CAD </CLASSIFICATIONS>
<ABSTRACT>
Designers work by associating abstract concepts with
graphic representations. For example, an architect may
associate the concept "wall" with the drawing
of a rectangle. At the early stages of the design
process, the concept associated with a graphic
representation may be relatively ambiguous. The
"wall" may be of undetermined materials,
construction, elevation and structure. In other words,
the wall may be a kind of marble wall, or a kind of
brick wall, or a kind of wood frame wall, etc. It may be
transparent, translucent or opaque. It may be load
bearing or non-load bearing. These alternative
possibilities may exist in the mind of the architect.
The alternatives may also be annotated on an
architectural drawing. However, the typical computer
aided design system of today would not contain any
database reference to the wide set of possible kinds of
objects that the rectangle could be.
In this dissertation, a computer aided design system is
developed which provides for geometrical modeling and
which accounts for ambiguity. A "conceptual
structure" is provided in which an ambiguous
"child" object may inherit attributes from
many alternative kinds of "parent" objects.
The "conceptual structure" can accommodate a
design process through which a "child" object
such as "wall" can become less ambiguous over
time. The end of this process is the detailed
specification of the final designed object.
The computer aided design system adapts the the
artificial intelligence techniques of
"frames", and "multiple-
inheritance". It also adapts the conventional
computer aided design techniques of
"instantiation", and "parametric
variation". The system is applied to a set of case
studies, and tested with a focus on raytracing
architectural objects.
Within chapter 1, the rationale for a "conceptual
structure" is outlined with some examples. Chapter
2 provides a detailed description of the components of a
conceptual structure. Chapter 3 relates classification
systems used in architecture to the use of
classification within a conceptual structural. Chapter 4
describes "conceptual structure" with respect
to the design process. Within chapters 5 and 6, case
studies are developed after some historically well known
works of architecture. Chapter 7 compares the
"conceptual structure" with other knowledge
representation schemes that have been developed for
computer aided design. Working examples of the computer
aided design system are provided throughout the text.
</ABSTRACT>
</THESIS>
<THESIS>
<NUMBER> 4191 </NUMBER>
<ORDER>   AAG9412011 </ORDER>
<TITLE>   KNOWLEDGE-BASED INFORMATION SYSTEMS DEVELOPMENT WITH AN ORGANIZATIONAL PERSPECTIVE </TITLE>
<AUTHOR>   MANGAL, RAM KISHORE </AUTHOR>
<YEAR>   1993 </YEAR>
<INSTITUTION>   THE OHIO STATE UNIVERSITY; 0168 </INSTITUTION>
<DESCRIPTORS>   BUSINESS ADMINISTRATION, MANAGEMENT; COMPUTER SCIENCE; ARTIFICIAL INTELLIGENCE; INFORMATION SCIENCE </DESCRIPTORS>
<ADVISER>   HASAN PIRKUL </ADVISER>
<CLASSIFICATIONS>   NIL </CLASSIFICATIONS>
<ABSTRACT>
Information systems (IS) development and maintenance for
the organizations today is a complex task. They
typically require systems that are integrated,
internally consistent, and consistent with their latest
operational and other business practices. Highly complex
requirements, bounded rationality problem for
developers, and high personal turnover makes it
imperative that IS development and maintenance is
supported with an organizational perspective.
We present the Organizational Systems Development (OSD)
model and the organization model based systems
development method to intelligently support systems
development and maintenance in a knowledge-based
environment with an organizational perspective. Besides
the domain knowledge and the systems development
knowledge, we integrate the support for the
organizational knowledge and the organizational model in
the OSD environment to enable system development that is
highly reuse based, considers other IS in the
organization, and inherently supports integration.
The OSD model has two main processes--specification
development process and system synthesizer process. The
specification development process develops system-
specifications from user requirements and propagates
changes in specifications when modifications are
required. The system-synthesizer process generates an
executable system from the specifications.
We present the concepts of the organizational model as
integration of all system specifications in the
organization, and application views as a minimal subset
of the organization model that specifies the application
system completely. We use these concepts for the
organization model based IS development and show the
advantages like high reuse, high productivity, capture
of design knowledge, specification based maintenance,
consistent implementation of changes across IS, etc. We
present various algorithms required to manage views and
OM in the OM-based systems development. An object-
oriented representation is adopted to maximize the
benefits of the organization model.
For implementing the OSD model, we present an
architecture that supports import and export of the
knowledge that is not specific to the organization. We
use an expert system shell to implement the key
components and demonstrate the feasibility and
advantages of OM based approach.
</ABSTRACT>
</THESIS>
<THESIS>
<NUMBER> 4192 </NUMBER>
<ORDER>   AAG9411173 </ORDER>
<TITLE>   A DESCRIPTIVE FRAMEWORK FOR IDENTIFYING SCHEMATIC ELEMENTS AND PATTERNS IN CERTAIN SCIENCE AND ENGINEERING REPORTS </TITLE>
<AUTHOR>   BARTHOLOMEW, BARBARA E. </AUTHOR>
<YEAR>   1993 </YEAR>
<INSTITUTION>   NEW YORK UNIVERSITY; 0146 </INSTITUTION>
<DESCRIPTORS>   LANGUAGE, LINGUISTICS; EDUCATION, PSYCHOLOGY </DESCRIPTORS>
<ADVISER>   HARVEY NADLER </ADVISER>
<CLASSIFICATIONS>   SCIENCE REPORTS </CLASSIFICATIONS>
<ABSTRACT>
The place of prior knowledge in helping a reader to
construct a sense of what she is reading is well known.
Less explored as a research topic is the place of prior
knowledge in the writing process.
Building on the theoretical foundations of scheme theory
and text linguistics, this thesis provides evidence,
through text analyses, of a cognitive map employed by
expert science and technical report writers. An
expository knowledge map is revealed as a global text-
level scheme of six rule-governed elements. The macro,
global elements are identified as follows: (1)
Introduction; (2) Scope; (3) Problem, Process, Procedure
(one or more); (4) Discussion; (5) Solution; (6)
Conclusions.
This text-level scheme was determined to include two
subschema: a formal scheme that dictated the order in
which the elements could occur, and a content scheme,
which specified what type of information could be found
within each element's bounds. Taken as a whole, the
scheme is believed to at least partially account for the
rhetorical/cognitive information that expert (report)
writers have access to that enables them to create
continually new and various types of reports.
The importance of this work is myriad. As a
representation of the mental processes of experienced
writers, it is of value to those in the applied
linguistic, psychology, and artificial intelligence
fields. For teachers, it is a foundation on which to
build a teaching model for expository and descriptive
writing students. Because the framework reflects the
expert knowledge of native English speakers, it may
prove useful for English as a Second Language (ESL) and
English for Specific Purposes (ESP) instructors seeking
ways of bridging the contrastive rhetoric gap, and in
mixed population technical, report writing, and
expository writing classrooms.
</ABSTRACT>
</THESIS>
<THESIS>
<NUMBER> 4193 </NUMBER>
<ORDER>   AAG9410712 </ORDER>
<TITLE>   A KNOWLEDGE-BASED APPROACH TO REACTIVE SCHEDULING </TITLE>
<AUTHOR>   BHARADWAJ, ANANDHI S. </AUTHOR>
<YEAR>   1993 </YEAR>
<INSTITUTION>   TEXAS A&M UNIVERSITY; 0803 </INSTITUTION>
<DESCRIPTORS>   BUSINESS ADMINISTRATION, GENERAL; COMPUTER SCIENCE; OPERATIONS RESEARCH; HEALTH SCIENCES, HOSPITAL MANAGEMENT; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER>   ARUN SEN; AJAY VINZE </ADVISER>
<CLASSIFICATIONS>   SCHEDULING, CATHETERIZATION LABORATORIES </CLASSIFICATIONS>
<ABSTRACT>
This research proposes a new architecture for knowledge
based scheduling systems that operate in a dynamic
environment. The study is based on an analysis of a real
world scheduling problem, namely, the scheduling of
catheterization laboratories (cath labs) for cardiac
procedures in a large hospital. The hospital setting
provided a particularly useful proving ground for
research in scheduling and rescheduling due to the
volatile environment and the critical nature of the
events that occur in this environment. The problem is
representative of domains where the scheduling process
is complicated by a large number of potential
disruptions that could affect the planned schedule.
A software engineering methodology was adopted for the
research. A conceptual framework for the problem was
developed by synthesizing our understanding from two
perspectives: (a) an investigation of the scheduling
processes and practices adopted by the expert schedulers
in the real world setting using the protocol analysis
technique, and (b) studying the relevant disciplines for
approaches and ideas leading to system functionalities
for supporting the problem requirements. Applying the
prior Artificial Intelligence (AI) research in the areas
of opportunistic planning and reason maintenance
systems, a hybrid architecture that incorporates the
twin features was proposed. Opportunistic plan
strategies are used to incrementally construct the
schedule, while the reason maintenance technique helps
in schedule revision by undoing only parts of the
schedule that are affected whenever changes take place.
Based on the architecture, and employing the data from
the cath labs, a knowledge based system CLASS (Cath LAb
Scheduling System) was developed and tested. Field
testing of the system was carried out by having the
expert scheduler at the cath labs evaluate the system
functionality and output. The domain expert expressed
strong agreement with the scheduling and rescheduling
decisions of CLASS. The system was found to generate
schedules consistent with the objectives and constraints
of the domain, and to adjust well to the changing
circumstances of the environment.
</ABSTRACT>
</THESIS>
<THESIS>
<NUMBER> 4194 </NUMBER>
<ORDER>   AAG9409643 </ORDER>
<TITLE>   HOW STRATEGIES ARE LEARNED </TITLE>
<AUTHOR>   BRUDERER, ERHARD </AUTHOR>
<YEAR>   1993 </YEAR>
<INSTITUTION>   THE UNIVERSITY OF MICHIGAN; 0127 </INSTITUTION>
<DESCRIPTORS>   BUSINESS ADMINISTRATION, GENERAL; BUSINESS ADMINISTRATION, MANAGEMENT; ECONOMICS, THEORY; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER>   MICHAEL D. COHEN; WILL MITCHELL </ADVISER>
<CLASSIFICATIONS>   INTELLIGENT ORGANIZATIONS </CLASSIFICATIONS>
<ABSTRACT>
I propose that both individuals and organizations can
learn strategies in complex or ill-defined situations
more effectively, using the process of inductive versus
deductive reasoning.
To support this proposition, a theory of strategy
learning is developed, where a strategy consists of a
set of moves which can be combined many ways to respond
to business situations. Strategy learning is captured by
three basic processes: variation, adaptation, and
selection. My theory is implemented using a computer-
simulated game among artificial agents, with each agent
represented by a computer program capable of intelligent
learning. This game can make more significant
predictions for a reputation game than traditional game
theory. Computer simulation results are then compared
with results from corresponding economic experiments.
They indicate that sophisticated strategies such as
reputation building can be learned inductively.
Using computer simulation of the genetic algorithm, Part
II explores different hierarchical levels of
organizational evolution. In the case presented,
selection at the population level of analysis influenced
learning capabilities at the organizational level, while
the learning capabilities influenced the selection
process. Thus, it is crucial to understand how strategy
learning at these different organizational levels
interact with each other.
Part III discusses the importance of long chains of
strategy moves. A mathematical model demonstrates that
specific strategic instances can be identified
effectively with a "bottom-up" hierarchical
search, which first looks for the smallest, stable parts
of an action chain and then combines them into larger
and larger sub-strategies until the final strategy is
identified. This model can predict how humans learn
specific strategic instances when provided with
intermediate feedback. Empirical evidence from a pilot
experiment indicates that humans use hierarchical search
to discover action chains.
This work provides a theoretical foundation for the
evolution of intelligent organizations. If individuals
can learn sophisticated strategies inductively, then so
can organizations. Organizations should be able to
function like large, parallel-distributed information
systems, capable of learning strategies more effectively
and able to leverage their strategic decision-making
capabilities through the contribution of many
intelligent individuals.
</ABSTRACT>
</THESIS>
<THESIS>
<NUMBER> 4195 </NUMBER>
<ORDER>   AAG9409164 </ORDER>
<TITLE>   PRINCIPAL SELECTION: AN APPLICATION OF NEURAL-NETWORK FORECASTING </TITLE>
<AUTHOR>   STONE, WILLIAM STEVE </AUTHOR>
<YEAR>   1993 </YEAR>
<INSTITUTION>   NORTH CAROLINA STATE UNIVERSITY; 0155 </INSTITUTION>
<DESCRIPTORS>   EDUCATION, ADMINISTRATION; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER>   RAYMOND G. TAYLOR; JOHN L. KEEDY </ADVISER>
<CLASSIFICATIONS>   NIL </CLASSIFICATIONS>
<ABSTRACT>
The purpose of this study has been to apply neural-
network technology to the process of identifying
potentially successful local school administrators.
Using historical data taken from personnel files of a
North Carolina school district, a neural-network model
was built for two purposes: (1) to predict the
likelihood that candidates for administrative jobs will
be successful as administrators, and (2) to make a
judgment on whether neural-networks can improve a school
system's hiring practices for school administrators.
This model has application to the subject school system
only, but the method can be used to build models that
fit the uniqueness of any school district. Neural-
network technology is a fairly new science in the field
of knowledge discovery and forecasting. Neural-network
technology mimics the human brain's own problem-solving
process. Knowledge gained from past experiences is
applied to new problems or situations. Previously solved
examples are applied to build a system of
interconnecting neurons that makes new decisions,
classifications, and forecasts.
The study results indicate that neural-network
technology is a reliable predictor of administrative
success, and is an effective tool for decision-making in
the selection of school administrators.
</ABSTRACT>
</THESIS>
<THESIS>
<NUMBER> 4196 </NUMBER>
<ORDER>   AAG9408889 </ORDER>
<TITLE>   A MODEL FOR EXPLAINING AND PREDICTING THE EFFECTIVENESS OF MACHINE LEARNING TECHNIQUES </TITLE>
<AUTHOR>   KATTAN, MICHAEL WAYNE </AUTHOR>
<YEAR>   1993 </YEAR>
<INSTITUTION>   UNIVERSITY OF HOUSTON; 0087 </INSTITUTION>
<DESCRIPTORS>   BUSINESS ADMINISTRATION, MANAGEMENT; BUSINESS ADMINISTRATION, GENERAL; COMPUTER SCIENCE; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER>   NIL </ADVISER>
<CLASSIFICATIONS>   NEURAL NETWORKS </CLASSIFICATIONS>
<ABSTRACT>
Several recent studies have examined the effectiveness
of machine learning techniques.
As a first step in building such theoretical foundation,
a model based on the statistical prediction literature
is developed. This literature describes statistical
prediction as encompassing the following activities: (1)
problem specification, (2) data collection, (3) data
modeling, and (4) model application.
The model is then tailored to apply specifically to
classification decisions. Many managerial decisions
involve placing a case (e.g., a firm) into one of
multiple classes (e.g., likely to go bankrupt versus
likely to remain solvent) based on currently known
predictors concerning the case (e.g., financial ratios).
This restriction to classification decisions increases
the model is power, and the model still applies to the
majority of the empirical machine learning research.
Three example machine learning techniques (a
backpropagation neural network, ID3, and CART), as well
as the statistical technique, discriminant analysis, are
analyzed to determine how they are theoretically
affected by the factors of the model.
The empirical portion of this research consists of two
phases. The first phase concerns refinement of the
theoretical model, while the second phase provides
validation of the refined model. The result is a model
which provides an interval-level ranking of expected
technique effectiveness for classification decisions.
Validation of the model occurs in two forms. In one form
of validation, the factor effects of the model provide
hypotheses which are tested via analysis of variance
using the simulation results. Support is found for these
hypotheses. As another form of validation, the model is
applied by measuring the factor levels from a data set
with predictor variables ease-of-use and usefulness and
outcome variable software package use. Based on the
factor levels, the model is employed to obtain a ranking
of expected effectiveness for the three machine learning
techniques and discriminant analysis. Next, the actual
performance of the techniques is measured and compared
with the predictions of the model. The results are
statistically analyzed using analysis of variance to
test support for the model. General support is found,
and implications are discussed for researchers who
compare machine learning techniques, developers who
build new machine learning techniques, and practitioners
who use machine learning techniques. (Abstract shortened
by UMI.)
</ABSTRACT>
</THESIS>
<THESIS>
<NUMBER> 4197 </NUMBER>
<ORDER>   AAG1354796 </ORDER>
<TITLE>   PATH SEARCHING USING GENETIC ALGORITHMS </TITLE>
<AUTHOR>   WEI, JENNIFER YING-FAN </AUTHOR>
<YEAR>   1993 </YEAR>
<INSTITUTION>   CALIFORNIA STATE UNIVERSITY, LONG BEACH; 6080 </INSTITUTION>
<DESCRIPTORS>   COMPUTER SCIENCE; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER>   THINH V. NGUYEN </ADVISER>
<CLASSIFICATIONS>   NIL </CLASSIFICATIONS>
<ABSTRACT>
In this thesis, we investigate the application of
genetic algorithm in solving the path searching problem
in robotics. We formulate the solution of this problem
as a string of location coordinates in a two-dimensional
space from the starting location to the destination.
The GA approach to this problem consists of forming a
chromosome population and allowing the chromosomes to
evolve through reproduction, selection, crossing over
and mutations. We developed a new crossover operator
called the Path Recombination Crossover, to accommodate
the variable size chromosomes. We also introduce three
additional operators: deletion, insertion, and modified
mutation. The problem is simulated on a PC environment.
The results indicate that the GA approach provides
satisfactory solution without resulting to complex
analytical and heuristic rules.
We believe that this thesis is a step toward a more
comprehensive research in robotic path planning, three-
dimensional obstacle avoidance and other areas in
robotic navigation.
</ABSTRACT>
</THESIS>
<THESIS>
<NUMBER> 4198 </NUMBER>
<ORDER>   AAG1354573 </ORDER>
<TITLE>   ENHANCED TELEOPERATION OF A MOBILE ROBOT </TITLE>
<AUTHOR>   MARTENS, JOHN DOUGLAS </AUTHOR>
<YEAR>   1993 </YEAR>
<INSTITUTION>   CASE WESTERN RESERVE UNIVERSITY; 0042 </INSTITUTION>
<DESCRIPTORS>   ENGINEERING, ELECTRONICS AND ELECTRICAL; ENGINEERING, NUCLEAR; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER>   WYATT S. NEWMAN </ADVISER>
<CLASSIFICATIONS>   NIL </CLASSIFICATIONS>
<ABSTRACT>
The use of mobile robots plays an essential role in
removing humans from hazardous environments. Currently,
mobile robots of sufficient construction for hazardous
material handling lack the intelligence to be very
efficient. Since operators are controlling the robot on
a "low level" they are sidetracked from their
goals and cannot perform tasks quickly. The research
presented in this thesis is focused on giving such
mobile robots the necessary intelligence to perform
tasks automatically and thus free the operator for
concentrating on higher level tasks.
This thesis discusses many of the essential pieces of
transforming a teleoperated low level mobile robot into
a teleoperated high level mobile robot. It also
describes some of the necessary steps to create a
tetherless, autonomous robot with appropriate computing
power on board. Algorithms for performing automatic
tasks, such as following lines on the floor, tracking
other teleoperated vehicles and climbing stairs are
implemented and discussed.
</ABSTRACT>
</THESIS>
<THESIS>
<NUMBER> 4199 </NUMBER>
<ORDER>   AAG1354304 </ORDER>
<TITLE>   A PROTOTYPE EXPERT SYSTEM MODEL FOR THE DEVELOPMENT OF AN AUTOMATED PROCESS PLANNING SYSTEM FOR PRISMATIC PARTS </TITLE>
<AUTHOR>   GUBBA, RAMESH </AUTHOR>
<YEAR>   1993 </YEAR>
<INSTITUTION>   UNIVERSITY OF LOUISVILLE; 0110 </INSTITUTION>
<DESCRIPTORS>   ENGINEERING, INDUSTRIAL; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER>   NIL </ADVISER>
<CLASSIFICATIONS>   NIL </CLASSIFICATIONS>
<ABSTRACT>
A Prototype Expert System Model for the development of
an Automated Process Planning System for prismatic parts
is presented. An Expert System Shell known as CLIPS, has
been used to develop the prototype model. A part file is
manually developed for a test part based on the part
design. The part file is interfaced with the Expert
System Program to get the process plan for the test
part. The Expert System Program contains the necessary
information about Machine tools, Cutting tools etc. that
are to be used for performing various machining
operations. The Expert System Program contains the
necessary process planning logic required to develop
process plans for the test part as well as few other
prismatic parts. With few additions and modifications in
the Expert System Program, process plans can be
developed for some more variety of parts.
</ABSTRACT>
</THESIS>
<THESIS>
<NUMBER> 4200 </NUMBER>
<ORDER>   AAG1354300 </ORDER>
<TITLE>   ANALOG MEMORY FOR NEURAL NETWORKS </TITLE>
<AUTHOR>   CHANDRASEKARAN, MOULISHANKAR </AUTHOR>
<YEAR>   1993 </YEAR>
<INSTITUTION>   UNIVERSITY OF LOUISVILLE; 0110 </INSTITUTION>
<DESCRIPTORS>   ENGINEERING, ELECTRONICS AND ELECTRICAL; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER>   JACEK M. ZURADA </ADVISER>
<CLASSIFICATIONS>   NIL </CLASSIFICATIONS>
<ABSTRACT>
Neural networks can be made programmable, a feature
which is essential in such applications as learning
machines and programmable associative memories.
Programmability requires modification of the synapse
strengths. The vital issue in building hardware
implementation of a neural network is the mechanism to
represent and manipulate the synaptic weights. In
efficient hardware implementation, the synapses and the
network as a whole are analog due to high synapse
density. It is possible to achieve variable synapse
strengths by using array of elements for each synapse,
which can be programmed externally. The performance of
the network is to be preserved by memorizing these
strengths (weights). An attempt is made in this thesis
to assess the active analog memory to preserve the
weights for implementing analog neural networks. Analog
memory is a very important device in order to fully
integrate a large-scale learning network. Requirements
for an analog memory is discussed. Characteristics of an
active analog memory are described in detail and
simulations for various parameters of the memory is
carried out and the results were in par with the
theoretical reasonings.
</ABSTRACT>
</THESIS>
<THESIS>
<NUMBER> 4201 </NUMBER>
<ORDER>   AAG1354283 </ORDER>
<TITLE>   SUPERVISED AND UNSUPERVISED LEARNING APPLIED TO ROBOTIC MANIPULATOR CONTROL </TITLE>
<AUTHOR>   MCLAUCHLAN, LIFFORD LEE LANCASTER </AUTHOR>
<YEAR>   1993 </YEAR>
<INSTITUTION>   TEXAS A&I UNIVERSITY; 0510 </INSTITUTION>
<DESCRIPTORS>   ENGINEERING, ELECTRONICS AND ELECTRICAL; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER>   RAJAB CHALLOO </ADVISER>
<CLASSIFICATIONS>   NIL </CLASSIFICATIONS>
<ABSTRACT>
Intelligent robotic control can be accomplished using
neural networks. A backpropagation network (supervised
learning) and a Hebbian learning network (unsupervised
learning) are trained on the REMOTEC RM-10A robotic arm
data. The backpropagation is able to develop the inverse
kinematics relationships for the arm. The Hebbian does
but would require two weight sets. The backpropagation
trains to an error from 1-21% depending on the training
set size, momentum value, learning rate, neurons in a
hidden layer, and number of layers. The Hebbian
oscillates when trained on both x and y. Separately for
x the error is 30% and for y 13-17% with the Hebbian.
The backpropagation was then implemented with the
REMOTEC arm. However a few degrees of joint error
corresponds to a few inches in end effector
displacement. The backpropagation is able to
satisfactorily control the arm while the Hebbian is not.
The Hebbian does converge quickly while the
backpropagation requires 10000-30000 iterations. Changes
in network size and configuration usually have no effect
on the Hebbian while the backpropagation converges
slower when the network is more complex. Thus, overall
the better network is the backpropagation. However a
hybrid of the two could improve the overall performance
of a neural controller, increasing its speed and
accuracy.
</ABSTRACT>
</THESIS>
<THESIS>
<NUMBER> 4202 </NUMBER>
<ORDER>   AAG1354184 </ORDER>
<TITLE>   QUALITATIVE INTELLIGENT MODELING OF COMPLEX REACTIVE SYSTEMS. </TITLE>
<AUTHOR>   CARLEY, ERIC D. </AUTHOR>
<YEAR>   1993 </YEAR>
<INSTITUTION>   KANSAS STATE UNIVERSITY; 0100 </INSTITUTION>
<DESCRIPTORS>   ENGINEERING, INDUSTRIAL; ENGINEERING, SYSTEM SCIENCE; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER>   DAVID BEN-ARIEH </ADVISER>
<CLASSIFICATIONS>   VOLUMES I AND II </CLASSIFICATIONS>
<ABSTRACT>
This research presents a new modeling approach that
captures the structure, functionality, and behavior of
any reactive system. The model uses qualitative methods
based on causality and structural hierarchy to build
cause-effect relations between system components.
A new modeling methodology was developed called Object-
Oriented Functional Networks (OOFN). This new approach
uses unique modeling structures based on current
qualitative modeling approaches combined with knowledge
based representation from the area of artificial
intelligence. The methodology supports various types of
analysis that are important to discrete reactive
environments. Forward and backward reachability analysis
are performed by intelligent control algorithms.
A complete implementation of the OOFN modeling
methodology was performed using KEE (Knowledge
Engineering Environment - Intellicorp) with Common LISP
as the base programming language. The software contains
several algorithms based on the principles of artificial
intelligence that allow it to "intelligently"
assist a user during the model building process.
(Abstract shortened by UMI.)
</ABSTRACT>
</THESIS>
<THESIS>
<NUMBER> 4203 </NUMBER>
<ORDER>   AAGMM83408 </ORDER>
<TITLE>   A COMPARISON OF NEURAL NETWORK AND LOGISTIC REGRESSION MODELS FOR PREDICTING LENGTH OF STAY IN THE INTENSIVE CARE UNIT FOLLOWING CARDIAC SURGERY </TITLE>
<AUTHOR>   TU, JACK VEN </AUTHOR>
<YEAR>   1993 </YEAR>
<INSTITUTION>   UNIVERSITY OF TORONTO (CANADA); 0779 </INSTITUTION>
<DESCRIPTORS>   HEALTH SCIENCES, MEDICINE AND SURGERY; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER>   D. NAYLOR </ADVISER>
<CLASSIFICATIONS>   NIL </CLASSIFICATIONS>
<ABSTRACT>
A predictive instrument for length of stay in the
intensive care unit (ICU) following cardiac surgery
could assist in scheduling cardiac surgery operations
when ICU resources are limited. Two predictive
instruments were developed for predicting long ICU
stays, defined as a stay over 2 days, using a training
set of 713 patients: (1) an artificial neural network
model and (2) a logistic regression model/predictive
index. 5 unique risk strata were created using each
model and were validated in a test set of 691 patients.
Both models predicted long ICU stays with areas under
the Receiver Operating Characteristic (ROC) curve of
0.6948 (SE 0.0229) and 0.6992 (SE 0.0224) (p = 0.4283)
respectively. The logistic regression model/predictive
index also predicted other ICU length of stay durations
($>$4, $>$7, $>$10 days) and patient mortality.
Either model could potentially be used as a risk
stratification tool for counselling patients and
scheduling operations. Advantages and disadvantages of
using neural network and logistic regression modelling
techniques were explored.
</ABSTRACT>
</THESIS>
<THESIS>
<NUMBER> 4204 </NUMBER>
<ORDER>   AAGMM83407 </ORDER>
<TITLE>   QUERY OPTIMIZATION FOR KNOWLEDGE BASE MANAGEMENT SYSTEMS: A MACHINE LEARNING APPROACH </TITLE>
<AUTHOR>   JURISICA, IGOR </AUTHOR>
<YEAR>   1993 </YEAR>
<INSTITUTION>   UNIVERSITY OF TORONTO (CANADA); 0779 </INSTITUTION>
<DESCRIPTORS>   COMPUTER SCIENCE </DESCRIPTORS>
<ADVISER>   JOHN MYLOPOULOS </ADVISER>
<CLASSIFICATIONS>   NIL </CLASSIFICATIONS>
<ABSTRACT>
Efficient query processing is a critical issue in the
design of knowledge base management systems. Several
methods for query optimization already exist and have
been used for database management systems since the late
seventies. Some of these methods have also served as
starting points for the development of optimization
algorithms for knowledge base management systems. More
recently, machine learning algorithms have been proposed
as a promising artificial intelligence application
contribution to the theory of query optimization.
This thesis proposes new machine learning applications
to optimize queries in a knowledge base management
systems. In particular, a machine learning algorithm
initially described in (Cohen and Greiner, 1991) is
adopted, extended and tested. The algorithm, called P
scALO (Probably Approximately Locally Optimal), is a
general model of a learning system and is directly
applicable to a variety of systems as a speedup learning
module. The algorithm is based on the theoretical work
of Valiant (Valiant, 1984) and uses statistical
information to produce a close approximation of a
locally optimal search strategy.
Some additions are made to the original version of the
algorithm, to solve a broader range of problems. In
addition, the termination condition in the algorithm is
changed in order to make it run faster without any
degradation of its performance. The learning module is
implemented and its integration into an architecture of
a knowledge base management system is shown. The
proposed optimization technique is tested with real and
artificial examples to establish its effectiveness.
</ABSTRACT>
</THESIS>
<THESIS>
<NUMBER> 4205 </NUMBER>
<ORDER>   AAGMM83084 </ORDER>
<TITLE>   EXPERT SELF ORGANIZING NEURAL NETWORK FOR THE DESIGN OF CELLULAR MANUFACTURING SYSTEMS </TITLE>
<AUTHOR>   ANANDA RAO, HARISH </AUTHOR>
<YEAR>   1993 </YEAR>
<INSTITUTION>   UNIVERSITY OF CALGARY (CANADA); 0026 </INSTITUTION>
<DESCRIPTORS>   ENGINEERING, MECHANICAL </DESCRIPTORS>
<ADVISER>   P. GU </ADVISER>
<CLASSIFICATIONS>   NIL </CLASSIFICATIONS>
<ABSTRACT>
The design of cellular manufacturing systems offers a
unique challenge in its diversity and complexity. The
numerosity of the problems presented by this nascent
field has led researchers to explore areas ranging from
the basic methodology used for machine-component
grouping to the socio-technical aspects involved during
the implementation of cellular manufacturing systems.
Most methods and algorithms developed for machine cell
design make some assumptions such as the availability of
sufficient duplicate machines and adequate machine
capacity. These assumptions can render the solutions non-
implementable.
This thesis presents three methods using artificial
intelligence techniques for the design of cellular
manufacturing systems. The first two algorithms deal
with cell formation based on the data from production
flow analysis chart, and the third method can design
cells considering practical constraints such as machine
capacity restriction, limit on the number of duplicate
machines available, component processing time, set-up
cost, material handling cost and alternate process
plans.
The approaches presented are original contributions to
the field of cellular manufacturing and have been tested
and compared against some of the other algorithms
available in literature. The results obtained indicate a
successful application of the algorithms developed and
its flexibility to deal with multiple objectives at the
design stage. This is crucial for the development of
algorithms which can offer practically implementable
solutions.
</ABSTRACT>
</THESIS>
<THESIS>
<NUMBER> 4206 </NUMBER>
<ORDER>   AAG9409179 </ORDER>
<TITLE>   STRENGTHENING HEURISTIC KNOWLEDGE IN A* SEARCH </TITLE>
<AUTHOR>   GREGOR, ANNA BRAMANTI </AUTHOR>
<YEAR>   1993 </YEAR>
<INSTITUTION>   WRIGHT STATE UNIVERSITY; 1131 </INSTITUTION>
<DESCRIPTORS>   COMPUTER SCIENCE; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER>   HENRY W. DAVIS </ADVISER>
<CLASSIFICATIONS>   MACHINE LEARNING </CLASSIFICATIONS>
<ABSTRACT>
Search is an important component of problem solving in
artificial intelligence. In difficult problems heuristic
search is used to reduce combinatorial explosion. The
most commonly used heuristic search algorithm is A*. The
role of the heuristic function in A* is critical because
it determines time and space complexity as well as
solution quality.
This thesis is concerned with methods for strengthening
the information made available to A* from its heuristic
function. Our methods are based on the idea that
statistical information obtained from A* search trees
may be used to substantially improve a heuristic, even
while search is in progress. We apply this idea to two
situations: (1) We assume optimal or near optimal
solutions are desired. Statistical information is used
to transform a heuristic function into one which causes
A* to meet this need. (2) We assume that optimality is
not essential if solution error is small and predictable
while the search is fast. To this end, statistical
information is used to combine features into a heuristic
which accurately estimates distance to goal. Our main
tool in this situation is linear regression. An
advantage to our approach is that it enables a
probabalistic assessment of the error to be incurred
when the heuristic so built is used by A*.
Our techniques are general. Their effectiveness is
demonstrated in two dissimilar families of state space
graphs: sliding tiles and TSP. High quality solutions at
low cost in node expansion are observed in both domains.
In addition, observed solution errors are consistent
with those predicted by our model when statistically
learned accurate heuristics are used by A*.
</ABSTRACT>
</THESIS>
<THESIS>
<NUMBER> 4207 </NUMBER>
<ORDER>   AAG9408927 </ORDER>
<TITLE>   AN ELECTRIC LOAD FORECASTING APPROACH USING EXPERT SYSTEMS AND ARTIFICIAL NEURAL NETWORKS </TITLE>
<AUTHOR>   MOHARARI, NADER SHARIAT </AUTHOR>
<YEAR>   1993 </YEAR>
<INSTITUTION>   GEORGIA INSTITUTE OF TECHNOLOGY; 0078 </INSTITUTION>
<DESCRIPTORS>   ENGINEERING, ELECTRONICS AND ELECTRICAL; PHYSICS, ELECTRONICS AND ELECTRICITY; BIOLOGY, NEUROSCIENCE; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER>   ATIF S. DEBS </ADVISER>
<CLASSIFICATIONS>   NIL </CLASSIFICATIONS>
<ABSTRACT>
The knowledge of accurate electric load demand is
desirable for a variety of reasons. Smooth and economic
operation of power systems is dependent upon reliable
load forecasting. Large errors in load estimates could
be costly. While accurate electric load forecasting will
help in reducing operating costs by arranging to
maintain and run the most economic generating plants to
meet consumer demand at any time.
In this dissertation a short-term load forecasting model
is introduced (Rule-Based ANN model). The model makes
use of Artificial Neural Networks (ANN) and Expert
Systems (ES). In the proposed model an auxiliary network
(sub net), driven by the ES has been utilized to adjust
the biases for the main network. The Expert System is
based on a set of rules which have been established
according to an analysis of historical patterns. The
role of ES is to tune the input components for the
auxiliary net.
The general forecasting process is as follows: the raw
data files act as input for the Expert System. Then
based on the rules and information available in the raw
data files the ES goes through a reasoning process in
order to prepare the processed data files for both
auxiliary and main networks. These processed data files
are then introduced to the ANN for training and
prediction purposes.
The model is capable of hourly load forecasting for the
next 168 hours which is necessary for unit commitment.
The model is also able to predict daily peak load for
one week ahead. Evaluation tests have proven the
viability of this approach. The results generated by
this model have been compared with some other production
grade packages in most cases the Rule-Based ANN model
has performed superior.
</ABSTRACT>
</THESIS>
<THESIS>
<NUMBER> 4208 </NUMBER>
<ORDER>   AAG9408920 </ORDER>
<TITLE>   A LEARNING MODEL ADAPTIVE ESTIMATOR FOR AN AUTOMATED GUIDED VEHICLE </TITLE>
<AUTHOR>   LAPIN, BRETT DENTON </AUTHOR>
<YEAR>   1993 </YEAR>
<INSTITUTION>   GEORGIA INSTITUTE OF TECHNOLOGY; 0078 </INSTITUTION>
<DESCRIPTORS>   ENGINEERING, ELECTRONICS AND ELECTRICAL; COMPUTER SCIENCE; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER>   ATIF DEBS </ADVISER>
<CLASSIFICATIONS>   MOBILE ROBOT </CLASSIFICATIONS>
<ABSTRACT>
An adaptive estimator and a learning system were
researched and developed to enhance the position
estimation capabilities of a landmark-tracking mobile
robot. The need for two adaptation subsystems for
advanced position estimation is a direct consequence of
the two inherent situations affecting a vehicle. For
positional errors which consistently recur during
operation, a system identification process was developed
in which general system parameters were estimated to
adapt to recurring errors as the robot traversed its
path. A maximum-likelihood estimation scheme was
incorporated into the vehicle's navigation system to
accomplish the system identification. For intermittent
positional errors resulting from regional anomalies, a
learning system was developed to deal with the errors. A
neural network scheme was used to affect the learning of
the error characteristics and occurrences. This
knowledge was then used to correct the vehicle's
behavior during the appropriate path segments.
Results of simulation and implementation tests indicated
that both algorithms work well. The simulations were
performed with and without noise perturbations, with
excellent results for both algorithms in both
situations. Results of implementing the algorithms on
the vehicle showed that the proposed adaptive estimator
and learning system can be used in an effective way to
enhance the accuracy of a mobile robot's position
estimation process by calibrating the navigation system
model and by diminishing regionally dependent positional
errors.
</ABSTRACT>
</THESIS>
<THESIS>
<NUMBER> 4209 </NUMBER>
<ORDER>   AAG9408916 </ORDER>
<TITLE>   NEURAL NETWORK HARDWARE WITH RANDOM WEIGHT CHANGE LEARNING ALGORITHM </TITLE>
<AUTHOR>   HIROTSU, KENICHI </AUTHOR>
<YEAR>   1993 </YEAR>
<INSTITUTION>   GEORGIA INSTITUTE OF TECHNOLOGY; 0078 </INSTITUTION>
<DESCRIPTORS>   ENGINEERING, ELECTRONICS AND ELECTRICAL; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER>   MARTIN A. BROOKE </ADVISER>
<CLASSIFICATIONS>   VLSI CHIP </CLASSIFICATIONS>
<ABSTRACT>
The objective of the presented research is to fabricate
neural network hardware with on-chip parallel learning.
Although many researchers have been engaged in this
area, few networks have been fabricated with learning
algorithms. A learning algorithm is required to be
implement on a VLSI chip because off-chip learning with
a digital computer consumes too much time to be applied
to practical problems. The main obstacle to implementing
a learning algorithm is the complexity of the proposed
algorithms. Current learning algorithms require
multiplication, summation, and derivative, which are
very difficult to implement in analog circuits without
non-idealities such as offset, nonlinearity and so on.
Therefore, a learning algorithm which is well suited to
VLSI implementation is proposed and the immunity of the
algorithm to analog non-idealities are demonstrated by
simulation. Very simple and small component circuits
which compose a neural network are developed for this
learning algorithm. 10 inputs x 10 outputs neural
networks with on-chip learning are fabricated and the
functionality is evaluated.
</ABSTRACT>
</THESIS>
<THESIS>
<NUMBER> 4210 </NUMBER>
<ORDER>   AAG9408625 </ORDER>
<TITLE>   IN SEARCH OF OPTIMAL HUMAN-EXPERT SYSTEM EXPLANATIONS: EMPIRICAL STUDIES OF HUMAN-HUMAN AND HUMAN-EXPERT SYSTEM INTERACTIONS </TITLE>
<AUTHOR>   HALGREN, SHANNON LEE </AUTHOR>
<YEAR>   1993 </YEAR>
<INSTITUTION>   RICE UNIVERSITY; 0187 </INSTITUTION>
<DESCRIPTORS>   PSYCHOLOGY, EXPERIMENTAL; COMPUTER SCIENCE; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER>   NANCY J. COOKE </ADVISER>
<CLASSIFICATIONS>   EXPERT SYSTEMS </CLASSIFICATIONS>
<ABSTRACT>
In this project explanations were studied along a
continuum ranging from human-human interactions to human-
expert system interactions with the goal of identifying
features of successful expert system explanations. The
project consisted of five distinct phases or steps: (a)
defining what a successful explanation entails, (b)
observing human-human explanation and formulating
hypotheses about the features of successful
explanations, (c) testing hypotheses formulated in step
b, (d) extending results to an expert system domain and
testing again, and (e) from this empirical data,
formulating recommendations for expert system
explanation designers. The progressive nature of this
study allowed conclusions to be drawn about both human-
human and human-expert system interactions and the role
explanations play in these exchanges. The most salient
conclusion drawn from these studies was that explanatory
interactions are complex and explanation success is
dependent on more than just features of the explanations
involved. Individual differences such as an explanation
recipient's initial abilities and their participation
level in the interaction influence their understanding
and performance as much, if not more so, than
explanation features. Consistently subjects'
participation level interacted with explanation content
level. Individuals who are active participants in
interactions with an expert perform better when given
explanations with low levels of content, whereas passive
participants benefit from explanations with high levels
of content. Overall, an active participation level
increases performance and understanding in human-human
interactions, but this result does not generalize to
human-expert system interactions where an active
participation style is detrimental to performance. This
and other inconsistencies between human-human and human-
expert system interactions are discussed as well as the
advantages of the research approach employed in this
project. Finally, recommendations based on the results
of these studies are provided for expert system
explanation designers.
</ABSTRACT>
</THESIS>
<THESIS>
<NUMBER> 4211 </NUMBER>
<ORDER>   AAG9408241 </ORDER>
<TITLE>   MARPLE: AN AUTONOMOUS DIAGNOSTICIAN FOR ISOLATING SYSTEM HARDWARE FAILURES </TITLE>
<AUTHOR>   FESQ, LORRAINE M. </AUTHOR>
<YEAR>   1993 </YEAR>
<INSTITUTION>   UNIVERSITY OF CALIFORNIA, LOS ANGELES; 0031 </INSTITUTION>
<DESCRIPTORS>   COMPUTER SCIENCE; ENGINEERING, GENERAL; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER>   LAWRENCE P. MCNAMEE </ADVISER>
<CLASSIFICATIONS>   NIL </CLASSIFICATIONS>
<ABSTRACT>
As we become more reliant on technology such as
aircraft, communication satellites, and power plants, we
must find ways to quickly detect and isolate the source
of system malfunctions. This dissertation presents and
demonstrates techniques to automate the diagnostic
process to identify hardware malfunctions. The research
is founded on the model-based reasoning concept called
constraint suspension, which was originally developed to
diagnose digital systems. The design presented here
extends constraint suspension in a number of ways, and
has been implemented in a computer program called
Marple.
First, we analyze the challenges introduced when moving
from the digital to the analog domain, and present
solutions to these challenges. Next, we examine the
concept of diagnostic resolution and develop a means to
automatically determine a hardware system's
diagnosability. This capability provides Marple with the
knowledge of its own diagnostic limitations, and
significantly reduces the number of its mis-diagnoses.
Third, we examine and undertake the challenges involved
in diagnosing systems which contain feedback. Finally,
in order to diagnose large, complex systems containing
hundreds or even thousands of components and sensors, we
present a hyper-dimensional approach to modeling that
captures sub-system knowledge in multiple models. These
concepts were implemented in the Marple program and
verified against spacecraft simulators of the power and
attitude control sub-systems.
</ABSTRACT>
</THESIS>
<THESIS>
<NUMBER> 4212 </NUMBER>
<ORDER>   AAG9408166 </ORDER>
<TITLE>   OPERATIONAL RATIONALITY THROUGH COMPILATION OF ANYTIME ALGORITHMS </TITLE>
<AUTHOR>   ZILBERSTEIN, SHLOMO </AUTHOR>
<YEAR>   1993 </YEAR>
<INSTITUTION>   UNIVERSITY OF CALIFORNIA, BERKELEY; 0028 </INSTITUTION>
<DESCRIPTORS>   COMPUTER SCIENCE; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER>   STUART J. RUSSELL </ADVISER>
<CLASSIFICATIONS>   NIL </CLASSIFICATIONS>
<ABSTRACT>
An important and largely ignored aspect of real-time
decision making is the capability of agents to factor
the cost of deliberation into the decision making
process. I have developed an efficient model that
creates this capability. The model uses as basic
components anytime algorithms whose quality of results
improves gradually as computation time increases. The
main contribution of this work is a compilation process
that extends the property of gradual improvement from
the level of single algorithms to the level of complex
systems.
In standard algorithms, the fixed quality of the output
allows for composition to be implemented by a simple
call-return mechanism. However, when algorithms have
resource allocation as a degree of freedom, there arises
the question of how to construct, for example, the
optimal composition of two anytime algorithms, one of
which feeds its output to the other. This scheduling
problem is solved by an off-line compilation process and
a run-time monitoring component that together generate a
utility maximizing behavior. The crucial meta-level
knowledge is kept in the anytime library in the form of
conditional performance profiles. These profiles
characterize the performance of each elementary anytime
algorithm as a function of run-time and input quality.
The compilation process therefore extends the principles
of procedural abstraction and modularity to anytime
computation. Its efficiency is significantly improved by
using local compilation that works on a single program
structure at a time. Local compilation is proved to
yield global optimality for a large set of program
structures.
Compilation produces contract algorithms which require
the determination of the total run-time when activated.
Some real-time domains require interruptible algorithms
whose total run-time is unknown in advance. An important
result of this work is a general method by which an
interruptible algorithm can be constructed once a
contract algorithm is compiled. Finally, the notion of
gradual improvement of quality is extended to sensing
and plan execution and the application of the model is
demonstrated through a simulated robot navigation
system. The result is a modular approach for developing
real-time agents that act by performing anytime actions
and make decisions using anytime computation.
</ABSTRACT>
</THESIS>
<THESIS>
<NUMBER> 4213 </NUMBER>
<ORDER>   AAG9408140 </ORDER>
<TITLE>   A LYAPUNOV METHOD FOR CORRELATIONAL LEARNING IN TWO LAYER NEURAL NETWORKS </TITLE>
<AUTHOR>   TROYER, TODD WILLIAM </AUTHOR>
<YEAR>   1993 </YEAR>
<INSTITUTION>   UNIVERSITY OF CALIFORNIA, BERKELEY; 0028 </INSTITUTION>
<DESCRIPTORS>   MATHEMATICS; BIOLOGY, NEUROSCIENCE; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER>   MORRIS W. HIRSCH </ADVISER>
<CLASSIFICATIONS>   NIL </CLASSIFICATIONS>
<ABSTRACT>
A class of two layer networks is defined. There are
feedforward connections between input and output layers
and lateral connections within the output layer. A
single input to the network consists of fixed pattern of
activation in the input layer. The lateral weights are
fixed and symmetric and constrained so that for any
given input pattern x and feedforward weight matrix W,
the activation dynamics within the output layer has a
globally attracting equilibrium $ z = F(x, W).$ Input
patterns are chosen ergodically from a fixed, finite set
and each feedforward weight is changed or learned
according to the average correlation of activity at
either end of the connection.
The main result of the dissertation is to produce a
Lyapunov function for the averaged learning equations
for this class of neural networks. In addition, two
saturation results are proved concerning existence of
solutions in which outputs are near their limiting
values.
These results are applied to networks with two different
patterns of lateral connectivity. In the first
application, uniform lateral inhibition is used to
implement "soft competition" within a layer of
category detecting nodes; algebraic conditions on the
resulting categories are derived. In the second network,
both the input layer and output layer consist of a one
dimensional "ring" of nodes and the lateral
connectivity is "center-surround". A
topographic solution for this network is a locally
stable configuration of the feedforward weight matrix in
which the input/output function F commutes with
translation. A geometrical representation of existence
conditions for such solutions is presented.
Assuming a high degree of symmetry and synchrony, the
method is extended to include the amplitude equations
for networks with oscillatory dynamics. Finally, it is
shown how the structure of the Lyapunov function
suggests a general approach to a broader class of such
two layer networks.
</ABSTRACT>
</THESIS>
<THESIS>
<NUMBER> 4214 </NUMBER>
<ORDER>   AAG9407919 </ORDER>
<TITLE>   PROBABLY APPROXIMATELY CORRECT LEARNING ON THE CLASS OF LIPSCHITZ FUNCTIONS </TITLE>
<AUTHOR>   COOPER, DUANE ANTHONY </AUTHOR>
<YEAR>   1993 </YEAR>
<INSTITUTION>   UNIVERSITY OF CALIFORNIA, BERKELEY; 0028 </INSTITUTION>
<DESCRIPTORS>   MATHEMATICS; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER>   MORRIS W. HIRSCH </ADVISER>
<CLASSIFICATIONS>   NONLINEAR MAPPING </CLASSIFICATIONS>
<ABSTRACT>
In the study of neural networks, we are often concerned
with a system's ability to reliably learn functions. Of
particular pertinence to this thesis is a network's
ability to reliably learn nonlinear mappings having both
uncountable domain and range. Such mappings arise in
applications involving robotics, machine vision, speech
processing, and graphics.
A network learns a function by approximating its value,
typically within some small $epsilon,$ when presented an
arbitrary element of the domain. For reliable learning,
the network should accurately return the function's
value with high probability, typically higher than $1 -
delta$ for some small $delta$. The Probably
Approximately Correct (PAC) model of learning is a
recent standard of analysis utilized by learning
theorists.
Mathematical analysis of learning over uncountable
domain and range is necessarily restricted to
consideration of particular classes of functions.
Restricting the analysis to the class of Lipschitz
functions is attractive in that the Lipschitz condition,
which merely bounds the rate of change, is perhaps the
weakest restriction we can impose to determine
significant conditions and bounds on the capabilities of
a network to learn functions.
The focal results of this thesis are the derivations of
bounds showing that, given $epsilon$ and $delta$ and an
arbitrary Lipschitz function $f: lbrack 0,1rbracksp{k}
to Re$, $$m ge (3M sqrt{k})sp{k} cdot
({1overepsilon})sp{k} cdot (k {rm ln} 3Msqrt{k} + k {rm
ln} {1overepsilon} + {rm ln} {1overepsilon})$$samples
from the uniform distribution on (0, 1) $sp{k}$ are
sufficient to reliably learn f, and that $$m ge
({Mover2}sqrt{k})sp{k} cdot ({1overepsilon})sp{k} cdot
{rm ln} {1overdelta}$$samples are necessary for reliable
learning. We exploit the Delaunay triangulation
technique which necessarily keeps simplex sizes small.
Similar analysis is presented for learning on the $Csp2$
and Holder function classes.
</ABSTRACT>
</THESIS>
<THESIS>
<NUMBER> 4215 </NUMBER>
<ORDER>   AAG9407910 </ORDER>
<TITLE>   EVALUATION OF HETEROGENEOUS ARCHITECTURES FOR ARTIFICIAL NEURAL NETWORKS </TITLE>
<AUTHOR>   CHINRUNGRUENG, CHEDSADA </AUTHOR>
<YEAR>   1993 </YEAR>
<INSTITUTION>   UNIVERSITY OF CALIFORNIA, BERKELEY; 0028 </INSTITUTION>
<DESCRIPTORS>   ENGINEERING, ELECTRONICS AND ELECTRICAL; COMPUTER SCIENCE; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER>   CARLO H. SEQUIN </ADVISER>
<CLASSIFICATIONS>   GRADIENT DESCENT </CLASSIFICATIONS>
<ABSTRACT>
Existing monolithic artificial neural network
architectures are not sufficient to cope with large
complex problems. A better approach is to build large
scale heterogeneous networks using both supervised and
unsupervised learning modules. In these architectures an
unsupervised learning algorithm, such as the k-means
algorithm, decomposes the overall task and a supervised
learning algorithm, such as one based on gradient
descent, solves each subtask.
We have investigated heterogeneous architectures that
are based on a novel k-means partitioning algorithm that
integrates into its partitioning process information
about the input distribution as well as the structures
of the goal function and expert modules. We have also
added two new mechanisms to our k-means algorithm. The
first mechanism biases the partitioning process toward
an optimal distribution of the approximation errors in
the various sub-domains. This leads to a consistently
lower overall approximation error. The second mechanism
adjusts the learning rate dynamically to match the
instantaneous characteristics of a problem; the learning
rate is large at first, allowing rapid convergence, and
then decreases in magnitude as the adaptation converges.
This results in a lower residual error and makes the new
k-means algorithm also viable for non-stationary
situations.
We evaluate the performance and complexity of these
heterogeneous architectures and compare them to
homogeneous radial basis function architectures and to
multilayer perceptrons trained by the error back-
propagation algorithm. The evaluation shows that the
heterogeneous architectures give higher performance with
lower system complexity when solving the Mackey-Glass
time series prediction problem and a hand-written
capital letter recognition task.
</ABSTRACT>
</THESIS>
<THESIS>
<NUMBER> 4216 </NUMBER>
<ORDER>   AAG9407847 </ORDER>
<TITLE>   A SHELL FOR DOMAIN INDEPENDENT INTELLIGENT HELP SYSTEMS </TITLE>
<AUTHOR>   YANG, GI-CHUL </AUTHOR>
<YEAR>   1993 </YEAR>
<INSTITUTION>   UNIVERSITY OF MISSOURI - KANSAS CITY; 0134 </INSTITUTION>
<DESCRIPTORS>   COMPUTER SCIENCE; LANGUAGE, LINGUISTICS </DESCRIPTORS>
<ADVISER>   NIL </ADVISER>
<CLASSIFICATIONS>   NIL </CLASSIFICATIONS>
<ABSTRACT>
The theory, design, and implementation of a shell for
domain independent intelligent help systems, along with
a survey of some intelligent help systems, is presented
in this document. Typical intelligent help systems are
dependent on the application domains since they have
concrete low-level knowledge representation language for
their knowledge base. This concrete language works in a
limited area only, confining the flexibility of the
knowledge base and causing a problem when the
application domain is changed. In order to solve this
problem, a system must have a flexible knowledge base.
The proposed knowledge base incorporates two levels: a
logical level which enables reasoning, and a heuristic
level which preserves efficiency and flexibility.
The proposed system is called UNIversal HELP (UNIHELP).
UNIHELP comprises the two levels and solves the
knowledge acquisition bottleneck problem by using Direct
Knowledge Acquisition Mechanism (DKAM) which works on
both the logical and heuristic level. Consequently, it
maintains a flexible knowledge base called UNIversal
Knowledge Base (UNIK). UNIK can be accessed from both
levels of UNIHELP to achieve the maximum efficiency in
terms of speed and quality of the answer. Unlike the
knowledge acquisition mechanism which uses a fixed
script, DKAM works for learning completely new concepts
and allows us to put natural intelligence on the
artificial intelligence systems without separation.
Natural language query is translated into conceptual
graphs and it is used as a key for retrieving the
corresponding plan from the knowledge base. The
retrieving is done by matching an input conceptual graph
to the conceptual graphs in the knowledge base. An
efficient conceptual graph matching algorithm is
presented in this document. The request understander
which uses a deterministic parsing technique, has
advantages of both a knowledge-based system and a
grammar-based system. An inferencing scheme which can be
used in a distributed computing environment is
presented. This way the system can be extended into a
distributed help system.
A prototype shell is presented to demonstrate some
salient features of the type of proposed intelligent
help system in this thesis.
</ABSTRACT>
</THESIS>
<THESIS>
<NUMBER> 4217 </NUMBER>
<ORDER>   AAG9407718 </ORDER>
<TITLE>   MULTI-LEVEL NEURAL NETWORKS, THEIR APPLICATIONS AND VLSI CIRCUIT IMPLEMENTATION </TITLE>
<AUTHOR>   YUH, JEN-DONG </AUTHOR>
<YEAR>   1993 </YEAR>
<INSTITUTION>   UNIVERSITY OF MARYLAND COLLEGE PARK; 0117 </INSTITUTION>
<DESCRIPTORS>   ENGINEERING, ELECTRONICS AND ELECTRICAL; ARTIFICIAL INTELLIGENCE; COMPUTER SCIENCE; BIOLOGY, NEUROSCIENCE </DESCRIPTORS>
<ADVISER>   ROBERT W. NEWCOMB </ADVISER>
<CLASSIFICATIONS>   NIL </CLASSIFICATIONS>
<ABSTRACT>
This research gives design formulations for VLSI multi-
level neural networks. VLSI implementation of them in
CMOS and BiCMOS technologies are demonstrated
respectively to show the feasibility of VLSI
implementation of multi-level neural networks. In
addition, applications of multi-level neural networks in
a variety of areas are accomplished and demonstrated.
For the purpose of hypothesizing theories of multi-level
neural networks, mathematical equations for multi-level
nonlinearities, multi-level neurons and multi-level
neural networks are developed. In addition, energy
functions and necessary properties for fully connected
multi-level neural networks and multi-level
bidirectional neural networks are introduced and
developed. For multi-level feed-forward neural networks,
a training algorithm is proposed using gradient descent
method.
To show the success of multi-level neural network
applications, a counter circuit design using a multi-
level neuron and an A/D converter design using a multi-
level neural network are given as examples. This neural
counter can also be used as a multi-valued memory
device. The multi-level neural network A/D converter
design results in reduction of a number of neural
network weights and the size of neural networks needed
as previously found in two-level neural networks. In
addition, a multi-level A/D converter is considered by
using simple optimization. It demonstrates a way of
training multi-level neural networks in optimization
problems. A general method for eliminating local minima
problems for multi-level A/D conversion is introduced
and proven to be effective. Spice3e1 simulations of 4-
level neural A/D converters are shown. A Computer Aided
Design for a 4-level neural A/D converter is carried out
and fabricated on a chip via the MOSIS BiC-MOS process.
Individual component measurements of this 4-level neural
A/D converter chip are carried out and shown in this
thesis. Finally, solving pattern recognition problems
using feed-forward multi-level neural networks is
accomplished and comparisons of solving pattern
recognition problems using two-level neural networks and
multi-level neural networks are given.
</ABSTRACT>
</THESIS>
<THESIS>
<NUMBER> 4218 </NUMBER>
<ORDER>   AAG9407707 </ORDER>
<TITLE>   PRIORITY PROGRAMMING FOR TRANSPORTATION NETWORKS USING ARTIFICIAL NEURAL NETWORKS </TITLE>
<AUTHOR>   WEI, CHIEN-HUNG </AUTHOR>
<YEAR>   1993 </YEAR>
<INSTITUTION>   UNIVERSITY OF MARYLAND COLLEGE PARK; 0117 </INSTITUTION>
<DESCRIPTORS>   ENGINEERING, CIVIL; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER>   PAUL SCHONFELD </ADVISER>
<CLASSIFICATIONS>   NIL </CLASSIFICATIONS>
<ABSTRACT>
As traffic demand increases over time, improvements to
existing transportation networks must be considered for
enhancing efficiency and/or capacity. Due to limited
resources, even justifiable projects may have to be
implemented gradually. The selection and timing of
improvement projects is very important to ensure the
most cost-effective investment plan. Conducting this
task for transportation networks is particularly
challenging since the project effects tend to be
inherently interdependent. Most previous methods focus
on the target year conditions for project selection and
determine implementation schedules based on budget
availability. By inadequately estimating project impacts
during intermediate periods, such methods tend to
generate far from optimal improvement plans.
This study develops a multiperiod network design problem
(MPNDP) model for the dynamic investment problem. The
proposed model can efficiently handle the
interdependencies among projects and demand changes in
each period. This method can be used for programming
various transportation network improvements or
transformations.
A branch-and-bound algorithm is designed to determine
the best project combination and schedules. The most
critical need for this approach is an efficient method
to evaluate the total user cost in the network. An
artificial neural network (ANN) approach is developed
for estimating the multiperiod user costs. The ANN is a
newly developed mathematical model that can be
manipulated to predict accurate outcomes for any system
inputs. For the MPNDP, a large fraction of computation
time can be saved by replacing conventional traffic
assignment or simulation with the ANN approach.
The recently developed ANN approach has had some
impressive successes in engineering, business,
operations research and other fields. This work,
constituting one of its first applications in
transportation, shows that it is definitely worth
pursuing.
This work demonstrates the applicability of the proposed
methodology in selecting and scheduling highway network
improvements. A number of potential applications of the
proposed MPNDP methodology are quite promising. For
example, it might be used to evaluate the appropriate
time-staging and effectiveness of converting some
traffic lanes into HOV or automated IVHS lanes, and to
schedule highway maintenance.
</ABSTRACT>
</THESIS>
<THESIS>
<NUMBER> 4219 </NUMBER>
<ORDER>   AAG9407696 </ORDER>
<TITLE>   A NOVEL NEURAL NETWORK APPROACH TO KNOWLEDGE ACQUISITION </TITLE>
<AUTHOR>   SU, MU-CHUN </AUTHOR>
<YEAR>   1993 </YEAR>
<INSTITUTION>   UNIVERSITY OF MARYLAND COLLEGE PARK; 0117 </INSTITUTION>
<DESCRIPTORS>   ENGINEERING, ELECTRONICS AND ELECTRICAL; COMPUTER SCIENCE; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER>   NICHOLAS DECLARIS </ADVISER>
<CLASSIFICATIONS>   NIL </CLASSIFICATIONS>
<ABSTRACT>
Often a major difficulty in the design of rule-based
expert systems is the process of acquiring the requisite
knowledge in the form of production rules. This
dissertation presents several classes of composite
neural networks which are trained to provide appealing
solutions to the problem of knowledge acquisition. The
value of the network parameters, after sufficient
training, are then utilized to generate production rules
on the basis of preselected meaningful coordinates.
Neural networks are attracting a lot of interest in the
scientific community because of their dynamical nature:
robustness, capability of generalization and fault
tolerance. Neural networks have already proven useful in
low level information processing (e.g. signal analysis).
However, an apparent disadvantage of traditional neural
networks (i.e. backpropagation networks) is that they do
not provide explanations of their response i.e. explicit
rules or logical reasoning processes. The classes of
composite neural networks studied in this dissertation
integrate the paradigm of neural networks with the rule-
based approach, rendering them more useful than either.
It is shown that the composite neural networks act as
Bayesian classifiers, and more importantly, can provide
density estimates of the class variables. The
dissertation provides a mathematical framework for
achieving reasonable generalization properties of
composite neural networks serving as universal
approximators via an appropriate training algorithm
(supervised decision-directed learning). The algorithm
is based on an approach that divides the input (feature)
space into proper subsets (e.g. hyperspheres,
hyperrectangles, or hyperellipsoids), represented as
portions of the trained composite neural networks, while
the complete structures provide acceptable knowledge
representations of the data.
The new concepts and methods presented in the
dissertation are illustrated via two traditional
academic pattern recognition examples and one practical
example from medical diagnosis. These examples are
discussed in detail. Finally the dissertation concludes
with a summary of the most important results
accomplished and with brief recommendation for future
work.
</ABSTRACT>
</THESIS>
<THESIS>
<NUMBER> 4220 </NUMBER>
<ORDER>   AAG9406589 </ORDER>
<TITLE>   QUALITATIVE THEORY OF DYNAMICAL SYSTEMS WITH SATURATION NONLINEARITIES </TITLE>
<AUTHOR>   LIU, DERONG </AUTHOR>
<YEAR>   1993 </YEAR>
<INSTITUTION>   UNIVERSITY OF NOTRE DAME; 0165 </INSTITUTION>
<DESCRIPTORS>   ENGINEERING, ELECTRONICS AND ELECTRICAL; ENGINEERING, SYSTEM SCIENCE; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER>   ANTHONY N. MICHEL </ADVISER>
<CLASSIFICATIONS>   NEURAL NETWORKS </CLASSIFICATIONS>
<ABSTRACT>
This dissertation which consists of three parts
addresses topics in the areas of control systems, signal
processing, and neural networks.
In the first part, we investigate two fundamental issues
for a class of dynamical systems with saturation
nonlinearities. For zero-input continuous-time and
discrete-time dynamical systems with saturation
nonlinearities, we establish several results for the
global asymptotic stability of the null solution. For
the discrete-time case, we utilize Lyapunov's Second
Method to arrive at our results and we establish
necessary and sufficient conditions under which positive
definite matrices can be used to construct quadratic
form Lyapunov functions. For discrete-time dynamical
systems with state saturation and control constraints,
we establish several sufficient conditions for null
controllability.
In the second part, we establish results for the
stability analysis of digital filters implemented in
finite wordlength format. We consider both one-
dimensional and multidimensional state-space digital
filters endowed with overflow nonlinearities. We utilize
the Second Method of Lyapunov in our analysis. Our
results greatly improve existing results and appear to
be the least conservative criteria for the subject
systems. The generalized overflow nonlinearity
considered herein includes the usual types of overflow
characteristics used in practice as special cases.
Results of this part build on the developments of the
first part.
In the third part, we consider analysis and design of a
class of feedback neural networks--neural networks with
linear saturation activation functions. We establish
results which enable us to determine all the equilibrium
points and their qualitative properties in a systematic
manner for a given neural network, and results which
enable us to determine allowable upper bounds for
parameter perturbations. We also develop synthesis
procedures for networks with various connectivity
constraints. Our focus is on various problems which
arise in the analog VLSI implementations of neural
networks which are of great practical interest. This
work constitutes the first successful synthesis
procedure for associative memories by means of
artificial neural networks with arbitrarily prespecified
full or partial interconnecting structure and with or
without symmetry constraints for the connection matrix.
</ABSTRACT>
</THESIS>
<THESIS>
<NUMBER> 4221 </NUMBER>
<ORDER>   AAG9406586 </ORDER>
<TITLE>   AN ON-LINE UNSUPERVISED LEARNING MACHINE FOR ADAPTIVE FEATURE EXTRACTION </TITLE>
<AUTHOR>   CHEN, HONG (ROBERT) </AUTHOR>
<YEAR>   1993 </YEAR>
<INSTITUTION>   UNIVERSITY OF NOTRE DAME; 0165 </INSTITUTION>
<DESCRIPTORS>   ENGINEERING, ELECTRONICS AND ELECTRICAL; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER>   RUEY-WEN LIU </ADVISER>
<CLASSIFICATIONS>   FEATURE EXTRACTION </CLASSIFICATIONS>
<ABSTRACT>
Adaptive feature extraction is useful in many
information processing systems. In this dissertation we
propose a learning machine called LEAP, which is
implemented via a neural network to perform such a task
using the tool of principal component analysis. This
machine (1) is based on unsupervised learning concept
and requires no prior knowledge of if or when the input
changes statistically, and (2) performs on-line
computation that requires little memory or data storage.
Associated with this machine we propose a learning
algorithm, whose convergence properties are
theoretically analyzed and whose performance is
evaluated via computer simulations. Two major
contributions of this research are: (1) Under some
modeling assumptions, we prove that the algorithm will
extract multiple principal components, when the learning
rate is constant; and (2) we identify a near optimal
domain of attraction.
</ABSTRACT>
</THESIS>
<THESIS>
<NUMBER> 4222 </NUMBER>
<ORDER>   AAG9406518 </ORDER>
<TITLE>   ANALYSIS AND IMPLEMENTATION OF CONTINUOUS-TIME FEEDBACK NEURAL NETWORKS WITH MULTIPLE-STATE NEURONS </TITLE>
<AUTHOR>   LING, BO </AUTHOR>
<YEAR>   1993 </YEAR>
<INSTITUTION>   MICHIGAN STATE UNIVERSITY; 0128 </INSTITUTION>
<DESCRIPTORS>   ENGINEERING, ELECTRONICS AND ELECTRICAL; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER>   FATHI M. A. SALAM </ADVISER>
<CLASSIFICATIONS>   NIL </CLASSIFICATIONS>
<ABSTRACT>
This work has focused on the design and analysis of two
types of continuous-time feedback neural networks,
namely, the Hopfield-type feedback neural network and
the dendro-dendritic artificial neural network (DANN).
The Hopfield-type feedback neural networks with two-
state neurons are widely used in various applications,
such as pattern recognition, optimization, etc. The more
recent DANN architecture has been used in pattern
association and as an edge detector. All of the networks
considered in this dissertation have multiple-state
neurons.
For the Hopfield-type continuous-time feedback neural
network with multiple-state neurons, we have proposed an
analytical recursive algorithm to find a set of weights
which will exactly store the desired gray-level patterns
as asymptotically stable equilibria. We introduce a
criterion which will ensure that the designed Hopfield-
type neural network to be implementable as an electronic
circuit. The criterion, moreover, allows the resistances
in the network to be made as large as desired. This
flexibility has the practically appealing consequence of
using very large resistances and hence considerably
reducing the power consumption in the circuit
implementation. We also give explicit bounds on the
variation of equilibria due to the variation in weights.
A cellular structure of the Hopfield-type feedback
neural networks is also considered. We propose a large
network structure which connects two or more smaller
identical networks (or cells) together. A parallel
recursive algorithm for this type of locally connected
neural network is introduced. This parallel algorithm
finds the weights for all cells simultaneously.
For the DANN architecture, we show that multiple
patterns can be stored as asymptotically stable
equilibria with only positive weights. We further
formulate the problem of finding all positive weights as
a standard linear programming problem. Thus, based on
the given patterns, all positive weights can be easily
determined. We also point out that the all positive
weights can be solved via a nonlinear (e.g. quadratic)
programming approach.
We have designed a CMOS circuit for a multiple-state
neuron which operates in sub-threshold. With this
neuron, the network power dissipation is considerably
reduced. As a prototype, a DANN architecture using 6
neurons has been designed. Each neuron has four states.
Numerous PSpice simulations have shown that this
prototype DANN network works quite well. A Tiny-Chip
using 6-neuron DANN architecture has been designed and
will be fabricated via MOSIS. All internal signals can
be accessed through the pins of this chip for thorough
laboratory testing.
</ABSTRACT>
</THESIS>
<THESIS>
<NUMBER> 4223 </NUMBER>
<ORDER>   AAG9407664 </ORDER>
<TITLE>   SELF-ORGANIZING SEMANTIC MAPS AS GRAPHICAL INTERFACES FOR INFORMATION RETRIEVAL </TITLE>
<AUTHOR>   LIN, XIA </AUTHOR>
<YEAR>   1993 </YEAR>
<INSTITUTION>   UNIVERSITY OF MARYLAND COLLEGE PARK; 0117 </INSTITUTION>
<DESCRIPTORS>   INFORMATION SCIENCE; COMPUTER SCIENCE; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER>   GARY MARCHIONINI; DAGOBERT SOERGEL </ADVISER>
<CLASSIFICATIONS>   NEURAL NETWORKS </CLASSIFICATIONS>
<ABSTRACT>
This dissertation investigates the potential of using
semantic map displays as browsing aids for information
retrieval. A map display is proposed as a graphical
representation of a document space. A neural network's
self-organizing learning algorithm, Kohonen's feature
map, is used to construct the map display. The map
displays generated by the algorithm are found to show
reasonable pictures of the underlying data: their major
concepts, their semantic relationships, and their
clusters, groups, and distributions. Such map displays
can be used as a graphical interface for a retrieval
system, in which users can pose broad queries and then
browse for relevant documents in the high recall/low
precision results.
As an evaluation of the proposed map display, an
experiment was conducted to examine how human subjects
generate map displays. Eight subjects, each spending two
hours, generated eight different map displays by placing
133 document titles on a large two-dimensional grid. The
subjects were found to generate two types of maps:
category-based maps and association-based maps. The
category-based maps tend to be arranged in columns where
categories are represented by more or less distinct
groups. The association-based maps tend to maintain
clear associations among clusters and groups, but
boundaries for the clusters and groups are not clear.
Comparing the map displays generated by the algorithm
and by the human subjects, similarities are found in the
semantic structures of the map displays, the processes
of generating the displays, and the functionalities of
the displays. When 68 subjects conducted some pseudo-
retrieval tasks on the map displays, no significant
difference is found between their performance on the
human-generated map displays and on the machine-
generated map displays, but a significant difference is
found between their performance on these map displays
and on a random display. These results suggest that the
map displays can provide quick access to documents by
virtue of their graphical representation. Results of
this dissertation strongly imply that information can be
and should be made visible to people who search for it.
</ABSTRACT>
</THESIS>
<THESIS>
<NUMBER> 4224 </NUMBER>
<ORDER>   AAG9407279 </ORDER>
<TITLE>   BEYOND WHAT-IF: ENHANCING MODEL ANALYSIS IN A DECISION SUPPORT SYSTEM </TITLE>
<AUTHOR>   STEIGER, DAVID MICHAEL </AUTHOR>
<YEAR>   1993 </YEAR>
<INSTITUTION>   OKLAHOMA STATE UNIVERSITY; 0664 </INSTITUTION>
<DESCRIPTORS>   BUSINESS ADMINISTRATION, MANAGEMENT; OPERATIONS RESEARCH </DESCRIPTORS>
<ADVISER>   RAMESH SHARDA </ADVISER>
<CLASSIFICATIONS>   MANAGEMENT SYSTEMS </CLASSIFICATIONS>
<ABSTRACT>
Scope and method of study. Once a Decision Support
System (DSS) model is built, validated and run for an
initial set of assumptions and instantiating values, the
decision maker's job has just begun. There follows an
extensive set of what-if questions and associated model
instances which explore the workings and trade-offs of
the business system represented by the model. That is,
the decision maker tries to develop insights into the
interrelationships between changes in model
variables/parameters and their effects on the model
solution. However, insightful analysis of multiple what-
if model instances becomes difficult as more and more
instances are considered. Further, very little theory
and few computer-aided tools have been provided to
enhance this insightful analysis process. The purpose of
this research is fourfold: (1) to define and justify
model insight generator systems (MIGS) which provide
support in multiple instance analysis, (2) to propose an
architecture for model insight generator systems and
discuss a set of software tools which could be used in
such systems, (3) to provide a mathematical statement of
the basic analysis functions of a model, and (4) to
implement one subsystem of the MIGS architecture, called
INSIGHT, which identifies the key factors and their
deterministic linear and nonlinear relationships.
Findings and conclusions. To test and validate the MIGS
concepts as well as the INSIGHT implementation, a
facility location model, corresponding to the insight-
generating model discussed by Geoffrion in his 1976
Interfaces article, was built and run for several values
of customer demand, transportation rates, fixed costs
and optimal numbers of facilities. It was found that the
MIGS INSIGHT subsystem, using artificial intelligence
and statistical analysis of multiple what-if model
instances, could generate results similar to the
insightful simplified auxiliary model produced by
Geoffrion.
</ABSTRACT>
</THESIS>
<THESIS>
<NUMBER> 4225 </NUMBER>
<ORDER>   AAG9406804 </ORDER>
<TITLE>   SMALL HUMAN GROUPS IN ISOLATED AND CONFINED ENVIRONMENTS: CONFLICT AND COMMUNICATION STRUCTURES AND DYNAMICS </TITLE>
<AUTHOR>   OWEN, ROBERT BARRY </AUTHOR>
<YEAR>   1993 </YEAR>
<INSTITUTION>   UNIVERSITY OF COLORADO AT BOULDER; 0051 </INSTITUTION>
<DESCRIPTORS>   ANTHROPOLOGY, CULTURAL; COMPUTER SCIENCE; SOCIOLOGY, GENERAL; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER>   PAYSON D. SHEETS </ADVISER>
<CLASSIFICATIONS>   NIL </CLASSIFICATIONS>
<ABSTRACT>
A computer-based system for the study and representation
of small human groups in isolated and confined
environments is presented. The system operates through
case-based reasoning, which is an artificial
intelligence methodology that makes use of case data or
studies. The system is based on case knowledge from
isolated and confined groups in space vehicles, polar
stations, and other environments; as well as a tailored
case study of an archeological field crew. Use is made
of most major anthropological paradigms--primarily
formalism, structuralism and cultural materialism--in
the representation of conflict and communication.
I am concerned with the structure of conflict and
communication, the human group, the environment, and
individual human actors. I represent these structures
explicitly, using specialized data structures. It is
found that events of group and individual conflict and
communication can be represented in these terms. It is
further found that the dynamics of conflict and
communication events can be studied and understood in
terms of conflict and communication triggers. These
triggers are also given a precise and explicit
structure. It is found that it is possible to connect
these conflict and communication structures with human
task performances, which we also define formally.
The results indicate that conflict is more discretely
structured than communication. Reported communication
events were relatively rare, and were interwoven with
conflict events. That is, the formal structure seems to
match conflict better than communication, and
communication events seem to have a less consciously
structured character than do conflict events.
I consider these structures and dynamics in terms of
both "official" and "unofficial"
factors. Official factors arise from the formal group
structure, and unofficial factors are personal factors.
The results indicate that case-based reasoning has the
power to combine both theoretical and case studies for
human groups, and thus potentially offers a new
anthropological paradigm.
</ABSTRACT>
</THESIS>
<THESIS>
<NUMBER> 4226 </NUMBER>
<ORDER>   AAG9404910 </ORDER>
<TITLE>   AN EMPIRICAL EVALUATION OF THE COGNITIVE INTERVIEW FOR ELICITATION OF EPISODIC KNOWLEDGE DURING EXPERT SYSTEMS DEVELOPMENT </TITLE>
<AUTHOR>   MOODY, JANETTE W. </AUTHOR>
<YEAR>   1993 </YEAR>
<INSTITUTION>   UNIVERSITY OF SOUTH FLORIDA; 0206 </INSTITUTION>
<DESCRIPTORS>   BUSINESS ADMINISTRATION, GENERAL; COMPUTER SCIENCE; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER>   PAUL H. CHENEY </ADVISER>
<CLASSIFICATIONS>   NIL </CLASSIFICATIONS>
<ABSTRACT>
The development of expert systems depends upon capturing
the expert's knowledge, either in the form of rules (for
rule-based expert systems) or cases (for case-based
expert systems). In either instance, the elicitation of
knowledge from an expert has been consistently
characterized as the primary stumbling block or
"bottleneck" in the expert systems development
process.
Various techniques have been suggested for knowledge
elicitation and attempts have been made to match the
elicitation technique to the type of knowledge sought.
These methods have been criticized for their lack of
theoretical foundations regarding how humans process and
store knowledge, and few have been empirically tested.
Despite the lack of empirical support for a particular
technique, the literature cites the interview as the
most commonly used method of knowledge elicitation.
Unfortunately, the interview is notable for eliciting
knowledge that is imprecise, incomplete, and
inconsistent because the knowledge sought is often
subconscious and not readily available by the expert for
articulation.
These issues of deficiencies in memory retrieval have
been faced in other disciplines. Accordingly, this study
is based on the premise that a theoretically grounded
technique utilized successfully in other disciplines
will prove useful in knowledge elicitation during expert
systems development. The technique is the Cognitive
Interview which is structured around five principles of
memory retrieval: context reinstatement, focused
retrieval, extensive retrieval, varied retrieval, and
multiple representations.
The research project consisted of a field experiment
utilizing a randomized two-group design. Subjects were
reference librarians in academic institutions who were
interviewed by Expert Systems students trained in both
the Cognitive Interview and the standard knowledge
elicitation interview. The two dependent variables
measured were efficiency and effectiveness. Both
variables were found to be significantly higher under
the Cognitive Interview, leading the researcher to
conclude that knowledge engineers can benefit from
including the Cognitive Interview during the knowledge
acquisition process.
</ABSTRACT>
</THESIS>
<THESIS>
<NUMBER> 4227 </NUMBER>
<ORDER>   AAG9406123 </ORDER>
<TITLE>   PRINCIPLED OPTIMIZATION OF FUNCTIONAL PROGRAMS </TITLE>
<AUTHOR>   WEBBER, ADAM BROOKS </AUTHOR>
<YEAR>   1993 </YEAR>
<INSTITUTION>   CORNELL UNIVERSITY; 0058 </INSTITUTION>
<DESCRIPTORS>   COMPUTER SCIENCE; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER>   DEVIKA SUBRAMANIAN </ADVISER>
<CLASSIFICATIONS>   TRACE GRAMMAR </CLASSIFICATIONS>
<ABSTRACT>
Automatic optimizers for computer programs work with a
fixed list of rote transformations, while human
programmers can go on to derive new optimizations from
broad and intuitive principles if known transformations
prove inadequate. This dissertation investigates the
possibility that principled optimization can be
automated, focusing on a single principle (the principle
that programs should not do anything unnecessary) single
program domain (the domain of purely functional, first-
order programs). Three questions are explored: How can
the principle be formalized? How can violations of the
principle be detected? How can violations be repaired?
The trace grammar is a new representation for first-
order functional programs. It permits a simple formal
statement of the optimizing principle. A trace grammar
is a kind of graph grammar. An individual graph
represents a path of execution through the program,
without any loops or conditionals. The grammar for a
program generates a language of graphs representing the
possible paths of execution through that program. Trace
grammars provide unique leverage for the twin problems
of identifying and repairing violations of the
principle.
Detecting violations of the principle is a problem in
semantic analysis. A new method of inference, the
relational constraint method, helps make this tractable.
The method treats a trace graph as a system of
constraints on a lattice of binary relations, and uses
those constraints to develop the strongest relation it
can find for each pair of values in the graph.
Repairing violations is not easy: given an example of an
unnecessary computation performed by the program, one
wants to modify the program so that it never makes that
mistake. This grammar thinning problem for trace
grammars corresponds to an interesting open problem on
context-free grammars. An (approximate) solution to this
CFG problem yields an optimization technique for trace
grammars.
An optimizer called Thinner is the proof-of-concept for
these ideas. Using the techniques outlined above,
Thinner rediscovers a variety of common compiler
optimizations. It also finds other, more exotic
transformations, including the well-known Fibonacci
reformulation. Thinner demonstrates the potential of the
principled approach as a high-powered optimizing tool.
</ABSTRACT>
</THESIS>
<THESIS>
<NUMBER> 4228 </NUMBER>
<ORDER>   AAG9406017 </ORDER>
<TITLE>   ADAPTIVE CLUSTERING OF PARTS AND MACHINES IN A CELLULAR MANUFACTURING ENVIRONMENT: AN APPLICATION OF THE FUZZY ART NEURAL NETWORK </TITLE>
<AUTHOR>   KAMAL, SOHEYLA </AUTHOR>
<YEAR>   1993 </YEAR>
<INSTITUTION>   LEHIGH UNIVERSITY; 0105 </INSTITUTION>
<DESCRIPTORS>   ENGINEERING, INDUSTRIAL; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER>   LAURA I. BURKE </ADVISER>
<CLASSIFICATIONS>   NIL </CLASSIFICATIONS>
<ABSTRACT>
The major goal of this thesis is to determine if
Artificial Neural Networks (ANNs) can be trained to
cluster the machines and parts, i.e. the Group
Technology (GT), problem in cellular manufacturing under
a multiple objective environment.
The existing clustering techniques are mainly concerned
with grouping parts and machines based on the parts'
processing routes. Similarity features such as design
requirements of parts, processing time on each machine,
and demand for each part are seldom considered. The
methods that consider more than one criteria, have
computational demands that render them inefficient for
problems of realistic size.
We have studied Self-organizing (unsupervised) neural
networks. In particular, we have considered competitive
learning and Adaptive Resonance Theory (ART) neural
networks. Fuzzy ART has shown more promising results. It
can handle both binary and continuous input data. It
uses a very powerful technique for evaluating the
similarities between the input patterns. Our
investigation shows that fuzzy ART by itself is not able
to solve some of the problems which we are facing in
group technology. To fulfill the shortcomings of fuzzy
ART we have developed the FACT (Fuzzy art with Add
Clustering Technique) algorithm.
In order to test the clustering efficiency of the FACT
algorithm we have developed two new measures. Generally,
these measures evaluate the similarity between the
members of each cluster and the distance between
different clusters. The difference between the two
methods is that the former measures similarity by
Euclidian distance, and the latter uses both fuzzy logic
and Euclidian distance. In addition, we have used some
well known group-technology-specific performance
measures to evaluate the goodness of our solutions to
the group technology problem.
A comparison of the results of the FACT algorithm with
several other GT clustering algorithms published in the
literature has shown that FACT's results are always
either better than or as good as the results of the
other algorithms.
</ABSTRACT>
</THESIS>
<THESIS>
<NUMBER> 4229 </NUMBER>
<ORDER>   AAG9406014 </ORDER>
<TITLE>   A BI-LEVEL PHYSICS STUDENT DIAGNOSTIC UTILIZING COGNITIVE MODELS FOR AN INTELLIGENT TUTORING SYSTEM </TITLE>
<AUTHOR>   GURER, DENISE WHITSON </AUTHOR>
<YEAR>   1993 </YEAR>
<INSTITUTION>   LEHIGH UNIVERSITY; 0105 </INSTITUTION>
<DESCRIPTORS>   COMPUTER SCIENCE; EDUCATION, SCIENCES </DESCRIPTORS>
<ADVISER>   PATTI T. OTA </ADVISER>
<CLASSIFICATIONS>   TUTORING </CLASSIFICATIONS>
<ABSTRACT>
Intelligent tutoring systems (ITSs) represent a
significant opportunity to augment our educational and
training systems. ITSs are also a substantial challenge
since they encompass the breadth of artificial
intelligence. An important component of any ITS is the
student model that diagnoses a student's problem solving
episode. Current student models use a pre-compiled
library of bugs to identify conceptual errors. This
method requires much preparation, is not robust and
fails to identify a student's overall problem solving
strategies. This dissertation describes a novel approach
to student modeling which addresses these issues.
A two-level student diagnostic analyzes a student's
problem solving event in general physics. The lower
level uses a dynamically evolving student model to
identify a student's errors and misconceptions. The
upper level uses cognitive models to analyze the
student's problem solving strategies.
The lower level, named RESTMOD: Reverse Evolution
STudent MODel, utilizes dynamic hierarchical networks to
represent physics knowledge and problem solutions.
Procedural and declarative knowledge are represented by
a physics text network and the qualitative knowledge
found in the environmental and force diagrams is
represented by a body inheritance tree. The equation
portion of a solution is embodied in a dynamically
evolving network that evolves from a copy of an expert's
solution to a representation of the student's solution.
The evolving feature of this model avoids error
repercussions and the compounding of bugs and also gives
the ITS a capability to dynamically create problems for
the student to solve.
The upper level of the diagnostic employs three
cognitive models to further analyze a student's problem
solving performance. The first model, Knowledge Type,
determines whether the student is using preconceived
notions or actual physics knowledge. The second model,
Focus, evaluates the student's equations to ascertain
whether the student's focus is on the problem's surface
features or on physics principles. The third model,
Approach, notes if the student is using schemes and/or
means-end analysis in their problem solving approach.
This unique combination of error detection and cognitive
modeling provides a comprehensive and a robust approach
to student modeling that can be applied to many
scientific disciplines.
</ABSTRACT>
</THESIS>
<THESIS>
<NUMBER> 4230 </NUMBER>
<ORDER>   AAG9405982 </ORDER>
<TITLE>   EXPLOITING PROGRAM SCHEMATA IN A PROLOG TUTORING SYSTEM </TITLE>
<AUTHOR>   GEGG-HARRISON, TIMOTHY SCOTT </AUTHOR>
<YEAR>   1993 </YEAR>
<INSTITUTION>   DUKE UNIVERSITY; 0066 </INSTITUTION>
<DESCRIPTORS>   COMPUTER SCIENCE; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER>   DONALD W. LOVELAND </ADVISER>
<CLASSIFICATIONS>   CAI </CLASSIFICATIONS>
<ABSTRACT>
After their beginnings in computer-aided instruction,
automated tutors have reemerged as intelligent tutoring
systems. These intelligent tutors have obtained
considerable success by using results from cognitive
psychology and artificial intelligence to permit non-
traditional instruction which is tailored to their
individual students. The success of these automated
tutors is due to their precise understanding and
modeling of both the student and the domain being
taught. A common measure of the robustness of an
automated tutor is the size of the domain that it can
understand. The schema-based Prolog tutor described in
this dissertation is capable of recognizing a larger
class of programs than existing Prolog tutors. By using
powerful generalized transformations, our Prolog tutor
can generate this class of programs from a very small
set of normal form programs. Thus, our Prolog tutor
recognizes a larger class of programs using fewer normal
form programs than existing Prolog tutors. One of the
biggest shortcomings of automated tutors for complex
domains is their lack of a characterization of their
domain. In computer programming tutors, for example, no
current tutoring system has the ability to precisely
state the class of programs that its tutor is capable of
understanding. In addition to being more robust than
existing programming tutors, our Prolog tutor provides a
characterization of the class of programs it
understands.
</ABSTRACT>
</THESIS>
<THESIS>
<NUMBER> 4231 </NUMBER>
<ORDER>   AAG9405757 </ORDER>
<TITLE>   THE MODAL LOGIC Z APPLIED TO LIFSCHITZ'S BENCHMARK PROBLEMS FOR FORMAL NONMONOTONIC REASONING </TITLE>
<AUTHOR>   LEASURE, DAVID ELDEN </AUTHOR>
<YEAR>   1993 </YEAR>
<INSTITUTION>   UNIVERSITY OF KANSAS; 0099 </INSTITUTION>
<DESCRIPTORS>   COMPUTER SCIENCE; PHILOSOPHY; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER>   FRANK M. BROWN </ADVISER>
<CLASSIFICATIONS>   NONMONOTONIC REASONING </CLASSIFICATIONS>
<ABSTRACT>
To give a standard against which to judge the
limitations and possibilities of a theory of
nonmonotonic reasoning, V. Lifschitz presented a paper
at the 1988 Second International Workshop on Non-
Monotonic Reasoning entitled "Benchmark Problems
for Formal Nonmonotonic Reasoning." We show in this
work the application of the modal logic Z to these
benchmark problems. The modal logic Z provides a
consistency-based approach to nonmonotonic reasoning. Z
is a fragment of second order modal quantificational
logic involving quantification over propositions but not
over properties. We demonstrate that Z leads to correct
and concise solutions to all the benchmark problems. We
also show that many solutions to nonmonotonic reasoning
problems expressed in Z are automatically derivable.
Because we are able to solve the benchmark problems by
hand using a small number of lemmas, we claim that Z has
a learnable proof theory.
In addition to handling all the benchmark problems,
which to our knowledge has not been demonstrated for a
single system of nonmonotonic reasoning, we also make a
number of smaller contributions. This work provides
solutions to the unique name problems which, to our
knowledge, have not been solved by any other formal
system. It demonstrates a new representation in Z for
temporal projection, and improves on a representation by
Lifschitz for temporal explanation. It describes a way
of generalizing temporal projection to handle concurrent
actions, and a way of using temporal explanation for
counterfactual reasoning. It shows that Z is able to
reason correctly about autoepistemic problems, including
problems with quantification. Finally, it reports
results on our use of and extensions to a theorem prover
for Z.
</ABSTRACT>
</THESIS>
<THESIS>
<NUMBER> 4232 </NUMBER>
<ORDER>   AAG9405624 </ORDER>
<TITLE>   NEURAL NETWORKS FOR PROCESS IDENTIFICATION AND CONTROL </TITLE>
<AUTHOR>   KASPARIAN, VICKEN S. </AUTHOR>
<YEAR>   1993 </YEAR>
<INSTITUTION>   THE UNIVERSITY OF AKRON; 0003 </INSTITUTION>
<DESCRIPTORS>   BIOLOGY, NEUROSCIENCE; COMPUTER SCIENCE; ENGINEERING, ELECTRONICS AND ELECTRICAL; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER>   NIL </ADVISER>
<CLASSIFICATIONS>   CONTROL STRATEGY </CLASSIFICATIONS>
<ABSTRACT>
Linear system theory has made enormous contributions to
developments in the area of classical controls in the
last two decades. The work in this dissertation deals
with the development of a control strategy that can be
used for non-linear time varying systems.
A neural network based non-linear adaptive control
strategy is proposed for controlling non-linear time-
varying plants. The feasibility of using a Least Squares
based neural network adaptation scheme will be
investigated for training the proposed controller.
Finally, the stability of the closed loop control system
will be studied.
Two feedforward neural networks will be trained
simultaneously in the proposed control strategy. One
network will be trained to model the non-linear dynamic
behavior of the plant to be controlled while the other
network will be trained to generate the control actions
to drive the plant. A Davidon based neural network will
be used for training both the controller and the process
model networks. A neural network linearization scheme
will be developed and be used to analyze the properties
of the control system around some operating point.
The simulation results carried out corroborate the
feasibility of using the proposed neural network
structure for a wide variety of non-linear and time
varying plants. Furthermore, the Davidon algorithm used
for training neural network is shown to outperform the
conventionally used back propagation algorithm. Finally,
the neural network linearization methodology used in
this dissertation is shown to provide a good
approximation of the non-linear control system around
the operating point of the plant.
</ABSTRACT>
</THESIS>
<THESIS>
<NUMBER> 4233 </NUMBER>
<ORDER>   AAG9405598 </ORDER>
<TITLE>   NEURAL PROGRAMMING, COMPUTATIONAL SCHEME AND APPLICATIONS </TITLE>
<AUTHOR>   WEISS, JACOB </AUTHOR>
<YEAR>   1993 </YEAR>
<INSTITUTION>   CITY UNIVERSITY OF NEW YORK; 0046 </INSTITUTION>
<DESCRIPTORS>   COMPUTER SCIENCE; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER>   ERALP AKKOYUNLU </ADVISER>
<CLASSIFICATIONS>   NET PROGRAM, C(+NET) </CLASSIFICATIONS>
<ABSTRACT>
An attempt is made to solve difficult AI problems by
introducing a new scheme, the net program. The net
program is a programmable network of cooperative neural
nets and procedural functions. Its goal is to bridge the
gap between connectionist-subsymbolic and symbolic
processing in AI. A set of subroutines has been devised
for "neural programming" as an enhancement to
the procedural language C. The resulting language, which
we call C$sp{rm +NET}$, enables and controls modular
structuring, training and activation of nets and the
interaction among nets and procedural functions. We
applied C$sp{rm +NET}$ on a model for natural language
comprehension as a cardinal unsolved AI problem of an
intricacy that would strain any conceivable
computational scheme and on a model for pattern
recognition as a demonstrative example of the advantages
of the approach we are presenting. We also present a
design of an application to financial forecasting
utilizing our net program scheme.
</ABSTRACT>
</THESIS>
<THESIS>
<NUMBER> 4234 </NUMBER>
<ORDER>   AAG9405556 </ORDER>
<TITLE>   EXPLORATION IN ON-LINE HANDWRITTEN CHARACTER RECOGNITION </TITLE>
<AUTHOR>   MATIC, NADA PETAR </AUTHOR>
<YEAR>   1993 </YEAR>
<INSTITUTION>   CITY UNIVERSITY OF NEW YORK; 0046 </INSTITUTION>
<DESCRIPTORS>   ENGINEERING, ELECTRONICS AND ELECTRICAL; COMPUTER SCIENCE; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER>   NENAD MARINOVICH </ADVISER>
<CLASSIFICATIONS>   CHARACTER RECOGNITION, NEURAL NETWORKS, OPTIMAL HYPERPLANE CLASSIFIER </CLASSIFICATIONS>
<ABSTRACT>
In this thesis we address the problem of learning and
recognition of the handwritten isolated characters. The
"core" of the recognition system is Time Delay
Neural Network (TDNN) which incorporates feature
extractor and classifier in a single trainable module.
Our experiments were carried out on a database of
handwritten characters, entered on a touch terminal.
Specifically, the objective of this research was to
improve the recognition rate by focusing on the most
informative patterns. They are examples of rare writing
styles that are typically under-represented in the
training database. We have used two different approaches
in order to pay special attention to these patterns.
One approach is applicable to the writer independent
task and consists of developing a systematic computer-
aided methodology for cleaning the large training
database. Using this method, non-informative (e.g.
meaningless and mislabeled) patterns are removed from
the training database. The rare and unusual patterns
that remain in the tail of the distribution after the
meaningless or mislabeled patterns have been removed are
then emphasized using special training procedure. By
combining cleaning and emphasizing training scheme we
have reduced the generalization error by a factor of
two.
Second approach is to introduce writer adaptation to
allow a specific user to provide, on-line, examples of
rare character styles that do not exist in the database.
To do that, we use the writer independent neural network
without its last layer as a preprocessor to the Optimal
Hyperplane Classifier. Through a process of adaptation,
we retrain the Optimal Hyperplanes with the set of most
informative patterns of the default database, augmented
by the examples provided on-line by a specific user.
Without degradation in speed, the average error rate
after adaptation is 1% to 2% for most writers.
</ABSTRACT>
</THESIS>
<THESIS>
<NUMBER> 4235 </NUMBER>
<ORDER>   AAG9405405 </ORDER>
<TITLE>   A BLACKBOARD INTEGRATION OF MANUFACTURING DATABASES USING AN INTELLIGENT INTERFACE </TITLE>
<AUTHOR>   KOONCE, DAVID ANDERSON </AUTHOR>
<YEAR>   1993 </YEAR>
<INSTITUTION>   THE LOUISIANA STATE UNIVERSITY AND AGRICULTURAL AND MECHANICAL COL.; 0107 </INSTITUTION>
<DESCRIPTORS>   ENGINEERING, INDUSTRIAL; COMPUTER SCIENCE; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER>   L. KEN KEYS </ADVISER>
<CLASSIFICATIONS>   MULTIPLE INTEGRATED MANUFACTURING INFORMATION RESOURCES </CLASSIFICATIONS>
<ABSTRACT>
The explosion of computer applications into the world of
manufacturing along functional lines has produced the
often mentioned "islands of automation."
Although many issues and problems are involved in
interfacing and integrating the databases that serve
these applications, we can extract valuable data from
these independent systems to provide important
information to decision makers. This research resulted
in the development of MIMIR (Multiple Integrated
Manufacturing Information Resources), a decision support
system based upon the blackboard architecture. The
blackboard architecture extends the common expert system
design to include multiple expert systems, termed
Knowledge Sources (KS's), which combine to solve
problems too diverse or complex for conventional expert
systems. Extending the architecture, MIMIR uniquely adds
Data Sources (DS's) to the conventional KS's for problem
decomposition and solution.
Developed in Common LISP and CLOS, MIMIR can answer
basic questions about the data in the remote databases
and generate multiple queries for more complex
questions. Seven partitions in MIMIR's blackboard allow
KS's and DS's to focus on specific levels of the problem
decomposition. MIMIR relies on an intelligent interface
to translate an internal LISP-based SQL-like query into
a valid SQL query string. This query is then be
submitted to an external relational database and results
are returned to the blackboard environment. While MIMIR
is currently limited to SQL-accessible relational
databases, the architecture can be extended to support
interfaces to other data formats.
</ABSTRACT>
</THESIS>
<THESIS>
<NUMBER> 4236 </NUMBER>
<ORDER>   AAG9405172 </ORDER>
<TITLE>   TOWARD FORMALIZING DIALECTICAL ARGUMENTATION </TITLE>
<AUTHOR>   FREEMAN, KATHLEEN </AUTHOR>
<YEAR>   1993 </YEAR>
<INSTITUTION>   UNIVERSITY OF OREGON; 0171 </INSTITUTION>
<DESCRIPTORS>   COMPUTER SCIENCE; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER>   ARTHUR M. FARLEY </ADVISER>
<CLASSIFICATIONS>   ARGUMENT GENERATION </CLASSIFICATIONS>
<ABSTRACT>
The construction of arguments has long been viewed as a
paradigmatic example of human reasoning and, as such, is
an important ability for computer programs that attempt
to model intelligent behavior. We explore the use of
argumentation for deriving and justifying claims in
domains where knowledge is incomplete, uncertain, or
inconsistent, i.e., weak theory domains. Argumentation
supports a notion of proof appropriate for reasoning in
weak theory domains, e.g., a claim is proved if there is
plausible, irrefutable support for the claim, and there
is no such support for any counter-claim.
We present elements of a theory of argumentation
involving two senses of argument, argument as supporting
explanation and argument as dialectical process. For
argument as supporting explanation, we create argument
structures that organize relevant, available support for
both a claim and its negation. In dialectical argument,
the format of a two-sided argument process is used to
intertwine the strengths and weaknesses of support for
competing claims, so arguments can be refuted and
directly compared. Our account of dialectical
argumentation includes a catalog of argument moves and a
set of heuristics for selecting moves and thereby
controlling argument generation.
This model, which has been implemented in a computer
program, is a flexible environment for exploring the
representation and generation of arguments. We show how
the program generates reasonable arguments for a set of
example problems. We give an analysis of the program,
including limits of the current model of argumentation.
For artificial intelligence programs, the ability to
generate arguments provides a useful technique for
reasoning in real world contexts. For argumentation
researchers, artificial intelligence methodology offers
a new way for evaluating theories of argumentation.
</ABSTRACT>
</THESIS>
<THESIS>
<NUMBER> 4237 </NUMBER>
<ORDER>   AAG9405013 </ORDER>
<TITLE>   FUZZY RULE GENERATION AND INFERENCE METHODS FOR PATTERN RECOGNITION AND COMPUTER VISION </TITLE>
<AUTHOR>   RHEE, FRANK CHUNG-HOON </AUTHOR>
<YEAR>   1993 </YEAR>
<INSTITUTION>   UNIVERSITY OF MISSOURI - COLUMBIA; 0133 </INSTITUTION>
<DESCRIPTORS>   ENGINEERING, ELECTRONICS AND ELECTRICAL; COMPUTER SCIENCE; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER>   RAGHU KRISHNAPURAM </ADVISER>
<CLASSIFICATIONS>   NIL </CLASSIFICATIONS>
<ABSTRACT>
In many decision making systems involving multiple
sources, the decisions made may be considered as the
result of a rule-based system in which the decision
rules are usually enumerated by experts or generated by
a learning process. In this dissertation, we present new
methods for generating fuzzy rules automatically from
training data for pattern recognition and high-level
computer vision. Features and spatial relations
representing the training data are treated as linguistic
variables that appear in the antecedent clauses of the
rules. Methods to generate the corresponding linguistic
labels (values) and their membership functions are
presented. The rules are generated by constructing a
minimal approximate fuzzy aggregation network and then
training the network using gradient descent methods. In
addition, we introduce inference procedures that can be
employed to deduce conclusions from information
presented to our rule-base. Several experimental results
involving synthetic and real data are presented.
</ABSTRACT>
</THESIS>
<THESIS>
<NUMBER> 4238 </NUMBER>
<ORDER>   AAG9404998 </ORDER>
<TITLE>   NEURAL NETWORK AND FUZZY LOGIC METHODS FOR POWER ELECTRONIC CONTROL </TITLE>
<AUTHOR>   LIN, BOR-REN </AUTHOR>
<YEAR>   1993 </YEAR>
<INSTITUTION>   UNIVERSITY OF MISSOURI - COLUMBIA; 0133 </INSTITUTION>
<DESCRIPTORS>   ENGINEERING, ELECTRONICS AND ELECTRICAL; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER>   RICHARD G. HOFT </ADVISER>
<CLASSIFICATIONS>   NIL </CLASSIFICATIONS>
<ABSTRACT>
In this dissertation, a new technique for power
electronic DC-DC and DC-AC power conversion control
based on neural network and fuzzy logic methods is
developed. In DC-AC conversion, sinusoidal current
regulation with inverter drives based on bang-bang or
sinusoidal band hysteresis methods has been used. The
major problem with these methods is high total harmonic
distortion. Proposed strategies for sinusoidal current
regulation of inverter drives based on neural network
and fuzzy logic methods are presented. Real-time digital
control of the PWM inverter with a fuzzy logic
compensator for nonlinear loads is also proposed in this
dissertation. Buck, boost and buck/boost converters with
fuzzy logic control are investigated for DC-DC
conversion. The performance of these DC-DC converters is
compared with bang-bang and sliding mode methods.
This research is the first extensive work known using
fuzzy logic and neural network approaches in inverter,
UPS and DC-DC converter controls.
The following are the most significant contributions of
this dissertation: (1) It is the first extensive
research on inverter and DC-DC converter controls using
neural network and fuzzy logic methods. (2) Sinusoidal
current regulation with inverter drives by the neural
network approach has less total harmonic distortion than
that of bang-bang and sinusoidal band hysteresis
methods. (3) The DC-DC converter with the fuzzy logic
approach has faster transient response than that of bang-
bang and sliding mode methods.
</ABSTRACT>
</THESIS>
<THESIS>
<NUMBER> 4239 </NUMBER>
<ORDER>   AAG9404943 </ORDER>
<TITLE>   AN ERROR DETECTION AND RECOVERY STRATEGY FOR FLEXIBLE ASSEMBLY SYSTEMS </TITLE>
<AUTHOR>   ABU-HAMDAN, MOUTASEM GHALEB </AUTHOR>
<YEAR>   1993 </YEAR>
<INSTITUTION>   UNIVERSITY OF MISSOURI - COLUMBIA; 0133 </INSTITUTION>
<DESCRIPTORS>   COMPUTER SCIENCE; ENGINEERING, MECHANICAL; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER>   A. SHERIF EL-GIZAWY </ADVISER>
<CLASSIFICATIONS>   TASK PRECONDITION </CLASSIFICATIONS>
<ABSTRACT>
A new error detection and recovery (EDR) strategy for
flexible assembly systems was developed. The strategy is
generalized to handle the common operations of flexible
assembly systems. In addition, the strategy is efficient
in terms of managing and processing information, as well
as flexible and interfacial to adapt to different
flexible assembly systems.
The uniqueness of the developed strategy is demonstrated
by its method of error detection. The task precondition
verification and execution monitoring of the strategy
resulted in the elimination of error propagation and the
need for event backtracking.
The EDR strategy is divided into three phases: primary,
recovery, and enhancement phases. The primary phase
consists of choosing the main constituents of the
strategy, planning the hierarchy of the components
within the strategy, determining the control structure,
and implementing the error detection and diagnosis
modules. The recovery phase of the strategy includes
building and executing a recovery module and a world
model. Finally, the enhancement phase contains the
implementation of a learning module into the strategy.
The development of the primary phase of the strategy was
the main objective of this study, the recovery and the
enhancement phases are recommended for future
development of the strategy.
A research flexible assembly work cell was constructed
in order to validate the functionality and to assess the
feasibility of the primary phase of the EDR strategy.
The work cell contained a robotic system equipped with a
vision system and a force sensing module, a computer
with a data acquisition system, and several other
sensors which were used for reporting the status of the
work cell.
In testing the primary phase, conflicts were encountered
between some of the twenty error causes that comprise
the error diagnosis module. Those conflicts were
resolved by adding more conditions to the premise list
of each error in conflict. A comprehensive verification
was conducted to ensure that there were no further
conflicts between any of the error causes.
</ABSTRACT>
</THESIS>
<THESIS>
<NUMBER> 4240 </NUMBER>
<ORDER>   AAG9404888 </ORDER>
<TITLE>   APPLICATION OF FUZZY SET THEORY IN DEVELOPING AN INTEGRATED INTELLIGENT PLANNING SYSTEM FOR FRESH PRODUCE PACKING </TITLE>
<AUTHOR>   AZHAR, TASHFEEN MAHMOOD </AUTHOR>
<YEAR>   1993 </YEAR>
<INSTITUTION>   UNIVERSITY OF SOUTH FLORIDA; 0206 </INSTITUTION>
<DESCRIPTORS>   ENGINEERING, INDUSTRIAL; ENGINEERING, SYSTEM SCIENCE; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER>   WILLIAM A. MILLER </ADVISER>
<CLASSIFICATIONS>   NIL </CLASSIFICATIONS>
<ABSTRACT>
This research focused on the application of fuzzy set
theory in developing an integrated fuzzy intelligent
decision system (FIDS) which can deal with the
uncertainty due to probabilistic nature as well as
fuzziness in the system. Fuzziness is explicitly dealt
with by applying fuzzy set theory to the mathematical
model in the FIDS.
In this framework, Bellman and Zadeh's (1970) method of
applying fuzzy set theory to the decision-making process
is used. It is shown that fuzzy set theory adequately
deals with fuzziness in the production system. Based on
the Zimmermann's (1976) method, the 0-1 integer
programming models were developed to approximate the
fuzzy programming model. In this regard, three
equivalent integer programming models were developed by
using different combinations of membership functions and
aggregating operators.
The probabilistic nature of the production system was
implicitly handled by employing the iterative process
proposed by Leung, Maheshwari and Miller (1993). A fuzzy
knowledge base expert system (FKBES) was used to analyze
the simulation results and to control the iterative
process. The expert system employs fuzzy inference
mechanism to modify the mathematical model's parameters
for a better solution.
A tomato packinghouse was selected to test this
methodology. The produce packing environment has an
abundance of both types of uncertainties. Four
mathematical models, a linear programming model and
three equivalent 0-1 integer programming models were
developed and tested for use in the FIDS. These models
are investigated for several test problems which are
partially based on industrial data. A simulation model
was developed to analyze the system performance for
these models.
Two performance measures, gassing volume and packing
time were selected to test the effectiveness of these
models in the produce packing system. The practicality
of the fuzzy intelligent decision system's result for
application in the real-world system was also addressed.
With some examples, it was shown that the decision
system gave good solutions to real-world problems.
</ABSTRACT>
</THESIS>
<THESIS>
<NUMBER> 4241 </NUMBER>
<ORDER>   AAG9404860 </ORDER>
<TITLE>   NONLINEAR MODAL CONTROL </TITLE>
<AUTHOR>   SLATER, JOSEPH CARL </AUTHOR>
<YEAR>   1993 </YEAR>
<INSTITUTION>   STATE UNIVERSITY OF NEW YORK AT BUFFALO; 0656 </INSTITUTION>
<DESCRIPTORS>   ENGINEERING, MECHANICAL; ENGINEERING, AEROSPACE; APPLIED MECHANICS; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER>   NIL </ADVISER>
<CLASSIFICATIONS>   MODAL ANALYSIS, VIBRATION </CLASSIFICATIONS>
<ABSTRACT>
The control of multiple degree of freedom nonlinear
systems is perhaps the most challenging control problem
engineers face today. Nonlinear oscillatory systems are
quite common problems (i.e. robotics, slewing, large
strain vibrations, vibration of bimodulus composite
materials, the motion of a swinging spring, the
vibrations of shells and composite plates...) and the
nonlinear control of these systems is becoming more
possible with the advent of ever faster control
computers. Popular methods being used today include
adaptive control, linearizing control, sliding mode
control and neural networks. Lyapunov analysis has been
discarded for extremely complicated systems due to the
difficulty in determining the Lyapunov functions for
them. One concept which has not been applied to
nonlinear systems is that of nonlinear modal control.
The concept of nonlinear modal control is to apply the
method of Shaw and Pierre$sp{24}$ for finding nonlinear
modes and extend the method to include forced excitation
and output equations. Once the dynamic equations of
motion have been decoupled into a set of nonlinear
modes, it is possible to extend the concept of modal
norms for linear systems to the case of systems with
nonlinear modes. The approximately "decoupled"
nonlinear modal equations also allow the design of
control laws for each nonlinear single degree of freedom
system using standard methods (such as Lyapunov design
for each individual modal equation). Once control laws
have been designed for the single degree of freedom
systems, the control is transformed back into the
original state space for controlling the original
system. It is demonstrated in examples that nonlinear
modal control can be used to satisfy multiple control
objectives which linear modal control alone cannot.
</ABSTRACT>
</THESIS>
<THESIS>
<NUMBER> 4242 </NUMBER>
<ORDER>   AAG9404699 </ORDER>
<TITLE>   MATHEMATICAL THEORY OF NEURAL LEARNING AND ITS APPLICATIONS TO STATISTICS AND MOLECULAR BIOLOGY </TITLE>
<AUTHOR>   XIONG, MOMIAO </AUTHOR>
<YEAR>   1993 </YEAR>
<INSTITUTION>   UNIVERSITY OF GEORGIA; 0077 </INSTITUTION>
<DESCRIPTORS>   STATISTICS; COMPUTER SCIENCE; BIOLOGY, GENETICS; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER>   HUBERT J. CHEN; JONATHAN ARNOLD </ADVISER>
<CLASSIFICATIONS>   NEURAL NETWORK </CLASSIFICATIONS>
<ABSTRACT>
In recent years, considerable progress in neural network
research have been made and applications of neural
networks have been extended to a large number of
different disciplines, including biology, psychology,
physics, mathematics, statistics, engineering,
operations research and computer science. The result is
a very interdisciplinary and inspiring research area,
and of course a variety of different terminologies,
concepts and notations. Also there has been increasing
interest in building a complex neural network which
consist of various modular neural subnetworks to carry
out increasingly sophisticated tasks.
This dissertation is devoted to the development of a
unified mathematical theory of neural learning to form
the basis for describing the network topology, for
constructing learning rules by nonsmooth analysis and a
dynamical system approach to constrained optimization,
and for synthesizing hierarchically organized modular
neural networks. This dissertation also illustrates
applications of neural networks to forecasting time
series and physical mapping in molecular biology.
By introducing a neural learning function for various
artificial neural network models, learning is
represented as an optimization process subject to
constraints inherent in a particular problem.
Transforming a constrained optimization problem into an
unconstrained optimization problem through Lagrange
multipliers, for example, may lead to a nonsmooth
learning function. Nonsmooth analysis and a differential
inclusion for solving nonsmooth optimization problems
are introduced to form the theoretical basis for
constructing learning rules. Several stability theorems
for a learning process are proven to guarantee that the
learning function is minimized as the neural network
evolves, i.e. the artificial network performs optimally.
A neural network model based on differential-algebraic
equations (DAEs) is also proposed. The global and local
convergence properties of neural learning algorithms for
constrained optimization problems are analyzed.
Simulations of neutral network models for constrained
optimization problems are carried out. It is
demonstrated that neural network models may provide a
good alternative method to solving constrained
optimization problems.
As an application, a general nonlinear autoregressive-
integrated moving average model based on neural networks
is proposed for forecasting time series and a new
dynamic backpropagation learning procedure is
introduced. The results of a forecasting competition
between a neural network model and a Box-Jenking
forecasting method are also presented. Simulation
results on several examples reveal that forecasting by
the neural network model outperforms the Box-Jenkins
model in terms of mean absolute error and mean
percentage forecast error.
The neural learning theory is also applied to a physical
mapping problem in molecular biology and an attempt to
prove the consistency of a neural learning algorithm in
this specific setting is established.
</ABSTRACT>
</THESIS>
<THESIS>
<NUMBER> 4243 </NUMBER>
<ORDER>   AAG9404622 </ORDER>
<TITLE>   AUTOMATIC DESIGN OF AUTOTUNERS FOR PID CONTROLLERS </TITLE>
<AUTHOR>   ZHOU, GAIYE </AUTHOR>
<YEAR>   1993 </YEAR>
<INSTITUTION>   THE UNIVERSITY OF TENNESSEE; 0226 </INSTITUTION>
<DESCRIPTORS>   ENGINEERING, ELECTRONICS AND ELECTRICAL; COMPUTER SCIENCE; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER>   J. DOUGLAS BIRDWELL </ADVISER>
<CLASSIFICATIONS>   MACHINE LEARNING, CONTROL SYSTEMS </CLASSIFICATIONS>
<ABSTRACT>
This dissertation describes three new methods to
automatically design autotuners for control systems: the
decision tree (DT) method, the simulated annealing and
decision tree (SA-DT) method, and the simulated
annealing and fuzzy logic (SA-FL) method. The DT method
uses representatives from a class of systems to
construct a decision tree autotuner. The autotuner
constructed is therefore to be applied to the systems
within that trained class, particularly lower order
systems. The SA-DT method uses a nominal process model
but allows the parameters of the model to change within
a certain range. A simulated annealing optimization
method is used to guide the modifications of controller
parameters for extracted example systems, and an
inductive inference method is used to construct a
decision tree autotuner. This method is intended to be
applied to more complex systems or higher order systems.
The SA-FL method uses a simulated annealing optimization
method to construct a fuzzy logic autotuning (FLA) rule
base. This approach produces a FLA rule base
automatically by making tests to the process without any
a priori information about the process or human
expertise about the tuning procedures. The main
advantages of the three methods over the existing
methods are that (1) the autotuner is constructed
automatically using machine learning and/or simulated
annealing optimization; (2) the design procedure is
easily repeated or modified to construct autotuners for
different types of systems with particular performance
requirements; (3) methods such as Ziegler-Nichols' and
of minimizing integral of time-weighted absolute error
(ITAE) or integral of squared error (ISE) are not used
to tune the controller or select an initial controller;
(4) neither human experience about the process nor
particular specifications on the system dynamics is
required to design an autotuner; (5) controller
structures are not limited; (6) the tuning process is
adaptive to the process changes, and (7) practioners
(users) can specify their own controller objectives and
ways to modify the controllers.
</ABSTRACT>
</THESIS>
<THESIS>
<NUMBER> 4244 </NUMBER>
<ORDER>   AAG9404172 </ORDER>
<TITLE>   A FACTORING APPROACH FOR PROBABILISTIC INFERENCE IN BELIEF NETWORKS </TITLE>
<AUTHOR>   LI, ZHAOYU </AUTHOR>
<YEAR>   1993 </YEAR>
<INSTITUTION>   OREGON STATE UNIVERSITY; 0172 </INSTITUTION>
<DESCRIPTORS>   COMPUTER SCIENCE; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER>   BRUCE D'AMBROSIO </ADVISER>
<CLASSIFICATIONS>   NIL </CLASSIFICATIONS>
<ABSTRACT>
Reasoning about any realistic domain always involves a
degree of uncertainty. Probabilistic inference in belief
networks is one effective way of reasoning under
uncertainty. Efficiency is critical in applying this
technique, and many researchers have been working on
this topic. This thesis is the report of our research in
this area.
This thesis contributes a new framework for
probabilistic inference in belief networks. The
previously developed algorithms depend on the
topological structure of a belief network to perform
inference efficiently. Those algorithms are constrained
by the way they use topological information and may not
work efficiently for some inference tasks. This thesis
explores the essence of probabilistic inference,
analyzes previously developed algorithms, and presents a
factoring approach for probabilistic inference. It
proposes that efficient probabilistic inference in
belief networks can be considered as an optimal
factoring problem.
The optimal factoring framework provides an alternative
perspective on probabilistic inference and a
quantitative measure of efficiency for an algorithm.
Using this framework, this thesis presents an optimal
factoring algorithm for poly-tree networks and for
arbitrary belief networks (albeit with exponential worst-
case time complexity for non-poly-tree networks). Since
the optimal factoring problem in general is a hard
problem, a heuristic algorithm, called set-factoring, is
developed for multiply-connected belief networks. Set
factoring is shown to outperform previously developed
algorithms. We also apply the optimal factoring
framework to the problem of finding an instantiation of
all nodes of a belief network which has the largest
probability and present an efficient algorithm for that
task.
Extensive computation of probabilistic inference renders
any currently used exact probabilistic inference
algorithm intractable for large belief networks. One way
to extend this boundary is to consider parallel
hardware. This thesis also explores the issue of
parallelizing probabilistic inference in belief
networks. The feasibility of parallelizing probabilistic
inference is demonstrated analytically and
experimentally. Exponential-time numerical computation
can be reduced by a polynomial-time factoring heuristic.
This thesis offers an insight into the effect of the
structure of a belief network on speedup and efficiency.
</ABSTRACT>
</THESIS>
<THESIS>
<NUMBER> 4245 </NUMBER>
<ORDER>   AAG9404052 </ORDER>
<TITLE>   A CRITIQUING EXPERT SYSTEM TO ASSIST IN OPERATIONS OF THE SAN FRANCISCO WATER SUPPLY SYSTEM </TITLE>
<AUTHOR>   STEINEMANN, ANNE CAROL </AUTHOR>
<YEAR>   1993 </YEAR>
<INSTITUTION>   STANFORD UNIVERSITY; 0212 </INSTITUTION>
<DESCRIPTORS>   ENGINEERING, CIVIL; COMPUTER SCIENCE; URBAN AND REGIONAL PLANNING; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER>   LEONARD ORTOLANO </ADVISER>
<CLASSIFICATIONS>   EXPERT SYSTEM </CLASSIFICATIONS>
<ABSTRACT>
A critiquing expert system was developed to assist in
operating San Francisco's water supply network. The
critiquing system goes beyond a traditional expert
system by refining (rather than supplying) the user's
proposed operating plan through a critique. A
traditional expert system requests problem-specific
data, then provides the operator with a plan. In the
critiquing approach, the operator submits not only
relevant information to the system, but also a proposed
plan. The system evaluates the plan and provides
feedback, which includes suggestions for improvement,
warnings, and alternatives.
The SFWD was motivated to have the critiquing system
developed because of the perceived benefits in
formalizing operating expertise in a critiquing system.
Operating decisions are based on heuristic knowledge,
not mathematical models. When personnel leave, the SFWD
loses key information about how to operate the water
supply network. A critiquing system can improve
operators' decisions by providing expert feedback on
their proposed plans, and can aid in training novice
operators.
Building the critiquing expert system provided several
technical challenges. A new paradigm was designed to
implement critiquing in an expert system development
tool. Also, developing a critiquing system is more
complex than developing a traditional expert system. The
critiquing paradigm and system development techniques
designed for this research can be used to build
critiquing systems in a variety of domains.
The research included experiments to test the postulated
advantages of the critiquing approach over the
traditional approach to expert systems. The results were
unambiguous; the critiquing system was preferred to the
traditional expert system for each of several measures
of system performance and acceptability.
The research makes three main contributions. First, the
research establishes the feasibility of implementing a
critiquing system for decision support in a civil
engineering problem domain. Second, the research
demonstrates, both theoretically and empirically, the
substantial benefits of the critiquing approach to
expert systems. Third, the research reveals ways the
organization influences the system's development, and
how system development profoundly influences the
organization. Not only the system itself, but also the
development process that creates the system, fosters
organizational acceptance and use of the system.
</ABSTRACT>
</THESIS>
<THESIS>
<NUMBER> 4246 </NUMBER>
<ORDER>   AAG9404028 </ORDER>
<TITLE>   PLACA, AN AGENT ORIENTED PROGRAMMING LANGUAGE </TITLE>
<AUTHOR>   THOMAS, SARAH REBECCA </AUTHOR>
<YEAR>   1993 </YEAR>
<INSTITUTION>   STANFORD UNIVERSITY; 0212 </INSTITUTION>
<DESCRIPTORS>   COMPUTER SCIENCE; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER>   YOAV SHOHAM </ADVISER>
<CLASSIFICATIONS>   NIL </CLASSIFICATIONS>
<ABSTRACT>
When multiple "agents" (robots, intelligent
processes, people) share an environment they very often
share resources; this requires coordination. Centralized
coordination introduces a bottleneck into the system, so
distributed coordination is often preferable. If agents
can adopt new tasks dynamically then maximum flexibility
is obtained when this coordination is done dynamically
as well. This requires that agents be able to
communicate with each other, and further that they be
able to decide dynamically when and what to communicate.
Shoham has proposed "agent oriented
programming" as a method for programming
intelligent, autonomous processes which interact in a
shared environment. "Agents" are entities that
may be modeled in terms of their "mental
states", consisting of such components as beliefs,
abilities, desires, and intentions. An agent's program
gives its initial mental state and a set of rules which
specify a transition function: given an agent's current
state and input, these rules specify the agent's new
mental state and output. Agents communicate by sending
messages; these messages come in several types, where
the types are drawn from speech act theory (requests,
promises, etc.).
In this dissertation we present and discuss a new agent-
oriented programming language, PLACA (which stands for
PLAnning Communicating Agents). PLACA is a descendant of
AGENT0, the first agent-oriented programming language;
it addresses a particular shortcoming of AGENT0.
Specifically, PLACA capitalizes on the planning
abilities of agents. Assuming that all agents in a
particular environment have at least elementary planning
abilities, PLACA agents can make high-level requests of
each other without worrying about the details of how a
particular task will be carried out. In order to achieve
this, agents' mental states have been expanded to
include plans and intentions in addition to the beliefs
and capabilities present in AGENT0 (obligations and
decisions were dropped). The kinds of changes to the
mental state which may be specified in an agent program
have also been expanded.
We present a logic in which to represent the components
of an agent's mental state, the programming language
PLACA, and a description and discussion of a simple
implemented PLACA interpreter.
</ABSTRACT>
</THESIS>
<THESIS>
<NUMBER> 4247 </NUMBER>
<ORDER>   AAG9404001 </ORDER>
<TITLE>   DESIGN AND CONSTRUCTION OF NORMATIVE RISK MANAGEMENT AND DECISION SYSTEMS </TITLE>
<AUTHOR>   REGAN, PETER J. </AUTHOR>
<YEAR>   1993 </YEAR>
<INSTITUTION>   STANFORD UNIVERSITY; 0212 </INSTITUTION>
<DESCRIPTORS>   ENGINEERING, SYSTEM SCIENCE; COMPUTER SCIENCE; ENGINEERING, INDUSTRIAL; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER>   M. ELISABETH PATE-CORNELL </ADVISER>
<CLASSIFICATIONS>   RISK MANAGEMENT </CLASSIFICATIONS>
<ABSTRACT>
My thesis research extends existing approaches and
develops new techniques for the design and construction
of normative decision software systems. Such systems,
which are based on the normative principles of decision
analysis, are used to formulate and evaluate diagnostic
and decision models, typically as influence diagrams.
Problem formulation and evaluation techniques are
applied to engineering risk management situations, which
are a class of partially observable sequential
decisions.
Engineering risk management situations exhibit a
characteristic dynamic pattern. Following an initiating
event, a physical system degrades. Warning signal
thresholds balance false alerts and lead time for
response to an abnormal situation. Delay between signal
and action balances system degradation and information
gathering. Alternative actions balance cost and
improvement.
I decompose the engineering risk management problem into
four basic activities--diagnosis, dynamic evolution,
decision making, and information gathering--and
corresponding representations--belief network, Markov
model, influence diagram, and decision tree. I devise an
automatic problem formulation method for sequential
information gathering that performs flexibly under
resource constraints. The method explicitly considers
temporal and other information-gathering alternative
eligibility conditions to incrementally formulate an
asymmetric set of test sequences. The method also
handles the dynamics of learning (e.g., diagnostic
tests) and of the underlying physical system state. I
illustrate these techniques with rapid detection of and
response to gas leaks on offshore oil platforms.
I design a domain-independent intelligent decision
system that balances guidance and flexibility in
assisting a user with constructing an influence diagram
representation of a decision problem. I also design a
method for customizing this domain-independent
interactive system for a particular domain. The
customization method enables decision analysts with
domain expertise to build prototype intelligent decision
systems whereas only designers skilled in both decision
analysis and software programming can do so now. I
illustrate these concepts with interactive formulation
and evaluation of repair timing decisions following
structural damage to an offshore platform.
</ABSTRACT>
</THESIS>
<THESIS>
<NUMBER> 4248 </NUMBER>
<ORDER>   AAG9403998 </ORDER>
<TITLE>   UTILITY-BASED CATEGORIZATION </TITLE>
<AUTHOR>   POH, KIM LENG </AUTHOR>
<YEAR>   1993 </YEAR>
<INSTITUTION>   STANFORD UNIVERSITY; 0212 </INSTITUTION>
<DESCRIPTORS>   ENGINEERING, SYSTEM SCIENCE; COMPUTER SCIENCE; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER>   MICHAEL R. FEHLING </ADVISER>
<CLASSIFICATIONS>   CATEGORIZATION, DECISION SYSTEMS </CLASSIFICATIONS>
<ABSTRACT>
The ability to categorize and use concepts effectively
is a basic requirement of any intelligent actor. The
utility-based approach to categorization is founded on
the thesis that categorization is fundamentally in
service of action, i.e., the choice of concepts made by
an actor is critical to its choice of appropriate
actions. This is in contrast to classical and similarity-
based approaches which seek logical completeness in
concept description with respect to sensory data rather
than action-oriented effectiveness. Utility-based
categorization is normative and not descriptive. It
prescribes how an intelligent agent ought to
conceptualize to act effectively. It provides ideals for
categorization, specifies criteria for the design of
effective computational agents, and provides a model of
ideal competence. A decision-theoretic framework for
utility-based categorization which involves reasoning
about alternative categorization models of varying
levels of abstraction is proposed. Categorization models
that are too abstract may be blind to details that are
critical for selecting the most appropriate action. On
the other hand, categorization models that are too
detailed may be too expensive to process or may contain
information not critical for selecting the most
appropriate action. Categorization models are,
therefore, evaluated on the basis of the expected value
of their recommended action, taking into account the
associated resource consumption. A knowledge
representation scheme, known as probabilistic conceptual
networks, has been developed to support the dynamic
construction of models at varying levels of abstraction.
This knowledge representation scheme combines the
formalisms of influence diagram from decision analysis
and inheritance/abstraction hierarchy from artificial
intelligence. An incremental approach to categorical
reasoning which involves the dynamic construction and
refinement of categorization models is also developed.
Models may be improved by incrementally making the
concepts under consideration in the model either more
abstract or more detailed. The expected increase in
value of the recommended actions due to model
improvement can be calculated and used to direct and
control the direction of model improvements. By applying
the principle of decision-theoretic control, a resource-
constrained agent can iteratively decide between
continuing to improve the current level of abstraction
in the model, or to act immediately.
</ABSTRACT>
</THESIS>
<THESIS>
<NUMBER> 4249 </NUMBER>
<ORDER>   AAG9403997 </ORDER>
<TITLE>   OPTIMAL TERMINAL CONTROL USING FEEDFORWARD NEURAL NETWORKS </TITLE>
<AUTHOR>   PLUMER, EDWARD STANLEY </AUTHOR>
<YEAR>   1993 </YEAR>
<INSTITUTION>   STANFORD UNIVERSITY; 0212 </INSTITUTION>
<DESCRIPTORS>   ENGINEERING, ELECTRONICS AND ELECTRICAL; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER>   BERNARD WIDROW </ADVISER>
<CLASSIFICATIONS>   NAVIGATION, OBSTACLE AVOIDANCE </CLASSIFICATIONS>
<ABSTRACT>
Multi-layer, sigmoidal neural networks are capable of
approximating continuous, multi-variate functions and,
as such, can implement nonlinear state-feedback
controllers. The most common algorithm for training such
controllers is backpropagation through time (BPTT).
However, BPTT does not deal with terminal control
problems in which the cost function includes the elapsed
trajectory-time.
This difficulty is investigated in the first half of the
thesis. The controller design is reformulated as an
optimization problem defined over the entire field of
extremals with the set of trajectory times incorporated
into this cost function. Necessary first-order
stationary conditions are derived which correspond to
standard BPTT with the addition of certain
transversality conditions. The new gradient algorithm
based on these conditions is called time-optimal
backpropagation through time (TOBPTT). This approach is
tested on several open final-time problems with very
good results.
In the second half of the thesis, an extension to TOBPTT
is proposed for dealing with the problem of navigation
and obstacle avoidance. This method separates the two
tasks of "navigation" and "control"
by first using an array of interconnected processors to
rapidly compute a navigational field associated with the
current obstacle configuration. The algorithm which
accomplishes this is called the cumulative barrier
method. It guarantees the absence of local minima and
ensures that gradient-induced paths steer clear of
obstacle surfaces. Then, a multi-layer network is
trained to steer the vehicle along the negative gradient
of the resulting field. No retraining is necessary when
obstacles are moved; rather, the array simply tracks the
obstacle movements and provides the new gradient
information to the controller. A variant of the truck-
backer is used with good results in testing this method.
</ABSTRACT>
</THESIS>
<THESIS>
<NUMBER> 4250 </NUMBER>
<ORDER>   AAG9403977 </ORDER>
<TITLE>   IRRELEVANCE REASONING IN KNOWLEDGE-BASED SYSTEMS </TITLE>
<AUTHOR>   LEVY, ALON YITZCHAK </AUTHOR>
<YEAR>   1993 </YEAR>
<INSTITUTION>   STANFORD UNIVERSITY; 0212 </INSTITUTION>
<DESCRIPTORS>   COMPUTER SCIENCE; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER>   RICHARD E. FIKES; EDWARD A. FEIGENBAUM </ADVISER>
<CLASSIFICATIONS>   QUERY TREE, HORN RULE </CLASSIFICATIONS>
<ABSTRACT>
Speeding up inferences made from large knowledge bases
is a key to scaling up knowledge based systems. To do
so, a system must have the ability to automatically
identify and ignore information that is irrelevant to a
specific task. This dissertation presents a general
framework and specific methods for enabling a system to
exploit knowledge about irrelevance. Such knowledge can
either be derived automatically by the system, or given
by a user. The framework, which identifies several
classes of irrelevance, is based on a proof-theoretic
analysis of irrelevance. As such, it enables the two key
issues of relevance reasoning to be addressed, namely
the utility of relevance reasoning and the development
of methods for automatically identifying irrelevant
parts of a knowledge base.
The research develops a general tool, the query-tree,
for reasoning about irrelevance. Based on the query-
tree, we developed several algorithms for deciding what
facts are irrelevant to a goal. These algorithms
dramatically speed up inference, especially when the
knowledge base includes a large data base of ground
facts. The query-tree has been investigated primarily
for Horn rule knowledge bases with interpretable
constraints (e.g., order and sort constraints), and
several more expressive extensions. For certain cases,
the algorithms are shown to be complete, in that they
detect all the irrelevant facts. An important aspect of
the query-tree is that it can be built by examining only
a small part of the knowledge base (e.g., only the
rules), and therefore, can be built efficiently. The
query-tree is also used to derive the consequences of
irrelevance knowledge given by a user. We present an
empirical analysis of the algorithms when doing backward
chaining on Horn rules, showing that in practice,
significant savings (often orders of magnitude) are
obtained.
The dissertation also explores the use of relevance
reasoning in the domain of modeling physical devices. It
considers the task of automatically creating a model for
a given device and given query, by composing model-
fragments from a library of models. We describe a novel
model-composition algorithm based on irrelevance
reasoning that composes a model with appropriate
abstractions and perspectives for answering the query.
</ABSTRACT>
</THESIS>
<THESIS>
<NUMBER> 4251 </NUMBER>
<ORDER>   AAG9403976 </ORDER>
<TITLE>   MULTIPLE CHANNEL NEURAL NETWORK MODEL FOR TEXTURE ANALYSIS </TITLE>
<AUTHOR>   LEUNG, MICHAEL MING-TAK </AUTHOR>
<YEAR>   1993 </YEAR>
<INSTITUTION>   STANFORD UNIVERSITY; 0212 </INSTITUTION>
<DESCRIPTORS>   ENGINEERING, ELECTRONICS AND ELECTRICAL; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER>   ALLEN M. PETERSON </ADVISER>
<CLASSIFICATIONS>   GABOR FILTERS, ARTIFICIAL NEURAL NETWORKS </CLASSIFICATIONS>
<ABSTRACT>
With the recent progress in artificial neural network
(ANN) research, the performance of these networks in
image processing and analysis operations is interesting
and important. A major issue in applying these networks
to image problems is the representation of the data
presented to the network. For manageable training and
computation, data reduction and feature representation
is essential. A modular image analysis model is proposed
which incorporates ANN and more conventional image
processing techniques, with particular attention being
paid to the representation of data and the utilization
of output signals from ANN.
The multiple channel neural network model is comprised
of four basic modules: image preprocessing
normalization, multiple channel representation filters,
a neural network classifier and a contextual correction
scheme. To carry out multiple channel representation,
Gabor filters are employed. To generate tuned Gabor
filters for better image representation, a two-phase
filter adaptation algorithm is introduced.
Various problems in textural image analysis are chosen
to evaluate the performance of the model. In fingerprint
features identification, the system is able to locate
minutia positions in fingerprint images. In textural
image classification, both scale-rotation variant and
invariant classifications are carried out. Simulations
demonstrate the usefulness of neural networks and Gabor
filters as classifiers and image features as the model
gives better performance when compared to other
approaches. In textural image segmentation, a context
competition algorithm is introduced to utilize image
context to improve segmentation results of composite
textural images.
</ABSTRACT>
</THESIS>
<THESIS>
<NUMBER> 4252 </NUMBER>
<ORDER>   AAG9403907 </ORDER>
<TITLE>   REDUCED OPERATION BACKPROPAGATION NEURAL NETWORK: ALGORITHMS AND IMPLEMENTATION </TITLE>
<AUTHOR>   BOONYANIT, KAN </AUTHOR>
<YEAR>   1993 </YEAR>
<INSTITUTION>   STANFORD UNIVERSITY; 0212 </INSTITUTION>
<DESCRIPTORS>   ENGINEERING, ELECTRONICS AND ELECTRICAL; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER>   ALLEN M. PETERSON </ADVISER>
<CLASSIFICATIONS>   DIGITAL VLSI </CLASSIFICATIONS>
<ABSTRACT>
Since the resurgence of the field of neural networks due
to the backpropagation algorithm, there have been
numerous proposed algorithms to speed up the convergence
time of backpropagation. Some of them are very good, but
most of them do not take into consideration the amount
of hardware required to implement the algorithm. Without
suitable hardware implementation, the real promise of
neural network applications will be difficult to
achieve. There is a need for special purpose hardware,
particularly in specialized integrated circuits to serve
in high performance real-time applications.
Consequently, this work proposes an adapted
backpropagation algorithm to be judged by the measure of
speed and area if it is implemented with digital VLSI.
Since multiply dominates computation and is expensive in
hardware, the approach is to reduce the number of
multiplies in the backward path of backpropagation
algorithm by setting some neuron errors to zero. This
work proves the convergence theorem for both batch and
stochastic update by the general Robbins-Monro process,
a stochastic approximation process. It is valid if
neuron errors are set to zero randomly and the learning
rate decreases with time.
However, setting the neuron errors to zero randomly is
slow compared to the standard algorithm. So, this work
proposes why neuron errors should be set to zero
according to their magnitudes. The theory is confirmed
with simulation results of a character recognition
problem by minimizing errors of training patterns only
and results of a function approximation problem with
testing patterns to monitor generalization performance.
Then this work proposes a detailed architecture for
hardware implementation of the algorithm with the
emphasis on the MAC (Multiply-Accumulate) unit and the
weight memory unit. The efficient implementation of the
Manchester carry chain based largest K unit, which is
used to select the largest K neuron errors, is proposed
in detail. Circuit simulations are performed to show its
feasibility for use in a high speed neural network
processor chip.
The conclusion is that the reduced operation algorithm
performance in terms of speed and area is superior to a
standard backpropagation algorithm.
</ABSTRACT>
</THESIS>
<THESIS>
<NUMBER> 4253 </NUMBER>
<ORDER>   AAG9330172 </ORDER>
<TITLE>   SIFT: A SELF-IMPROVING FRACTIONS TUTOR </TITLE>
<AUTHOR>   GUTSTEIN, ERIC HOWARD </AUTHOR>
<YEAR>   1993 </YEAR>
<INSTITUTION>   THE UNIVERSITY OF WISCONSIN - MADISON; 0262 </INSTITUTION>
<DESCRIPTORS>   COMPUTER SCIENCE; EDUCATION, MATHEMATICS; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER>   JUDE W. SHAVLIK </ADVISER>
<CLASSIFICATIONS>   MACHINE LEARNING </CLASSIFICATIONS>
<ABSTRACT>
Artificially intelligent computer systems that interact
with the environment should be able to learn from
experience and improve their performance. This thesis
describes a rule-based learning system: scSIFT--a Self-
Improving Fractions Tutor--is a computer model of what
and how a human tutor might learn over the course of
tutoring. scSIFT learns through its tutoring experience
and is based on a detailed study of a human tutor
teaching fractions. scSIFT tutors computer simulations
of student problem solvers and inputs the transcripts to
its learning module. After each tutoring session, the
learning module reviews the transcript and (1)
recognizes inappropriate tutorial actions, (2) analyzes
the source of the problem, and (3) modifies both its
procedural knowledge--it creates new tutorial rules in
three different ways--and its conceptual knowledge--it
extends its data base of possible student
misconceptions. As it continues to tutor with its
augmented knowledge, it evaluates the efficacy of its
knowledge alterations and adjusts them accordingly.
scSIFT's principle weakness is that it tutors
simulations rather than tutoring and learning from
children. However, machine learning can be viewed as an
experimental science--one can vary system parameters,
learning conditions, and independent variables to
systematically study the results. Experiments were
conducted with a population of student simulations and a
measure of tutorial quality was defined to evaluate the
sessions. The empirical results show: (1) scSIFT's
quality improves as it tutors and learns, (2) quality
degrades gradually as random student error increases,
(3) with one rule-learning method removed, quality
suffers, but scSIFT still learns, (4) its learning
behavior is intuitively plausible in several ways, and
(5) scSIFT learns quickly at first, then gradually slows
down and fine tunes its new knowledge.
scSIFT's contribution is that it synthesizes mathematics
education and machine learning in an intelligent
tutoring system in novel ways. It shows that through a
detailed study of a human tutor, one can design a system
that learns in ways that would be desirable if it were
teaching and learning from children--thus, scSIFT
presents a framework for future work in self-improving
tutoring systems.
</ABSTRACT>
</THESIS>
<THESIS>
<NUMBER> 4254 </NUMBER>
<ORDER>   AAGNN82765 </ORDER>
<TITLE>   AN INFORMATION-THEORETIC UNSUPERVISED LEARNING ALGORITHM FOR NEURAL NETWORKS </TITLE>
<AUTHOR>   BECKER, HELEN SUZANNA </AUTHOR>
<YEAR>   1993 </YEAR>
<INSTITUTION>   UNIVERSITY OF TORONTO (CANADA); 0779 </INSTITUTION>
<DESCRIPTORS>   COMPUTER SCIENCE; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER>   GEOFFREY HINTON </ADVISER>
<CLASSIFICATIONS>   VISUAL IMAGES </CLASSIFICATIONS>
<ABSTRACT>
In the unsupervised learning paradigm, a network of
neuron-like units is presented an ensemble of input
patterns from a structured-environment, such as the
visual world, and learns to represent the regularities
in that input. The major goal in developing unsupervised
learning algorithms is to find objective functions that
characterize the quality of the network's representation
without explicitly specifying the desired outputs of any
of the units. Previous approaches in unsupervised
learning, such as clustering, principal components
analysis, and information-transmission-based methods,
make minimal assumptions about the kind of structure in
the environment, and they are good for preprocessing raw
signal input. These methods try to model all of the
structure in the environment in a single processing
stage. The approach taken in this thesis is novel, in
that our unsupervised learning algorithms do not try to
preserve all of the information in the signal. Rather,
we start by making strongly constraining assumptions
about the kind of structure of interest in the
environment. We then proceed to design learning
algorithms which will discover precisely that structure.
By constraining what kind of structure will be extracted
by the network, we can force the network to discover
higher level, more abstract features. Additionally, the
constraining assumptions we make can provide a way of
decomposing difficult learning problems into multiple
simpler feature extraction stages. We propose a class of
information-theoretic learning algorithms which cause a
network to become tuned to spatially coherent features
of visual images. Under Gaussian assumptions about the
spatially coherent features in the environment, we have
shown that this method works well for learning depth
from random dot stereograms of curved surfaces. Using
mixture models of coherence, these algorithms can be
extended to deal with discontinuities, and to form
multiple models of the regularities in the environment.
Our simulations demonstrate the general utility of the
Imax algorithms in discovering interesting, non-trivial
structure (disparity and depth discontinuities) in
artificial stereo images. This is the first attempt we
know of to model perceptual learning beyond the earliest
stages of low-level feature extraction, and to model
multiple stages of unsupervised learning.
</ABSTRACT>
</THESIS>
<THESIS>
<NUMBER> 4255 </NUMBER>
<ORDER>   AAGNN82518 </ORDER>
<TITLE>   ON EFFICIENT LEARNING ALGORITHMS FOR NEURAL NETWORKS </TITLE>
<AUTHOR>   GOLEA, MOSTEFA </AUTHOR>
<YEAR>   1993 </YEAR>
<INSTITUTION>   UNIVERSITY OF OTTAWA (CANADA); 0918 </INSTITUTION>
<DESCRIPTORS>   PHYSICS, ELECTRONICS AND ELECTRICITY; ARTIFICIAL INTELLIGENCE; ENGINEERING, ELECTRONICS AND ELECTRICAL </DESCRIPTORS>
<ADVISER>   MARIO MARCHAND </ADVISER>
<CLASSIFICATIONS>   HEBB RULE </CLASSIFICATIONS>
<ABSTRACT>
Inductive Inference Learning can be described in terms
of finding a good approximation to some unknown
classification rule f, based on a pre-classified set of
training examples $langle$x,f(x)$rangle.$ One particular
class of learning systems that has attracted much
attention recently is the class of neural networks. But
despite the excitement generated by neural networks,
learning in these systems has proven to be a difficult
task. In this thesis, we investigate different ways and
means to overcome the difficulty of training feedforward
neural networks. Our goal is to come up with efficient
learning algorithms for new classes (or architectures)
of neural nets. In the first approach, we relax the
constraint of fixed architecture adopted by most neural
learning algorithms. We describe two constructive
learning algorithms for two-layer and tree-like
networks. In the second approach, we adopt the
"probably approximately correct" (PAC)
learning model and we look for positive learnability
results by restricting the distribution generating the
training examples, the connectivity of the networks,
and/or the weight values. This enables us to identify
new classes of neural networks that are efficiently
learnable in the chosen setting. In the third and final
approach, we look at the problem of learning in neural
networks from the average case point of view. In
particular, we investigate the average case behavior of
the well known clipped Hebb rule when learning different
neural networks with binary weights. The arguments given
for the "efficient learnability" range from
extensive simulations to rigorous mathematical proofs.
</ABSTRACT>
</THESIS>
<THESIS>
<NUMBER> 4256 </NUMBER>
<ORDER>   AAG9406405 </ORDER>
<TITLE>   NEURAL NETWORK DESIGN: A PROCESS MODEL DEVELOPMENT METHODOLOGY </TITLE>
<AUTHOR>   HUSTON, TERRY LEE </AUTHOR>
<YEAR>   1993 </YEAR>
<INSTITUTION>   UNIVERSITY OF PITTSBURGH; 0178 </INSTITUTION>
<DESCRIPTORS>   BUSINESS ADMINISTRATION, MANAGEMENT; PSYCHOLOGY, GENERAL; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER>   JERROLD MAY </ADVISER>
<CLASSIFICATIONS>   NIL </CLASSIFICATIONS>
<ABSTRACT>
Managerial problem solvers utilize a number of decision
making aids to assist them in problem solving. There has
been little work done to assess how the problem solver
formulates the initial setup of a problem using these
aids. Such an assessment can provide insight into how
the problem formulation process can be improved.
Gathering information concerning the initial problem
formulation process is an important and difficult task.
It is important because a better initial formulation can
result in a more efficient solution procedure. It is
difficult because the formulation process is more of an
art than a science. A human problem solving approach is
used to study human expertise in the art of problem
formulation in the area of neural network design.
Concurrent verbal protocol analysis is used to construct
a cognitive model of an expert neural network designer
solving a real world problem formulation task for use as
the basis for a process model. Augmentations to this
cognitive model arise from the protocols of a second
problem solver, as well as protocols from each of the
subjects solving an additional problem. The resultant
process model of neural network design is tested on a
third problem and by neural network design novices.
An incremental verification and validation procedure is
demonstrated incorporating a method for eliciting user
intentions and the effects of a decision aid on the
problem solving processes. Mental model comparisons are
made in light of expert/novice differences.
The result offers structure to the neural network
problem formulation process for subsequent analysis and
improvement. An extension of the research methodology
can be used to elicit the problem formulation processes
in other problem solving domains with possible
improvement offered to the formulation process in these
domains. The methodology also offers a basis for
selection of the best problem solving tool to apply to a
particular problem.
</ABSTRACT>
</THESIS>
<THESIS>
<NUMBER> 4257 </NUMBER>
<ORDER>   AAG9406403 </ORDER>
<TITLE>   A NEURAL NETWORK APPROACH FOR REAL-TIME CONTROL OF FLEXIBLE MANUFACTURING SYSTEMS </TITLE>
<AUTHOR>   HAO, GANG </AUTHOR>
<YEAR>   1993 </YEAR>
<INSTITUTION>   UNIVERSITY OF PITTSBURGH; 0178 </INSTITUTION>
<DESCRIPTORS>   BUSINESS ADMINISTRATION, MANAGEMENT; ARTIFICIAL INTELLIGENCE; OPERATIONS RESEARCH </DESCRIPTORS>
<ADVISER>   LUIS G. VARGAS </ADVISER>
<CLASSIFICATIONS>   NIL </CLASSIFICATIONS>
<ABSTRACT>
Flexible Manufacturing Systems (FMS) are of interest to
both academic and industrial communities and are rapidly
replacing classical manufacturing systems. In general, a
Flexible Manufacturing System, with all operations under
central computer control, consists of three major
components: (1) a job shop, including machine tools or
workstations and other support equipment for
manufacturing, (2) a storage system, involving in-
process storage or warehouse inventory for material
stores, and (3) a Material Handling System (MHS), which
automates material movement among the FMS cells. In
existing FMS literature, research has been focused on
each component in isolation. The optimization of
operations related to linkages among the components have
not been adequately studied. In particular, the
interaction and integration of operations management
between a job shop and the MHS has been least
researched. FMS control is a very complicated task,
which involves many problems that are computationally NP-
hard. Methodologically, some difficulties and
limitations have been identified in most approaches
currently adopted in FMS research, such as heuristic
approaches, optimization techniques and AI/ES methods.
The real manufacturing environment, with its constant
machine breakdown and limited capacity, requires
simultaneous consideration and effective coordination of
both machine operations and MHS operations, as well as
on-line decision efficiency, and the capability of
dealing with dynamic changes and different system
configurations. Neural Networks, as a means of real-time
control, fulfill these requirements. Our research
provides not only a new strategy to the long- standing
FMS operation control problem, but also a new area for
Neural Network application.
</ABSTRACT>
</THESIS>
<THESIS>
<NUMBER> 4258 </NUMBER>
<ORDER>   AAG9406394 </ORDER>
<TITLE>   A PROCESS MODEL OF INITIAL REPRESENTATION FORMATION IN A LAN PLANNING PROBLEM </TITLE>
<AUTHOR>   ABRAHAM, DOLPHY MATHEW </AUTHOR>
<YEAR>   1993 </YEAR>
<INSTITUTION>   UNIVERSITY OF PITTSBURGH; 0178 </INSTITUTION>
<DESCRIPTORS>   BUSINESS ADMINISTRATION, GENERAL; PSYCHOLOGY, GENERAL; COMPUTER SCIENCE; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER>   NIL </ADVISER>
<CLASSIFICATIONS>   EXPERT SYSTEMS </CLASSIFICATIONS>
<ABSTRACT>
This dissertation investigates the process of the
formation of an initial representation of ill-structured
problems in business decision making. A typical ill-
structured problems, namely LAN planning is used as the
domain for executing the study. The process model of LAN
planning describes the information used by the problem
solver in the initial stages of problem solving and
creation of an initial representation of the problem.
The process model tracks how the initial representation
is created and describes how to test that the initial
representation process is complete. The initial
representation contains information about the problem
context, and the problem solver's perspective of the
problem. To validate the process model, additional
concurrent verbal protocols were traced through the
process model to see how the model matched the process.
Research into how ill-structured problems are solved
suggests that problem solvers impose structure on the
problem which helps in arriving at a solution. Prior
research also suggests that initial problem
representations are one way to impose structure onto ill-
structured problems. While there have been studies
looking at how initial problem representations affect
problem solving, there is a lack of research into the
process by which initial representations are formed. The
research is aimed at this gap in the problem solving
literature.
The primary contribution of this research is, thus, the
process model of initial representation formation. The
components of the process model improves our
understanding of the problem structuring process. They
also point to new directions that may be pursued in
attempting to enhance the design of decision support
systems.
</ABSTRACT>
</THESIS>
<THESIS>
<NUMBER> 4259 </NUMBER>
<ORDER>   AAG9404824 </ORDER>
<TITLE>   CELL FORMATION TECHNIQUES FOR LARGE DATA SETS </TITLE>
<AUTHOR>   KAPARTHI, SHASHIDHAR </AUTHOR>
<YEAR>   1993 </YEAR>
<INSTITUTION>   STATE UNIVERSITY OF NEW YORK AT BUFFALO; 0656 </INSTITUTION>
<DESCRIPTORS>   BUSINESS ADMINISTRATION, MANAGEMENT; ARTIFICIAL INTELLIGENCE; OPERATIONS RESEARCH </DESCRIPTORS>
<ADVISER>   NALLAN C. SURESH </ADVISER>
<CLASSIFICATIONS>   NEURAL NETWORKS, GROUP TECHNOLOGY </CLASSIFICATIONS>
<ABSTRACT>
The design of a cellular manufacturing system typically
involves a hierarchical, multi-phased procedure such as
Burbidge's production flow analysis (PFA). These
procedures include the mathematically complex
"group analysis" phase towards which this
dissertation is addressed. The problem involves
rearranging a part-machine incidence matrix into a block
diagonal form. This has been known to be a NP-complete
problem, and hence numerous heuristic procedures have
been developed.
In this dissertation, in addition to traditional
methods, a new, pattern recognition approach based on
massive parallelism is also investigated for this
problem. These neural network-based approaches were
recently introduced for cell formation by a few
researchers exploiting their pattern recognition
capabilities. In addition, using ideas from these leader
clustering algorithms, traditional algorithms such as
linear clustering method and the p-median formulation
are augmented to enable them to assign parts to cells.
In this research, the performance of cell formation
methods is studied on large data sets using a mixture-
model approach. The relative performance of a variety of
cell formation techniques, including bond energy
algorithm (BEA), direct clustering analysis (DCA),
improved rank order clustering algorithm (ROC2), ZODIAC,
ideal seed non-hierarchical clustering method (ISNC),
augmented p-median method (APM), augmented linear
clustering algorithm (ALC), and neural network-based
algorithms, including ART1, its modifications (ART1/KS,
ART1/KSC), and fuzzy ART (ART/F), is evaluated using a
randomized block experimental design. Since the optimal
solution is unknown for large data sets, a known
solution (block diagonal structure) is disguised and
clustered by various algorithms. Performance measures
include Rand index, adjusted Rand index and bond energy
recovery ratio. Experimental factors include matrix
size, degree of distortion, and the order of
presentation of the information.
The results show that, in general, the leader clustering
methods (ART1, ART1/KS, ART1/KSC, ART/F, ALC) are
superior to non-agglomerative clustering methods (ISNC,
ZODIAC), which in turn are superior to array-based
methods (BEA, ROC2, DCA). The efficiency of these
algorithms, the limited computer resources needed, and
as well as the quality of the solutions indicate that
these methods would be of great value for the cell
formation process.
</ABSTRACT>
</THESIS>
<THESIS>
<NUMBER> 4260 </NUMBER>
<ORDER>   AAG9404651 </ORDER>
<TITLE>   MODELING CANNABIS CULTIVATION IN NORTH GEORGIA </TITLE>
<AUTHOR>   FUNG, DEVLIN SHEONG-SIEW </AUTHOR>
<YEAR>   1993 </YEAR>
<INSTITUTION>   UNIVERSITY OF GEORGIA; 0077 </INSTITUTION>
<DESCRIPTORS>   GEOGRAPHY; COMPUTER SCIENCE; SOCIOLOGY, CRIMINOLOGY AND PENOLOGY; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER>   ROY WELCH </ADVISER>
<CLASSIFICATIONS>   NATIONAL FORESTS, GIS, EXPERT SYSTEMS </CLASSIFICATIONS>
<ABSTRACT>
Cannabis and its associated product, Marijuana, is a
Schedule I controlled substance. Its use, possession,
production, and transportation is prohibited by law.
However, it is the most readily available drug in the
United States, and of particular concern to authorities
is the increasing illegal use of the National Forest
System lands for Cannabis cultivation. Over the last
five years this has become a serious problem in the
Chattahoochee National Forest of north Georgia, and the
number of arrests and seizures has risen sharply in the
past two years. The objective of this project was to
develop an expert system knowledge-base and a geographic
information system (GIS) database, and to integrate
their applications for identifying potential Cannabis
growth sites on National Forest lands in north Georgia.
The knowledge-base was developed from information
acquired from the United States Forest Service (USFS)
and the Drug Enforcement Administration (DEA) law
enforcement personnel involved in the interdiction
operations. This information was coded as rules in the
knowledge-base using the expert system shell, 1stCLASS.
The GIS database included map layers in ARC/INFO format,
digitized from United States Geological Survey (USGS)
and USFS maps, supplemented by USGS digital line graph
(DLG) and digital elevation model (DEM) files. A
software interface which included routines for data-
access, data-transfer, decision-support, and graphics
display was developed to integrate the knowledge-base
with the GIS database.
The integrated-system was evaluated based on a
comparative analysis of Cannabis growth site locations
predicted by the system with confirmed field site
locations provided by law enforcement agencies. Results
of the analysis indicated that more than 80 percent of
the confirmed sites were located within the predicted
regions. With the cooperation of the USFS Law
Enforcement Unit, field checks were undertaken at three
of the predicted locations. At all three locations,
Cannabis was discovered.
Successful evaluation of the integrated system has
demonstrated the feasibility of integrating an expert
system knowledge-base with a GIS database for
identifying Cannabis growth sites in the Chattahoochee
National Forest of north Georgia. It is anticipated that
the system will be a useful tool for law enforcement
applications in Cannabis interdiction operations.
</ABSTRACT>
</THESIS>
<THESIS>
<NUMBER> 4261 </NUMBER>
<ORDER>   AAG9404581 </ORDER>
<TITLE>   BUILDING EXPERT SYSTEMS: A PHENOMENOLOGICAL APPROACH TO ACCESSING EXPERT KNOWLEDGE </TITLE>
<AUTHOR>   GREENE, JAMES IVAN HUGH, JR. </AUTHOR>
<YEAR>   1993 </YEAR>
<INSTITUTION>   THE UNIVERSITY OF TENNESSEE; 0226 </INSTITUTION>
<DESCRIPTORS>   EDUCATION, TECHNOLOGY; EDUCATION, ADULT AND CONTINUING; ARTIFICIAL INTELLIGENCE; BUSINESS ADMINISTRATION, MANAGEMENT </DESCRIPTORS>
<ADVISER>   JOHN M. PETERS </ADVISER>
<CLASSIFICATIONS>   KNOWLEDGE ACQUISITION </CLASSIFICATIONS>
<ABSTRACT>
The purpose of this study was to demonstrate a knowledge
acquisition technique for developing expert systems.
Employee performance problem cases were prepared which
represented a wide range of organizations and problems
situations that manager could be expected to encounter.
An expert manager/trainer was presented these cases and
asked to select an appropriate intervention to correct
employee problems.
Data were collected by an audio-taped interview using
the Action-Reason-Thematic-Technique (ARTT). ARTT
involves a phenomenological interview and analysis
procedure designed to identify and describe a person's
actions and supporting reasoning structure.
An ARTT analysis of the expert's reasoning structure
revealed 52 rules used by the expert as he selected
intervention strategies. These rules were encoded into
an expert system shell to create an operational expert
system. These results demonstrated that: (1) the ARTT
successfully described the expert's actions and
reasoning structure; (2) the analysis procedure
identified and described rules that could explain the
expert's problem solving process; and (3) a
phenomonological analysis of an expert's account of a
problem solving process can successfully produce a
knowledge base for an expert system.
Implications of the study include: (1) ARTT should be
used in additional studies that would demonstrate its
utility as a knowledge acquisition technique; (2) the
effectiveness of the expert system developed with the
use of ARTT should be tested in experimental conditions
to determine the system's effectiveness as a decision
aid; and (3) expert systems have potential use as
training aids where expert knowledge is scarce or other
access to expert knowledge is not cost efficient.
</ABSTRACT>
</THESIS>
<THESIS>
<NUMBER> 4262 </NUMBER>
<ORDER>   AAG9404572 </ORDER>
<TITLE>   AUDITOR EXPERIENCE IN PRELIMINARY CONTROL RISK ASSESSMENTS: NEURAL NETWORK MODELS OF AUDITORS' KNOWLEDGE STRUCTURES </TITLE>
<AUTHOR>   DAVIS, JEFFERSON TORONTO </AUTHOR>
<YEAR>   1993 </YEAR>
<INSTITUTION>   THE UNIVERSITY OF TENNESSEE; 0226 </INSTITUTION>
<DESCRIPTORS>   BUSINESS ADMINISTRATION, ACCOUNTING; COMPUTER SCIENCE; PSYCHOLOGY, EXPERIMENTAL; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER>   JAMES H. SCHEINER </ADVISER>
<CLASSIFICATIONS>   NIL </CLASSIFICATIONS>
<ABSTRACT>
This study examines how experience influences auditors'
abilities to select and use relevant cues to make
efficient, appropriate preliminary control risk
assessments (CRAs). Using the preliminary CRAs of two
auditor groups with differing levels of experience, this
study developed two neural network models of auditors'
CRA decision processes. The models provided a means of
capturing and measuring auditors' selective attention, a
cognitive concept describing a decision process that
selects and uses cues based on cue dimensions, the
different qualities or aspects of a cue perceived to
provide a contrast in level of significance for making
categorical decisions. The results showed that the
typical experienced senior auditor exhibited a higher
level of selective attention to cue dimensions. The
experienced group also used fewer cues and exhibited
less decision time than did the less experienced group.
The results are consistent with the conclusions in the
expertise literature (e.g. Anderson, 1983; Johnson, et
al. 1984; Dreyfus & Dreyfus, 1986) that experience
does lead to a more top-down approach to cue selection
and a more highly developed knowledge structure that
provides more information content for relating the
selected cues to the resulting decision response.
However, decision error in relation to the firm's CRA
solution was nearly the same for both groups and
suggested that both groups could improve their CRA
process. In order for the inexperienced seniors to
adjust their control risk assessment to match the firm's
solution, they need to use the information provided by
their selected cue set better. Although the experienced
seniors' CRAs were more consistent with their cue sets
than the inexperienced seniors' CRAs were with their
chosen cue sets, in terms of increasing consensus to the
firm's prescribed solution, the experienced group may
need to consider planning to rely more on internal
controls and less on tests of account balances for this
case that exhibited a fairly strong internal control
structure.
</ABSTRACT>
</THESIS>
<THESIS>
<NUMBER> 4263 </NUMBER>
<ORDER>   AAGNN82445 </ORDER>
<TITLE>   OUTILS QUANTITATIFS D'AIDE A LA DECISION: LE DIFFICILE EQUILIBRE ENTRE RIGUEUR ET PERTINENCE </TITLE>
<AUTHOR>   BOULAIRE, CHRISTELE </AUTHOR>
<YEAR>   1993 </YEAR>
<INSTITUTION>   UNIVERSITE LAVAL (CANADA); 0726 </INSTITUTION>
<DESCRIPTORS>   SOCIOLOGY, THEORY AND METHODS; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER>   JEAN-MARC MARTEL </ADVISER>
<CLASSIFICATIONS>   FRENCH TEXT, EXPERT SYSTEM </CLASSIFICATIONS>
<ABSTRACT>
Toute activite d'aide a la decision sous-entend une
relation d'aide. Nous esquissons un schema de cette
relation qui devient la pierre angulaire de cette these.
Nous dressons un bilan critique de differentes
conceptions de cette relation et constatons un
desequilibre dans la "couverture" des divers
elements de notre schema. Afin de tendre vers un
meilleur equilibre, nous cherchons alors a etayer le
discours actuel sur l'usage des methodes en considerant
certaines caracteristiques des aides et aidants, au plan
social et notamment dans sa composante cognitive. Une
demarche concrete d'aide a la decision avec recours aux
formalismes mathematiques vient illustrer certains
usages mis de l'avant par notre reflexion et apporter
des exemples d'usages plus contextuels, qui debordent
l'usage technique de l'outil. Nous proposons quelques
points de repere au conseiller puis quelques elements
que pourrait contenir sa formation ainsi que des voies
de recherche pour favoriser l'atteinte de ce difficile
mais primordial equilibre entre rigueur et pertinence
dans des demarches d'aide a la decision avec recours aux
formalismes mathematiques.
</ABSTRACT>
</THESIS>
<THESIS>
<NUMBER> 4264 </NUMBER>
<ORDER>   AAG1353879 </ORDER>
<TITLE>   DEVELOPMENT OF AN INTELLIGENT ANALYSIS TOOL FOR CONTINUOUS SIMULATION SYSTEMS </TITLE>
<AUTHOR>   GUDIPATI, AMBAPRASAD </AUTHOR>
<YEAR>   1993 </YEAR>
<INSTITUTION>   MISSISSIPPI STATE UNIVERSITY; 0132 </INSTITUTION>
<DESCRIPTORS>   INFORMATION SCIENCE; ENGINEERING, AGRICULTURAL; ARTIFICIAL INTELLIGENCE; COMPUTER SCIENCE </DESCRIPTORS>
<ADVISER>   SUSAN BRIDGES </ADVISER>
<CLASSIFICATIONS>   NIL </CLASSIFICATIONS>
<ABSTRACT>
Generally expert simulation systems contain heuristic
rules in their knowledge base. These rules are just
summaries of experiences and may not provide context
sensitive information to the expert system component.
When these rules are used, the expert system component
may not analyze the results of simulation in a proper
way and it may not provide appropriate input parameters
to the simulation, as a result of which the simulation
may not be used effectively. The hypothesis of this
research is that an expert advisor with the assistance
of an intelligent analysis tool can utilize a simulation
to make decisions in a manner similar to that used by
human experts. To validate this hypothesis, a PIX
Advisor was developed as part of the GOSSYM-COMAX
simulation-based expert system. The analysis tool of the
PIX Advisor utilizes a knowledge base and an analytical
model in making recommendations. With the successful
development of the PIX Advisor, the author demonstrated
the utility of combining heuristic rules and an
analytical tool to direct the use of a complex
simulation system with many interacting factors and
feedback loops.
</ABSTRACT>
</THESIS>
<THESIS>
<NUMBER> 4265 </NUMBER>
<ORDER>   AAG1353823 </ORDER>
<TITLE>   A STUDY OF AUTOMATED ESTIMATING OF SOFTWARE COST </TITLE>
<AUTHOR>   WANG, STEVEN SHOULI </AUTHOR>
<YEAR>   1993 </YEAR>
<INSTITUTION>   WESTERN MICHIGAN UNIVERSITY; 0257 </INSTITUTION>
<DESCRIPTORS>   COMPUTER SCIENCE; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER>   DIONYSIOS KOUNTANIS </ADVISER>
<CLASSIFICATIONS>   NIL </CLASSIFICATIONS>
<ABSTRACT>
The objectives of this thesis are to survey software
cost estimation methods and to discuss how the methods
can be applied as conceptual knowledge in a software
cost estimation expert database system. The various
applications of expert database systems are discussed.
Consequently, a new method to approach the software cost
estimation has been proposed.
This proposed method is based upon a dozen years of
analyzing software cost models which have been done by
some dedicated scientists in universities, research
organizations, and industry. A CASE tool called IASCE
has been designed to assist the project manager to
estimate a proposed project cost. This tool collects
accurate data from current software industry so that
researchers may explore new software models and metrics.
IASCE offers a mechanism for long range improvements of
software cost estimation. The IASCE system is discussed
and explained.
</ABSTRACT>
</THESIS>
<THESIS>
<NUMBER> 4266 </NUMBER>
<ORDER>   AAG1353567 </ORDER>
<TITLE>   MICROCOMPUTER AND EXSYSP BASED EXPERT SYSTEM FOR SELECTION AND DESIGN OF RETAINING STRUCTURES </TITLE>
<AUTHOR>   SINHA, ANURADHA </AUTHOR>
<YEAR>   1993 </YEAR>
<INSTITUTION>   FLORIDA ATLANTIC UNIVERSITY; 0119 </INSTITUTION>
<DESCRIPTORS>   ENGINEERING, CIVIL; GEOTECHNOLOGY </DESCRIPTORS>
<ADVISER>   M. AROCKIASAMY </ADVISER>
<CLASSIFICATIONS>   NIL </CLASSIFICATIONS>
<ABSTRACT>
The automation of retaining structure selection and
design by utilizing artificial intelligence tools is
presented herein. The study involved the development of
a microcomputer based expert system, RESTEX (REtaining
STructure EXpert). The modules of the expert systems
RETAININGEARTH, with M.1 knowledge base, and REFLEXYS
have been updated and the resulting RESTEX modules are
written in C using Exsys Professional for high speed and
efficient utilization of memory. RESTEX is an
interactive menu-driven system consisting of modules for
Structure Selection, Preliminary Design, Soils
Classification, Stability Analysis, and Reinforcement
Design. The system is capable of performing selection,
analysis, and design of gravity walls, cantilever walls,
counterfort walls, reinforced earth, gabion, cantilever
and anchored sheet piles.
</ABSTRACT>
</THESIS>
<THESIS>
<NUMBER> 4267 </NUMBER>
<ORDER>   AAG1353550 </ORDER>
<TITLE>   KNOWLEDGE BASED QUERY GENERATOR FOR RELATIONAL DATABASE SYSTEMS </TITLE>
<AUTHOR>   SESHADRI, MAHESH </AUTHOR>
<YEAR>   1993 </YEAR>
<INSTITUTION>   UNIVERSITY OF LOUISVILLE; 0110 </INSTITUTION>
<DESCRIPTORS>   COMPUTER SCIENCE; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER>   RAMMOHAN RAGADE </ADVISER>
<CLASSIFICATIONS>   NIL </CLASSIFICATIONS>
<ABSTRACT>
Database Management Systems usually provides access to
the data in the database through standard query
languages such as SQL. Query languages hide the physical
operations involved in the retrieval of data from the
users and make the applications portable to different
platforms. The main problem with these standard query
languages is the user has to know the logical structures
in the database in order to access the data in it. The
focus of this thesis is to study methods which hide the
logical structures in the database and provide a user
friendly direct access to the data stored in a
relational database. Various algorithms which are
portable and application independent have been developed
for a query generator. The merits and demerits of
implementations of the query generator are examined in a
standard ORACLE environment; (i) coupled with C
routines; (ii) coupled with an expert system shell such
as CLIPS. Implications for various applications of
expert and decision support systems are also given.
</ABSTRACT>
</THESIS>
<THESIS>
<NUMBER> 4268 </NUMBER>
<ORDER>   AAG1353534 </ORDER>
<TITLE>   SIMULATION OF A DISTRIBUTED EXPERT AND DATABASE SYSTEM </TITLE>
<AUTHOR>   KANCHARLA, VIJAYAKUMAR </AUTHOR>
<YEAR>   1993 </YEAR>
<INSTITUTION>   UNIVERSITY OF LOUISVILLE; 0110 </INSTITUTION>
<DESCRIPTORS>   COMPUTER SCIENCE; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER>   RAMMOHAN RAGADE </ADVISER>
<CLASSIFICATIONS>   NIL </CLASSIFICATIONS>
<ABSTRACT>
Many Distributed database packages are now in the world
which are not based on Intelligent query transactions.
These Distributed database systems are based on the fact
each query on the system goes through all the
nodes/database tables of the system before it is
processed completely. This is due to the lack of
information of the other nodes at the particular node
where the query is placed for processing.
This thesis project involves the design, simulation and
Analysis of an intelligent distributed database system.
The system is based on the fact that each node has a
knowledgebase of its own and each node has the
intelligence to decipher the query before processing. In
the initial stage the system works like any other
distributed database system but with the number of
queries processed on the system, the performance
increases.
The system improves its performance by increasing its
knowledge. The system has been simulated on VAX, and
written in C language. The thesis gives an insight into
the advantages of combining two prominent fields of
computer science, Databases and Artificial Intelligence.
</ABSTRACT>
</THESIS>
<THESIS>
<NUMBER> 4269 </NUMBER>
<ORDER>   AAG1353531 </ORDER>
<TITLE>   PHYSICIAN ATTITUDES TOWARD MEDICAL EXPERT SYSTEMS </TITLE>
<AUTHOR>   HANER, SUZANNE MARIE </AUTHOR>
<YEAR>   1993 </YEAR>
<INSTITUTION>   UNIVERSITY OF LOUISVILLE; 0110 </INSTITUTION>
<DESCRIPTORS>   COMPUTER SCIENCE; HEALTH SCIENCES, MEDICINE AND SURGERY; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER>   ROBERT E. HOYE </ADVISER>
<CLASSIFICATIONS>   NIL </CLASSIFICATIONS>
<ABSTRACT>
This study examines the expectations and demands of the
Department of Family and Community Medicine at the
University of Louisville of medical expert systems.
Computer literacy of each respondent was determined.
Relationships between computer literacy and years since
completion of medical degree, computer literacy and
expectations, and computer literacy and demands were
explored. Physicians with greater than ten years since
completion of their medical degree (n = 7) were the most
literate, while physicians with less than five years
since completion of their medical degree (n = 7) were
the least computer literate. Expectations and demands of
medical expert systems were measured on Likert-type
scales for the two groups. Computer literate physicians
were found to have more realistic expectations than the
non-computer literate group of physicians toward medical
expert systems. Neither group was found to have
realistic expectations of these systems.
</ABSTRACT>
</THESIS>
<THESIS>
<NUMBER> 4270 </NUMBER>
<ORDER>   AAG0665098 </ORDER>
<TITLE>   PIPELINED LOGIC PROGRAMMING FOR REAL-TIME MODEL-BASED IMAGE UNDERSTANDING </TITLE>
<AUTHOR>   POTGIETER, ANNA ELIZABETH GEZINA </AUTHOR>
<YEAR>   1993 </YEAR>
<INSTITUTION>   UNIVERSITY OF PRETORIA (SOUTH AFRICA); 6004 </INSTITUTION>
<DESCRIPTORS>   COMPUTER SCIENCE </DESCRIPTORS>
<ADVISER>   D. G. KOURIE </ADVISER>
<CLASSIFICATIONS>   NIL </CLASSIFICATIONS>
<ABSTRACT>
Recent research in image understanding has been strongly
influenced by the realization that artificial
intelligence techniques combined with parallel
processing may be essential to implement real-time model-
based image understanding systems. A parallel logic
programming language, tailored for image processing,
seems to be an ideal tool to build systems such as
these.
An interpreter for parallel logic programs, based on
pipelined inferencing is described. It is based on a
process model called the PIPELOG Process Model and it
exploits pipelined AND-parallelism and pipelined OR-
parallelism. This study describes a prototype
implementation of such an interpreter, called TIPS, and
its application in a model-based image understanding
domain.
</ABSTRACT>
</THESIS>
<THESIS>
<NUMBER> 4271 </NUMBER>
<ORDER>   AAGMM81239 </ORDER>
<TITLE>   ON THE DEVELOPMENT OF A KINEMATIC AND DYNAMIC EXPERT SYSTEM </TITLE>
<AUTHOR>   LO, LYNETTE </AUTHOR>
<YEAR>   1993 </YEAR>
<INSTITUTION>   UNIVERSITY OF WATERLOO (CANADA); 1141 </INSTITUTION>
<DESCRIPTORS>   ENGINEERING, MECHANICAL; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER>   NIL </ADVISER>
<CLASSIFICATIONS>   NIL </CLASSIFICATIONS>
<ABSTRACT>
In this research project, the solving structure for an
expert system kinematic and dynamic problem solver was
developed, based on a combination of vector-network
theory, the blackboard and hierarchical design expert
system theories, and Maple, a symbolic algebraic
computation system.
Expert system theory is essential in organizing the
variety of equations required such that vector-network
theory can be applied. KINDY, the KINematic and DYnamic
expert system developed in this research project was
written in C-language to solve kinematic and dynamic
particle problems. KINDY produces numerical results for
the desired unknown variables. The blackboard
architecture developed is composed of a blackboard, two
agenda schedulers that regulate the blackboard, and a
group of solving agents that are hierarchically
organized based on vector-network theory. Maple is used
as the blackboard which registers all the equations
generated in the solving process and solves the
resulting set of equations. Communication with Maple is
made possible using a recently developed C-callable
version of Maple in which a C-program is directly linked
to Maple's kernel. This link was adapted for interaction
between KINDY and Maple and is a greater advantage over
comparable expert systems. (Abstract shortened by UMI.)
</ABSTRACT>
</THESIS>
<THESIS>
<NUMBER> 4272 </NUMBER>
<ORDER>   AAGMM81236 </ORDER>
<TITLE>   SIGNAL PROCESSING ALGORITHMS APPLIED TO MYOELECTRIC SIGNAL DECOMPOSITION </TITLE>
<AUTHOR>   ALIREZAIE, S. M. JAVAD </AUTHOR>
<YEAR>   1993 </YEAR>
<INSTITUTION>   UNIVERSITY OF WATERLOO (CANADA); 1141 </INSTITUTION>
<DESCRIPTORS>   ENGINEERING, BIOMEDICAL; COMPUTER SCIENCE; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER>   NIL </ADVISER>
<CLASSIFICATIONS>   NIL </CLASSIFICATIONS>
<ABSTRACT>
Myoelectric (ME) signal decomposition is the procedure
by which the ME signal is resolved into its constituent
motor unit action potential trains (MUAPTs). This thesis
presents a hybrid technique, incorporating Neural
Networks and functional knowledge of motor units for ME
signal decomposition. A variant of the supervised
Learning Vector Quantization (LVQ1), was applied to the
classification of motor unit action potentials (MUAPs)
and its performance was evaluated and compared with a
supervised classification technique. A new algorithm was
developed for estimating the motor unit (MU) firing time
parameters, $mu,$ the MU's mean interpulse interval
(IPI) and $sigma,$ the standard deviation of the MU's
inter-pulse interval. A novel algorithm for resolving
superpositions of MUAPs was developed based on knowledge
of firing behavior of MUAPs. The firing behavior was
used to perform a heuristic search to find motor units
possibly contributing to the superposition.
The performance of the LVQ algorithm, mean IPI and IPI
standard deviation and the superposition algorithm were
evaluated using simulated concentric needle ME signals
corresponding to different muscle contractions. For
stationary data, the LVQ algorithm achieved accuracies
of up to 99%, 98% and 94% corresponding to muscle
contraction levels of 10%, 20% and 30% maximum voluntary
contraction (MVC). The superposition algorithm obtained
accuracies of up to 93% with a contraction level of 30%
MVC. The decomposition systems achieved a combined
accuracy of up to 99.6% with 99.4% MUAPs assigned.
</ABSTRACT>
</THESIS>
<THESIS>
<NUMBER> 4273 </NUMBER>
<ORDER>   AAINN95327 </ORDER>
<TITLE>   MAKING PREDICTIONS DIRECTLY FROM PAST EXPERIENCES </TITLE>
<AUTHOR>   CRADDOCK, ARTHUR JULIAN PATTERSON </AUTHOR>
<YEAR>   1993 </YEAR>
<INSTITUTION>   THE UNIVERSITY OF BRITISH COLUMBIA (CANADA); 2500 </INSTITUTION>
<DESCRIPTORS>   COMPUTER SCIENCE; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER>   DAVID POOLE </ADVISER>
<CLASSIFICATIONS>   DOMAIN KNOWLEDGE, KNOWLEDGE BASE </CLASSIFICATIONS>
<ABSTRACT>
This thesis considers the problem of making predictions
about new experiences based upon past experiences. The
problem is of interest to artificial intelligence
because past experiences are a kind of domain knowledge
that is readily available to computational agents, and
are at least one form of knowledge that humans use to
make predictions.
Instead of considering the problem in terms of first
inducting a domain model from a set of past experiences,
and then using some form of deduction to make
predictions, this thesis develops a new technique called
the reference class approach (RCA) that directly infers
estimates of conditional probabilities from a knowledge
base of past experiences. The resulting estimates can be
readily used in a number of contexts such as non-
monotonic reasoning, the characterisation of probability
distribution functions, prediction and classification.
Given a knowledge base (KB) of descriptions of past
experiences, a description of a new experience, and a
proposition representing a query about the new
experience, the RCA estimates the conditional
probability of the proposition being true of the new
experience. The RCA starts by identifying a subset of
the KB called the reference class that contains all
those past experiences in the KB whose descriptions
cover everything that is known about the new experience
in addition to providing a truth value for the
proposition.
If there are no directly applicable past experiences,
i.e., the reference class is empty, then the description
of the new experience is modified until a non-empty
reference class can be found. This thesis investigates
two new approaches to modifying the description, namely
syntactic generalisation and chaining. Previous research
has proposed that logical implication can be used to
semantically generalise an empty reference class to any
non-empty reference class. This thesis shows that
semantic generalisation does not work in the context of
making predictions from a KB of past experiences. This
thesis argues that we should syntactically generalise
the description of the new experience. Chaining is a
novel extension of syntactic generalisation that allows
us to systematically increase what we know about a new
experience by elaborating its description while
generalising. Once a non-empty reference class has been
identified the RCA estimates the conditional probability
of the proposition being true by measuring the frequency
with which the proposition is true in the reference
class.
The RCA is an inductive technique in that it estimates
probabilities directly from past experiences. One useful
test of an inductive technique is to test whether or not
it can be used to make accurate predictions from past
experiences. This thesis argues that in order to
implement the RCA we need a notion of irrelevance to
pick the most appropriate generalised or chained
reference class. This thesis shows that even with very
simple notions of irrelevance, the RCA's estimates can
be used to make predictions whose accuracy compares
favourably with state of the art machine learning
techniques on standard test data from the machine
learning community.
</ABSTRACT>
</THESIS>
<THESIS>
<NUMBER> 4274 </NUMBER>
<ORDER>   AAIMM93307 </ORDER>
<TITLE>   DEVELOPING PROBLEM SOLVING ABILITIES WITH ARTIFICIAL INTELLIGENCE </TITLE>
<AUTHOR>   RIVIERE, FREDERIC </AUTHOR>
<YEAR>   1993 </YEAR>
<INSTITUTION>   UNIVERSITY OF WINDSOR (CANADA); 0115 </INSTITUTION>
<DESCRIPTORS>   EDUCATION, SECONDARY; EDUCATION, TECHNOLOGY; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER>   L. HORTON </ADVISER>
<CLASSIFICATIONS>   NIL </CLASSIFICATIONS>
<ABSTRACT>
New programming languages are available in the market
place that ease the design of intelligent tasks executed
by the computer. PROLOG is one of the leading
programming languages of this kind that allows programs
which result from precise observation of experts and
that learn from experience. In order to test the impact
of Artificial Intelligence and the use of PROLOG, twenty
students were trained to use this language, and were
compared with twenty other students in a high school.
The students learned how to build an expert system using
PROLOG. The hypothesis was that these students would
develop abilities to find relationships between concepts
and therefore develop some problem solving abilities.
Two tests each divided into three subtests were used to
measure the ability to find analogies between ideas, to
find relationships between visual concepts and to use
logical thinking. The results showed that there was no
significant relationship between designing an expert
system using PROLOG and finding relationships between
concepts despite the fact that PROLOG is based on the
logic of predicates and that predicates are the
relations which link the different characteristics of an
object.
</ABSTRACT>
</THESIS>
<THESIS>
<NUMBER> 4275 </NUMBER>
<ORDER>   AAI9517878 </ORDER>
<TITLE>   DETECTION OF MOVING OBJECTS IN THE PRESENCE OF NOISE </TITLE>
<AUTHOR>   REHMAN, ASIM UR </AUTHOR>
<YEAR>   1993 </YEAR>
<INSTITUTION>   POLYTECHNIC UNIVERSITY; 0179 </INSTITUTION>
<DESCRIPTORS>   ENGINEERING, ELECTRONICS AND ELECTRICAL </DESCRIPTORS>
<ADVISER>   LUDWIK KURZ </ADVISER>
<CLASSIFICATIONS>   NIL </CLASSIFICATIONS>
<ABSTRACT>
The tracking of moving objects is an interesting problem
of significant practical importance. Some of the related
areas are robotics, computer vision, artificial
intelligence, and medical applications. In this
dissertation, statistical techniques are developed for
the detection of moving objects, specifically stressing
methodologies based on the analysis of variance (ANOVA).
The algorithms are used for detecting moving objects by
locating the important features followed by the matching
process between two consecutive frames.
The Graeco-Latin square design is used to locate
important features: edges and corners, then the concept
of contrast function is used to locate the exact
position of pertinent features. The decision mechanism
based on testing various hypotheses on moving objects
yields the detected motion by matching similar features
in two consecutive frames.
Another technique used here is based on nested designs
in conjunction with the partition of a window mask into
equal parts and the analysis of the various effects. A
three-way, complete nested designs are applied, based on
the fixed-effect and random-effect models, which are
based on the assumption of effects being unknown
deterministic or random, respectively. Three
experimental models are introduced. In these models, the
temporal segmentations are performed by inter-frame
segmentation, while feature segmentation involves intra-
frame picture content, using tests based on various mask
sizes. It is learned that the best results are achieved
when the mask size is comparable to the feature under
consideration.
Next, the least square estimates of effects in four-
directions are approximated by a time series, and the
features of moving objects are predicted using
autoregressive models. The comparisons of the proposed
methods include the Yule-Walker (Y-W), the Burg, and the
robustized Burg methods. The Y-W and the Burg methods
are based on the Levinson algorithm, while the
robustized Burg method is found to be computationally
efficient. These methods are capable of analyzing a
large number of frames.
In support of procedures introduced in the dissertation,
simulations were performed using actual image scenes. A
significant improvement was observed by new procedures,
which include the effect of independent and correlated
noise of varying levels.
</ABSTRACT>
</THESIS>
<THESIS>
<NUMBER> 4276 </NUMBER>
<ORDER>   AAI1359213 </ORDER>
<TITLE>   IDENTIFICATION OF POTENTIAL SYSTEMS BY THE CONSTRUCTION OF SYSTEM BEHAVIOR </TITLE>
<AUTHOR>   ACHARYA, NABIN </AUTHOR>
<YEAR>   1993 </YEAR>
<INSTITUTION>   THE AMERICAN UNIVERSITY; 0008 </INSTITUTION>
<DESCRIPTORS>   COMPUTER SCIENCE; ARTIFICIAL INTELLIGENCE; ENGINEERING, SYSTEM SCIENCE </DESCRIPTORS>
<ADVISER>   NIL </ADVISER>
<CLASSIFICATIONS>   NIL </CLASSIFICATIONS>
<ABSTRACT>
Problem solving in Distributed Artificial Intelligence
involves the decomposition of tasks into subtasks that
are then distributed to single autonomous agents. If the
collection of these agents is viewed as a system, then
several important problems exist involving the
relationships between the individual agents and the
system. Some of these problems are, deriving system
behavior and understanding what the system is achieving
as the individual agents achieve their goals. This
thesis discusses how the concept of system behavior can
be defined by considering the formation of system
behaviors from the unification of rules, how a goal tree
structure could be used to prune unnecessary behaviors,
and how the derived system behavior can be used to
identify potential systems.
</ABSTRACT>
</THESIS>
<THESIS>
<NUMBER> 4277 </NUMBER>
<ORDER>   AAIMM92127 </ORDER>
<TITLE>   ETUDE ET DEVELOPPEMENT DE TECHNIQUES D'APPRENTISSAGE DES RESEAUX NEURONIQUES APPLICABLES A LA MODELISATION ET A LA COMMANDE INTELLIGENTE DE PROCEDES </TITLE>
<AUTHOR>   SLIMANI, KARIM </AUTHOR>
<YEAR>   1993 </YEAR>
<INSTITUTION>   UNIVERSITE LAVAL (CANADA); 0726 </INSTITUTION>
<DESCRIPTORS>   ENGINEERING, MECHANICAL; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER>   MICHEL GUILLOT </ADVISER>
<CLASSIFICATIONS>   FRENCH TEXT </CLASSIFICATIONS>
<ABSTRACT>
Recent advances in the field of artificial neural
networks have unveiled their potential for process
modelling and control. They have proven to be very
effective in modelling any process response, but they
need to be trained prior to their utilization which
increases the cost for industrial implementation.
This research reviews the basics of Back Propagation
neural networks based on Generalized Delta rule. It
introduces also, a new approach for process modelling
using neural networks based on Broyden-Fletcher-Goldfarb-
Shanno rule.
This research demonstrates the model learning
capabilities based on experimental results of turning
operations and a special attention is given to training
and testing both methods: Back Propagation and BFGS. The
aspect of learning speed and memorization have been
studied and their results exposed.
</ABSTRACT>
</THESIS>
<THESIS>
<NUMBER> 4278 </NUMBER>
<ORDER>   AAIMM91801 </ORDER>
<TITLE>   DIAGNOSING FAULTS ON TELEPHONE SUBSCRIBER LOOPS USING NEURAL NETWORKS </TITLE>
<AUTHOR>   GROLEAU, FRANCOIS </AUTHOR>
<YEAR>   1993 </YEAR>
<INSTITUTION>   MCGILL UNIVERSITY (CANADA); 0781 </INSTITUTION>
<DESCRIPTORS>   ENGINEERING, ELECTRONICS AND ELECTRICAL; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER>   ALFRED S. MALOWANY </ADVISER>
<CLASSIFICATIONS>   NIL </CLASSIFICATIONS>
<ABSTRACT>
Neural networks have recently regained significant
interest in the scientific community for their ability
to generalize about large samples of data. In this
thesis, the feasibility of applying neural networks in
the domain of telephone access network fault
identification and localization is explored. Firstly,
the access network and the computerized work environment
of today's Repair Service Bureaus are described. A
survey of past and present automated diagnosis systems
used in communications follows. Neural networks are then
presented and the back-propagation learning algorithm is
given particular attention. Another literature review
ensues where neural network based diagnosis systems from
a number of domains are presented. Finally, the first
components for an improved access network maintenance
system are laid. Experimental results show that the
opportunity exists to benefit from neural networks
pattern classification ability in access network
maintenance. A discussion of results and suggestions for
future research work ends this thesis.
</ABSTRACT>
</THESIS>
<THESIS>
<NUMBER> 4279 </NUMBER>
<ORDER>   AAIMM91588 </ORDER>
<TITLE>   TEXTURE IDENTIFICATION USING ARTIFICIAL NEURAL NETWORKS AND 2D-AUTOREGRESSIVE MODEL </TITLE>
<AUTHOR>   XU, HE </AUTHOR>
<YEAR>   1993 </YEAR>
<INSTITUTION>   MEMORIAL UNIVERSITY OF NEWFOUNDLAND (CANADA); 0306 </INSTITUTION>
<DESCRIPTORS>   COMPUTER SCIENCE; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER>   SIWEI LU </ADVISER>
<CLASSIFICATIONS>   NIL </CLASSIFICATIONS>
<ABSTRACT>
As an important aspect of image analysis, texture
identification has been pursued by many researchers.
Among techniques developed, the approach of modeling
texture images through a 2-D Autoregressive (AR) Model
is of special interest. The major problem with the
modeling methods is the estimation of parameters due to
the intensive amount of computation involved. From a
parallel computing perspective, parameter estimation can
be implemented by learning procedure of a neural
network, and texture classification can be mapped into a
neural computation. A multilayer network is proposed
which consists of three subnets, namely the input subnet
(ISN), the analysis subnet (ASN) and the classification
subnet (CSN). The network obtains the classification
capability through an adaptive learning procedure. In
the processing phase, images proceed through the network
without the preprocessing and feature extraction
required by many other techniques.
An integrated texture segmentation technique is proposed
to segment textured images. The technique is implemented
by comparing local region properties, which are
represented by a 2-D AR model, in a hierarchical manner.
It is able to grow all regions in a textured image
simultaneously starting from initially decided internal
regions until smooth boundaries are formed between all
adjacent regions. The performances of the classification
and segmentation techniques are shown by experiments on
natural textured images.
</ABSTRACT>
</THESIS>
<THESIS>
<NUMBER> 4280 </NUMBER>
<ORDER>   AAI9509189 </ORDER>
<TITLE>   NON-FULLY CONFIGURED SECOND-ORDER NEURAL NETWORKS USING MULTI-DIMENSIONAL WEIGHTS </TITLE>
<AUTHOR>   SHIN, YONG-CHUL </AUTHOR>
<YEAR>   1993 </YEAR>
<INSTITUTION>   STATE UNIVERSITY OF NEW YORK AT BUFFALO; 0656 </INSTITUTION>
<DESCRIPTORS>   ENGINEERING, ELECTRONICS AND ELECTRICAL; ENGINEERING, SYSTEM SCIENCE; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER>   RAMALINGAM SRIDHAR </ADVISER>
<CLASSIFICATIONS>   NEURAL NETWORKS </CLASSIFICATIONS>
<ABSTRACT>
A neural network architecture that can provide quadratic
discrimination per layer using complex valued (or two-
dimensional) weights and a modified activation function
is presented. This method can realize second-order
network without using the $Pi$-elements that are
typically required to build the higher-order networks.
For each layer, the input and output domains of the
proposed network are defined in Real $({cal R}),$ while
the weights are in Complex $({cal C})$ domain. The model
of the activation function can be divided into two
parts: (1) the magnitude of the sum of the complex-
valued weighted inputs and (2) the sigmoid function.
With the use of back-propagation method, training is
accomplished and results of tests on simple non-linearly
separable functions demonstrate faster training with
less number of epochs as compared to conventional
networks. The complex weights are generalized to multi-
dimensional vectors. It is observed that the full
configuration of the N-input second order neural network
can be obtained using N-dimensional vectors as weights.
However, many non-fully configured networks can be
achieved using R-dimensional vectors $(R < N).$ It is
established that the non-fully configured second-order
neural networks can classify many problems in N-input
domain. This is accomplished with an analysis of these
networks based on topological equivalence as well as
exhaustive tests. This provides a method in determining
the minimum network configuration for a given problem.
Also, it has been observed that the new configuration
method not only simplifies the architecture for
implementation of the second-order networks, but also
speeds up training. Several networks configured with
this method have been applied to handwritten digit
recognition problem and the results show significant
improvements on learning speed and recognition
performance over conventional linear networks. The
feasibility of implementation of the non-fully
configured second-order neural networks in VLSI is also
demonstrated using the systolic array architecture with
prototype processing elements designed using $2murm m$
CMOS technology.
</ABSTRACT>
</THESIS>
<THESIS>
<NUMBER> 4281 </NUMBER>
<ORDER>   AAG9505580 </ORDER>
<TITLE>   TEMPORAL KNOWLEDGE BASE MANAGEMENT: MODEL, QUERY LANGUAGE, ALGEBRA AND IMPLEMENTATION TECHNIQUES </TITLE>
<AUTHOR>   CHEN, HSIN-HSING MORE </AUTHOR>
<YEAR>   1993 </YEAR>
<INSTITUTION>   UNIVERSITY OF FLORIDA; 0070 </INSTITUTION>
<DESCRIPTORS>   ENGINEERING, ELECTRONICS AND ELECTRICAL; COMPUTER SCIENCE; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER>   STANLEY Y. W. SU </ADVISER>
<CLASSIFICATIONS>   KNOWLEDGE BASE </CLASSIFICATIONS>
<ABSTRACT>
There has been a considerable amount of work on object-
oriented databases, active databases, and deductive
databases. The common objective of these efforts is to
produce highly intelligent and active systems for
supporting the next generation of database applications.
These future systems must be capable of capturing the
concepts of time and managing not just temporal data but
temporal knowledge expressed by knowledge rules. In this
dissertation, we describe our efforts on a temporal
object-oriented knowledge model, OSAM*/T, its associated
temporal query language, OQL/T, an underlying temporal
algebra, TA-algebra, and some implementation techniques.
In addition to the features of the traditional object-
oriented paradigm, the model is characterized by its
strong support of association types and its
incorporation of temporal knowledge rules for specifying
temporal and other types of semantic constraints
associated with object classes and their temporal object
instances. The query language is distinguished by its
pattern-based specification of temporal object
associations, which allows complex queries with various
time constraints to be formulated in a relatively simple
way. The temporal algebra provides a set of primitive
operators for manipulating homogeneous and/or
heterogeneous patterns of temporal object associations,
thus providing the needed mathematical foundation for
processing and optimizing temporal queries. The
implementation techniques include a Delta-Instance and
Multi-Snapshot Storage Model, as well as data
partitioning and clustering schemes for storage
management of temporal knowledge bases. Also, in order
to understand the relative merits of the techniques
proposed in our approach and those of the existing
proposals, we evaluate and compare their performances in
terms of storage consumption, time for materializing
temporal data and times for processing temporal queries.
</ABSTRACT>
</THESIS>
<THESIS>
<NUMBER> 4282 </NUMBER>
<ORDER>   AAGMM91302 </ORDER>
<TITLE>   FUZZY LOGIC IN COMPUTER-BASED ENGINEERING </TITLE>
<AUTHOR>   TAO, HUA </AUTHOR>
<YEAR>   1993 </YEAR>
<INSTITUTION>   SIMON FRASER UNIVERSITY (CANADA); 0791 </INSTITUTION>
<DESCRIPTORS>   COMPUTER SCIENCE; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER>   JOHN D. JONES </ADVISER>
<CLASSIFICATIONS>   NIL </CLASSIFICATIONS>
<ABSTRACT>
Since it was first conceived in 1965, fuzzy logic has
been an important way of simulating human reasoning.
Fuzzy logic provides an effective conceptual framework
for dealing with uncertainty and imprecision, which are
inherent in preliminary engineering design.
In this thesis, we present an approach based on fuzzy
logic and mathematical modelling of potential design
components. We develop an algorithm for fuzzy
calculation of functions, and compare it with previously
published methods. We review some of the literature on
fuzzy logic in design, in particular the work of
Antonsson and his students. Then we develop a novel
approach, which introduces a vocabulary of linguistic
variables to describe potential design components. This
vocabulary is stored in a knowledge base. Linguistic
variables are also used to describe design requirements,
and a metric is suggested to allow trade-off between
multiple performance parameters and design requirements.
A detailed example is given for the design of Stirling
engine heat exchangers.
</ABSTRACT>
</THESIS>
<THESIS>
<NUMBER> 4283 </NUMBER>
<ORDER>   AAGMM91188 </ORDER>
<TITLE>   A CONNECTIONIST APPROACH TO ACQUIRING SEMANTIC KNOWLEDGE USING COMPETITIVE LEARNING </TITLE>
<AUTHOR>   CHIN, KENWARD </AUTHOR>
<YEAR>   1993 </YEAR>
<INSTITUTION>   SIMON FRASER UNIVERSITY (CANADA); 0791 </INSTITUTION>
<DESCRIPTORS>   COMPUTER SCIENCE; ARTIFICIAL INTELLIGENCE; LANGUAGE, LINGUISTICS </DESCRIPTORS>
<ADVISER>   ROBERT F. HADLEY </ADVISER>
<CLASSIFICATIONS>   NIL </CLASSIFICATIONS>
<ABSTRACT>
Recent work in the field of cognitive science has
involved the use of connectionist networks for learning
semantics from simple English utterances. While
significant results have been obtained, many such
networks embody architectures which have obvious
deficiencies. One deficiency is the use of the back
propagation learning algorithm. This algorithm requires
that continual feedback be provided during training.
Though back propagation is an effective technique, it
has the drawback of not being a plausible explanation of
human language acquisition, since humans do not
typically receive continual corrective feedback while
learning language. Another deficiency is the failure of
some systems to provide a link between the semantics
discovered from input sentences and the real-world
objects referred to in the input sentences. Also, many
systems require that the knowledge acquired be
represented according to a pre-determined
representational scheme.
The work presented here is an attempt to provide a
connectionist basis for correcting these deficiencies.
Firstly, the use of the competitive learning strategy
frees the system from requiring continual feedback and
from requiring a pre-determined representational scheme.
Secondly, the system's task is specifically to learn the
associations between the words in input sentences and
the real-world concepts to which they refer.
</ABSTRACT>
</THESIS>
<THESIS>
<NUMBER> 4284 </NUMBER>
<ORDER>   AAGMM91161 </ORDER>
<TITLE>   REPRESENTING ENGINEERING DESIGN KNOWLEDGE IN AN OBJECT- ORIENTED CONSTRAINT LOGIC PROGRAMMING LANGUAGE </TITLE>
<AUTHOR>   LI, DONG </AUTHOR>
<YEAR>   1993 </YEAR>
<INSTITUTION>   SIMON FRASER UNIVERSITY (CANADA); 0791 </INSTITUTION>
<DESCRIPTORS>   ENGINEERING, GENERAL; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER>   JOHN D. JONES </ADVISER>
<CLASSIFICATIONS>   NIL </CLASSIFICATIONS>
<ABSTRACT>
We intend to develop a two-part knowledge base to
support the design of a range of artifacts. A prototype
knowledge base has been built which can support the
design of Stirling engine heat exchangers. The knowledge
base is implemented with the Echidna constraint
reasoning system, which incorporates constraint logic
programming, truth maintenance and dependency-directed
intelligent backtracking, all in an object-oriented
framework. In developing this knowledge base, we face a
trade-off between generality and efficiency. To solve
this problem, we introduced a new form of knowledge
representation which incorporates scaling information, a
form not generally available in other knowledge-based
systems.
In this thesis, we show how the knowledge base is
created and how some of the knowledge underlying the
designer's sense of scale can be formally represented in
a knowledge base. A design example is also included.
</ABSTRACT>
</THESIS>
<THESIS>
<NUMBER> 4285 </NUMBER>
<ORDER>   AAGMM91129 </ORDER>
<TITLE>   FAULT DETECTION AND DIAGNOSIS OF A NUCLEAR POWER PLANT USING ARTIFICIAL NEURAL NETWORKS </TITLE>
<AUTHOR>   HWANG, BOON CHONG </AUTHOR>
<YEAR>   1993 </YEAR>
<INSTITUTION>   SIMON FRASER UNIVERSITY (CANADA); 0791 </INSTITUTION>
<DESCRIPTORS>   ENGINEERING, NUCLEAR; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER>   MEHRDAD SAIF </ADVISER>
<CLASSIFICATIONS>   NIL </CLASSIFICATIONS>
<ABSTRACT>
Fault detection, isolation and accommodation (FDIA) have
always been an important aspect of control system
design. Various design techniques such as hardware
redundancy, analytical redundancy and expert systems
have been used to enhance system performance. Recently,
artificial neural networks (ANN) have been highlighted
for their potential ability in feature (fault)
recognition. Due to their learning capabilities and
their inherent parallel structures, ANN are a promising
method for fault-tolerant control system design. In this
thesis, an approach based on neural networks and
mathematical models for detecting and diagnosing
instrument failures in nuclear reactors is presented.
The reactor's mathematical model is that of H. B.
Robinson's nuclear plant located in North Carolina,
which produces 2200mw(th) at full power. Multi-layer
neural networks are used at the first level for
identification of plant parameters and at the second
level for distinguishing parameter variations from
possible faults, and as a pattern recognizer in the
third level for the detection of faulty instruments. The
design approach was able to simultaneously classify
single and multiple anomalies such as sensors and
actuators under plant parameter uncertainties.
Simulation results presented reveal the promise of
artificial neural networks for improving the operating
characteristics of nuclear power plants.
</ABSTRACT>
</THESIS>
<THESIS>
<NUMBER> 4286 </NUMBER>
<ORDER>   AAGMM91071 </ORDER>
<TITLE>   A LOGICAL FRAMEWORK FOR MODEL BASED DIAGNOSIS WITH PROBABILISTIC SEARCH </TITLE>
<AUTHOR>   MACDONALD, PETER </AUTHOR>
<YEAR>   1993 </YEAR>
<INSTITUTION>   SIMON FRASER UNIVERSITY (CANADA); 0791 </INSTITUTION>
<DESCRIPTORS>   COMPUTER SCIENCE; ENGINEERING, BIOMEDICAL; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER>   WILLIAM S. HAVENS </ADVISER>
<CLASSIFICATIONS>   NIL </CLASSIFICATIONS>
<ABSTRACT>
Diagnosis involves finding explanations for the observed
behavior of an often complex physical system.
Historically, approaches to diagnosis have differed,
depending upon the existence, or not, of a theoretical
model of system behavior. Problems in medical diagnosis
are characterized by a highly incomplete knowledge of
how the human body operates. In contrast, the behavior
of engineered systems is typically described by a
sophisticated theory based on established scientific
principles.
Early expert systems developed for medical diagnosis
model the reasoning strategies of human experts, rather
than human physiology. These systems feature ad-hoc
uncertainty calculi, and shallow, heuristic domain
knowledge. Alternatively, recent medical diagnosis
systems utilize Bayesian Belief Networks to represent
statistical, causal models of the human body and
disease.
Model-based diagnosis systems address engineering
domains and incorporate engineering models of system
behavior. The lack of a generalized uncertainty calculus
results in difficulties in ranking diagnoses, and in
diagnosing faults which are not covered by the
theoretical model.
We propose a generalized model-based approach to
diagnosis which reconciles statistical and deterministic
modeling. We argue that even with an engineered system,
particularly one which is faulty, there are aspects of
system behavior which are incompletely understood. We
require a representation which is equally good at
representing both well-understood and partially-
understood aspects of system behavior.
We present a way of representing Bayesian Belief
networks as logic programs with extra-logic probability
annotations. In doing so we extend the dual procedural
and declarative semantics of the annotated logic
programs. We also present an architecture for diagnostic
inferencing. The proposed architecture features a
combination of best-first search and intelligent
backtracking and generates diagnoses in order of
decreasing likelihood. The architecture explicitly
supports the comparison of multiple diagnoses with
incremental observations, a process typical of
diagnostic problem solving.
</ABSTRACT>
</THESIS>
<THESIS>
<NUMBER> 4287 </NUMBER>
<ORDER>   AAGMM90972 </ORDER>
<TITLE>   ARTIFICIAL INTELLIGENCE: AN ESSAY ON COMPUTERS AS LANGUAGE USERS </TITLE>
<AUTHOR>   WOODBURN, ERIC R. </AUTHOR>
<YEAR>   1993 </YEAR>
<INSTITUTION>   SAINT MARY'S UNIVERSITY (CANADA); 1104 </INSTITUTION>
<DESCRIPTORS>   PHILOSOPHY; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER>   WAYNE GRENNAN </ADVISER>
<CLASSIFICATIONS>   NIL </CLASSIFICATIONS>
<ABSTRACT>
The author has embarked on an investigation of
Artificial Intelligence and Cognitivism. The focus is
directed at AI's attempt to implement a program to endow
a computer with intelligence. However, this endeavor may
have been undermined by John Searle's Chinese room
experiment. Searle, in Minds, Brains, and Science,
rejects AI's fundamental claim that a properly
programmed computer could ever be intelligent. His
thesis relies on two main assumptions: (1) The formal
structure of a computer is insufficient to produce
understanding, and (2) the "hard wiring" of a
computer, as opposed to the brain's "wet
wiring," is insufficient to cause mind. These
assumptions will be put to the test in rebuttals
presented by several philosophers and AI researchers.
However, each of these criticisms will be laid to rest,
or at least questioned, by the author. The point of
inquiry is now directed at the type of program needed to
endow a computer with linguistic understanding. The
quest begins with human language acquisition within a
community of languages users and ends with a thought
experiment. The experiment illuminates the nature of the
program needed to produce linguistic understanding in a
computer.
</ABSTRACT>
</THESIS>
<THESIS>
<NUMBER> 4288 </NUMBER>
<ORDER>   AAGMM90860 </ORDER>
<TITLE>   GROUP TECHNOLOGY DECISION AIDS FOR THE DESIGN OF CELLULAR MANUFACTURING SYSTEMS: AN EXPERT SYSTEMS APPROACH </TITLE>
<AUTHOR>   GOVINDARAJAN, VENKATESH </AUTHOR>
<YEAR>   1993 </YEAR>
<INSTITUTION>   CONCORDIA UNIVERSITY (CANADA); 0228 </INSTITUTION>
<DESCRIPTORS>   ENGINEERING, INDUSTRIAL; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER>   NIL </ADVISER>
<CLASSIFICATIONS>   NIL </CLASSIFICATIONS>
<ABSTRACT>
The study develops a methodology for the design of a
cellular manufacturing system (CMS) utilizing the group
technology output. The design process is built into an
expert system (ES) and a framework of the ES has been
developed in this research. A new algorithm for forming
a groupable matrix using alternate process plans is also
developed. This algorithm increases the chances of
obtaining a well defined grouping of machines and parts.
The application of group technology to the binary
incidence matrix generates machine-part groupings and by
considering a different set of process plans alternate
groupings are obtained. An advantage of the new approach
is it gives alternatives at various stages which can be
evaluated and a solution can be selected by the user.
The ES consists of a knowledge base i.e. production and
expert rules, database, algorithms and an inference
engine. It aids the user in choosing a feasible set of
layouts and material handling systems (MHSs) for each
cell and the overall manufacturing system. A new method
for the joint selection of layout and MHS is also
proposed. Knowledge base rules evaluate the feasibility
of these layout and MHS combinations. The alternative
cell and cellular manufacturing system designs generated
are evaluated by simulation to select the best design.
The complete design procedure is built into a heuristic
which forms the inference engine of the ES. Unlike other
researches in this area, which deal only with the
grouping of machines and parts, a practical methodology
for the design of a CMS is proposed in this thesis.
</ABSTRACT>
</THESIS>
<THESIS>
<NUMBER> 4289 </NUMBER>
<ORDER>   AAGMM90189 </ORDER>
<TITLE>   THE DAME EDITOR: A USER INTERFACE FOR DATA ACQUISITION IN AN EXPERT MICROPROCESSOR-BASED-SYSTEMS DESIGNER </TITLE>
<AUTHOR>   LI, DONGNI </AUTHOR>
<YEAR>   1993 </YEAR>
<INSTITUTION>   UNIVERSITY OF VICTORIA (CANADA); 0244 </INSTITUTION>
<DESCRIPTORS>   COMPUTER SCIENCE; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER>   NIKITAS J. DIMOPOULOS </ADVISER>
<CLASSIFICATIONS>   NIL </CLASSIFICATIONS>
<ABSTRACT>
The automation of computer hardware design has received
considerable attention in recent years. Expert systems,
that incorporate explicit domain knowledge into problem-
solving programs, have been successfully applied in
design problems. DAME (Design Automation of
Microprocessor-based systems using an Expert system
approach) is a system capable of designing
microprocessor-based systems from original
specifications. In this thesis, the DAME Editor, a user
interface for data acquisition for DAME's component
database, is presented.
DAME's knowledge domain is represented by a component
model which structures the component information into
several abstraction levels to facilitate the design
process by breaking down the design task into several
phases. Based on the component model, each component in
DAME is associated to a template which specifies its
structure. The DAME editor assists the user in creating
and maintaining the component database, through a user
graphical interface.
</ABSTRACT>
</THESIS>
<THESIS>
<NUMBER> 4290 </NUMBER>
<ORDER>   AAGMM89973 </ORDER>
<TITLE>   SYSTEME EXPERT EN CONCEPTION DE TRANSFORMATEURS </TITLE>
<AUTHOR>   LAVOIE, JEAN </AUTHOR>
<YEAR>   1993 </YEAR>
<INSTITUTION>   UNIVERSITE DE SHERBROOKE (CANADA); 0512 </INSTITUTION>
<DESCRIPTORS>   ENGINEERING, ELECTRONICS AND ELECTRICAL; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER>   JEAN-MARIE DIRAND </ADVISER>
<CLASSIFICATIONS>   FRENCH TEXT </CLASSIFICATIONS>
<ABSTRACT>
Un systeme expert a ete realise pour permettre la
conception automatique de transformateurs electrique de
puissance. Le systeme permet a partir de specifications
fonctionnelles fournies par son utilisateur, de deriver
un ensemble de descriptions de transformateurs
lesquelles sont conformes et directement exploitables
pour l'etape de fabrication.
Le systeme implante une base de connaissances et un plan
de raisonnement. Grace a un moteur d'inference d'une
"coquille" de systeme expert, le plan de
raisonnement est execute en chai nage avant. Il permet
l'exploitation de differentes sources de connaissances,
afin de produire pour une specification initiale, une
ensemble de descriptions de transformateurs.
Le systeme a permis de produire des descriptions
conformes de transformateurs qui sont compatibles a des
produits existants chez un manufacturier ou qui
correspondent a des nouveaux produits fabricables.
</ABSTRACT>
</THESIS>
<THESIS>
<NUMBER> 4291 </NUMBER>
<ORDER>   AAGMM89945 </ORDER>
<TITLE>   CONTRIBUTION POUR LA MISE EN OEUVRE D'UN SYSTEME DE GESTION D'OBJETS </TITLE>
<AUTHOR>   KHOURY, SAMIR </AUTHOR>
<YEAR>   1993 </YEAR>
<INSTITUTION>   UNIVERSITE DE SHERBROOKE (CANADA); 0512 </INSTITUTION>
<DESCRIPTORS>   COMPUTER SCIENCE; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER>   RUBEN GONZALEZ-RUBIO </ADVISER>
<CLASSIFICATIONS>   FRENCH TEXT </CLASSIFICATIONS>
<ABSTRACT>
Les systemes de gestion de bases de donnees relationnels
sont incapables de repondre aux besoins des applications
dans le domaine de l'intelligence artificielle, de la
conception assistee par ordinateur CAO, du traitement
d'image et de la parole qui exigent le support des
objets ayant une semantique riche et une structure
complexe. Pour cela, la recherche dans les bases de
donnees se dirige vers la conception des systemes de
gestion de bases de donnees qui sont en train d'evoluer
vers des bases d'objets.
Dans ce memoire, nous allons presenter notre approche
pour la conception et la mise en oeuvre d'un prototype
simplifie d'un Systeme de Base d'Objets (SBOS).
L'emphase est sur la mise en oeuvre d'un module de
stockage oriente-objets persistant qui peut etre vu
comme une librairie orientee-objets independante. Cette
librairie peut servir comme un module de stockage a
d'autres applications. Le module va gerer un espace
secondaire pour stocker les objets. Cette gestion
comprend la partition de l'espace secondaire disponible
en pages, la decomposition interne des pages en des
champs pour gerer les pages et leur contenu,
l'allocation des pages, l'organisation d'un repertoire
des pages, la recuperation des espaces libres qui se
fait a deux niveaux: le premier est a l'interieur de la
page, tandis que le deuxieme est la recuperation des
pages libres au niveau de tout l'espace secondaire
disponible. A un niveau different, le systeme gere la
creation et la destruction des classes d'objets,
l'heritage, le traitement des references pour les objets
complexes, l'insertion, la selection, la mise a jour et
l'effacement des objets. Dans le but d'acceder
efficacement aux objets, le systeme supporte
l'indexation d'informations des classes d'objets. Le
module de stockage est ecrit en langage C sur la machine
SUN sous l'environnement UNIX.
Dans le but de valider cette librairie, nous avons
defini la grammaire du langage de requetes SQLO qui est
similaire a SQL, mais avec une extension pour supporter
les objets. De plus, nous avons concu prototype
simplifie d'un systeme de gestion de base d'objets
SGBOS. Il s'agit d'un interpreteur pour le langage SQLO.
</ABSTRACT>
</THESIS>
<THESIS>
<NUMBER> 4292 </NUMBER>
<ORDER>   AAGMM89879 </ORDER>
<TITLE>   A NEURAL ALGORITHM FOR THE DEVELOPMENT OF INVARIANT TRANSFORMATIONS FOR RECOGNITION </TITLE>
<AUTHOR>   DECRUYENAERE, JEAN-PAUL </AUTHOR>
<YEAR>   1993 </YEAR>
<INSTITUTION>   CARLETON UNIVERSITY (CANADA); 0040 </INSTITUTION>
<DESCRIPTORS>   ENGINEERING, SYSTEM SCIENCE; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER>   NIL </ADVISER>
<CLASSIFICATIONS>   NIL </CLASSIFICATIONS>
<ABSTRACT>
A self-organizing neural technique is demonstrated which
is capable of producing nontrivial invariant transforms
which are suitable for image recognition tasks. This
method is not limited to the processing of images, but
can instead be used in principle to produce invariant
transforms for any type of vector data. The invariant
transform is implicitly encoded by way of a training
sample set. The general issues of invariant transforms
and their use in vision systems are addressed, as well
as those issues which relate to a subsequent neural
implementation. Results are given for numerous
simulations, including that of a shift and rotation
invariant net which is trained with a set of random
synthetic images. Recommendations are given for further
study, including improvements to the existing method, as
well as extensions to more complex visual recognition
systems.
</ABSTRACT>
</THESIS>
<THESIS>
<NUMBER> 4293 </NUMBER>
<ORDER>   AAGMM80534 </ORDER>
<TITLE>   AN APPROACH TO MYOELECTRIC CONTROL USING A SELF- ORGANIZING NEURAL NETWORK FOR FEATURE EXTRACTION </TITLE>
<AUTHOR>   GALLANT, PETER JOSEPH </AUTHOR>
<YEAR>   1993 </YEAR>
<INSTITUTION>   QUEEN'S UNIVERSITY AT KINGSTON (CANADA); 0283 </INSTITUTION>
<DESCRIPTORS>   ENGINEERING, ELECTRONICS AND ELECTRICAL; ENGINEERING, BIOMEDICAL; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER>   NIL </ADVISER>
<CLASSIFICATIONS>   NIL </CLASSIFICATIONS>
<ABSTRACT>
This work describes a new method of processing
myoelectric signals (MES) using a self-organizing neural
network for feature extraction, leading to a new
approach to the control of myoelectric prostheses and
functional neuromuscular stimulation (FNS) systems. The
amplitude of the MES during the first 200 ms after the
onset of a voluntary muscle contraction activity has a
deterministic structure which permits the application of
advanced pattern recognition techniques to the problems
of MES processing and control. The myoelectric control
task is formulated as two-step process involving a
representational stage, and a classification stage.
The extraction of MES features is accomplished by a self-
organizing neural net-work composed of BCM neurons that
performs an advanced statistical analysis procedure
known as Exploratory Projection Pursuit. The adaptive,
or "learning", ability of the neural network-
based classifier used in the control system offers
enhanced functionality of a myoelectric prosthesis or
FNS system, and also simplifies user training through
adaptation to the individual MES characteristics of each
user. (Abstract shortened by UMI.)
</ABSTRACT>
</THESIS>
<THESIS>
<NUMBER> 4294 </NUMBER>
<ORDER>   AAGMM80516 </ORDER>
<TITLE>   PARTITIONING STRATEGIES FOR PARALLELIZING NEURAL NETWORKS </TITLE>
<AUTHOR>   WONG, TAK SHING </AUTHOR>
<YEAR>   1993 </YEAR>
<INSTITUTION>   QUEEN'S UNIVERSITY AT KINGSTON (CANADA); 0283 </INSTITUTION>
<DESCRIPTORS>   COMPUTER SCIENCE; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER>   NIL </ADVISER>
<CLASSIFICATIONS>   NIL </CLASSIFICATIONS>
<ABSTRACT>
In this thesis, we illustrate how an Artificial Neural
Network (ANN) using Back-propagation algorithm can be
implemented in a distributed memory and message passing
environment. Three partitioning strategies, horizontal
slicing, vertical slicing and block cutting, are
suggested. The performance of each strategy is analyzed
theoretically by establishing an analytic model, and
analyzed experimentally using a parallel network
simulator. It is found that there are large
discrepancies between the predicted and the measured
results. The discrepancies are mainly due to the
implementation method and the underestimation of the
communication and computation costs. Block cutting is
found to be the best strategy to obtain high speedup and
parallelism for an ANN with the same width for each
layer.
</ABSTRACT>
</THESIS>
<THESIS>
<NUMBER> 4295 </NUMBER>
<ORDER>   AAG9403574 </ORDER>
<TITLE>   EXPERT SYSTEM FOR BRIDGE RAIL SELECTION </TITLE>
<AUTHOR>   PREMTHAMKORN, PRAKIT </AUTHOR>
<YEAR>   1993 </YEAR>
<INSTITUTION>   TEXAS A&M UNIVERSITY; 0803 </INSTITUTION>
<DESCRIPTORS>   ENGINEERING, CIVIL; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER>   PAUL ROSCHKE </ADVISER>
<CLASSIFICATIONS>   NIL </CLASSIFICATIONS>
<ABSTRACT>
Bridge Rail EXpert System (BREXS) is a rule-based expert
system developed to aid novice engineers in coping with
bridge rail design and retrofit problems. Development
goals for this system are to incorporate bridge rail
knowledge bases, bridge rail databases, analytical
computer codes, and fuzzy logic decision-making
capabilities into a comprehensive decision support
system. The resulting system is intended to assist less
experienced bridge engineers in choosing an optimum rail
that conforms to standard specifications and satisfies
service requirements. BREXS is customized to meet
standard requirements of bridge railing practice in
Texas. Knowledge from state level officials and several
experienced district engineers were elicited and
represented in the form of rules and databases.
Knowledge bases and supporting analysis programs are
integrated under a graphical user interface. Integration
is transparent to the user, thus ensuring ease of use.
BREXS consists of two subsystems that deal with new
construction and retrofit problems.
BREXS is a relatively small expert system which contains
a total of approximately 400 rules in its knowledge
bases. Problem-solving strategy is based on the
derivation approach. BREXS infers functional
requirements from the characteristics of a given bridge
site. Each standard Texas rail is then evaluated for its
merits and drawbacks for installation based on a set of
criteria. The MYCIN method for uncertainty treatment is
employed to accommodate determination of the most
appropriate rail. The optimal position for installation
on an existing bridge and type of anchorage are also
determined for retrofit problems.
Special attention is placed on design of the user
interface to ensure ease of use. Interactive windows and
pull-down menus facilitate input of data and execution
of the system. From the interface, users can also access
the bridge rail database and update the records. On-line
help on system usage is available. A scale drawing of
the recommended rails and existing bridge can be
displayed and printed to accommodate preparation of
construction drawings.
A method of system validation was designed to deal with
the multiple experts. Extensive field testing on several
district offices was performed to evaluate the system in
real-world conditions. Several phases of testing, that
involved face validation, Turing test, and sensitivity
analysis, were used to validate and measure performance
of the system. Results of validation show a satisfactory
level of performance. BREXS exhibits expertise that is
comparable to experienced district engineers.
A total effort of three man-years was required in
prototyping, expanding, and revising BREXS.
Implementation of the system is being planned by Texas
Department of Transportation.
</ABSTRACT>
</THESIS>
<THESIS>
<NUMBER> 4296 </NUMBER>
<ORDER>   AAG9403539 </ORDER>
<TITLE>   TBSM: A TASK-BASED SPECIFICATION METHODOLOGY FOR EXPERT SYSTEMS </TITLE>
<AUTHOR>   LEE, YUUNJUNG RAITZ </AUTHOR>
<YEAR>   1993 </YEAR>
<INSTITUTION>   TEXAS A&M UNIVERSITY; 0803 </INSTITUTION>
<DESCRIPTORS>   COMPUTER SCIENCE; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER>   JOHN YEN </ADVISER>
<CLASSIFICATIONS>   NIL </CLASSIFICATIONS>
<ABSTRACT>
There has been an increasing interest in improving the
quality and reliability of artificial intelligence
systems. As a result, several methodologies for
specifying expert systems have been proposed. However,
these approaches are limited in formally verifying and
validating the intended functionality and behavior of an
expert system. In this dissertation, a novel methodology
is proposed, the task-based specification methodology,
for specifying the model and the process knowledge of an
expert system at different abstraction levels.
Specifications are acquired and organized around the
system's functional units called tasks. To capture a
specification at its appropriate abstraction levels, we
use the task structure to achieve a functional
decomposition that supports polymorphism.
A formal foundation for the proposed methodology is
presented to formulate two major components: functional
and behavioral specification. The notion of state
transition model is adopted for formulating the
functional specification. The notion of task structure
is formalized for the analysis of task process
refinement. Task state expressions are used to describe
expected behavior specifications. Progression operators
and frame axioms are adopted for constructing the state
description. The formalism provided by the framework
serves as a basis for the verification of
specifications. The proposed methodology and its
benefits are demonstrated using a specification of
R1/SOAR constructed in a reverse engineering fashion.
Based on the proposed methodology, a knowledge
engineering tool is developed to facilitate acquiring
and organizing the specification and the prototype. In
the proposed framework, the prototype complements the
specification throughout the expert systems life cycle.
The traceability between them is facilitated by
organizing both types of artifacts using a common
functional decomposition structure. In a preliminary
study of the role of fuzzy logic in specifying imprecise
requirements, the proposed methodology is further
extended by formulating soft functional requirements
using test-score semantics, and by using the criticality
qualifier to represent the degree of importance of soft
requirements.
The proposed specification methodology not only enables
the verification of an expert system's knowledge in an
earlier phase of the software life cycle, but can be
used to facilitate the validation and the maintenance of
large expert systems.
</ABSTRACT>
</THESIS>
<THESIS>
<NUMBER> 4297 </NUMBER>
<ORDER>   AAG9401483 </ORDER>
<TITLE>   SYSTEM DYNAMICS STRUCTURAL OPTIMIZATION FOR PROCESS RE- DESIGN </TITLE>
<AUTHOR>   VYE, PATRICK DENNIS </AUTHOR>
<YEAR>   1993 </YEAR>
<INSTITUTION>   UNIVERSITY OF WASHINGTON; 0250 </INSTITUTION>
<DESCRIPTORS>   ENGINEERING, INDUSTRIAL </DESCRIPTORS>
<ADVISER>   SCOTT IVERSON </ADVISER>
<CLASSIFICATIONS>   HEALTH CARE </CLASSIFICATIONS>
<ABSTRACT>
A new quantitative modeling approach is proposed in
order to re-engineer organizational structures and
policies. The approach uses a System Dynamics simulation
and an Artificial Intelligence machine learning
technique known as a genetic algorithm. This research
proposes a replacement for traditional system dynamics
optimization. This approach is different in that it: (1)
analyzes a greater number of policy options than normal;
(2) optimizes a selection of structures instead of
adjusting parameters in a fixed simulation structure;
and (3) develops a set of robust policies that perform
well despite uncertainty and noise in the environment.
The SDSO software and approach are first applied to a
'Simple Production Problem' in order to refine and
validate the approach. Finally the approach and software
is applied to the Seattle VA hospital ambulatory care
system in order to re-design the patient and treatment
flow processes to improve accessibility and efficiency
in the system.
</ABSTRACT>
</THESIS>
<THESIS>
<NUMBER> 4298 </NUMBER>
<ORDER>   AAG9401445 </ORDER>
<TITLE>   PROCESS MONITORING AND SYSTEM IDENTIFICATION USING A COMBINED ARCHITECTURE OF LINEAR AND NONLINEAR ARTIFICIAL NEURAL NETWORKS </TITLE>
<AUTHOR>   LEE, SAMUEL EUI </AUTHOR>
<YEAR>   1993 </YEAR>
<INSTITUTION>   UNIVERSITY OF WASHINGTON; 0250 </INSTITUTION>
<DESCRIPTORS>   ENGINEERING, CHEMICAL; CHEMISTRY, ANALYTICAL; STATISTICS; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER>   BRADLEY R. HOLT </ADVISER>
<CLASSIFICATIONS>   NIL </CLASSIFICATIONS>
<ABSTRACT>
Accurately modeling the process data is an important
part of process control, quality control, process
monitoring, and sensor development. This research was
focused on demonstrating that artificial neural networks
(ANNs) are good tools for modeling linear and nonlinear
process data. The problems and issues that this research
had to deal with were related to a single objective--the
correct modeling of the available process data. To reach
such a goal, this research studied: (1) how to construct
a proper ANN model structure, (2) how to handle limited
calibration data sets, (3) how to reduce the calibration
or training time, and (4) how to correctly validate the
resulting model. It is well understood though that
solutions for these problems are problem-dependent and
that there is no one heuristic which can be applied to
all problems. This research identified the advantageous
modeling and analytical properties of the direct linear
feedthrough (DLF) network structure which incorporated
the linear mapping abilities to the nonlinear network.
When the DLF network was compared with a wide spectrum
of linear and nonlinear regression tools, the DLF
network always produced one of the best models. A
powerful analytical method was developed using a four-
layer DLF network where one can determine the severity
of the nonlinearity of the process data. For handling
the limited data set, different data treatment methods
were tested and a vast amount of knowledge has been
obtained on the relationships between data structures
and model structures. Also, the training time was
significantly reduced by the sequential quadratic
programming (SQP) method. For the model validation,
statistical validation methods were used to improve the
confidence and robustness of the final model.
</ABSTRACT>
</THESIS>
<THESIS>
<NUMBER> 4299 </NUMBER>
<ORDER>   AAG9401437 </ORDER>
<TITLE>   AN INTELLIGENT SYSTEM AS A COMPUTER AID FOR POWER CONVERTER DESIGNERS </TITLE>
<AUTHOR>   HSIEH, JIMMY </AUTHOR>
<YEAR>   1993 </YEAR>
<INSTITUTION>   UNIVERSITY OF WASHINGTON; 0250 </INSTITUTION>
<DESCRIPTORS>   ENGINEERING, ELECTRONICS AND ELECTRICAL; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER>   CHEN-CHING LIU </ADVISER>
<CLASSIFICATIONS>   NIL </CLASSIFICATIONS>
<ABSTRACT>
A knowledge-based system (KBS) is developed as a
computer aid for power converter designers. The
knowledge acquired from experienced designers are
generalized and incorporated in the KBS. The algorithm-
based methods (ABM) and case-based reasoning techniques
are integrated with the KBS to help overcome the
difficulty of incomplete design knowledge. Given a set
of specifications, the KBS is able to suggest converter
circuit parameters. The parameter estimation algorithm
can be used to calculate parameter adjustments necessary
to eliminate violations of the specifications. Previous
designs are stored as cases. The case information
includes the parameter values of the cases and the
knowledge derived from the cases. A design close to a
previous case can be retrieved and modifications which
may be needed to correct violations can be found using
the stored knowledge. The knowledge derived from the
stored cases is specific to cases of the same types,
however. A fast converter simulation algorithm is also
integrated with the design software; this time domain
simulator provides the dynamic trajectory of the
converter. This integrated methodology is intended to
help reduce the design time and costs. Practical
converter design examples are provided.
The KBS is intended to emulate the human expert in power
converter design. It contains the knowledge of converter
synthesis and modification alternatives. The designers'
experience in utilizing the software tools to help solve
the design problem is also modeled in the controller
section of the KBS. A parameter estimation algorithm is
developed and integrated with the KBS. This algorithm
formulates the design problem as a non-linear least
square problem and uses Levenberg-Marquardt method to
solve it. The sensitivity matrix is computed by the
forward difference approximation based on results of the
converter simulator. The estimation algorithm provides a
systematic approach to elimination of the design
violations. The case-based reasoning technique is also
included in the design methodology to take advantage of
the previous designs. An efficient indexing scheme
allows easy retrieval of a similar design solution to
solve the new problem. The indexing scheme is derived
from the design specifications. The knowledge model is
derived from the existing cases to store the
modification alternatives of the previous designs. It
will be used by the KBS to adapt the retrieved case
whenever any violations of the specifications exist. A
fast time-domain converter simulator is used by the KBS
to verify the design. This simulator uses only the ideal
switch models and provides accurate dynamic responses.
</ABSTRACT>
</THESIS>
<THESIS>
<NUMBER> 4300 </NUMBER>
<ORDER>   AAG9401409 </ORDER>
<TITLE>   GENETIC ALGORITHMS AND NEURAL NETWORKS APPLIED TO MANUFACTURING SCHEDULING </TITLE>
<AUTHOR>   CASKEY, KEVIN RICHARD </AUTHOR>
<YEAR>   1993 </YEAR>
<INSTITUTION>   UNIVERSITY OF WASHINGTON; 0250 </INSTITUTION>
<DESCRIPTORS>   ENGINEERING, INDUSTRIAL; OPERATIONS RESEARCH; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER>   RICHARD L. STORCH </ADVISER>
<CLASSIFICATIONS>   NIL </CLASSIFICATIONS>
<ABSTRACT>
This research applies two current Artificial
Intelligence techniques to develop a tool that will
provide scheduling strategies in a dynamic, rapidly
changing factory. Such a tool is required to analyze the
specific scheduling problem that is the subject of this
research, the heterogeneous dispatching rule problem
(allowing each machine in a facility to use its own
dispatching rule). The need for a tool and the desire to
understand the problem lead to two goals for this work,
creating a tool to provide the strategies and analyzing
the impact of allowing heterogeneous dispatching rules.
The methodology developed in this research uses genetic
algorithms to drive factory simulations toward
optimality. The results of many genetic algorithm
controlled searches are then generalized using neural
networks. This approach allows the results of the
searches to be used in a time frame suitable for factory
scheduling.
The methodology is used in this research to examine
whether it is beneficial to allow the heterogeneous
versus homogeneous application of dispatching rules to
the machines in a factory. The results indicate that
there is no benefit to heterogeneous rules for the
conditions examined in this research. Though there is
little benefit in performance, there is a benefit in
terms of scheduling flexibility. If optimal rules are
applied to bottleneck machines the choice of rule on non-
bottleneck machines has a minimal impact on performance,
as long as the worst rules are not used. The worst rule
found in this research was first in first out.
This dissertation discusses the development of the
methodology and the results of its use to examine the
heterogeneous dispatching rule problem. Extensions of
this methodology to other manufacturing scheduling
problems are presented in the final chapter.
</ABSTRACT>
</THESIS>
<THESIS>
<NUMBER> 4301 </NUMBER>
<ORDER>   AAG9401285 </ORDER>
<TITLE>   EXPLOITING A FUNCTIONAL MODEL OF PROBLEM-SOLVING FOR ERROR DETECTION IN TUTORING </TITLE>
<AUTHOR>   JOHNSON, KATHY ANNE </AUTHOR>
<YEAR>   1993 </YEAR>
<INSTITUTION>   THE OHIO STATE UNIVERSITY; 0168 </INSTITUTION>
<DESCRIPTORS>   COMPUTER SCIENCE; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER>   JACK W. SMITH, JR. </ADVISER>
<CLASSIFICATIONS>   NIL </CLASSIFICATIONS>
<ABSTRACT>
Tutoring systems are a fundamental research area in
artificial intelligence. Consequently, many techniques
for tutoring have been explored as well as specific
tactics for tutoring various domains. Given that a
student has had some basic training in a problem solving
area, tutoring can be viewed as a process during which a
system must (1) monitor a student for mistakes, (2)
determine the cause of the mistake, and (3) give the
student appropriate information to correct his mistake.
Previous tutoring systems frequently ignore the
monitoring problem or assume it is easy. A few systems
have tackled the problem in various ways.
The research reported in this document is an
investigation of how to detect errors when there is a
large amount of variability in correct problem-solving
behavior. The goal was to construct a system capable of
detecting errors in a student's behavior despite this
variability. The system should meet the criteria of (1)
flexibility--allow any correct path performed by the
student, (2) generality--be useful in many domains, and
(3) diagnosticity--provide useful information for
diagnosing the cause of the error. This document
outlines a monitoring system that meets these criteria.
This system uses an explicit model of problem solving
based on a functional decomposition of the problem-
solving goals for the domain. Flexibility is achieved
since such a decomposition provides a representation for
all correct solution paths. Generality is achieved
because the monitor is only dependent on the form of the
problem-solving model, not the content. Only the
representation of the task itself and the expert system
are specific to the task, the portion of the system that
uses the model to detect errors is general and may be
applied to other domains. Finally, the criterion of
diagnosticity is met since monitoring using a model of
problem solving provides information about the student's
state that will aid the diagnosis of the student's
error. The contributions of this work include a
technique for describing problem-solving behavior, a
scheme for using that technique to monitor students, and
an enhancement to a previous version of a functional
representation.
</ABSTRACT>
</THESIS>
<THESIS>
<NUMBER> 4302 </NUMBER>
<ORDER>   AAG9401195 </ORDER>
<TITLE>   NEURAL NETWORKS AND THEIR EXTENSIONS FOR BUSINESS DECISION-MAKING </TITLE>
<AUTHOR>   AGARWAL, ANURAG </AUTHOR>
<YEAR>   1993 </YEAR>
<INSTITUTION>   THE OHIO STATE UNIVERSITY; 0168 </INSTITUTION>
<DESCRIPTORS>   COMPUTER SCIENCE; OPERATIONS RESEARCH; BUSINESS ADMINISTRATION, GENERAL; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER>   HASAN PIRKUL </ADVISER>
<CLASSIFICATIONS>   NIL </CLASSIFICATIONS>
<ABSTRACT>
This study proposes Neural Network frameworks for
solving two different problems, namely--Scheduling and
Bankruptcy Prediction.
In the scheduling problem, tasks with precedence
relationship are to be assigned to machines, which may
be identical or non-identical, such that the makespan
time is minimized. There are arbitrary number of
machines and task preemption is not allowed. In the
proposed framework, a scheduling problem is represented
in the form of a network resembling a Neural Network. It
is an iterative procedure wherein each iteration
produces a feasible solution, and a learning rule
improves the solution from one iteration to the next,
much like in a Neural Network. The proposed framework is
implemented in Pascal running on microcomputer and
tested on 200 problems for the case of identical
machines and 124 problems for the case of non-identical
machines. For the case of identical machine, the results
are compared with those of a known heuristic and we find
that in 77% of the cases, the proposed framework gave
improved solutions. The improvement in makespan was
1.13% on average. For the case of non identical
machines, the proposed framework improved over heuristic
in 60% of the cases and the improvement in makespan was
3.69% on average.
For the Bankruptcy Prediction Problem, we propose a
framework which allows us to detect trends across time
in the financial data of companies and accordingly
discriminate between healthy and failing companies. The
proposed Neural Network framework is implemented in
Pascal running on microcomputer and tested on companies
from four different SIC Code groups. Results were
compared with those obtained by using existing
statistical techniques, namely--multivariate
discriminant analysis (MDA) and logistic regression
(Logit) and it was found that the proposed framework
performed better than Logit, which is the better of the
two statistical techniques, at a p-value of 0.062. The
Neural Network framework was also used to detect
bankruptcy using single year data. The results were
compared with those obtained by Logit and MDA and it was
found that the Neural Networks outperformed logit for
all the SIC Codes at significant p-values.
</ABSTRACT>
</THESIS>
<THESIS>
<NUMBER> 4303 </NUMBER>
<ORDER>   AAG9335173 </ORDER>
<TITLE>   THE COMPILATION OF DESIGN DECOMPOSITION KNOWLEDGE </TITLE>
<AUTHOR>   LIU, JINGWEN </AUTHOR>
<YEAR>   1993 </YEAR>
<INSTITUTION>   WORCESTER POLYTECHNIC INSTITUTE; 0774 </INSTITUTION>
<DESCRIPTORS>   COMPUTER SCIENCE; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER>   DAVID C. BROWN </ADVISER>
<CLASSIFICATIONS>   KNOWLEDGE COMPILATION, EXPERT SYSTEMS </CLASSIFICATIONS>
<ABSTRACT>
Design expert systems can be characterized by the type
of compiled knowledge used. Such knowledge is efficient
for a bounded set of design problems, but often leads to
failure for slightly different problems. Decomposition
knowledge is often compiled into systems. Requirements
changes often change the problem decomposition.
The goal of this research is to decompose design
problems using many types of knowledge such as knowledge
of objects, functions, design cases, design heuristics,
general problem-solving, the domain, and the
requirements. We have proposed a static knowledge
compilation mechanism which can generate good
decompositions for parametric design problems. Knowledge
Compilation is learning in which existing knowledge is
converted into new forms, to improve problem-solving
efficiency. The proposed mechanism uses a variety of
types of available knowledge to synthesize
decompositions for different design problems. We claim
that those good decompositions generated can reduce
search and make design more efficient.
From analysis, we have found two general heuristics for
decomposing design problems: attribute partitioning
should based on interaction strength, and subproblem
ordering should based on the size of subproblem solution
spaces. Our mechanism is a procedure for
operationalizing those decomposition heuristics. It
recursively applies these steps to each subproblem: (1)
Knowledge extraction and decomposition factor
generation. (2) Hypothesis proposal and refinement. (3)
Hypothesis confirmation.
A system called KDD has been developed to implement the
mechanism. We have tested the system on two domains of
engineering design, force transducer design and poppet
relief valve design. Quantitative evaluations of the
resulting problem decompositions have been conducted.
The results show that the generated decompositions can
greatly reduce the amount of backtracking.
</ABSTRACT>
</THESIS>
<THESIS>
<NUMBER> 4304 </NUMBER>
<ORDER>   AAG9332727 </ORDER>
<TITLE>   ESTIMATING PATIENT SEVERITY USING A BAYESIAN PATTERN RECOGNITION APPROACH AND A NEURAL NETWORK APPROACH </TITLE>
<AUTHOR>   CHEN, SUYUN </AUTHOR>
<YEAR>   1993 </YEAR>
<INSTITUTION>   ILLINOIS INSTITUTE OF TECHNOLOGY; 0091 </INSTITUTION>
<DESCRIPTORS>   ENGINEERING, SYSTEM SCIENCE; ENGINEERING, BIOMEDICAL; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER>   MARTHA W. EVENS </ADVISER>
<CLASSIFICATIONS>   NIL </CLASSIFICATIONS>
<ABSTRACT>
Severity measurement is crucial for medical resource
allocation and patient management. It is also very
useful for monitoring the performance of care and
quality of treatment.
This research explores two methods that are totally
different from existing severity scoring systems, that
is, a Bayesian Pattern Recognition approach and a Neural
Network approach.
The Bayesian approach was used in two successful
experiments. In the first experiment, two physicians
were asked to estimate patient severity for two groups
of patients, one with myocardial infarction and one with
diabetes mellitus. These severity estimates were
compared with those produced by the system. The system
agreed with the average of the two physicians even
better than they agreed with each other. The second
experiment involved a series of patients from the
Cardiac Intensive Care Unit at the North Chicago VA
Medical Center. The Bayesian method was used to estimate
patient severity two hours after admission, four to six
hours after admission, and then three more times at
roughly four hour intervals during the first twelve
hours. The severity scores computed in this manner
predicted the APACHE score at twenty-four hours with
high correlation. What is more, the MEDAS severity score
predicted the severity estimates made by two physicians
more closely than the APACHE score did.
The Neural Network approach was also used in two other
successful experiments. It was used on the same data
from the ICU patients involved in the second experiment.
The results are even better than those given by the
Bayesian approach. The Neural Network method was so
promising that we used in it another experiment using
data from the Diabetes Clinic at the North Chicago VA
hospital. The results show that this new approach seems
to be very successful.
</ABSTRACT>
</THESIS>
<THESIS>
<NUMBER> 4305 </NUMBER>
<ORDER>   AAG0574020 </ORDER>
<TITLE>   PARALLEL MEMORY-BASED PARSING ON A MARKER-PASSING COMPUTER </TITLE>
<AUTHOR>   CHUNG, MINHWA </AUTHOR>
<YEAR>   1993 </YEAR>
<INSTITUTION>   UNIVERSITY OF SOUTHERN CALIFORNIA; 0208 </INSTITUTION>
<DESCRIPTORS>   ENGINEERING, ELECTRONICS AND ELECTRICAL </DESCRIPTORS>
<ADVISER>   DAN I. MOLDOVAN </ADVISER>
<CLASSIFICATIONS>   NIL </CLASSIFICATIONS>
<ABSTRACT>
Recently, due to the availability of massively parallel
computers, the role of parallel processing techniques in
artificial intelligence (AI) applications is increasing.
Applying parallel processing to AI not only offers an
improved speed, but also provides us a new perspective
to look at the problems. However, there is not much work
done in applying parallel processing to natural language
processing (NLP) applications. Since we can find
parallelism available in NLP and there is a need for
high performance NLP systems, we set our research goal
at developing a high performance NLP system on a
massively parallel computer. This dissertation presents
a parallel memory-based parser called PARALLEL, which is
implemented on a marker-passing parallel AI computer
called Semantic Network Array Processor (SNAP).
In the PARALLEL memory-based parser, the parallelism in
natural language processing is utilized by a memory
search model of parsing. Linguistic information is
stored as phrasal patterns in a semantic network
knowledge base that is distributed over the memory of
the parallel computer. Parsing is performed by
recognizing and linking linguistic patterns that reflect
a sentence interpretation. This is achieved via
propagating markers over the distributed network. In
order to handle a large and realistic domain with real
time performance: (1) a flexible knowledge
representation scheme is provided, where the whole
sentence pattern is represented by a dynamic combination
of smaller templates; (2) parallel marker-passing
solutions are provided by encoding syntactic information
into the knowledge base and incorporating an integrated
syntactic and semantic analysis into the memory-based
parsing algorithm for various linguistic phenomena, such
as embedded sentences. Real time performance was
obtained for parsing newswire articles about terrorism
domain with a large knowledge base of 12,000 semantic
network nodes. (Copies available exclusively from
Micrographics Department, Doheny Library, USC, Los
Angeles, CA 90089-0182.)
</ABSTRACT>
</THESIS>
<THESIS>
<NUMBER> 4306 </NUMBER>
<ORDER>   AAGNN81812 </ORDER>
<TITLE>   DETERMINISTIC BOLTZMANN MACHINES: LEARNING INSTABILITIES AND HARDWARE IMPLICATIONS </TITLE>
<AUTHOR>   SCHNEIDER, ROLAND </AUTHOR>
<YEAR>   1993 </YEAR>
<INSTITUTION>   THE UNIVERSITY OF MANITOBA (CANADA); 0303 </INSTITUTION>
<DESCRIPTORS>   ENGINEERING, ELECTRONICS AND ELECTRICAL; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER>   NIL </ADVISER>
<CLASSIFICATIONS>   NEURAL NETWORK </CLASSIFICATIONS>
<ABSTRACT>
The deterministic Boltzmann machine (DBM) neural network
architecture was originally derived from the stochastic
Boltzmann machine (BM) by substituting the expected
values of unit activations for the stochastic
activations of the BM. Our simulations show that the
DBM, unlike the BM, exhibits unstable behavior such as
oscillation during learning and hypersensitivity to
small perturbations of the weights or other network
parameters. While other researchers have encountered
similar oscillatory behavior, it has never been
satisfactorily analyzed.
It is shown that this unstable behavior is the result of
over-parameterization (excessive freedom in the
weights), which leads to continuous instead of isolated
optimal weight solution sets. Because the optimal weight
solution sets are continuous, the weights are free to
drift without correction from the learning algorithm
until two minima in the network energy function are of
equal depth and a gross output error occurs. The
subsequent correction and later recurrence of these
gross errors appears as a series of narrow spikes in the
output error of the network. The DBM learning algorithm
is incapable of preventing this oscillation because it
uses only the final output error of the network to
adjust the weights, and the output error is zero for an
optimal weight set until a gross error occurs.
The existence of multiple minima in the DBM energy
function, and the resulting behavior, is shown to be
analogous to prematurely terminating the statistics
gathering period in a BM. Since the required period
increases with the size of the BM, and the DBM is
analogous to an infinite-sized BM, simply increasing the
size of the DBM network will not prevent the oscillatory
DBM behavior.
Various issues relating to the implementation of DBMs
using non-ideal analog hardware, and their relationship
to the weight drift problem, are also explored. It is
found that only non-ideal behaviors that cause the
weight values to drift, most notably weight decay, have
a significant effect on network performance, and that
there is no threshold below which these behaviors can be
tolerated. Other non-ideal analog behaviors, such as
component non-linearities, do not seriously degrade
network performance.
</ABSTRACT>
</THESIS>
<THESIS>
<NUMBER> 4307 </NUMBER>
<ORDER>   AAGNN81142 </ORDER>
<TITLE>   A VLSI DESIGN METHODOLOGY FOR ARTIFICIAL NEURAL NETWORKS </TITLE>
<AUTHOR>   SONG, LIANG-YONG </AUTHOR>
<YEAR>   1993 </YEAR>
<INSTITUTION>   UNIVERSITY OF WATERLOO (CANADA); 1141 </INSTITUTION>
<DESCRIPTORS>   ENGINEERING, ELECTRONICS AND ELECTRICAL; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER>   NIL </ADVISER>
<CLASSIFICATIONS>   AUTOMATION </CLASSIFICATIONS>
<ABSTRACT>
A VLSI design methodology for artificial neural networks
(ANNs) is presented in this thesis. This methodology
augments the digital design automation methodologies to
support the analog or hybrid implementations of ANNs.
The methodology is implemented in a prototype of a
module generator MANNA for ANNs. Given ANN
specifications, MANNA automatically generates a
hierarchical circuit schematic, then generates a
standard cell layout.
Two types of circuit building blocks have been designed
to implement the basic building block operations in
ANNs. One based on a novel current model subthreshold
operation (CMSO) concept yields ver low power
consumption circuit with relatively high speed. The
other is designed to compactly implement ANNs with
digital inputs/outputs and analog weights. This allows
more neurons to be implemented on a single chip.
A new sea-of-neurons (SON) structure is proposed to be
as an ANN physical design style for fast prototyping.
The SON structure is an analog or hybrid array and
supports analog or hybrid neural circuit
implementations. A novel placement algorithm that is
suitable for large scale and highly interconnected
systems is presented. The initial placement is obtained
by a global placement method. A Tabu search technique,
which attempts to overcome the limitations and problems
of moving from a local optimal point, is adapted to
improve the placement quality. The placement method has
been implemented in the C language in the programs TS
and TSSC for gate array and standard cell placement
separately. The programs TS and TSSC yield placements
that are comparable with simulated annealing based
layout package TimberWolfSC5.4. However, the running
speed is much faster. The initial placement method can
also be extended to solve the circuit partitioning
problem. The method yields very good results for fast
circuit partitioning.
</ABSTRACT>
</THESIS>
<THESIS>
<NUMBER> 4308 </NUMBER>
<ORDER>   AAGNN80872 </ORDER>
<TITLE>   DISPERSIVE NEURAL NETWORKS FOR ADAPTIVE SIGNAL PROCESSING </TITLE>
<AUTHOR>   DAY, SHAWN P. </AUTHOR>
<YEAR>   1993 </YEAR>
<INSTITUTION>   THE UNIVERSITY OF BRITISH COLUMBIA (CANADA); 2500 </INSTITUTION>
<DESCRIPTORS>   ENGINEERING, ELECTRONICS AND ELECTRICAL; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER>   NIL </ADVISER>
<CLASSIFICATIONS>   SIGNAL PROCESSING </CLASSIFICATIONS>
<ABSTRACT>
Back-propagation is a popular method for training feed-
forward neural networks. This thesis extends the back-
propagation technique to dispersive networks, which
contain internal delay elements. Both the delays and the
weights adapt to minimize the error at the output.
Dispersive networks can perform many tasks, including
signal prediction, signal production, channel
equalization, and spatio-temporal pattern recognition.
For comparison with conventional techniques, a
dispersive network was trained to predict future values
of a chaotic signal using only its present value as an
input. With adaptable delays, the network had less than
half the prediction error of an identical network with
fixed delays, and about one-quarter the error of a
conventional back-propagation network. Moreover, a
dispersive network can simultaneously adapt and predict,
while a conventional network cannot.
After training as a predictor, the network was placed in
a signal production configuration, where it autonomously
generated a close approximation to the training signal.
The power spectrum of the network output was a good
reproduction of the training signal spectrum. Networks
with fixed time delays produced much less accurate power
spectra, and conventional back-propagation networks were
unstable, generating high-frequency oscillations.
Dispersive networks also showed an improvement over
conventional techniques in an adaptive channel
equalization task, where the channel transfer function
was nonlinear. The adaptable delays in the dispersive
network allowed it to reach a lower error than other
equalizers, including a conventional back-propagation
network and an adaptive linear filter. However, the
improved performance came at the expense of a longer
training time.
Dispersive networks can be implemented in serial or
parallel form, using digital electronic circuitry.
Unlike conventional back-propagation networks, they can
operate in a fully pipelined fashion, leading to a
higher signal throughput. Their implementation in analog
hardware is a promising area for future research.
</ABSTRACT>
</THESIS>
<THESIS>
<NUMBER> 4309 </NUMBER>
<ORDER>   AAG9403497 </ORDER>
<TITLE>   THE EFFECTS OF A KNOWLEDGE-BASED SYSTEM ON ORGANIZATIONAL INFORMATION INPUT OVERLOAD </TITLE>
<AUTHOR>   GEYER, MICHELLE WALTERS </AUTHOR>
<YEAR>   1993 </YEAR>
<INSTITUTION>   TEXAS A&M UNIVERSITY; 0803 </INSTITUTION>
<DESCRIPTORS>   INFORMATION SCIENCE; BIOLOGY, ENTOMOLOGY; COMPUTER SCIENCE; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER>   GEORGE FOWLER; DAVID PARADICE </ADVISER>
<CLASSIFICATIONS>   ORGANIZATIONAL INFORMATION </CLASSIFICATIONS>
<ABSTRACT>
Successful decisions largely depend on correct
interpretation of data. Today, our ability to collect
and present data outstrips our ability to interpret it.
This situation has been called "information input
overload" (Miller 1960). Information input overload
was first investigated by Miller as the logical opposite
of information input deprivation and is now accepted as
an everyday occurrence. Information input overload is
known to have a deleterious effect on decision makers
(Sheridan and Ferrell 1974). These effects include:
ignoring further input, delay in making a decision,
filtering the data, and giving up (Miller 1960). A
knowledge-based system was developed that is not
affected by information input overload. The system makes
full use of data, knowledge, and other information,
extracts the critical decision factors and follows a
decision tree to find related pieces of information. The
system puts these factors into a form that minimizes the
volume of data while presenting a complete picture of
the situation to the decision maker. The system was
tested against project management and performed equally
well in identifying core problem areas. The system
performed significantly better than did project
management in assigning treatments to these core areas,
thus minimizing risk, optimizing use of resources, and
enforcing the prescribed protocol. The knowledge-based
system also satisfactorily identified areas indirectly
affected and performed significantly better than project
management in assigning treatments to those areas. In
addition, the system provided superior documentation of
reasoning and actions to be taken. It also provided a
platform for using existing simulation models to aid in
strategic decision making, and for a geographic
information system to aid tactical performance of
recommendations. The system used object-oriented design,
expert system techniques, a link to simulation models,
and database management in an integrated system to
optimize, improve, and ease the decision making process,
whether under the effects of information input overload
or not.
</ABSTRACT>
</THESIS>
<THESIS>
<NUMBER> 4310 </NUMBER>
<ORDER>   AAG9402906 </ORDER>
<TITLE>   SEMI-NONPARAMETRIC ESTIMATION AND TESTING OF CONSUMER DEMAND SYSTEMS </TITLE>
<AUTHOR>   LI, YING </AUTHOR>
<YEAR>   1993 </YEAR>
<INSTITUTION>   WASHINGTON STATE UNIVERSITY; 0251 </INSTITUTION>
<DESCRIPTORS>   ECONOMICS, GENERAL; ECONOMICS, THEORY; COMPUTER SCIENCE; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER>   WAYNE JOERDING </ADVISER>
<CLASSIFICATIONS>   NEURAL NETWORKS </CLASSIFICATIONS>
<ABSTRACT>
Inconsistency between the theory of consumer demand and
empirical evidence represents a persistent problem in
economic studies of consumer behavior. Traditional
models, when used to estimate a demand system and test
the validity of consumer demand theory, assume a
specific functional form for consumer behavior and
therefore can reject the theory because of function
misspecification. This study investigates consumer
behavior using a flexible functional form derived from
the neural network models of artificial intelligence.
Using flexible functional forms to test consumer theory
goes back at least to the work of Christensen, Jorgenson
and Lau (1975) and currently uses expansion models, with
Gallant's fourier flexible form perhaps the most well
known. These expansion models call approximate any
functional form and its derivatives in a wide class of
functions. Thus, they can model consumer behavior
without imposing any but modest assumptions on
preferences, such as piecewise continuity. Since many of
the consumer characteristics economists seek to measure
and test depend on derivatives, e.g. elasticity of
substitution, the ability of expansion models to
approximate an unknown function and its derivative,
Sobolov flexibility, constitutes an important advantage
over traditional models.
Feedforward (neural) networks, a special form of neural
networks, fall in the class of expansion models and have
been shown by Hornik, Stinchcombe, and White (1989) to
have the Sobolov flexibility characteristic. However,
feedforward networks differ from previous expansion
models since they use expansions of adaptive basis
functions rather than pre-determined functions. This
difference means that under certain conditions
feedforward networks may approximate unknown functions
more rapidly as a function of the number of parameters
than other expansion models. Unfortunately this
advantage also makes the feedforward networks more
difficult to estimate, or train in the neural networks
jargon, requiring special estimation algorithms.
This dissertation shows how to apply the new feedforward
network technique to the study of consumer demand
systems. Two important contributions of this work
include: (i) developing methods to impose restrictions
implied by consumer demand theory such as adding up,
homogeneity, symmetry, and negativity, on the
feedforward network model; (ii) developing methods to
estimate unknown consumer demands and test economically
interesting hypotheses about consumer theory. As an
application, I present empirical tests of the theory
based on the data used by Christensen, Jorgenson and Lau
(1975) to study the trans-log specification and used by
Gallant (1981) to study the Fourier flexible form.
</ABSTRACT>
</THESIS>
<THESIS>
<NUMBER> 4311 </NUMBER>
<ORDER>   AAG9402798 </ORDER>
<TITLE>   A KNOWLEDGE-BASED APPROACH TO AUTOMATE AND SUPPORT DYNAMIC DECISION-MAKING FOR THE CONTROL OF COMPLEX DISCRETE SYSTEMS </TITLE>
<AUTHOR>   PFLUGHOEFT, KURT ALFRED </AUTHOR>
<YEAR>   1993 </YEAR>
<INSTITUTION>   THE UNIVERSITY OF WISCONSIN - MILWAUKEE; 0263 </INSTITUTION>
<DESCRIPTORS>   BUSINESS ADMINISTRATION, MANAGEMENT; OPERATIONS RESEARCH; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER>   GEORGE K. HUTCHINSON </ADVISER>
<CLASSIFICATIONS>   DECISION SUPPORT SYSTEMS, MACHINE LEARNING </CLASSIFICATIONS>
<ABSTRACT>
The loading and control of complex discrete systems,
e.g. manufacturing scheduling, is a problem that has
long plagued researchers and practitioners. Researchers
have often narrowed the scope of the problem to identify
optimal or generalizable solutions but their efforts
were largely unsuccessful (Lenstra, 1991).
Practitioners, forced to cope with the problem's
entirety, have resorted to non-optimal solutions in an
attempt to satisfy their goals. The search for these
satisfactory solutions is often costly and lengthy,
demonstrating the need for methodologies to expedite the
process.
This research develops and tests a general architecture,
namely a Knowledge-Based Simulator (KBSim), for system
control combining the benefits of Decisions Support
Systems and Experts Systems. This approach is knowledge-
based, adapts to changing environments and management
objectives, and incrementally improves performance via
machine learning. Flexpert, a KBSim prototype, is
designed, implemented, and tested for scheduling
discrete manufacturing systems.
Extensive tests were done for all combinations of the
static/dynamic and deterministic/stochastic continuums,
and an industrial case. Flexpert's performance was
superior to selected scheduling rules in many
circumstances and was seldom inferior. Flexpert
consistently outperformed SPT for mean flow time and
S/OPN for static problems with tardiness goals. Flexpert
has proven its ability in exploratory research to
quantify process plan flexibility and find problems
where the effects of scheduling are minimal. The latter
discovery uses KBSim's static analyzer to determine the
upper performance bound and the random rule for the
lower bound.
Researchers will be interested in KBSim's architecture
and its ability to adaptively control discrete systems
as a new approach to a difficult problem. Practitioners
constantly search for approaches such as KBSim to gain a
competitive advantage. In the past, they have
substituted information technologies primarily for
physical tasks. Future productivity gains will be made
by substituting information technology for human
decision making to improve performance, achieve
consistency, and reduce costs. Flexpert's good
performance for manufacturing scheduling suggests that
the KBSim approach will lead to these productivity gains
for many control problems.
</ABSTRACT>
</THESIS>
<THESIS>
<NUMBER> 4312 </NUMBER>
<ORDER>   AAG9402666 </ORDER>
<TITLE>   FORMATION AND DYNAMIC ROUTING OF PART FAMILIES AMONG FLEXIBLE MANUFACTURING CELLS </TITLE>
<AUTHOR>   WEN, HUNGTAO JOSEPH </AUTHOR>
<YEAR>   1993 </YEAR>
<INSTITUTION>   VIRGINIA COMMONWEALTH UNIVERSITY; 2383 </INSTITUTION>
<DESCRIPTORS>   INFORMATION SCIENCE; ENGINEERING, INDUSTRIAL; COMPUTER SCIENCE; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER>   RICHARD T. REDMOND </ADVISER>
<CLASSIFICATIONS>   NIL </CLASSIFICATIONS>
<ABSTRACT>
Because of the nature of 0-1 part-family incidence
matrix, a multi-cell flexible manufacturing systems
(MCFMS) using conventional part-family formation
algorithms, such as array-based clustering, similarity
coefficient-based clustering, and mathematical
programming, in a cellular manufacturing mode can assign
a part only to one machine cell. The consequence is that
each part type has a fixed route through the system.
When each part is limited to a fixed route through the
system, the performance of a MCFMS is diminished. This
is because the inherent flexibility of the FMS is not
fully utilized.
This research proposes a dynamic routing method that
applies a fuzzy clustering algorithm and certainty
factors. The fuzzy clustering algorithm, in which a part
can belong to all families with different degrees of
membership, provides extra information that is not
available in conventional algorithms. This information
would permit managers to make better informed dynamic
routing decisions and allow for more flexible assignment
of parts to flexible manufacturing cells (FMCs). This is
important information and would be especially useful in
balancing machine cell workloads. A workload imbalance
among FMCs can cause excessive flowtimes and tardiness,
and low rates of machine utilization.
</ABSTRACT>
</THESIS>
<THESIS>
<NUMBER> 4313 </NUMBER>
<ORDER>   AAG9402404 </ORDER>
<TITLE>   EXPERT SYSTEMS IN AUDITING: DECISION AID OR DECISION SUBJUGATION </TITLE>
<AUTHOR>   SWINNEY, LAURIE S. </AUTHOR>
<YEAR>   1993 </YEAR>
<INSTITUTION>   THE UNIVERSITY OF NEBRASKA - LINCOLN; 0138 </INSTITUTION>
<DESCRIPTORS>   BUSINESS ADMINISTRATION, ACCOUNTING; COMPUTER SCIENCE; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER>   KUNG H. CHEN </ADVISER>
<CLASSIFICATIONS>   NIL </CLASSIFICATIONS>
<ABSTRACT>
The purpose of this dissertation research is to examine
the extent of auditor reliance on expert system
judgments. The accounting expert system literature is
replete with statements to the effect that although the
expert system is capable of making judgments, these
judgments are to be used only as input into the decision
maker's final determination. The evidence presented in
prior research, however, is not conclusive on the
auditor's use of and reliance on the expert system
judgment.
The belief-adjustment model (Hogarth and Einhorn 1992),
suggests that individuals adjust from their prior
judgment according to the evaluated strength of new
evidence encountered. The primary evidence provided by
an expert system is an explanation of the system's
recommendation. Prior research has shown that self-
generated written explanations influence auditor
judgment. The current research examines the differential
impact of explanations that are self-generated compared
to explanations that are expert system-generated. Prior
auditing research also indicates that auditors attend to
negative evidence to a greater degree than positive
evidence. The current research examines the differential
impact of negative compared to positive explanations on
auditor judgment.
On the basis of experimentation with 41 auditors
evaluating the adequacy of a loan loss reserve, the
results indicate that belief adjustment is greatest when
auditors consider expert system explanations that are
negative. In addition, the level of belief adjustment
following consideration of positive expert system
explanations appears consistent with Hogarth and
Einhorn's belief-adjustment model. The level of belief
adjustment following consideration of negative expert
system explanations, however, appears greater than
expected according to the belief-adjustment model. This
result is consistent with a "strategic attitude
shift" described by Tetlock (1985). Thus, excessive
reliance on the expert system is indicated only when the
expert system's judgment is negative.
</ABSTRACT>
</THESIS>
<THESIS>
<NUMBER> 4314 </NUMBER>
<ORDER>   AAG9402300 </ORDER>
<TITLE>   THE DEVELOPMENT OF AN EXPERT SYSTEM TO EVALUATE THE INDIVIDUALIZED EDUCATION PROGRAM COMPONENTS OF STUDENT RECORDS </TITLE>
<AUTHOR>   HOEHLE, ROBERT LEE, II </AUTHOR>
<YEAR>   1993 </YEAR>
<INSTITUTION>   UTAH STATE UNIVERSITY; 0241 </INSTITUTION>
<DESCRIPTORS>   EDUCATION, SPECIAL; EDUCATION, TECHNOLOGY; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER>   ALAN M. HOFMEISTER </ADVISER>
<CLASSIFICATIONS>   NIL </CLASSIFICATIONS>
<ABSTRACT>
In 1975, Congress passed the Education of All
Handicapped Children Act, mandating that every student
receiving special education have an individualized
education program (IEP). This document is a report on a
research and development project designed to develop an
expert system, IEP Advisor, that provides users with
evaluative feedback on IEPs contained in student
records.
The project included formative and summative evaluations
of IEP Advisor. Formative evaluations involved an expert
panel who guided the development of the system through
three phases: product definition, product design, and
prototype development. Results from the formative
evaluations provided evidence of the content validity of
the system.
During summative evaluations of IEP Advisor, the
researcher studied the reliability and validity of
system reports generated through the use of IEP Advisor.
To estimate the reliability of information in reports,
the researcher compared conclusions generated by IEP
Advisor when different users examined the same student
record. Results indicated moderate and statistically
significant levels of interuser agreement.
To estimate the validity of IEP Advisor, the researcher
compared reports generated through the use of IEP
Advisor with reports generated by local personnel
recognized for their skill in IEP development. The users
of IEP Advisor were, by their own admission, naive about
how to evaluate IEPs. Both groups based their reports on
the same set of simulated student records. The reports
from both groups were given to an expert panel that was
blind to the source of the reports. Expert panel members
were asked to rank order the reports from best to worst.
The results indicated wide variation in the opinions of
expert panel members on which reports contained the best
information. Despite the variation, the analysis of phi
coefficients comparing the source of the reports (IEP
Advisor user vs. expert) to their ranking (high vs. low)
revealed that reports generated by IEP Advisor were
consistently ranked as good as or better than reports
produced by locally recognized experts.
Recommendations for future research included:
simplifying the judgments required by users, updating
the knowledge base, dividing the expert system into
several smaller systems, and additional studies of
system validity.
</ABSTRACT>
</THESIS>
<THESIS>
<NUMBER> 4315 </NUMBER>
<ORDER>   AAG9401710 </ORDER>
<TITLE>   A KNOWLEDGE-BASED SUPPORT SYSTEM FOR PROBLEM DIAGNOSIS IN INFORMATION SYSTEMS </TITLE>
<AUTHOR>   SURESH, BANGALORE ANATHASWAMI RAO </AUTHOR>
<YEAR>   1993 </YEAR>
<INSTITUTION>   SYRACUSE UNIVERSITY; 0659 </INSTITUTION>
<DESCRIPTORS>   BUSINESS ADMINISTRATION, MANAGEMENT; COMPUTER SCIENCE; ARTIFICIAL INTELLIGENCE; INFORMATION SCIENCE </DESCRIPTORS>
<ADVISER>   MOHAN TANNIRU </ADVISER>
<CLASSIFICATIONS>   NIL </CLASSIFICATIONS>
<ABSTRACT>
Problem diagnosis is an important part of systems
analysis, but its treatment in IS literature is somewhat
adhoc and limited. Very few methodologies for
structuring this problem diagnosis task were discussed
and no tool support exists for this task in many CASE
environments today, even though there is some consensus
on what constitutes such a task. Prior research
characterizes this task in terms that closely parallel
medical diagnosis, specifically in the way a problem is
modeled, data synthesized and problem structured. In
this research, medical diagnostic systems were studied
to understand these parallels, certain methodologies
used in this discipline were modified to fit the
information systems domain, and a knowledge based system
that captures this underlying reasoning process was
built using a frame based representation in KEE. Its
flexibility and generalizability was illustrated by its
application to two different case situations, and a
qualitative validation was performed by a panel of
experienced systems analysts. The results demonstrate
that the embedded reasoning process used in the
knowledge based system has face, content and construct
validity. It also has features that will make it
effective in assisting systems analysts in a new domain
by providing them with relevant organizational knowledge
and training new systems analysts to the diagnostic
task.
</ABSTRACT>
</THESIS>
<THESIS>
<NUMBER> 4316 </NUMBER>
<ORDER>   AAG9401702 </ORDER>
<TITLE>   A STUDY OF NEURAL NETWORK CONSTRUCTION AND ITS APPLICATION TO STATISTICAL FORECASTING </TITLE>
<AUTHOR>   PARK, YOUNG RYONG </AUTHOR>
<YEAR>   1993 </YEAR>
<INSTITUTION>   SYRACUSE UNIVERSITY; 0659 </INSTITUTION>
<DESCRIPTORS>   BUSINESS ADMINISTRATION, MANAGEMENT; ARTIFICIAL INTELLIGENCE; STATISTICS </DESCRIPTORS>
<ADVISER>   THOMAS J. MURRAY </ADVISER>
<CLASSIFICATIONS>   NIL </CLASSIFICATIONS>
<ABSTRACT>
Interest in neural networks has expanded rapidly in
recent years. Neural networks, which are inspired by
biological systems, consist of a set of elementary
processing units which operate in parallel. Parallel
processing appears to provide a powerful and practical
approach to overcome the limitations in the speed of a
single processor.
In addition to parallelism, a characteristic of neural
networks is their inherent learning capability, i.e.,
the ability to adapt behavior based on observations.
Learning is usually seen as an important element of an
"artificially intelligent" system.
The objectives of this study are: first, to develop a
formal procedure for determining the structure of a
neural network. Despite many studies in this area, few
studies have attempted to build the structure of the
network formally. The procedure provides users with an
automated way to build a neural network model for a
given task. A principal component analysis method is
proposed to determine the optimal internal structure of
a neural network model.
Second, unlike most other studies which empirically
compare forecasting power from neural network models
with those from other statistical methods, this study
reviews the relationship between the neural network
approach and other statistical methods, and investigates
conditions which make the neural approach superior.
Simulated and empirical data are investigated to examine
the conditions. Five conditions are examined under
simulated data. Also, 3 additional empirical series are
analyzed to examine the claims made in this study.
Eventually, those results found in this study will
provide users with guidelines for the neural approach to
be used successfully.
</ABSTRACT>
</THESIS>
<THESIS>
<NUMBER> 4317 </NUMBER>
<ORDER>   AAG9400617 </ORDER>
<TITLE>   RECOGNIZING MELODIC MOTION IN MUSICAL SCORES: RULES AND CONTEXTS. </TITLE>
<AUTHOR>   DEMSKE, THOMAS RICHARD </AUTHOR>
<YEAR>   1993 </YEAR>
<INSTITUTION>   YALE UNIVERSITY; 0265 </INSTITUTION>
<DESCRIPTORS>   EDUCATION, MUSIC; MUSIC; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER>   NIL </ADVISER>
<CLASSIFICATIONS>   VOLUMES I AND II) (COMPUTERS </CLASSIFICATIONS>
<ABSTRACT>
This study describes a computer-implemented formal
system for recognizing surface melodic activity in piano
score excerpts. The system has two components: a set of
rules for determining which, if either, of a pair of
melodic connections is stronger than the other and an
algorithm for applying the rules to select only
preferred connections. The rules derive from a small,
initial set, which was tested against scores, revised,
and tested again until achieving acceptable results. The
algorithm merges the rules' disjunct, pairwise
distinctions into a more meaningful whole, whereby some
melodic connections may be seen as more salient than
others within the given musical context. The algorithm
tolerates dissent among rules, meaning that rules may
misfire on occasion without skewing the final results.
Theoretical issues of musical context are engaged
empirically at the note level, with general implications
for theories of melody and voice leading. The study also
exposes in a rigorous setting some of the myriad details
which ultimately inform our interpretation of scores,
and yet which are rarely considered explicitly in
analysis. Finally, the study formally casts the process
of listening as a complex, continually evolving dynamic
among competing determinants of melodic activity.
</ABSTRACT>
</THESIS>
<THESIS>
<NUMBER> 4318 </NUMBER>
<ORDER>   AAG9322542 </ORDER>
<TITLE>   MUSICAL RULES: A KNOWLEDGE-BASED SIMULATION OF AN IMPLICATION-REALIZATION MODEL </TITLE>
<AUTHOR>   MCGEE, DERON L. </AUTHOR>
<YEAR>   1993 </YEAR>
<INSTITUTION>   THE UNIVERSITY OF WISCONSIN - MADISON; 0262 </INSTITUTION>
<DESCRIPTORS>   MUSIC; ARTIFICIAL INTELLIGENCE; COMPUTER SCIENCE </DESCRIPTORS>
<ADVISER>   JOHN WM. SCHAFFER </ADVISER>
<CLASSIFICATIONS>   COMPUTERS, NARMOUR EUGENE </CLASSIFICATIONS>
<ABSTRACT>
Eugene Narmour's recent implication-realization theory
for analyzing melodies provides an interesting
integration of established concepts from previous work
in music and cognitive psychology. Narmour proposes a
diachronic theory that represents the "note-to-
note" syntax of a melody and the underlying mental
processes that essentially establish the syntax. While
Narmour's theory represents an interesting effort to
integrate concepts from distinct fields into a coherent
theory of melodic implication, it is fraught with
inconsistencies and ambiguities, as is often the case
with a new, complex work. Fortunately, the structure of
the theory suggests a method for investigating and
refining it based on developments in artificial
intelligence.
"Knowledge-based programming," referring to
computer programs that encode and use human knowledge to
solve problems, is an outgrowth of artificial
intelligence research. Specific knowledge is often
stored in the form of "rules," which a
computer uses to logically deduce solutions to a
problem, resembling human reasoning. A computer program
can be written to simulate a music theory by encoding
the knowledge required to create plausible analyses with
the theory and encoding the process by which those rules
are applied to pieces of music (the analytical process).
There are essentially two coequal goals for this
project. The first goal is to present the simulation of
music theories by computer as a methodological process
for their investigation. The second goal is to critique
Eugene Narmour's The Analysis and Cognition of Basic
Melodic Structures (1990) and The Analysis and Cognition
of Melodic Complexity (1992) based on the experience
gained through constructing a knowledge-based computer
simulation of his "bottom-up syntactic
primitives." The analyses generated by the
simulation, combined with the experience gained through
building the simulation, serve as a basis for evaluating
and reformulating the theory. During the process of
building a computer simulation, many of the incomplete,
ambiguous, and undefined portions of the theory must be
codified in order to make the simulation operate in a
manner analogous to an analyst. The resulting
"knowledge-based computer simulation" may
express in more complete terms many of the complexities
prevalent in the theory.
</ABSTRACT>
</THESIS>
<THESIS>
<NUMBER> 4319 </NUMBER>
<ORDER>   AAG9400830 </ORDER>
<TITLE>   FUZZY SETS IN SELF-GENERATING NEURAL NETWORK ARCHITECTURES </TITLE>
<AUTHOR>   SZTANDERA, LESZEK MAREK </AUTHOR>
<YEAR>   1993 </YEAR>
<INSTITUTION>   THE UNIVERSITY OF TOLEDO; 0232 </INSTITUTION>
<DESCRIPTORS>   ENGINEERING, GENERAL; COMPUTER SCIENCE; ENGINEERING, SYSTEM SCIENCE; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER>   NIL </ADVISER>
<CLASSIFICATIONS>   PATTERN RECOGNITION </CLASSIFICATIONS>
<ABSTRACT>
The purpose of this research is to introduce and operate
on fuzzy sets in neural network architectures. In such
architectures the needed membership functions are
learned from a set of training examples.
The work in this dissertation is divided into two parts.
In the first part, the equivalence between fuzzy and
neural models is discussed. Through this equivalence a
concept of incorporating fuzzy set theory into neural
network architecture is investigated and is acknowledged
as being an extremely powerful and promising technology.
Furthermore, a hybrid fuzzy-neural algorithm (Fuzzy
CID3) for converting fuzzy trees into hidden layers of a
neural network is proposed. It allows self-generation of
a feedforward neural network architecture. The
performance of the new algorithm is evaluated on
difficult, nonlinearly separable data.
In the second part, a comparative study of the ranking
indices of the fuzzy subsets generated by a neural
network algorithm is presented. Through this comparative
study centroidal approach indices are identified as
being the best under given conditions. These indices are
thus recommended for use in a generalized decision
making problems in a fuzzy environment produced by a
neural network architecture. Also, extensions to a
multiclass classifier are presented and analyzed.
</ABSTRACT>
</THESIS>
<THESIS>
<NUMBER> 4320 </NUMBER>
<ORDER>   AAG9400814 </ORDER>
<TITLE>   DESIGN AND IMPLEMENTATION OF AN INTELLIGENT PARALLEL CONTROLLER FOR ADAPTIVE POWER SYSTEM STABILIZERS </TITLE>
<AUTHOR>   BRIHOUM, MOHAMED EL AMINE </AUTHOR>
<YEAR>   1993 </YEAR>
<INSTITUTION>   THE UNIVERSITY OF TOLEDO; 0232 </INSTITUTION>
<DESCRIPTORS>   ENGINEERING, ELECTRONICS AND ELECTRICAL; COMPUTER SCIENCE </DESCRIPTORS>
<ADVISER>   ADEL A. GHANDAKLY </ADVISER>
<CLASSIFICATIONS>   POWER SYSTEM STABILIZERS </CLASSIFICATIONS>
<ABSTRACT>
An on line computer control system for a laboratory
generating unit has been designed for real time
feasibility investigations of adaptive power system
stabilizers. The system has a two level hierarchical
control arrangement in a master (IBM PC system 2 model
80) slave (Intel 80C196 embedded micro controller)
configuration.
All necessary hardware interface and transducers have
been designed and integrated in the overall control
loop. The system software was designed to be time
efficient and user friendly. The communication software
was written in assembly language for both processors. C
language was used for the remainder of control software.
User interaction with the controller has been
implemented in a graphical environment that uses popup
menus which are window oriented to operate the station
effortlessly and with a great deal of flexible
investigation capabilities.
Three self tuning PSS which have been widely accepted on
the basis of their simulation performance were selected
for real time feasibility investigations. Those are the
Single Input, Single Output Minimum Variance, the Multi
Input, Multi Output Generalized Minimum Variance, and
the Parametrically Optimized Controller. The controllers
were first tested by computer simulations under a wide
range of operation and disturbance conditions. They were
then implemented on the laboratory system for real time
investigations.
A novel approach for the design of a feasible adaptive
PSS has also been developed, and investigated. The
proposed stabilizer is based on the newly emerging
parallel control technology, which deals with parallel
processing and artificial intelligence. In the proposed
controller an intelligent decision block performs the
logical and functional parallelization of the two
effective controller designs to achieve desired
performance. The decision block uses the identification
results for key information in the two controller
combination. The two controllers used consist of the
conventional PSS and one of the above mentioned three
self tuning PSS. The proposed intelligent PSS has shown
superior simulation and laboratory performance in
comparison to its original STR counterparts.
</ABSTRACT>
</THESIS>
<THESIS>
<NUMBER> 4321 </NUMBER>
<ORDER>   AAG9400202 </ORDER>
<TITLE>   ORGANIZING RELATIONS IN LARGE KNOWLEDGE BASES </TITLE>
<AUTHOR>   CHEN, YUFENG FRED </AUTHOR>
<YEAR>   1993 </YEAR>
<INSTITUTION>   UNIVERSITY OF SOUTH CAROLINA; 0202 </INSTITUTION>
<DESCRIPTORS>   COMPUTER SCIENCE; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER>   LARRY M. STEPHENS </ADVISER>
<CLASSIFICATIONS>   DISCRIMINATION BASES </CLASSIFICATIONS>
<ABSTRACT>
This dissertation develops a knowledge organization
methodology that supports the classification of
relations, which are implemented by slots in slot-and-
filler structure knowledge bases. Our approach differs
from classifying relations from linguistic and
psychological perspectives because the features of a
representation language differ from those of a natural
language. We consider both the knowledge-level semantics
of relations and the symbol-level function of slots that
implement the representation language. We show how this
approach can be applied to a large-scale, knowledge-
based system (Cyc) to improve knowledge retrieval and
understanding. A slot classification scheme was
developed that recognizes the importance of the
different discrimination bases yet provides a uniform
and principled methodology for slot organization.
</ABSTRACT>
</THESIS>
<THESIS>
<NUMBER> 4322 </NUMBER>
<ORDER>   AAG9335129 </ORDER>
<TITLE>   AN INTEGRATED EXPERT SYSTEM FOR INTERFEROMETRIC IMAGE ANALYSIS </TITLE>
<AUTHOR>   JOO, WONJONG </AUTHOR>
<YEAR>   1993 </YEAR>
<INSTITUTION>   UNIVERSITY OF ILLINOIS AT CHICAGO; 0799 </INSTITUTION>
<DESCRIPTORS>   ENGINEERING, MECHANICAL; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER>   SOYOUNG S. CHA </ADVISER>
<CLASSIFICATIONS>   NIL </CLASSIFICATIONS>
<ABSTRACT>
Interferometry, an optical diagnostic technique which
utilizes the interference property of coherent light,
has made important contributions to accurate and
reliable measurements in heat transfer, fluid mechanics,
deformation studies, and aerodynamics. Its ability to
instantaneously capture gross fields can negate tedious
point-by-point measurements. The nonintrusiveness is of
great value in situations where probe insertion is
impractical because it would alter test object field.
Interferometric methods, however, frequently encounter
various complicated noise problems. The noise effects
coupled with a high fringe density inhibit accurate data
acquisition. The currently available techniques, that
is, fringe tracking, Fourier transform, and phase
shifting methods as well as regression method frequently
confront limitations of application and phase-unwrapping
problems due to noises and thus need substantial manual
interactive correction. Conventional approaches have
depended heavily on local information covered by a small
mask. Complicated fringe patterns, however, need to be
interpreted not by local information but by global and
regional information. In this research, an integrated
expert system shell and a prototype knowledge base for
high-speed aerodynamic interferometric image analysis
has been developed and tested. The developed expert
system utilizes both global and regional information of
fringe patterns and makes use of expert knowledge.
The developed expert system integrates, in a single
package, the low-level processing involving algorithmic
noise reduction and extraction of global/regional
feature values, with the high-level processing for
further noise reduction and phase retrieval based on
knowledge-based global structure examination. It can
thus have the potential to substantially eliminate
operator interaction and be a foundation for an
expandable knowledge-based expert system for automated
fringe analysis. The developed expert system adopts a
fringe tracking method for automatic fringe analysis but
also workable for the phase-shift and Fourier transform
techniques. A new approach of regional phase-unwrapping
by using isophase lines, the result of the high-level
processing, is proposed and partially verified.
</ABSTRACT>
</THESIS>
<THESIS>
<NUMBER> 4323 </NUMBER>
<ORDER>   AAG9334623 </ORDER>
<TITLE>   AN AI APPROACH TO RELATIONAL DATA MODELS FOR UNCERTAIN AND IMPRECISE INFORMATION </TITLE>
<AUTHOR>   LEE, SUK KYOON </AUTHOR>
<YEAR>   1993 </YEAR>
<INSTITUTION>   THE UNIVERSITY OF IOWA; 0096 </INSTITUTION>
<DESCRIPTORS>   COMPUTER SCIENCE; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER>   HANTAO ZHANG </ADVISER>
<CLASSIFICATIONS>   UNCERTAIN INFORMATION </CLASSIFICATIONS>
<ABSTRACT>
Real world information is often imprecise and uncertain.
While uncertainty management has been a central research
issue in the AI community, the database community has
been slow to adapt to this trend. There have been
attempts to use uncertainty calculi developed in AI to
data modeling for incomplete information: data models
based on fuzzy set theory are considered good for data
which are intrinsically lexically imprecise, but
generally it is difficult to justify the usage of fuzzy
membership functions for uncertain information. Data
models based on Bayesian probability theory have well
defined theoretical foundations, but the assumption of
the availability of probability distributions for
uncertain data is unreasonable in many practical
applications. The Dempster-Shafer theory as a
generalization of the Bayesian theory is an attempt to
overcome those weaknesses.
This is the first approach to use the Dempster-Shafer
theory in database applications. The Dempster-Shafer
theory is applied to relational data modeling for
uncertain and imprecise information. Since a basic
probability assignment in the Dempster-Shafer theory,
natural to represent ignorance as well as uncertainty,
is used for the representation of an uncertain attribute
value in a relation. The Bel and Pls functions in the
Dempster-Shafer theory are extended at the tuple level
to define Selection operation as well as Join, Union,
Intersect and Projection. In this model, every tuple in
a relation has a special attribute CL which represents
our belief of the support for the tuple.
We identify two new problems in our model: the potential
existence of identical tuples with different degrees of
belief and the potential existence of conflicting data
from different sources. The former is solved by the
proposed relational algebra. One proposed solution to
the latter is based on Dempster's rule of combination in
the Dempster-Shafer theory, which performs pooling data
from different sources for purpose of making choices
between hypotheses. Dempster's rule is extended to
define the evidential union and projection operations,
for purpose of pooling data from different sources at
the tuple level, and as a means of removing
inconsistency in relations.
</ABSTRACT>
</THESIS>
<THESIS>
<NUMBER> 4324 </NUMBER>
<ORDER>   AAG9334427 </ORDER>
<TITLE>   HETEROGENEOUS INFORMATION INTEGRATION USING AN OBJECT- ORIENTED KNOWLEDGE FRAMEWORK </TITLE>
<AUTHOR>   SULL, WONHEE </AUTHOR>
<YEAR>   1993 </YEAR>
<INSTITUTION>   PURDUE UNIVERSITY; 0183 </INSTITUTION>
<DESCRIPTORS>   ENGINEERING, ELECTRONICS AND ELECTRICAL; COMPUTER SCIENCE; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER>   RANGASAMI L. KASHYAP </ADVISER>
<CLASSIFICATIONS>   INFORMATION INTEGRATION </CLASSIFICATIONS>
<ABSTRACT>
To develop a system that enables intelligent access to,
and integration of, information spread over various
independent information sources is an important issue in
data intensive applications. While typical heterogeneous
database management systems provide only for the
integration of conventional databases, notably
relational databases, we aim at a knowledge framework
which can incorporate existing heterogeneous databases
with nonconventional data types, as found in object-
oriented databases, or rulebases.
In this thesis, we investigate the self-organizing
knowledge representation aspects of the schema
integration involving object-oriented databases,
relational databases, and rulebases. We consider a facet
of self-organizability which sustains the structural
semantic integrity of an integrated schema regardless of
the dynamic nature of local schemata. To achieve this
objective, we propose an overall scheme for schema
translation and schema integration with an object-
oriented data model as common data model, and it is
shown that integrated schemata can be maintained
effortlessly by propagating updates in local schemata to
integrated schemata unambiguously.
As an interface to the integrated system, ODML (Object
Data Manipulation Language) is proposed as the global
query language which is based on the nested relational
data model, and is extended with object-oriented
features and quantificational tags. With these
extensions, schema and data do not have to be
differentiated in formulating queries. In addition, set-
based path expressions can be mixed with singular path
expressions. In decomposing a global query into locally
executable subqueries, an algorithm is presented which
guarantees search of all the relevant objects within the
federation of information systems. This issue has seldom
been considered, but it is important in environments
where heterogeneous objects are integrated using
generalization and aggregation abstraction mechanisms.
It is the case that there are large number of
constraints often associated with data, or object
classes. In this environment, when an integrity
constraint is to be added, or when existing databases
and knowledge bases are integrated, resolving conflicts
among constraints from different information sources are
not well understood even though it is one of the most
important problems in integration. In the first stage,
we identified the necessity of acquiring only those
constraints which are necessary and consistent with
respect to the current knowledge base. Then, an
algorithm is presented to determine whether an incoming
rule is consistent with respect to a target rulebase.
For efficiency, a set of rules relevant to the new rule
is to be collected from the rulebase. For this purpose,
a data structure dependency graph is defined. Also, a
logic theorem proving method is used for classifying the
incoming rule.
</ABSTRACT>
</THESIS>
<THESIS>
<NUMBER> 4325 </NUMBER>
<ORDER>   AAG9334409 </ORDER>
<TITLE>   COOPERATION REQUIREMENT PLANNING FOR MULTI-ROBOT ASSEMBLY CELLS </TITLE>
<AUTHOR>   RAJAN, VENKAT N. </AUTHOR>
<YEAR>   1993 </YEAR>
<INSTITUTION>   PURDUE UNIVERSITY; 0183 </INSTITUTION>
<DESCRIPTORS>   ENGINEERING, INDUSTRIAL; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER>   SHIMON Y. NOF </ADVISER>
<CLASSIFICATIONS>   ROBOTICS </CLASSIFICATIONS>
<ABSTRACT>
Cooperation among machines is deemed an essential
attribute of intelligent manufacturing and assembly
systems. It improves the flexibility and reliability of
such systems. The nature of task cooperation among
machines can be of three types: Mandatory, Optional, and
Concurrent.
Cooperation Requirement Planning (CRP) for multi-robot
assembly cells is divided into two steps: (1) CRP-I
involving the mapping of geometric, physical, and
operational information of an assembly to the
corresponding capabilities of the robots, and generating
assembly, robot and cell constraints, and (2) CRP-II
involving the assignment of tasks to single robots and
multi-robot sets based on their capabilities, and
generating a consistent and coordinated global plan.
CRP is an integrated assembly and cooperation task
planning methodology that provides greater planning
flexibility than that achieved by performing assembly
and task planning independently. A prototype
implementation of the CRP I methodology has been
developed using the ROBCAD$sp{rm TM}$Open Systems
Environment on a Silicon Graphics IRIS 4D/80GT graphics
workstation.
</ABSTRACT>
</THESIS>
<THESIS>
<NUMBER> 4326 </NUMBER>
<ORDER>   AAG9334384 </ORDER>
<TITLE>   A DISTRIBUTED PRODUCTION CONTROL FOR INTELLIGENT MANUFACTURING SYSTEMS </TITLE>
<AUTHOR>   LIN, GRACE YUH-JIUN </AUTHOR>
<YEAR>   1993 </YEAR>
<INSTITUTION>   PURDUE UNIVERSITY; 0183 </INSTITUTION>
<DESCRIPTORS>   ENGINEERING, INDUSTRIAL; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER>   JAMES SOLBERG </ADVISER>
<CLASSIFICATIONS>   MANUFACTURING </CLASSIFICATIONS>
<ABSTRACT>
Global competition and advances in technologies have
resulted in some fundamental changes in the
manufacturing environment. The fast rate of change is
increasing without any pause in sight. A practical
control/scheduling strategy which can handle complexity,
cope with the changing environment, and accommodate
changing multi-objectives with the aid of advanced
production technologies and facilities is worth
exploring.
In this thesis, we present a production control
framework that utilizes distributed decision making and
distributed information flow and is based on a price and
objective mechanism. The framework supports
heterogeneous job objectives, admits job priorities,
recognizes multiple resource types, and allows multiple
step negotiation between parts and resources. Under the
framework, each job enters the system with some currency
and tries to fulfill its processing requirements to meet
its objectives by actively bargaining with resources to
purchase processing services. On the other hand,
resources determine their service charge based on
demands and try to sell their services to maximize their
profit. In this way, the complicated coherent
manufacturing control problem is decomposed into a
collection of independent agents' decision-making
problems. The global states and entity interactions are
reflected and controlled by a price system.
In order to ensure harmonious and effective operation,
price adjustment among different resources and parts
needs to be handled with care. This issue is addressed
through the presentation of different distributed
control schemes: a part-initiated negotiation scheme, a
resource-initiated negotiation scheme, a multiple-
reservation negotiation for both part-initiated and
resource-initiated schemes, and a bottleneck centered,
look-ahead negotiation scheme.
A Flexible Routing Adaptive Simulation System has been
built to demonstrate the flexibility and effectiveness
of the proposed framework. The performance of different
control strategies is analyzed and compared. The results
show that the proposed frame-work provides a foundation
for highly adaptive production control, and the price
system provides a mechanism for system state monitoring
in a distributed environment.
</ABSTRACT>
</THESIS>
<THESIS>
<NUMBER> 4327 </NUMBER>
<ORDER>   AAG9334343 </ORDER>
<TITLE>   A FARMSTEAD DRINKING WATER QUALITY DECISION SUPPORT SYSTEM </TITLE>
<AUTHOR>   EMBLETON, KARLA MARIE </AUTHOR>
<YEAR>   1993 </YEAR>
<INSTITUTION>   PURDUE UNIVERSITY; 0183 </INSTITUTION>
<DESCRIPTORS>   ENGINEERING, AGRICULTURAL; ARTIFICIAL INTELLIGENCE; ENVIRONMENTAL SCIENCES </DESCRIPTORS>
<ADVISER>   BERNARD A. ENGEL </ADVISER>
<CLASSIFICATIONS>   NIL </CLASSIFICATIONS>
<ABSTRACT>
A prototype decision support system (DSS) has been
developed to provide educational and analytical services
in the area of private well drinking water quality. As
most private wells are located on farmsteads, this DSS
focuses on rural water quality issues. Educational and
analytical services are provided through a combination
of expert system and hypertext programming techniques.
This combination was selected to improve the ability of
the system to meet varying end user knowledge levels and
information needs.
The DSS has a modular format. Prototyping has focused on
the definition of the DSS structure and the development
of program modules for inclusion within the analytical
section. Eleven risk assessment modules and one
educational module were developed. Ten of the risk
assessments predict future risk of water contamination
from specific sources common to farmsteads. The eleventh
diagnoses current water pollutants on the basis of local
activities and sensory clues of contamination. The
educational module has a tutorial format.
Initial evaluation of the DSS consisted of a risk
assessment effectiveness test and a user appeal survey.
Tests were conducted using the pesticide storage and
handling risk assessment program from the DSS and
worksheet #2 from the Farm-A-Syst package. Forty seven
extension agents, farmers, and students analyzed two
test case farms using these assessment tools. Their
results were compared to average risk ratings assigned
to the test cases by of a panel of ten experts. There
was no significant variation in results between
participant groups. Differences arose due to the
assessment tool used. Program results varied less often
from the experts' than did worksheet results. When
differences arose, the program more often over estimated
risk in comparison to the experts rating than did the
worksheet.
Participants found the program easier to use and had
higher confidence in the results obtained with this tool
than with the worksheet. All participants felt the
program to be better suited for educational purposes.
Farmers and extension agents felt the worksheet was a
better tool for "real life" risk assessments
while the students slightly favored the program.
</ABSTRACT>
</THESIS>
<THESIS>
<NUMBER> 4328 </NUMBER>
<ORDER>   AAG9334018 </ORDER>
<TITLE>   GENERATING HIGH-LEVEL STRUCTURE FOR EXTENDED EXPLANATIONS. </TITLE>
<AUTHOR>   MOONEY, DAVID JACK </AUTHOR>
<YEAR>   1993 </YEAR>
<INSTITUTION>   UNIVERSITY OF DELAWARE; 0060 </INSTITUTION>
<DESCRIPTORS>   COMPUTER SCIENCE; LANGUAGE, LINGUISTICS; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER>   M. SANDRA CARBERRY; KATHLEEN F. MCCOY </ADVISER>
<CLASSIFICATIONS>   VOLUMES I AND II) (EXPLANATION, NATURAL LANGUAGE </CLASSIFICATIONS>
<ABSTRACT>
This dissertation analyzes the high-level features of
naturally-occurring, extended explanations of a
narrative/descriptive nature. Some of these features are
independent of the rhetorical relations that conjoin the
segments of a cohesively structured text. Others suggest
that text structure is not completely recursive as has
been claimed. These features have been incorporated into
the Basic Block Model, a theory that describes the
characteristics of good high-level structure for formal,
extended explanations. This theory contends that good
expository high-level structure consists of primary
segments of text that are structured about coordinate
themes that represent various aspects of a single, all-
inclusive organizational scheme. The explanation should
be relatively well-balanced, with each primary segment
approximating a "preferred" size. These
characteristics are dependent on the particular body of
information to be presented.
This dissertation contends that the recursive strategies
that are popularly employed for explanation generation
cannot guarantee high-level structure that meets the
criteria of the Basic Block Model. In these popular
approaches, high-level structure is a side effect of
independent strategies concerned solely with local text
organization as determined by rhetorical means; they are
incapable of taking into consideration any global
characteristics that may be inherent in the body of
material to be conveyed. Rather, good high-level
structure can only be insured if it is actively pursued
as a goal in itself, using the inherent characteristics
of the material to guide the process.
A computational strategy is then presented for
incrementally generating extended explanations whose
high-level structure captures the features that are
advocated by the Basic Block Model. This strategy is
based on the hypothesis that good high-level structure
is best determined by bottom-up processes that attempt
to satisfy speaker, listener, and structural goals,
after which top-down strategies can be used to organize
the material within the established framework. This
strategy has been implemented in the EEG, a system for
generating extended explanations in an interactive
environment.
</ABSTRACT>
</THESIS>
<THESIS>
<NUMBER> 4329 </NUMBER>
<ORDER>   AAG9333832 </ORDER>
<TITLE>   LOW-NOISE CMOS CIRCUITS FOR ON-CHIP SIGNAL PROCESSING IN FOCAL-PLANE ARRAYS </TITLE>
<AUTHOR>   PAIN, BEDABRATA </AUTHOR>
<YEAR>   1993 </YEAR>
<INSTITUTION>   COLUMBIA UNIVERSITY; 0054 </INSTITUTION>
<DESCRIPTORS>   ENGINEERING, ELECTRONICS AND ELECTRICAL; PHYSICS, SOLID STATE; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER>   ERIC R. FOSSUM </ADVISER>
<CLASSIFICATIONS>   SIGNAL PROCESSING, NEURAL NETWORK </CLASSIFICATIONS>
<ABSTRACT>
The performance of focal-plane arrays can be
significantly enhanced through the use of on-chip signal
processing. Novel, in-pixel, on-focal-plane, analog
signal-processing circuits for high-performance imaging
are presented in this thesis.
The presence of a high background-radiation is a major
impediment for infrared focal-plane array design. An in-
pixel, background-suppression scheme, using dynamic
analog current memory circuit, is described. The scheme
also suppresses spatial noise that results from response
non-uniformities of photo-detectors, leading to
background limited infrared detector readout
performance.
Two new, low-power, compact, current memory circuits,
optimized for operation at ultra-low current levels
required in infrared-detection, are presented. The first
one is a self-cascading current memory that increases
the output impedance, and the second one is a novel,
switch feed-through reducing current memory, implemented
using error-current feedback. This circuit can operate
with a residual absolute-error of less than 0.1%. The
storage-time of the memory is long enough to also find
applications in neural network circuits. In addition, a
voltage-mode, accurate, low-offset, low-power, high-
uniformity, random-access sample-and-hold cell,
implemented using a CCD with feedback, is also presented
for use in background-suppression and neural network
applications.
A new, low noise, ultra-low level signal readout
technique, implemented by individually counting photo-
electrons within the detection pixel, is presented. The
output of each unit-cell is a digital word corresponding
to the intensity of the photon flux, and the readout is
noise free. This technique requires the use of unit-cell
amplifiers that feature ultra-high-gain, low-power, self-
biasing capability and noise in sub-electron levels.
Both single-input and differential-input implementations
of such amplifiers are investigated.
A noise analysis technique is presented for analyzing
sampled-data systems having 1/f noise reduction
capability. Closed form expressions have been derived
and low-noise design criteria have been established,
taking into account both the 1/f and white noise, and
the effects of under-sampling. The analysis technique
will be an important tool for analysis and design of a
large variety of focal-plane sampled-data signal
processing circuits.
</ABSTRACT>
</THESIS>
<THESIS>
<NUMBER> 4330 </NUMBER>
<ORDER>   AAG9333756 </ORDER>
<TITLE>   USING ARGUMENTATION TO CONTROL LEXICAL CHOICE: A FUNCTIONAL UNIFICATION IMPLEMENTATION </TITLE>
<AUTHOR>   ELHADAD, MICHAEL </AUTHOR>
<YEAR>   1993 </YEAR>
<INSTITUTION>   COLUMBIA UNIVERSITY; 0054 </INSTITUTION>
<DESCRIPTORS>   COMPUTER SCIENCE; LANGUAGE, LINGUISTICS; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER>   KATHLEEN R. MCKEOWN </ADVISER>
<CLASSIFICATIONS>   NIL </CLASSIFICATIONS>
<ABSTRACT>
This thesis presents new surface generation techniques
that improve on both aspects of surface generation: (1)
lexical choice, which consists of choosing words and
their associated syntactic structures and (2) syntactic
realization, which consists of combining these partial
structures into grammatical sentences. The thesis
investigates the impact of the pragmatic situation on
surface generation. Because surface generation depends
directly on many aspects of the situation, these new
techniques allow a purely conceptual input to be
expressed by a greater variety of linguistic forms and
with more sensitivity to pragmatic factors than was
previously possible.
Specifically, this research focuses on the impact on
lexical choice of one part of the pragmatic situation:
the speaker's argumentative intent, i.e., the goal of
the speaker to convince the hearer of a certain
conclusion. The argumentative intent can be realized by
a variety of evaluative expressions appearing at various
ranks in the syntactic structure. This thesis describes
the selection of four classes of evaluative expressions:
judgment determiners (i.e., many), scalar adjectives
(i.e., difficult), connotative verbs (i.e., require,
enjoy) and argumentative connectives (i.e., but, so).
These four classes were not addressed in previous
generators.
The scFUF formalism is introduced in this thesis to
address the issue of complex constraint interaction
arising when performing lexical choice under pragmatic
constraints. scFUF is derived from Functional
Unification Grammars (scFUGs), a formalism previously
used for syntactic realization only. scFUF extends
scFUGs by providing new mechanisms for control, for
expressing hierarchical relations and for using modular
knowledge sources. These extensions make scFUF capable
of handling lexical choice. In addition, this thesis
describes the use of scFUF to develop scSURGE, one of
the largest and most widely used syntactic realization
grammar available.
Finally these new generation techniques are applied to
the implementation of scADVISOR II, a question-answering
system helping students to choose classes for a
semester. In particular, scADVISOR II uses the increased
expressive flexibility provided by these techniques to
convince a student to choose different classes by
presenting the same objective data, retrieved from an
underlying knowledge base, in different linguistic forms
using evaluative expressions.
</ABSTRACT>
</THESIS>
<THESIS>
<NUMBER> 4331 </NUMBER>
<ORDER>   AAG9333440 </ORDER>
<TITLE>   TRANSFERRING PREVIOUSLY LEARNED BACK-PROPAGATION NEURAL NETWORKS TO NEW LEARNING TASKS </TITLE>
<AUTHOR>   PRATT, LORIEN YEOMANS </AUTHOR>
<YEAR>   1993 </YEAR>
<INSTITUTION>   RUTGERS THE STATE UNIVERSITY OF NEW JERSEY - NEW BRUNSWICK; 0190 </INSTITUTION>
<DESCRIPTORS>   COMPUTER SCIENCE; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER>   JACK MOSTOW; HAYM HIRSH </ADVISER>
<CLASSIFICATIONS>   NEURAL NETWORKS </CLASSIFICATIONS>
<ABSTRACT>
When people learn a new task, they often build on their
ability to solve related problems. For example, a doctor
moving to a new country can use prior experience to aid
in diagnosing patients. A chess player can use
experience with one set of end-games to aid in solving a
different, but related, set.
However, although people are able to perform this sort
of skill transfer between tasks, most neural network
training methods in use today are unable to build on
their prior experience. Instead, every new task must be
learned from scratch.
This dissertation explores how a back-propagation neural
network learner can build on its previous experience. We
present an algorithm, called Discriminability-Based
Transfer (DBT), that facilitates the transfer of
information from the learned weights of one network to
the initial weights of another. Through evaluation of
DBT on several benchmark tasks we demonstrate that it
can speed up learning on a new task. We also show that
DBT is more reliable than simpler methods for transfer.
</ABSTRACT>
</THESIS>
<THESIS>
<NUMBER> 4332 </NUMBER>
<ORDER>   AAG9333343 </ORDER>
<TITLE>   PART SELECTION FOR PREDEFINED CONFIGURATIONS USING GENETIC SEARCH BASED ALGORITHMS </TITLE>
<AUTHOR>   HWANG, KUO-YEN </AUTHOR>
<YEAR>   1993 </YEAR>
<INSTITUTION>   THE UNIVERSITY OF UTAH; 0240 </INSTITUTION>
<DESCRIPTORS>   ENGINEERING, MECHANICAL; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER>   DON R. BROWN </ADVISER>
<CLASSIFICATIONS>   NIL </CLASSIFICATIONS>
<ABSTRACT>
Part selection from parts catalogs for predefined
configurations of mechanical mechanisms requires
searching large inventories and is a time consuming
problem. Traditional numerical optimization methods are
not practical for this type of problem because they tend
to become trapped in local extrema and are very
sensitive to the starting point they are given. This
dissertation points out that genetic-search-based
techniques can be used to create feasible alternatives.
This work discovered that a search technique based on
genetic search to supply starting points can solve a
variety of discrete and continuous problems.
A black box method was designed to simulate catalog
selection in order to compare genetic algorithm (GA)
with other search methods. To converge to within 3% of
the optimum solution, GA is much faster than Branch-
bound search or random search. For searching a space
with 10$sp8$ items, GA reduces CPU time for the Branch-
bound method from 230 minutes to 25 minutes and reduces
the number of generations over a random search from
22000 to 40.
Starting point search (SPS), a hybrid method that
combines numerical methods and GA, was designed and
proved to outperform GA by 5 to 10%. A few examples are
presented in this dissertation including continuous
problems, discrete problems and combination problems.
SPS can even find out the exact solution in the gear-
drive problem. The airtank problem, which is hard to
solve through gradient method, is easily solved using
SPS.
A graphical user interface prototype was designed in
conjunction with this dissertation to allow designers to
use the catalog selection package more easily and to
reduce their time of design.
</ABSTRACT>
</THESIS>
<THESIS>
<NUMBER> 4333 </NUMBER>
<ORDER>   AAG9333172 </ORDER>
<TITLE>   INTEGRATING FUNCTIONAL, LOGIC, AND OBJECT-ORIENTED PROGRAMMING LANGUAGE PARADIGMS WITH APPLICATION TO DEDUCTIVE DATABASES </TITLE>
<AUTHOR>   BAYRAM, ZEKI OGUZ </AUTHOR>
<YEAR>   1993 </YEAR>
<INSTITUTION>   UNIVERSITY OF ALABAMA AT BIRMINGHAM; 0005 </INSTITUTION>
<DESCRIPTORS>   COMPUTER SCIENCE; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER>   BARRETT R. BRYANT </ADVISER>
<CLASSIFICATIONS>   FUNCTIONAL PROGRAMMING LANGUAGE, LOGIC PROGRAMMING LANGUAGE </CLASSIFICATIONS>
<ABSTRACT>
This dissertation is about the ultimate integration of
the functional, logic and object-oriented programming
language paradigms and the application of such a
combined framework to the area of object-oriented
deductive databases. The significance of such an
integration is that it permits declarative, symbolic
manipulation of complex objects, a major step in the
advancement of software engineering.
Towards that goal, we first describe a higher order
functional/logic language, ROSE, that is implemented in
the Prolog language. Programs of ROSE consist of
conditional rewrite rules with optional committing
guards. The operational semantics of ROSE is conditional
narrowing and e-unification, augmented to deal with
committing guards. Committing guards, combined with non-
determinism in rewrite rules, give the programmer extra-
logical control over the execution of programs in a
sequential environment. A consequence of this is the
possibility of defining the not function which
implements the negation as finite failure rule in the
context of functional/logic programming.
DataFunLog (DFL for short) is a deductive database model
that adapts functional/logic programming to the area of
databases. A DFL database is defined by a set of
conditional rewrite rules. DFL subsumes the logic and
functional data models. One major achievement in DFL is
the development of a query evaluation algorithm that
terminates even if the rules defining the database are
non-terminating.
We then describe FLOOP, a language integrating
functional, logic and object-oriented programming
language paradigms. Programs of FLOOP consist of
conditional rewrite rules, augmented to permit object-
expressions to appear in the place of constants. The
operational semantics is e-unification through
transformations, and calls to an underlying object-
expression evaluator. FLOOP, which is implemented in
Smalltalk, achieves the ultimate integration of the
three paradigms we mentioned above.
Next, we describe an object-oriented database system,
Next Generation Opal (NGO), implemented in Smalltalk,
which, in combination with FLOOP, results in an object-
oriented deductive database model with object-oriented
deduction. In this database model, inter-object
relationships are described using conditional rewrite
rules and queries are posed declaratively in the form of
equations to be solved.
</ABSTRACT>
</THESIS>
<THESIS>
<NUMBER> 4334 </NUMBER>
<ORDER>   AAG9333050 </ORDER>
<TITLE>   THE REPRESENTATION OF UNCERTAINTY IN EXPERT SYSTEMS: AN APPLICATION IN CRIMINAL INVESTIGATION </TITLE>
<AUTHOR>   FORST, BRIAN </AUTHOR>
<YEAR>   1993 </YEAR>
<INSTITUTION>   THE GEORGE WASHINGTON UNIVERSITY; 0075 </INSTITUTION>
<DESCRIPTORS>   COMPUTER SCIENCE; SOCIOLOGY, CRIMINOLOGY AND PENOLOGY; OPERATIONS RESEARCH; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER>   PETER B. VAILL </ADVISER>
<CLASSIFICATIONS>   BAYESIAN </CLASSIFICATIONS>
<ABSTRACT>
Expert systems are frequently used as
"advisors" in complex decision problems
involving uncertainty. Of considerable importance, both
theoretical and practical, is the question: How should
uncertainty be represented in these systems? Formal
probability theory provides a rigorous foundation for
the symbolic representation of uncertainty in expert
systems, but the demands imposed by that theory are
often felt to be too great in real-world applications.
This dissertation compares formal probability theory
with alternative methods, focusing on the strengths and
weaknesses of each method. It then assesses each method
in a particular problem domain--criminal investigation.
The aims of the research are to: (1) survey the
principal methods for representing uncertainty in expert
systems, examining the strengths and weaknesses of each
method; (2) develop a model of decision making under
uncertainty in the domain of criminal investigation; (3)
examine how alternative representations of uncertainty
affect system outputs in that domain; and (4) consider
opportunities for improved decision making through a
more principled selection among alternative systems for
representing uncertainty in expert systems.
Theoretical issues. The inquiry begins with a review of
the literature on uncertainty and its symbolic
representation in formal probability theory. Alternative
representations are described: the subjectivist and
frequentist interpretations of probability, the Bayesian
decision framework, the Buchanan-Shortliffe certainty
factor system, the Dempster-Shafer belief theory, and
Zadeh's fuzzy logic. The case of criminal investigation,
an archetypical decision problem under uncertainty, is
used to ground the discussion of how such systems might
be applied in a real problem domain. A model of criminal
investigation is formulated with decision rules for
efficient investigative procedure.
Empirical issues. The empirical analysis simulates tens
of thousands of parameter structures and hundreds of
thousands of cases under specific structures to assess
the accuracy with which each method of representing
uncertainty estimates an offender attribute under
various conditions: as the simple probability of an
attribute approaches 0.5; as conditional probabilities
vary; when relevant factors are conditionally
independent; when evidence factors are mutually
confirming and when mutually conflicting; and when
attributes of interest are related to one other. The
assessments are based on the mean square error and mean
absolute error criteria. The Bayesian weights are found
to be slightly, but systematically, more accurate than
the weights produced by three different certainty factor
methods under most parameter structures. The work
concludes with a discussion of implications of the
findings and an agenda for further research.
</ABSTRACT>
</THESIS>
<THESIS>
<NUMBER> 4335 </NUMBER>
<ORDER>   AAG9332974 </ORDER>
<TITLE>   ROBUST POLYNOMIAL ALGORITHMS FOR DESIGNING LOCALLY TUNED NEURAL NETS FOR FUNCTION APPROXIMATION AND PATTERN CLASSIFICATION </TITLE>
<AUTHOR>   GOVIL, SANDEEP </AUTHOR>
<YEAR>   1993 </YEAR>
<INSTITUTION>   ARIZONA STATE UNIVERSITY; 0010 </INSTITUTION>
<DESCRIPTORS>   OPERATIONS RESEARCH; COMPUTER SCIENCE; STATISTICS; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER>   A. ROY </ADVISER>
<CLASSIFICATIONS>   NIL </CLASSIFICATIONS>
<ABSTRACT>
This research presents new algorithms for generating
radial basis function neural networks. Truncated
gaussian functions are used as kernel functions to
provide locally tuned non-linearities in the hidden
layer of the networks. Robustness and efficiency of the
algorithms are empirically established. A neural network
based learning method should be able to both design and
train a network appropriate to the task. The algorithms
presented here use a statistics based heuristic scheme
to design the networks and then use linear programming
models to train the networks. Polynomial time complexity
of the method is proven and computational results are
provided for prediction of chaotic systems, prediction
of noisy business time series, neuro-control
applications, and pattern classification in varied
domains of applications. Variations of the algorithm
including more adaptive implementations are discussed.
</ABSTRACT>
</THESIS>
<THESIS>
<NUMBER> 4336 </NUMBER>
<ORDER>   AAG9332942 </ORDER>
<TITLE>   A STANDARD SIMULATION-KNOWLEDGE INTERFACE </TITLE>
<AUTHOR>   RUSSELL, CAROL SCHULER </AUTHOR>
<YEAR>   1993 </YEAR>
<INSTITUTION>   UNIVERSITY OF LOUISVILLE; 0110 </INSTITUTION>
<DESCRIPTORS>   COMPUTER SCIENCE; ENGINEERING, SYSTEM SCIENCE; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER>   JAMES H. GRAHAM; ADEL S. ELMAGHRABY </ADVISER>
<CLASSIFICATIONS>   FACTORY SCHEDULING, REASONING SYSTEMS </CLASSIFICATIONS>
<ABSTRACT>
A formal model for a standard simulation-knowledge
interface (SSKI) is proposed which provides the logical
model for interaction between a simulation and an
intelligent agent. The interface formalism consists of
set-theoretic definitions for both the simulation and
manager as well as a set-theoretic definition of the
interface itself.
Simulations are defined in terms of their observable
attributes and outputs. It is shown that the simplified
simulation definition is consistent with standard
simulation models. Similarly, the definition for the
intelligent agent in terms of its predicate and rule
sets is shown to be consistent with most reasoning
systems.
The interface definition extracts those elements from
both the simulation and the manager models which are
essential to the decision-making process. Those elements
consist of the set of variables supplied by the
simulation, the set of predicates and the set of
possible conclusions generated the manager, a calling
function and a responding function. The time-base of the
simulation is also included to provide a means to
synchronize the interaction between the modules.
The design advantages of providing such an interface are
discussed and illustrated with an analysis of a factory
scheduling problem. The system devised for the factory
problem demonstrates the concepts of modular design, use
of language of best fit, incremental development,
component reuse and component interchange for a
simulation written in the simulation language SIMSCRIPT
II.5 and an intelligent manager written in the
artificial intelligence language CLIPS.
The communication overhead of the proposed interface is
also discussed. This overhead can be contained by using
various techniques for reducing the frequency of
interaction between the simulation and its manager and
for reducing the volume of information to be
communicated. These techniques include decision-point
analysis, decision-criteria analysis and the use of low-
level decision-making within the simulation. The effects
of these reduction techniques are shown in the context
of the factory scheduling problem. These techniques are
then applied to a supermarket management problem to
illustrate the advantages of the interface model in
designing a simulation/manager system.
</ABSTRACT>
</THESIS>
<THESIS>
<NUMBER> 4337 </NUMBER>
<ORDER>   AAG9332657 </ORDER>
<TITLE>   ROBUST CONTROL OF A LINEAR SYSTEM WITH PLANT UNCERTAINTIES USING AN ARTIFICIAL NEURAL NETWORK </TITLE>
<AUTHOR>   YOO, KISUCK </AUTHOR>
<YEAR>   1993 </YEAR>
<INSTITUTION>   FLORIDA INSTITUTE OF TECHNOLOGY; 0473 </INSTITUTION>
<DESCRIPTORS>   ENGINEERING, ELECTRONICS AND ELECTRICAL; ENGINEERING, MECHANICAL; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER>   M. H. THURSBY </ADVISER>
<CLASSIFICATIONS>   NEURAL NETWORKS </CLASSIFICATIONS>
<ABSTRACT>
This dissertation investigates the design of a robust
controller for a linear system based on an Artificial
Neural Network (ANN) and compares that approach with
conventional methods. LQR (Linear Quadratic Regulator),
LQG (Linear Quadratic Gaussian), H$sbinfty$-constrained
LQR control, and H$sbinfty$-constrained LQG control
problems are considered. Each controller design
technique is explained in terms of robustness in the
frequency domain.
The dynamic system is assumed to be in one of a finite
number of configurations, each of which contains a
bounded plant uncertainty, corresponding to which exists
a pre-designed stabilizing controller. Multi-layer
neural networks are used for the indentification of a
plant uncertainty level which allows us to choose the
best controller among a finite number of given
controllers. Simulation results are given in every
chapter. The examples given in Chapters 7 and 8
especially reveal that an efficient robust controller
design using ANN can be achieved.
</ABSTRACT>
</THESIS>
<THESIS>
<NUMBER> 4338 </NUMBER>
<ORDER>   AAG9332473 </ORDER>
<TITLE>   TRANSIENT DETECTION AND FEATURE EXTRACTION USING NEURAL NETWORKS </TITLE>
<AUTHOR>   WILSON, ELIZABETH J. </AUTHOR>
<YEAR>   1993 </YEAR>
<INSTITUTION>   UNIVERSITY OF RHODE ISLAND; 0186 </INSTITUTION>
<DESCRIPTORS>   ENGINEERING, ELECTRONICS AND ELECTRICAL; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER>   DONALD W. TUFTS </ADVISER>
<CLASSIFICATIONS>   NIL </CLASSIFICATIONS>
<ABSTRACT>
Neural networks provide innovative methods for transient
detection and feature extraction. A number of network
structures and algorithms are explored and their
attributes explained. The research described focuses on
the use of neural networks for detection of a transient
or multiple transients embedded in noise. The emphasis
is in three major areas: network structure design and
fast training through the calculation of good starting
weights, test set design and performance evaluation, and
multistage network design. The research developments are
applied to sonar transient and nuclear magnetic
resonance transient examples.
The network structure design and fast training are part
of a new design algorithm that uses information from the
training set to structure the network including the
calculation of the necessary number of hidden nodes to
execute the mapping and computing good starting weights.
The design algorithm also provides a means of reducing
the training time, improving the convergence rate,
increasing the likelihood of converging at a global
minimum, and improving the generalization performance on
novel data. Performance evaluation includes the
calculation of confidence intervals to bound the error
analysis on the test set and the design of the test set
to insure that enough samples are chosen to properly
validate the performance of the network with the desired
accuracy, but that time is not being wasted on excessive
testing examples. The Multistage network design is a
coarse to fine algorithm for good resolution of the time
and frequency components and is applied to the transient
analysis problem. This algorithm also allows efficient
computation from a pipeline architecture where networks
can be repeated and used for different states of the
problem.
</ABSTRACT>
</THESIS>
<THESIS>
<NUMBER> 4339 </NUMBER>
<ORDER>   AAG9332348 </ORDER>
<TITLE>   A HYBRID PATTERN RECOGNITION PARADIGM USING MOMENT INVARIANTS AND POLYNOMIAL NETWORKS FOR SEGMENTING OBJECTS IN MULTI-SPECTRAL IMAGERY </TITLE>
<AUTHOR>   DRAKE, KEITH CARLISLE </AUTHOR>
<YEAR>   1993 </YEAR>
<INSTITUTION>   UNIVERSITY OF VIRGINIA; 0246 </INSTITUTION>
<DESCRIPTORS>   COMPUTER SCIENCE; ENGINEERING, ELECTRONICS AND ELECTRICAL; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER>   EUGENE S. MCVEY </ADVISER>
<CLASSIFICATIONS>   NIL </CLASSIFICATIONS>
<ABSTRACT>
The image understanding task of object classification
can be described as segmenting objects from their
background, extracting object features, and assigning
class definitions to these features. Successful object
classification is highly dependent upon initial
segmentation of an object from its background. For
complex, real-world imaging applications, this task is
extremely challenging and critical to the success of the
recognition system. Traditional object segmentation
techniques rely heavily upon noise removal during pre-
processing, and subsequently employs one of two image-
level strategies: histogram analysis or region growing.
Because effective noise removal strategies are difficult
to develop for actual imagery, the success of the
overall classification strategy often falls short of
requirements. Therefore, alternate methods are required
for object segmentation.
An alternate approach is to determine Target/Non-Target
status of image regions at the pixel level. In this
manner, noise removal and object segmentation are
performed in a single process, taking advantage of the
large amount of information contained in present-day,
multi-spectral imagery. The key issues associated with
this approach are proper determination of a pixel
information representation and choice of an information
fusion algorithm to process pixel-level information.
These questions were addressed during this dissertation
research.
The goal of this research was to design, develop, and
demonstrate an object segmentation paradigm that is
robust in the face of noise, clutter, and other adverse,
real-world conditions. To achieve this objective, the
research integrated multi-spectral imagery (co-
registered laser radar and thermal) of real-world
scenes, a pixel classification strategy for object
segmentation, moment invariants feature extraction
algorithms for pixel characterization, and polynomial
networks for feature processing. This approach is unique
in that it is the first to integrate these advanced
image understanding technologies.
To validate the proposed approach, the research compared
the utility provided by moment invariants with
conventional pixel-level features, heuristically
assessed segmentation results, and determined the
processing requirements for an operational
implementation of the resulting object segmentation
methodology.
</ABSTRACT>
</THESIS>
<THESIS>
<NUMBER> 4340 </NUMBER>
<ORDER>   AAG9400292 </ORDER>
<TITLE>   THE ACCEPTANCE AND EFFECTIVENESS OF HYPERTEXT SYSTEMS IN LEGAL EDUCATION: AN EXPERIMENTAL EVALUATION </TITLE>
<AUTHOR>   TROTTER, DAN LEWIS </AUTHOR>
<YEAR>   1993 </YEAR>
<INSTITUTION>   UNIVERSITY OF SOUTH CAROLINA; 0202 </INSTITUTION>
<DESCRIPTORS>   BUSINESS ADMINISTRATION, MANAGEMENT; ARTIFICIAL INTELLIGENCE; EDUCATION, BUSINESS; EDUCATION, TECHNOLOGY </DESCRIPTORS>
<ADVISER>   JAMES TENG </ADVISER>
<CLASSIFICATIONS>   NIL </CLASSIFICATIONS>
<ABSTRACT>
For years, AI/Expert Systems has been studied for its
relevance to the legal field, and to the field of legal
and business education. Hypertext is rooted in AI and
cognitive science theory and has been proposed to be an
advanced tool for learning.
This research seeks two objectives: to study the
acceptance of hypertext-based systems for legal
education by the students, and to evaluate the
effectiveness of such systems. To accomplish the first
objective, Davis' Technology Acceptance Model (TAM) was
used to model the factors contributing to the acceptance
of the system by the students. To evaluate the
effectiveness of the system, a controlled laboratory
experiment was conducted.
A hypertext system named "O&A" has been
developed by the researcher. The system incorporates
knowledge from the domain of the offer and acceptance
area of commercial law. Senior business students
participated in the study as experimental subjects. Each
student was randomly assigned to the control group or
the experimental group. In the latter case, the student
would use O&A to learn the particular domain for a
written exercise.
The results indicate the Technology Acceptance Model
received general support, but that there is no
significant difference in performance between the
control and experimental group. Contrary to
expectations, five of six hypotheses designed to test
effectiveness showed no significant advantage of
hypertext over traditional methods. These results were
interpreted to have been a product of experimental
design limitations, in that students had very restricted
exposure to the system in the learning process.
Although the results on teaching effectiveness were not
found to be significant, the path analysis for TAM
yielded many interesting findings. It can be concluded,
at least in the context of the current experiment, that
TAM predicts behavioral intention well, that perceived
usefulness is not a major determinant of behavioral
intention, that behavioral intention is affected more by
attitude than by perceived usefulness, and that attitude
is more affected by perceived usefulness than by ease of
use. Future studies may involve the replication of the
current experiment by increasing the intensity of
hypertext usage throughout the learning process.
</ABSTRACT>
</THESIS>
<THESIS>
<NUMBER> 4341 </NUMBER>
<ORDER>   AAG9333966 </ORDER>
<TITLE>   DEVELOPMENT OF OPTIMAL NETWORK STRUCTURES FOR BACK- PROPAGATION-TRAINED NEURAL NETWORKS </TITLE>
<AUTHOR>   GUAN, QING </AUTHOR>
<YEAR>   1993 </YEAR>
<INSTITUTION>   THE UNIVERSITY OF NEBRASKA - LINCOLN; 0138 </INSTITUTION>
<DESCRIPTORS>   BUSINESS ADMINISTRATION, MANAGEMENT; COMPUTER SCIENCE; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER>   SANG M. LEE </ADVISER>
<CLASSIFICATIONS>   BANKRUPTCY PREDICTION </CLASSIFICATIONS>
<ABSTRACT>
A critical question in the neural network research today
concerns how many hidden neurons to use. There is no
magic formula because it seems to be largely dependent
upon the complexity of the problem being solved. The
potential performance impact of hidden layers and
neurons must be taken into consideration in the network
development process.
This study focuses mainly on how to develop an optimal
neural network model for a specific task. In other
words, for a given task, it is desired to find a neural
network structure which has a minimal number of layers,
minimal number of units in each layer, and good
generalization ability. A process to build an optimal
network structure is proposed in this study. The core of
this process is the direct weight pruning method. This
method is based on mathematical deduction and the
property of the dominant subnet of a network that is
trained by a back-propagation algorithm with normalized
input data. The smallest magnitude weight in the trained
network is pruned sequentially. After no further pruning
is possible, the isolated units of the network are
deleted thus simplifying the original trained network.
The proposed process is evaluated using two common
benchmark problems: XOR and Parity. It is demonstrated
that the new pruning method produces the optimal network
models while being both simple and efficient. The
process is also evaluated using a real-world application
problem: firm bankruptcy prediction. The performance of
the neural network is compared to that of multivariate
discriminant analysis models for matched bankruptcy
samples. The neural network structure produced by the
proposed process offers a superior modeling approach for
firm bankruptcy prediction.
</ABSTRACT>
</THESIS>
<THESIS>
<NUMBER> 4342 </NUMBER>
<ORDER>   AAG9333735 </ORDER>
<TITLE>   MEADOW: AN INTEGRATED SYSTEM FOR INTELLIGENT TUTORING OF SUBTRACTION CONCEPTS AND PROCEDURES </TITLE>
<AUTHOR>   BURNS, LUANNE MARIE </AUTHOR>
<YEAR>   1993 </YEAR>
<INSTITUTION>   COLUMBIA UNIVERSITY; 0054 </INSTITUTION>
<DESCRIPTORS>   EDUCATION, PSYCHOLOGY; COMPUTER SCIENCE; EDUCATION, MATHEMATICS; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER>   HERBERT P. GINSBURG </ADVISER>
<CLASSIFICATIONS>   NIL </CLASSIFICATIONS>
<ABSTRACT>
This dissertation describes the development and
evaluation of a procedural bug diagnostic tool and
feedback device. It also describes an experiment on
feedback. The domain of the tool and the study is
children's subtraction.
The procedural bug diagnostic tool, MEADOW (Mathematics,
Errors, and Automatic Debugging Of Written input),
incorporates the content and sequence of handwritten
marks made during the execution of a mathematics
procedure into the knowledge base of an expert system.
The rule-based system then utilizes these process data
to analyze the procedure and detect procedural errors.
The process data allow analysis of the intermediate
steps of a procedure; insight into the problem-solving
technique is therefore more finely grained than mere
examination of the final result.
A computer input/output device consisting of a flat
display and electronic pen are used to collect
handwritten process data. MEADOW uses a neural network
approach for handwriting recognition and a rule-based
for analysis of subtraction procedures. MEADOW then
provides interactive feedback incorporating voice
narration, visual clues, and animation.
An experiment involving 76 third-grade students in four
classrooms is also described. Two varying styles of
feedback comprise the treatment groups; namely, student-
based feedback, which provides feedback directed at
exactly where the individual student went wrong, and
domain-based feedback, which reteaches the correct
procedure without regard for the individual's specific
mistakes. In addition, one control group received
Right/Wrong feedback and another control group received
no feedback. Students competed a total of forty problems
at three levels of complexity and were measured for
accuracy both during the learning phase and on a post
test.
The system evaluation included handwriting recognition
and bug detection rates. The handwriting recognition
rate was approximately.88. Full, partial, and unknown
bug detection rates were.61,.25, and.13 respectively.
Psychological experiment results indicated that student-
based feedback was more effective than domain-based
feedback. During the course of the experiment, both
experimental groups performed significantly better on
problem-correctness than the control groups but the
experimental groups did not differ significantly from
each other. However, both experimental groups showed a
linear trend on correctness within each complexity
level; the student-based group's trend was significantly
greater than the domain-based group at the first level
of complexity. Student-based subjects retried problems
significantly more than domain-based subjects. A delayed
post test found that only student-based subjects
performed significantly better than the control groups.
</ABSTRACT>
</THESIS>
<THESIS>
<NUMBER> 4343 </NUMBER>
<ORDER>   AAG9323751 </ORDER>
<TITLE>   KNOWLEDGE-BASED SYSTEMS: KNOWLEDGE REPRESENTATION AND INFERENCE STRATEGIES FOR EFFECTIVE MILITARY BIOMEDICAL R&D MANAGEMENT </TITLE>
<AUTHOR>   ODEYALE, CHARLES OLAJIDE </AUTHOR>
<YEAR>   1993 </YEAR>
<INSTITUTION>   WALDEN UNIVERSITY; 0543 </INSTITUTION>
<DESCRIPTORS>   BUSINESS ADMINISTRATION, MANAGEMENT; COMPUTER SCIENCE; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER>   JAMES T. BROWN </ADVISER>
<CLASSIFICATIONS>   NIL </CLASSIFICATIONS>
<ABSTRACT>
Research and Development (R&D) management is a
complex and unique procedural process. While many
attempts have been made to quantify the project
selection procedure, many laboratories use only the
simplest procedures. Of the currently available
managerial tools that may be used in effective R&D
management, there is no single tool that provides a
method for complete and credible research impact or
success/failure evaluation. The purposes of the study
were: (1) major R&D management problems
identification and characterization; (2) R&D
management knowledge-based system knowledge
representation and inference strategies identification--
a suitable set for the development of a prototype that
can enable an effective management of military
biomedical R&D; and (3) identified strategies
validation.
The "Case Study" research methodology, which
in turn mobilized longitudinal descriptive research
methodology, was used also. A significant finding was
that any R&D management knowledge representation and
inference that hope to approach the richness of an
R&D management expert's conceptual apparatus must
have characteristics including thoroughness, fidelity,
density, and uniformity. With respect to these
characteristics and as a framework for prototype
construction, a suggested organizational management
theoretical model was combined with a traditional
R&D review process of the Office of Naval Research
(ONR). Using a longitudinal descriptive research method,
Connectionist Networks (CNets) and Expert Systems (ES)
were combined to construct a prototype. This was
demonstrated to managers and investigators during
several interviews. Another significant finding was that
major principles such as abstraction, categorization,
communication, encapsulation, inheritance, relationship,
and scale were vital to the analyses, design, and coding
of the prototype.
Strategies validation used a framework consisting of six
elements including construct, content, and criterion
validity, as well as economics, objectivity, and
reliability. Each of the framework elements was
described and related to strategies during the
validation process. This demonstrated that, through
CNets and ES synergy, as well as object oriented
analysis, design, and programming, complex issue
resolution is feasible. Results advantages include: (1)
managerial tools to assist and support managers in
effective management; (2) synergistic usage of CNets and
ES in analytical yet holistic R&D management process
that integrates policy-oriented performance assessment
mechanisms; and (3) a method for complete and credible
research impact, investigator, and organization
performance evaluation.
</ABSTRACT>
</THESIS>
<THESIS>
<NUMBER> 4344 </NUMBER>
<ORDER>   AAG1352506 </ORDER>
<TITLE>   A HYBRID NEURAL NETWORK/CONCEPTUAL GRAPH SYSTEM FOR SPACE SHUTTLE TELEMETRY MONITORING </TITLE>
<AUTHOR>   PARRIS, FRANK RAY, JR. </AUTHOR>
<YEAR>   1993 </YEAR>
<INSTITUTION>   UNIVERSITY OF ALABAMA IN HUNTSVILLE; 0278 </INSTITUTION>
<DESCRIPTORS>   COMPUTER SCIENCE; ENGINEERING, AEROSPACE; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER>   PEGGY ISRAEL </ADVISER>
<CLASSIFICATIONS>   NIL </CLASSIFICATIONS>
<ABSTRACT>
This thesis describes a hybrid Neural Network/Conceptual
Graph system for Space Shuttle telemetry monitoring. The
system integrates the two paradigms, using Conceptual
Graphs to model information about shuttle subsystems,
and Counterpropagation Neural Networks to store and
manipulate this information. This work addresses other
efforts in spacecraft telemetry analysis; provides
background for the two paradigms used; and describes
implementation issues and prototyping of the system,
including the source code used.
</ABSTRACT>
</THESIS>
<THESIS>
<NUMBER> 4345 </NUMBER>
<ORDER>   AAG1352364 </ORDER>
<TITLE>   INVESTIGATION OF NEURAL NETWORKS FOR THE SCHEDULING AND ALLOCATION PROBLEM IN HIGH-LEVEL SYNTHESIS </TITLE>
<AUTHOR>   GASSEN, DAVID WAYNE </AUTHOR>
<YEAR>   1993 </YEAR>
<INSTITUTION>   THE UNIVERSITY OF ARIZONA; 0009 </INSTITUTION>
<DESCRIPTORS>   ENGINEERING, ELECTRONICS AND ELECTRICAL; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER>   JO DALE CAROTHERS </ADVISER>
<CLASSIFICATIONS>   NIL </CLASSIFICATIONS>
<ABSTRACT>
In recent years neural network have been shown to be
quite effective in solving difficult combinatorial
optimization problems. In this work a Hopfield neural
network is used to schedule operations in a dataflow
graph. This is an important step in behavioral synthesis
systems. These operations must be assigned to a limited
number of control steps, functional units, and busses.
Also, there is an objective to minimize the lengths of
data paths. Current methods which do this type of
scheduling typically rely on heuristic algorithms. The
neural network devised to solve this problem is one of
the most complex to date. A special mechanism,
"flag" neurons, was developed to enable the
neural network to encode a bussing constraint. The
neural network has been tested with problems from
literature and problems randomly generated. The results
have been consistently superior to those produced by a
heuristic algorithm called ALAP.
</ABSTRACT>
</THESIS>
<THESIS>
<NUMBER> 4346 </NUMBER>
<ORDER>   AAG9332265 </ORDER>
<TITLE>   DESIGNING AND TUNING OF A FUZZY LOGIC CONTROLLER VIA GENETIC INPUT/OUTPUT MAPPING FACTORS </TITLE>
<AUTHOR>   CHANG, CHIR-HO </AUTHOR>
<YEAR>   1993 </YEAR>
<INSTITUTION>   THE UNIVERSITY OF OKLAHOMA; 0169 </INSTITUTION>
<DESCRIPTORS>   ENGINEERING, ELECTRONICS AND ELECTRICAL; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER>   JOHN Y. CHEUNG </ADVISER>
<CLASSIFICATIONS>   NIL </CLASSIFICATIONS>
<ABSTRACT>
In this dissertation, a general purpose fuzzy logic
controller is designed, analyzed, and tuned through the
use of symmetrical membership functions (SMFs). The
mathematical model for the fuzzy logic controller is
established using SMFs for the first time. Based on the
least squared approximation, the control decision plane
is approximated by a set of nonlinear fitting functions.
By manipulating these functions, the necessary stability
condition(s) of the fuzzy logic controller is(are)
derived.
The designed fuzzy logic controller requires tuning to
satisfy manufacturers' specifications. The proposed
tuning method uses the genetic algorithm (GA) as the
learning process. GA can be used to search the decision
rule table (denoted by GA $to$ Rules) or the membership
functions (denoted by GA $to$ MBFS). A new searching
domain which searches symmetrical membership functions
is proposed (denoted as GA $to$ SMFs). This approach is
compared with other searching methods by evaluating the
GA efficiency in differential cost and the time
efficiency for linear time invariant plants. Major
comparisons are drawn between GA-tuned and fuzzy
addition (FA) based FLC systems, GA $to$ Rules-based and
GA $to$ MBFs-based FLC systems, GA $to$ MBF-based and GA
$to$ SMFs-based FLC systems, and GA $to$ SMFs-based FLC
and a tuned PID controller.
Simulation results showed that a GA-tuned FLC system is
a true domain expert-free system, can achieve an
arbitrary (sub)optimal control goal easily, and is far
better than the FA-based FLC system. The proposed GA
$to$ SMF-based FLCs are seen to outperform both the GA
$to$ Rules-based and the GA $to$ MBFs-based FLCs.
</ABSTRACT>
</THESIS>
<THESIS>
<NUMBER> 4347 </NUMBER>
<ORDER>   AAG9332231 </ORDER>
<TITLE>   DEVELOPMENT OF THE NEW BEST INFORMATION ALGORITHM FOR A MEDICAL EXPERT SYSTEM </TITLE>
<AUTHOR>   GUO, DI </AUTHOR>
<YEAR>   1993 </YEAR>
<INSTITUTION>   THE UNIVERSITY OF UTAH; 0240 </INSTITUTION>
<DESCRIPTORS>   BIOPHYSICS, MEDICAL; COMPUTER SCIENCE; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER>   NIL </ADVISER>
<CLASSIFICATIONS>   ILIAD </CLASSIFICATIONS>
<ABSTRACT>
Iliad is a diagnostic expert system for internal
medicine. One important feature that Iliad offers is the
ability to analyze a particular patient case and to
determine the most cost-effective findings to pursue
next at any stage of a work-up. The "best
information" algorithm combines an information
content calculation together with a cost factor. The
calculations then provide a rank-ordering of the
alternative patient findings according to cost-
effectiveness.
This dissertation presents a three-part study to
evaluate the performance of different best information
algorithms. In the first two parts of the study the
suggestions about the next best data elements to pursue
from different algorithms were collected for different
vignettes. The performance of different algorithms was
compared based on the judgments provided by expert
clinicians. The results indicated that the current Iliad
information content model could be improved by using a
version of Shannon information content model.
The third part of the study evaluated different best
information algorithms by a simulation approach. The
results indicated that two types of diagnostic behaviors
could be simulated. The first type of behavior was
characterized by pursuing more history and physical
examination findings, less laboratory tests, less
expensive work-ups, and more steps to solve a patient
case. The second type of behavior was characterized by
pursuing less history and physical examination findings,
more laboratory tests, more expensive work-ups, and less
steps to solve a patient case. The Shannon information
content model accomplished work-ups that were
significantly less costly than work-ups performed by the
current LR (likelihood ratio) information content model.
However, the Shannon model required additional
computational resources and more history and physical
examination steps than the LR model. Decisions regarding
the implementation of alternative models require a
balance of the relative merits of cost, steps, expert
preference, and other important factors.
</ABSTRACT>
</THESIS>
<THESIS>
<NUMBER> 4348 </NUMBER>
<ORDER>   AAG9331920 </ORDER>
<TITLE>   RATIONAL SENSING FOR AN AI PLANNER: A COST-BASED APPROACH </TITLE>
<AUTHOR>   KREBSBACH, KURT DONALD </AUTHOR>
<YEAR>   1993 </YEAR>
<INSTITUTION>   UNIVERSITY OF MINNESOTA; 0130 </INSTITUTION>
<DESCRIPTORS>   COMPUTER SCIENCE; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER>   MARIA GINI </ADVISER>
<CLASSIFICATIONS>   ROBOTICS, SENSORS </CLASSIFICATIONS>
<ABSTRACT>
Task planning involves the construction of plans to
accomplish goals and the execution of these plans in the
task environment by an agent. We have developed a
planner/executor that can plan to perform sensor
operations which allow an agent to gather the
information necessary to complete planning and achieve
its goals in the face of missing or uncertain
environmental information.
The problem can be viewed as one of choosing among
various sensing policies in order to maximize some
reward (a successful plan) or minimize some cost
(execution plan length). Determining an optimal policy
for a given planning problem consists of computing
tradeoffs between domain-specific factors such as sensor
reliabilities, the cost of firing sensors, premature
action recovery costs, bad data recovery costs, and the
cost of human intervention. Some of these costs are
determined while others are analytically derived.
Exhaustive strategies for this computation become
intractable for even a modest degree of environmental
uncertainty. A major objective of this research is to
suggest computationally feasible ways to solve this
problem.
Two methods will be presented in two distinct
demonstration domains. The first method, static sensor
scheduling, involves probabilistically constructing a
sensor schedule offline which is used by the
planner/executor to minimize expected plan length. The
second, dynamic sensor selection, consists of building a
directed graph offline and using actual world states as
an index into the graph as planning and execution
progress. Both algorithms have been implemented and can
be shown to be polynomial in both time and space
complexity.
</ABSTRACT>
</THESIS>
<THESIS>
<NUMBER> 4349 </NUMBER>
<ORDER>   AAG9331892 </ORDER>
<TITLE>   ROBOTIC PLAN EXECUTION IN DYNAMIC AND UNPREDICTABLE ENVIRONMENTS </TITLE>
<AUTHOR>   BUDENSKE, JOHN RAYMOND </AUTHOR>
<YEAR>   1993 </YEAR>
<INSTITUTION>   UNIVERSITY OF MINNESOTA; 0130 </INSTITUTION>
<DESCRIPTORS>   COMPUTER SCIENCE; ENGINEERING, SYSTEM SCIENCE; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER>   NIL </ADVISER>
<CLASSIFICATIONS>   DYNAMIC ENVIRONMENTS </CLASSIFICATIONS>
<ABSTRACT>
To be useful in the real world, robots need to be able
to move safely in unstructured environments and achieve
their given tasks despite unexpected environmental
changes or failures of some of their sensors. The
variability of the world makes it impractical to develop
very detailed plans of actions prior to execution since
the world might change before execution begins, and thus
invalidate the plan. The transformation from the high
level description of the task to the primitive actions
should be performed primarily at execution time. This
allows access to up-to-date information about the
environment through sensors as well as integration of
sensed information in deciding how to achieve the task.
The Logical Sensor/Actuator (LSA) theory was developed
to specify the types of knowledge and processes
necessary for a mobile robot to execute a plan. The LSA
theory is based on three premises: (1) plan execution
requires relevant details (hidden in the plan's
abstraction) to be made explicit; (2) knowledge is
integral to the plan execution process, and thus proper
application of knowledge increases the robustness of
plan execution; and (3) plan execution is an information-
based process where determining which information is
relevant constitutes a great deal of the process. This
research also addresses the issue of what knowledge
needs to be available about sensors, actuators and
processes in order to be able to integrate their usage,
and control them during execution. The methods proposed
are applicable to any sensor/actuator existing on the
robot when given such knowledge.
This research yielded an object-oriented homogeneous
architecture for plan execution, called the Logical
Sensor/Actuator Testbed (LSAT). LSAT was used to develop
laboratory experiments on a real mobile robot, providing
data in support of the theory. A large number of
laboratory experiments were conducted on the
implementation. The experiments covered various
capabilities of the implementation across a number of
environmental scenarios. The results not only support
the theory, but also illustrate how the proper
application of knowledge in the integration and
utilization of sensors and actuators increases the
robustness of plan execution.
</ABSTRACT>
</THESIS>
<THESIS>
<NUMBER> 4350 </NUMBER>
<ORDER>   AAG9331672 </ORDER>
<TITLE>   A METHODOLOGY FOR THE ANALYSIS AND MONITORING OF VIBRATION DATA USING ARTIFICIAL NEURAL SYSTEMS </TITLE>
<AUTHOR>   ALGUINDIGUE, ISRAEL ELIAS </AUTHOR>
<YEAR>   1993 </YEAR>
<INSTITUTION>   THE UNIVERSITY OF TENNESSEE; 0226 </INSTITUTION>
<DESCRIPTORS>   ENGINEERING, NUCLEAR; COMPUTER SCIENCE; ENGINEERING, MECHANICAL; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER>   ROBERT E. UHRIG </ADVISER>
<CLASSIFICATIONS>   NUCLEAR POWER PLANTS </CLASSIFICATIONS>
<ABSTRACT>
This dissertation deals with the use of artificial
neural networks for the monitoring and diagnosis of
components in nuclear power plants. The technology of
neural networks provides an attractive complement to
traditional vibration analysis because of its potential
to operate in real-time and to handle data which may be
distorted or noisy. The technique enhances traditional
vibration analysis and provides a means of automating
the monitoring and diagnosis of vibrating equipment.
The study is conducted in two phases. First, the
mechanical behavior of rotating machinery is studied,
and a neural network system is developed for the
detection of faults in rolling element bearings (REB).
The system learns association between features in the
spectrum and operating states of the bearings, the
system is tested using data from an aging simulation
bench test.
A technique is presented for modelling the relationship
among sensors in a machine that is shown to be very
effective for identifying changes in operating states.
REB's are especially interesting components because they
are responsible for a large fraction of the malfunctions
in manufacturing equipment. In an average nuclear power
plant about one third of all measuring points is
allocated to REB's. The second phase of the study is
related to the problem of the vibration of the internals
of pressurized water reactors (PWR). The vibratory
behavior of the internals in a PWR can be identified and
monitored using ex-core neutron data from ionization
chambers located outside the vessel. The data collected
from these detectors provide information regarding the
behavior of mechanical components, the presence of
contacts between the core barrel and the pressure
vessel, and more importantly, a means of verifying the
integrity of components in the system.
A neural network-based methodology is described for
identifying the vibration mode of the core barrel, and
for detecting a particular family of mechanical
failures. Features are extracted from the neutron noise
spectra, and used for training neural network models to
identify the different states of vibration typically
exhibited by PWR's. The technique was tested on data
collected over 93 fuel cycles from twenty-eight 900 MWe
pressurized water reactors in France.
</ABSTRACT>
</THESIS>
<THESIS>
<NUMBER> 4351 </NUMBER>
<ORDER>   AAG9331363 </ORDER>
<TITLE>   AN INTEGRATED SIMULATION-EXPERT SYSTEM APPROACH FOR IRRIGATION MANAGEMENT </TITLE>
<AUTHOR>   BODLA, MUHAMMAD ABID </AUTHOR>
<YEAR>   1993 </YEAR>
<INSTITUTION>   COLORADO STATE UNIVERSITY; 0053 </INSTITUTION>
<DESCRIPTORS>   ENGINEERING, CIVIL; ENGINEERING, AGRICULTURAL; COMPUTER SCIENCE; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER>   NIL </ADVISER>
<CLASSIFICATIONS>   SURFACE IRRIGATION MANAGEMENT </CLASSIFICATIONS>
<ABSTRACT>
Identifying suitable management practices is crucial in
efficient control of surface irrigation performance.
While a present capability exists for analysis of
surface irrigation through existing simulation models,
the corresponding synthesis i.e., determination of
appropriate management operating parameters (inflow rate
and cutoff time) to achieve an optimal performance level
is not directly provided by these models. This
limitation of existing models stems from the enormity of
the problem search space and the associated complexity
arising out of non-availability of a systematic
algorithm to help reduce the search space that
encompasses a very wide range of possible combinations
of these irrigation management parameters. This suggests
the leed for development of an integrated simulation-
expert system approach foy surface irrigation
management.
A systematic algorithm has been identified in the
present study for adaptive control of surface irrigation
efficiencies through combining heuristics with decision
rules. These heuristics and decision rules were
developed through inferences obtained from extensive
analyses of border irrigation systems' performance
responses to a large number of varying input data sets.
A knowledge-based expert system ESBIM has been developed
in this research for improved irrigation management of
open ended borders. Integration of the rule based expert
system with an existing simulation model, SIRMOD and
linking the hybrid simulation-expert system to a dynamic
database provides a composite technical base for
explicit determination of the management operating
parameters. Implementation of this advisory system is
accomplished through the artificial intelligence logic
programming language PROLOG. Validation of ESBIM is
carried out in real operational settings to demonstrate
the system's capability for accurate and explicit
determination of optimal and alternate management
strategies leading to improvement of current irrigation
performance levels.
The dynamic database in ESBIM is designed to store and
update selected ESBIM solutions and can be queried to
provide comprehensive decision support for precise
control of border irrigation performance without
requiring re-execution of the simulation model.
</ABSTRACT>
</THESIS>
<THESIS>
<NUMBER> 4352 </NUMBER>
<ORDER>   AAG9331109 </ORDER>
<TITLE>   AUTOMATIC RECOGNITION OF HANDWRITTEN NUMERALS VIA ORTHOGONAL MOMENTS USING STATISTICAL AND NEURAL NETWORK CLASSIFIERS </TITLE>
<AUTHOR>   BAILEY, ROBERT RICHARD </AUTHOR>
<YEAR>   1993 </YEAR>
<INSTITUTION>   SOUTHERN METHODIST UNIVERSITY; 0210 </INSTITUTION>
<DESCRIPTORS>   ENGINEERING, ELECTRONICS AND ELECTRICAL; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER>   M. D. SRINATH </ADVISER>
<CLASSIFICATIONS>   NIL </CLASSIFICATIONS>
<ABSTRACT>
This research is concerned with the automatic machine
classification of handwritten Arabic numerals. In
particular it examines in detail a variety of approaches
based on the application of two-dimensional orthogonal
polynomials for feature extraction and the use of
parametric and non-parametric statistical and neural
network classifiers. This work utilizes a data base of
over 16000 binary digitized images collected from a
large number of individuals covering a wide range of
style, neatness, character size, and pen width.
Polynomials, including Legendre, Zernike, and pseudo-
Zernike, are used to generate features invariant to
location, size, and (optionally) rotation. An efficient
method for computing the moments via geometric moments
is presented. A side effect of this method also yields
scale invariance. A new approach to location invariance
using a minimum bounding circle is presented, and a
detailed analysis of the rotational properties of the
moments is given. Pre- and post-processing steps are
used to improve the classification accuracy. Classifiers
include the Bayes quadratic, k-nearest neighbor, three
varieties of Parzen, and multilayer perceptron neural
network.
Since numerous combinations of features and classifiers
are evaluated, a simple ranking of how well they perform
would not adequately discern real differences in their
relative performance due to statistical scatter in the
observed results. To help draw statistically justifiable
conclusions about their performance, the method of
analysis of variance is employed in this research to
compare the mean classification error of both feature
types and classifiers. In the past researchers into
pattern recognition have, unfortunately, ignored such
methods.
For rotational invariant character recognition, the
highest percentage of correctly classified characters
was 91.7%, and for non-rotational invariant recognition
it was 97.6%. This compares with a previous effort,
using the same data and test conditions, of 94.8%.
An analysis of all the results indicate that, overall,
the Parzen classifiers performed best, although in
particular cases the k-nearest neighbor and multilayer
perceptron sometimes were better. The quadratic
classifier nearly always gave the most errors. The
pseudo-Zernike moments, using either centroid or minimum
bounding circle location invariant method, were the best
features.
The techniques developed here should also be applicable
to other areas of shape recognition.
</ABSTRACT>
</THESIS>
<THESIS>
<NUMBER> 4353 </NUMBER>
<ORDER>   AAG9331099 </ORDER>
<TITLE>   A STRUCTURED APPROACH TO REAL-TIME PROBLEM SOLVING </TITLE>
<AUTHOR>   PAUL, C. J. </AUTHOR>
<YEAR>   1993 </YEAR>
<INSTITUTION>   CARNEGIE-MELLON UNIVERSITY; 0041 </INSTITUTION>
<DESCRIPTORS>   COMPUTER SCIENCE; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER>   NIL </ADVISER>
<CLASSIFICATIONS>   DOMAIN KNOWLEDGE, ARTIFICIAL INTELLIGENCE </CLASSIFICATIONS>
<ABSTRACT>
Real-time problem solving is not only reasoning about
time, it is also reasoning in time. This is becoming
increasingly critical in systems that monitor and
control complex processes in semi-autonomous, ill-
structured, real-world environments. Many techniques,
mostly ad-hoc, have been developed in both the Real-Time
and the Artificial Intelligence research communities for
solving problems within time constraints. But a
coherent, wholistic picture does not exist. This thesis
is an attempt to step back from the details, and examine
the entire issue of real-time problem solving from first
principles. The basic premise of this thesis is that
there exists a structured approach to real-time problem
solving, based on the fundamental degrees of freedom
available in using domain knowledge to reduce execution
time variations due to search, and to structure the
search space and the search process to produce best-so-
far solutions in limited time. The degrees of freedom
are examined at two levels of problem solving search--at
the problem-level search space and the rule-retrieval
level search space. Existing real-time problem solving
techniques are shown to be compositions of these
fundamental degrees of freedom. System level issues were
considered in providing temporal isolation between
conventional hard real-time tasks and real-time problem
solving tasks executing on a common computing platform.
An AI Server was developed to facilitate the integration
of real-time problem solving tasks into hard real-time
systems. A real-time problem solving architecture,
Concurrent Real-Time OPS5 (CROPS5), and two applications
were developed to validate some aspects of the approach.
CROPS5 is a real-time production system architecture
implemented in C, supporting multiple problem-solving
streams, a fast and predictable context switch
mechanism, global working memory and a data handler for
interface to the environment. It runs on the Chimera II
and ARTS real-time operating systems. CROPS5 was used to
implement an aircraft collision avoidance application
and a dynamic scheduling and pacing system for steel
mills.
</ABSTRACT>
</THESIS>
<THESIS>
<NUMBER> 4354 </NUMBER>
<ORDER>   AAG9331098 </ORDER>
<TITLE>   AGENT DESIGN FOR AUTOMATIC USE OF A SOFTWARE SYSTEM: A CASE STUDY WITH A SOAR AGENT FOR MATHEMATICA </TITLE>
<AUTHOR>   PATHAK, DHIRAJ KUMAR </AUTHOR>
<YEAR>   1993 </YEAR>
<INSTITUTION>   CARNEGIE-MELLON UNIVERSITY; 0041 </INSTITUTION>
<DESCRIPTORS>   COMPUTER SCIENCE; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER>   ALLEN NEWELL; DAVID STEIER </ADVISER>
<CLASSIFICATIONS>   NIL </CLASSIFICATIONS>
<ABSTRACT>
It is useful to build agents to mediate in the use of
complex software systems. To understand some dimensions
of mediating agents, this thesis presents an agent
design for the automatic use of a computer algebra
system (CAS). Such an agent must take a task
specification from the user and produce a plan for
achieving the task while also producing a plan for the
CAS. In particular, I use the Soar architecture to build
an agent for using Mathematica, guided by a study of
protocols of human users of Mathematica. The general
design principles for mediating agents suggested by the
particular agent for Mathematica include a blackboard-
style control structure using a production systems
architecture, a dual-space planning function,
integration of planning and execution, and mechanisms
for automatic knowledge acquisition through environment
interaction.
</ABSTRACT>
</THESIS>
<THESIS>
<NUMBER> 4355 </NUMBER>
<ORDER>   AAG9330864 </ORDER>
<TITLE>   ACTIONS, BELIEFS AND INTENTIONS IN MULTI-ACTION UTTERANCES </TITLE>
<AUTHOR>   BALKANSKI, CECILE TIBERGHIEN </AUTHOR>
<YEAR>   1993 </YEAR>
<INSTITUTION>   HARVARD UNIVERSITY; 0084 </INSTITUTION>
<DESCRIPTORS>   COMPUTER SCIENCE; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER>   BARBARA GROSZ </ADVISER>
<CLASSIFICATIONS>   DISCOURSE PROCESSING, SEMANTICS </CLASSIFICATIONS>
<ABSTRACT>
Multi-action utterances convey critical information
about agents' beliefs and intentions with respect to the
actions they talk about or perform. Two such utterances
may, for example, describe the same actions while the
speakers of these utterances hold beliefs about these
actions that are diametrically opposed. Hence, for a
language interpretation system to understand multi-
action utterances, it must be able (1) to determine the
actions that are described and the ways in which they
are related, and (2) to draw appropriate inferences
about the agents' mental states with respect to these
actions and action relations.
This thesis investigates the semantics of two particular
multi-action constructions: utterances with means
clauses and utterances with rationale clauses. These
classes of utterances are of interest not only as
exemplars of multi-action utterances, but also because
of the subtle differences in information that can be
felicitously inferred from their use. Their meaning is
shown to depend on the beliefs and intentions of the
speaker and agents whose actions are being described as
well as on the actions themselves. Thus, the thesis
demonstrates (a) that consideration of mental states
cannot be reserved to pragmatics and (b) that other
aspects of natural language interpretation besides the
interpretation of mental state verbs or plan recognition
may provide information about mental states. To account
for this aspect of natural language interpretation, this
thesis presents a theory of logical form, a theory of
action and action relations, an axiomatization of belief
and intention, and interpretation rules for means
clauses and rationale clauses.
Together these different pieces constitute an
interpretation model that meets the requirements
specified in (1) and (2) above and that predicts the set
of beliefs and intentions shown to be characteristic of
utterances with means clauses and rationale clauses.
This model has been implemented in the MAUI system
(Multi-Action Utterance Interpreter), which accepts
natural language sentences from a user, computes their
logical form, and answers questions about the beliefs
and intentions of the speaker and actor regarding the
actions and action relations described.
</ABSTRACT>
</THESIS>
<THESIS>
<NUMBER> 4356 </NUMBER>
<ORDER>   AAG9330408 </ORDER>
<TITLE>   OCCURRENCE-BASED WORD CATEGORIZATION </TITLE>
<AUTHOR>   BENSCH, PETER ALLAN </AUTHOR>
<YEAR>   1993 </YEAR>
<INSTITUTION>   UNIVERSITY OF CALIFORNIA, SAN DIEGO; 0033 </INSTITUTION>
<DESCRIPTORS>   COMPUTER SCIENCE; LANGUAGE, LINGUISTICS; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER>   WALTER J. SAVITCH </ADVISER>
<CLASSIFICATIONS>   MACHINE LEARNING </CLASSIFICATIONS>
<ABSTRACT>
We have embarked on a research program that we call
OCCURRENCE-BASED processing. This methodology, quite
simply, monitors the contexts in which data elements
appear. As such, it is similar to co-occurrence
statistical studies, but we do not tally the number of
times the data element occurs in the context--we simply
record that it has occurred. Thus, one occurrence is the
same as 1,000 occurrences.
We have been applying this methodology to the task of
categorizing words from a natural language. In
particular, we have been applying it to corpora
consisting of samples of written English text (edited
newspaper articles and unedited technical articles).
Shifting the emphasis from co-occurrence likelihoods
(frequency-based studies) to co-occurrence possibilities
(occurrence-based studies) has allowed us to isolate
interesting "natural" word categories from
moderate-sized corpora. The preliminary investigations
mentioned in this dissertation have shown that
occurrence-based processing is a research approach that
warrants further investigation.
</ABSTRACT>
</THESIS>
<THESIS>
<NUMBER> 4357 </NUMBER>
<ORDER>   AAG9330406 </ORDER>
<TITLE>   A METHODOLOGY AND ARCHITECTURE FOR INTERACTIVE KNOWLEDGE- BASED DIAGNOSTIC PROBLEM-SOLVING IN VLSI MANUFACTURING </TITLE>
<AUTHOR>   HEKMATPOUR, AMIR </AUTHOR>
<YEAR>   1993 </YEAR>
<INSTITUTION>   UNIVERSITY OF CALIFORNIA, SAN DIEGO; 0033 </INSTITUTION>
<DESCRIPTORS>   COMPUTER SCIENCE; ENGINEERING, ELECTRONICS AND ELECTRICAL; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER>   CHARLES P. ELKAN; LAURENCE B. MILSTEIN </ADVISER>
<CLASSIFICATIONS>   EXPERT SYSTEM </CLASSIFICATIONS>
<ABSTRACT>
This dissertation describes an architecture for
multimedia diagnostic knowledge-based systems, and a
methodology for their development. The knowledge
engineering methodology and the knowledge representation
architecture introduced here are suited for the class of
diagnostic problems whose analysis and resolution can be
captured by condition-action trees and case libraries.
The primary target applications include tool maintenance
and troubleshooting, process control and diagnosis, and
decision support. The proposed methodology improves
knowledge capture and technology transfer by providing
the necessary tools and techniques to domain experts.
Expert knowledge is represented as a hierarchy of
condition-action trees (a generalization of decision
trees) rather than by rules, decision tables, or complex
models. This improves system performance, reduces system
maintenance, enables incremental expansion, provides
access to intermediate states and thus reduces search,
and finally, it provides a representation consistent
with the mental model of experts. The knowledge
representation architecture involves three hierarchical
levels of knowledge: the abstract behavioral level,
representing general information about the domain of
diagnosis; the structural level, capturing knowledge
about specific tools, tasks, and processes; and the
lowest level consisting of diagnosis and recovery
information for individual problems.
Reasoning is also hierarchical, and can be described as
a data-driven, look-ahead, breadth-first process.
Inferencing is based on a hierarchical knowledge
processing algorithm where nodes in the knowledge base
are ranked following an entropy-based measure of useful
information. Nodes can invoke hypermedia and multimedia
service modules, which makes documentation available on-
line in a focused manner. This interactive knowledge
processing closely fits the everyday work environment,
which improves the acceptance of diagnostic systems and
their integration into the workplace.
The knowledge engineering methodology provides a set of
guidelines to capture completely and accurately the
knowledge hierarchy, reasoning strategy, and heuristics
involved in the diagnostic process. These guidelines are
based on supervised knowledge acquisition principles.
They provide consistency, serve as checklists during the
development process, and improve and encourage the
expert's involvement. The proposed methodology also
includes a strategy for technology transfer through top-
down training and bottom-up development by domain
experts.
</ABSTRACT>
</THESIS>
<THESIS>
<NUMBER> 4358 </NUMBER>
<ORDER>   AAG9330331 </ORDER>
<TITLE>   ARTIFICIAL INTELLIGENCE METHODOLOGIES FOR AEROSPACE AND OTHER CONTROL SYSTEMS </TITLE>
<AUTHOR>   WU, YUANLAN </AUTHOR>
<YEAR>   1993 </YEAR>
<INSTITUTION>   WASHINGTON UNIVERSITY; 0252 </INSTITUTION>
<DESCRIPTORS>   ENGINEERING, ELECTRONICS AND ELECTRICAL; COMPUTER SCIENCE; ENGINEERING, SYSTEM SCIENCE; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER>   ERVIN Y. RODIN </ADVISER>
<CLASSIFICATIONS>   NEURAL NETWORKS </CLASSIFICATIONS>
<ABSTRACT>
Artificial intelligence methodologies have been applied
to the modeling and implementation of control systems
and differential games problems. To be more specific,
artificial neural networks, a multiple instruction
multiple data parallel processor tuned by connection
weights, are used to model a control system or used as
an identifier/controller which functions as a mapping
between two information domains. Based on a new paradigm
of neural networks consisting of Neurons With Local
Memory (NLMs), the representation of a control system by
neural networks is discussed. Using this representation,
the basic issues of complete controllability and
observability for the system are addressed. A separation
principle of learning and control is presented for
Networks with NLMs (NNLM). The result shows that the
weights of the network will not affect its dynamics. The
principle may be utilized to prespecify the steady state
properties of the system. Modeled by NNLM, the resulting
system is a typical nonlinear one which, through
rigorous mathematical analysis, is shown to be locally
linearizable via a regular static state feedback and a
nonlinear coordinate transformation.
Significant advances have been achieved in applying
differential games theory, a theory dealing with most of
conflicts in daily life, economics, military affairs,
etc., to practical problems. In this dissertation, this
theory has been thoroughly addressed from a new point of
view. A configuration, based on the paradigm of semantic
control, is proposed, which can be used to derive two
paradigms of differential games with neural networks.
Generally, two neural networks are used in each of these
two paradigms. One network is called the neural-
identifier and it is used to identify the control
strategy of one's opponent. The other one is the neural-
controller which, taking the estimate of the control
strategy of one's opponent, outputs the control value
for oneself. The issue of existence of solutions is
discussed. To demonstrate the effectiveness of the
method, a simulation experiment was carried out and
studied for a pursuit-evasion game problem.
In Chapter 3, a learning control algorithm is developed.
The algorithm can be used to evaluate the weights of a
neural controller in the paradigms proposed in the
chapter or in other control systems. Using the learning
control algorithm, we study the aircraft control problem
in the presence of windshear.
In Chapter 4, we shall discuss another aspect of
artificial intelligence techniques in control systems:
rule-based system in a class of pursuit-evasion game
problems. The pursuit-evasion game problems can be
converted to classical optimal control problems. The
optimal control solution is obtained. The solution offer
several advantages such as significant time-saving in
implementation. Further research directions are
addressed in the last chapter.
</ABSTRACT>
</THESIS>
<THESIS>
<NUMBER> 4359 </NUMBER>
<ORDER>   AAG9330303 </ORDER>
<TITLE>   PROCESS-ORIENTED PLANNING FOR THE PLACEMENT OF REINFORCING BARS </TITLE>
<AUTHOR>   SALIM, MD. </AUTHOR>
<YEAR>   1993 </YEAR>
<INSTITUTION>   NORTH CAROLINA STATE UNIVERSITY; 0155 </INSTITUTION>
<DESCRIPTORS>   ENGINEERING, CIVIL; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER>   LEONHARD E. BERNOLD </ADVISER>
<CLASSIFICATIONS>   NIL </CLASSIFICATIONS>
<ABSTRACT>
The two main goals of this research were: (1) to develop
and test a CAD-integrated intelligent process planning
system for the placement of reinforcing bars (rebar),
and (2) measure the effects of placement-oriented
bundling, tagging, delivery and staging on the crew-
level productivity. For the first goal an extended
input/output (I/O) process model has been developed to
better represent the dynamic nature of construction.
This modified I/O model demonstrated the need for
utilizing process-oriented planning concept for the
placement of rebar in concrete construction. Feature
based frameworks for design and planning were
established to allow the use of artificial intelligence
(AI) in the development of a CAD-integrated process
planning system. The thesis also includes a discussion
of the system architecture of a computerized prototype.
The CAD-Integrated Rebar Placement Planning System
(CRPP) is implemented on a PC-486 computer using LEVEL5
OBJECT, AutoCAD and dBASE III PLUS.
The second goal of this research is based on extensive
comparative field experiments in the construction of a
six-story governmental office building project in Chapel
Hill, North Carolina. Three different methods of
observation were utilized to collect data of the same
rebar crew being provided with rebar that were bundled,
tagged, delivered and staged (a) in a traditional
manner, and (b) based on the placement sequence.
The overall outcome of this comprehensive research
project indicates that process-oriented planning,
computerized and CAD-integrated, can yield drastic
improvements in the crew-level productivity. This study
showed that many planning tasks can be automated.
Furthermore, such automation in planning, when used in
an integrated fashion that also includes material
suppliers, etc., may be a key to unlocking the
potentials for streamlining construction practices
through the use of multi-level planning models.
</ABSTRACT>
</THESIS>
<THESIS>
<NUMBER> 4360 </NUMBER>
<ORDER>   AAG9330103 </ORDER>
<TITLE>   INFORMATION FUSION IN VISUAL RECONSTRUCTION AND RECOGNITION </TITLE>
<AUTHOR>   RAJAPAKSE, JAGATH CHANDANA </AUTHOR>
<YEAR>   1993 </YEAR>
<INSTITUTION>   STATE UNIVERSITY OF NEW YORK AT BUFFALO; 0656 </INSTITUTION>
<DESCRIPTORS>   ENGINEERING, ELECTRONICS AND ELECTRICAL; COMPUTER SCIENCE; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER>   RAJ ACHARYA </ADVISER>
<CLASSIFICATIONS>   RECONSTRUCTION FUSION, NEURAL NETWORKS </CLASSIFICATIONS>
<ABSTRACT>
One of the reasons for the power in human vision system
is its ability to combine information from different
visual processes. Fusion of visual information of
multiple visual sensors can resolve some of the unsolved
complex computer vision problems. The thesis
investigates the problem of information fusion in visual
reconstruction, and visual recognition. In
reconstruction fusion, the reconstruction of a single
sensor information is improved by the information of
other sensors, and in recognition fusion, the
recognition of patterns is contributed by the
information from other multiple sensors.
Regularization techniques have been developed to
reconstruct visual data consisting of discontinuities.
Rotational symmetric continuity stabilizers have been
utilized as continuity stabilizers for visual
reconstruction. These stabilizers often result in
oversmooth solution, and it has been difficult to make a
compromise between the discontinuity detection and
smooth reconstruction. To resolve this problem, we
introduce directional stabilizers for visual
reconstruction. 1-D stabilizers are fitted in orthogonal
directions, and bound together to form directional
stabilizers in multidimensional space. With directional
stabilizers, the energy penalties to appear as a step
discontinuity, or a crease discontinuity can be
specified considering the neighborhood of the
discontinuity. This facilitates the extension of
regularization approach to information fusion in visual
reconstruction.
A class of neural networks, which self-organizes to
recognize visual discontinuity patterns is considered.
This includes both neocognitron and MARA. These networks
are hierarchical. The cells at the lower level of the
hierarchy self-organize to recognize simple features and
the cells at the higher level self-organize to recognize
complex patterns which are combinations of low level
features. We propose a neuromorphic model for fusion of
activities in such networks processing the information
relating to the same visual pattern. The fusion process
increases the recognition ability and the reliability of
the networks.
</ABSTRACT>
</THESIS>
<THESIS>
<NUMBER> 4361 </NUMBER>
<ORDER>   AAG9329597 </ORDER>
<TITLE>   LEARNING OBJECT RECOGNITION STRATEGIES </TITLE>
<AUTHOR>   DRAPER, BRUCE ANTHONY </AUTHOR>
<YEAR>   1993 </YEAR>
<INSTITUTION>   UNIVERSITY OF MASSACHUSETTS; 0118 </INSTITUTION>
<DESCRIPTORS>   COMPUTER SCIENCE; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER>   EDWARD M. RISEMAN </ADVISER>
<CLASSIFICATIONS>   COMPUTER VISION, MACHINE LEARNING </CLASSIFICATIONS>
<ABSTRACT>
Most knowledge-directed vision systems recognize objects
by the use of hand-crafted, heuristic control
strategies. Generally, the programmer or knowledge
engineer who constructs them begins with an intuitive
notion of how an object should be recognized, a notion
that is laboriously refined by trial-and-error.
Eventually the programmer finds a combination of
features (e.g. shape, color, or context) and methods
(e.g. geometric model matching, minimum-distance
classification or generalized Hough transforms) that
allow each object to be reliably identified within its
domain.
Unfortunately, human engineering is not cost-effective
for many real-world applications, a defect that has
relegated most knowledge-directed visions systems to the
laboratory. Knowledge-directed systems also tend to be
difficult to analyze, since their performance, in terms
of cost, accuracy, and reliability, is unknown, and
comparisons to other hand-crafted systems are difficult
at best. Worst of all, when the domain is changed,
knowledge-directed systems often have to be rebuilt from
scratch.
The Schema Learning System (SLS) addresses these
problems by learning knowledge-directed recognition
strategies under supervision. More precisely, SLS learns
its recognition strategies from training images (with
solutions) and a library of generic visual procedures.
The result is a system that develops robust and
efficient recognition strategies with a minimum of human
involvement, and that analyzes the strategies it learns
to estimate both their expected cost and probability of
failure.
In order to represent strategies, recognition is modeled
in SLS as a sequence of small verification tasks
interleaved with representational transformations. At
each level of representation, features of a
representational instance, called a hypothesis, are
measured in order to verify or reject the hypothesis.
Hypotheses that are verified (or, more accurately, not
rejected) are then transformed to a more abstract level
of representation, where features of the new
representation are measured and the process repeats
itself. The recognition graphs learned by SLS are
executable recognition graphs capable of recognizing the
3D locations and orientations of objects in complex
scenes.
</ABSTRACT>
</THESIS>
<THESIS>
<NUMBER> 4362 </NUMBER>
<ORDER>   AAG9329570 </ORDER>
<TITLE>   LOCAL SEARCH ALGORITHMS FOR GEOMETRIC OBJECT RECOGNITION: OPTIMAL CORRESPONDENCE AND POSE </TITLE>
<AUTHOR>   BEVERIDGE, J. ROSS </AUTHOR>
<YEAR>   1993 </YEAR>
<INSTITUTION>   UNIVERSITY OF MASSACHUSETTS; 0118 </INSTITUTION>
<DESCRIPTORS>   COMPUTER SCIENCE; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER>   EDWARD M. RISEMAN </ADVISER>
<CLASSIFICATIONS>   MACHINE VISION </CLASSIFICATIONS>
<ABSTRACT>
Recognizing an object by its shape is a fundamental
problem in computer vision, and typically involves
finding a discrete correspondence between object model
and image features as well as the pose--position and
orientation--of the camera relative to the object. This
thesis presents new algorithms for finding the optimal
correspondence and pose of a rigid 3D object. They
utilize new techniques for evaluating geometric matches
and for searching the combinatorial space of possible
matches. An efficient closed-form technique for
computing pose under weak-perspective (four parameter 2D
affine) is presented, and an iterative non-linear 3D
pose algorithm is used to support matching under full 3D
perspective.
A match error ranks matches by summing a fit error,
which measures the quality of the spatial fit between
corresponding line segments forming an object model and
line segments extracted from an image, and an omission
error, which penalizes matches which leave portions of
the model omitted or unmatched. Inclusion of omission is
crucial to success when matching to corrupted and
partial image data.
New optimal matching algorithms use a form of
combinatorial optimization called local search, which
relies on iterative improvement and random sampling to
probabilistically find globally optimal matches. A novel
variant has been developed, subset-convergent local
search finds optimal matches with high probability on
problems known to be difficult for other techniques.
Specifically, it does well on a test suite of highly
fragmented and cluttered data, symmetric object models,
and multiple model instances. Problem search spaces
grows exponentially in the number of potentially paired
features n, yet empirical performance suggests
computation is bounded by $nsp2.$
Using the 3D pose algorithm during matching, local
search solves problems involving significant amounts of
3D perspective. No previous work on geometric matching
has generalized in this way. Our hybrid algorithm
combines the closed-form weak-perspective pose and
iterative 3D pose algorithms to efficiently solve
matching problems involving perspective. For robot
navigation, this algorithm recognizes 3D landmarks, and
thereby permits a mobile robot to successfully update
its estimated pose relative to these landmarks.
</ABSTRACT>
</THESIS>
<THESIS>
<NUMBER> 4363 </NUMBER>
<ORDER>   AAG9328667 </ORDER>
<TITLE>   SYNTHESIS OF VISION-BASED ROBOT CALIBRATION USING MOVING CAMERAS </TITLE>
<AUTHOR>   WANG, KUANCHIH </AUTHOR>
<YEAR>   1993 </YEAR>
<INSTITUTION>   FLORIDA ATLANTIC UNIVERSITY; 0119 </INSTITUTION>
<DESCRIPTORS>   ENGINEERING, ELECTRONICS AND ELECTRICAL; ENGINEERING, INDUSTRIAL; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER>   ZVI S. ROTH; HANQI ZHUANG </ADVISER>
<CLASSIFICATIONS>   NIL </CLASSIFICATIONS>
<ABSTRACT>
Robot calibration using a vision system and moving
cameras is the focus of this dissertation. The
dissertation contributes in the areas of robot modeling,
kinematic identification and calibration measurement.
The effects of perspective distortion of circular camera
calibration points is analyzed. A new modified complete
and parametrically continuous robot kinematic model, an
evolution of the complete and parametrically continuous
(CPC) model, is proposed. It is shown that the model's
error-model can be developed easily as the structure of
this new model is very simple and similar to the Denavit-
Hartenbert model. The derivation procedure of the error-
model follows a systematic method that can be applied to
any kind of robot arms.
Pose measurement is the most crucial step in robot
calibration. The use of stereo as well as mono mobile
camera measurement system for collection of pose data of
the robot end-effector is investigated. The Simulated
Annealing technique is applied to the problem of optimal
measurement configuration selection. Joint travel limits
can be included in the cost function. It is shown that
trapping into local minimum points can be effectively
avoided by properly choosing an initial point and a
temperature schedule.
The concept of simultaneous calibration of camera and
robot is developed and implemented as an automated
process that determines the system model parameters
using only the system's internal sensors. This process
uses a unified mathematical model for the entire
robot/camera system.
The results of the kinematic identification, optimal
configuration selection, and simultaneous calibration of
robot and camera using the PUMA 560 robot arm have
demonstrated that the modified complete and
parametrically continuous model is a viable and simple
modeling tool, which can achieve desired accuracy. The
systematic way of modeling and performing of different
kinds of vision-based robot applications demonstrated in
this dissertation will pave the way for industrial
standardizing of robot calibration done by the robot
user on the manufacturing floor.
</ABSTRACT>
</THESIS>
<THESIS>
<NUMBER> 4364 </NUMBER>
<ORDER>   AAG9327036 </ORDER>
<TITLE>   EMBEDDINGS IN PARALLEL SYSTEMS </TITLE>
<AUTHOR>   KWON, YOUNGGEUN </AUTHOR>
<YEAR>   1993 </YEAR>
<INSTITUTION>   OREGON STATE UNIVERSITY; 0172 </INSTITUTION>
<DESCRIPTORS>   COMPUTER SCIENCE; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER>   BELLA BOSE </ADVISER>
<CLASSIFICATIONS>   RING STRUCTURED NETWORKS </CLASSIFICATIONS>
<ABSTRACT>
The embedding of butterfly-like graphs into Banyan-
Hypercube networks is studied. The butterfly-like
structures, considered here are the FFT, butterfly (wrap-
around FFT), and the CCC (cube-connected cycle). Our
embedding finds that the FFT graph, and CCC are the
subgraphs of the smallest Banyan-Hypercubes which are
big enough to hold them.
Further, embedding of ring structured networks on Banyan-
Hypercubes network is studied. The ring structures,
considered here are the regular rings, X-trees, Chordal
rings, and Torus. In many cases, it is shown that the
dilation of these embeddings is one. In the case where
dilation is two, we show that the embedding is optimal
in terms of the average dilation.
The topological properties of k-ary n-cube such as
diameter, average distance, connectivity, recursive
decomposibility, node-symmetry, and the number of node-
disjoint paths between two nodes are also investigated.
In addition, the embedding of rings in the k-ary n-cube
is investigated. Our embedding finds that a ring with n
nodes, k$sp{rm p-1}$ $<$ n $le$ k$sp{rm p}$, can be
embedded into a k-ary p-cube with dilation 1 between any
two adjacent nodes if k is odd. In the case of k being
even, a ring with n nodes, k$sp{rm p-1}$ $<$ n $le$
k$sp{rm p}$ can be embedded into a k-ary p-cube with
dilation 2 if n is odd, and with dilation 1 if n is
even.
The embedding of a Hamiltonian cycle in the presence of
edge faults in the k-ary n-cube is also studied. Our
embedding shows that there exists a Hamiltonian cycle in
any direction in the k-ary n-cube with 2n - 2 edge
faults, such that the Hamiltonian cycle includes any
particular nonfaulty edge in that direction; A
Hamiltonian cycle in the k-ary n-cube is said to be
dominant in the dimension i, 0 $le$ i $le$ n - 1 if the
number of edges, not of dimension i in the k-ary n-cube
used in the Hamiltonian cycle is less than or equal to 2
(k$sp{rm n-1}$ - 1). It is also shown that there exists
a dominant Hamiltonian cycle in the k-ary n-cube with 4n
- 5 edge faults, provided that each node is incident to
at least two nonfaulty links. These results are shown to
be optimal in the sense that if more than this number of
edge faults occur, it may not be possible to construct a
Hamiltonian cycle. (Abstract shortened by UMI.)
</ABSTRACT>
</THESIS>
<THESIS>
<NUMBER> 4365 </NUMBER>
<ORDER>   AAG9325705 </ORDER>
<TITLE>   ASSOCIATIVE PROCESS PLANNING: APPLYING ARTIFICIAL NEURAL NETWORKS IN COMPUTER AIDED PROCESS PLANNING </TITLE>
<AUTHOR>   HUFFMAN, JOHN EUGENE </AUTHOR>
<YEAR>   1993 </YEAR>
<INSTITUTION>   WICHITA STATE UNIVERSITY; 0260 </INSTITUTION>
<DESCRIPTORS>   ENGINEERING, INDUSTRIAL; OPERATIONS RESEARCH; COMPUTER SCIENCE; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER>   DONALD L. HOMMERTZHEIM </ADVISER>
<CLASSIFICATIONS>   NIL </CLASSIFICATIONS>
<ABSTRACT>
Knowledge-based computer aided process planning systems
have improved the process planning function in many
industries. There remains some cognitive information
processing tasks that are deficient in these systems. An
approach that incorporates the associative reasoning
capability of artificial neural networks is presented.
This approach, called associative process planning, is
based on a methodology for computer aided process
planning and a taxonomy for the cognitive information
processing tasks within these systems. A comparison of
applications using knowledge-based systems and
artificial neural networks within the associative
process planning approach indicates that artificial
neural networks can significantly improve the
associative memory and adaptive capacity of computer
aided process planning systems.
</ABSTRACT>
</THESIS>
<THESIS>
<NUMBER> 4366 </NUMBER>
<ORDER>   AAG9320883 </ORDER>
<TITLE>   KNOWLEDGE-BASED ARTIFICIAL NEURAL NETWORKS FOR PROCESS MODELLING AND CONTROL </TITLE>
<AUTHOR>   SCOTT, GARY M. </AUTHOR>
<YEAR>   1993 </YEAR>
<INSTITUTION>   THE UNIVERSITY OF WISCONSIN - MADISON; 0262 </INSTITUTION>
<DESCRIPTORS>   ENGINEERING, CHEMICAL; COMPUTER SCIENCE; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER>   W. HARMON RAY </ADVISER>
<CLASSIFICATIONS>   NEURAL NETWORKS, ARTIFICIAL NEURAL NETWORKS </CLASSIFICATIONS>
<ABSTRACT>
Artificial Neural Networks (ANNs) are a rapidly growing
facet of Artificial Intelligence which uses a collection
of simple processing units that are massively
interconnected in order to produce meaningful behavior.
This report applies ANNs to the tasks of process
modelling and process control. ANNs are found to be
particularly applicable in modelling the nonlinear
behavior of systems. Also, since ANNs learn from
examples rather than being programmed, they are useful
when there is a great deal of data available, but where
a physical model cannot easily be found. This report
introduces the components and the learning aspects of
artificial neural networks as well as briefly discussing
a methodology for ANN application development and the
interpretation of trained networks.
In the field of process modelling, knowledge-based ANNs
were used to successfully model a CSTR containing a
first-order chemical reaction. In modelling this system,
a linear model, in the form of a transfer function
matrix, was used to determine the architecture and
initial conditions of the network, which was
subsequently trained using the backpropagation learning
algorithm. The technique was successful in modelling
systems that showed strong parametric sensitivity,
oscillations, and multiple steady states. Finally, an
interpretation technique that recovers locally linear
models was also developed.
In the field of process control, three design techniques
were investigated. In the first technique, the network
was structured and initialized using a traditional
paradigm, this time in the form of a PID controller.
Also investigated was the use of the knowledge-based ANN
models in model-based controllers. ANN models were
incorporated in the Direct Synthesis Control (DSC), the
Internal Model Control (IMC) and the Generalized, Multi-
delay Compensator (GMDC) designs. Finally, a ANN-based
supervisory controller is described in which the tuning
parameters of a PI controller are determined from a
knowledge-based ANN model of the process.
</ABSTRACT>
</THESIS>
<THESIS>
<NUMBER> 4367 </NUMBER>
<ORDER>   AAG9319029 </ORDER>
<TITLE>   RECOGNITION OF QUADRIC SURFACES FROM RANGE DATA: AN ANALYTICAL APPROACH </TITLE>
<AUTHOR>   D'CUNHA, IVAN XAVIER DIAMON </AUTHOR>
<YEAR>   1993 </YEAR>
<INSTITUTION>   OLD DOMINION UNIVERSITY; 0418 </INSTITUTION>
<DESCRIPTORS>   ENGINEERING, ELECTRONICS AND ELECTRICAL; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER>   NICOLAS ALVERTOS </ADVISER>
<CLASSIFICATIONS>   NIL </CLASSIFICATIONS>
<ABSTRACT>
In this dissertation, a new technique based on analytic
geometry for the recognition and description of three-
dimensional quadric surfaces from range images is
presented. Beginning with the explicit representation of
quadrics, a set of ten coefficients are determined for
various three-dimensional surfaces. For each quadric
surface, a unique set of two-dimensional curves which
serve as a feature set is obtained from the various
angles at which the object is intersected with a plane.
Based on a discriminant method, each of the curves is
classified as a parabola, circle, ellipse, hyperbola, or
a line. Each quadric surface is shown to be uniquely
characterized by a set of these two-dimensional curves,
thus allowing discrimination from the others.
Before the recognition process can be implemented, the
range data have to undergo a set of pre-processing
operations, thereby making it more presentable to
classification algorithms. One such pre-processing step
is to study the effect of median filtering on raw range
images. Utilizing a variety of surface curvature
techniques, reliable sets of image data that approximate
the shape of a quadric surface are determined. Since the
initial orientation of the surfaces is unknown, a new
technique is developed wherein all the rotation
parameters are determined and subsequently eliminated.
This approach enables us to position the quadric
surfaces in a desired coordinate system.
Experiments were conducted on raw range images of
spheres, cylinders, and cones. Experiments were also
performed on simulated data for surfaces such as
hyperboloids of one and two sheets, elliptical and
hyperbolic paraboloids, elliptical and hyperbolic
cylinders, ellipsoids and the quadric cones. Both the
real and simulated data yielded excellent results. Our
approach is found to be more accurate and
computationally inexpensive as compared to traditional
approaches, such as the three-dimensional discriminant
approach which involves evaluation of the rank of a
matrix.
Finally, we have proposed one other new approach, which
involves the formulation of a mapping between the
explicit and implicit forms of representing quadric
surfaces. This approach, when fully realized, will yield
a three-dimensional discriminant, which will recognize
quadric surfaces based upon their component surface
patches. This approach is faster than prior approaches
and at the same time is invariant to pose and
orientation of the surfaces in three-dimensional space.
(Abstract shortened by UMI.)
</ABSTRACT>
</THESIS>
<THESIS>
<NUMBER> 4368 </NUMBER>
<ORDER>   AAG0573792 </ORDER>
<TITLE>   SPECIALIZATION OF PERCEPTUAL PROCESSES </TITLE>
<AUTHOR>   HORSWILL, IAN D. </AUTHOR>
<YEAR>   1993 </YEAR>
<INSTITUTION>   MASSACHUSETTS INSTITUTE OF TECHNOLOGY; 0753 </INSTITUTION>
<DESCRIPTORS>   COMPUTER SCIENCE; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER>   RODNEY BROOKS; LYNN ANDREA STEIN </ADVISER>
<CLASSIFICATIONS>   VISION SYSTEMS, MOBILE ROBOT </CLASSIFICATIONS>
<ABSTRACT>
In this dissertation, I will discuss the use of vision
to support concrete, everyday activity. I will argue
that a variety of interesting tasks can be solved using
simple and inexpensive vision systems. I will provide a
number of working examples in the form of a state-of-the-
art mobile robot, Polly, which uses vision to give
primitive tours of the seventh floor of the MIT AI
Laboratory. By current standards, the robot has a broad
behavioral repertoire and is both simple and inexpensive
(the complete robot was built for less than $20,000
using commercial board-level components).
The approach I will use will be to treat the structure
of the agent's activity--its task and environment--as
positive resources for the vision system designer. By
performing a careful analysis of task and environment,
the designer can determine a broad space of mechanisms
which can perform the desired activity. My principal
thesis is that for a broad range of activities, the
space of applicable mechanisms will be broad enough to
include a number mechanisms which are simple and
economical.
The simplest mechanisms that solve a given problem will
typically be quite specialized to that problem. One thus
worries that building simple vision systems will be
require a great deal of ad-hoc engineering that cannot
be transferred to other problems. My second thesis is
that specialized systems can be analyzed and understood
in a principled manner, one that allows general lessons
to be extracted from specialized systems. I will present
a general approach to analyzing specialization through
the use of transformations that probably improve
performance. By demonstrating a sequence of
transformations that derive a specialized system from a
more general one, we can summarize the specialization of
the former in a compact form that makes explicit the
additional assumptions that it makes about its
environment. The summary can be used to predict the
performance of the system in novel environments.
Individual transformations can be recycled in the design
of future systems. (Copies available exclusively from
MIT Libraries, Rm. 14-0551, Cambridge, MA 02139-4307.
Ph. 617-253-5668; Fax 617-253-1690.)
</ABSTRACT>
</THESIS>
<THESIS>
<NUMBER> 4369 </NUMBER>
<ORDER>   AAG0573791 </ORDER>
<TITLE>   THE ROLE OF CHEMICAL MECHANISMS IN NEURAL COMPUTATION AND LEARNING </TITLE>
<AUTHOR>   HILLER, MARTHA JEAN </AUTHOR>
<YEAR>   1993 </YEAR>
<INSTITUTION>   MASSACHUSETTS INSTITUTE OF TECHNOLOGY; 0753 </INSTITUTION>
<DESCRIPTORS>   COMPUTER SCIENCE; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER>   RODNEY A. BROOKS </ADVISER>
<CLASSIFICATIONS>   ELECTRICAL TRANSMISSION </CLASSIFICATIONS>
<ABSTRACT>
Most computational models of neurons have assumed that
their electrical characteristics are of paramount
importance. The speed of electrical transmission
relative to most chemical and metabolic processes
combined with the apparently binary nature of action
potentials has biased the field toward neglecting other
aspects of the neural substrate as irrelevant. However,
examples abound in the neuroscience literature in which
chemical mechanisms, slow as they are, serve important
roles in modulating the cell's electrical properties. In
addition to mediating all long-term changes (e.g. the
underlying mechanisms for learning processes), chemical
mechanisms can have short-term effects that modify the
processing of inputs received while those effects last.
Both mechanical and chemical mechanisms also play
important roles in the creation of the brain's
anatomical structure during development, interacting
with electrical mechanisms that determine the detailed
connectivity between neurons.
The topic of this dissertation is the interaction
between electrical and chemical mechanisms in neural
processing, especially as they relate to learning and
development. The emphasis on learning recognizes the
prevalence of plasticity at all levels in the brain, and
its central role in the establishment of the brain's
structure and function.
My central thesis is that chemical mechanisms must be
taken into account if we are to build accurate models of
neural computation. To demonstrate their role, two
neural systems are modelled in some detail. The first is
a circuit controlling the gill withdrawal reflex in
Aplysia, a marine snail. This circuit has been
extensively studied to elucidate the mechanisms
underlying observed habituation, sensitization, and
associative learning in the reflex. These mechanisms
display an intricate interaction between electrical
conductances and chemical processes inside the synaptic
terminals.
The second simulation models the formation of ordered
topographic connections between different structures in
the early visual pathway. These connections form over
long distances, and initially they are highly
disordered. The process of sorting the axonal
projections to produce a detailed topographic
correspondence between the retinal image and the images
projected on other visual structures also makes use of a
combination of chemical and electrical mechanisms. The
behavior of individual neurons is simplified in this
model so that their interactions in networks can be
studied; however, some care is taken to remain
compatible with experimental results and with what is
known about the biological mechanisms. (Copies available
exclusively from MIT Libraries, Rm. 14-0551, Cambridge,
MA 02139-4307. Ph. 617-253-5668; Fax 617-253-1690.)
</ABSTRACT>
</THESIS>
<THESIS>
<NUMBER> 4370 </NUMBER>
<ORDER>   AAG0573314 </ORDER>
<TITLE>   DATA-DRIVEN LEARNING FRAMEWORKS FOR CONTINUOUS PROCESS ANALYSIS AND IMPROVEMENT </TITLE>
<AUTHOR>   SARAIVA, PEDRO MANUEL TAVARES LOPES ANDRADE </AUTHOR>
<YEAR>   1993 </YEAR>
<INSTITUTION>   MASSACHUSETTS INSTITUTE OF TECHNOLOGY; 0753 </INSTITUTION>
<DESCRIPTORS>   ENGINEERING, CHEMICAL; OPERATIONS RESEARCH; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER>   NIL </ADVISER>
<CLASSIFICATIONS>   NIL </CLASSIFICATIONS>
<ABSTRACT>
This thesis revisits an old problem, which consists of
exploring the information contained in a set of (x,y)
operation data records and learn from it how to improve
y performance by taking decisions on the x space. Our
primary target is the analysis at the supervisory
control level of (x,y) data generated by systems that
can not be described effectively through first
principles models, and whose performance depends to a
large extent on quality related issues and measurements.
Modified statements and solution formats for the above
problem are introduced, with hyperrectangles in the
decision space replacing the conventional pointwise
results. The advantages and implications of adopting
this alternative language to express final solutions are
discussed, and it is also shown that traditional
formulations can be interpreted as a particular
degenerate case of the suggested more general problem
definitions, where one searches for ranges of decision
variables rather than single values.
Data-driven nonparametric learning methodologies, based
on direct sampling approaches and machine learning
techniques, are described. They require far fewer
assumptions and a priori decisions on the part of the
user than most conventional techniques. These practical
frameworks for extracting knowledge from operation data
present the final uncovered solutions to the decision-
maker in formats that are both easy to understand and
implement, leading to continuous improvement of process
operations.
I will also discuss and analyze extensions/variations of
the basic learning methodologies, aimed at enlarging
their scope and cover a number of different situations,
including systems where performance is evaluated by
categorical or continuous y variables, with single or
multiple objectives, simple or complex plants containing
some type of internal structure and composed of a number
of interconnected subsystems.
Rather than automating the decision-making process, the
goal of our methodologies is to provide as much support
as possible to the user, who is kept in the loop,
responsible for the analysis of a final set of uncovered
solutions presented to him/her, choosing one alternative
among them, and selecting the course of action to
follow.
The potential practical capabilities of the described
learning methodologies are illustrated through the
presentation of a series of case studies with both real-
world industrial and simulated operating data, including
a CSTR, an activated sludge wastewater treatment plant,
a refinery unit, a plasma etching reactor, a Kamyr
digester and a pulp plant. (Copies available exclusively
from MIT Libraries, Rm. 14-0551, Cambridge, MA 02139-
4307. Ph. 617-253-5668; Fax 617-253-1690.) (Abstract
shortened by UMI.)
</ABSTRACT>
</THESIS>
<THESIS>
<NUMBER> 4371 </NUMBER>
<ORDER>   AAG0573240 </ORDER>
<TITLE>   STABLE ADAPTIVE CONTROL AND RECURSIVE IDENTIFICATION OF NONLINEARSYSTEMS USING RADIAL GAUSSIAN NETWORKS </TITLE>
<AUTHOR>   SANNER, ROBERT MICHAEL </AUTHOR>
<YEAR>   1993 </YEAR>
<INSTITUTION>   MASSACHUSETTS INSTITUTE OF TECHNOLOGY; 0753 </INSTITUTION>
<DESCRIPTORS>   ENGINEERING, GENERAL; ENGINEERING, MECHANICAL; ARTIFICIAL INTELLIGENCE; COMPUTER SCIENCE </DESCRIPTORS>
<ADVISER>   JEAN-JACQUES E. SLOTINE </ADVISER>
<CLASSIFICATIONS>   NIL </CLASSIFICATIONS>
<ABSTRACT>
Massively parallel arrays of simple processing elements,
the so-called feedforward "neural" network
models, can be used to greatly enhance and extend
techniques for identification and control of complex,
nonlinear dynamical systems. However, the design of
practical algorithms capable of ensuring prespecified
performance levels requires a comprehensive, cross-
disciplinary treatment, drawing techniques and insights
from such diverse fields as machine learning,
constructive approximation, nonlinear dynamical
stability, and robust systems analysis. This thesis
presents a methodology for assembling all of these
elements into an integrated and systematic framework,
developing both constructive neural network analysis and
synthesis methods, as well as algorithms for adaptive
nonlinear prediction and control with guaranteed levels
of performance.
The possible instability mechanisms underlying neural
network applications are first diagnosed, and the
methods for avoiding them found to depend upon an
ability to quantify the uniform approximation capability
of the chosen network architecture. To provide this
characterization sampling theory is used to develop a
constructive theory of radial Gaussian networks,
precisely quantifying the impact of each component on
the quality of the approximation. The approximation
error bounds provided by these constructions are then
used with robust adaptation mechanisms to produce stable
recursive identifiers whose asymptotic prediction
capabilities are limited only by the approximating
capability of the networks used. Moreover, use of radial
basis function networks for these applications allows
specification of conditions which must be satisfied by
the signals input to the network to ensure that the
adaptation mechanism is persistently excited.
Robust adaptive techniques are insufficient in a control
application to accommodate the inexact parameterization
provided by a network; the control law itself must also
be made robust. By smoothly combining sliding control
with an adaptive feedback linearization algorithm, in
which Gaussian networks adaptively cancel the natural
nonlinear dynamics of the plant, a class of stable,
convergent direct adaptive controllers is developed.
This blended control strategy is then combined with a
robust version of classical adaptive robot control
algorithms to create stable direct adaptive control laws
for a class of multivariable nonlinear systems
controlled by neural networks. (Copies available
exclusively from MIT Libraries, Rm. 14-0551, Cambridge,
MA 02139-4307. Ph. 617-253-5668; Fax 617-253-1690.)
</ABSTRACT>
</THESIS>
<THESIS>
<NUMBER> 4372 </NUMBER>
<ORDER>   AAG9331728 </ORDER>
<TITLE>   EXPERTS LEARNING: PROBLEM-SOLVING IN A SIMULATED ENVIRONMENT </TITLE>
<AUTHOR>   RABINOWITZ, LOUIS OWEN </AUTHOR>
<YEAR>   1993 </YEAR>
<INSTITUTION>   THE UNIVERSITY OF TENNESSEE; 0226 </INSTITUTION>
<DESCRIPTORS>   EDUCATION, ADULT AND CONTINUING; EDUCATION, TECHNOLOGY; EDUCATION, VOCATIONAL; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER>   JOHN M. PETERS </ADVISER>
<CLASSIFICATIONS>   NIL </CLASSIFICATIONS>
<ABSTRACT>
The purpose of this study was to show that, by
critically reflecting on one's own knowledge base and
the knowledge base of another in a simulated
environment, an expert can learn new ways for solving
problems in his domain of expertise. The simulated
environment used for this study consisted of both an
expert system and hypertext program. The method employed
in this research was qualitative and was largely
dependent on the phenomenological understanding of two
subjects' experiences in solving problems. An interview
and analysis method known as the Action-Reason Thematic
Technique (ARTT) was central to the research and was
used to acquire and analyze interview transcripts of the
subjects.
By an examination of three types of rules that were
identified from the subjects' acquired knowledge bases,
it was determined that the subjects did, in fact, add
to, delete from, or otherwise modify their knowledge
bases indicating that learning took place.
</ABSTRACT>
</THESIS>
<THESIS>
<NUMBER> 4373 </NUMBER>
<ORDER>   AAG9329803 </ORDER>
<TITLE>   USE OF A GROUP SUPPORT SYSTEM TO ELICIT KNOWLEDGE ABOUT CORPORATE REAL ESTATE DISPOSITION FROM MULTIPLE EXPERTS </TITLE>
<AUTHOR>   LIPP, ASTRID </AUTHOR>
<YEAR>   1993 </YEAR>
<INSTITUTION>   UNIVERSITY OF GEORGIA; 0077 </INSTITUTION>
<DESCRIPTORS>   BUSINESS ADMINISTRATION, MANAGEMENT; COMPUTER SCIENCE; INFORMATION SCIENCE; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER>   HUGH J. WATSON </ADVISER>
<CLASSIFICATIONS>   NIL </CLASSIFICATIONS>
<ABSTRACT>
Knowledge acquisition has been recognized as a major
bottleneck in building expert systems. Additional
difficulties must be overcome when multiple experts
provide the knowledge for a knowledge-based system.
Although the group support system called Plexsys (now
called GroupSystems) has been successfully used to
elicit knowledge from multiple Help Desk experts to
build the expert system known as ICE/H, additional
investigation was required to determine to what extent
the results obtained in building ICE/H could be
generalized to other domains and to experts who are less
comfortable with computers.
This research investigated the effectiveness of a group
support system (GSS) in supporting knowledge acquisition
from experts in corporate real estate disposition. All
experts worked for different organizations. The six
experts who contributed their knowledge met face-to-face
for four knowledge acquisition sessions that were
supported by Plexsys. At the end of every session, the
experts evaluated the effectiveness of the GSS tools
used to assist the group in reaching a consensus about
the knowledge that an expert system for real estate
disposition should contain. Successive versions of a
knowledge-based system called DISPOSITION ADVISOR were
developed after each knowledge acquisition session. The
final version of the expert system prototype was
evaluated by the experts who participated in the
development of the program, other experts in corporate
real estate disposition, real estate managers with some
experience in disposition, and novices.
This research showed that the public screen can be a
useful knowledge acquisition tool when the experts are
not good typists, when the experts have not worked
closely with one another and need to resolve differences
in vocabulary, and when problems in the domain take a
long time to solve. In the latter case, experts can
identify missing information. Evaluation of DISPOSITION
ADVISOR revealed that an expert system for disposition
would be most useful if separate modules are offered for
different types of properties, if the system allows the
user to determine what features of the system he wants
to use, if the system explains its reasoning, and if the
system permits a record of the consultation to be saved
and printed.
</ABSTRACT>
</THESIS>
<THESIS>
<NUMBER> 4374 </NUMBER>
<ORDER>   AAG9324826 </ORDER>
<TITLE>   A COMPARATIVE CASE STUDY OF NEURAL NETWORK ANALYSIS AND STATISTICAL DISCRIMINANT FUNCTION ANALYSIS FOR PREDICTING LAW STUDENTS PASSING THE BAR EXAMINATION </TITLE>
<AUTHOR>   WHEELER, M. CANDACE </AUTHOR>
<YEAR>   1993 </YEAR>
<INSTITUTION>   GONZAGA UNIVERSITY; 0736 </INSTITUTION>
<DESCRIPTORS>   EDUCATION, TECHNOLOGY; COMPUTER SCIENCE; STATISTICS; ARTIFICIAL INTELLIGENCE; EDUCATION, TESTS AND MEASUREMENTS </DESCRIPTORS>
<ADVISER>   SANDRA M. WILSON </ADVISER>
<CLASSIFICATIONS>   NIL </CLASSIFICATIONS>
<ABSTRACT>
The purpose of this study was to compare the predictive
accuracy of the discriminant function analysis to the
predictive accuracy of a neural network analysis using
data from graduates of a law school in the Northwest.
There were four research questions explored by this
study. The first question explored if there was a
significant difference between the discriminant function
analysis method and the neural network analysis method
in rate of accuracy in predicting graduates' success in
passing a bar examination. Neural network analysis was
more accurate than discriminant analysis. The difference
between the two accuracy rates appears not to have
occurred by chance.
The second research question analyzed if there was a
significant difference between the discriminate analysis
and the neural network analysis method in rate of
accuracy in predicting graduates' success in passing a
bar examination. Neural network analysis was more
accurate than discriminant analysis. The difference
between the two accuracy rates appears not to have
occurred by chance.
The second research question analyzed if there was a
significant difference between the discriminate analysis
and the neural network analysis in the rate of accuracy
of predicting graduates' success in passing different
state bar examinations from three geographic locations.
Neural network analysis was more accurate than
discriminant analysis for the three groups; however the
test of significant difference indicated that the
difference could have happened by chance.
The third research question explored if there was a
significant difference between the two methods in
predicting minority graduates' success in passing a bar
examination. Discriminant analysis was more accurate
than neural network analysis in predicting minority
graduates passing a bar, but the test for significant
difference in the proportion revealed that the
difference could have occurred by chance.
The final research question investigated the assumptions
of neural network analysis dealing with the concepts
that: (1) longer training provided more accurate
predictions; (2) a representative test set trained a
more accurate network; (3) and a retrained network was
consistent in its accuracy rate but was based on
different connections. The results of this study support
that longer training does not result in better
predictions, a random training test set provides similar
results as a representative training test set if the
sample set is large, and a retrained network produces
consistent results while based on different connections.
(Abstract shortened by UMI.)
</ABSTRACT>
</THESIS>
<THESIS>
<NUMBER> 4375 </NUMBER>
<ORDER>   AAG9329142 </ORDER>
<TITLE>   INVERSE ENGINEERING: A MACHINE LEARNING APPROACH TO SUPPORT ENGINEERING SYNTHESIS </TITLE>
<AUTHOR>   RAO, R. BHARAT </AUTHOR>
<YEAR>   1993 </YEAR>
<INSTITUTION>   UNIVERSITY OF ILLINOIS AT URBANA-CHAMPAIGN; 0090 </INSTITUTION>
<DESCRIPTORS>   ENGINEERING, ELECTRONICS AND ELECTRICAL; COMPUTER SCIENCE; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER>   STEPHEN C.-Y. LU </ADVISER>
<CLASSIFICATIONS>   LEARNING ALGORITHMS </CLASSIFICATIONS>
<ABSTRACT>
This research presents a knowledge processing
methodology called inverse engineering, that uses
machine learning techniques for early stage design in
parameterized domains. This methodology functions as a
model translator, changing the representation of
analysis knowledge embedded in a unidirectional
simulator, into a multidirectional model that supports
design synthesis. This methodology requires addressing
two issues.
The first is the task of learning models from data in
specified representations. This thesis describes an
empirical learning algorithm called KEDS, the Knowledge-
based Equation Discovery System. The user selects a
restricted hypothesis space bias in the form of a class
of parameterized (polynomial) model families, and KEDS
learns accurate models that are restricted to those
forms. In addition to being a model-driven empirical
discovery system, KEDS is also a conceptual clustering
system that partitions the problem domain based upon the
relationships that it discovers among the problem
variables. The use of the minimum description length
(MDL) principle as a preference bias for KEDS provides a
foundation for learning the "best" models
(i.e., those that minimize predictive error on unseen
data). KEDS has been applied to model three real-world
domains: a diesel engine combustion chamber, a CMOS
circuit for an operational amplifier, and a turning
process on a lathe.
The second issue is that of supporting early stage
design. Current computer-aided methods for product and
process design require the iterative use of computer-
based analysis models in a generate-and-test fashion.
While this process is essential to optimize performance
during the final stages of design, it has a number of
disadvantages during early design. By restricting the
models families used by KEDS to forms that can provide
synthesis support (hyperplanes), the user can learn a
multidirectional model. The user can use this model to
propagate constraints in the analysis as well as the
synthesis direction. This avoids the time-consuming
traditional procedure of iteratively using analysis
models to support synthesis. Further this
multidirectional model provides the user with great
flexibility during early stage design, and the valuable
ability to perform "What-if?" analysis. The
inverse engineering methodology has been successfully
applied to learn models to support early product design
of combustion chambers for diesel engines, and to
support process design for a turning machine.
</ABSTRACT>
</THESIS>
<THESIS>
<NUMBER> 4376 </NUMBER>
<ORDER>   AAG9329098 </ORDER>
<TITLE>   A KNOWLEDGE-BASED MACHINE VISION SYSTEM FOR GRAIN QUALITY INSPECTION </TITLE>
<AUTHOR>   LIAO, KE </AUTHOR>
<YEAR>   1993 </YEAR>
<INSTITUTION>   UNIVERSITY OF ILLINOIS AT URBANA-CHAMPAIGN; 0090 </INSTITUTION>
<DESCRIPTORS>   ENGINEERING, AGRICULTURAL; AGRICULTURE, FOOD SCIENCE AND TECHNOLOGY; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER>   MARVIN R. PAULSEN </ADVISER>
<CLASSIFICATIONS>   NEURAL NETWORKS </CLASSIFICATIONS>
<ABSTRACT>
A knowledge-based machine vision system was developed
for automatic corn quality inspection. This system
consisted of a primitive feature extraction algorithm,
several quality-related feature extraction algorithms,
and several knowledge-based corn quality inspection
algorithms. The feature extraction and corn quality
inspection algorithms were developed and their
performance evaluated.
The primitive feature extraction algorithm was developed
using on-board hardware-based operations. The primitive
features were computed in a processing time of less than
one second for one object. The quality-related feature
extraction algorithms were developed based on the
results of the primitive feature extraction algorithm. A
geometric dimension measurement algorithm was evaluated.
An average color measurement algorithm was used to
separate white and yellow corn varieties. The processing
time was about 1.3 seconds.
The knowledge-based quality inspection algorithms were
developed by training with pre-classified corn samples
using knowledge acquisition algorithms. The pericarp
damage inspection algorithm provided a successful
classification of 95, 80, and 93% for negligible, minor,
and severe damage, respectively. The processing time for
the pericarp damage inspection program was about 1.0 to
2.5 seconds.
A Fourier profile-based kernel breakage inspection
algorithm had an accuracy of 95% for classifying whole
kernels as whole and 96% for classifying broken kernels
as broken. The processing time of the breakage
inspection program was about 1.5 seconds.
A morphological, curvature/symmetry, profile-based
kernel breakage inspection algorithm provided a
successful classification of 94 and 95% for whole and
broken kernels. The processing time for the
classification required about 1.5 seconds from grabbing
the live image to the final classification result. The
software-based neural network classifier required about
0.2 second of the 1.5 second total time.
The RGB and multispectral image-based color
discrimination algorithms were also developed and
evaluated by separating the color regions of vitreous
endosperm, floury endosperm, germ, and red streak areas
on white and on yellow corn. The color discrimination
functions provided a successful off-line classification
rate from 90 to 100% for the color regions of white and
yellow corn kernels. The six-band multispectral images
recovered more information about the variation of the
spectral reflectance of corn kernels than the standard
RGB images.
</ABSTRACT>
</THESIS>
<THESIS>
<NUMBER> 4377 </NUMBER>
<ORDER>   AAG9328958 </ORDER>
<TITLE>   ON THE LEARNABILITY OF DISJUNCTIVE NORMAL FORM FORMULAS AND DECISION TREES </TITLE>
<AUTHOR>   AIZENSTEIN, HOWARD JAY </AUTHOR>
<YEAR>   1993 </YEAR>
<INSTITUTION>   UNIVERSITY OF ILLINOIS AT URBANA-CHAMPAIGN; 0090 </INSTITUTION>
<DESCRIPTORS>   COMPUTER SCIENCE; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER>   L. PITT </ADVISER>
<CLASSIFICATIONS>   MACHINE LEARNING </CLASSIFICATIONS>
<ABSTRACT>
The learnability of disjunctive normal form formulas and
decision trees is investigated. Polynomial time
algorithms are given, and nonlearnability results are
obtained, for restricted versions of these general
learning problems.
Polynomial time algorithms are presented for exactly
learning (with membership and equivalence queries) read-
twice DNF and read-k-disjoint DNF. A read-twice DNF
formula is a boolean formula in disjunctive normal form
where each variable appears at most twice. A read-k
disjoint DNF formula f is a DNF formula where each
variable appears at most k times (for an arbitrary
positive integer k) and every assignment to the
variables satisfies at most one term of f. The read-k
disjoint DNF result also applies for a generalization of
this class, which we call read-k sat-j DNF.
For a similar learning protocol, it is shown that,
assuming NP $not=$ co-NP, there does not exist a
polynomial time algorithm for learning read-thrice DNF
formulas-boolean formulas in disjunctive normal form
where each variable appears at most three times. This
result contrasts with our polynomial time algorithm for
learning read-twice DNF, and adds evidence to the
conjecture that DNF is hard to learn in the membership
and equivalence query model. Nonlearnability results are
also obtained for the class of read-k decision trees. It
is shown that this class is hard to learn in the
membership and equivalence query model, provided that
the equivalence queries are also required to be read-k
decision trees. It is also shown that read-k decision
trees are hard to learn in the PAC model (without
membership queries).
A different type of nonlearnability result is obtained
for the class of arbitrary DNF formulas. A natural
approach for learning DNF formulas (suggested by Valiant
in a seminal paper of learning theory) is to greedily
collect the prime implicants of the hidden function. We
show that no algorithm using such an approach can learn
DNF in polynomial time. Results which suggest that DNF
formulas are hard to learn rely on the construction of
rare hard-to-learn formulas. This raises the question of
whether most DNF formulas are learnable. For certain
natural definitions of most DNF formulas, this question
is answered affirmatively.
</ABSTRACT>
</THESIS>
<THESIS>
<NUMBER> 4378 </NUMBER>
<ORDER>   AAG9328896 </ORDER>
<TITLE>   CAMERA-SPACE MANIPULATION WITH NATURAL VISUAL INFORMATION </TITLE>
<AUTHOR>   KORDE, UMESH ARVIND </AUTHOR>
<YEAR>   1993 </YEAR>
<INSTITUTION>   UNIVERSITY OF NOTRE DAME; 0165 </INSTITUTION>
<DESCRIPTORS>   ENGINEERING, MECHANICAL; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER>   STEVEN B. SKAAR </ADVISER>
<CLASSIFICATIONS>   MACHINE VISION </CLASSIFICATIONS>
<ABSTRACT>
Camera-space manipulation is a precise and robust
approach to robot hand/eye coordination in practical,
three-dimensional situations. The acquisition of visual
information necessary for camera-space manipulation has
so far been simplified by placing easily detectable
visual "cues" on the objects involved in the
task. This work concerns the development of an approach
to speedy and precise extraction of visual information
from "natural" features on the objects.
This approach invokes a symbiosis between the estimation
procedure of camera-space manipulation and image
analysis, in which each procedure builds on
progressively improving information "learned"
by the other, both during a particular cycle of a
repetitive task, and from one task-cycle to the next.
The idea was implemented in a three-dimensional
automobile wheel-loading task, in which the natural
features were circular. The relative locations of video
cameras were such that error-propagation from the
estimation procedure to object positioning would be near
a minimum. The image-analysis procedure developed in
this work could respond to the availability of better
information. Its speed and precision improved
continually with improving accuracy of the estimation
procedure. This procedure can be expected to be more
suitable for camera-space manipulation than methods
based on the Hough transform. Finally, a method to
generalize the approach to tasks involving a class of
features was proposed and tested.
</ABSTRACT>
</THESIS>
<THESIS>
<NUMBER> 4379 </NUMBER>
<ORDER>   AAG9328797 </ORDER>
<TITLE>   COMPUTATIONAL ISSUES OF NONMONOTONIC REASONING </TITLE>
<AUTHOR>   SANDERS, LESLIE KENT </AUTHOR>
<YEAR>   1993 </YEAR>
<INSTITUTION>   TEXAS A&M UNIVERSITY; 0803 </INSTITUTION>
<DESCRIPTORS>   COMPUTER SCIENCE; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER>   DONALD K. FRIESEN </ADVISER>
<CLASSIFICATIONS>   LOGIC SYSTEMS </CLASSIFICATIONS>
<ABSTRACT>
From the earliest days of the modern computer age,
humankind has dreamed of machines that use "common
sense" to reason about the world. However, common
sense as displayed by humans largely consists of
techniques for dealing with the enormous amount of
information provided by the five senses. Since this
information can overwhelm even the human brain, the
brain can only process it effectively in the form of
generalizations and "rules of thumb." Hence,
much of its information is not complete; it only
captures the most general cases. So, despite efforts to
provide vast and thorough knowledge bases, it has become
clear that reasoning machines must have the ability to
model their worlds in the face of incomplete information
about those worlds.
Towards this end, many types of "nonmonotonic"
reasoning techniques have been proposed. Using these
techniques a computer can "change its mind"
about what it believes to be true in the light of new
information. In recent years, nonmonotonic reasoning has
grown to be one of the most widely researched fields in
computer science. Unfortunately, while it is apparent
that this type of reasoning is very complex, little
research has focussed on just how complex it truly is.
More importantly, little is known about what kinds of
restricted forms of nonmonotonic reasoning can be
practically implemented on computers. The research
presented herein is aimed at answering the question,
"Are there computationally prohibitive
characteristics that are part of the nature of
nonmonotonic reasoning?" Perhaps a clearer way to
state this is, "Can any useful form of nonmonotonic
reasoning be automated in an efficient manner?"
The general approach taken in this research is as
follows. First, a semantic model of generalized
nonmonotonic reasoning that lends itself to
computational analysis is developed. Then, a methodology
for using this model to analyze restricted forms of
nonmonotonic reasoning is discussed. Some restricted
classes of nonmonotonic reasoning systems are then
defined and analyzed. Finally, the correctness and
practical importance of this work is demonstrated by
using it to analyze some previous work; in particular,
several classes of "model-preference" default
logic systems are analyzed.
</ABSTRACT>
</THESIS>
<THESIS>
<NUMBER> 4380 </NUMBER>
<ORDER>   AAG9328493 </ORDER>
<TITLE>   A NEURAL NETWORK FOR MOVING OBJECT DETECTION AND TRACKING INSPIRED BY THE FLY VISUAL SYSTEM </TITLE>
<AUTHOR>   MISSLER, JAMES MICHAEL </AUTHOR>
<YEAR>   1993 </YEAR>
<INSTITUTION>   THE UNIVERSITY OF TEXAS AT ARLINGTON; 2502 </INSTITUTION>
<DESCRIPTORS>   COMPUTER SCIENCE; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER>   FARHAD A. KAMANGAR </ADVISER>
<CLASSIFICATIONS>   NIL </CLASSIFICATIONS>
<ABSTRACT>
This dissertation presents an artificial neural network
inspired by studies of the fly visual system. Its
purpose is the real-time detection and tracking of a
moving object in the network's field of view. Background
material reviews the problems and requirements of motion
processing, discusses the organization and functions of
the fly visual system relevant to this processing, and
presents a model of this system as proposed by H. Ogmen
and S. Gagne. This model motivates the development of a
new three layer network. The proposed network processes
variations in light intensities, detects motion on both
the local and the wide-field levels, and outputs
information necessary to control pursuit tracking of a
moving object. After describing the network's
architecture and functions, an implementation in the C
programming language running in the Khoros software
environment is explained. Simulations of the
implementation serve to validate the network's ability
to do pursuit tracking.
Though there are limitations to the network's ability,
the current design is promising, and the software
simulation methods presented in this dissertation
provide an attractive, low-cost alternative to its
refinement. With improvements, this network's
implementation on a massively parallel computer system
will enable real-time processing of imagery from sources
such as cameras, radar, and sonar, for pursuit tracking
and interception tasks.
</ABSTRACT>
</THESIS>
<THESIS>
<NUMBER> 4381 </NUMBER>
<ORDER>   AAG9328348 </ORDER>
<TITLE>   CLASSIFIER EVALUATION AND THE USE OF ALGORITHMIC CLASSIFIERS WITH EXPERT SYSTEM CLASSIFIERS </TITLE>
<AUTHOR>   IRANI, ERACH ASPANDIAR </AUTHOR>
<YEAR>   1993 </YEAR>
<INSTITUTION>   UNIVERSITY OF MINNESOTA; 0130 </INSTITUTION>
<DESCRIPTORS>   COMPUTER SCIENCE; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER>   JAMES R. SLAGLE </ADVISER>
<CLASSIFICATIONS>   NIL </CLASSIFICATIONS>
<ABSTRACT>
This thesis discusses techniques to compare classifiers,
specifically algorithmic classifiers (algorithms) and
expert system classifiers (expert systems). The basic
criterion used is L, the weighted loss of mis-
classification. A relatively unknown variant of Cohen's
$kappa,$ that we shall call Brennan's kappa or kappa
base $(kappasb{b})$ is introduced from the biomedical
and psychological literature. $kappasb{b}$ adjusts for
agreement attainable due to chance. $kappasb{b}$ is
extended to $kappasb{b,w}$ for the case when the mis-
classifications are of varying degrees of severity. The
importance of using statistical techniques such as
hypothesis testing and confidence intervals is stressed.
The use of cross-validation, the grouped jackknife, and
the bootstrap for estimating the value, standard error,
and other properties of a criterion is shown. A
deficiency in the bootstrap method for estimating
Expected Excess Error of a trainable classifier is
proved. The split-recombination (SR) conjecture is
introduced to estimate properties of a trainable
classifier and three new techniques, the split
multinomial (SM), split grouped jackknife (SGJK), and
the split bootstrap (SB) are introduced. A simple
experiment on artificial data consisting of two classes
from two univariate normal populations is done to
demonstrate the plausibility of the SR conjecture.
The Classifier-based Overall Loss Minimization Strategy
(COLMS) and the Overall Loss Minimization Strategy
(OLMS) are introduced to combine classifier evaluations
to improve L and $kappasb{b,w}.$ The COLMS is an
independent discovery and development of the coupling
procedure for classifiers introduced by Wernecke. An ad-
hoc strategy for combining classifiers, viz. an Expert
Defined Domain-Specific Strategy (EDSS) for combining
classifiers, is developed and compared with the COLMS.
The use of an expert-defined test (EDT) is introduced to
further increase confidence in a classifier. These ideas
are demonstrated on real-world atherosclerosis
evaluation data from the Program On the Surgical Control
of the Hyperlipidemias (POSCH) and four real-world
classifiers viz. an expert system ESCA, multiple linear
regression, back-propagation, and C4.5 (an
implementation of ID3).
</ABSTRACT>
</THESIS>
<THESIS>
<NUMBER> 4382 </NUMBER>
<ORDER>   AAG9328190 </ORDER>
<TITLE>   COMPUTER MODELING AND SIMULATION TECHNIQUES FOR COMPUTER VISION PROBLEMS </TITLE>
<AUTHOR>   LU, MING-CHIN </AUTHOR>
<YEAR>   1993 </YEAR>
<INSTITUTION>   STATE UNIVERSITY OF NEW YORK AT STONY BROOK; 0771 </INSTITUTION>
<DESCRIPTORS>   COMPUTER SCIENCE; ENGINEERING, ELECTRONICS AND ELECTRICAL; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER>   MURALIDHARA SUBBARAO </ADVISER>
<CLASSIFICATIONS>   OBJECT RECOGNITION, IMAGE SENSING, NEURAL NETWORK </CLASSIFICATIONS>
<ABSTRACT>
Verification of computer vision theories is facilitated
by the development and implementation of computer
simulation systems. Computer simulation avoids the
necessity of building actual systems; they are fast,
flexible, and can be easily duplicated for use by
others. Development and implementation of computational
models in computer vision are both interesting and
challenging. It involves research in diverse areas and
requires integration of both science and technology.
This dissertation addresses the computer modeling and
simulation techniques for two computer vision problems:
object recognition and image sensing process. Image
sensing process investigates how an image is sensed by
specifying the input characteristics of the object and
the imaging devices, while object recognition is a high
level processing of the sensed image. We present a
neural network model to solve the problem of 3-D object
identification and pose estimation. The network is
divided into two stages, namely Feature Extraction Stage
and Feature Detection Stage to extract the feature
vectors and to identify the objects, respectively. 3-D
moments are used as input feature vectors to the
network. Therefore, unoccluded objects are required. We
also present a useful computational model to explore the
image sensing process. This model decouples the
photometric information and the geometric information of
objects in the scene. Therefore, it is computationally
tractable. Finally, we extend the proposed image sensing
model to simulate the formation of moving objects and
stereo imaging applications. All the models presented
here have been implemented and the implementations are
efficient, modular, extensible, and user-friendly so
that others can easily reproduce and/or verify their
experiments on a broader set of computer vision
theories.
</ABSTRACT>
</THESIS>
<THESIS>
<NUMBER> 4383 </NUMBER>
<ORDER>   AAG9328173 </ORDER>
<TITLE>   PARALLEL HEURISTIC SOLVABILITY OF THE QUADRATIC ASSIGNMENT AND RELATED PROBLEMS </TITLE>
<AUTHOR>   CHAKRAPANI, JAISHANKAR </AUTHOR>
<YEAR>   1993 </YEAR>
<INSTITUTION>   STATE UNIVERSITY OF NEW YORK AT STONY BROOK; 0771 </INSTITUTION>
<DESCRIPTORS>   OPERATIONS RESEARCH; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER>   JADRANKA SKORIN-KAPOV </ADVISER>
<CLASSIFICATIONS>   TABU SEARCH, NEURAL NETWORKS </CLASSIFICATIONS>
<ABSTRACT>
The heuristic solvability of the quadratic assignment
and related problems is addressed. An instance of a
quadratic assignment problem (QAP) of size n is
specified by two n x n matrices D and F and is denoted
by QAP(D,F).
First, the QAP is introduced along with tabu search--the
heuristic studied predominantly in this dissertation. An
introduction to the connection machine CM-2 is also
presented. CM-2 is the parallel environment in which the
parallel tabu search algorithms are implemented. An
adaptation of the Boltzmann machine, a connectionist
model, is developed to solve the QAP. This serves as a
testbed to compare the performance of simulated
annealing and tabu search. This also provides a
motivation for a massively parallel tabu search
heuristic $Parsb-tabu$ which is implemented on the CM-2.
The heuristic uses several advanced features of tabu
search and matches or improves the results obtained from
other comparative studies in fewer number of iterations.
$Parsb-tabu$ is then adapted to solve the TSP, which can
be considered as a special case of the QAP. An efficient
and highly scalable implementation of the 2-opt move on
the CM-2 forms the basis of the tabu search heuristic
for TSP.
Next, a parallel tabu search based heuristic is
developed and implemented (on the CM-2) for the problem
of mapping tasks to processors in a massively parallel
system to minimize communication time. This problem is
also formulated as a quadratic assignment problem (QAP),
and problems of size up to 64,000 are solved. The
algorithm compares favorably with other heuristics for
the same problem.
Finally, a new constructive approach to obtaining lower
bounds for a special class of QAPs is developed. Two
matrices $Fsb{opt}$ and $Fsb{res}$ are constructed such
that $F = Fsb{opt} + Fsb{res},$ and the optimal solution
of QAP$(D,Fsb{opt})$ is known. Any existing lower bound
can then be applied to QAP$(D,Fsb{res}),$ which in sum
with the optimal value for QAP$(D,Fsb{opt})$ provides a
valid lower bound to QAP(D,F). Thus, this method could
serve as a reduction process to possibly improve the
results from a variety of bounding techniques. This
approach is tested on two bounds from the literature,
the Gilmore-Lawler bound (GLB) and an eigenvalue bound
(PB), for various problems of size ranging from 6 to 49.
Computational results show a good improvement in bounds
for all the test problems.
</ABSTRACT>
</THESIS>
<THESIS>
<NUMBER> 4384 </NUMBER>
<ORDER>   AAG9328086 </ORDER>
<TITLE>   NEURAL NETWORK APPLICATIONS FOR INTERCONNECTION NETWORKS </TITLE>
<AUTHOR>   GOUDREAU, MARK WILLIAM </AUTHOR>
<YEAR>   1993 </YEAR>
<INSTITUTION>   PRINCETON UNIVERSITY; 0181 </INSTITUTION>
<DESCRIPTORS>   ENGINEERING, ELECTRONICS AND ELECTRICAL; COMPUTER SCIENCE; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER>   NIL </ADVISER>
<CLASSIFICATIONS>   ROUTING, MACHINE LEARNING </CLASSIFICATIONS>
<ABSTRACT>
Artificial Neural Networks (ANNs) have features that can
be exploited to solve computational problems. First, the
inherently parallel structure of some ANNs makes them
suitable for use as parallel computers. Second, the fact
that some ANNs can learn input/output mappings and
generalize is a feature that has generated a huge amount
of interest.
In this thesis, ANNs are used to solve certain problems
for Interconnection Networks (INs). The first subject
that is examined is routing through INs. Specifically,
an ANN is presented that solves the circuit switching
routing problem for Multistage Interconnection Networks
(MINs). The method involves reducing the routing problem
into a constraint satisfaction problem that can be
solved using an energy relaxation ANN, such as a
Hopfield network. The ANN routing methodology is
compared to exhaustive search routing and greedy
routing. For MINs that are not too large, the three
routing methodologies produce solutions that are of
similar quality. However, since the ANN is itself a
parallel computer, it is likely to have speed advantages
over the other routing approaches.
The representational abilities of certain Recurrent
Neural Networks (RNNs) is the second subject that is
addressed. It is proved that a first order, Single Layer
RNN (SLRNN) with hard limiting transfer functions is
incapable of implementing a finite state recognizer for
certain regular languages, including parity. It is also
demonstrated that a second order SLRNN can implement a
finite state recognizer for each regular language.
The third subject that is investigated is the ability of
RNNs to learn the structure of an IN from examples. The
approach is essentially an expansion of the grammatical
inference problem that has been explained in the RNN
literature. Gradient descent methods are used to train a
second order SLRNN, and the IN structure can then be
extracted from the SLRNN using simple clustering
algorithms.
</ABSTRACT>
</THESIS>
<THESIS>
<NUMBER> 4385 </NUMBER>
<ORDER>   AAG9327929 </ORDER>
<TITLE>   A MASSIVELY PARALLEL APPROACH TO MODELING THREE- DIMENSIONAL OBJECTS IN MACHINE VISION </TITLE>
<AUTHOR>   DANIEL, RONALD ELLISON, JR. </AUTHOR>
<YEAR>   1993 </YEAR>
<INSTITUTION>   OKLAHOMA STATE UNIVERSITY; 0664 </INSTITUTION>
<DESCRIPTORS>   ENGINEERING, ELECTRONICS AND ELECTRICAL; COMPUTER SCIENCE; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER>   KEITH A. TEAGUE </ADVISER>
<CLASSIFICATIONS>   NEURAL NETWORKS </CLASSIFICATIONS>
<ABSTRACT>
Scope of study. Machine vision processing can be divided
into two domains; signals and symbols. Object modeling
techniques perform the transformation from the signals
domain to the symbols domain. This study examines a
massively parallel method for computing a particular
object modeling technique, Superquadric Description
(SQD). SQD can be cast as a minimization problem. The
best previous method for solving SQD by minimization was
developed by Solina. This study reformulated the
objective function and investigated the use of a neural
network in an attempt to improve his method by
exploiting image coherence. One of the major hopes for
this network was that it would be able to discover
boundaries between interpenetrating SQs, which Solina's
method can sometimes do.
Findings and conclusions. The minimization was first
attempted with a unique vector extension to the Koch
network. The simple gradient descent method of this
network was not capable of minimizing the objective
function. A unique hybrid method was then developed
which used different minimization techniques on
different portions of the objective function. This
technique proved successful except when modeling flat
faces where these is insufficient curvature information
to obtain reliable estimates. The network does exploit
image coherence, which the previous method was not
doing. However, the network was not able to discover the
boundary between interpenetrating SQs. Reasons for this
limitation are discussed and future research directions
outlined.
</ABSTRACT>
</THESIS>
<THESIS>
<NUMBER> 4386 </NUMBER>
<ORDER>   AAG9327789 </ORDER>
<TITLE>   ON THE DEVELOPMENT OF COMPUTER ASSISTED INSTRUCTION SOFTWARE AND ITS INITIAL APPLICATION TO FRACTURE MECHANICS OF CONCRETE WITH INTELLIGENT DATA INTERPRETATION </TITLE>
<AUTHOR>   O'NEILL, ROBERT JAMES </AUTHOR>
<YEAR>   1993 </YEAR>
<INSTITUTION>   KANSAS STATE UNIVERSITY; 0100 </INSTITUTION>
<DESCRIPTORS>   ENGINEERING, CIVIL; COMPUTER SCIENCE; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER>   NIL </ADVISER>
<CLASSIFICATIONS>   NIL </CLASSIFICATIONS>
<ABSTRACT>
With the depth and breadth of our knowledge growing at
an ever-increasing rate, it becomes extremely important
that this knowledge be available in a usable format. On
the leading edge of technology is the development of
intelligent database systems that provide up to date
knowledge on an ever growing number of subjects.
To aid in the systematic organization and use of this
knowledge, a computer assisted instruction computer
program has been written. This program, called Hyper
Manual, provides the framework for the development of
intelligent database applications. Hyper Manual
incorporates hypertext, multimedia, a graphical user
interface, and machine intelligence concepts to provide
a tool that can author any number of topic specific
applications. Any application written with Hyper Manual
is portable, inexpensive to reproduce and updatable. Its
ability to access other software makes any application
written with it more powerful. The program is a
Microsoft Windows 3.1 application written in C++, an
object oriented programming language that allows for
modularity and growth.
Hyper Manual is used to develop FRACMECH, a fracture
mechanics of concrete application. FRACMECH is the
beginnings of a complete application on the subject of
fracture mechanics of concrete. The completed
application would aid in the transfer of knowledge and
technology in the field of fracture mechanics. It
provides the user with a knowledge base that is
organized and referenced, making the information readily
usable and accessible. FRACMECH provides sections on
learning about fracture mechanics principles, fracture
mechanics testing programs, structural applications
using fracture mechanics concepts and accesses a large
database of published literature on the topic of
fracture mechanics of concrete. In addition, FRACMECH
has access to two software applications, NeuroNet, a
neural network creation application and TPLOT, a finite
element demonstration. NeuroNet provides the FRACMECH
user the ability to analyze, interpret and evaluate test
data using a neural network approach. An example using
NeuroNet to analyze and interpret fracture test data is
provided. TPLOT demonstrates how other software
applications can be linked to FRACMECH.
</ABSTRACT>
</THESIS>
<THESIS>
<NUMBER> 4387 </NUMBER>
<ORDER>   AAG9327642 </ORDER>
<TITLE>   AN INVESTIGATION OF MULTI-PARAMETER FIBER OPTIC SENSORS WITH AN APPLICATION FOR STRAIN AND TEMPERATURE DIFFERENTIATION USING A NOVEL CONTROLLED GAUGE LENGTH DUAL TWO-MODE FIBER OPTIC SENSOR </TITLE>
<AUTHOR>   O'KEEFE, CHRISTIAN VICTOR </AUTHOR>
<YEAR>   1993 </YEAR>
<INSTITUTION>   THE JOHNS HOPKINS UNIVERSITY; 0098 </INSTITUTION>
<DESCRIPTORS>   ENGINEERING, ELECTRONICS AND ELECTRICAL; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER>   NIL </ADVISER>
<CLASSIFICATIONS>   STRAIN DIFFERENTIATION </CLASSIFICATIONS>
<ABSTRACT>
Optical fibers, while commonly associated with
communication functions, are finding increasing
usefulness as sensors. In particular as large area
structural sensors, they can be configured to measure
strains caused by events such as structural vibrations,
crack growths, pressurization and material yielding.
This can lead to the creation of a nervous system within
a structure, which if coupled with processing and
actuation capabilities can result in the formation of a
"smart structure." One disadvantage that fiber
optic sensors do exhibit is a sensitivity to temperature
effects which can mask or be confused with strain
changes. A fiber optic sensor to eventually be practical
must also have a controlled sensing region, have the
capability to be multiplexed, not require a separate
reference fiber, require only a single, relatively
inexpensive laser/light source, have a large dynamic
range and have an inherently robust, potentially
inexpensive to manufacture design. Although various
techniques had been developed to address some of these
requirements, there was still a need for a sensor which
could meet all of these requirements while having a
large but well defined sensing section.
This treatise explores the basis for multi-parameter
sensing in optical fibers, and describes past efforts in
this area. The research outlined in this dissertation
resulted in the creation of a novel fiber optic sensor
system with a controlled sensing region which can
measure and separate the effects of axial strain and
temperature changes, as well as meet the other
previously stated requirements. This sensor was
formulated through the creation of two sensors or two
sensing channels within a single optical fiber such that
each sensor exhibits a different response to strain and
temperature. The resulting sensor outputs were then
processed to extract the strain (elongation) and/or
temperature changes experienced by the sensor system.
Insensitive lead-in and lead-out fibers were used to
create a large, but well defined sensing section.
Testing of the sensor system under various strain and/or
temperature conditions revealed the successful operation
of this sensor system.
</ABSTRACT>
</THESIS>
<THESIS>
<NUMBER> 4388 </NUMBER>
<ORDER>   AAG9327485 </ORDER>
<TITLE>   RECOGNITION IN CONTEXT: VISION AND PURPOSE </TITLE>
<AUTHOR>   RIVLIN, EHUD </AUTHOR>
<YEAR>   1993 </YEAR>
<INSTITUTION>   UNIVERSITY OF MARYLAND COLLEGE PARK; 0117 </INSTITUTION>
<DESCRIPTORS>   COMPUTER SCIENCE; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER>   YIANNIS ALOIMONOS </ADVISER>
<CLASSIFICATIONS>   OBJECT RECOGNITION, MACHINE VISION </CLASSIFICATIONS>
<ABSTRACT>
We present an approach to visual recognition. We claim
that recognition is meaningful only in a context. Taking
a purposive approach, we define a framework for
recognition. We study the problem of object recognition
by asking a different question, i.e. by considering it
in the context of an agent performing it in an
environment, where the agent's intentions translate into
a set of behaviors. What are objects for? An object can
suit a purpose, fulfill a function. If the agent
recognizes this, it has in effect recognized the object.
To perform this type of recognition we need on one hand
a definition of the desired function, and on the other
the means of determining whether the object can fulfill
that function. To find out if an object can fulfill a
function we need to perform various partial recovery
tasks.
Realizing that vision is recognition within a behavior,
we present a formal framework formalizing behaviors and
the connection between vision and action. The framework
is based on a state transition formalism that enables us
to prove different properties on a behavior of a visual
system. The approach gives the ability to capture the
connection between an agent and the environment (this is
actually the link between perception and action), as
well as the option of combining behaviors in a
meaningful way and proving properties of the resulting
combination.
Experimental results for different recognition tasks in
a constraint context, as well as formalization for
behaviors in that context, are shown. Treating the
problem of place recognition in the context of indoor
environment is also presented.
</ABSTRACT>
</THESIS>
<THESIS>
<NUMBER> 4389 </NUMBER>
<ORDER>   AAG9327426 </ORDER>
<TITLE>   NAVIGATIONAL VISION </TITLE>
<AUTHOR>   HERVE, JEAN-YVES </AUTHOR>
<YEAR>   1993 </YEAR>
<INSTITUTION>   UNIVERSITY OF MARYLAND COLLEGE PARK; 0117 </INSTITUTION>
<DESCRIPTORS>   COMPUTER SCIENCE; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER>   YIANNIS ALOIMONOS </ADVISER>
<CLASSIFICATIONS>   VISUAL CONTROL, COMPUTER VISION </CLASSIFICATIONS>
<ABSTRACT>
Traditionally, a robot's visual system is assigned the
task of reconstructing the shape of the surrounding
scene in the form of a depth map, which can be exploited
to solve navigation problems by means of trajectory
planning, control of mechanisms, etc. Unfortunately, as
an overview of the state of the art in visual
reconstruction reveals, it is still impossible to
reliably compute depth maps, due to the fact that all
shape-from-x problems are mathematically ill-posed (they
have no unique solution and/or the solution is
unstable). Furthermore, judging by progress made in
recent years in problems such as road following and
visual servoing, it appears that the depth map may after
all not be the most suitable data representation for
such tasks.
We propose an image-based approach to the navigation
problem, in which visual processes are closely and
actively integrated with robot control, and show that
task-specific visual information with a minimum of
structure is sufficient to accomplish classical
navigational tasks such as obstacle avoidance and
hand/eye coordination. Through these examples we
demonstrate that the use of vision actually simplifies
the solution of robotics problems, allowing real-time
control without the complex calibration procedures
traditionally required.
It has been assumed in the past that the robot's
trajectory is determined exclusively by the location of
the goal and that the appropriate visual data can be
acquired as the robot progresses toward the goal. In
particular, the trajectory planning module never takes
into account the needs of the visual module. It has been
recognized that the stability and accuracy of visual
algorithms are affected by the motion of the observer,
but not much work has been done on deciding what
constitutes a "good" motion. In the final part
of this thesis, we propose a quantitative criterion for
the evaluation of the goodness of a particular action
and show how this additional layer of planning can be
incorporated into the low-level control strategy,
together with higher-level symbolic reasoning.
</ABSTRACT>
</THESIS>
<THESIS>
<NUMBER> 4390 </NUMBER>
<ORDER>   AAG9327190 </ORDER>
<TITLE>   LEARNING FROM STORIES: INDEXING AND REMINDING IN A SOCRATIC CASE-BASED TEACHING SYSTEM FOR ELEMENTARY SCHOOL BIOLOGY </TITLE>
<AUTHOR>   EDELSON, DANIEL CHOY </AUTHOR>
<YEAR>   1993 </YEAR>
<INSTITUTION>   NORTHWESTERN UNIVERSITY; 0163 </INSTITUTION>
<DESCRIPTORS>   COMPUTER SCIENCE; EDUCATION, TECHNOLOGY; EDUCATION, SCIENCES </DESCRIPTORS>
<ADVISER>   ROGER SCHANK </ADVISER>
<CLASSIFICATIONS>   NIL </CLASSIFICATIONS>
<ABSTRACT>
Good teachers teach with stories. To reproduce this
effective teaching technique in a computer-based
learning environment, we have developed the case-based
teaching architecture. A case-based teaching system uses
artificial intelligence techniques adapted from case-
based reasoning research to teach by presenting stories
in context. That context is established by a task
environment which provides a student with a naturally
motivating task and an engaging environment for pursuing
that task. A storyteller monitors the student's
interactions with the task environment, looking for
opportunities to present stories that will help the
student to learn from his or her situation. Learning
from stories provides students with cases that support
the natural process of case-based reasoning.
The challenge of constructing a case-based teaching
system lies in developing a scheme for indexing the
stories in the storyteller's library and in implementing
algorithms that will allow the storyteller to identify
appropriate stories when they are relevant. To retrieve
these stories, a case-based teaching system employs
reminding strategies. Reminding strategies enable a
storyteller to identify and retrieve stories to serve
specific goals. Reminding strategies rely on a
sufficiently expressive indexing scheme for labeling the
stories in a story library.
In this dissertation, I present the case-based teaching
architecture and propose several general reminding
strategies. These have been used in the development of
Creanimate, a case-based teaching system that teaches
animal adaptation to elementary school students. Its
task environment invites a student to create a new
animal and engages the student in a discussion of how
his or her invented animal might survive. Its
storyteller possesses a library of dramatic video clips
showing actual animals in the wild. These video stories
are presented as illustrations of the principles that
arise in the discussion of the student's animal.
Creanimate uses thought-provoking questions called
explanation questions as the basis for dialogues that
establish a context for learning from stories.
Creanimate employs three general reminding strategies:
example reminding, similarity-based reminding, and
expectation-violation reminding. Its story library is
indexed according to the principles of animal adaptation
that the stories illustrate.
</ABSTRACT>
</THESIS>
<THESIS>
<NUMBER> 4391 </NUMBER>
<ORDER>   AAG9327169 </ORDER>
<TITLE>   ARTIFICIAL NEURAL NETWORKS FOR THREE-DIMENSIONAL MOTION ANALYSIS </TITLE>
<AUTHOR>   CHEN, TING </AUTHOR>
<YEAR>   1993 </YEAR>
<INSTITUTION>   NORTHWESTERN UNIVERSITY; 0163 </INSTITUTION>
<DESCRIPTORS>   COMPUTER SCIENCE; ENGINEERING, ELECTRONICS AND ELECTRICAL; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER>   WEI-CHUNG LIN </ADVISER>
<CLASSIFICATIONS>   NEURAL NETWORKS </CLASSIFICATIONS>
<ABSTRACT>
Novel approaches to three-dimensional (3-D) motion
analysis using artificial neural network techniques are
proposed. The research presented in this dissertation
consists of three phases: (1) artificial neural networks
for 3-D rigid motion analysis, (2) artificial neural
networks for 3-D nonrigid motion analysis, and (3) fuzzy
neural networks for 3-D motion understanding. The
research in phases one and two formulates a complete
framework for neural network-based approaches to 3-D
motion analysis at the numerical level. The 3-D motion
of a nonrigid object can be decomposed into a global
rigid motion and a set of local nonrigid deformations.
The global rigid motion is studied in phase one. In the
proposed two-frame approach, a Hopfield network is
configured to enforce the matching constraints for a
stable and coherent correspondence establishment, and a
three-layered learning network is constructed to extract
motion parameters based on the correspondence
established. A multi-frame approach to the rigid motion
analysis is also proposed as an extension of the two-
frame approach. In phase two, the local nonrigid
deformations are discussed. A set of neural networks
similar in structure and dynamics but different in
physical size is proposed to tackle the problem of
nonrigidity in the local deformation estimation. The
objective of the proposed neural networks is to find the
optimal deformation matrices that satisfy the
constraints specified for all of the points on the
surface of a nonrigid object. The research in phase
three concerns 3-D motion analysis and focuses
specifically of heart motion study at the semantic
level. An automated system is developed to classify and
interpret the motion of the left ventricle of a heart
from the estimated local deformation matrices. The
proposed system, structured as a decision tree, combines
the techniques of both neural networks and fuzzy
reasoning.
The research presented in this dissertation contributes
to the fields of both computer vision and neural
networks by proposing novel neural network-based
approaches to examine problems in 3-D motion analysis.
The techniques proposed in this dissertation constitute
a complete theoretical framework for 3-D motion analysis
at both the numerical and semantic level. In comparison
with other conventional motion estimation methods, the
proposed approaches provide a fast implementation speed
resulting from parallel neural network structures,
capability to estimate various types of nonrigid
motions, and flexibility in terms of estimating
different types of motions with a unique architecture.
Experiments are conducted to corroborate the proposed
techniques.
</ABSTRACT>
</THESIS>
<THESIS>
<NUMBER> 4392 </NUMBER>
<ORDER>   AAG9326991 </ORDER>
<TITLE>   DESIGN FOR MAINTAINABILITY: AN ARCHITECTURE FOR MACHINE REASONING ON FASTENER STRUCTURE IN A CONSTRAINT MODELING SYSTEM </TITLE>
<AUTHOR>   BERWANGER, MARY CHRISTINE </AUTHOR>
<YEAR>   1993 </YEAR>
<INSTITUTION>   NORTH CAROLINA STATE UNIVERSITY; 0155 </INSTITUTION>
<DESCRIPTORS>   ENGINEERING, INDUSTRIAL; ENGINEERING, MECHANICAL; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER>   ROBERT E. YOUNG </ADVISER>
<CLASSIFICATIONS>   CONCURRENT ENGINEERING </CLASSIFICATIONS>
<ABSTRACT>
Providing design advice for manufacturability and
supportability requirements early in the design process
is a central tenant of concurrent engineering. The
purpose of this research is to demonstrate the
feasibility of providing maintainability advice to a
design engineer, by employing the artificial
intelligence technology of constraint monitoring. The
maintainability guidelines are transparent to the
designer, unless the emerging design violates a
maintainability constraint. Maintainability guidelines
are implemented as constraints for the field maintenance
environment, where the method of repair is to remove and
replace a failed component. The maintainability
constraints are tied to required levels of performance
in this environment, such as mean time to repair.
Specifically, fastener removal (replacement) time is
addressed.
</ABSTRACT>
</THESIS>
<THESIS>
<NUMBER> 4393 </NUMBER>
<ORDER>   AAGMM89841 </ORDER>
<TITLE>   TMDAS: THEMATIC MAP DESIGN ADVISORY SYSTEM FOR GEOGRAPHICAL INFORMATION SYSTEMS AND ELECTRONIC MAPPING SYSTEMS </TITLE>
<AUTHOR>   YANG, JUN </AUTHOR>
<YEAR>   1993 </YEAR>
<INSTITUTION>   CARLETON UNIVERSITY (CANADA); 0040 </INSTITUTION>
<DESCRIPTORS>   GEOGRAPHY; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER>   FRASER TAYLOR </ADVISER>
<CLASSIFICATIONS>   NIL </CLASSIFICATIONS>
<ABSTRACT>
The research focuses on the development of a Thematic
Map Design Advisory System (TMDAS) for geographic
information systems and electronic mapping systems. The
objectives of the project are to extract the inherent
knowledge of thematic map design, and to provide this
knowledge in an automated mapping environment, through
the use of expert system technology, in order to
safeguard against the creation of misleading maps. The
research was carried out as a knowledge engineering
project, in which the concept design was developed for
an expert system in thematic map design; the knowledge
was codified, further developed, and transformed into
formal knowledge; this knowledge was structured into
modules; knowledge representation schemes for different
types of knowledge were studied and applied; an expert
system shell, named J.shell, was developed; the TMDAS
knowledge base, with about 500 knowledge entries, was
implemented in the J.shell format; and, finally,
preliminary case tests and analysis were accomplished.
Each of these aspects is discussed in detail in the
thesis. Recommendations for further development of the
system are also proposed.
</ABSTRACT>
</THESIS>
<THESIS>
<NUMBER> 4394 </NUMBER>
<ORDER>   AAGMM89749 </ORDER>
<TITLE>   THE DEVELOPMENT AND TESTING OF A KNOWLEDGE-BASED PATIENT SIMULATOR </TITLE>
<AUTHOR>   MACDONALD, SIOBHAN CARA </AUTHOR>
<YEAR>   1993 </YEAR>
<INSTITUTION>   CARLETON UNIVERSITY (CANADA); 0040 </INSTITUTION>
<DESCRIPTORS>   COMPUTER SCIENCE; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER>   GREGORY KERSTEN </ADVISER>
<CLASSIFICATIONS>   NIL </CLASSIFICATIONS>
<ABSTRACT>
Recently, medical simulators have emerged as a viable
instrument to use in assessing students' diagnostic and
treatment skills. This study involved research on the
development and the testing of a prototype of a
knowledge-based patient simulator that was developed
according to the KADS methodology. The KADS methodology
is similar to conventional software development
methodologies. The research opportunity consisted of two
components. The first component involved determining if
restructurable modelling was a suitable approach to
simulate a patient's medical condition. The second
component involved testing an application of
restructurable modelling to determine if it is a
suitable instrument with which to assess a student's
diagnostic and treatment skills. The software package
used in developing the patient simulator was Negoplan
which is a shell based upon the principles of
restructurable modelling. The simulator was tested by
students, and the feedback provided was integrated into
iterations of the prototype, resulting in a successful
implementation of restructurable modelling. This
prototype proved to be useful in assessing a student's
diagnostic and treatment skills.
</ABSTRACT>
</THESIS>
<THESIS>
<NUMBER> 4395 </NUMBER>
<ORDER>   AAGMM89608 </ORDER>
<TITLE>   TACTILE PATTERN RECOGNITION USING NEURAL NETWORKS </TITLE>
<AUTHOR>   COLVEN, DAVID MICHAEL </AUTHOR>
<YEAR>   1993 </YEAR>
<INSTITUTION>   UNIVERSITY OF OTTAWA (CANADA); 0918 </INSTITUTION>
<DESCRIPTORS>   ENGINEERING, ELECTRONICS AND ELECTRICAL; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER>   EMIL PETRIU </ADVISER>
<CLASSIFICATIONS>   NIL </CLASSIFICATIONS>
<ABSTRACT>
This thesis presents a system for the capture and
recognition of tactile images using neural networks.
Neural Networks utilizing the backpropagation technique
are used to provide a general purpose recognition engine
for several classes of pattern recognition problems.
Examples of successful networks are presented with
discussion of the results and methodology for
development of each. The system consists of the
following: Image capture, training of network using an
iterative approach and testing of the network against
independent images not present during training.
Pattern capture is performed by scanning a force
sensitive tactile sensor that interfaces to a general
purpose computer. Following capture, examples of tactile
patterns of desired types are stored in a training file
and the training goal of the network set. The goal is
determined by the "trainer" who when the
patterns are captured indicates the pattern type.
Related patterns are given the same class name. The
Network is required to consist of as many output neurons
as classification types. The goal is that an output
neuron becomes "activated" when its pattern
types are present and "de-activated" when
another type is present.
Patterns in the training file are then recursively
applied to the inputs of the Neural Network. Once the
Network converges to the desired goal it is tested
against a new set of patterns to determine if the
network has learned to apply generalization in its
recognition of the patterns. The training set and
network topology may be modified in heuristic fashion
until satisfactory results are achieved.
</ABSTRACT>
</THESIS>
<THESIS>
<NUMBER> 4396 </NUMBER>
<ORDER>   AAGC398600 </ORDER>
<TITLE>   LAS COLOCACIONES DE NOMBRE Y ADJETIVO. UN PASO HACIA UNA TEORIA LEXICO-SEMANTICA DE LA TRADUCCION; SPANISH NOUN AND ADJECTIVE COLLOCATIONS. A STEP TOWARDS A LEXICAL SEMANTICS BASED THEORY OF TRANSLATION </TITLE>
<AUTHOR>   DE AGUILAR-AMAT CASTILLO, ANA </AUTHOR>
<YEAR>   1993 </YEAR>
<INSTITUTION>   UNIVERSITAT AUTONOMA DE BARCELONA (SPAIN); 5852 </INSTITUTION>
<DESCRIPTORS>   LANGUAGE, LINGUISTICS BARCELONA, EDIFICI RECTORAT, APARTAT POSTAL 20, E-08193 BELLATERRA (BARCELONA), SPAIN </DESCRIPTORS>
<ADVISER>   NIL </ADVISER>
<CLASSIFICATIONS>   NIL </CLASSIFICATIONS>
<ABSTRACT>
This work aims to prove the existence of certain links
between words of a particular language. It also aims to
prove the need of pointing out these links in
lexicographic descriptions and the relevance of that
information in any task related to translation and
language description. It is very important in lexical
selection, which characterizes processes of language
generation.
The thesis is divided in two parts. The first one raises
some questions related to the meaning of meaning and
deduces that collocation information is, among all
factors that constitute sense, the more conceivable
linguistic reality. In that sense, prediction of
structures is placed in front of linguistic universals.
However, the universal nature of the relations is
admitted, but families of relations are conceived as
syntagmatic or thematic functions instead of taxonomic
functions.
A machine translation system named ATLAS with an
interlingua strategy (based on a concept dictionary)
serves as an empirical model.
An important aspect of the first part of the book is
that the distinction between lexical function,
cooccurrence, collocation and cooccurrence relation
label is made more precise. Basically, all collocations
are cooccurrences but each cooccurrence does not
generate the same set of collocations. So, the
cooccurrence sculpted stone gives a N + A collocation
and also a V + N collocation (to sculpt a stone), but
this does not happen in the case of the cooccurrence
precious stone.
The second part of the work gives a relational
classification of adjectives based on their syntagmatic
behaviour. There are different collocation links between
adjectives and nouns. An adjective can be an argument of
a noun or vice versa, resulting in seven types of nouns
and eight types of adjectives.
Cooccurrence relation labels are also useful when trying
to control the problem of adjective order typical in
Spanish. Once traditional explanations are rejected, we
can observe a relation between adjective position
(before/after the noun) and its thematic role in
relation to the noun. So, when transitivity is produced,
that is, when the noun is an agent or experimenter, the
adjective will go after the noun. In the other cases
(valuation or quantifying) the adjective will go before.
Up till now lexicographic research on computational
linguistics has focused on morphological and syntactic
questions. A machine readable dictionary, which could
provide relational or combinatory information in a
systematic way, will be very useful to machine
translation, assisted translation, word processing and
editing, natural language processing (NLP) and
artificial intelligence (AI). (Abstract shortened by
UMI.)
</ABSTRACT>
</THESIS>
<THESIS>
<NUMBER> 4397 </NUMBER>
<ORDER>   AAGC384134 </ORDER>
<TITLE>   DIAGNOSTIC REASONING AND EXPLANATION IN FINANCIAL MODELS OF THE FIRM </TITLE>
<AUTHOR>   FEELDERS, ADRIANUS JOHANNES </AUTHOR>
<YEAR>   1993 </YEAR>
<INSTITUTION>   KATHOLIEKE UNIVERSITEIT BRABANT (THE NETHERLANDS); 0687 </INSTITUTION>
<DESCRIPTORS>   COMPUTER SCIENCE </DESCRIPTORS>
<ADVISER>   NIL </ADVISER>
<CLASSIFICATIONS>   NIL </CLASSIFICATIONS>
<ABSTRACT>
Although the importance of diagnosis for the managerial
decision process is frequently stressed in the
literature, relatively little theory has been developed
on this subject.
Within the discipline of artificial intelligence (AI),
diagnostic problem solving has been one of the main
research topics in recent years. However, almost all
research has been devoted to either medical diagnosis or
diagnosis of technical devices.
In this dissertation, a formal framework for the
diagnosis of company performance is developed. Diagnosis
is based on financial and operational data of the
company and its competitors. The formal framework
developed has been inspired by both literature findings,
and analysis of the reasoning process of a stock
analyst. It is shown that the newly developed model-
based method has substantial advantages over approaches
found in the literature. Furthermore, a computer program
that implements the new method is shown to generate
analyses almost identical to those found in a financial
textbook.
The diagnostic method developed could serve as the basis
for the development of knowledge based systems for the
diagnosis of company results. Such a knowledge based
system could be used to support the decision making of
company management, stock analysts, or bank loan
officers.
</ABSTRACT>
</THESIS>
<THESIS>
<NUMBER> 4398 </NUMBER>
<ORDER>   AAGNN90032 </ORDER>
<TITLE>   BASE DE CONNAISSANCES INTEGREE POUR L'ASSEMBLAGE AUTOMATISE </TITLE>
<AUTHOR>   RABEMANANTSOA, MONJY </AUTHOR>
<YEAR>   1993 </YEAR>
<INSTITUTION>   ECOLE POLYTECHNIQUE, MONTREAL (CANADA); 1105 </INSTITUTION>
<DESCRIPTORS>   ENGINEERING, ELECTRONICS AND ELECTRICAL </DESCRIPTORS>
<ADVISER>   MARIO GODARD </ADVISER>
<CLASSIFICATIONS>   FRENCH TEXT, KNOWLEDGE BASE, AUTOMOBILE ASSEMBLY </CLASSIFICATIONS>
<ABSTRACT>
This thesis presents the achievement of an integrated
knowledge base for generating assembly sequences in
CAD/CAM. The problems lie in three major states. The
first is the data modeling based on product design. The
next state is the knowledge modeling which supports the
data semantic and the assembly feasibility study through
the graph level of connections, symbolic features and
shape identification including the spatial configuration
of all parts. The last issue is the AI techniques
relating to decision tree and production rule in
conjunction with rule development and logic processing
for generating the assembly sequences. The idea is to
build a pattern-accessible data, but also to use all
relevant information automatically for good decisions in
design and planning.
The parts or products are designed with a parametric and
feature-based solid modeling Pro/Engineer. Then, data
are stored into two related formats: IGES and NEUTRAL
files. We design an object-oriented database written in
C language called SISDES (System of Integrated Software
for Data Exchange Specification) to support the model
analyser in terms of shape and feature 3D object-
recognition. The processing provides a framework for
integrating the geometric explicit functionality meaning
points, lines, arcs, together with the specific explicit
functionality such as diameter, length, tolerance, and,
the implicit functionality such as filets, chamfers,
slots, pockets. Beside, we introduce the notion of
abstraction: the abstraction of generalization
represents a set of objects as a generic object and the
abstraction of aggregation represents the part-component
structure where the object instances inherit the
characteristics of higher level object. Given these
concepts, our model goes beyond the CAD itself to carry
out a knowledge-based representation in which are
embedded implicit functionalities, namely, the contact
and relative mobility for mating conditions. Knowledge
processing constitutes the next step based on inference
mechanism plus a set of heuristics and rule base. To do
so, artificial intelligence (AI) paradigm known as modus
ponens, uncertainty reasoning and resolution have been
adopted into a problem-solving software called XGEN
(Assembly Sequences Generation) developed in Mprolog.
An efficient implementation of the integrated system has
been successfully demonstrated by results based on
various complexities of parts. The relationships between
the CAD environment and the feasible sequences
demonstrate the correctness and completeness of our
methodology. The implementation of the knowledge base as
a central component of the integrated system bridges the
gap between CAD and CAM.
The innovative contributions of this thesis are
emphasized within four discipline synthesis. The first
computation involves a complete data extraction with
emphasis given to the model-based integrated system used
for pattern-directed invocation of data. The second
layer supports the use of these data using object-
oriented concepts and abstractions for object
recognition. Like few other databases, SISDES contains
also knowledge about the semantics of the data. Based on
this reasoning, the third layer is concerned with
building up a knowledge-based system. At last, the AI
inferencing XGEN embedded into the fourth layer provides
efficient tools with its logic processing facilities for
the search of solution. The database supports data
processing while the AI supports knowledge processing.
This integrated environment has been achieved by
associating the solid modeling system with object-
oriented (SISDES) and expert system XGEN to prove the
validity of the generation process of assembly
sequences. (Abstract shortened by UMI.)
</ABSTRACT>
</THESIS>
<THESIS>
<NUMBER> 4399 </NUMBER>
<ORDER>   AAG1358013 </ORDER>
<TITLE>   HYBRID INTELLIGENT SYSTEMS: INTEGRATING EXPERT SYSTEMS WITH FUZZY LOGIC AND NEURAL NETWORKS </TITLE>
<AUTHOR>   BRAMANTE, MICHAEL JAMES </AUTHOR>
<YEAR>   1993 </YEAR>
<INSTITUTION>   THE AMERICAN UNIVERSITY; 0008 </INSTITUTION>
<DESCRIPTORS>   COMPUTER SCIENCE; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER>   LARRY MEDSKER </ADVISER>
<CLASSIFICATIONS>   NIL </CLASSIFICATIONS>
<ABSTRACT>
This thesis examines the problems with and benefits of
hybrid intelligent systems. Three disparate fields of
artificial intelligence are focused on: expert systems,
fuzzy logic, and neural networks. These areas are
explained and their benefits and disadvantages are
explored. Also, the dynamics of the integration of these
areas are analyzed. This analysis includes explanations
of how some disadvantages of these areas of artificial
intelligence are overcome by some of the advantages of
the other areas. The process of integration is further
explored through the actual designing, coding and
implementation of a hybrid intelligent system that has
been constructed as part of this thesis.
</ABSTRACT>
</THESIS>
<THESIS>
<NUMBER> 4400 </NUMBER>
<ORDER>   AAGMM88209 </ORDER>
<TITLE>   INTEGRATION APPROACH TO PROCESS MODELLING USING NEURAL NETWORK AND TO CONTROL SYSTEM DESIGN </TITLE>
<AUTHOR>   KIM, HEON CHANG </AUTHOR>
<YEAR>   1993 </YEAR>
<INSTITUTION>   UNIVERSITY OF ALBERTA (CANADA); 0351 </INSTITUTION>
<DESCRIPTORS>   ENGINEERING, SYSTEM SCIENCE; COMPUTER SCIENCE; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER>   MING RAO </ADVISER>
<CLASSIFICATIONS>   NIL </CLASSIFICATIONS>
<ABSTRACT>
As the modern industrial process is becoming
increasingly complex, it is difficult to operate the
process effectively. Accordingly, the importance of
integrating different tools within a package for
intelligent process operation has been realized.
This thesis study primarily consists of two parts. A
unique feature of this research is the utilization of
the meta-system concept for the integration issues both
in AI systems and in conventional programs.
In the first part of this study, a multilayer feedfoward
Backpropagation (BP) neural network has been developed
for inferential process modelling, then integrated to an
Integrated Distributed Intelligent System (IDIS). To
demonstrate the ability of Artificial Neural Network
(ANN) in process modelling, ANN was applied to the
maximization of the desired product yield by predicting
its volatility in refinery plants. Two case studies have
been carried out for different refinery processes using
the BP network. Due to major drawbacks in the
Generalized Descent (GD) method, which is a typical
optimization algorithm in BP, the Conjugate Gradient
(CG) method was also considered in training ANN. In the
first case study, the ANN and Regression Analysis (RA)
models were compared in representing the relation
between the plant stream data and the product
volatility. In the second case study, ANN model was also
applied to demonstrate its ability to fit noisy plant
data. The ANN model can then be used for inferred
volatility control.
The second part of the thesis is regarding the
development of an interactive Computer-Aided Control
System Design (CACSD) environment for chemical processes
by applying the meta-system concept to the integration
of several independently developed conventional
programs. Its result is an interactive graphical
software package PCET (Process Control Engineering
Teachware). PCET has a hierarchical structure of several
independently developed subprograms which are integrated
under the control of a supervising system, meta-system.
It covers a wide spectrum of process control engineering
applications, including Time Domain Analysis (TDA),
Routh Stability Criterion (RSC), Root Locus Technique
(RLT), Frequency Domain Analysis (FDA), Discrete-time
System Analysis (DSA), Linear State Space Analysis (LSA)
and Industrial Application Case (IAC). This package can
be used to design and analyze control systems. It can
also improve understanding of the basics of process
control engineering, and help users gain experience on
simulation and computer-aided design.
</ABSTRACT>
</THESIS>
<THESIS>
<NUMBER> 4401 </NUMBER>
<ORDER>   AAGMM88101 </ORDER>
<TITLE>   AN ADAPTIVE APPROACH FOR ACQUIRING MISSING KNOWLEDGE </TITLE>
<AUTHOR>   SHARPE, ALAN DOUGLAS </AUTHOR>
<YEAR>   1993 </YEAR>
<INSTITUTION>   UNIVERSITY OF ALBERTA (CANADA); 0351 </INSTITUTION>
<DESCRIPTORS>   COMPUTER SCIENCE; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER>   NIL </ADVISER>
<CLASSIFICATIONS>   NIL </CLASSIFICATIONS>
<ABSTRACT>
No matter how sophisticated the reasoning mechanism is
in a knowledge-based system, its performance will always
be limited by the quality of its store of domain
dependent knowledge--its knowledge base. The acquisition
of this knowledge has long been considered a
"bottleneck" in the development of knowledge-
based systems. Although much effort goes into eliciting
and encoding the knowledge base of a system, there will
almost always be some omissions and errors. It is
therefore useful for a knowledge-based system to
continually acquire new knowledge during its operation.
THINK is a framework to integrate interactive machine
learning into a knowledge-based system which allows a
system to incrementally acquire new knowledge when the
current knowledge base is inadequate to solve a given
problem. This knowledge method uses the current problem
context and line of reasoning to hypothesize missing
items of knowledge. Hypotheses are generated through a
generalized abduction method and then subjected to a
neural net based plausibility test prior to presentation
to an expert user. The knowledge base is updated
according to the response. If hypotheses are rejected
then alternate ones are generated until accepted. In
interactions between expert and system, learning is
achieved through experience so more plausible hypotheses
are presented earlier. This learning takes the form of
training the neural net with previous hypothesis-
response pairs.
All implementation of THINK is described along with
experimental results which indicate the validity of the
concept.
</ABSTRACT>
</THESIS>
<THESIS>
<NUMBER> 4402 </NUMBER>
<ORDER>   AAGMM87923 </ORDER>
<TITLE>   FINAL VERSION: UNCERTAINTY IN ARTIFICIAL INTELLIGENCE </TITLE>
<AUTHOR>   ALDROBI, MOLHAM RATEB </AUTHOR>
<YEAR>   1993 </YEAR>
<INSTITUTION>   MCGILL UNIVERSITY (CANADA); 0781 </INSTITUTION>
<DESCRIPTORS>   COMPUTER SCIENCE; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER>   CHRIS PAIGE </ADVISER>
<CLASSIFICATIONS>   NIL </CLASSIFICATIONS>
<ABSTRACT>
Reasoning with uncertain information has received a
great deal of attention recently, as this issue has to
be addressed when developing many expert systems.
In this thesis we study the literature of uncertainty in
AI. The approaches taken by the researchers in this
field can be classified into two categories: non-numeric
approaches and numeric approaches. From non-numeric
methods, we summarize The Theory of Endorsements, and
non-monotonic logics. From numeric methods, we elaborate
on MYCIN certainty Factors, Dempster-Shafer Theory,
Fuzzy Logic, and Probabilistic Approach. We point out
that probability theory is an adequate approach if we
interpret probability values as beliefs and not only as
frequencies.
We first discuss broad and more thoroughly researched
areas. We then focus more on integrating probability and
logic as we believe this is a crucial approach to build
up a setting for reasoning with uncertain information
based on strong local foundations. Some key works in
that area are traced back to 1913 when Lukasiewics
published his paper on Logical Foundation of
Probability. Comparisons between Nilsson's probabilistic
logic and the related work of Quinlan, Grosof, McLeish,
Chen, and Bacchus are given. We conclude the thesis by
our remarks and suggestions for possible future research
topics.
</ABSTRACT>
</THESIS>
<THESIS>
<NUMBER> 4403 </NUMBER>
<ORDER>   AAG9326892 </ORDER>
<TITLE>   LEARNING ALGORITHMS FOR NEURAL NETWORKS AND DEVELOPMENT OF NEURAL-NETWORK-BASED ACTIVE VIBRATION ABSORBERS </TITLE>
<AUTHOR>   MA, RWEI-PING </AUTHOR>
<YEAR>   1993 </YEAR>
<INSTITUTION>   THE PENNSYLVANIA STATE UNIVERSITY; 0176 </INSTITUTION>
<DESCRIPTORS>   ENGINEERING, MECHANICAL; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER>   ALOK SINHA </ADVISER>
<CLASSIFICATIONS>   NIL </CLASSIFICATIONS>
<ABSTRACT>
This thesis deals with the development of learning
algorithms for recurrent and multilayer neural networks
and application of neural networks to the control of
vibration in rotordynamic systems. These learning
algorithms are based on the concept of terminal
attractors and the attractive condition used in the
sliding mode control theory. Terminal attractors, which
are based on the violation of the Lipschitz condition,
represent singular solutions of dynamical systems. The
fact that the system can reach singular solutions (or
the desired solutions) in a finite time is utilized to
enhance the learning rates of neural networks. The
derivations of these new learning algorithms are
formulated for both recurrent and multilayer neural
networks. An inverse kinematic problem associated with a
two-link robot manipulator is chosen as an example to
verify the usefulness of new learning algorithms.
Simulation results for both neural networks are
presented.
A neural-network-based active vibration absorber has
been developed to optimally suppress rotor vibrations
caused by rotor unbalance. The unique feature of this
new vibration absorber is its ability to optimally
control vibration at different rotor speeds. Numerical
examples dealing with a single-degree-of-freedom spring-
mass system and a multi-degree-of-freedom rigid rotor
supported by magnetic bearings are presented to verify
the advantages of this novel neural-network-based active
vibration absorber.
</ABSTRACT>
</THESIS>
<THESIS>
<NUMBER> 4404 </NUMBER>
<ORDER>   AAG9326878 </ORDER>
<TITLE>   DIAGONAL RECURRENT NEURAL NETWORKS FOR CONTROL OF DYNAMIC SYSTEMS </TITLE>
<AUTHOR>   KU, CHAO-CHEE </AUTHOR>
<YEAR>   1993 </YEAR>
<INSTITUTION>   THE PENNSYLVANIA STATE UNIVERSITY; 0176 </INSTITUTION>
<DESCRIPTORS>   ENGINEERING, ELECTRONICS AND ELECTRICAL; COMPUTER SCIENCE; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER>   KWANG Y. LEE </ADVISER>
<CLASSIFICATIONS>   NEURAL NETWORKS, LEARNING RATES </CLASSIFICATIONS>
<ABSTRACT>
A new neural network architecture called Diagonal
Recurrent Neural Network (DRNN) is presented. The
architecture of DRNN is a modified model of fully
connected recurrent neural network with one hidden
layer. The hidden layer is comprised of self-recurrent
neurons, each feeding its output only into itself and
not to other neurons in the hidden layer. Two DRNNs are
utilized in a control system, one as an identifier
called Diagonal Recurrent Neuroidentifier (DRNI) and the
other as a controller called Diagonal Recurrent
Neurocontroller (DRNC). A controlled plant is identified
by the DRNI, which then provides the sensitivity
information of the plant to the DRNC. A generalized
dynamic backpropagation algorithm (DBP) is developed and
used to train both DRNC and DRNI.
To guarantee convergence and for faster learning, an
approach that uses adaptive learning rates is developed
by introducing a Lyapunov function. Convergence theorems
for the adaptive backpropagation algorithms are
developed for both DRNI and DRNC. Convergence and the
closed-loop stability are established for the DRNN based
control system when the plant is BIBO stable. The
proposed DRNN model is tested on a number of examples.
Two different approaches for selecting learning rates,
namely the fixed learning rate and the adaptive learning
rate approaches, are investigated. The generalization
ability, a BIBO nonlinear control, a non-BIBO nonlinear
control, the on-line adapting ability of the DRNN based
control, and an unstable plant control are investigated.
The results show that the DRNN based control system
requires much fewer neurons and weights, and that the
number of training cycles required is reduced
considerably. Moreover, the convergence, which is
guaranteed for a BIBO plant, is also fast and the result
is a closed-loop system which tracks reference input
very well. An unstable plant was also controlled
successfully by incorporating temperature and scaling
schemes. The DRNN is also applied in a practical
problem: nuclear reactor temperature control, and the
simulation results demonstrated that the DRNN based
control is very promising for future real-time
applications.
</ABSTRACT>
</THESIS>
<THESIS>
<NUMBER> 4405 </NUMBER>
<ORDER>   AAG9326836 </ORDER>
<TITLE>   AUTOMATED VISUAL INSPECTION OF PRODUCE: NEURAL NETWORKS VERSUS TRADITIONAL CLASSIFIERS </TITLE>
<AUTHOR>   DECK, SIDNEY </AUTHOR>
<YEAR>   1993 </YEAR>
<INSTITUTION>   THE PENNSYLVANIA STATE UNIVERSITY; 0176 </INSTITUTION>
<DESCRIPTORS>   ENGINEERING, AGRICULTURAL; ENGINEERING, ELECTRONICS AND ELECTRICAL; COMPUTER SCIENCE; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER>   CHARLES T. MORROW </ADVISER>
<CLASSIFICATIONS>   NIL </CLASSIFICATIONS>
<ABSTRACT>
This was a study to determine the relative strengths and
weaknesses of artificial neural networks and traditional
statistical classifiers. This research was divided into
two experimental groups. The first experimental group
was a pilot study to see if there are any advantages in
using neural networks for the detection of greening in
potatoes. A training set of 20 potatoes with greening
and 20 potatoes without greening were imaged and hue
histogram information was collected. These data were
used to train both a backpropagation network and a
linear discriminant function. The two methods were then
applied to 10 test potato samples with greening and 10
test samples without greening and the data were
compared. The backpropagation network discriminated with
an accuracy of 95% while the linear discriminant method
performed with 90% accuracy.
For the second experiment set, the performances of the
backpropagation neural network and the Fisher
discriminant function were compared for the inspection
of greening, shape, and shatter bruise in potatoes. The
training sets consisted of 34 potato samples for
greening, 20 potato samples for shape, and 28 potato
samples for shatter bruise detection. The test sets
consisted of 20 potato samples for greening, 14 potato
samples for shape, and 30 potato samples for shatter
bruise detection. The results were mixed. The
backpropagation network and the Fisher method both
performed with a 70% accuracy for greening. The
backpropagation method performed better for shape
discrimination with a 78.6% accuracy versus a 71.4%
accuracy. The Fisher method performed the greatest for
shatter bruise detection with a 76.7% accuracy versus a
50.0% accuracy for backpropagation.
</ABSTRACT>
</THESIS>
<THESIS>
<NUMBER> 4406 </NUMBER>
<ORDER>   AAG9326725 </ORDER>
<TITLE>   ARCHITECTURE AND STATISTICAL MODEL OF A PULSE-MODE DIGITAL MULTILAYER NEURAL NETWORK </TITLE>
<AUTHOR>   KIM, YOUNG-CHUL </AUTHOR>
<YEAR>   1993 </YEAR>
<INSTITUTION>   MICHIGAN STATE UNIVERSITY; 0128 </INSTITUTION>
<DESCRIPTORS>   ENGINEERING, ELECTRONICS AND ELECTRICAL; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER>   NIL </ADVISER>
<CLASSIFICATIONS>   NIL </CLASSIFICATIONS>
<ABSTRACT>
A new architecture for a pulse-mode digital neural
network is presented. Algebraic neural operations are
replaced by stochastic processes using pseudo-random
pulse sequences. Synaptic weights and neuron states are
represented as probabilities and estimated as average
rates of pulse occurrences in corresponding pulse
sequences. A statistical model of error (or noise) is
developed to estimate relative accuracy associated with
stochastic computing in terms of a mean and a variance.
The stochastic computing model translates into simple
logic gates as basic computing elements leading to a
high neuron-density on a chip. Furthermore, the use of
simple logic gates for neural operations, the pulse-mode
signal representation, and the modular design techniques
lead to a massively parallel yet compact and flexible
network architecture well-suited for VLSI
implementation. Any size feed-forward network can be
configured using the modules. Processing speed is
independent of the network size.
Multilayer feed-forward networks are modeled and applied
to pattern classification problems such as encoding and
character recognition. The architecture and all digital
sub-components in the proposed neural network are
modeled and simulated in VHDL. Computational accuracy is
analyzed and the network performance is evaluated in
terms of a correct classification rate. The simulation
experiments in these applications show the network
performance is competitive with that of deterministic
DMNN simulations and ordinary back-propagation networks
while retaining the desirable properties of high speed
and high density on a chip.
</ABSTRACT>
</THESIS>
<THESIS>
<NUMBER> 4407 </NUMBER>
<ORDER>   AAG9326443 </ORDER>
<TITLE>   CONTINGENCY-TOLERANT ROBOT MOTION PLANNING AND CONTROL </TITLE>
<AUTHOR>   CHOI, WONYUN </AUTHOR>
<YEAR>   1993 </YEAR>
<INSTITUTION>   STANFORD UNIVERSITY; 0212 </INSTITUTION>
<DESCRIPTORS>   ENGINEERING, MECHANICAL; COMPUTER SCIENCE; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER>   JEAN-CLAUDE LATOMBE </ADVISER>
<CLASSIFICATIONS>   NAVIGATION SYSTEM, CONTINGENCY TOLERANCE, PATH PLANNING </CLASSIFICATIONS>
<ABSTRACT>
This dissertation describes a new approach and enabling
techniques to build the navigation system of a mobile
robot operating in a partially known environment. The
main layout of this environment is known in advance, but
the locations and shapes of some smaller objects may not
be known. Environments of this type include shop-floors,
offices, etc. The problem is to automatically determine
how the robot should move from one position to another
without colliding with objects in the environment.
In order to be both efficient and robust, the navigation
system should interweave a planning component and a
reaction component. The planning component should take
advantage of available prior knowledge to produce
globally efficient plans. However, it should be aware
that knowledge may be incomplete and generate lesser-
committed plans that leave some freedom of choice at
execution time to deal with contingencies. The reaction
component should organize the robot's behavior according
to both the ongoing plan and the sensory inputs.
The main idea underlying the approach proposed in this
dissertation is to let the reaction component share some
global knowledge of the robot's environment with the
planning component. Based on this idea, we have
developed a new type of navigation system where the
planning component generates a lesser-committed motion
plan, called a channel, represented by a sequence of
parallelepipedic cells, and the reaction component uses
artificial potential fields to pull the robot toward its
goal within the channel, while repelling it away from
unexpected obstacles.
Various arrangements of unexpected obstacles may be
encountered during navigation. The treatment of these
arrangements by the reaction component is organized in
three layers: channel navigation, local replanning, and
global replanning. The most common and simpler cases are
processed by the first layer using less complex
techniques, while less frequent but more complex cases
are handled by the other layers using more complex
techniques.
This navigation system applies to mobile robots with
holonomic or nonholonomic constraints. Three versions of
the system have been implemented. They have been
experimented with simulated robots and a real mobile
robot. Experimental results are discussed in this
report.
</ABSTRACT>
</THESIS>
<THESIS>
<NUMBER> 4408 </NUMBER>
<ORDER>   AAG9326405 </ORDER>
<TITLE>   LEARNING AND NEGOTIATION IN POWER SYSTEM DECISION-MAKING ENVIRONMENT </TITLE>
<AUTHOR>   WANG, SHIH-MING </AUTHOR>
<YEAR>   1993 </YEAR>
<INSTITUTION>   UNIVERSITY OF WASHINGTON; 0250 </INSTITUTION>
<DESCRIPTORS>   ENGINEERING, ELECTRONICS AND ELECTRICAL; COMPUTER SCIENCE; OPERATIONS RESEARCH; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER>   CHEN-CHING LIU </ADVISER>
<CLASSIFICATIONS>   NIL </CLASSIFICATIONS>
<ABSTRACT>
Most of the knowledge-based systems for power system
decision making lack the self-learning capability. In
this dissertation, an inductive learning method which is
used to construct decision trees from examples is
applied to aid a voltage control expert system (VCES) in
classifying the severity of voltage problems. The
classification results enable VCES to provide sufficient
control to correct a voltage problem at one time. To
avoid repeating previous mistakes, a tree-modification
algorithm is developed, allowing VCES to initiate
minimal modification of a decision tree when a
misclassification occurs. Also, the modified leaming
method is used to automate acquisition of knowledge for
screening voltage contingencies. Tested on the IEEE 30-
bus system, the method can acquire effective structural
contingency selection knowledge for the system.
Another issue rarely addressed in the existing knowledge-
based systems is decision making with conflicting
objectives. Due to increasing environmental concerns and
the trend of deregulation of the utilities, power system
planners are impelled to consider tradeoffs between
conflicting objectives which result from diverse
interests of different organizations. This dissertation
presents a negotiation method for resolution of
conflicting objectives in power system planning. The
framework is based on human negotiation behavior. It
includes a goal-decision network model and a negotiation
algorithm that integrates three negotiation operators:
bridging, unlinking, and logrolling. A goal-decision
network models the interaction between the objectives
and decisions in a planning problem. The planning
process is viewed as a negotiation process in which the
negotiation algorithm determines beneficial planning
options by searching through a goal-decision network.
</ABSTRACT>
</THESIS>
<THESIS>
<NUMBER> 4409 </NUMBER>
<ORDER>   AAG9325875 </ORDER>
<TITLE>   AN EXPERT SYSTEM FOR TIMBER HARVESTING DECISION MAKING IN MAINE'S COMMERCIAL TIMBERLANDS </TITLE>
<AUTHOR>   LINEHAN, PETER EUGENE </AUTHOR>
<YEAR>   1993 </YEAR>
<INSTITUTION>   UNIVERSITY OF MAINE; 0113 </INSTITUTION>
<DESCRIPTORS>   AGRICULTURE, FORESTRY AND WILDLIFE; ARTIFICIAL INTELLIGENCE; ENGINEERING, AGRICULTURAL </DESCRIPTORS>
<ADVISER>   THOMAS J. CORCORAN </ADVISER>
<CLASSIFICATIONS>   NIL </CLASSIFICATIONS>
<ABSTRACT>
Using Expert Systems, a product of Artificial
Intelligence research, a decision support system for
timber harvesting leads a forester through a series of
questions to arrive at a determination of harvesting
viability. The program, X-Harvester, was written in a
development package, EXSYS Professional. The system is
divided into modules, accessed independently through a
menu program.
Machine cost models in separate spreadsheets evaluate
individual harvesting machines using several common
methods. The harvesting system module builds specific
harvesting systems from individual machines. Operating
and labor costs are included in the analysis.
The log prices and value, and stumpage modules use price
information stored in data frame files to calculate the
income from timber sales of and the cost of stumpage
purchases. Calculations are made by species and product.
A user can update price and stumpage information by
editing the data files.
The financial viability module uses information from
other modules in its evaluation process. The user can
compute costs for the entire system as a whole, or for
each machine in the system on an individual basis. Costs
can also be input on a daily or per hour basis.
Miscellaneous costs, such as road building, overhead or
transportation can also be included.
A cutting regulations module evaluates the operation for
compliance with the Maine timber and land use laws. The
user may also evaluate the site for physical operability
and suitability of soils for forest regeneration.
Alternative problem solving approaches and Artificial
Intelligence methods are discussed. A sample run of the
program and a printout of the program modules are also
included.
X-Harvester has been designed to allow modifications
reflecting specific needs and objectives of land holding
companies or agencies. The framework of the system
provides a useful foundation to assist land managers in
making timber harvesting decisions.
</ABSTRACT>
</THESIS>
<THESIS>
<NUMBER> 4410 </NUMBER>
<ORDER>   AAG9325581 </ORDER>
<TITLE>   ON COMPUTING PERCEPTUAL ORGANIZATION IN COMPUTER VISION </TITLE>
<AUTHOR>   SARKAR, SUDEEP </AUTHOR>
<YEAR>   1993 </YEAR>
<INSTITUTION>   THE OHIO STATE UNIVERSITY; 0168 </INSTITUTION>
<DESCRIPTORS>   ENGINEERING, ELECTRONICS AND ELECTRICAL; COMPUTER SCIENCE; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER>   K. L. BOYER </ADVISER>
<CLASSIFICATIONS>   NIL </CLASSIFICATIONS>
<ABSTRACT>
The evolution of perceptual organization in biological
vision, and its necessity in advanced computer vision
systems, arises from the characteristic that perception,
the extraction of meaning from sensory input, is an
intelligent process. This is particularly so for high
order organisms and, analogically, for more
sophisticated computational models. By perceptual
organization we refer to the ability of a vision system
to organize detected features in images based on
viewpoint consistency and other Gestaltic perceptual
phenomena. This imparts robustness, efficiency, and a
qualitative and holistic nature to vision.
Our computational paradigm aims to organize features
into highly plausible sets of higher level geometric
features which are present in images of objects
belonging to a large number of domains. Our
organizational philosophy is hierarchical, with complex
organizations being formed from simpler ones. Each level
of the hierarchy is constructed using voting methods,
graph operations, and knowledge based reasoning in a new
extension of the Bayesian network we call the Perceptual
Inference Network. Analogous to theories in human
vision, our strategy divides broadly into two parts:
detecting regularities and similarities in the tokens
(preattentive vision) and reasoning, based on a
knowledge base built from past experience, to enable one
to go beyond the information provided (attentive
vision). The voting method provides organizations based
on Gestalt principles and the network reasons on those
organizations to extract geometric features. The two
steps of voting and evidential reasoning are repeated.
Previous approaches to perceptual organization have
mostly been purely bottom up, without any top down
knowledge base influence and therefore entirely
dependent on the inputs, which may be imperfect. The
knowledge base, besides coping with such input
imperfections, also allows us to integrate multiple
sources of information and to form a composite
organization hypothesis.
</ABSTRACT>
</THESIS>
<THESIS>
<NUMBER> 4411 </NUMBER>
<ORDER>   AAG9325176 </ORDER>
<TITLE>   AN EXPERT SYSTEM FOR SELECTION OF AN APPROPRIATE ENHANCED OIL RECOVERY METHOD </TITLE>
<AUTHOR>   ELMTALAB, JABBAR </AUTHOR>
<YEAR>   1993 </YEAR>
<INSTITUTION>   NORTH DAKOTA STATE UNIVERSITY OF AGRICULTURE AND APPLIED SCIENCE; 0157 </INSTITUTION>
<DESCRIPTORS>   ENGINEERING, PETROLEUM; COMPUTER SCIENCE; ENERGY </DESCRIPTORS>
<ADVISER>   RUFUS O. ELEMO </ADVISER>
<CLASSIFICATIONS>   ENHANCED OIL RECOVERY </CLASSIFICATIONS>
<ABSTRACT>
High demand for experts in most of the technical and
scientific fields has prompted work in artificial
intelligence and expert systems to identify many areas
for theoretical research and practical applications,
such as enhanced oil recovery (EOR). Expert systems in
EOR can serve as valuable tools to assist petroleum
professionals, who analyze and solve the complex problem
of selecting an appropriate EOR technique in advanced
oil recovery operations. The systems developed in this
research select the most suitable EOR process(es),
predict the additional percentage of original oil in
place (OOIP) recoverable by the selected method(s), and
analyze the economic feasibility of the selected
process(es).
Based upon user response to the reservoir
characteristics, reservoir engineering data, and other
operational information, an appropriate EOR technique(s)
was/were selected. Possible choices were steam drive, in
situ combustion, cyclic steam injection, polymer
flooding, micellar polymer flooding, alkaline flooding,
hydrocarbon miscible flooding (gas or LPG), alcohol
miscible flooding, miscible CO$sb2$ flooding, immiscible
CO$sb2$ flooding, and none tertiary EOR method. The most
appropriate EOR process was selected, based on the
technical feasibility. Economic analysis of the selected
process was made.
The knowledge based for selecting the most suitable EOR
techniques and predicting the additional percentage of
OOIP recoverable by a selected process were developed
using an expert system shell called PCPLUS. The economic
analyses of the selected method(s) were implemented
using FORTRAN computer language.
The developed expert systems and FORTRAN program were
tested against several sets of real reservoir data. The
results of the test cases indicated that the developed
systems are reliable, since the results agreed with EOR
human experts' selections.
</ABSTRACT>
</THESIS>
<THESIS>
<NUMBER> 4412 </NUMBER>
<ORDER>   AAG9324496 </ORDER>
<TITLE>   AN AI-BASED, DECENTRALIZED APPROACH TO PROCESS-CONTROL AND PLANNING WITH MASSIVELY PARALLEL SYSTEMS </TITLE>
<AUTHOR>   DUBASH, RUMI MINOO </AUTHOR>
<YEAR>   1993 </YEAR>
<INSTITUTION>   UNIVERSITY OF HOUSTON; 0087 </INSTITUTION>
<DESCRIPTORS>   COMPUTER SCIENCE; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER>   NIL </ADVISER>
<CLASSIFICATIONS>   ROBOTICS, AUTOMATION </CLASSIFICATIONS>
<ABSTRACT>
Process-control systems form an integral and important
part of the present automated society. They are
generally deployed for tasks that are hazardous,
laborious, repetitive, and need quick response. Due to
the nature of the tasks, it is very important that these
systems be highly reliable and efficient. Accommodating
all of these requirements makes such systems very large
and complex. Hence, decentralization and distribution
are the norm rather than an exception. Measures such as
decentralization and decomposition into smaller subtasks
imposes, a hierarchy on the system, which requires that
robust, higher level tasks act as
supervisors/coordinators. In spite of these measures,
there are problems with such decomposed systems. In this
dissertation we present a general model of process-
control systems that will address the problems with the
current approaches.
We replace the coordinating process by a massively
parallel cellular automaton. The process-control system
is reduced from its physical-world manifestation to a
configuration-space and finally to a processor-state
space. This transforms the process-control problem to
that of path planning of a point object in the presence
of obstacles. We develop a massively parallel,
decentralized solution to the path planning problem. We
present an interface between the massively parallel
planning system and the physical process-control system
that is responsible for transforming the physical-world
information into processor-state variables and the
generated plan back to lower-level instructions for the
controllers. The massively parallel solution has several
advantages such as simplicity, inherent fault-tolerance,
and reusability.
We go on to discuss methods of fault-tolerance based on
elimination of critical processors, and generalized
trajectories that minimize synchronization. Further, we
put forward a symbolic approximation of the system with
regard to 2-terminal reliability employing partitioning
envelopes. Some other issues considered are reduction of
non-convex obstacles to convex obstacles using exterior
visibility theorems and Weak Voronoi diagrams.
Robots can be considered a special class of process-
control systems. We propose a Hybrid Architecture based
on decentralized path planning. We argue that there are
certain tasks where a completely decentralized,
autonomous, multi-robot system may not provide a good
solution. In such cases, the massively parallel
decentralized planning system as a centralized planning
entity, may still provide opportunity for centralized
robotic systems.
</ABSTRACT>
</THESIS>
<THESIS>
<NUMBER> 4413 </NUMBER>
<ORDER>   AAG9329119 </ORDER>
<TITLE>   EXPERT DECISION SUPPORT SYSTEMS: EFFECTS ON PERFORMANCE OF PARTICIPANTS IN THE LIVE HOG FUTURES MARKETS </TITLE>
<AUTHOR>   NARAYANAN, NACHIAPPAN </AUTHOR>
<YEAR>   1993 </YEAR>
<INSTITUTION>   UNIVERSITY OF ILLINOIS AT URBANA-CHAMPAIGN; 0090 </INSTITUTION>
<DESCRIPTORS>   ECONOMICS, AGRICULTURAL; BUSINESS ADMINISTRATION, MANAGEMENT; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER>   STEVEN T. SONKA </ADVISER>
<CLASSIFICATIONS>   NIL </CLASSIFICATIONS>
<ABSTRACT>
Although expert systems technology that takes advantage
of artificial intelligence techniques is very powerful,
its application in the business domain is not without
problems. Nevertheless, integration of Decision Support
System (DSS) and Expert System (ES) will improve
decision maker capabilities and create more powerful and
useful computer-based systems. The quality and
efficiency of both ES and DSS may be enhanced by
integrating them.
EDSS can be used to improve the decision making
performance of hog producers. Price forecasts can be
valuable to the decision makers involved in the hog
market due to uncertainty in hog prices. Production,
marketing and resource allocation decisions can be made
more efficient by accurate forecasts. The large number
of marketing alternatives available, the vast amount of
information that must be considered, and integration of
qualitative and quantitative information suggest that an
expert decision support system is an appropriate tool
for the marketing alternative selection problem.
The purpose of this research is to investigate whether
Expert Decision Support System (EDSS) technology,
incorporating a theoretical forecast model, data base,
expert knowledge, and user input could be used to
enhance the decision performance of hog producers.
The results provided evidence supporting the view that
an expert decision support system improves the decision
performance of hog producers. A second conclusion is
that use of EDSS will encourage more hog producers to
participate in hedging strategies to reduce price risks.
Third, the subjects indicated the data and the knowledge
of experts were valuable in their hog marketing
decisions. Another conclusion is that perception
measures do not necessarily reflect actual decision
performance. Access to human experts, data and
theoretical models are available to the hog producers
but it involves time, cost, and interpretation problems.
Hence, this research shows that EDSS can be a useful
source for hog producers to improve their performance.
</ABSTRACT>
</THESIS>
<THESIS>
<NUMBER> 4414 </NUMBER>
<ORDER>   AAG9328816 </ORDER>
<TITLE>   MODELER: A CASE-BASED APPROACH FOR INTEGRATING EXPERIENCE IN MODEL FORMULATION SYSTEMS </TITLE>
<AUTHOR>   VELLORE, RAVI CHAND D. </AUTHOR>
<YEAR>   1993 </YEAR>
<INSTITUTION>   TEXAS A&M UNIVERSITY; 0803 </INSTITUTION>
<DESCRIPTORS>   BUSINESS ADMINISTRATION, GENERAL; COMPUTER SCIENCE; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER>   AJAY S. VINZE; ARUN SEN </ADVISER>
<CLASSIFICATIONS>   NIL </CLASSIFICATIONS>
<ABSTRACT>
Model formulation is pivotal to any effort in the area
of intelligent decision support system (IDSS). The
different approaches used in model formulation cover a
spectrum that includes: those that emphasize selection
of suitable problem or tool representation; those that
support the view that model representation and model
execution are integrated; and those that treat model
formulation separately. Most of these approaches have
used techniques such as: logic modelling, knowledge-
based representations, graphics, and executable modeling
languages. Recent trends in model formulation are
starting to focus on a case-based approach. In this
approach, previously used model formulation plans are
stored in memory as cases. In attempting new problems,
cases are recalled in an attempt to apply them as is, or
by modifying them for the given situation. This
methodology of using cases to solve problems is called
case-based planning.
The research focuses on the model formulation process in
the production planning domain. In an attempt to
understand the role of experience in the formulation
process of expert modelers, a cognitive model is
developed. The basis for this cognitive model is a set
of verbalizations obtained from experts' while solving
problems in the production planning domain. A protocol
analysis conducted on these experts' verbalizations
provided evidence of a case based approach that is done
opportunistically. Using this cognitive model, design
considerations are drawn up for constructing MODELER, a
case based system which incorporates experience to
support the model formulation process.
The MODELER integrates techniques from the blackboard
paradigm and case based reasoning approach. The
blackboard provides a natural environment for the
implementation of an opportunistic formulation process.
Case based reasoning provided insights for the recall
and storage aspects of experience in the model
formulation process.
An experiment was conducted with subjects whose
experience and exposure to linear programming models was
wide ranging. The experiment focussed on the recall
aspects of subjects' while performing a simple
formulation task. The experiment showed that the
subjects' exposure and experience with the problem type
does determine the cues/stimuli retrieved from the
situation to assist the recall process.
</ABSTRACT>
</THESIS>
<THESIS>
<NUMBER> 4415 </NUMBER>
<ORDER>   AAG9327227 </ORDER>
<TITLE>   AN EXPLORATION OF EXECUTIVE CONTROL PROCESSES IN CONVERSATIONS: EXTENDING A PLAN-BASED MODEL OF COMMUNICATION </TITLE>
<AUTHOR>   JORDAN, JERRY MONROE </AUTHOR>
<YEAR>   1993 </YEAR>
<INSTITUTION>   NORTHWESTERN UNIVERSITY; 0163 </INSTITUTION>
<DESCRIPTORS>   SPEECH COMMUNICATION; PSYCHOLOGY, SOCIAL; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER>   MICHAEL E. ROLOFF </ADVISER>
<CLASSIFICATIONS>   NIL </CLASSIFICATIONS>
<ABSTRACT>
Plan-based models of communication are pervasive in
Artificial Intelligence and Communication Studies. But,
it is not yet clear exactly what role social action
plans might play in the production of conversational
discourse. AI models of conversation depict plans as the
necessary precursors to action that play a direct and
strong role in guiding discourse. Other views of
discourse depict plans as very weak guides for behavior.
They view plans as retrospective or prospective sense-
making heuristics. This study was designed to explore
directly how cognitive social action plans function in
the production of human conversational discourse. Since
a plan-based model of conversation entails that some
plan monitoring processes occur, it was hypothesized
that an individual's cognitive efficiency would have a
direct impact on the effectiveness of their plans, their
social effectiveness as indexed by loneliness and an
effect on the extent to which they actually followed
their plan in an interaction. This last effect was
hypothesized to be mediated by the actor's degree of
interaction involvement. Two research question designed
to directly assess the actors' plan monitoring processes
were also proposed. Respondents completed a measure of
cognitive efficiency and a loneliness measure.
Respondents' plans for three social interactions were
elicited through a think-aloud procedure. They later
actually conducted one of the interactions for which
they had planned and completed a measure of interaction
involvement. Respondents' cognitive activity experienced
during the interaction was assessed through a cued-
recall procedure. The hypothesized relationship between
cognitive efficiency and plan effectiveness was
supported within only one social scenario. The
association between inefficiency and loneliness was
strongly supported. The hypothesized interaction between
cognitive inefficiency and plan-behavior correspondence
did not emerge. Post-hoc analyses indicated that
inefficiency and motivation did interact to predict plan-
behavior correspondence. Examination of the on-line
cognitions suggested that actors think in terms of
intermediate rhetorical goals mediating between social
goals and manifest discourse forms. This appears to be
the case during planning and during the interaction.
Results are discussed in terms of building a
comprehensive, plan-based theory of human conversation.
</ABSTRACT>
</THESIS>
<THESIS>
<NUMBER> 4416 </NUMBER>
<ORDER>   AAG9326711 </ORDER>
<TITLE>   SEARLE'S CHINESE BOX: THE CHINESE ROOM ARGUMENT AND ARTIFICIAL INTELLIGENCE. </TITLE>
<AUTHOR>   HAUSER, LARRY STEVEN </AUTHOR>
<YEAR>   1993 </YEAR>
<INSTITUTION>   MICHIGAN STATE UNIVERSITY; 0128 </INSTITUTION>
<DESCRIPTORS>   PHILOSOPHY; COMPUTER SCIENCE; PSYCHOLOGY, GENERAL; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER>   NIL </ADVISER>
<CLASSIFICATIONS>   VOLUMES I AND II) (SEARLE JOHN, THOUGHT </CLASSIFICATIONS>
<ABSTRACT>
The apparently intelligent doings of computers occasion
philosophical debate about artificial intelligence (AI).
Evidence of AI (such doings) is not bad; arguments
against AI are: such is the case for. One argument
against AI--currently, perhaps, the most influential--is
considered in detail: John Searle's Chinese room
argument (CRA). This argument and its attendant thought
experiment (CRE) are shown to be unavailing against
claims (of AI proper) that computers can and even do
think. CRA is formally invalid and informally
fallacious. CRE's putative experimental result is not
robust (similar "experiments" give conflicting
results) and fails to generalize from understanding to
other mental attributes as claimed. Further, CRE depends
for its credibility, in the first place, on a dubious
tender of the epistemic privilege of overriding all
"external" behavioral evidence to first person
disavowals of mental properties like understanding.
Advertised as effective against AI, Searle's argument is
an ignoratio elenchi, feigning to refute AI by disputing
a similar (but logically independent) claim of
"strong AI" or Turing machine functionalism
(FUN) metaphysically identifying minds with programs.
AI, however, is warranted independently of FUN: even if
CRA disproved FUN this would still fail to refute or
seriously disconfirm claims of AI. Searle's contention
that everyday predications of mental terms of computers
are discountable as equivocal (figurative) "as-
if" predications--impugning independent seeming-
evidence of AI if tenable--is unwarranted. Lacking
intuitive basis, such accusations of ambiguity require
theoretical support. The would-be theoretical
differentiation of intrinsic intentionality (ours) from
as-if intentionality (theirs) Searle propounds to
buttress allegations of ambiguity against mental
attributions to computers, however, depends either on
dubious doctrines of objective intrinsicality according
to which meanings are physically in the head or on even
more dubious (as if dualistic) notions of subjective
intrinsicality according to which meanings are
phenomenologically "in" consciousness. Neither
would such would-be differentiae as these
unproblematically rule out seeming instances of AI if
granted. The dubiousness of as if dualistic
identification of thought with consciousness also
undermines the epistemic privileging of the "first
person point of view" crucial to Searle's thought
experiment.
</ABSTRACT>
</THESIS>
<THESIS>
<NUMBER> 4417 </NUMBER>
<ORDER>   AAG9326601 </ORDER>
<TITLE>   CAD-BASED GRAPH FEATURES FOR THREE-DIMENSIONAL NEURORECOGNITION IN A MANUFACTURING ENVIRONMENT </TITLE>
<AUTHOR>   TSENG, KUANG-MING </AUTHOR>
<YEAR>   1993 </YEAR>
<INSTITUTION>   UNIVERSITY OF MISSOURI - ROLLA; 0135 </INSTITUTION>
<DESCRIPTORS>   ENGINEERING, INDUSTRIAL; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER>   CIHAN H. DAGLI </ADVISER>
<CLASSIFICATIONS>   CAD, VIEWGRAPHS </CLASSIFICATIONS>
<ABSTRACT>
This study addresses the problem of generating
representations of three-dimensional (3-D) objects
automatically from view sequences of unoccluded objects.
In designing the models, processed frames of a video
sequence from Computer-Aided Design (CAD) are clustered
into view categories called view graphs, which represent
characteristic views of an object invariant to its
apparent position, size, two-dimensional (2-D)
orientation, and limited foreshortening deformation. The
view graphs, as well as the view transitions of a view
sequence, are used to build and refine the 3-D object
representations to train a Learning Vector Quantizer
(LVQ) neural network in the form of neural memory.
Object recognition emerges as the hypothesis that has
accumulated the maximum weight in a certain neuron at
each moment. The study concentrates on 3-D appearance
modeling and succeeds under favorable viewing conditions
by using image processing techniques to segment objects
from the scene and derive the spatial arrangement of
object features. A Bidirectional Associative Memory
(BAM) neural network has been successfully applied to
pre-process the image and an LVQ neural network to
search the view point direction and to recognize
objects.
</ABSTRACT>
</THESIS>
<THESIS>
<NUMBER> 4418 </NUMBER>
<ORDER>   AAG9326184 </ORDER>
<TITLE>   NCLIPS: AN ARCHITECTURE THAT INTEGRATES NEURAL NETWORKS AND RULE BASED KNOWLEDGE REPRESENTATION </TITLE>
<AUTHOR>   BHATNAGAR, HIMANSHU </AUTHOR>
<YEAR>   1993 </YEAR>
<INSTITUTION>   UNIVERSITY OF LOWELL; 0111 </INSTITUTION>
<DESCRIPTORS>   COMPUTER SCIENCE; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER>   PATRICK KROLAK; CHARLES STEELE </ADVISER>
<CLASSIFICATIONS>   NIL </CLASSIFICATIONS>
<ABSTRACT>
We describe NCLIPS, an architecture that comprehensively
integrates rule based expert systems and neural
networks, in a mutually supportive way. The architecture
is three-layered and is designed to support integration
at several different levels. At the core of this
architecture is an object oriented conceptual framework
of classes that define the four main objects in NCLIPS.
These classes are implemented on a library of C
functions, some of which are available while others were
created. The objects are represented homogeneously and
are graphically accessible in the top-most application
development layer. In this thesis we create a component
level structured representation for expert systems and
neural networks in the form of expert and neural
objects. Then, by selectively inheriting from either we
create a new type of object, the integrated object. This
object is more robust than expert objects, exhibits
better control than neural objects, has the capability
to learn and generalize unlike expert objects, has a
viable real world interface not available with neural
objects and has some capability to explain its reasoning
process. These three families of objects are supported
by a kernel object that provides facilities such as
controlled graphical display, inter-process
communication and multi-processing. At this level,
integration is available in four different form: a loose
form (via message passing between objects and via
inheritance), a strong form (special integrated classes
for shared structures), a dynamic form (integrated
classes for transient structures) and a fully integrated
form (integrated classes for structures). System defined
classes can be used to develop applications either in
the object oriented domain, or through a visual
programming and control interface (application
development layer). In addition new types of rules and
facts are created that enable 'integrated system'
development within the implementation layer. They also
enable creation of neural network 'programs' and
'integrated programs'. These objects together with a new
integrated programming language and a visual programming
and control interface form the basis for a comprehensive
integration. This integrated has yielded a new
technology in the area of knowledge based problem
solving.
</ABSTRACT>
</THESIS>
<THESIS>
<NUMBER> 4419 </NUMBER>
<ORDER>   AAG9325990 </ORDER>
<TITLE>   A DYNAMIC SYSTEMS APPROACH TO PATTERN RECOGNITION </TITLE>
<AUTHOR>   SRIKANTH, RADHAKRISHNAN </AUTHOR>
<YEAR>   1993 </YEAR>
<INSTITUTION>   TULANE UNIVERSITY; 0235 </INSTITUTION>
<DESCRIPTORS>   COMPUTER SCIENCE; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER>   CRIS KOUTSOUGERAS </ADVISER>
<CLASSIFICATIONS>   NEURAL NETWORK, HYBRID NETWORK </CLASSIFICATIONS>
<ABSTRACT>
In this thesis we attempt to unify methods for
supervised and unsupervised learning in new hybrid
schemes while assuming feed forward neural nets as the
underlying computing structure. In general, feed forward
neural networks have a multilayer architecture
associated with them, i.e. layers of units stacked on
top of each other. Here we treat the process of learning
as successive transformations of the input space to the
required output space. In the context of neural nets the
process is viewed as recoding followed by curve fitting.
In the models that we propose, specific attention is
given to the development of the internal representations
in the hidden layers, by using unsupervised learning
algorithms to extract significant features inherent in
the training pattern set. The final output layer then
handles the labeling or the curve fitting part by using
a supervised learning algorithm. Thus by synthesizing
meaningful representations in the hidden layers, the
root cause of the problems in feed forward networks,
like sensitivity to architecture, initial conditions,
overtraining, and other related problems are addressed.
The new models, Hybrid Charge Clustering Network (HCCN)
and Hybrid Kohonen Network (HKN) are referred to as
Heterogeneous neural net models as they are
heterogeneous in the makeup of their architecture and
adaptive algorithms.
</ABSTRACT>
</THESIS>
<THESIS>
<NUMBER> 4420 </NUMBER>
<ORDER>   AAG9325785 </ORDER>
<TITLE>   DIGITAL VLSI IMPLEMENTATION OF ARTIFICIAL NEURAL NETWORK SYSTEMS </TITLE>
<AUTHOR>   CHAMON, JORGE DE CARVALHO </AUTHOR>
<YEAR>   1993 </YEAR>
<INSTITUTION>   TEXAS TECH UNIVERSITY; 0230 </INSTITUTION>
<DESCRIPTORS>   ENGINEERING, ELECTRONICS AND ELECTRICAL; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER>   DONALD L. GUSTAFSON </ADVISER>
<CLASSIFICATIONS>   VLSI </CLASSIFICATIONS>
<ABSTRACT>
Neural networks have been studied for several years in
the hope of simulating brain-like activities such as
pattern recognition, that are inefficiently handled by
general purpose digital computers. Until now, most high
performance neural network systems have been implemented
by using analog circuits for the neurons and synaptic
weights due to low power consumption and compatibility
with sensor inputs. In this dissertation qualitatively
and quantitatively analyzed the characteristics of
digital neural network systems. Several properties such
as single component delay time, overall system
throughput, quantization effects, and the use of hard-
limiting nonlinear functions are explored to evaluate
the system performance.
Other contribution include: (1) use of a fast binary
tree parallel summation scheme to decrease the time
required to recognize a throughput, and (2) the
modification on the standard back-propagation learning
algorithm to train the network's weights when the
network's neurons have hard limiting nonlinear
functions. Both neuron and connection models are
analyzed in detail. Simulation results are shown to be
consistent with theoretical work.
</ABSTRACT>
</THESIS>
<THESIS>
<NUMBER> 4421 </NUMBER>
<ORDER>   AAG9325386 </ORDER>
<TITLE>   ROBOTIC HAND-EYE MOTOR LEARNING </TITLE>
<AUTHOR>   RUOFF, CARL FREDERICK </AUTHOR>
<YEAR>   1993 </YEAR>
<INSTITUTION>   CALIFORNIA INSTITUTE OF TECHNOLOGY; 0037 </INSTITUTION>
<DESCRIPTORS>   COMPUTER SCIENCE; ENGINEERING, ELECTRONICS AND ELECTRICAL; ENGINEERING, MECHANICAL; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER>   FRED E. C. CULICK </ADVISER>
<CLASSIFICATIONS>   NEURAL NETWORKS, MACHINE LEARNING, HAND EYE CALIBRATION </CLASSIFICATIONS>
<ABSTRACT>
This thesis investigates the use of neural networks and
nonlinear estimation in robotic motor learning.
It presents a detailed experimental investigation of the
performance and parametric sensitivity of resource-
allocating neural networks along with a new learning
algorithm that offers rapid adaptation and excellent
accuracy. It also includes an appendix that relates
feedforward neural networks to familiar mathematical
ideas.
In addition, it presents two learning hand-eye
calibration systems, one based on neural networks and
the other on nonlinear estimation. The network-based
system learns to correct robot positioning errors
arising from the use of nominal system kinematics, while
the estimation-based system identifies the robot's
kinematic parameters. Both systems employ the same two-
link robot with stereo vision, and include noise and
various other error sources. The network-based system is
robust to all error sources considered, though noise
naturally limits performance. The estimation-based
system has significantly better performance when the
robot and vision systems are well modeled, but is
extremely sensitive to unmodeled error sources and
noise.
Finally, it presents a robot control system based on
neural networks that learns to catch balls perfectly
without requiring explicit programming or conventional
controllers. It uses only feedforward pursuit motions
learned through practice, and is initially incapable of
even moving its arm in response to external stimuli. It
learns to identify and control its pursuit movements, to
identify and predict ball behavior, and, with the aid of
advice from a critic, to modify its movement commands to
improve catching success. The system, which incorporates
information from visual, arm state, and drive force
sensors, characterizes control situations using
input/response pairs. This allows it to learn and
respond to plant variations without requiring parametric
models or parameter identification. It achieves robust
execution by comparing predicted and observed behavior,
using inconsistencies to trigger learning and behavioral
change. The architectural approach, which involves both
declarative and analog knowledge as well as short- and
long-term memory, can be extended to learning other
sensor-motor skills like mechanical assembly and
synchronizing motor actions with external processes.
</ABSTRACT>
</THESIS>
<THESIS>
<NUMBER> 4422 </NUMBER>
<ORDER>   AAG9325372 </ORDER>
<TITLE>   PARALLEL ANALOG COMPUTATION WITH CHARGE COUPLED DEVICES </TITLE>
<AUTHOR>   NEUGEBAUER, CHARLES FRANCIS </AUTHOR>
<YEAR>   1993 </YEAR>
<INSTITUTION>   CALIFORNIA INSTITUTE OF TECHNOLOGY; 0037 </INSTITUTION>
<DESCRIPTORS>   ENGINEERING, ELECTRONICS AND ELECTRICAL; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER>   AMNON YARIV </ADVISER>
<CLASSIFICATIONS>   NEURAL NETWORKS </CLASSIFICATIONS>
<ABSTRACT>
Many signal processing and neural network algorithms can
be mathematically described in terms of vector matrix
multiplication. This thesis introduces two new
architectures for computing high-speed vector matrix
multiplication using charge coupled devices. These
integrated circuits have been designed to accept optical
matrix input as well as direct electrical matrix input.
In both architectures, the matrix elements are stored as
analog charge packets in CCD wells while the vectors are
communicated to and from the integrated circuits by
electrical means.
The first architecture accomplishes the vector matrix
product using a semiparallel computation scheme that
requires N clock cycles of the device to complete one
vector matrix multiplication where N is the length of
the input vector. An analysis of the linearity and
charge transfer induced errors is given. The circuit
represents an advance over other analog signal
processors in density and speed but has serious
shortcomings in accuracy, particularly the limited
precision of the input vectors.
The second architecture is based on charge injection
device (CID) imager arrays and addresses many of the
inadequacies of the semiparallel architecture. A fully
parallel circuit, the CID has similar density and much
higher computation speed and accuracy. A novel digital
input method is introduced that extends the input vector
precision significantly. In addition, accuracy issues
related to charge transfer efficiency are resolved. An
analysis of linearity and accuracy is provided showing
the advantages of the architecture over previous
implementations.
</ABSTRACT>
</THESIS>
<THESIS>
<NUMBER> 4423 </NUMBER>
<ORDER>   AAG9324705 </ORDER>
<TITLE>   TROUBLESHOOTING UNFAMILIAR DEVICES </TITLE>
<AUTHOR>   VOLOVIK, DMITRY </AUTHOR>
<YEAR>   1993 </YEAR>
<INSTITUTION>   UNIVERSITY OF MINNESOTA; 0130 </INSTITUTION>
<DESCRIPTORS>   COMPUTER SCIENCE; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER>   WEI-TEK TSAI; PAUL E. JOHNSON </ADVISER>
<CLASSIFICATIONS>   EXPERT SYSTEMS </CLASSIFICATIONS>
<ABSTRACT>
The dissertation presents a theory of troubleshooting
unfamiliar devices. The theory explains the
troubleshooting processes for unfamiliar devices by
means of enabling constraints that must be satisfied in
troubleshooting task environments. Provided these
constraints are met, the theory derives necessary and
sufficient conditions on computations. The computations
are carried out by agents that efficiently perform the
task of troubleshooting complex unfamiliar devices in
the task environment. The dissertation discusses several
instances of a troubleshooting process that occurs in
the absence of device-specific troubleshooting
experience in the domain of digital electronic devices.
In this domain troubleshooters develop a number of
specific heuristic methods. Failures and limitations of
these heuristic methods are discussed. The dissertation
constructs a framework and a formal theory of
troubleshooting abstract unfamiliar devices. The theory
is based on enabling constraints as axioms. The
dissertation presents an efficient algorithm for
troubleshooting unfamiliar devices based on the
requirements of the theory. The dissertation discusses
limiting constraints in troubleshooting task
environments. The dissertation proposes that device-
specific knowledge of designers has the power to
overcome some of these constraints. The dissertation
presents a number of modifications to the above
algorithm. These modifications are based on relaxing
limiting constraints. To relax limiting constraints the
dissertation uses various descriptions embedded in
natural by-products of the device design process, such
as components descriptions, test descriptions, finite
state control descriptions, and hierarchical functional
device decompositions. Designers create the by-products
in the process of design and use them to circumscribe
the complexity of the design and debugging task. The
dissertation discusses data from an experiment in the
domain of digital electronic devices. The experiment
demonstrates the difference in performance on simulated
troubleshooting tasks of several algorithms that carry
out the troubleshooting process for unfamiliar devices
in this domain. In particular, the experiment
demonstrates that the above algorithm outperforms
heuristic methods of troubleshooters on complex devices.
In addition, various algorithmic extensions based on
relaxing different limiting constraints are compared to
identify the effects on performance of relaxing
individual limiting constraints.
</ABSTRACT>
</THESIS>
<THESIS>
<NUMBER> 4424 </NUMBER>
<ORDER>   AAG9324581 </ORDER>
<TITLE>   ON THE USE OF NEURAL NETWORKS AND EXPERT SYSTEMS TO AID A REACTOR OPERATOR IN DIAGNOSIS OF COMPLEX ATWS SEQUENCES IN A BOILING WATER NUCLEAR POWER PLANT </TITLE>
<AUTHOR>   XING, LEIMING </AUTHOR>
<YEAR>   1993 </YEAR>
<INSTITUTION>   UNIVERSITY OF CALIFORNIA, LOS ANGELES; 0031 </INSTITUTION>
<DESCRIPTORS>   ENGINEERING, NUCLEAR; COMPUTER SCIENCE; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER>   DAVID OKRENT </ADVISER>
<CLASSIFICATIONS>   NIL </CLASSIFICATIONS>
<ABSTRACT>
Anticipated Transients Without Scram (ATWS) represent
nuclear reactor accident sequences where control rods
can not be inserted into the reactor core immediately
after an initiating event. ATWS can be a dominant
accident sequence in a BWR nuclear power plant.
Difficulties in diagnosis and proper operator actions
may arise due to large amplitude oscillations and
temporary loss of some instrument readings.
The back propagation (BP) neural network is used in an
example application to distinguish four ATWS patterns. A
combination of the BP network with Hopfield net is used
to improve neural networks' ability to resist error.
Test results and theoretical analysis demonstrate the
ability of the BP network to recall correctly given
random noise and incomplete information to some extent.
Potential problem of using the BP network to diagnose in
the oscillatory regimes is identified, i.e., an
inaccurate measure of the transient starting time may
result in a difference between the sensor data and the
training data. A solution is to use multiple sets of
training data for one case. Data of twelve ATWS cases
for the Susquehanna Steam Electric Station (SSES)
reactor are arranged into several groups by using
unsupervised learning based on discovery of cluster
structures (Pao's approach). The BP networks are then
used to map patterns of different groups into different
case signatures. Intensive tests are performed on recall
correctness in the presence of parameter oscillations,
random noise, and incomplete information. The BP network
is also used to predict the time left to oscillations
given the transient underway is correctly diagnosed.
A prototype expert system consists of IF... THEN... and
DO... format rules is implemented. The expert system can
simulate the ATWS strategy developed by Pennsylvania
Power & Light (PP&L) Company. It is a real time
prototype system, and undertakes diagnosis using an
event tree structure. In addition, the expert system can
execute the trained BP networks and make decisions based
on the retrieved information. It is also designed to
deal with temporary loss of level indication and to
undertake containment monitoring. Tests for twelve ATWS
cases are performed.
</ABSTRACT>
</THESIS>
<THESIS>
<NUMBER> 4425 </NUMBER>
<ORDER>   AAG9324550 </ORDER>
<TITLE>   A COGNITIVE HINTING STRUCTURE FOR DEEP DOMAIN KNOWLEDGE </TITLE>
<AUTHOR>   NCUBE, CATHY CLAIBORNE </AUTHOR>
<YEAR>   1993 </YEAR>
<INSTITUTION>   THE FLORIDA STATE UNIVERSITY; 0071 </INSTITUTION>
<DESCRIPTORS>   COMPUTER SCIENCE; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER>   WYLLIS BANDLER </ADVISER>
<CLASSIFICATIONS>   EXPERT SYSTEMS, ENVHINT </CLASSIFICATIONS>
<ABSTRACT>
A framework is presented for the acquisition of domain-
specific knowledge from experts. This framework is
referred to as the ENVIRONMENTAL HINTING (ENVHINT)
framework. ENVHINT attempts to steer the expert's focus
to the derivation of expert knowledge by embedding
acquisition of expert knowledge in the dynamics of the
environment which influenced expertise development.
Within this framework, the research focuses on the
development of cognitive structures which can be used to
develop probing domain-specific questions.
Cognitive structures are developed from urban residents'
repertory grids which are based on personal construct
theory. A cognitive structure reveals dependencies in
the form of construct equivalence classes and
implications from one equivalence class to another.
Weights are assigned to the implication lines of a
cognitive structure. They are obtained from a fuzzy
grid, from which the cognitive structure is derived. The
weights allow paths to be accessed according to
relevancy of urban concerns. The relevancy strengths of
paths are used to derive hinting domain-specific
questions for experts.
</ABSTRACT>
</THESIS>
<THESIS>
<NUMBER> 4426 </NUMBER>
<ORDER>   AAG9324548 </ORDER>
<TITLE>   MODIFIED ELECTION METHODOLOGY: A METHODOLOGY FOR DESCRIBING HUMAN BELIEFS </TITLE>
<AUTHOR>   LAMM, JAMES ERIK </AUTHOR>
<YEAR>   1993 </YEAR>
<INSTITUTION>   THE FLORIDA STATE UNIVERSITY; 0071 </INSTITUTION>
<DESCRIPTORS>   COMPUTER SCIENCE; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER>   DANIEL G. SCHWARTZ </ADVISER>
<CLASSIFICATIONS>   EXPERT SYSTEMS </CLASSIFICATIONS>
<ABSTRACT>
This dissertation presents Modified Election (or ME)
methodology and shows how it may be used to describe the
beliefs a human expert would form regarding the answer
to a given question, based on the available evidence.
For example, the methodology could be used to describe
the beliefs a heart specialist would form, regarding the
question whether a patient should be put on a low fat,
low cholesterol diet, based on whether the patient is
overweight, has a family history of heart problems, etc.
ME methodology employs statistical methods used to
interpret random samples, as well as the concept of a
"Modified Election" which is developed in this
dissertation. In ME methodology, the numbers of
"votes" for the possible outcomes in a
modified election are used to weight the different
pieces of evidence which might affect an expert's
beliefs.
Two other popular formalisms for describing beliefs are
Bayesian theory and Dempster/Shafer theory. Certain
problematic aspects of these two formalisms which
motivated ME methodology are discussed. It is then shown
how ME methodology overcomes these problems. ME
methodology may be used as the basis for the design of
expert systems. An expert system is presented which
illustrates how to do this.
</ABSTRACT>
</THESIS>
<THESIS>
<NUMBER> 4427 </NUMBER>
<ORDER>   AAG9324238 </ORDER>
<TITLE>   REPRESENTATION OF MISSION PLANS FOR SPECIAL OPERATIONS FORCES AT THE COMPANY AND DETACHMENT LEVELS </TITLE>
<AUTHOR>   VAN GRONINGEN, CHARLES NEIL </AUTHOR>
<YEAR>   1993 </YEAR>
<INSTITUTION>   ILLINOIS INSTITUTE OF TECHNOLOGY; 0091 </INSTITUTION>
<DESCRIPTORS>   COMPUTER SCIENCE; ARTIFICIAL INTELLIGENCE; OPERATIONS RESEARCH </DESCRIPTORS>
<ADVISER>   MARTHA EVENS </ADVISER>
<CLASSIFICATIONS>   MILITARY </CLASSIFICATIONS>
<ABSTRACT>
This thesis describes the development of a mission
planning tool that is to be used by personnel from the
United States Special Operations Command to plan
missions. These forces perform a wide range of missions.
The system has been developed by designing and
implementing a wide range of planning objects. Each of
these objects can be tailored for a specific type of
mission. A mission structure orders these planning
objects into a tailored interface for each type of
mission. The planning objects include functions for:
scheduling time and activities, creating equipment and
information requirements, designating movement
schematics, creating and analyzing routes, and analyzing
and creating documents.
</ABSTRACT>
</THESIS>
<THESIS>
<NUMBER> 4428 </NUMBER>
<ORDER>   AAG9324218 </ORDER>
<TITLE>   DESIGN AND MODELING OF A COMPUTER-BASED MEDICAL DECISION ANALYSIS SYSTEM FOR THE MEDAS PROJECT </TITLE>
<AUTHOR>   CHANG, CHUNG C. </AUTHOR>
<YEAR>   1993 </YEAR>
<INSTITUTION>   ILLINOIS INSTITUTE OF TECHNOLOGY; 0091 </INSTITUTION>
<DESCRIPTORS>   COMPUTER SCIENCE; HEALTH SCIENCES, MEDICINE AND SURGERY; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER>   MARTHA EVENS </ADVISER>
<CLASSIFICATIONS>   COMPUTERIZED DECISION ANALYSIS </CLASSIFICATIONS>
<ABSTRACT>
Medical decision making in treatment and testing is
known as one of the most critical tasks for physicians
in medical care. Currently, physicians usually make
clinical decisions based on their intuitive judgments.
While this intuitive approach is suitable for those
simple and fairly straightforward clinical situations,
it is difficult and insufficient to handle clinical
situations that are more ambiguous or complex, or
situations that involve dangerous or costly treatment or
tests. Therefore, a medical decision analysis system
applying modern computer technology and formal medical
decision analysis methodology to help physicians quickly
and effectively solve this kind of problem is
undoubtedly useful.
This thesis focuses on the design and modeling of a
computer-based medical decision analysis system (MEDATT)
for the MEDAS project. The main purpose of the system is
to develop an easy-to-use, clear, and effective medical
decision support tool to help practicing physicians in
making important yet difficult decisions in treatment
and testing. The fundamental methodology used in this
system is based on Weinstein and Fineberg's method and
the concept of the value of clinical information.
Three models in treatment decision analysis have been
discussed--the automated consultation model, the user
self-consultation model, and the training model. Each
model provides a different function for the system. The
automated consultation model serves as an expert system
to automatically execute treatment decision analysis
(risk, cost, life expectancy, patient morbidity, etc.)
for the physician. The user self-consultation model
performs treatment decision analysis for physicians
based on their beliefs or assessments. The training
model helps physicians acquire basic treatment decision
analysis concepts and skills applied in the system.
</ABSTRACT>
</THESIS>
<THESIS>
<NUMBER> 4429 </NUMBER>
<ORDER>   AAG9324162 </ORDER>
<TITLE>   REASONING ABOUT DOMAIN KNOWLEDGE LEVEL FOR DYNAMIC USER MODELING IN ADAPTIVE HUMAN-COMPUTER INTERFACES: A FUZZY LOGIC/NEURAL NETWORK APPROACH </TITLE>
<AUTHOR>   CHIU, CHAOCHANG </AUTHOR>
<YEAR>   1993 </YEAR>
<INSTITUTION>   UNIVERSITY OF MARYLAND BALTIMORE COUNTY; 0434 </INSTITUTION>
<DESCRIPTORS>   ENGINEERING, INDUSTRIAL; COMPUTER SCIENCE; PSYCHOLOGY, GENERAL; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER>   ANTHONY F. NORCIO </ADVISER>
<CLASSIFICATIONS>   NIL </CLASSIFICATIONS>
<ABSTRACT>
Adapting dialogue strategy to the skills and tasks of a
user is the ultimate goal of adaptive human-computer
interfaces. Dynamic user modeling offers an effective
technique for determining user requirements and for
enhancing the relationship between a user's cognitive
abilities and software sophistication. To model users
more accurately, however, a better modeling methodology
is required to accomplish this goal by gaining more
insights about user. One of the most important insights
is about a user's task domain knowledge. This knowledge
can be derived by careful inspection on the actual
dialog behavior. Only when user's expertise can be
accurately captured, can a system better determine the
subsequent interaction strategy to adapt to the user.
This study proposes a methodology that is based upon the
use of fuzzy logic and neural networks to support
modeling users dynamically. This study presents the
details of the system's underlying fuzzy logic structure
as well as its neural network architecture. The proposed
research architecture helps to produce a user model that
accurately captures user progression along the novice-
expert continuum. Consequently, the user model is able
to adapt the interface in a smooth and gradual manner
rather than discrete and sudden shifts during the
interaction session. Additionally, better system
performance is achieved by reducing system overhead, and
overcoming some inherent inconsistency and uncertainty
problems. An implementation prototype KRS (Knowledge
Reasoning System) is developed and tested using fuzzy
expert system and neural network shells running on
Microsoft Windows. This experiment results indicate the
promising future development of complete adaptive
intelligent application environments that could
efficiently determine what should adapt to the user
after the domain knowledge is captured.
</ABSTRACT>
</THESIS>
<THESIS>
<NUMBER> 4430 </NUMBER>
<ORDER>   AAG9323552 </ORDER>
<TITLE>   A THEORY OF ACTIONS, INTENTIONS, AND COMMUNICATIONS FOR MULTIAGENT SYSTEMS </TITLE>
<AUTHOR>   SINGH, MUNINDAR PAUL </AUTHOR>
<YEAR>   1993 </YEAR>
<INSTITUTION>   THE UNIVERSITY OF TEXAS AT AUSTIN; 0227 </INSTITUTION>
<DESCRIPTORS>   COMPUTER SCIENCE; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER>   ERNEST A. EMERSON, II; NICHOLAS M. ASHER </ADVISER>
<CLASSIFICATIONS>   NIL </CLASSIFICATIONS>
<ABSTRACT>
Multiagent systems are of great significance in a number
of current and future applications of Computer Science.
For example, they arise in systems for electronic data
interchange, air traffic control, manufacturing
automation, computer supported cooperative work, and
electronic banking, as well as in robotics and
heterogeneous database systems. As the nature of
computing begins to be characterized by networking and
resource-integration, multiagent systems will occur in
all key computing applications. Unfortunately, no
general framework is available at present that we may
use to specify, design, or implement multiagent systems.
The intentions and know-how of agents, and the
communications that take place among them, are important
scientific abstractions for such systems. These
abstractions (1) are natural to us, as designers, (2)
apply to agents whose implementations evolve, and (3)
may be used by the agents in reasoning about each other.
I propose a semantics of intentions and know-how in a
general model of actions and time. Using this semantics,
I also provide a semantics for the different modes of
communication, e.g., promises and prohibitions. The
proposed framework involves the programs that agents
can, and do, execute. Thus, we can use intentions, know-
how, and communications as more than just conceptual
descriptions. Their semantics is useful for comparing
implementations and for creating design tools. It also
aids us in stating constraints on system behavior that
more naturally capture users' requirements.
</ABSTRACT>
</THESIS>
<THESIS>
<NUMBER> 4431 </NUMBER>
<ORDER>   AAG9323462 </ORDER>
<TITLE>   A THEORETICAL AND COMPUTATIONAL FRAMEWORK FOR QUALITATIVE MODELING IN THE MANAGEMENT AND ECONOMICS DOMAINS </TITLE>
<AUTHOR>   LANG, KARL REINER </AUTHOR>
<YEAR>   1993 </YEAR>
<INSTITUTION>   THE UNIVERSITY OF TEXAS AT AUSTIN; 0227 </INSTITUTION>
<DESCRIPTORS>   OPERATIONS RESEARCH; BUSINESS ADMINISTRATION, MANAGEMENT; ECONOMICS, GENERAL </DESCRIPTORS>
<ADVISER>   ANDREW B. WHINSTON </ADVISER>
<CLASSIFICATIONS>   NIL </CLASSIFICATIONS>
<ABSTRACT>
The thesis is concerned with the development of formal
methods for representing and analyzing management and
economics systems using qualitative knowledge. While
qualitative concepts predominate in management research,
little consideration has been given to possible
mathematical representations and derivations. The thesis
organized into four parts. Part one presents an
introduction and history of qualitative reasoning,
including the work done in economics and artificial
intelligence. The chapter introduces the mathematical
concept of a correspondence and restriction of a
correspondence, and the role of these concepts in
developing an abstract formality that integrates the
work in economics and artificial intelligence. The
possibility of qualitative optimization is introduced.
The second part of the thesis presents a formal
development of qualitative modeling. Precise
characterizations of qualitative modeling and
qualitative solution methods are defined and discussed.
Section three presents an application of qualitative
ideas to enterprise-wide modeling. An example is
presented to illustrate how the computational ideas
would be applied. The last part of the thesis discusses
an approach of developing more extensive enterprise
modeling capabilities and the interrelationship with
management research.
</ABSTRACT>
</THESIS>
<THESIS>
<NUMBER> 4432 </NUMBER>
<ORDER>   AAG9323360 </ORDER>
<TITLE>   CLICHE-BASED MODELING FOR EXPERT PROBLEM-SOLVING SYSTEMS </TITLE>
<AUTHOR>   CHANG, RUEY-JUIN </AUTHOR>
<YEAR>   1993 </YEAR>
<INSTITUTION>   THE UNIVERSITY OF TEXAS AT AUSTIN; 0227 </INSTITUTION>
<DESCRIPTORS>   COMPUTER SCIENCE; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER>   GORDON S. NOVAK, JR. </ADVISER>
<CLASSIFICATIONS>   EXPERT SYSTEMS </CLASSIFICATIONS>
<ABSTRACT>
A human analyst who wishes to answer a question such as
"What is the total energy production of counties
within 100 miles of Austin?" must use several types
of reasoning. Geometric reasoning is required to find
the counties that are within 100 miles of Austin. One or
more databases may contain data about different forms of
energy production. Physics reasoning may be required to
convert the existing form of data (e.g., barrels of oil,
tons of coal) into the desired form (energy equivalent).
The goal of this dissertation is to develop methods for
automating the construction of computer programs to
answer analysis questions. To achieve that, a cliche-
based modeling approach for problem solving is proposed.
Analysis programs are specified by selecting and
connecting high-level, generic models of problem-solving
components, which we term cliches. A reflective
architecture is described that allows such structures of
high-level, generic components to be specialized into
executable programs. Reflection provides great
flexibility in adapting the generic components to fit
the particular features of an application. In this way,
problem solving is viewed as a modeling activity rather
than a programming activity.
Four kinds of cliche components have been identified in
this research. Task components are used to model target
problems, which may have alternative solution structures
composed of method components. Method components provide
either direct solutions or decompositions into subtasks.
Control components specify connections and ordering of
cliche components for a reflective architecture. Data
description components describe data in application
domains.
Concepts of the cliche-based modeling for problem
solving have been demonstrated by a test-bed system,
called Analyst's Workbench. This system is designed to
help analysts to interactively select, construct and
edit analysis models by a graphical user interface, and
to compile these models into programs for answering a
family of analysis questions.
The major contributions of this dissertation are (1) a
cliche model to coherently represent problem-solving
components, (2) a cliche-based reflective architecture,
which provides an extensible framework for plugging
together generic components to generate application-
specific programs for problem solving.
</ABSTRACT>
</THESIS>
<THESIS>
<NUMBER> 4433 </NUMBER>
<ORDER>   AAG9323357 </ORDER>
<TITLE>   A KNOWLEDGE-BASED METHODOLOGY FOR VALIDATING DEPENDABILITY MODELS </TITLE>
<AUTHOR>   CHANDRA, ARUN </AUTHOR>
<YEAR>   1993 </YEAR>
<INSTITUTION>   THE UNIVERSITY OF TEXAS AT AUSTIN; 0227 </INSTITUTION>
<DESCRIPTORS>   COMPUTER SCIENCE; ENGINEERING, ELECTRONICS AND ELECTRICAL; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER>   CHUAN-LIN WU </ADVISER>
<CLASSIFICATIONS>   NIL </CLASSIFICATIONS>
<ABSTRACT>
The important problem of validating models used in
dependability analysis is addressed. The lack of model
visibility makes model validation difficult and without
adequate validation, there is a risk involved in using
the results of dependability analysis. This risk has to
be reduced considerably for both critical and non-
critical applications.
A knowledge-based methodology for validation of
dependability models is developed. The scope of this
methodology is limited to conceptual validation with
respect to model completeness and model consistency.
Knowledge derived from the system specification is used
for model validation. Knowledge concerning dependability
models is also stored in the knowledge base, thus
enhancing model visibility. The model validation process
primarily involves: (1) Generating a reference model for
a targeted system given the system knowledge in the
knowledge base, (2) Translating the target dependability
model into the reference model format given the model
knowledge in the knowledge base, and (3) Comparing the
two models in the reference model format to find
incompleteness and inconsistencies in the target
dependability model. Event trees are used as the common
format for both reference and target models. Also, for
validating complex system models, this methodology
generates and compares hierarchical models.
The effectiveness of this methodology is verified by
validating the dependability models of some example
systems. Five simple systems and ten complex systems are
selected, primarily from published literature. For
testing purposes, errors are introduced in some of the
dependability models of these systems. All errors
introduced are detected, and for some models, more
errors are detected than introduced. The reason for the
latter is that these models had voluntary omissions or
errors.
This effort is also generalized with the definition and
specification of a knowledge-based framework for
analysis of fault-tolerant systems. The major components
of this framework are: (1) An intelligent model building
aid, (2) A multilayered model evaluation methodology,
and (3) A model validation and improvement mechanism.
</ABSTRACT>
</THESIS>
<THESIS>
<NUMBER> 4434 </NUMBER>
<ORDER>   AAG9323348 </ORDER>
<TITLE>   INFERENCING ON LARGE DATA SETS </TITLE>
<AUTHOR>   BRANT, DAVID ANDREW </AUTHOR>
<YEAR>   1993 </YEAR>
<INSTITUTION>   THE UNIVERSITY OF TEXAS AT AUSTIN; 0227 </INSTITUTION>
<DESCRIPTORS>   COMPUTER SCIENCE; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER>   DANIEL P. MIRANKER </ADVISER>
<CLASSIFICATIONS>   EXPERT SYSTEM </CLASSIFICATIONS>
<ABSTRACT>
Rule-based systems are a well established means for
encoding the specialized knowledge of an expert system.
There is a strong interest in expanding the scope of
this technology to allow rule programs to inference on
large data sets, on the scale of a typical database
system. This has led to an area of research directed
toward the integration of rule and database systems--
known variously as expert database systems, knowledge-
base systems, database rule systems, and active database
systems. However, the underlying rule matching
algorithms currently in use have a worst-case space and
time complexity of ${rm O}(nsp{c}),$ where n is the
number of tuples in the database and c is the number of
positive condition elements in the rule containing the
most positive condition elements (typically three to
five). While these systems seldom exhibit worst-case
behavior, they do display extremes in space requirements
that can easily exhaust the entire virtual storage of
large modern computer systems. The space and time
requirements are a result of the eager technique of
maintaining the set of all instantiations for all rules
from one rule firing to the next, even though only a
single instantiation is fired. We have developed a
matching algorithm that reduces the worst-case space to
O(n) for systems without negation and O(min(max
timestamp, $nspnu))$ for rules with negation, where max
timestamp is a count of the number of tuples that have
been in the database over the life of the program, and
$nu$ is the maximum number of positive condition
elements that share a variable with a negated condition
element. Moreover, we have significantly improved the
average-case time and space demands of these systems as
well. The technique used is known as lazy matching and
is based on finding only the instantiation to be fired
on any given rule cycle. The result is a rule system
that can effectively inference on data sets on the order
of 10$sp6$ tuples.
</ABSTRACT>
</THESIS>
<THESIS>
<NUMBER> 4435 </NUMBER>
<ORDER>   AAG9323265 </ORDER>
<TITLE>   PERFORMANCE DEBUGGING ENVIRONMENTS FOR PARALLEL PROGRAMS </TITLE>
<AUTHOR>   SARUKKAI, SEKHAR RANGARAJAN </AUTHOR>
<YEAR>   1993 </YEAR>
<INSTITUTION>   INDIANA UNIVERSITY; 0093 </INSTITUTION>
<DESCRIPTORS>   COMPUTER SCIENCE; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER>   DENNIS GANNON </ADVISER>
<CLASSIFICATIONS>   PROGRAM DEPENDENCE GRAPH </CLASSIFICATIONS>
<ABSTRACT>
While writing a good parallel program is hard, writing
one which is efficient is harder still. Though compiler
technology is improving, we cannot expect it to turn all
inefficient parallel programs into efficient ones. This
is due to the fact that parallel algorithms can fail in
many more dramatic ways than sequential algorithms
running on conventional hardware. Consequently, a
powerful performance debugging system must be an
integral part of a parallel program development
environment.
Most of the existing parallel program debugging
approaches have been ad-hoc and tailored to specific
machines. In this work we develop a novel approach for
developing portable and programmable performance
debugging environments, which addresses a number of
important issues including instrumentation, performance
visualization and scalability studies. Central to the
approach is the use of the program dependence graph and
the treatment of the program performance data as a
historical database. We demonstrate with the help of
examples that a systematic application of program views
can help in debugging the performance of programs. We
also develop a method for reducing the perturbations
introduced in a program execution, due to source level
instrumentation, using event and time based analysis.
</ABSTRACT>
</THESIS>
<THESIS>
<NUMBER> 4436 </NUMBER>
<ORDER>   AAG9323216 </ORDER>
<TITLE>   ABSTRACTION OF CONTROL AND SYNTAX IN SCHEME </TITLE>
<AUTHOR>   HIEB, ROBERT G. </AUTHOR>
<YEAR>   1993 </YEAR>
<INSTITUTION>   INDIANA UNIVERSITY; 0093 </INSTITUTION>
<DESCRIPTORS>   COMPUTER SCIENCE; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER>   R. KENT DYBVIG </ADVISER>
<CLASSIFICATIONS>   ARTIFICIAL INTELLIGENCE, PROGRAMMING LANGUAGE </CLASSIFICATIONS>
<ABSTRACT>
This dissertation covers four related language design
and implementation topics within the context of the
programming language Scheme.
The first part of this dissertation describes a
convenient and efficient procedural interface that
allows the definition and use of procedures with
optional and indefinite numbers of arguments without the
need for a language-dependent data structure in which to
store the arguments. This interface solves many problems
inherent in the use of lists to store indefinite numbers
of arguments. A natural multiple return value extension
is also presented.
Traditional continuations are not useful in the presence
of concurrency, because the notion of the rest of the
computation represented by a continuation does not in
general make sense. The second part of this dissertation
presents a new type of continuation that may be used to
control tree-structured concurrency. Process
continuations allow nonlocal exits from arbitrary
subtrees of a process tree and allow the capture of
arbitrary subtrees as composable continuations for later
use. Even in the absence of concurrency, the precise
control achievable with process continuations makes them
more useful than traditional continuations.
The syntactic theories of control and state are
conservative extensions of the $lambdasb{v}$-calculus
for equational reasoning about imperative programming
facilities in higher-order languages. Unlike the simple
$lambdasb{v}$-calculus, the extended theories are
mixtures of equivalence relations and compatible
congruence relations on the term language, significantly
complicating the reasoning process. The third part of
this dissertation develops fully compatible equational
theories of the same imperative higher-order programming
languages. The new theories subsume the original calculi
and satisfy the usual Church-Rosser and Standardization
Theorems. With the new calculi, equation reasoning about
imperative programs becomes as simple as reasoning about
functional programs.
Naive program transformations can result in the
inadvertent capture of identifiers due to interactions
among existing and introduced bindings and references.
Furthermore, transformed programs may have little
resemblance to the original programs, complicating
correlation of source and object code. The fourth part
of this dissertation introduces a new approach to
implementing syntactic transformations and a new
representation for syntactic expressions. It allows the
programmer to define program transformations using an
unrestricted, general-purpose language, while helping
the programmer avoid capturing problems and maintaining
a correlation between the original and transformed code.
</ABSTRACT>
</THESIS>
<THESIS>
<NUMBER> 4437 </NUMBER>
<ORDER>   AAG9322795 </ORDER>
<TITLE>   AN INTELLIGENT TOOL FOR EXPERIENCED PROGRAMMERS LEARNING ADA </TITLE>
<AUTHOR>   FIX, VIKKI LORRAINE </AUTHOR>
<YEAR>   1993 </YEAR>
<INSTITUTION>   THE UNIVERSITY OF NEBRASKA - LINCOLN; 0138 </INSTITUTION>
<DESCRIPTORS>   COMPUTER SCIENCE; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER>   SUSAN WIEDENBECK </ADVISER>
<CLASSIFICATIONS>   PROGRAMMER LEARNING </CLASSIFICATIONS>
<ABSTRACT>
When experienced programmers learn a new language, their
previous planning knowledge results in both positive and
negative transfer to the new language. A tool to help
them learn the new language must include planning as an
important component and the planning help must consider
the previous planning knowledge of the programmer.
Several existing programming tutors guide novice users
through a few simple problems and spend at least as much
time on coding as on planning. This dissertation
describes an intelligent tool built to help experienced
Pascal or C programmers learn to use Ada packages to
create reusable software components.
Empirical studies were completed to determine the
knowledge base of correct and buggy plans used by
programmers as they create modules which use packages.
This knowledge base is used to model the student and to
diagnose errors. Given an exercise, the student creates
a solution by working from high-level plans to more
detailed plans to code. This method of solution
simulates a programmer using pseudocode for planning and
replacing plans with code when the way to implement a
plan becomes clear. When it is clear that the student is
using a plan from a previous language that is impossible
or extremely suboptimal in Ada, the tool intervenes to
get the user back on a productive path. The tool uses
model-tracing for diagnosis. In some situations,
students choose from a menu to indicate their mental
state, and in other situations, plan recognition is used
to determine their mental state from their intermediate
actions.
The initial version of the tool was evaluated in a study
in which programmers at the senior or graduate level
used the tool to solve one problem and then completed
transfer tasks. The results of the study showed that
subjects learned package concepts using the tool. The
results also suggest improvements for the next version
of the tool.
</ABSTRACT>
</THESIS>
<THESIS>
<NUMBER> 4438 </NUMBER>
<ORDER>   AAG9322747 </ORDER>
<TITLE>   A NEURAL NETWORK ARCHITECTURE FOR GENERATING ARTIFICIAL POTENTIAL FIELDS </TITLE>
<AUTHOR>   KASSIM, ASHRAF ALI </AUTHOR>
<YEAR>   1993 </YEAR>
<INSTITUTION>   CARNEGIE-MELLON UNIVERSITY; 0041 </INSTITUTION>
<DESCRIPTORS>   ENGINEERING, ELECTRONICS AND ELECTRICAL; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER>   B. V. K. VIJAYA KUMAR </ADVISER>
<CLASSIFICATIONS>   ROBOTICS, PATH PLANNING </CLASSIFICATIONS>
<ABSTRACT>
In the potential field approach to path planning, the
development of the artificial potential field (APF) is
the most computationally expensive operation. APF
development and the subsequent path planning are carried
out either in the moving object's physical workspace or
configuration space. The realization that the APFs can
be developed by parallel distributed techniques has
prompted recent interest in using neural networks for
developing APFs. This thesis introduces a new neural
network architecture capable of exhibiting behavior
reminiscent of wavefront expansion which is useful for
developing APFs over discretized representations of a
moving object's environment (i.e. physical workspace or
configuration space). We call this neural network the
Wave Expansion Neural Network or WENN. In this thesis,
we analyze the dynamics of the WENN and examine the
ability of the WENN to develop various APFs over
different environments. We also describe methodologies
which use the APFs developed by WENNs to plan paths for
objects with two or three degrees of freedom. One such
methodology uses a workspace skeleton extracted from an
APF developed by a WENN. All other neural networks which
are also capable of developing APFs have only been used
for the development of one particular type of APF. The
WENN, on the other hand, is capable of developing a
variety of APFs making it more versatile than the other
neural networks. We will also show that the dynamics of
the WENN can be efficiently emulated both in
conventional processing systems as well as distributed
processing systems which have the potential of real-time
APF development. In summary, we introduce, analyze and
evaluate a new neural network architecture called WENN
that is capable of producing artificial potential fields
that are of use in path planning.
</ABSTRACT>
</THESIS>
<THESIS>
<NUMBER> 4439 </NUMBER>
<ORDER>   AAG9322590 </ORDER>
<TITLE>   OPTICAL MEASUREMENT OF INTRACELLULAR PH IN BRAIN TISSUE AND THE QUANTITATIVE APPLICATION OF ARTIFICIAL NEURAL NETWORKS TO SPECTRAL ANALYSIS </TITLE>
<AUTHOR>   LIN, CHII-WANN </AUTHOR>
<YEAR>   1993 </YEAR>
<INSTITUTION>   CASE WESTERN RESERVE UNIVERSITY; 0042 </INSTITUTION>
<DESCRIPTORS>   ENGINEERING, BIOMEDICAL; BIOLOGY, NEUROSCIENCE; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER>   JOSEPH C. LAMANNA </ADVISER>
<CLASSIFICATIONS>   NIL </CLASSIFICATIONS>
<ABSTRACT>
Compartmental distribution of protons and associated
regulation mechanisms are important aspects of brain
functions. The dynamic regulation of proton
concentration in brain tissue is essential for
maintaining normal metabolic and electrophysiological
activities. Two optical methods are used because of
their superior spatial and temporal resolution and the
potential capability for measurement of multiple ionic
species. Neutral red (NR) and carboxy-
seminaphthorhodaflur-1 (SNARF-1) are used to measure
intracellular pH in hippocampal brain slices and in vivo
brain. The evidence suggests that these two dyes locate
in different compartments. NR may enter both neuronal
and glial compartments while SNARF-1 predominantly
stains the neuronal compartment. The different baseline
pH$sb{rm i}$ reading observed by using these two dyes
also suggest that different pH regulation schemes are
used in these two compartments. The effect of the
Na$sp+$/H$sp+$ exchanger blockers, amiloride and its
analogs, are tested on the recovery slope of NH$sb4$Cl
acid-loading technique. The different responses to the
amiloride suggest that different set point for the
activation of Na$sp+$/H$sp+$ exchanger in these two
compartments may operate in the slice preparation.
Quantitative application of artificial neural network is
demonstrated with the spectral recognition for pH value
output. A working network can be trained with a set of
teaching spectra from a small random connection weight
matrix or from one with previous experience by using
generalized delta rule and back-propogation for weight
modification. The imprinting of principal components of
the teaching patterns is distributively stored within
the connection weight matrix of the input to hidden
layers. A calibration curve needs to be constructed to
translate the actual output values of the network to pH
values after the convergence with training patterns. The
quantitative output during performing phase is the inner
product of weight matrix and the input vectors (unknown
patterns). This method can thus achieve the real-time
quantitative application with learning from example
spectra.
</ABSTRACT>
</THESIS>
<THESIS>
<NUMBER> 4440 </NUMBER>
<ORDER>   AAG9322501 </ORDER>
<TITLE>   A FUZZY LINGUISTIC ARTIFICIAL INTELLIGENCE MODEL FOR ASSESSING RISKS OF CUMULATIVE TRAUMA DISORDERS OF THE FOREARM AND HAND </TITLE>
<AUTHOR>   MCCAULEY-BELL, PAMELA ROCHELLE </AUTHOR>
<YEAR>   1993 </YEAR>
<INSTITUTION>   THE UNIVERSITY OF OKLAHOMA; 0169 </INSTITUTION>
<DESCRIPTORS>   ENGINEERING, INDUSTRIAL; ENGINEERING, SYSTEM SCIENCE; COMPUTER SCIENCE; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER>   NIL </ADVISER>
<CLASSIFICATIONS>   NIL </CLASSIFICATIONS>
<ABSTRACT>
The purpose of this research was to develop a fuzzy
expert system to be used in industrial and medical
settings for the purpose of predicting the risk of
employee injury in the workplace. The expert system
(CTXPERT) focuses on cumulative trauma disorders (CTDs)
of the forearm and hand. CTDs are injuries of the soft
tissues that may result from a number of factors
including repetitive motion, awkward posture, and
excessive force. Various knowledge acquisition
methodologies were used to develop the knowledge base
and the Analytic Hierarchy Process (AHP) was used to
assign relative weights to the determined risk factors.
To provide a decision, the model requires three
components of input: task characteristics, personal
characteristics, and organizational characteristics. The
system uses linguistic risk levels as well as quantified
risks in assessing the overall risk of injury. A system
evaluation was conducted and the accuracy of the
predictions was 80%. The Type I and Type II errors were
calculated and were 19% and 22% respectively. The
limitations and contributions of the system are
discussed.
</ABSTRACT>
</THESIS>
<THESIS>
<NUMBER> 4441 </NUMBER>
<ORDER>   AAG9322089 </ORDER>
<TITLE>   APPLYING STATISTICAL INFERENCE TO PLANNING UNDER UNCERTAINTY </TITLE>
<AUTHOR>   MARTIN, NATHANIEL GRAFTON </AUTHOR>
<YEAR>   1993 </YEAR>
<INSTITUTION>   THE UNIVERSITY OF ROCHESTER; 0188 </INSTITUTION>
<DESCRIPTORS>   COMPUTER SCIENCE; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER>   JAMES F. ALLEN </ADVISER>
<CLASSIFICATIONS>   DECISION THEORY, PLANNING SYSTEM </CLASSIFICATIONS>
<ABSTRACT>
Because planning involves reasoning about the future,
uncertainty permeates it. Some recent planners represent
uncertainty about actions and observation by
probability. Unfortunately, unless experts are available
to quantify this uncertainty, it is difficult to assess
them. This dissertation explores techniques for
representing knowledge so that a planning system can use
its experience to reason about probability in uncertain
situations.
To support this type of knowledge representation, the
dissertation develops a formal event-based language in
which the planner's probabilities are calculated from
the binomial random variable generated by the ratio of
one type of event to another. Inferences about the long-
run ratio of these events can be made using statistics.
Inferences about the validity of the approximations
provided by the statistics allow the planner to avoid
making choices that are only weakly supported by the
planner's evidence.
To test the techniques investigated in the development
of the formal language, a planning language, based on
the formal language, was developed. The complexity of
reasoning about probability makes generating plans that
take full account of uncertainty impossible. As an
alternative to a planner that uses the planning
language, a planning assistant was designed and
implemented. This planning assistant performs three
services for a logic-based planner. It advises the
planner about appropriate actions, executes plans
generated by the planner, and monitors the plans it
executes.
</ABSTRACT>
</THESIS>
<THESIS>
<NUMBER> 4442 </NUMBER>
<ORDER>   AAG9322042 </ORDER>
<TITLE>   AUTOMATING NEGOTIATED DESIGN INTEGRATION: FORMAL REPRESENTATIONS AND ALGORITHMS FOR COLLABORATIVE DESIGN </TITLE>
<AUTHOR>   ROBINSON, WILLIAM NORTON </AUTHOR>
<YEAR>   1993 </YEAR>
<INSTITUTION>   UNIVERSITY OF OREGON; 0171 </INSTITUTION>
<DESCRIPTORS>   COMPUTER SCIENCE; ENGINEERING, SYSTEM SCIENCE; INFORMATION SCIENCE </DESCRIPTORS>
<ADVISER>   NIL </ADVISER>
<CLASSIFICATIONS>   NIL </CLASSIFICATIONS>
<ABSTRACT>
This dissertation presents a methodology and automated
algorithms for collaborative design. The methodology
calls for individuals to independently create designs
achieving their own goals, and then collectively derive
a single unified design using automated negotiation
techniques. From a software engineering perspective, the
methodology provides parallelism, simplicity, rationale,
and reuse. From a negotiation perspective, the
methodology provides multiple agent preference
maximization and novel resolution synthesis. From an
artificial intelligence perspective, the algorithms
provide automation of the complex processes of conflict
detection, resolution synthesis, and resolution
selection. This dissertation describes how the selfish
interests of individuals or subgroups can productively
aid the derivation of robust collaborative designs
through the automated negotiation of their conflicts.
This dissertation describes formal representations for
modeling individual perspectives, design conflicts, and
subtasks involved in negotiation. Specifically described
are representations for: (1) goals and preferences over
domain operators, objects, and relations, (2) categories
of design and goal conflicts, and (3) categories of
conflict resolutions. Automated processes can manipulate
these representations to aid group negotiation.
This dissertation describes formal algorithms for
detecting conflicts and synthesizing resolutions.
Specifically described are algorithms for: (1)
distinguishing between simple design differences and
design interference, (2) mapping between goals and their
supporting design components, (3) detecting goal
conflicts, (4) synthesizing analytic and heuristic
resolutions, and (5) reintegrating resolved goals into a
design. Analytic resolution consists of compromise
generation using a multiple criteria linear programming
method. Heuristic resolution consists of search through
domain hierarchies to synthesize dissolutions and
compensations. These methods have been implemented and
applied.
This dissertation describes the implementation of our
negotiation algorithms and their application to library
design problems. The design of library systems is a
complex, multiple agent, negotiation enterprise. We have
represented portions of documented library designs in
our implemented collaborative design tool, Oz. Oz has
been used to detect conflicts and derive negotiated
resolutions similar to those published by expert
librarians. The implementation and its application to
the library domain support the central tenet of this
dissertation: processes of negotiated design can be
automated through the representation of a generic domain
model and specific representations of individual
perspectives.
</ABSTRACT>
</THESIS>
<THESIS>
<NUMBER> 4443 </NUMBER>
<ORDER>   AAG9322013 </ORDER>
<TITLE>   AUTOMATING REQUIREMENTS ENGINEERING USING ARTIFICIAL INTELLIGENCE PLANNING TECHNIQUES </TITLE>
<AUTHOR>   ANDERSON, JOHN SEARLES </AUTHOR>
<YEAR>   1993 </YEAR>
<INSTITUTION>   UNIVERSITY OF OREGON; 0171 </INSTITUTION>
<DESCRIPTORS>   COMPUTER SCIENCE; ARTIFICIAL INTELLIGENCE; INFORMATION SCIENCE </DESCRIPTORS>
<ADVISER>   NIL </ADVISER>
<CLASSIFICATIONS>   REACTIVE SYSTEMS, LIBRARY DATABASES </CLASSIFICATIONS>
<ABSTRACT>
Requirements engineering is a critical and yet poorly
understood aspect of software engineering and other
complex design tasks. In this dissertation I focus on
requirements engineering for a particular class of
designed artifacts, referred to as reactive systems,
which provide services in response to events in the
environment. For this class of systems, the requirements
engineering task is to identify the set of services that
best satisfy the client's requirements, and to ensure
that the client understands and agrees to any trade-offs
between competing concerns such as functionality,
performance, ease of use, and cost. Coming to consensus
requires bridging the gap between the client's
requirements, which describe states in the application
domain, and the functional specification, which
describes the services to be provided by the target
artifact.
My thesis is that the process of constructing and
validating a functional specification of a reactive
system can be carried out using artificial intelligence
planning techniques. The client's requirements can be
expressed as a set of planning problems: finding a
sequence of actions that lead from an initial state to a
goal state. The sequence of actions required to reach
the goal state may include actions to be performed by
the target artifact. These actions determine the
services that must be provided by the target artifact.
I have implemented an automated planner and used it to
explore the role of planning in the requirements
engineering process. In this dissertation I first
describe how requirements engineering can be viewed as a
planning problem in which actions are composed into
sequences that achieve goal states. I then show how the
automated planner can be used in several parts of the
requirements engineering process: proposing action
sequences that satisfy the requirements, constructing
functional specifications based on those sequences, and
critiquing the functional specifications by showing
violations of client restrictions. I describe an
extended example of using the automated planner to
develop a functional specification of a benchmark
problem, a library database. I evaluate the strengths
and weaknesses of the planning approach to requirements
engineering based on experience with the automated
planner.
</ABSTRACT>
</THESIS>
<THESIS>
<NUMBER> 4444 </NUMBER>
<ORDER>   AAG9321989 </ORDER>
<TITLE>   KNOWLEDGE ORGANIZATION FOR A FAILURE MODES AND EFFECTS ANALYSIS </TITLE>
<AUTHOR>   RUSSOMANNO, DAVID JAMES </AUTHOR>
<YEAR>   1993 </YEAR>
<INSTITUTION>   UNIVERSITY OF SOUTH CAROLINA; 0202 </INSTITUTION>
<DESCRIPTORS>   ENGINEERING, ELECTRONICS AND ELECTRICAL; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER>   RONALD D. BONNELL </ADVISER>
<CLASSIFICATIONS>   FMEA </CLASSIFICATIONS>
<ABSTRACT>
Failure Modes and Effects Analysis (FMEA) software has
not significantly exploited artificial intelligence (AI)
techniques, nor has the knowledge possessed by a team of
FMEA experts been thoroughly investigated. Attempts have
been made to automate the FMEA process; however, these
implementations and techniques have utilized little or
no AI methods. Instead, they have emphasized clerical
functions, data collection, database manipulations, and
automatic report generation. This dissertation
investigates the knowledge organization and distribution
of an expert system for failure modes and effects
analysis (XFMEA). The primary contribution of this work
is the specification of the organization, distribution,
and nature of the requisite, problem-solving knowledge
necessary to migrate computer-aided FMEA programs toward
an AI approach.
The design of the XFMEA system is approached from a
knowledge-use level perspective to provide a complete
understanding of the problem. The blackboard paradigm is
utilized to functionally decompose XFMEA into a set of
knowledge sources, each containing the knowledge
associated with a subfunction of the FMEA task. This
research seeks to establish the theoretical background
that is required for integrating and traversing diverse
knowledge representation formalisms and inference
procedures which organize and focus a simulation
subsystem for XFMEA. Functional FMEA methodology is
emphasized with the motivation to include FMEA as an
integral constituent in the design process. Furthermore,
the research argues that employing a blackboard
framework as the computational construct for XFMEA is a
key to successful automation. The research specifies an
experimental XFMEA framework for relating a failure mode
to an effect. Experiments are conducted that illustrate
the utility of the developed theory. Although pragmatic
extensions to the proposed paradigm are necessary to
build a significant prototype system; the organizational
model, problem-solving heuristics, and symbol-level
details developed in this research provide a substrate
for building knowledge-based, computer-aided FMEA
systems.
</ABSTRACT>
</THESIS>
<THESIS>
<NUMBER> 4445 </NUMBER>
<ORDER>   AAG9320567 </ORDER>
<TITLE>   PHYSICALLY-BASED MODELING AND DISTRIBUTED COMPUTATION FOR SIMULATION OF DYNAMIC TERRAIN IN VIRTUAL ENVIRONMENTS </TITLE>
<AUTHOR>   LI, XIN </AUTHOR>
<YEAR>   1993 </YEAR>
<INSTITUTION>   UNIVERSITY OF CENTRAL FLORIDA; 0705 </INSTITUTION>
<DESCRIPTORS>   COMPUTER SCIENCE; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER>   J. MICHAEL MOSHELL </ADVISER>
<CLASSIFICATIONS>   SOIL DYNAMICS </CLASSIFICATIONS>
<ABSTRACT>
In a complex interactive training or simulation system,
a large number of simulation entities and a large set of
geographical data are involved. Networked virtual
environments are being built to provide the capability,
within realtime graphical simulation, of reconstructing
landscape architecture or rearranging the terrain
surface. Under those actions, objects must be faithful
to the laws of physics and behave appropriately in
response. The geographical database and simulation
entities are desired to be partitioned and distributed
across loosely coupled networks of simulators to meet
requirements of low cost and high efficiency.
This research work is dedicated to resolutions of the
above issues. Physically-based soil models are
established to provide physical realism of a realtime
simulation. Distribution strategies are also presented
and estimated for performances of systems. The results
of the research are summarized in two parts. For
physically-based models, soil properties and behaviors
are investigated. Realtime graphical models for soil
slippage and manipulations are introduced to simulate
excavating activities on the dynamic terrain. For
distributed computations, approaches for distributing
terrain databases and simulation entities across loosely
coupled networks of simulators are proposed. An
analytical model is then defined, which can be used to
estimate quantitatively expenses of a distributed
system. Experimental simulation study is also conducted
to provide a verification of the correctness of the
analytical method.
</ABSTRACT>
</THESIS>
<THESIS>
<NUMBER> 4446 </NUMBER>
<ORDER>   AAG9319310 </ORDER>
<TITLE>   A CONCEPTUAL DESIGN FOR ORDER PICKING AND LOAD FORMING WITH ROBOTIC PALLETIZING VEHICLES </TITLE>
<AUTHOR>   BLOEMER, KENNETH F. </AUTHOR>
<YEAR>   1993 </YEAR>
<INSTITUTION>   UNIVERSITY OF CINCINNATI; 0045 </INSTITUTION>
<DESCRIPTORS>   ENGINEERING, INDUSTRIAL </DESCRIPTORS>
<ADVISER>   RICHARD L. SHELL </ADVISER>
<CLASSIFICATIONS>   NIL </CLASSIFICATIONS>
<ABSTRACT>
This research focuses on the development of a conceptual
model of a distribution center (DC) which utilizes
robotic palletizing vehicles (RPVs) for the most costly
and labor intensive activities--order picking and load
forming. RPVs are a synergistic integration of automated
vehicles, industrial robots and artificial intelligence.
RPVs are not commercially available at the present time;
however, the necessary mechanical components and control
technologies have been successfully employed in industry
for years. The DC model does not concentrate on total
automation; rather, it is a harmonious combination of
manual labor, traditional material handling equipment,
and sophisticated guided vehicle, robotic, and
artificial intelligence technologies.
This research will concentrate on low to medium volume
DCs which receive materials in uniform palletized loads
and ship complex orders composed of multiple stock
keeping units. This mode of operation is typical today
of many industries, including food products and consumer
goods industries. This work is intended to be inventive
and imaginative, yet as pragmatic as possible. An
underlying objective is to develop the RPV and the RPV-
based DC environment in sufficient detail to assist a
team of experts in developing a prototype RPV and a
demonstration DC.
This effort has established that an RPV-based DC is both
technologically and functionally feasible. The primary
benefits of the demonstration DC include: relieving
humans from the fatiguing, monotonous and hazardous work
of order picking and load forming; improved quality of
life for DC personnel; higher order integrity (i.e.,
elimination of picking errors); elimination of outbound
order inspection; reduced product damage; and, increased
flexibility in adapting to changes in volume without
significant addition or reduction of personnel. The
primary disadvantages of the RPV-based DC include the
significant risk involved with the implementation of new
technology and the high initial investment required.
In the author's opinion based on evidence presented
herein, the emergence of RPVs or similar devices in the
near future is indisputable. As global competition in
both manufacturing and distribution escalates, RPVs and
related technologies will provide distribution centers
with the productivity edge necessary to successfully
compete in the global marketplace.
</ABSTRACT>
</THESIS>
<THESIS>
<NUMBER> 4447 </NUMBER>
<ORDER>   AAG9326584 </ORDER>
<TITLE>   A SYNERGISTIC APPROACH TO INTELLIGENT MONITORING OF LARGE PROJECTS </TITLE>
<AUTHOR>   AL-SUNAIDI, SALEH SALIM </AUTHOR>
<YEAR>   1993 </YEAR>
<INSTITUTION>   UNIVERSITY OF MISSOURI - ROLLA; 0135 </INSTITUTION>
<DESCRIPTORS>   BUSINESS ADMINISTRATION, MANAGEMENT; COMPUTER SCIENCE; ENGINEERING, INDUSTRIAL; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER>   YILDIRIM OMURTAG; COLIN O. BENJAMIN </ADVISER>
<CLASSIFICATIONS>   NIL </CLASSIFICATIONS>
<ABSTRACT>
This dissertation addresses the need for a more
innovative, flexible, and dynamic approach to project
management in an environment of increasing uncertainty.
It also explores solutions to the problems posed by
inexperienced project managers and inadequate project
techniques and systems for monitoring and controlling
large projects in developing countries. To address these
problems, an intelligent data analysis and
interpretation framework that combines project
monitoring and artificial intelligence concepts was
developed. The framework suggests a synergistic approach
that can be used by managers and system designers for
developing an automated intelligent monitoring decision
support system (IMDSS).
To validate the suitability of this framework and to
identify its effectiveness to the monitoring and control
function, a microcomputer-based decision support system
(DSS) was developed and tested. The system conducts an
intelligent analysis of project data, flags significant
project deviations, and suggests possible remedial
action in a timely manner. Synergy is achieved through
the effective integration of AI techniques with database
management systems (DBMSs) and conventional project
management software. This AI-based DSS performed very
credibly when tested at both the development and user
environments. Results indicate that the system can be an
effective and productive tool in monitoring and
controlling large engineering projects. These
encouraging results suggest that the proposed framework
is feasible and could be applied to improve decision
making in many data-intensive management systems
(DIMSs).
</ABSTRACT>
</THESIS>
<THESIS>
<NUMBER> 4448 </NUMBER>
<ORDER>   AAG9326105 </ORDER>
<TITLE>   NEURAL NETWORKS IN FINANCIAL DISTRESS PREDICTION: AN APPLICATION TO THE LIFE INSURANCE INDUSTRY </TITLE>
<AUTHOR>   HUANG, CHIN-SHENG </AUTHOR>
<YEAR>   1993 </YEAR>
<INSTITUTION>   THE UNIVERSITY OF MISSISSIPPI; 0131 </INSTITUTION>
<DESCRIPTORS>   ECONOMICS, FINANCE; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER>   ROBERT E. DORSEY </ADVISER>
<CLASSIFICATIONS>   NIL </CLASSIFICATIONS>
<ABSTRACT>
In this dissertation, a multi-layered feedforward neural
network trained with the genetic algorithm (ANN) is used
to forecast financial distress in life insurers.
Comparisons of prediction efficiency of ANN with three
traditional statistical techniques, namely, k-nearest
neighbor (k-N), Logit, and discriminant analysis (DA),
are systematically examined across three insolvency
models under different criteria.
The underlying insolvency models are built up from a
data base provided by the National Association of
Insurance Commissioners (NAIC). Two models using the
NAIC IRIS' ratios are created with one (HNR) strictly
following NAIC truncating ratios and the another (TUR)
with full measurements of IRIS ratios. The effect of
NAIC calculation rules on prediction efficacy is tested.
The third insolvency model (6-VARIABLE) is created by
using stepwise discriminant selection from a broad range
of 33 financial variables. Three criteria, namely,
misclassification cost, resubstitution risk, and naive
comparison, are set up to examine the prediction
efficacy of ANN, k-N, Logit, and DA across models.
The empirical results show that ANN consistently
outperforms the three traditional methods for the full
measurement, TUR, model, in out of sample prediction;
Logit performs best using NAIC's truncated HNR model but
is severely effected by the outliers in the TUR model; k-
N and DA are less efficient in all models. The
discriminant stepwise selection, 6-VARIABLE, model has
less discriminant capacity than either IRIS models. This
study suggests that more work is needed to effectively
identify discriminant variables in insurance insolvency
prediction using the promising area of dimension
reduction by neural networks instead of using the
traditional discriminant analysis selection procedure.
</ABSTRACT>
</THESIS>
<THESIS>
<NUMBER> 4449 </NUMBER>
<ORDER>   AAG9325772 </ORDER>
<TITLE>   A REFERENCE ARCHITECTURE FOR DISTRIBUTED INTELLIGENT SYSTEMS AND A PRELIMINARY DESCRIPTION LANGUAGE FOR THEIR INTEGRATION </TITLE>
<AUTHOR>   BIRD, SHAWN DANIEL </AUTHOR>
<YEAR>   1993 </YEAR>
<INSTITUTION>   TEXAS TECH UNIVERSITY; 0230 </INSTITUTION>
<DESCRIPTORS>   BUSINESS ADMINISTRATION, GENERAL; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER>   GEORGE M. KASPER </ADVISER>
<CLASSIFICATIONS>   NIL </CLASSIFICATIONS>
<ABSTRACT>
Artificial intelligence and information systems research
is just beginning to grapple with the problems of
integrating autonomous, intelligent machine and human
agents into complex problem-solving systems. These
powerful multi-agent collaborative systems are
theoretically possible, but conceptual tools for their
development are lacking. This research develops a
general model of distributed intelligent systems and a
layered language for agent interaction in an attempt to
provide a foundation for the realization of such
conceptual tools. The model provides a basic definition
of distributed, asynchronous, intelligent problem-
solving systems. The language, which is constructed from
temporal and modal logics, provides an axiomatized
logical system in which the knowledge, beliefs, and
intentions of multiple agents are exchanged. Combined,
the language and model provide a reference architecture
for the development of and future research into
distributed intelligent systems.
</ABSTRACT>
</THESIS>
<THESIS>
<NUMBER> 4450 </NUMBER>
<ORDER>   AAG9325255 </ORDER>
<TITLE>   QUALITY ISSUES OF KNOWLEDGE BASES IN EXPERT SYSTEM DEVELOPMENT: AN EXPLORATORY STUDY </TITLE>
<AUTHOR>   LEE, SUNRO </AUTHOR>
<YEAR>   1993 </YEAR>
<INSTITUTION>   RENSSELAER POLYTECHNIC INSTITUTE; 0185 </INSTITUTION>
<DESCRIPTORS>   BUSINESS ADMINISTRATION, MANAGEMENT; INFORMATION SCIENCE; COMPUTER SCIENCE; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER>   ROBERT M. O'KEEFE; MARTHA GRABOWSKI </ADVISER>
<CLASSIFICATIONS>   QUALITY CONTROL </CLASSIFICATIONS>
<ABSTRACT>
A strategy for verification and validation (V&V) of
expert systems (ES) has been proposed. The life cycle
component of this research uses an integrative
development model based upon Boehm's spiral development
model as its focus. It is shown that the characteristics
of the application, regardless of the development
methodology, have an impact on V&V; hence V&V
methods are also mapped onto system characteristics.
As a part of efforts for extending the scope of
verification, this research outlines a taxonomy for
subsumption-related anomalies, comparing them with those
in rule-based systems, and provides a graph-based
technique for analyzing subsumption relationships and an
associated anomaly-detection procedure.
The experimental part of the thesis involved laboratory
experiments with 24 subjects developing an ES for 7
weeks and performing maintenance tasks both at the
beginning and the end of the project. Research findings
include the importance of the interaction effect between
knowledge representation and development methods in
total development time, changed lines of codes during
prototyping, coding productivity, and usability. Also,
the size of the product was primarily determined by
knowledge representation while the coding productivity
was dominated by developers' skill. Functionality was
affected by knowledge representation and development
methods, but unexpectedly not by developers skill. Rule
subsumption was the most frequently committed error
other than syntax errors during the development of rule-
based systems while design errors, such as
misclassification and missing slots, were most
frequently found in hybrid systems.
In addition, results from the first maintenance
experiment involved with a classification system showed
that an object-based system, compared to a structured
rule-based system, was easier to maintain in terms of
the time to do the maintenance tasks, but not
necessarily in terms of accuracy of the alterations. The
second maintenance experiment which used a different
system (i.e., planning system) from the first revealed
that knowledge representation has no effect on
maintainability. This contradictory finding suggests
that the problem type should be further investigated as
a moderating variable in the experimental model.
</ABSTRACT>
</THESIS>
<THESIS>
<NUMBER> 4451 </NUMBER>
<ORDER>   AAG9325095 </ORDER>
<TITLE>   ECONOMIC RATIONALITY AND NEURAL NETWORKS </TITLE>
<AUTHOR>   GARAVAGLIA, SUSAN BERGER </AUTHOR>
<YEAR>   1993 </YEAR>
<INSTITUTION>   CITY UNIVERSITY OF NEW YORK; 0046 </INSTITUTION>
<DESCRIPTORS>   ECONOMICS, GENERAL; ECONOMICS, COMMERCE-BUSINESS; ECONOMICS, LABOR; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER>   PETER S. ALBIN </ADVISER>
<CLASSIFICATIONS>   NIL </CLASSIFICATIONS>
<ABSTRACT>
Artificial Neural Networks are constructed by linking
primitive computing structures with weighted
connections. The information content of a neural network
develops through the adaptation of the connection
weights by learning algorithms to meet some measurable
criterion. This adaptability, combined with parallelism
and distributed information processing, produce a highly
effective paradigm of a decision making organization.
Higher degrees of organizational complexity are
represented through a larger number of primitive units
and connections which can be decomposed into any
meaningful subdivision. Because of the efficiency and
modularity of this representation of a decision making
entity, a neural network exemplifies Simon's procedural
rationality.
To establish foundations, an overview essay includes a
survey of economic applications, including predictive
econometric models, classification, and behavioral
models. Specific examples of neural networks developed
to perform estimation of non-linear functions,
discriminant analysis and clustering, and pattern
recognition, are discussed. This essay also discusses
some of the key statistical and mathematical properties
of neural networks, reviewing the work of Halbert White
and others.
The principal justification of the application of neural
networks to economic problems is delivered in the
context of procedural rationality (Herbert A. Simon).
The use of neural networks to reduce the complexity of a
model is demonstrated and compared with Peter Albin's
work on complexity measurement and organizational
committee structures. In addition, the theme of
biological analogy is examined in the work of Kornai and
others. An economic system is often compared to a
biological organism to explain its structure and
behavior. One essay demonstrates the application of a
neural network to modeling Akerlof's reciprocal gift
exchange theory.
A new neural network model is proposed for application
to rational decision making in organizations, based on
R. K. Sah's and J. E. Stiglitz' work on optimal
consensus size in committees and hierarchies, and Nils
Nilsson's committee machine. This neural network learns
the optimal size of a consensus in a committee and the
characteristics of good decisions by observing the odds
ratio of bad to good options. The behavior of the
network is instructive in understanding decision-making
behavior in large organizations.
</ABSTRACT>
</THESIS>
<THESIS>
<NUMBER> 4452 </NUMBER>
<ORDER>   AAG9324949 </ORDER>
<TITLE>   DISTRIBUTED ECONOMIC SYSTEMS WITH AGENTS THAT LEARN </TITLE>
<AUTHOR>   PERRY, STANLEY FOSTER </AUTHOR>
<YEAR>   1993 </YEAR>
<INSTITUTION>   PORTLAND STATE UNIVERSITY; 0180 </INSTITUTION>
<DESCRIPTORS>   ECONOMICS, GENERAL; COMPUTER SCIENCE; ENGINEERING, SYSTEM SCIENCE; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER>   GEORGE G. LENDARIS </ADVISER>
<CLASSIFICATIONS>   NEURAL NETWORKS, EXPERIMENTAL ECONOMICS </CLASSIFICATIONS>
<ABSTRACT>
Economic systems are defined in such a way that it is
feasible to construct artificial economic systems that
are composed of self-interested agents operating
according to principles that are prescribed by the
researcher. An artificial economic system was actually
constructed and tested in a computer environment. The
system constructed allows up to 1000 agents to interact
without any central control.
A computer "blackboard system" is used as the
architecture for providing common information to the
agents in the artificial economic system. Prices,
quantities, wealth and market structure emerge naturally
in the artificial economy that depend on the
characteristics and strategies of the agents in the
system. The trading frequently produces time series that
have the characteristics of a random walk, a condition
that is well known in real world markets.
Three classes of producer agents were used in these
artificial economic systems: optimizing agents that
incorporate neural networks, satisficing agents that
incorporate rule-based approaches, and Stackelberg
agents that have knowledge about the consumers in the
system, but do not have knowledge about their
competitor's intentions. Neural networks are used to
model the behavior of economic agents that can be said
to learn.
An important result emerging from this research is that
at least one agent with accurate knowledge about market
demand increases the resultant wealth of the system as a
whole. Markets containing a single Stackelberg or neural
agent produced far more wealth than markets composed
only of satisficing agents. However, the agents with
knowledge do not necessarily capture the highest share
of the wealth.
The success of individual agents depends on the agent's
trading strategy, and on the combination of agents in
the system. Certain strategies appeared to be flexible
while others were brittle, and were easily foiled by
changing the agents in the market, or by changing the
market conditions.
Additionally, neural networks were successfully tested
for solving various economics problems that were not
related to the simulation of economic systems. Neural
networks were found to effectively solve problems with
missing and redundant data that are not directly
solvable with well known methods such as least squares.
</ABSTRACT>
</THESIS>
<THESIS>
<NUMBER> 4453 </NUMBER>
<ORDER>   AAG9324520 </ORDER>
<TITLE>   PROFILE OF AN IDEAL CATHOLIC SCHOOL TEACHER: CONTENT ANALYSIS OF ROMAN AND AMERICAN DOCUMENTS, 1965 TO 1990 </TITLE>
<AUTHOR>   SHIMABUKURO, VIRGINIA HODEL </AUTHOR>
<YEAR>   1993 </YEAR>
<INSTITUTION>   UNIVERSITY OF SAN FRANCISCO; 6019 </INSTITUTION>
<DESCRIPTORS>   EDUCATION, PHILOSOPHY OF; EDUCATION, RELIGIOUS </DESCRIPTORS>
<ADVISER>   MARY PETER TRAVISS </ADVISER>
<CLASSIFICATIONS>   NIL </CLASSIFICATIONS>
<ABSTRACT>
Catholic education is in the midst of an identity
crisis. There are many reasons for this, including new
paradigms for thinking in the world, as well as in the
post-Vatican Church, transition from a predominantly
religious teaching body to one comprised mainly of the
laity, and recent learning theory evolving from distinct
fields, such as artificial intelligence, developmental
psychology, and neurology. This period in the history of
Catholic education demands an examination and
reformulation of Catholic school identity. In the
context of Vatican II new-paradigm thinking, this study
was dedicated to the exploration of the identity of the
Catholic school teacher, to a discovery of those
characteristics of the teacher that are distinguishably
Catholic.
A content analysis of eight Roman and American Church
documents pertaining to education was conducted to
obtain data in order to form a portrait of the ideal
Catholic school teacher. Documentation included:
Declaration on Christian Education (1965); To Teach as
Jesus Did (1972); Teach Them (1976); The Catholic School
(1977); Sharing the Light of Faith (1979); Lay Catholics
in Schools:Witnesses to Faith (1982); The Religious
Dimension of Education in a Catholic School (1988); and,
In Support of Catholic Elementary and Secondary Schools
(1990).
Five major themes characterizing the ideal Catholic
school teacher emerged from the literature, in order of
frequency of citations: (1) The teacher forms the
Christian spirituality of students (318 units of text;
14,365 words); (2) The teacher is vocationally prepared
(245 units of text; 9,282 words); (3) The teacher is a
builder of community (243 units of text; 9,709 words);
(4) The teacher forms the humanity of students (45 units
of text; 1,393 words); and, (5) The teacher is
professionally prepared (38 units of text; 1,178 words).
A typology of the ideal Catholic school teacher was
formulated as a result of this investigation. Related to
the five major themes, thirty-one sub-themes, more
specifically descriptive of the ideal Catholic school
teacher, emerged.
The emergent teacher characteristics and expectations,
although displayed hierarchically and quantitatively,
represent parts of a wholistic, organic approach to
education that is characteristically Catholic. The ideal
Catholic school teacher spans the needs of students in
at least the following areas: religious, spiritual,
moral, intellectual, psychological, developmental,
interpersonal, social, environmental, global, and
technological.
</ABSTRACT>
</THESIS>
<THESIS>
<NUMBER> 4454 </NUMBER>
<ORDER>   AAG9324100 </ORDER>
<TITLE>   THE USE OF CONSTRUCT VALIDITY IN THE EVALUATION OF INTELLIGENT TUTORING SYSTEM PERFORMANCE </TITLE>
<AUTHOR>   SHOTSBERGER, PAUL GAHLEN </AUTHOR>
<YEAR>   1993 </YEAR>
<INSTITUTION>   THE UNIVERSITY OF NORTH CAROLINA AT CHAPEL HILL; 0153 </INSTITUTION>
<DESCRIPTORS>   EDUCATION, TESTS AND MEASUREMENTS; EDUCATION, TECHNOLOGY; EDUCATION, MATHEMATICS; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER>   J. HUNTER BALLEW </ADVISER>
<CLASSIFICATIONS>   MATHEMATICS, CAI </CLASSIFICATIONS>
<ABSTRACT>
The National Council of Teachers of Mathematics (NCTM)
has identified the use of computers as a necessary
teaching tool for enhancing mathematical discourse in
schools. Through the use of technology, NCTM envisions
the transformation of classrooms into laboratories for
experimentation and exploration, with the consequent
altering of the teacher's role to that of a partner in
and facilitator of student discovery. One possible
vehicle of technological change in mathematics
classrooms is the Intelligent Tutoring System (ITS), an
artificially intelligent computer-based tutor. The focus
of this dissertation is on the usefulness of construct
validation methods for evaluating ITS performance.
The pilot study analyzed on-line data from a classroom
evaluation involving 74 students solving an algebra
equation using The RAND Corporation Intelligent Tutor
for Basic Algebra. Construct validation techniques
provided a means of extracting factors, comparing these
factors to hypothesized constructs for the system, and
then supplying and testing rival hypotheses concerning
the extracted factors' identities. The main study used a
similar methodology to analyze data from another ITS,
the ANGLE geometric proof tutor developed at Carnegie-
Mellon University.
The first phase of the main study employed data from a
laboratory evaluation of 15 students using ANGLE to
establish the consistency, and therefore the
suitability, of the data for a construct validity study.
The second phase used data from a classroom evaluation
in which 42 students had solved a proof problem using
ANGLE. Two factors were extracted, with one of the two
factors being identified as a hypothesized construct of
the system, with some contamination. A rival hypothesis
was generated for the second factor, but the meaning of
the factor could not be determined due to a low
reliability coefficient for its measures.
Results from these studies provided useful information
concerning the strength of hypothesized constructs of
the RAND ITBA and ANGLE, and this information served to
amplify the results of previous evaluations carried out
with the ITSs. Implications for the practice of ITS
evaluation are provided, as well as directions for
future research.
</ABSTRACT>
</THESIS>
<THESIS>
<NUMBER> 4455 </NUMBER>
<ORDER>   AAG9323451 </ORDER>
<TITLE>   A FRAMEWORK OF DISTRIBUTED ASSUMPTION-BASED COLLABORATION SYSTEM </TITLE>
<AUTHOR>   KIM, GARP CHOONG </AUTHOR>
<YEAR>   1993 </YEAR>
<INSTITUTION>   THE UNIVERSITY OF TEXAS AT AUSTIN; 0227 </INSTITUTION>
<DESCRIPTORS>   BUSINESS ADMINISTRATION, MANAGEMENT; COMPUTER SCIENCE; ENGINEERING, GENERAL; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER>   ANDREW B. WHINSTON </ADVISER>
<CLASSIFICATIONS>   DACS) FOR CONCURRENT ENGINEERING (CE) SUPPORT (COMMUNICATION, CONFLICT RESOLUTION </CLASSIFICATIONS>
<ABSTRACT>
In today's turbulent and globally competitive
environment, developing new products with better
quality, faster time to market and higher customer
satisfaction has become the focus of industrial
competition. Traditional, serial approach to product
development becomes no longer appropriate for today's
environment. The concept of Concurrent Engineering (CE)
has emerged as a means to overcome the global
competition. This dissertation views the CE as a
collaboration process in product development and
recognizes three essential requirements for the
successful implementation of the CE: Shared
Understanding, Conflict Resolution and Simultaneous
Change Management.
This study proposes a Distributed Assumption-based
Collaboration System (DACS) in support of the
requirements with a single unified system. The DACS
builds an advanced environment for distributed, multi-
agent problem solving by ensuring that the right
information is available to the right person at the
right time; conflicts are detected and resolved
effectively and as early as possible; design solutions
are modified accordingly as design specifications evolve
due to environmental change; consistencies in global and
local solutions are maintained; and design rationale is
recorded for future use.
The DACS extends the Assumption-based Truth Maintenance
System (ATMS) to the Distributed Multi-agent ATMS (DM-
ATMS) by integrating an intelligent communication system
(ICS). The ICS minimizes human intervention in the
communicative interactions and leaves the communication
events, such as information formation, transmission,
receiving, interpretation and reply, to machine
processing, as much as possible, thus relieving the
communication overload problem. The ICS is based on
three constructs: a structured message, a set of
communication rules and dependency relations in the
ATMS.
The DACS provides the Dialogue Game as a conflict
resolution mechanism. The Dialogue Game facilitates
shared understanding by surfacing hidden assumptions and
resolves the conflicts in a rule-governed manner. Shared
consistency among agents is guaranteed by the mechanism.
Communication protocols, a truth maintenance algorithm
and a set of control routines are developed. The DACS
framework is so general that it can be applied to many
areas where multiple agents under uncertain and
incomplete information are required to work together in
a cooperative manner to achieve a common goal.
</ABSTRACT>
</THESIS>
<THESIS>
<NUMBER> 4456 </NUMBER>
<ORDER>   AAG9323149 </ORDER>
<TITLE>   A DYNAMIC COMPARISON BETWEEN COMPUTER-BASED INSTRUCTION AND TRADITIONAL METHODS OF INSTRUCTION AS APPLIED TO TEACHING DIGITAL CIRCUIT ANALYSIS </TITLE>
<AUTHOR>   WILSON, LEON E. </AUTHOR>
<YEAR>   1993 </YEAR>
<INSTITUTION>   UNITED STATES INTERNATIONAL UNIVERSITY; 0239 </INSTITUTION>
<DESCRIPTORS>   EDUCATION, PHILOSOPHY OF; ENGINEERING, GENERAL; COMPUTER SCIENCE; EDUCATION, TECHNOLOGY </DESCRIPTORS>
<ADVISER>   MARIA FERNANDEZ </ADVISER>
<CLASSIFICATIONS>   NIL </CLASSIFICATIONS>
<ABSTRACT>
The problem. The evolution of high speed computers and
artificial intelligence has improved human interaction
in the classroom by opening the door for the use of the
computer as a teaching tool. A comparison of computer-
based instruction (CBI) and traditional methods of
instruction (TMI) as applied to teaching digital circuit
analysis in the engineering classroom was made. The
computer has produced a high rate of change in the way
courses are taught. The current study sought to explore
the possibility that CBI is more effective than TMI.
Method. An experimental group was presented with CBI and
a control group was taught using TMI. The experimental
group used interactive programs to analyze digital logic
circuits on the Apple IIe computer. The control group
participated in a formal lecture series and performed
the same analysis without the aid of a computer. All
subjects were students at a community college.
In order to determine the most effective teaching
method, students from each group were given five tests
throughout the semester. The tests were designed to
assess knowledge gained in the course. Test scores were
analyzed to determine whether there was a significant
difference between the two teaching methods.
Results. There were no significant differences in the
test scores between the CBI and TMI groups. The
frequency distribution for TMI test scores indicated
that 22 percent of the subjects scored in the 18th
percentile. The data indicated that TMI methods were not
superior, though subject scores were higher in this
group than for the CBI group.
A criticism of the study was that instructors generally
did not think there was sufficient time to tailor course
studies in engineering to CBI subjects who scored in the
18th percentile. It was noted that the top 5 percent of
subjects received personal attention from their
instructors. Personal attention was also provided to
subjects with lower scores to assist them in passing the
course. It is unknown how this may have affected the
results.
</ABSTRACT>
</THESIS>
<THESIS>
<NUMBER> 4457 </NUMBER>
<ORDER>   AAG1351655 </ORDER>
<TITLE>   OPTICAL CHARACTER RECOGNITION USING NEURAL NETWORK CO- PROCESSOR BOARD </TITLE>
<AUTHOR>   SAHAWNEH, JEHAD IBRAHEEM </AUTHOR>
<YEAR>   1993 </YEAR>
<INSTITUTION>   UNIVERSITY OF SOUTH ALABAMA; 0491 </INSTITUTION>
<DESCRIPTORS>   ENGINEERING, ELECTRONICS AND ELECTRICAL; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER>   WILFORD RABURN </ADVISER>
<CLASSIFICATIONS>   NIL </CLASSIFICATIONS>
<ABSTRACT>
Optical Character Recognition systems address the
problem of importing text directly into the computer.
The approach adopted was to use a hard-wired neural
network, housed in a personal computer, with its weights
set using the "Back Propagation" algorithm.
The study was limited to the English uppercase
characters, and the numerals one through nine. The
characters were presented to the neural network in a bit-
mapped format, and were hand coded. The character
recognition system successfully recognized all
characters presented with excellent precision and speed.
</ABSTRACT>
</THESIS>
<THESIS>
<NUMBER> 4458 </NUMBER>
<ORDER>   AAG9322262 </ORDER>
<TITLE>   SYMBIOSIS OF NURSE AND MACHINE THROUGH FUZZY LOGIC: IMPROVED SPECIFICITY OF A NEW NEONATAL PULSE OXIMETER ALARM </TITLE>
<AUTHOR>   BOSQUE, ELENA MARIE </AUTHOR>
<YEAR>   1993 </YEAR>
<INSTITUTION>   UNIVERSITY OF CALIFORNIA, SAN FRANCISCO; 0034 </INSTITUTION>
<DESCRIPTORS>   HEALTH SCIENCES, NURSING; COMPUTER SCIENCE; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER>   NIL </ADVISER>
<CLASSIFICATIONS>   NIL </CLASSIFICATIONS>
<ABSTRACT>
Non-invasive pulse oximeters are used by nurses to
monitor oxygenation in $>$600 NICU's in the USA for
$>$80% of mechanically ventilated infants. Motion
causes false alarms up to 29% of the time, resulting in
poor specificity. I developed a fuzzy logic computer
prototype alarm system using fuzzy sets of desaturation,
within limits, and artifact. The purpose of this study
was to compare the new (NEW) vs. conventional (OLD)
alarm systems to test the hypothesis that a neonatal
pulse oximeter alarm system based on fuzzy logic will
have equivalent sensitivity and improved specificity vs.
the OLD alarm system. Thirty-eight infants were enrolled
with a mean (range) study weight of 1495g (470-3390).
Oxygen saturation signals (Nellcor N200) were collected
for 1 hour per infant on a strip chart recorder and
saved on a computer. Reference (REF) signals were
simultaneously recorded from a second pulse oximeter and
transcutaneous O$sb2$ monitor. If an alarm persisted,
each 30 second interval was considered a separate event.
The NEW vs. OLD alarms were compared to the REF for 919
alarm events. There were 451 new alarm events, with a
mean of 12.1 (range 1-36) new events per subject, and
the others were persistent alarms. Oxygen desaturation
was defined as transcutaneous $rm POsb2<40$ torr and
$rm SaOsb2$ $<$ 85% for the REF.
(UNFORMATTED TABLE OR EQUATION
FOLLOWS)$$vbox{halign{#hfil&&quad#hfilcr
&&&&Oxygen&No Oxygencr
&&&&$underline{rm
Desaturation}$&$underline{rm
Desaturation}$cr&OLD&Desat
Alarm&&197&508cr &&Pulse
Search&&  2&212cr &NEW&Desat
Alarm&&199&333cr &&Within
Limits&&  0&129cr &&Artifact
Alarm&&  0&258cr &&$underline{rm
Sensitivity}$&$underline{rm
Specificity}$&$underline {rm
Pos.Pred.Value}$&$underline{rm Neg.Pred.Value}$cr
&NEW&1.0&0.54&0.37&1.0cr}}$$(TABLE/E
QUATION ENDS)
The NEW alarm system had 34% fewer false positive alarms
(p $<$.001). The NEW fuzzy logic alarm system has
equivalent sensitivity and improved specificity vs. the
OLD alarm system. When used to monitor oxygenation in
infants, this system with fewer false alarms may
decrease the "Cry Wolf Syndrome", and
represents a symbiosis between nurse and machine.
</ABSTRACT>
</THESIS>
<THESIS>
<NUMBER> 4459 </NUMBER>
<ORDER>   AAG9321422 </ORDER>
<TITLE>   LEARNING HEURISTICS FOR REPETITIVE COMBINATORIAL OPTIMIZATION PROBLEMS: WITH AN APPLICATION IN TRAIN SCHEDULING </TITLE>
<AUTHOR>   KRAAY, DAVID RUSSELL </AUTHOR>
<YEAR>   1993 </YEAR>
<INSTITUTION>   UNIVERSITY OF PENNSYLVANIA; 0175 </INSTITUTION>
<DESCRIPTORS>   OPERATIONS RESEARCH; COMPUTER SCIENCE; TRANSPORTATION; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER>   PATRICK T. HARKER </ADVISER>
<CLASSIFICATIONS>   OPTIMIZATION </CLASSIFICATIONS>
<ABSTRACT>
This dissertation presents a case-based approach for the
development of learning heuristics for solving
repetitive operations research problems. We first define
the subset of problems we will consider in this work:
repetitive combinatorial optimization problems. We then
present several general forms which can be used to
select previously solved problems which might aid in the
solution of the current problem, and several different
techniques for actually using this information to derive
a solution for the current problem. We present both
fixed forms and forms which have the ability to change
as we solve more problems, which will be implemented
using genetic algorithms. We illustrate the learning
heuristic on three well-known problems in operations
research: the knapsack problem, the simple plant
location problem, and travelling salesman problem.
We also develop a new model for the railroad network
control problem, which is a very large, non-linear,
mixed integer program. We develop a special mathematical
programming technique for the continuous variables which
takes advantage of the structure of the problem. We
present two different heuristics for choosing the values
for the integer variables. The first of these is a
specialized heuristic which only uses the information
available in the current problem. The second heuristic
is a learning heuristic, similar to the ones used for
the common optimization problems. Numerical results are
presented on sample problems derived from data of a
major United States' railroad.
</ABSTRACT>
</THESIS>
<THESIS>
<NUMBER> 4460 </NUMBER>
<ORDER>   AAG9321355 </ORDER>
<TITLE>   PLASTICITY IN THE RAT SOMATOSENSORY CORTEX INDUCED BY LOCAL MICROSTIMULATION AND THEORETICAL INVESTIGATIONS OF INFORMATION FLOW THROUGH NEURONS </TITLE>
<AUTHOR>   BEDENBAUGH, PURVIS HOBSON, III </AUTHOR>
<YEAR>   1993 </YEAR>
<INSTITUTION>   UNIVERSITY OF PENNSYLVANIA; 0175 </INSTITUTION>
<DESCRIPTORS>   BIOLOGY, NEUROSCIENCE; ENGINEERING, BIOMEDICAL; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER>   GEORGE L. GERSTEIN </ADVISER>
<CLASSIFICATIONS>   NIL </CLASSIFICATIONS>
<ABSTRACT>
Weak electric stimulation of the rat somatosensory
cortex induced changes in the mapping of the rat's paw
to its sensory representation in cortex. In low
resolution recordings of multiple neuron clusters, the
representational plasticity was clear. It appeared over
a few hours, and reversed over the same time course.
Efforts to dissect the mechanisms underlying the
representational change were hampered by the lack of
methods to quantitatively interpret the relationships
among the responses of several single neurons. The
dissertation's theoretical section laid the foundation
for methods that make such quantitative interpretations
possible.
The relationship between the outputs of computer-modeled
neuron pairs with partially shared and partially
independent input was studied. Both linear and nonlinear
measures showed that relative relationship between the
outputs was less than the relative relationship between
the inputs. Output relationships were similarly
insensitive to asymmetry in the independent inputs. Not
only do the output spike trains contain less information
than the array of input spike trains, but the relative
relationship between output pairs is less than between
corresponding input pairs. Neurons experience disorderly
information loss.
A threshold spiking model neuron was developed that
allowed analytic calculation of the relationship between
its input and output correlations. This model and a
sigmoid nonlinearity were compared to the computer
model. The output correlation of the computer-modeled
neurons was more like that of the threshold spiking
neuron than like that of the sigmoid nonlinearity,
suggesting that the spiking process itself contributes
to the computer model neuron's disorderly information
loss. It was found that the sigmoid nonlinearity can
rectify the correlation between input signals whose mean
is not at the sigmoid's midpoint. This helps explain why
"neural network" models are sensitive to the
balance between excitation and inhibition.
Though single neurons lose information in a disorderly
fashion, many scientists believe that neural systems
preserve information. Neural systems certainly make good
use of information, so that behavior can be influenced
by slight differences in sensation. Analyses in the
dissertation suggests that neurons are more appropriate
building blocks for adaptive systems that correctly
categorize their inputs than for systems that accurately
represent their inputs.
</ABSTRACT>
</THESIS>
<THESIS>
<NUMBER> 4461 </NUMBER>
<ORDER>   AAG9320614 </ORDER>
<TITLE>   TRAINING MULTI-LAYERED NEURAL NETWORKS FOR PATTERN CLASSIFICATION USING LINEAR PROGRAMMING FORMULATIONS </TITLE>
<AUTHOR>   KIM, LARK SANG </AUTHOR>
<YEAR>   1993 </YEAR>
<INSTITUTION>   ARIZONA STATE UNIVERSITY; 0010 </INSTITUTION>
<DESCRIPTORS>   COMPUTER SCIENCE; ARTIFICIAL INTELLIGENCE; OPERATIONS RESEARCH </DESCRIPTORS>
<ADVISER>   ASIM ROY </ADVISER>
<CLASSIFICATIONS>   NIL </CLASSIFICATIONS>
<ABSTRACT>
The back propagation algorithm is the most widely used
method to train multilayer neural networks for pattern
classification. The simplicity of the algorithm and its
ability to solve complex classification problems through
nonlinear mapping make it a popular tool for pattern
classification. However, it has some critical drawbacks
such as painfully slow convergence and the presence of
local minima, which makes the learning difficult for
larger problems.
In this research linear programming based methods for
training multilayer neural networks for pattern
classification are developed and tested for several
classification problems. The linear programming based
methods that generate and train a hidden layer of
restricted high order units (quadratic) with less
training time are presented in Chapters 3 and 4. A new
method using linear programming formulation for
initializing weights to a hidden layer of multilayer
neural networks is discussed in Chapter 5, compared with
the ordinary back propagation method. The training
process of multilayer neural networks is accelerated by
initializing the weights of hidden layer (linear
hyperplanes) around input patterns.
</ABSTRACT>
</THESIS>
<THESIS>
<NUMBER> 4462 </NUMBER>
<ORDER>   AAG9320461 </ORDER>
<TITLE>   INCREASING SHARED UNDERSTANDING OF A DESIGN TASK BETWEEN DESIGNERS AND DESIGN ENVIRONMENTS: THE ROLE OF A SPECIFICATION COMPONENT </TITLE>
<AUTHOR>   NAKAKOJI, KUMIYO </AUTHOR>
<YEAR>   1993 </YEAR>
<INSTITUTION>   UNIVERSITY OF COLORADO AT BOULDER; 0051 </INSTITUTION>
<DESCRIPTORS>   COMPUTER SCIENCE; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER>   GERHARD FISCHER </ADVISER>
<CLASSIFICATIONS>   KNOWING-IN-DESIGN </CLASSIFICATIONS>
<ABSTRACT>
Design is ill-defined and open-ended. Traditional
waterfall process models do not support the way in which
specifying a design problem and constructing a solution
are intertwined. Knowledge required for a design task
can neither be completely identified nor formalized
before generating a solution that fits the task's
changing needs. Integrated, domain-oriented, knowledge-
based design environments are computer systems that
provide design tools and information repositories that
help designers understand and frame their design task.
The K scIDS scPECIFICATION component supports designers
in informally specifying their design goals, objectives,
criteria, and constraints in the K scID (Knowing-In-
Design) design environment for kitchen floor plans.
Explicit knowledge representations embodied by the
specification component, in conjunction with a
construction component that supports designers in
constructing floor plans, provide "shared
understanding" of the task at hand between human
designers and the design environment. The increased
shared understanding by the specification component
augments the quality of knowledge delivery mechanisms of
K scID that deliver the design knowledge relevant to the
designers' task at hand. Protocol analyses of designers
interacting with K scID demonstrated that the explicit
representation of designers' goals and intentions helped
designers in better understanding a design problem by
allowing them to (1) frame concrete objects to reflect
on as a partial specification and construction, and (2)
see the partially framed design with task-relevant
design knowledge delivered by K scID. This seeing-
framing-seeing cycle of design processes driven by
designers in collaboration with the design environment
has been frequently observed. Designers' reflection was
enhanced by the delivery of sometimes unexpected
information. The delivery encouraged designers to
articulate design knowledge that had been implicit.
Assessment of these mechanisms illustrates the
beneficial role of the specification component in
conjunction with the knowledge delivery mechanisms in
enabling the K scID design environment to effectively
support human designers.
</ABSTRACT>
</THESIS>
<THESIS>
<NUMBER> 4463 </NUMBER>
<ORDER>   AAG9320352 </ORDER>
<TITLE>   PARALLEL TREE SEARCH ON A SINGLE-INSTRUCTION, MULTIPLE- DATA </TITLE>
<AUTHOR>   POWLEY, CURTIS NELSON </AUTHOR>
<YEAR>   1993 </YEAR>
<INSTITUTION>   UNIVERSITY OF CALIFORNIA, LOS ANGELES; 0031 </INSTITUTION>
<DESCRIPTORS>   COMPUTER SCIENCE; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER>   RICHARD E. KORF </ADVISER>
<CLASSIFICATIONS>   SIMD </CLASSIFICATIONS>
<ABSTRACT>
This dissertation evaluates the suitability of using
Single-Instruction Multiple-Data (SIMD) machines to
parallelize tree-recursive algorithms, particularly
search algorithms. The set of tree-recursive algorithms
includes backtracking for constraint satisfaction,
Iterative-Deepening-A$sp*$ (IDA$sp*$), depth-first
branch-and-bound, two-player game minimax search with
alpha-beta pruning, and most divide-and-conquer
algorithms. Our algorithm, called SIMD Tree Search
(STS), works by alternating depth-first search with load
balancing phases. Because the trees are dynamically
generated and irregular, load balancing is critical to
performance, and we explore several different
techniques. To control the initiation of load-balancing,
we chose a dynamic trigger that is simple to compute,
and works by greedily optimizing the rate of work over a
load-balance/search cycle. Our implementation is
structured so that it presents a high-level environment
for simple implementation of new applications, requiring
little consideration of parallel aspects such as load
balancing.
With 16K processors on the SIMD Connection Machine$sp1,$
STS achieves an efficiency of 65% for the N-Queens
problem using backtracking for constraint satisfaction,
64% for the Fifteen Puzzle using IDA$sp*,$ 28% for the
traveling salesman problem using branch-and-bound, and
only about 2% for Othello using alpha-beta minimax
search. On hard problem instances of the Fifteen Puzzle,
STS achieves efficiencies as high as 80%, for a speedup
of 26,215 with 32,768 (32K) processors, the highest
reported for this class of algorithms. With the
exception of two-player games, our results indicate that
work needs to increase as P log P to maintain constant
efficiency, where P is the number of processors, and
this indicates good scalability.
To predict and analyze performance, we developed four
intuitive factors of efficiency. In general, SIMD
machines can be used very effectively for tree-recursive
applications in which the problems of interest are large
enough to utilize the machine, the time of node
generations is relatively constant, and the
parallelizable component of the problem is large
relative to the non-parallelizable component. This
research extends the capability of SIMD machines, while
at the same time demonstrating some of their
limitations. ftn$sp1$Connection Machine is a trademark
of Thinking Machines Corporation.
</ABSTRACT>
</THESIS>
<THESIS>
<NUMBER> 4464 </NUMBER>
<ORDER>   AAG9320212 </ORDER>
<TITLE>   A NEW DIRECTION IN ANALOGICAL REASONING </TITLE>
<AUTHOR>   MANAFI SHEMIRANI, ALI AKBAR </AUTHOR>
<YEAR>   1993 </YEAR>
<INSTITUTION>   THE UNIVERSITY OF OKLAHOMA; 0169 </INSTITUTION>
<DESCRIPTORS>   COMPUTER SCIENCE; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER>   JOHN Y. CHEUNG </ADVISER>
<CLASSIFICATIONS>   KNOWLEDGE BASE </CLASSIFICATIONS>
<ABSTRACT>
The literature discussing the theories of learning and
reasoning by analogy are briefly reviewed. The proposed
approach is differentiated from some related works. The
concepts of the semantic nets, the formal logic, the
frames, and their significance as a tool are discussed.
A new approach in reasoning by analogy is presented. In
this approach, the body of knowledge is represented in
terms of the relationship between its parts so that the
nonessential things are cut away and the essential
elements are found. The concept of semantic nets is
employed, in order to make the relationship explicit
between the objects. Then a string representing the
graph of the semantic net is produced, and a grammar
which generates that graph as one of its sentences is
synthesized. Hence, this is a generalization, since a
way of parsing from one particular relationship
represented by the semantic net into a much more general
entity which presents a whole group of semantic nets is
constructed. These semantic nets are related to one
another by the means of the constructed grammar.
The basic elements of the approach, meaning the grammar
and the general algorithms are discussed and the
usefulness and the applicability of the approach
demonstrated through examples in the domains of physical
mechanics and Algebra. The object oriented enhanced
analogy is presented to improve the approach. The
performance and characteristics of the proposed approach
(namely order/sequence independence, covering,
sufficiency, efficiency, and limitations) are discussed.
The PHS (PHysical Structure) system has been implemented
to support the ideas discussed in this dissertation.
The result of these ideas is to predict the physical or
structural behavior of a new problem based on the
solution of the past sample problems.
</ABSTRACT>
</THESIS>
<THESIS>
<NUMBER> 4465 </NUMBER>
<ORDER>   AAG9320186 </ORDER>
<TITLE>   DEVELOPMENT AND PERFORMANCE ANALYSIS OF ARTIFICIAL NEURAL NETWORKS TO DECODE CONVOLUTIONAL CODES </TITLE>
<AUTHOR>   SAGAR, VIDYA </AUTHOR>
<YEAR>   1993 </YEAR>
<INSTITUTION>   THE CATHOLIC UNIVERSITY OF AMERICA; 0043 </INSTITUTION>
<DESCRIPTORS>   ENGINEERING, ELECTRONICS AND ELECTRICAL; PHYSICS, ELECTRONICS AND ELECTRICITY; MATHEMATICS; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER>   NIL </ADVISER>
<CLASSIFICATIONS>   NIL </CLASSIFICATIONS>
<ABSTRACT>
The fundamentals and underlying principles in the
development of Artificial Neural Networks (ANN) decoders
for convolutional codes are presented. The error
detection and correction strategies employed rely on
hetero-associative synaptic weights and the Hamming
network. Based on the error correction method used, two
decoder designs were examined; one decoder was designed
with synaptic weights and the other decoder was designed
using a Hamming network.
A modified Hamming network technique has been developed
to excite the neural network decoder neurons with input
data sequences. The information content of each neuron
excitation has been analytically examined. Different
neuron excitation patterns have been discussed and their
effect on decoder performance has been evaluated.
The performance of these decoders has been evaluated in
terms of error detection capability, error correction
capacity, and interaction with infinite SNR signals.
A Monte Carlo simulation has been performed to test
these decoders. It has been observed that for high SNR
signals, the ANN synaptic weight decoder performance
compares favorably with a conventional maximum
likelihood decoder (Viterbi); however, as SNR decreases
performance is less than optimal. The ANN Hamming net
decoder performs maximum likelihood decoding with
selective error correction computation. For high SNR
signals, the decoder does not require error correction
computation. This design is flexible and based on input
SNR requirements the extent of error correction
computation can be programmed.
The decoder models and experimental techniques developed
in this study show that the ANN decoders are a viable
and effective means of decoding convolutional codes used
in deep space probes and satellite communications.
</ABSTRACT>
</THESIS>
<THESIS>
<NUMBER> 4466 </NUMBER>
<ORDER>   AAG9319985 </ORDER>
<TITLE>   A FEASIBILITY STUDY OF THE USE OF THREE PC EXPERT SYSTEM SHELLS IN EPIDEMIOLOGIC RESEARCH </TITLE>
<AUTHOR>   MURRAY, CYNTHIA KAY </AUTHOR>
<YEAR>   1993 </YEAR>
<INSTITUTION>   THE UNIVERSITY OF OKLAHOMA HEALTH SCIENCES CENTER; 0361 </INSTITUTION>
<DESCRIPTORS>   BIOLOGY, BIOSTATISTICS; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER>   WILLIS L. OWEN </ADVISER>
<CLASSIFICATIONS>   NIL </CLASSIFICATIONS>
<ABSTRACT>
Induction is a method used by shells to build expert
systems by giving the program a series of examples. The
source of examples was the 1980 National Natality Survey
and the 1980 National Fetal Mortality Survey. 1st-CLASS
FUSION, KnowledgePro, and IXL were used to generate
models, based on infant characteristics, to predict
outcome. The resulting models were compared between (1)
the replicates for each sample size within each expert
system shell, (2) the sample sizes for each expert
system shell within each replicate, and (3) the expert
system shells for each replicate within each sample
size. These comparisons were made with respect to the
accuracy and reproducibility of the classification of
the infants. The accuracy rates between models were
fairly consistant, but the overall rate was low. Few
models showed good reproducibility of classification.
These shells, as a tool for determining risk factors in
epidemiological studies, should be used with caution.
</ABSTRACT>
</THESIS>
<THESIS>
<NUMBER> 4467 </NUMBER>
<ORDER>   AAG9319933 </ORDER>
<TITLE>   MINSTREL: A COMPUTER MODEL OF CREATIVITY AND STORYTELLING </TITLE>
<AUTHOR>   TURNER, SCOTT R. </AUTHOR>
<YEAR>   1993 </YEAR>
<INSTITUTION>   UNIVERSITY OF CALIFORNIA, LOS ANGELES; 0031 </INSTITUTION>
<DESCRIPTORS>   COMPUTER SCIENCE; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER>   MICHAEL DYER </ADVISER>
<CLASSIFICATIONS>   NIL </CLASSIFICATIONS>
<ABSTRACT>
Telling a story is a difficult task that requires a
variety of knowledge and cognitive processes: knowledge
about themes, writing techniques, the story world, and
presentation; processes such as planning, problem-
solving, recall and creativity. This dissertation
presents a model of the storytelling process which
incorporates theories of creativity, memory and author-
level planning. This model has been implemented in a
computer program called MINSTREL which tells short,
theme-based stories about King Arthur and his Knights of
the Round Table.
MINSTREL's creativity process is based upon creativity
heuristics called Transform-Recall-Adapt Methods
(TRAMs). Each TRAM integrates a simple problem
transformation which searches the problem-space for new
knowledge to apply to a problem with a corresponding
adaptation which can adapt any discovered knowledge to
the original problem. By using TRAMs to augment the
problem-solving process, MINSTREL is able to invent
useful new problem solutions. By incorporating
creativity into the recall process, MINSTREL makes
creativity available to any cognitive process, and
permits the use of multiple TRAMs to make creative
"leaps".
MINSTREL's storytelling process is based upon a model of
author-level problem-solving. In addition to a process
model of author-level problem-solving, MINSTREL
implements four important classes of author-level goals
and plans: (1) Thematic, (2) Dramatic, (3) Consistency,
and (4) Presentation. MINSTREL uses these goals and
plans to tell a number of short stories in the King
Arthur domain.
MINSTREL is a computational model of the cognitive
processes of storytelling and creativity. MINSTREL (1)
describes a process model of storytelling, (2)
identifies important storytelling goals and plans, (3)
identifies fundamental storytelling processes, (4)
describes a process model of creativity, (5) explains
how a problem-solver can find and adapt old knowledge to
create new solutions, (6) identifies useful creativity
heuristics, (7) explains creative "leaps", (8)
explains the relation of creativity to problem-solving,
(9) describes the relationship between memory and
creativity, and (10) integrates creativity into a larger
cognitive model.
</ABSTRACT>
</THESIS>
<THESIS>
<NUMBER> 4468 </NUMBER>
<ORDER>   AAG9319672 </ORDER>
<TITLE>   REAL-TIME FAULT-TOLERANT COMMUNICATION IN COMPUTER NETWORKS </TITLE>
<AUTHOR>   ZHENG, QIN </AUTHOR>
<YEAR>   1993 </YEAR>
<INSTITUTION>   THE UNIVERSITY OF MICHIGAN; 0127 </INSTITUTION>
<DESCRIPTORS>   COMPUTER SCIENCE; ENGINEERING, ELECTRONICS AND ELECTRICAL; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER>   KANG G. SHIN </ADVISER>
<CLASSIFICATIONS>   NIL </CLASSIFICATIONS>
<ABSTRACT>
A network is required to provide the users with a
convenient means of guaranteeing delay bounds in message
transmission and making message transmission tolerant of
network component failures. Solutions to this problem
will greatly improve the quality of service of the
contemporary computer networks and expand their
application domains to such areas as distributed real-
time controls and digital continuous-media (motion
video, audio) transmissions.
Our solution to the problem is to use a new transfer
mode called a real-time channel which guarantees the
timely delivery of messages like the circuit-switched
transmission while preserving the high transmission
efficiency of the packet-switched mode. We give a
comprehensive coverage of this new transfer mode, from
the fundamental deadline scheduling theory and real-time
channel protocols, to the detailed hardware
implementation. Using the spatial redundancy of a
network topology, real-time fault-tolerant communication
is achieved by enhancing the basic real-time channels to
be Single Failure Immune (SFI) or Isolated Failure
Immune (IFI). Backup channels can also be used to
increase the reliability of real-time channels.
The issue of establishing real-time channels over shared-
medium Local Area Networks (LANs) is then discussed,
which is of practical importance since most end systems
are connected to a LAN first and then to a point-to-
point Wide Area Network (WAN). We also present a
technique which can significantly improve the FDDI's
capacity of supporting real-time traffic with a few
simple modifications to its Medium Access Control (MAC)
protocols. Finally, the application of our results for
multimedia networking is illustrated through
simulations.
</ABSTRACT>
</THESIS>
<THESIS>
<NUMBER> 4469 </NUMBER>
<ORDER>   AAG9319653 </ORDER>
<TITLE>   AN ACTIVE-SYMBOL CONNECTIONIST MODEL OF CONCEPT REPRESENTATION AND CONCEPT LEARNING </TITLE>
<AUTHOR>   WEAVER, MARK </AUTHOR>
<YEAR>   1993 </YEAR>
<INSTITUTION>   THE UNIVERSITY OF MICHIGAN; 0127 </INSTITUTION>
<DESCRIPTORS>   COMPUTER SCIENCE; PSYCHOLOGY, GENERAL; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER>   STEPHEN KAPLAN </ADVISER>
<CLASSIFICATIONS>   NEURAL NETWORK, OBJECT RECOGNITION, COGNITION </CLASSIFICATIONS>
<ABSTRACT>
Many authors have emphasized the role that concepts play
as basic building blocks of cognition. This suggests two
things. First, if one wishes to understand cognition,
one must understand how concepts are acquired and
represented. Second, if an understanding of concepts is
critical primarily because it serves as the basis for a
general understanding of cognition, then a theory of
concepts is most meaningful when developed in the
context of a general cognitive theory and when connected
to as many psychological phenomena as possible. The
first point is widely appreciated--models of concept
learning and representation are ubiquitious. The second
point, though, is widely and unfortunately neglected.
Because this second point is taken seriously, this
dissertation represents a departure from the usual
practices of connectionist modelling. An initial set of
constraints is imposed by virute of working within the
framework of an general cognitive theory known as
"active symbol connectionism". Additional
constraints are drawn from the domains of
neuropsychology, object recognition, the psychology of
categories and concepts, evolution, and connectionist
modelling.
Taking a "constraint-rich" approach has
resulted in two classes of useful results. The first
class comprises technical innovations in connectionist
modelling. These include: (1) a method of using coarse-
coding to improve the resolution of a parts-based models
of object recognition and representation, (2) novel
learning and activation rules based on an economic
metaphor of diminishing returns, and (3)
neurophysiologically plausible methods of implementing
connectionist map learning.
The struggle to accomodate multiple constraints has also
suggested new perspectives for a number of issues. These
include: (1) a recasting of the distributed vs. local
representation debate in connectionism by breaking the
issue down into its subcomponents, (2) an evolutionary
perspective for the relative roles of statistical and
theoretical mechanisms of categorization, and (3) the
implications of separate cortical visual systems for
connectionist models of concept representation.
</ABSTRACT>
</THESIS>
<THESIS>
<NUMBER> 4470 </NUMBER>
<ORDER>   AAG9319590 </ORDER>
<TITLE>   THE USE OF ABSTRACTION IN COORDINATING ARTIFICIALLY INTELLIGENT AGENTS </TITLE>
<AUTHOR>   MONTGOMERY, THOMAS ANTHONY </AUTHOR>
<YEAR>   1993 </YEAR>
<INSTITUTION>   THE UNIVERSITY OF MICHIGAN; 0127 </INSTITUTION>
<DESCRIPTORS>   COMPUTER SCIENCE; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER>   EDMUND H. DURFEE </ADVISER>
<CLASSIFICATIONS>   NIL </CLASSIFICATIONS>
<ABSTRACT>
The coordination of networked computer systems (and of
other distributed intelligent agents) is becoming an
increasingly important area of research. By viewing the
process of coordination as a distributed search, we are
able to adapt recent research on search--and how its
complexity can be reduced through the use of abstraction-
-to the coordination of intelligent agents. We do this
using a framework which allows our intelligent agents to
reason and communicate at multiple levels of
abstraction.
Communication is necessary in a distributed search since
each agent only searches a fraction of the overall
space. By beginning dialogues at an abstract level, our
intelligent agents can reduce the amount of information
that they must communicate when coordinating their
actions. Any reduction in information exchanged that is
accomplished by this hierarchical communication reduces
both the transmission load on the communication medium,
and the processing load on the agents. However, since
there is some overhead associated with sending abstract
information, we describe the circumstances under which
hierarchical communication results in the transmission
of less information than the brute force approach of
exchanging all details.
Extending hierarchical communication to the level of
teams of agents, and allowing the teams to negotiate in
parallel, makes further efficiency gains possible. In
general, the combined effects of parallelism and
abstraction can reduce the complexity of an exponential
search to logarithmic time. By recognizing that a
hierarchical organization of teams of agents can map
onto more common abstraction hierarchies in search, we
are able to show how this complexity reduction can be
applied to the coordination problem. We validate our
analysis through empirical results at both the task-
level (in the Towers of Hanoi problem domain) and meta-
level (in the coordination of robots in a delivery
task). Since this research requires the distinctions
between schedules, plans, and organizations to be
blurred, it is a step toward an interdisciplinary study
of coordination that includes such diverse fields as
operations research, artificial intelligence, and
organization theory.
</ABSTRACT>
</THESIS>
<THESIS>
<NUMBER> 4471 </NUMBER>
<ORDER>   AAG9319412 </ORDER>
<TITLE>   NEURAL NETWORKS AS FIRST LEVEL TRIGGERS IN SCINTILLATING FIBER DETECTORS </TITLE>
<AUTHOR>   ORGERON, JOSEPH ANTHONY </AUTHOR>
<YEAR>   1993 </YEAR>
<INSTITUTION>   THE UNIVERSITY OF TEXAS AT DALLAS; 0382 </INSTITUTION>
<DESCRIPTORS>   PHYSICS, ELEMENTARY PARTICLES AND HIGH ENERGY; COMPUTER SCIENCE; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER>   ERVIN J. FENYVES </ADVISER>
<CLASSIFICATIONS>   SUPERCOLLIDERS </CLASSIFICATIONS>
<ABSTRACT>
Trained feed-forward neural networks have been shown to
have the inherent capability of providing a novel
approach to performing extremely fast pattern
recognition that can be incorporated into first-level
triggers for particle detectors at high energy
colliders. In this specific case, an extensive Monte
Carlo software package specifically adapted for the
proposed Solenoidal Detector Collaboration (SDC)
detector at the Superconducting Super Collider (SSC) was
used to simulate the expected high energy physics
processes and detect the generated particles in order to
obtain the most realistic data for training and testing
of the networks. Computational facilities at both UTD
and at the SSC Laboratory were used to train and test
the accuracy and efficiency of these novel triggering
schemes. Results obtained show that a neural network
first-level trigger, with its inherent capacity for
pattern recognition, has the ability to provide the
triggering performance equal to the currently proposed
(combinatorial logic) trigger at design luminosity and
outperform it as luminosities are increased to ten times
the design level by providing false trigger rates a full
order of magnitude lower.
</ABSTRACT>
</THESIS>
<THESIS>
<NUMBER> 4472 </NUMBER>
<ORDER>   AAG9319326 </ORDER>
<TITLE>   IMPROVING CLASSIFICATION WITH ADAPTIVE SYNTHESIS BASED ON COLLECTIVE LEARNING </TITLE>
<AUTHOR>   BIELAK, DENNIS CHESTER </AUTHOR>
<YEAR>   1993 </YEAR>
<INSTITUTION>   THE GEORGE WASHINGTON UNIVERSITY; 0075 </INSTITUTION>
<DESCRIPTORS>   COMPUTER SCIENCE; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER>   PETER BOCK </ADVISER>
<CLASSIFICATIONS>   MACHINE LEARNING, PATTERN RECOGNITION </CLASSIFICATIONS>
<ABSTRACT>
Classification is a process that transforms and reduces
sensor data to a class label. This process is one of
statistical inference. Based on sensor information, a
"best guess" is made of the class label of the
object being classified. Additional information useful
in making the classification decision is obtained by
measuring more than one feature. An important
consideration when using multiple features is the method
employed to synthesize the diverse feature data into a
single class label decision. A weighted average scheme
is used to combine multiple class label hypotheses into
a single class label. This weighted average is part of
an adaptive learning process. The weights are changed
during the training process to improve the
classification performance. Adapting the weights depends
on two factors. First, a collective evaluation of the
classification system's overall performance is
determined. Second, individual compensations based on
the contribution of each sub-hypothesis to the overall
decision are calculated based on their histograms of
detected patterns. Previous research has shown that a
two-layered approach of (1) choosing a best possible
solution and (2) continuing to generate multiple
possible solutions, is one of the most efficient methods
in multi-objective programming. The application of this
approach to image processing as described in this
dissertation is unique. In particular, a Collective
Learning Automaton (CLA) is employed to learn
appropriate weights for the combination of a number of
candidate sub-hypotheses into a single super hypothesis.
This process is referred to as Adaptive Synthesis. It
has been successfully applied to recognizing computer-
generated characters, discriminating a hand-printed font
from a script computer-generated font, detecting
vehicles in cluttered background, and discriminating
fractal images of differing dimension using the Adaptive
Learning Image and Signal Analysis (ALISA) system at the
George Washington University in Washington D.C. and the
Research Institute for Applied Knowledge Processing
(FAW) in Ulm, Germany. This research shows that
employing an adaptive synthesis method based on
collective learning improves a classifier's system
performance.
</ABSTRACT>
</THESIS>
<THESIS>
<NUMBER> 4473 </NUMBER>
<ORDER>   AAG9319323 </ORDER>
<TITLE>   SMARTQ: A KNOWLEDGE-BASED QUALITY ASSURANCE SYSTEM </TITLE>
<AUTHOR>   KUO, TSUANG YIH </AUTHOR>
<YEAR>   1993 </YEAR>
<INSTITUTION>   UNIVERSITY OF CINCINNATI; 0045 </INSTITUTION>
<DESCRIPTORS>   ENGINEERING, INDUSTRIAL; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER>   ANIL MITAL </ADVISER>
<CLASSIFICATIONS>   NIL </CLASSIFICATIONS>
<ABSTRACT>
SmartQ, a total statistical quality control (SQC) expert
system package, has the following characteristics: (1)
it is the only general purpose SQC package that is
presently available, (2) it is a hybrid system which
takes advantage of both expert system techniques and
traditional procedural languages, (3) it is the only SQC
package which has all five desired capabilities: control
chart selection, establishment of statistical control
limits, economical design of control charts, and
interpretation and diagnosis of unnatural patterns, (4)
it is the only package which integrates supplemental run
criterion, process capability study, regression analysis
and time series analysis into one system, making
interpretation on a scientific and uniform basis, and
(5) it is the only SQC expert system which allows users
to define their own diagnostic rules in order to
customize the system for specific applications.
</ABSTRACT>
</THESIS>
<THESIS>
<NUMBER> 4474 </NUMBER>
<ORDER>   AAG9319319 </ORDER>
<TITLE>   A NONLINEAR ARCHITECTURE FOR REAL-TIME SYSTEM IDENTIFICATION AND CONTROL </TITLE>
<AUTHOR>   GOVIND, GIRISH </AUTHOR>
<YEAR>   1993 </YEAR>
<INSTITUTION>   UNIVERSITY OF CINCINNATI; 0045 </INSTITUTION>
<DESCRIPTORS>   ENGINEERING, ELECTRONICS AND ELECTRICAL; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER>   P. A. RAMAMOORTHY </ADVISER>
<CLASSIFICATIONS>   NIL </CLASSIFICATIONS>
<ABSTRACT>
This dissertation addresses the problem of nonlinear
system identification and control using neural
architectures. The results of this research present a
technique to build a neural network architecture and an
online training algorithm that is efficient, accurate
and that can be used for nonlinear system
identification.
Nonlinear system identification algorithms are difficult
to derive and use. In most applications the problem of
nonlinear system identification is simplified such that
linear modeling would suffice over a selected restricted
input range. Or, use is made of an adaptive model that
would keep fitting a linear model around the current
state. Multi-layered neural networks were first used for
nonlinear system identification about four years ago.
However, to this date there is no method for the
selection of values for the learning parameters, or
number of hidden nodes in the architecture, and training
is slow if conservative estimates of the learning
parameters are used. Typically, hundreds of thousands of
iterations are required to converge and sometimes the
network topology itself has to be modified when initial
selections of the number of hidden nodes do not yield an
acceptable solution.
In this dissertation, first a survey of conventional
nonlinear system identification techniques is given. The
approximation properties of multi-layered neural
networks for nonlinear system identification are
analyzed by a new method that presents a lot of new
insights into the system identification problem. Another
advantage of analysis by this new method is that it
clearly shows the advantages of using multi-layered
neural networks over other conventional methods for the
approximation of nonlinear systems. This dissertation
develops a new architecture and training algorithm that
utilizes a time-evolving topology to adapt to the
complexity of given data. The new training algorithm is
capable of quickly learning an input-output map without
any apriori information of the structure of the neural
model. Furthermore, unlike other constructive algorithms
in the literature, the algorithm proposed in this
research is capable of online (real-time) learning.
Finally, the new method for nonlinear system
identification is extended to the control of nonlinear
systems, and use of this method for pattern
classification and fuzzy control is discussed.
</ABSTRACT>
</THESIS>
<THESIS>
<NUMBER> 4475 </NUMBER>
<ORDER>   AAG9318667 </ORDER>
<TITLE>   KNOWLEDGE-BASED SOFTWARE DEVELOPMENT FOR HIGHLY PARALLEL COMPUTERS </TITLE>
<AUTHOR>   GAU, JYH-LIN JACK </AUTHOR>
<YEAR>   1993 </YEAR>
<INSTITUTION>   HARVARD UNIVERSITY; 0084 </INSTITUTION>
<DESCRIPTORS>   COMPUTER SCIENCE; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER>   NIL </ADVISER>
<CLASSIFICATIONS>   NIL </CLASSIFICATIONS>
<ABSTRACT>
The increasing complexity of parallel computer hardware
poses a serious challenge for software science and
engineering. How are we going to develop software for
these machines that exploits their potential parallelism
without sacrificing usability and portability because of
that complexity? The past approaches to solving this
problem from the parallel language design, intelligent
compiler, or programming environment perspective are, at
best, only partially successful.
To tackle the problem we developed the methodology of
knowledge-based software development (KBSD) for highly
parallel architectures, which integrates expert system
technology with the advanced compiler optimization
research conducted over the past decade. KBSD is a
methodology of program construction in which successive
transformation rules are applied. Because the
architecture specific information is explicitly
encapsulated in a machine knowledge base, it is possible
to separate the programmatic statement of an algorithm
from the machine-dependent partition, mapping, and
communication specification. It is our goal that the
same high level language program can be refined to run
on different classes of target parallel machines.
There are several fundamental issues needed to be
addressed before KBSD can be realized: abstracting and
building machine knowledge, representing and organizing
transformation knowledge, performing extensive
dependence analysis of the programs, etc. It will also
be shown that the essential issues in parallel computing
software, i.e. vectorization, concurrentization,
partition, scheduling, synchronization, and memory
utilization can all be handled very elegantly within the
framework of KBSD.
</ABSTRACT>
</THESIS>
<THESIS>
<NUMBER> 4476 </NUMBER>
<ORDER>   AAG9317634 </ORDER>
<TITLE>   HYPOTHESIS-DRIVEN CONSTRUCTIVE INDUCTION </TITLE>
<AUTHOR>   WNEK, JANUSZ </AUTHOR>
<YEAR>   1993 </YEAR>
<INSTITUTION>   GEORGE MASON UNIVERSITY; 0883 </INSTITUTION>
<DESCRIPTORS>   COMPUTER SCIENCE; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER>   RYSZARD S. MICHALSKI </ADVISER>
<CLASSIFICATIONS>   NIL </CLASSIFICATIONS>
<ABSTRACT>
This dissertation is concerned with research on
constructive induction within the symbolic, rule-
learning paradigm. Constructive induction, as introduced
by Michalski in 1978, addresses the problem of changing
the representation space so that it is more adequate for
the learning problem at hand.
To this end, a method called hypothesis-driven
constructive induction (HCI) is presented. The HCI
method assumes changing the representation space in the
process of concept learning. The changes involve
expansion and contraction of the representation space,
and are based on the analysis of consecutively created
inductive hypotheses.
The changes in the representation space are analyzed
using the diagrammatic visualization system, DIAV. This
system presents learned and target concepts, as well as
intermediate concepts, as images in a planar model of a
multidimensional space. For the first time, diagrammatic
visualization is used to model and analyze
representation changes, in particular the abstraction
and concretion knowledge transmutations. The analysis
makes a contribution to the Inferential Theory of
Learning, and data-driven constructive induction
methods.
An implementation of the HCI method was tested and
compared with other methods, both in abstract and
practical domains. The applicability of the method to
engineering domains was demonstrated using the problem
of learning design rules for wind bracings in tall
buildings. The empirical results show the advance of the
method over selective (non-constructive) induction
methods and a decision tree-based constructive induction
method.
</ABSTRACT>
</THESIS>
<THESIS>
<NUMBER> 4477 </NUMBER>
<ORDER>   AAG9317460 </ORDER>
<TITLE>   AN ANALYSIS OF EXPLANATION AND ITS IMPLICATIONS FOR THE DESIGN OF EXPLANATION PLANNERS </TITLE>
<AUTHOR>   SUTHERS, DANIEL DERWENT </AUTHOR>
<YEAR>   1993 </YEAR>
<INSTITUTION>   UNIVERSITY OF MASSACHUSETTS; 0118 </INSTITUTION>
<DESCRIPTORS>   COMPUTER SCIENCE; EDUCATION, TECHNOLOGY; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER>   EDWINA L. RISSLAND </ADVISER>
<CLASSIFICATIONS>   HYBRID ARCHITECTURE, TEXT PLANNING, NATURAL LANGUAGE GENERATION </CLASSIFICATIONS>
<ABSTRACT>
The dissertation provides an analysis of how the content
and organization of explanations function to achieve
communicative goals under potentially conflicting
constraints, and applies this analysis to the design of
a planner for generation of explanations by computer. An
implementation of this planner as a multimedia question
answering system is described.
The functional analysis has four major subparts: (1) A
theory of the kinds of knowledge that can provide the
basis for "informatively satisfying" responses
to a given question. (2) A theory of context sensitive
constraints on the choice between alternate domain
models that compete as the basis for answering a given
question. (3) A theory of how supplemental explanations
aid the comprehension and retention of the primary
explanation. (4) A theory of how the sequencing of the
parts of an explanation enhances the communicative
functionality of those parts.
The functional aspects of explanation just outlined
imply a variety of explanation planning subtasks having
distinct information processing requirements. A planning
architecture is presented that matches these planning
subtasks to appropriate mechanisms: (1) Top-down goal
refinement translates queries into specifications of
relevant knowledge on which a response can be based. (2)
Prioritized preferences restrict competing domain models
to those that are expected to be both informative and
comprehensible to the questioner at a given point in the
dialogue. (3) Plan critics examine the evolving plan and
post new goals to supplement the explanation as needed.
(4) A constrained graph traversal mechanism sequences
the parts of an explanation in a manner respecting
certain functional relationships between the parts.
Contributions include: (1) the clarification and
integration of a variety of functional aspects of
explanatory text, (2) an analysis of the roles and
limitations of various explanation planning mechanisms,
(3) the design of a flexible explanation planner that
applies various constraints on explanation independently
of each other, and (4) an approach to selection between
multiple domain models that is more general than
previous approaches.
Together these contributions clarify the correspondence
between knowledge about communication, planning tasks,
and types of discourse structure and provide improved
interactive explanation capabilities.
</ABSTRACT>
</THESIS>
<THESIS>
<NUMBER> 4478 </NUMBER>
<ORDER>   AAG9315493 </ORDER>
<TITLE>   MODELLING OBJECTS, KNOWLEDGE AND LEARNING IN DISTRIBUTED OBJECT-BASED SYSTEMS </TITLE>
<AUTHOR>   NDJATOU, GILBERT </AUTHOR>
<YEAR>   1993 </YEAR>
<INSTITUTION>   CITY UNIVERSITY OF NEW YORK; 0046 </INSTITUTION>
<DESCRIPTORS>   COMPUTER SCIENCE; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER>   ROHIT PARIKH </ADVISER>
<CLASSIFICATIONS>   NIL </CLASSIFICATIONS>
<ABSTRACT>
Our model is intended to provide a means of specifying
and reasoning about the behavior of systems consisting
of active, autonomous and interacting components, as
well as those of the constituting components while
abstracting the detailed mechanisms involved. We also
provide mechanisms to describe object classes and
inheritance within our model.
Unlike previous models of reactive systems, we would
like ours to capture both the data and the process views
of objects, on the same lines as the objectcharts of S.
Bear et al (BACH90), or L. Lamport's (L89) transition
axiom method. Objects are thus viewed as reactive
systems with some intelligence and a decision mechanism
or the organ of will of J. McCarthy and P. J. Hayes
(MH69). To capture the intelligence of objects, we
introduce and reason about objects' knowledge within our
framework. We also introduce the notions of objects'
procedural knowledge and learning in distributed object-
based systems. It will then be possible to provide a
knowledge-based characterization of object
"similarity", inheritance and rational
behavior.
An object's knowledge corresponds to facts about its
task-domain situations that it should be said to know
according to its behavior specifications or protocol. It
is static and does not depend on system computations. It
is introduced in a modal and dynamic logics framework,
and leads to a logic of knowledge and actions. An
object's procedural knowledge corresponds to the notion
of "laws of ability" in (MH69), and expresses
the ability of an object to use and transform its
knowledge of facts about its task-domain situations. It
is specified in terms of objects' knowledge and actions.
Our approach to learning corresponds to the knowledge
obtained and transferred in distributed object-based
systems. It also corresponds to object instances'
awareness of their own knowledge or properties of
computations in distributed object-based systems, and is
closely related to the intuitive notion of learning by
experience. We introduce a modal logic of knowledge and
learning/awareness, and also prove some properties of
learning/awareness and forgetting in distributed object-
based systems. This approach to knowledge and
learning/awareness also gives us a semantical basis to
the distinction and relationship between these two
aspects of knowledge in distributed object-based systems
that we refer to as static/local knowledge and dynamic
knowledge. (Abstract shortened by UMI.)
</ABSTRACT>
</THESIS>
<THESIS>
<NUMBER> 4479 </NUMBER>
<ORDER>   AAG0573077 </ORDER>
<TITLE>   STATISTICAL OBJECT RECOGNITION </TITLE>
<AUTHOR>   WELLS, WILLIAM MERCER, III </AUTHOR>
<YEAR>   1993 </YEAR>
<INSTITUTION>   MASSACHUSETTS INSTITUTE OF TECHNOLOGY; 0753 </INSTITUTION>
<DESCRIPTORS>   COMPUTER SCIENCE; ENGINEERING, ELECTRONICS AND ELECTRICAL; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER>   W. ERIC L. GRIMSON </ADVISER>
<CLASSIFICATIONS>   COMPUTER VISION, ROBOTICS </CLASSIFICATIONS>
<ABSTRACT>
To be practical, recognition systems must deal with
uncertainty. Positions of image features in scenes vary.
Features sometimes fail to appear because of unfavorable
illumination. In this work, methods of statistical
inference are combined with empirical models of
uncertainty in order to evaluate and refine hypotheses
about the occurrence of a known object in a scene.
Probabilistic models are used to characterize image
features and their correspondences. A statistical
approach is taken for the acquisition of object models
from observations in images: Mean Edge Images are used
to capture object features that are reasonably stable
with respect to variations in illumination.
The Alignment approach to recognition, that has been
described by Huttenlocher and Ullman, is used. The
mechanisms that are employed to generate initial
hypotheses are distinct from those that are used to
verify (and refine) them. In this work, posterior
probability and Maximum Likelihood are the criteria for
evaluating and refining hypotheses. The recognition
strategy advocated in this work may be summarized as
Align Refine Verify, whereby local search in pose space
is utilized to refine hypotheses from the alignment
stage before verification is carried out.
Two formulations of model-based object recognition are
described. MAP Model Matching evaluates joint hypotheses
of match and pose, while Posterior Marginal Pose
Estimation evaluates the pose only. Local search in pose
space is carried out with the Expectation-Maximization
(EM) algorithm.
Recognition experiments are described where the EM
algorithm is used to refine and evaluate pose hypotheses
in 2D and 3D. Initial hypotheses for the 2D experiments
were generated by a simple indexing method: Angle Pair
Indexing. The Linear Combination of Views method of
Ullman and Basri is employed as the projection model in
the 3D experiments. (Copies available exclusively from
MIT Libraries, Rm. 14-0551, Cambridge MA 02139-4307. Ph.
617-253-5668; Fax 617-253-1690.)
</ABSTRACT>
</THESIS>
<THESIS>
<NUMBER> 4480 </NUMBER>
<ORDER>   AAG0572892 </ORDER>
<TITLE>   PLAY AND THE GENESIS OF MIDDLE MANAGER AGENTS </TITLE>
<AUTHOR>   MCGEE, KEVIN </AUTHOR>
<YEAR>   1993 </YEAR>
<INSTITUTION>   MASSACHUSETTS INSTITUTE OF TECHNOLOGY; 0753 </INSTITUTION>
<DESCRIPTORS>   PSYCHOLOGY, DEVELOPMENTAL; EDUCATION, PSYCHOLOGY; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER>   SEYMOUR PAPERT </ADVISER>
<CLASSIFICATIONS>   COGNITION </CLASSIFICATIONS>
<ABSTRACT>
Play-like behaviors result in substantial changes to an
individual's way of knowing, changes that are difficult
to explain in such traditional terms as "problem
solving," or reinforcement and reward.
Developmental psychologist Jean Piaget discovered that
during the course of development individuals construct
fundamentally new ways of understanding the world. In
one of his famous clinical experiments, Piaget and his
associates asked individuals of different ages what
would happen to liquids as they were poured from one
container to another. In one version of this experiment,
three clear glasses, two the same size and one taller
and thinner, are presented. Each of the two similar
glasses are filled with equal amounts of liquid. When
asked "is there one that has more?" most
individuals say that they have the same amount. However,
if, before their very eyes, the liquid is poured from
one of the shorter glasses into the tall, thin glass and
they are then asked "is there one that has
more?" individuals before a certain stage give a
surprising answer. They say that the tall glass has
more.
Professors Minsky and Papert developed a Society of Mind
model of this phenomenon which says that individuals
have cognitive agents for, among other things, measuring
liquids in terms of height and width. The answers given
by individuals before a certain stage of development are
the result of the "height" agent winning over
the "width" agent. After a certain stage, a
middle-manager agent exists which neutralizes the
competing answers, allowing the individual to say they
are the same. In its broadest terms, the problem left is
how these agents ever come to compete with each other.
This thesis outlines a theory of the genesis of the
conflict and the resulting middle-manager agent. In this
theory, weaker agents are strengthened in other contexts-
-contexts where they are not dominated. Therefore, I
propose that a central part of the transition between
different ways of knowing is the result of actions in
one context, the movement of seemingly unrelated
activities (without necessarily having an explicitly
formulated goal in doing so), and then the return to the
original situations. Individuals who assert that the
taller liquid is more do not formulate the situation in
terms of a problem to be solved; they are typically
quite content with their assessment of which container
has more. Thus, goal-directed activities are less
important than are "non-instrumental"
activities (such as play) to the emergence of middle-
managers. This is new way of thinking about the central
importance of behavior which until now has been
considered to have little cognitive utility. (Copies
available exclusively from MIT Libraries, Rm. 14-0551,
Cambridge, MA 02139-4307. Ph. 617-253-5668; Fax 617-253-
1690.)
</ABSTRACT>
</THESIS>
<THESIS>
<NUMBER> 4481 </NUMBER>
<ORDER>   AAG9320442 </ORDER>
<TITLE>   USING ARTIFICIAL INTELLIGENCE TECHNIQUES AND LEARNING TO SOLVE MULTI-LEVEL KNAPSACK PROBLEMS </TITLE>
<AUTHOR>   KO, ILSANG </AUTHOR>
<YEAR>   1993 </YEAR>
<INSTITUTION>   UNIVERSITY OF COLORADO AT BOULDER; 0051 </INSTITUTION>
<DESCRIPTORS>   BUSINESS ADMINISTRATION, MANAGEMENT; OPERATIONS RESEARCH; COMPUTER SCIENCE; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER>   JAMES KELLY; FRED GLOVER </ADVISER>
<CLASSIFICATIONS>   LEARNING APPROACHES </CLASSIFICATIONS>
<ABSTRACT>
In solving multi-level knapsack problems, conventional
heuristic approaches often assume a shortsighted plan
within a static decision environment to find a near
optimal solution. These conventional approaches are
inflexible, and lack the ability to adapt to different
problem structures. This research approaches the problem
from a totally different viewpoint, and a new method
that utilizes artificial intelligence (AI) techniques is
designed and implemented. The term "AI
technique" implies that one performs intelligent
actions based on memories of historic data, knowledge
bases, and learning. These actions are developed not
only by observing the attributes of the optimal
solution, the solution space, and its corresponding path
to the optimal solution, but also by applying human
intelligence, experience, and intuition with respect to
the search strategies. By accomplishing memory-based
learning from previous history, the intensive learning
approach makes decisions in a dynamic way. The approach
intensifies, or diversifies the search process
appropriately in time and space. In order to create a
good neighborhood structure, this learning approach uses
two powerful choice rules that emphasize the impact of
candidate variables on the current solution with respect
to their profit contribution. A side effect of so-called
"pseudo moves," similar to
"aspirations," supports these choice rules
during the evaluation process. For the purpose of
visiting as many relevant points as possible, strategic
oscillation between feasible and infeasible solutions
around the boundary is applied for intensification. To
avoid redundant moves, short-term (tabu-lists),
intermediate-term (cycle detection), and long-term
(recording frequency and significant solutions for
diversification) memories are used. In addition, the
concepts of "diversification within
intensification" and "intensification within
diversification" also enhance the intensive
learning approach by dynamically creating a effective
rhythm of the search process. From a macroperspective,
all the intelligent actions are systematically applied
during the oscillation between the "information-
acquiring process" and the "information-
utilizing process." Test results show that among
the 45 generated problems (these problems pose
significant or insurmountable challenges to exact
methods) the approach produces the optimal solutions in
39 cases.
</ABSTRACT>
</THESIS>
<THESIS>
<NUMBER> 4482 </NUMBER>
<ORDER>   AAG9318871 </ORDER>
<TITLE>   PHYSICALLY-BASED MODELS FOR THE REFLECTION, TRANSMISSION AND SUBSURFACE SCATTERING OF LIGHT BY SMOOTH AND ROUGH SURFACES, WITH APPLICATIONS TO REALISTIC IMAGE SYNTHESIS </TITLE>
<AUTHOR>   HE, XIAO DONG </AUTHOR>
<YEAR>   1993 </YEAR>
<INSTITUTION>   CORNELL UNIVERSITY; 0058 </INSTITUTION>
<DESCRIPTORS>   ENGINEERING, MECHANICAL; PHYSICS, OPTICS; COMPUTER SCIENCE; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER>   NIL </ADVISER>
<CLASSIFICATIONS>   SMOOTH SURFACES </CLASSIFICATIONS>
<ABSTRACT>
This thesis studies light scattering processes off rough
surfaces. Analytic models for reflection, transmission
and subsurface scattering of light are developed. The
results are applicable to realistic image generation in
computer graphics.
The investigation focuses on the basic issue of how
light is scattered locally by general surfaces which are
neither diffuse nor specular; Physical optics is
employed to account for diffraction and interference
which play a crucial role in the scattering of light for
most surfaces. The thesis presents: (1) A new
reflectance model; (2) A new transmittance model; (3) A
new subsurface scattering model. All of these models are
physically-based, depend on only physical parameters,
apply to a wide range of materials and surface finishes
and more importantly, provide a smooth transition from
diffuse-like to specular reflection as the wavelength
and incidence angle are increased or the surface
roughness is decreased. The reflectance and
transmittance models are based on the Kirchhoff Theory
and the subsurface scattering model is based on Energy
Transport Theory. They are valid only for surfaces with
shallow slopes.
The thesis shows that predicted reflectance
distributions given by the reflectance model compare
favorably with experiment. The thesis also investigates
and implements fast ways of computing the reflectance
and transmittance models. Furthermore, the thesis
demonstrates that a high level of realistic image
generation can be achieved due to the physically-correct
treatment of the scattering processes by the reflectance
model.
</ABSTRACT>
</THESIS>
<THESIS>
<NUMBER> 4483 </NUMBER>
<ORDER>   AAG9318863 </ORDER>
<TITLE>   USING ALGEBRAIC INVARIANTS AND GROUPING TO SPEED OBJECT RECOGNITION IN A SINGLE, TWO-DIMENSIONAL IMAGE </TITLE>
<AUTHOR>   WAYNER, PETER </AUTHOR>
<YEAR>   1993 </YEAR>
<INSTITUTION>   CORNELL UNIVERSITY; 0058 </INSTITUTION>
<DESCRIPTORS>   COMPUTER SCIENCE; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER>   NIL </ADVISER>
<CLASSIFICATIONS>   NIL </CLASSIFICATIONS>
<ABSTRACT>
When a computer must recognize objects in an image, it
must solve two problems: finding potential objects in
the image and looking up the potential matches for these
hypotheses in a database of object models. This thesis
presents a coordinated approach to solving both of these
problems. The first part, a graph-based grouping
algorithm, locates places in the image with a high
probability of corresponding to objects. The second half
of the system uses a pose-invariant index to look up
objects in a database. This database is stored in a
format that is tuned to the structure of the grouping
results. Splitting the process into two halves in this
way allows the overall system to have a low-order
running time that is generally proportional to the
product of the complexity of the image and the
complexity of the database of potential objects.
The coordination between the two systems provides for
substantial reduction in computation. The grouping
system uses only local rules of convexity which are fast
and easy to compute, but do not produce globally optimal
results. A more sophisticated and slower grouping
algorithm is not needed because the indexing system will
rule out the bad hypotheses. The indexing subsystem is
also substantially smaller because it only needs to be
able to look up groups that could be generated by the
grouping algorithm.
The principle contributions of this thesis are (1) a new
grouping method based on convexity, (2) an indexing
function for a two dimensional image of a 3-dimensional
collection of points and (3) a unified architecture for
robustly and efficiently combining grouping information
with an index.
</ABSTRACT>
</THESIS>
<THESIS>
<NUMBER> 4484 </NUMBER>
<ORDER>   AAG9318374 </ORDER>
<TITLE>   NEURAL NETWORK BASED IMAGE PROCESSING FOR THE DETECTION OF MULTIPLE POINT TARGETS IN NOISE AND CLUTTER </TITLE>
<AUTHOR>   SEMANCIK, WILLIAM JOSEPH </AUTHOR>
<YEAR>   1993 </YEAR>
<INSTITUTION>   THE CATHOLIC UNIVERSITY OF AMERICA; 0043 </INSTITUTION>
<DESCRIPTORS>   ENGINEERING, ELECTRONICS AND ELECTRICAL; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER>   MOHAMMED AROZULLAH </ADVISER>
<CLASSIFICATIONS>   NIL </CLASSIFICATIONS>
<ABSTRACT>
This dissertation deals with the problem of near real
time detection of densely located multiple targets in
images. A new detection scheme is developed and its
performance is evaluated and compared with that of other
relevant detectors. This detector provides high
probability of detection, P$sb{rm d}$, of a primary
target, and a high total probability of detection,
P$sb{rm dT}$, of all targets within the field of view.
In addition, it provides a constant false alarm rate
(CFAR). This detector is called Lateral Suppression CFAR
(LS-CFAR) as it uses the local feedback of target
detections to successively remove target induced biases
in the estimate of the background intensity. A
connectionist/neural implementation of the LS-CFAR
detector has been developed that is capable of near real
time detection of multiple targets. Analytical
expressions have been developed for both P$sb{rm d}$ and
P$sb{rm dT}$ for the LS-CFAR detector as well as P$sb{rm
dT}$ for the Cell Averaging CFAR (CA-CFAR) detector for
one, two, and three targets cases. In the light of the
complexity of corresponding analytical expressions for
more than three targets, Monte Carlo simulation has been
used to evaluate and compare the performance of these
detectors for four through nine targets.
From these results, it is shown that for a single target
the LS-CFAR detector performs as well as the CA-CFAR
detector. For multiple targets, at moderately high false
alarm rates (e.g. 1 $times$ 10$sp{-4}$) the LS-CFAR
detector performs as well or better than all other CFAR
schemes. At moderate to very low false alarm rates (1
$times$ 10$sp{-6}$ to 1 $times$ 10$sp{-9}$), LS-CFAR
outperforms all other CFAR schemes except for certain
variations of the Ordered Statistics CFAR (OS-CFAR)
detector under some specific conditions. The LS-CFAR
detector, however, is more computationally tractable for
use in a real time system.
</ABSTRACT>
</THESIS>
<THESIS>
<NUMBER> 4485 </NUMBER>
<ORDER>   AAG9317799 </ORDER>
<TITLE>   INTERACTIVE MAN-MACHINE LEARNING IN A DYNAMIC MANUFACTURING ENVIRONMENT </TITLE>
<AUTHOR>   NARONGDEJ, POL </AUTHOR>
<YEAR>   1993 </YEAR>
<INSTITUTION>   STANFORD UNIVERSITY; 0212 </INSTITUTION>
<DESCRIPTORS>   ENGINEERING, SYSTEM SCIENCE; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER>   EDISON T. S. TSE </ADVISER>
<CLASSIFICATIONS>   MACHINE LEARNING </CLASSIFICATIONS>
<ABSTRACT>
In a highly competitive market, a problem of a
manufacturing firm is how to operate optimally. A
dynamic environment makes this a difficult problem for a
firm because the changing environment alters both a
feasible region and an optimal region of a process over
time. The lack of necessary information about these
regions prevents the full use of available optimal
control theory to solve the problem. Our approach uses
the dual control concept where learning necessary
information occurs simultaneously with learning how to
control the process towards the optimal region. We use
tools from optimization theory, control theory, expert
system technology, and computer learning models,
together with assistance from a human expert, to
implement the concept. Benefits accrued from using the
concept include increases in productivity, improvements
in operators' skills and knowledge, and valuable
information for improving the process. A case study
carried out in a tissue paper factory is also provided.
</ABSTRACT>
</THESIS>
<THESIS>
<NUMBER> 4486 </NUMBER>
<ORDER>   AAG9317759 </ORDER>
<TITLE>   BELIEF REVISION AND UPDATE </TITLE>
<AUTHOR>   DEL VAL, ALVARO </AUTHOR>
<YEAR>   1993 </YEAR>
<INSTITUTION>   STANFORD UNIVERSITY; 0212 </INSTITUTION>
<DESCRIPTORS>   COMPUTER SCIENCE; PHILOSOPHY; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER>   YOAV SHOHAM </ADVISER>
<CLASSIFICATIONS>   NIL </CLASSIFICATIONS>
<ABSTRACT>
This dissertation is a contribution to the study of
belief change from both a formal and computational
perspective. Theories of belief change address the
following general question: Given an initial database
$Gamma$ and a new piece of information $mu$ to be
incorporated into it, what should the new database be?
In this study we focus on two specific types of belief
change, revision and update. We ground each of them on a
solid semantic foundation, and develop syntactic
characterizations and algorithms to compute a number of
specific belief change operators instantiating these
semantics.
The study is divided into two parts. The first part
addresses the foundational aspects of belief change,
specifically the definition of appropriate semantics for
revision and update operators. We encode belief update
in a non-monotonic temporal framework for reasoning
about action and change that makes explicit the temporal
evolution of the database, and use this framework to
show both the applicability and the limits of some of
the most important update proposals in the literature. A
very similar approach can be used to capture revision.
We develop a "mental situation calculus" to
encode the agent's beliefs, and capture revision in
terms of the effects of learning the new information in
a theory of action very similar to the one used for
update, and that allows for a unified treatment of both
types of belief change within a single formalism. As
with update, we show that the most important proposals
for revision found in the literature can be captured in
our construction.
Part 2 is devoted to the computation of updates and
revisions of knowledge bases under a variety of specific
operators, most of which are special cases of the
framework developed in part 1. We develop techniques to
systematically characterize all the operators
considered, and use the resulting syntactic
characterizations to design algorithms for revision and
update of CNF, NNF and DNF databases. The algorithms for
update are the first of their kind which do not need
explicit manipulation or storage of complete models of
the knowledge base, and its usefulness for updating
large knowledge bases is experimentally demonstrated.
</ABSTRACT>
</THESIS>
<THESIS>
<NUMBER> 4487 </NUMBER>
<ORDER>   AAG9316663 </ORDER>
<TITLE>   ACCEPTING THE INEVITABLE: THE ROLE OF FAILURE RECOVERY IN THE DESIGN OF PLANNERS </TITLE>
<AUTHOR>   HOWE, ADELE E. </AUTHOR>
<YEAR>   1993 </YEAR>
<INSTITUTION>   UNIVERSITY OF MASSACHUSETTS; 0118 </INSTITUTION>
<DESCRIPTORS>   COMPUTER SCIENCE; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER>   PAUL R. COHEN </ADVISER>
<CLASSIFICATIONS>   NIL </CLASSIFICATIONS>
<ABSTRACT>
Failures are inevitable for many types of computer
systems. Designers who seek to limit the frequency and
impact of failures can adopt two basic approaches:
automated failure recovery and debugging failures. This
dissertation describes how automated failure recovery
can both repair failures and expedite debugging of an
autonomous planner, the Phoenix planner, in a dynamic
environment.
The automated failure recovery component applies general
methods to recover from failures detected by the Phoenix
planner. The design of the failure recovery component
was developed by applying a methodology of first
constructing a model of expected cost of failure
recovery and then evaluating whether changes in the
design of failure recovery result in improvements in the
evaluation of expected cost. Additionally, the model was
used to derive a control strategy for best selecting
from a set of recovery methods. The expected cost model,
its assumptions and the failure recovery component were
tested in a set of three experiments. The first
determined performance baselines for failure recovery,
the second evaluated the performance of the control
strategy, and the third compared the performance of an
initial set of recovery methods to a new set augmented
to lower the expected cost of recovery. As predicted,
the control strategy and the augmented set of recovery
methods improved performance by reducing the overall
cost of recovery and increasing the overall recovery
rate.
Failure recovery analysis (FRA) is a procedure for
analyzing execution traces of failure recovery to
discover how the planner's actions might be causing
failures. The procedure involves statistically analyzing
execution traces for dependencies between actions and
failures, mapping those dependencies to plan structures,
and explaining how the structures might produce the
observed dependencies. Failure Recovery Analysis is a
partially automated procedure that can be applied by
designers to identify cases in which the plan library
may be causing its own failures (i.e., bugs) and to
implement and evaluate modifications to the plan library
intended to eliminate the bugs. FRA is demonstrated by
analyzing some of the data from the three experiments
testing failure recovery.
This research shows how failure recovery can help a
planner repair failures due to both unexpected events
and plan bugs and help planner designers determine how
plan failures depend on the planner's actions and
evaluate design changes over time. The primary
contributions of the thesis are: an empirical
methodology for designing and evaluating failure
recovery in planning and a tool for debugging a plan
library.
</ABSTRACT>
</THESIS>
<THESIS>
<NUMBER> 4488 </NUMBER>
<ORDER>   AAG9316628 </ORDER>
<TITLE>   KNOWLEDGE-BASED FEATURE GENERATION FOR INDUCTIVE LEARNING </TITLE>
<AUTHOR>   CALLAN, JAMES PATRICK </AUTHOR>
<YEAR>   1993 </YEAR>
<INSTITUTION>   UNIVERSITY OF MASSACHUSETTS; 0118 </INSTITUTION>
<DESCRIPTORS>   COMPUTER SCIENCE; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER>   PAUL E. UTGOFF </ADVISER>
<CLASSIFICATIONS>   NIL </CLASSIFICATIONS>
<ABSTRACT>
Inductive learning is an approach to machine learning in
which concepts are learned from examples and
counterexamples. One requirement for inductive learning
is an explicit representation of the characteristics, or
features, that determine whether an object is an example
or counterexample. Obvious or easily available
representations do not reliably satisfy this
requirement, so constructive induction algorithms have
been developed to satisfy it automatically. However,
there are some features, known to be useful, that have
been beyond the capabilities of most constructive
induction algorithms.
This dissertation develops knowledge-based feature
generation, a stronger, but more restricted, method of
constructive induction than was available previously.
Knowledge-based feature generation is a heuristic method
of using one general and easily available form of domain
knowledge to create functional features for one class of
learning problems. The method consists of heuristics for
creating features, for pruning useless new features, and
for estimating feature cost. It has been tested
empirically on problems ranging from simple to complex,
and with inductive learning algorithms of varying power.
The results show knowledge-based feature generation to
be a general method of creating useful new features for
one class of learning problems.
</ABSTRACT>
</THESIS>
<THESIS>
<NUMBER> 4489 </NUMBER>
<ORDER>   AAG9316546 </ORDER>
<TITLE>   LEARNING TO RECOGNIZE VISUAL CONCEPTS: DEVELOPMENT AND IMPLEMENTATION OF A METHOD FOR TEXTURE CONCEPT ACQUISITION THROUGH INDUCTIVE LEARNING </TITLE>
<AUTHOR>   BALA, JERZY WOJCIECH </AUTHOR>
<YEAR>   1993 </YEAR>
<INSTITUTION>   GEORGE MASON UNIVERSITY; 0883 </INSTITUTION>
<DESCRIPTORS>   COMPUTER SCIENCE; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER>   RYSZARD SPENCER MICHALSKI </ADVISER>
<CLASSIFICATIONS>   NIL </CLASSIFICATIONS>
<ABSTRACT>
The goal of this research is to explore the application
of symbolic learning methods to problems of computer
vision. The research presented in this thesis has been
concerned primarily with the development of methods for
inductive learning of texture descriptions. Texture
description learning is done in the following phases:
(i) data preprocessing and attribute extraction, (ii)
acquisition of texture concept descriptions, (iii)
optimization of acquired descriptions, and (iv)
recognition of unknown texture samples. The methodology
adapted to the acquisition and recognition of complex
vision data is based on an extension of AQ (Michalski,
1986), a learning from-examples algorithm. This approach
for inductive learning of texture descriptions was
originally proposed by Michalski (1973) and was
initially applied using ILLIAC III image recognition
computer facilities. This research presents a novel
extension to the initial approach, which is called
Multilevel Logical Templates. The novelty lies in
multilevel symbolic image transformations, new advanced
concept description optimization methods for noise-
tolerant learning, and a multistrategy approach to
learning from vision data. An important contribution of
the research is the experimental demonstration that
symbolic inductive learning methods can be successfully
applied to the domain of continuous attributes of low
level vision in which non symbolic methods have been
traditionally employed.
</ABSTRACT>
</THESIS>
<THESIS>
<NUMBER> 4490 </NUMBER>
<ORDER>   AAG9316146 </ORDER>
<TITLE>   BASEMENT FAILURE DIAGNOSIS EXPERT SYSTEM </TITLE>
<AUTHOR>   DIAZ SUAREZ, CARLOS FERNANDO </AUTHOR>
<YEAR>   1993 </YEAR>
<INSTITUTION>   THE OHIO STATE UNIVERSITY; 0168 </INSTITUTION>
<DESCRIPTORS>   ENGINEERING, CIVIL; COMPUTER SCIENCE; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER>   FABIAN C. HADIPRIONO </ADVISER>
<CLASSIFICATIONS>   NIL </CLASSIFICATIONS>
<ABSTRACT>
Failures in basements are one of the most common
problems in residential buildings in the United States.
An expert frequently is needed to assess the causes of
basement failures. Hiring an expert to diagnose the
cause of the damage of one single house is often more
expensive than repair the cracking caused by the
basement failure. For this reason, many owners shy away
from hiring consultants to inspect the condition of the
basement.
Although structural and soil mechanics theory is used to
discover the causes of basement failures, experts
frequently use intuition, rules of thumb, and heuristic
approaches. Despite the fact that these approaches often
are not quantifiable, an excellent and affordable
engineering tool could be constructed if the opinions of
these experts were to be incorporated into a
computerized system.
The result of this dissertation is the development of
the Basement Failure Diagnosis Expert System, BAFDES, an
expert system that can identify causes of basement
failure. BAFDES is very user friendly, provides on-
screen help and explanations at the user's request, and
indicates how the conclusions of a consultation are
reached.
To implement BAFDES, this dissertation introduces an
innovative and effective method for the production of
semantic net models based on fault trees. Semantic net
models are then translated into a classificatory tree.
The method accomplishes this through three steps that
utilize the caused-by arcs in the semantic net, identify
tests, and create intermediate branching by grouping
alternatives in the classificatory tree. BAFDES has been
tested and validated by the knowledge engineer and his
adviser, by the participating expert, and by non-
participating experts. The result indicates that the
system completeness, user interface, and efficiency of
BAFDES range between good and very good. The
applicability of BAFDES ranges between fair and good.
</ABSTRACT>
</THESIS>
<THESIS>
<NUMBER> 4491 </NUMBER>
<ORDER>   AAG9315503 </ORDER>
<TITLE>   JOSEKI SEARCH, PARALLEL COMPUTATION AND COMPUTER GO: A NEW APPROACH TO THE JOSEKI PROBLEMS </TITLE>
<AUTHOR>   SHYU, WENG-YU </AUTHOR>
<YEAR>   1993 </YEAR>
<INSTITUTION>   CITY UNIVERSITY OF NEW YORK; 0046 </INSTITUTION>
<DESCRIPTORS>   COMPUTER SCIENCE; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER>   MICHAEL ANSHEL </ADVISER>
<CLASSIFICATIONS>   COMPUTER GO </CLASSIFICATIONS>
<ABSTRACT>
Now that startlingly successful computer chess programs
have been developed, a similarly advanced Go program is
the next logical goal for the AI game-modeling
community. A strong Go program was an original goal of
the Japanese Fifth Generation project, but it was later
dropped. To date, the best Go programs are still at the
beginner level. The primary reason for this is that the
game of Go has a much larger number of legal moves than
does chess and it is also much harder to evaluate the
strength of positions with heuristics. Furthermore,
since most Go programs run on a personal computer, they
lack necessary computational resources. Because the game
tree generated by a Go game is so large, an exhaustive
search is not possible with current technology. Adding
more computational resources to current programs may
enhance the abilities of these programs. Advances in the
hardware circuits and the algorithms used to play Go--as
we introduce here--make a far greater difference. In
this thesis, we develop a system to handle the Go
opening game. Because of the multiplicity of choices,
this requires a sophisticated searching method and much
computational power. First, a pattern recognition
program extracts the book knowledge called 'joseki' from
a joseki dictionary. Second, a tree construction program
compiles the knowledge into a tree. Third, an algorithm
is used to match the pattern in a joseki with the
pattern on the game board. Fourth, an alpha-beta search
and a static evaluation select the best joseki for the
next move. Some parallel evaluation algorithms under
hypercube machines are also discussed. Finally, logic
circuits are designed to implement some of the critical
functions in the algorithm and their simulations are
shown. These circuits dramatically improve the speed of
the algorithm. They can also be applied to the middle
game and the end game of a Go program.
</ABSTRACT>
</THESIS>
<THESIS>
<NUMBER> 4492 </NUMBER>
<ORDER>   AAG9314925 </ORDER>
<TITLE>   BLACKBOARD SCHEDULER CONTROL KNOWLEDGE FOR HEURISTIC CLASSIFICATION: REPRESENTATION AND INFERENCE </TITLE>
<AUTHOR>   PARK, YOUNG-TACK </AUTHOR>
<YEAR>   1993 </YEAR>
<INSTITUTION>   UNIVERSITY OF ILLINOIS AT URBANA-CHAMPAIGN; 0090 </INSTITUTION>
<DESCRIPTORS>   COMPUTER SCIENCE; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER>   DAVID C. WILKINS </ADVISER>
<CLASSIFICATIONS>   NIL </CLASSIFICATIONS>
<ABSTRACT>
The scheduler is an key component of a blackboard system
architecture. This thesis addressed the important
problem of how to make the blackboard scheduler more
knowledge intensive in a way that facilitates the
acquisition, integration, and maintenance of the
blackboard scheduler knowledge. The solution approach
described in this thesis involved formulating the
blackboard scheduler task as a heuristic classification
problem, and then implementing it as a classification
expert system. By doing this, the wide spectrum of known
methods of acquiring, refining, and maintaining the
knowledge of a classification expert system are
applicable to the blackboard scheduler knowledge.
In this thesis, the MINERVA expert system shell was
extended by the addition of a blackboard scheduler
level. The problem solving cycle involves a deliberation
phase, wherein all the heuristic classification
strategies that are applicable are collected. This is
followed by a scheduling phase wherein the
classification expert system for scheduling
automatically gathers evidence for and against each of
the applicable strategic actions, thereby ranking them
according to desirability. Finally, there is an action
phase that executes the most highly ranked strategic
task.
One important innovation of this research is that of
recursive heuristic classification: this thesis
demonstrates that it is possible to formulate and solve
a key subcomponent of heuristic classification as a
heuristic classification problem. Another key innovation
is the creation of a method of dynamic heuristic
classification: the classification alternatives that are
selected among are dynamically generated in real-time
and then evidence is gathered for and against these
alternatives. In contrast, the normal model of heuristic
classification is that of structured selection between a
set of preenumerated fixed alternatives.
</ABSTRACT>
</THESIS>
<THESIS>
<NUMBER> 4493 </NUMBER>
<ORDER>   AAG9314916 </ORDER>
<TITLE>   AUTOMATED LEARNING OF LOAD-BALANCING STRATEGIES FOR A DISTRIBUTED COMPUTER SYSTEM </TITLE>
<AUTHOR>   MEHRA, PANKAJ </AUTHOR>
<YEAR>   1993 </YEAR>
<INSTITUTION>   UNIVERSITY OF ILLINOIS AT URBANA-CHAMPAIGN; 0090 </INSTITUTION>
<DESCRIPTORS>   COMPUTER SCIENCE; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER>   B. W. WAH </ADVISER>
<CLASSIFICATIONS>   NIL </CLASSIFICATIONS>
<ABSTRACT>
Workstations interconnected by a local-area network are
the most common examples of distributed systems. The
performance of such systems can be improved via load
balancing, which migrates tasks from the heavily loaded
sites to the lightly loaded ones. Load-balancing
strategies have two components: load indices and
migration policies. This thesis presents SMALL
(Systematic Method for Automated Learning of Load-
balancing strategies), a system that learns new load
indices and tunes the parameters of given migration
policies. The key component of SMALL is DWG, a dynamic
workload generator that allows off-line measurement of
task-completion times under a wide variety of precisely
controlled loading conditions. The data collected using
DWG are used for training comparator neural networks, a
novel architecture for learning to compare functions of
time series. After training, the outputs of these
networks can be used as load indices. Finally, the load-
index traces generated by the comparator networks are
used for tuning the parameters of given load-balancing
policies. In this final phase, SMALL interfaces with the
TEACHER system of Wah, et al. in order to search the
space of possible parameters using a combination of
point-based and population-based approaches. Together,
the components of SMALL constitute an automated strategy-
learning system for performance-driven improvement of
existing load-balancing software.
</ABSTRACT>
</THESIS>
<THESIS>
<NUMBER> 4494 </NUMBER>
<ORDER>   AAG9314853 </ORDER>
<TITLE>   THE IMPLEMENTATION OF AN INTEGRATED TRANSPORTATION PLANNING MODEL WITH GIS AND EXPERT SYSTEMS FOR INTERACTIVE TRANSPORTATION PLANNING </TITLE>
<AUTHOR>   CHOI, KEECHOO </AUTHOR>
<YEAR>   1993 </YEAR>
<INSTITUTION>   UNIVERSITY OF ILLINOIS AT URBANA-CHAMPAIGN; 0090 </INSTITUTION>
<DESCRIPTORS>   ENGINEERING, CIVIL; OPERATIONS RESEARCH; TRANSPORTATION; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER>   TSCHANGHO JOHN KIM </ADVISER>
<CLASSIFICATIONS>   NIL </CLASSIFICATIONS>
<ABSTRACT>
The purpose of this research is to examine the possible
benefits of combining transportation planning models
with geographic information systems (GIS) and expert
systems (ES) in the hope that integrating these systems
can alleviate the inherent problems of transportation
planning models such as user-unfriendliness, labor-
intensiveness, and theoretical limitations.
Specifically, this research focuses on the potential
application of GIS topological data base to generate
transportation network and traffic analysis zone (TAZ)
configurations in the context the of interactive
transportation planning process. To achieve these goals,
first, network incompatibility between GIS and the
conventional transportation planning models has been
carefully reviewed and it is concluded that resolving
this conflict in topologies is a cornerstone for
eliminating the user-unfriendly and labor-intensive
problems of the conventional transportation planning
model. To implement this, a FORTRAN-based topology
conversion algorithm has been developed to convert GIS
topology into transportation network topology.
Second, to overcome the theoretically static and
sequential aspects of the conventional four-step
transportation planning model, a feedback mechanism and
looping structure have been simulated to seek a better
spatial aggregation form (a better traffic analysis
zoning scheme) and a more appropriate scale of spatial
aggregation (a more appropriate level of network
detail). Along with statistical clustering methods, GIS
topology is utilized to propose a set of alternative TAZ
schemes that may produce overall better results of the
conventional transportation planning model. To implement
this, FORTRAN-based zone aggregation routines have been
developed for grouping spatially homogeneous subregions
based on a heuristic algorithm.
An expert system, in the integration, facilitates the
generation of the input for the transportation planning
model and provides a user-friendly interface. Moreover,
the application of an expert system resolves judgmental
issues in the transportation planning process. The
expert system also governs a feedback mechanism in the
sequential modeling approach and provides a user-
friendly interface. The provision of this function is an
important addition since variations in TAZ schemes and
network conditions often generate different results.
To demonstrate the feasibility of integrating
transportation planning models, GIS and ES, the design
and development of an interactive desktop transportation
planning system called TranDASS was developed. TranDASS
is a personal computer-based decision support system
developed to aid quick responsive support for
transportation planning process. The result of empirical
evaluation reveals that the conceptual framework of
TranDASS can be easily applied to analyzing
transportation problems in different cities, regions, or
countries.
</ABSTRACT>
</THESIS>
<THESIS>
<NUMBER> 4495 </NUMBER>
<ORDER>   AAG9314848 </ORDER>
<TITLE>   LEARNING AND SMOOTH SIMULTANEOUS ESTIMATION OF ERRORS BASED ON EMPIRICAL DATA </TITLE>
<AUTHOR>   BUESCHER, KEVIN LEE </AUTHOR>
<YEAR>   1993 </YEAR>
<INSTITUTION>   UNIVERSITY OF ILLINOIS AT URBANA-CHAMPAIGN; 0090 </INSTITUTION>
<DESCRIPTORS>   ENGINEERING, SYSTEM SCIENCE; COMPUTER SCIENCE; STATISTICS; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER>   P. R. KUMAR </ADVISER>
<CLASSIFICATIONS>   NIL </CLASSIFICATIONS>
<ABSTRACT>
This thesis examines issues related to Valiant's
Probably Approximately Correct (PAC) model for learning
from examples. In this model, a student observes
examples that consist of sample points drawn according
to a fixed, unknown probability distribution and labeled
by a fixed, unknown binary-valued function. Based on
this empirical data, the student must select, from a set
of candidate functions, a particular function, or
"hypothesis," that will accurately predict the
labels of future sample points. The expected mismatch
between its prediction and the label of a new sample
point is called a hypothesis' "generalization
error."
We treat a more realistic problem than Valiant's model
in this thesis. We allow the labels and the hypotheses
to take general values (rather than just the values zero
and one). We do not assume that a hypothesis with zero
generalization error exists. Further, we do not even
assume that a deterministic functional relationship
exists between the sample points and the labels. In
particular, the observed values of the labels and sample
points may be subject to noise. Also, we allow prior
knowledge about the set of probability distributions to
be incorporated into the problem. In addition, we
address the issue of determining the appropriate
complexity for the class of candidate hypotheses. This
is related to the problem of the tendency to fit the
noise in the data, and the attendant increase in
generalization error, as the complexity of the candidate
hypotheses increases.
Following the pioneering work of Vapnik and
Chervonenkis, others have attacked this sort of learning
problem by finding hypotheses that minimize the relative
frequency-based empirical error estimate. We generalize
this approach by examining the "simultaneous
estimation" problem: When does some procedure exist
for estimating the generalization error of all of the
candidate hypotheses, simultaneously, from the same
labeled sample? We demonstrate how one can learn from
such a simultaneous error estimate and propose a new
class of estimators, called "smooth
estimators," that, in many cases of interest,
contains the empirical estimator. We characterize the
class of simultaneous estimation problems solvable by a
smooth estimator. We give a canonical form for the
smooth simultaneous estimator. Further, we show that,
when the empirical estimator is smooth, a learning
procedure based on the canonical estimator will work in
every case in which empirical error minimization does.
We derive bounds to show that the number of samples
required by the canonical estimator and the empirical
estimator is comparable.
</ABSTRACT>
</THESIS>
<THESIS>
<NUMBER> 4496 </NUMBER>
<ORDER>   AAG9314845 </ORDER>
<TITLE>   A MACHINE LEARNING APPROACH TO PLANNING IN COMPLEX REAL- WORLD DOMAINS </TITLE>
<AUTHOR>   BENNETT, SCOTT WILLIAM </AUTHOR>
<YEAR>   1993 </YEAR>
<INSTITUTION>   UNIVERSITY OF ILLINOIS AT URBANA-CHAMPAIGN; 0090 </INSTITUTION>
<DESCRIPTORS>   COMPUTER SCIENCE; ENGINEERING, ELECTRONICS AND ELECTRICAL; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER>   GERALD F. DEJONG </ADVISER>
<CLASSIFICATIONS>   ROBOTICS </CLASSIFICATIONS>
<ABSTRACT>
Classical planning techniques have some serious problems
when employed in real-world domains. In classical
planning, it is assumed we know the current state of the
world and can project that state through a reasonably
well-defined set of actions to yield a future state.
However, perfect models of the world and of operators
are not possible in most domains. Consequently,
discrepancies occur between the projected future state
and the observed future state. In these complex domains,
the success of the plan can never be guaranteed.
Furthermore, an important tradeoff exists between the
time spent constructing a plan and its resulting chance
of success. Several approaches to these problems have
been investigated, including the use of decision-
theoretic methods and the incorporation of reactivity
into planners. We present a new technique called
permissive planning. Explicit approximations are
employed in representing the world state and operators.
Plans are then constructed efficiently using the
approximate theory. In response to plan execution
failures, plans are refined so they become less
sensitive to the approximate knowledge used in their
initial construction. This is achieved by tuning
parameters of the plan so as to minimize the expected
future deviation.
Each permissive plan has a target success rate and a
degree of confidence desired in that success rate. We
present a formal permissive planning algorithm which can
be shown to either produce a plan with the desired
success rate and degree of confidence, if possible, or
otherwise to return the plan falling short of the target
but with the best possible success rate. One of the
downsides of this is that many examples are needed to
gather the statistical evidence necessary to ensure
these claims. Consequently, we propose an approximation
to this algorithm which uses heuristics to determine how
to refine plans and achieves good performance in the
real-world domains we have investigated. We demonstrate
the technique on the task of grasping of novel laminar
objects and on orienting parts in a tiltable tray.
</ABSTRACT>
</THESIS>
<THESIS>
<NUMBER> 4497 </NUMBER>
<ORDER>   AAG9313928 </ORDER>
<TITLE>   A VLSI INTERCONNECT STRATEGY FOR BIOLOGICALLY INSPIRED ARTIFICIAL NEURAL NETWORKS </TITLE>
<AUTHOR>   BAILEY, JAMES L. </AUTHOR>
<YEAR>   1993 </YEAR>
<INSTITUTION>   OREGON GRADUATE INSTITUTE OF SCIENCE & TECHNOLOGY; 0284 </INSTITUTION>
<DESCRIPTORS>   COMPUTER SCIENCE; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER>   NIL </ADVISER>
<CLASSIFICATIONS>   NEURAL NETWORKS </CLASSIFICATIONS>
<ABSTRACT>
Current interconnection architectures are not adequate
to support the communications requirements of Artificial
Neural Networks based upon Neurophysiological models.
For ANN models, direct implementation has a cost in
required area which scales as the cube of the number of
connections per node. A system of one million nodes,
each connected to one thousand others, would require 40
times as much silicon if implemented as a series of
direct wires as it would with multiplexed interconnect.
This thesis further shows that using a broadcast
communication paradigm improves cost-performance results
by at least a factor of $Nsp{1/2}$ over point-to-point.
Broadcast also allows for fewer messages, shorter
messages, easier implementation, and can be implemented
either with a physical broadcast interconnection
structure or as a virtual model imposed upon a point-to-
point physical interconnection architecture. This
research lays the theoretical foundations for
development of broadcast as an effective communications
paradigm for ANN implementations.
In support of the primary results of this thesis,
methods of analyzing target models and interconnection
architectures are developed. Other proposed
interconnection architectures are compared with the
proposed broadcast solutions and shown to be inadequate
for these network models.
In addition, results are given which show the
effectiveness of broadcast for implementing ANN models
ranging from artificial models such as feed-forward
layered networks to olfactory piriform cortex to
mammalian hippocampus to abstract neurophysiological
models. It is shown that a complete rat hippocampus
could be implemented in a single eight inch wafer with
a.3 micron technology.
</ABSTRACT>
</THESIS>
<THESIS>
<NUMBER> 4498 </NUMBER>
<ORDER>   AAG9313375 </ORDER>
<TITLE>   A GEOMETRIC FRAMEWORK FOR MACHINE LEARNING </TITLE>
<AUTHOR>   HEATH, DAVID GEORGE </AUTHOR>
<YEAR>   1993 </YEAR>
<INSTITUTION>   THE JOHNS HOPKINS UNIVERSITY; 0098 </INSTITUTION>
<DESCRIPTORS>   COMPUTER SCIENCE; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER>   NIL </ADVISER>
<CLASSIFICATIONS>   NIL </CLASSIFICATIONS>
<ABSTRACT>
Due to advances in the sciences, the ability of mankind
to collect data has increased enormously in recent
years. In many different areas, the research bottleneck
is no longer in data collection, but rather in data
interpretation. Often, the underlying processes
described by the data are very complex, compounding the
problem. In response, much research in computer analysis
of large datasets is under way. Machine learning is one
of the fields responding to the challenge of this
problem.
This thesis considers the interpretation of machine
learning problems and techniques under a geometric
model. Geometry is a useful for several reasons. It aids
in visualization, allowing for alternative ways of
thinking. It provides a rigorous framework for analyzing
learning problems and methods. It suggests modifications
to methods which can increase their usefulness and
efficiency.
In this thesis, geometric analysis is used to formulate
and analyze two theoretical machine learning problems
and to improve an existing machine learning method. A
form of best-case analysis is presented which can be
used to generate bounds on the number of examples needed
for learning. A formal trade-off between available
memory and speed of learning is established. In
addition, geometry is used to generalize the decision
tree method of machine learning. An algorithm for
learning based on this generalization is presented, and
its usefulness is demonstrated on a variety of
artificial and real-world databases.
</ABSTRACT>
</THESIS>
<THESIS>
<NUMBER> 4499 </NUMBER>
<ORDER>   AAG9312489 </ORDER>
<TITLE>   INVESTIGATIONS INTO DATABASE MANAGEMENT SYSTEM SUPPORT FOR EXPERT SYSTEM SHELLS. </TITLE>
<AUTHOR>   JOHNSON, VERLYN MARK </AUTHOR>
<YEAR>   1993 </YEAR>
<INSTITUTION>   UNIVERSITY OF MINNESOTA; 0130 </INSTITUTION>
<DESCRIPTORS>   COMPUTER SCIENCE; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER>   JOHN V. CARLIS </ADVISER>
<CLASSIFICATIONS>   VOLUMES I AND II </CLASSIFICATIONS>
<ABSTRACT>
Many expert system shells are available for developing
production rule based expert system applications.
However, it is difficult to rapidly change those
applications to respond to changing business conditions.
Each shell has its own production rule language and
inferencing capabilities. It is unclear what information
can be shared (reused). Use of main memory instead of a
shared, common source for rules constrains the size of
applications and can result in duplication. Maintenance
is not immediately available to existing inference
sessions and updates made by a session only affect that
session.
This thesis approaches production rules and working
storage as data that can be managed by enhanced database
management systems (DBMSs). Five expert system shells
are studied. A composite (canonical) production rule
syntax is developed which provides knowledge engineers
with a common language for production rules. It is
mapped into an integrated data model for use by tool
developers who wish to design common production rule
storage databases and maintenance tools. Extensions to
the data model allow expert system shell developers to
reduce main memory constraints by using a DBMS to store
and manage execution data. The analysis performed in
building the data model reveals where translation,
system enhancements, or standard definitions are
required to share production rules.
Two DBMS enhancements are defined to facilitate
management of production rule and execution data (but
which also have other applications). Reflexive indexes
enable a DBMS to incrementally maintain transitive
closures (including multiple tables, duplicates, side
paths, and accumulated values) as a database index. They
simplify query formats, and eliminate the need for
recursive processing during retrieval. One use is to
accumulate rule premise evaluation values during
inferencing. The inference locking protocol allows
concurrent, dynamic access by those maintaining and
executing control data. For example, it provides greater
flexibility in maintaining production rules by allowing
knowledge engineers to use multiple versions and
notification to control how updates to production rules
affect other maintenance and inference sessions. The
protocol can also be used to extend production rule
capabilities by allowing production rules to maintain
production rules concurrently with other maintenance and
inference sessions.
</ABSTRACT>
</THESIS>
<THESIS>
<NUMBER> 4500 </NUMBER>
<ORDER>   AAG9312381 </ORDER>
<TITLE>   IMAGE SEGMENTATION USING AN ANNEALED HOPFIELD NEURAL NETWORK </TITLE>
<AUTHOR>   KIM, YUNGSIK </AUTHOR>
<YEAR>   1993 </YEAR>
<INSTITUTION>   NORTH CAROLINA STATE UNIVERSITY; 0155 </INSTITUTION>
<DESCRIPTORS>   ENGINEERING, ELECTRONICS AND ELECTRICAL; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER>   SARAH A. RAJALA </ADVISER>
<CLASSIFICATIONS>   NEURAL NETWORKS </CLASSIFICATIONS>
<ABSTRACT>
Neural network architectures have been proposed as new
computer architectures, which, in some sense, are based
on knowledge about a "biological computer"
such as the human brain. A Hopfield neural network is a
very complex network of very simple processing units
that operate asynchronously, but in parallel. It can
find good solutions very fast in solving the
optimization problems.
In image segmentation, the data size may be large and
many image segmentation algorithms use iterative schemes
to get the improved results. As a result, it can take a
lot of time to process even a small image. Image
segmentation, like other engineering problems, can be
formalized as an optimization problem and the desired
image segmentation can be achieved by finding the
globally optimum solution to the optimization function.
A Hopfield neural network can solve optimization
problems fast, but it is only guaranteed to reach a
local minimum, not the global minimum. Finding a local
minimum fast is desirable in some problems such as the
associate memory problem, but not in other problems such
as image segmentation.
Algorithms such as stochastic simulated annealing (9)
and deterministic mean field annealing (8) are used to
get the global optimum or nearly global optimum
solutions. Mean field annealing can reach the nearly
global optimum solutions faster than stochastic
simulated annealing while maintaining many of the
advantages of stochastic simulated annealing.
Furthermore, Van den Bout et al. (12) showed that there
is a relationship between a Hopfield neural network and
mean field annealing if the annealing parameter is fixed
at a certain value.
In this dissertation, we propose using an annealed
Hopfield neural network for solving the image
segmentation problem. This approach finds the global or
nearly global solution fast through an annealing
schedule for the neuron gains. This network is expected
to solve other kinds of optimization problems as well,
where a fast approach to finding the global or the
nearly global minimum is desired.
A weak constraints approach proposed by Blake and
Zisserman (13) is used for finding the appropriate
optimization function for implementing image
segmentation and then the annealed Hopfield neural
network is used for finding the nearly global or the
globally minimum solution. Finally, the simulation
results are discussed and compared with other existing
techniques to assess the performance of our algorithm.
</ABSTRACT>
</THESIS>
<THESIS>
<NUMBER> 4501 </NUMBER>
<ORDER>   AAG9312319 </ORDER>
<TITLE>   AN INTELLIGENT SELF-ADAPTIVE USER INTERFACE: CLASSIFYING USERS WITH A LINEAR-PROGRAMMING BASED NEURAL NETWORK </TITLE>
<AUTHOR>   EL-GAYAR, MONA AHMED </AUTHOR>
<YEAR>   1993 </YEAR>
<INSTITUTION>   LEHIGH UNIVERSITY; 0105 </INSTITUTION>
<DESCRIPTORS>   COMPUTER SCIENCE; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER>   EDWIN KAY </ADVISER>
<CLASSIFICATIONS>   NIL </CLASSIFICATIONS>
<ABSTRACT>
The increasing complexity of today's software packages
combined with the rapid use of computer usage by the
general population has created an urgent need for
software interfaces that can cater to computer users who
differ widely in their levels of expertise, styles, and
preferences. While experts can appreciate the
capabilities of sophisticated software tools, novices
too often find these tools overwhelming and difficult to
use. This thesis investigates mechanisms that enable
user interfaces to adapt themselves automatically to the
needs and expertise of the individual user.
Interface features for different users (novices,
experts) were designed, and empirical experiments
demonstrated that novices perform better on the
interface with novice features and experts performed
well on both interfaces (but preferred the expert
interface). An adaptive interface architecture was
designed to control the presentation of the novice and
expert interface features.
The adaptive system consists of a monitor which captures
the user interaction trace and extracts expertise
features of the user's behavior, a filter which forwards
the data to the appropriate neural network depending on
the interface feature accessed, and neural networks
which classify the user's behavior as novice or expert.
A comparative study of three different neural network
models showed that a linear-programming based network
was most accurate in classifying users' behavior.
The user classification is passed to the rule adaptor,
which compares the users' recent behavior history to pre-
defined thresholds to determine whether the interface
feature should adapt (novice to expert, or expert to
novice). This technique prevents the interface feature
from quickly changing.
The mechanisms in this thesis were implemented in the
Smalltalk-80 environment with the Smalltalk-80 interface
itself as the target adaptive interface. An exploratory
experiment to test the adaptation techniques
successfully demonstrated interface adaptation to the
user's expertise during a one-half hour session.
</ABSTRACT>
</THESIS>
<THESIS>
<NUMBER> 4502 </NUMBER>
<ORDER>   AAG9312246 </ORDER>
<TITLE>   RECURRENT NEURAL NETWORKS AND GRAMMATICAL INFERENCE </TITLE>
<AUTHOR>   MASKARA, ARUN KUMAR </AUTHOR>
<YEAR>   1993 </YEAR>
<INSTITUTION>   POLYTECHNIC UNIVERSITY; 0179 </INSTITUTION>
<DESCRIPTORS>   COMPUTER SCIENCE; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER>   ANDREW NOETZEL </ADVISER>
<CLASSIFICATIONS>   NIL </CLASSIFICATIONS>
<ABSTRACT>
Recurrent neural networks produce outputs that depend
not only on the current input, but also on the network's
internal state, which is usually determined by previous
inputs. Previous research has shown that a simple
recurrent network (SRN) can be trained to predict each
successive symbol of any sequence in a particular
language, and thus act as a recognizer of the language.
Here, several conditions occurring within the class of
regular languages are shown that result in recognition
failure by any SRN with a limited number of nodes in the
hidden layer. Simulation experiments show how modified
versions of the SRN can overcome these failure
conditions. In one case it is found to be necessary to
train the SRN to show at its output units both the
current input symbol as well as the predicted symbol. In
another case the SRN must show the current contents of
the context units. It is shown that the SRN with both
modifications, called the auto-associative recurrent
network (AARN), overcomes the identified conditions for
SRN failure, even when they occur simultaneously.
However, it cannot be trained to recognize all of the
regular languages.
The effect of the size of the training set for
grammatical inference is also considered. In previous
research the SRN type network has been shown to be
effective when trained on an infinite (or very large)
set of positive examples. When a finite (small) set of
positive training data is used, training often fails.
This problem is solved through a new training algorithm
that uses both positive and negative examples of the
sequences. When a finite set of positive and negative
data is used for training, the generalization capability
depends on the data set. The generalization capability
improves when the data set has no cutoff points. A
cutoff point is defined as a position in a negative
example at which the next input symbol is invalid.
</ABSTRACT>
</THESIS>
<THESIS>
<NUMBER> 4503 </NUMBER>
<ORDER>   AAG9310543 </ORDER>
<TITLE>   KNOWLEDGE-BASED FRAMEWORK FOR AN AUTOMATED USER INTERFACE PRESENTATION DESIGN TOOL </TITLE>
<AUTHOR>   KIM, WON CHUL </AUTHOR>
<YEAR>   1993 </YEAR>
<INSTITUTION>   THE GEORGE WASHINGTON UNIVERSITY; 0075 </INSTITUTION>
<DESCRIPTORS>   COMPUTER SCIENCE; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER>   JAMES DAVID FOLEY </ADVISER>
<CLASSIFICATIONS>   AUTOMATED DESIGN </CLASSIFICATIONS>
<ABSTRACT>
The capabilities of user interface design tools can be
enhanced by providing high-level design control
throughout the user interface presentation design
process. Current user interface builders provide only
low-level assistance, because they have knowledge of
neither the application, nor the principles by which
interface elements are combined effectively. In this
research, a framework that unites the essential
knowledge components needed for effective user interface
presentation design was developed. The framework
consists of an application model (both a data model and
a control model), a design process model that supports
top-down iterative development, and graphic design
knowledge that is used both to place dialog box elements
such that their application dependent logical
relationships are visually reinforced and to control
design symmetry and balance. To demonstrate the
framework's viability, we have constructed a tool based
on encapsulated design knowledge that establishes high-
level style preferences and provides expert assistance
to create the user interface presentation design
automatically.
The design process architecture developed in this
research incorporates models of the three major design
tasks of user interface presentation design: (1) content
organization; (2) interface object selection; and (3)
presentation design layout. A designer is guided through
each stage of the design process. The design tool
provides high-level design control by allowing a
designer to specify the high-level preferences prior to
each design activity and by allowing a designer to
modify automated design decisions interactively after
each design activity. By working with the design tool in
a cooperative manner, a designer is able to constrain
and explore the design space to automatically generate
menu and dialog box presentation that can be further
refined until a presentation that meets a designer's
needs is generated. The underlying knowledge base is
transformed automatically at each stage until the final
presentation design representation is generated. The
effectiveness of the design tool comes from the
knowledge base representation of various stages of the
interface design process and embedded design knowledge
that supplements a designer's knowledge.
</ABSTRACT>
</THESIS>
<THESIS>
<NUMBER> 4504 </NUMBER>
<ORDER>   AAG9309601 </ORDER>
<TITLE>   TOPICS IN MULTI-AGENT EPISTEMIC LOGIC </TITLE>
<AUTHOR>   GROVE, ADAM JOSEPH </AUTHOR>
<YEAR>   1993 </YEAR>
<INSTITUTION>   STANFORD UNIVERSITY; 0212 </INSTITUTION>
<DESCRIPTORS>   COMPUTER SCIENCE; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER>   JOSEPH Y. HALPERN </ADVISER>
<CLASSIFICATIONS>   EPISTEMIC LOGIC, MODAL LOGIC </CLASSIFICATIONS>
<ABSTRACT>
Reasoning about knowledge is useful in artificial
intelligence and distributed systems theory,
particularly when we look at systems composed of many
interacting "agents." This dissertation
investigates various questions concerning knowledge that
are specific to multi-agent systems, and develops
theories that cope with them.
Many existing multi-agent logics fail to make a clear
distinction between the agents themselves and the names
for agents that occur within the logic. This is
restrictive and prohibits a general treatment of, for
instance, anonymous agents, names with varying or
unknown denotation, agents with many names, named groups
of agents, and relative (indexical) reference. We
examine the principles involved in such cases, and give
simple propositional logics that are expressive enough
to cope with them all. We also give a new and powerful
first-order modal logic for knowledge. Although this
logic is motivated by practical examples, it is also
relevant to some well-known philosophical concerns, such
as indexical descriptions, de re knowledge, and
quantifying-in. The logic adopts a new and
nontraditional approach to such subjects, because this
seems to be required by our use of epistemic logic as a
descriptive tool for computer science applications.
The dissertation also investigates systems of message-
passing agents. We argue that it would be useful to
augment the standard theory of ascribed knowledge with a
logic and semantics for ascribed message content. The
theories we develop in this dissertation have the
important feature that content, like knowledge, can be
ascribed to concrete messages in existing message-
passing systems. The goal is to be able to reason about
real systems in high-level terms, using knowledge,
content, and the interaction between them.
</ABSTRACT>
</THESIS>
<THESIS>
<NUMBER> 4505 </NUMBER>
<ORDER>   AAG9309600 </ORDER>
<TITLE>   UPDATING AND STRUCTURE IN NON-MONOTONIC THEORIES </TITLE>
<AUTHOR>   GROSOF, BENJAMIN NATHAN </AUTHOR>
<YEAR>   1993 </YEAR>
<INSTITUTION>   STANFORD UNIVERSITY; 0212 </INSTITUTION>
<DESCRIPTORS>   COMPUTER SCIENCE; PHILOSOPHY; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER>   NILS J. NILSSON </ADVISER>
<CLASSIFICATIONS>   KNOWLEDGE BASES </CLASSIFICATIONS>
<ABSTRACT>
The challenge we address is how to support non-monotonic
reasoning tasks over large-scale knowledge bases of rich
expressive form. We identify a central problem of
updating: which parts of the previous retractable
conclusions are safe, i.e., unaffected, when various new
axioms are added? This problem is important not only for
the task of belief maintenance and revision, but also
for specification and for inference. The difficulty
arises because non-monotonicity implies potential
globality of conflicting interaction. We attack the
problem at a logical level, choosing the circumscription
formalism as our vehicle of analysis for its
mathematical convenience and expressive power.
This dissertation provides a primary groundwork for
implementing circumscriptive (and other) non-monotonic
reasoning systems that go beyond previous ones in
several respects: to perform forward inference and to
maintain a body of valid conclusions, as well as to
answer queries, for more expressively complex and larger-
scale theories. Our major results build sequentially.
(1) We extend the circumscription formalism by
generalizing the idea of prioritization (relative
precedence) so as to enable, for example, the more
adequate representation of source reliability and of
default inheritance networks. (2) We show that non-
monotonic theories are hierarchically decomposable in a
manner analogous to programming languages with side
effects. (3) We demonstrate several broad cases of
safeties of updating, including updating with new
default rules. Enabling conditions include syntactic
independence and positivity, as well as relative
prioritization. (4) We define a generalized
"assumption-based" truth maintenance scheme to
support inference and belief revision.
</ABSTRACT>
</THESIS>
<THESIS>
<NUMBER> 4506 </NUMBER>
<ORDER>   AAG9309585 </ORDER>
<TITLE>   A SYMBOLIC GENERALIZATION OF PROBABILITY THEORY </TITLE>
<AUTHOR>   DARWICHE, ADNAN YOUSSEF </AUTHOR>
<YEAR>   1993 </YEAR>
<INSTITUTION>   STANFORD UNIVERSITY; 0212 </INSTITUTION>
<DESCRIPTORS>   COMPUTER SCIENCE; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER>   MATTHEW GINSBERG </ADVISER>
<CLASSIFICATIONS>   ABSTRACT BELIEF CALCULUS, OBJECTION CALCULUS </CLASSIFICATIONS>
<ABSTRACT>
Three questions motivate much work in AI. How should an
agent's state of belief be represented? How should an
agent change its state of belief upon recording an
observation? And what is a practical way for domain
experts to convey their states of belief to agents?
Probability calculus provides answers to these
questions: A state of belief should be (1) represented
by a probability function over some language, (2)
changed using probabilistic conditionalization, and (3)
conveyed using a probabilistic causal network. Despite
the popularity of these answers, domain experts have
often complained about their commitment to numeric
degrees of belief. In this thesis, I attempt to address
this complaint by suggesting an abstract belief calculus
that is not committed to numbers (nor to any specific
set of degrees of belief) and yet has the key features
of probability calculus. The abstract calculus has three
major components: (1) Abstract states of belief, (2)
abstract conditionalization, and (3) abstract causal
networks. The calculus is also equipped with an
algorithm for computing degrees of belief, which
corresponds to a popular algorithm in the probabilistic
literature.
I present many concrete instances of the proposed
abstract belief calculus. Some of these instances are
well known, such as proposition, possibility, and
probability calculi. But other instances are novel, such
as objection calculus. I also show that objection
calculus is closely related to clause management and
diagnosis systems--which are influential in AI--and
study the ramifications of this relation.
</ABSTRACT>
</THESIS>
<THESIS>
<NUMBER> 4507 </NUMBER>
<ORDER>   AAG9308230 </ORDER>
<TITLE>   STRUCTURAL DESIGN USING NEURAL NETWORKS </TITLE>
<AUTHOR>   SWIFT, RICHARD ALAN </AUTHOR>
<YEAR>   1993 </YEAR>
<INSTITUTION>   UNIVERSITY OF NOTRE DAME; 0165 </INSTITUTION>
<DESCRIPTORS>   ENGINEERING, AEROSPACE; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER>   STEPHEN BATILL </ADVISER>
<CLASSIFICATIONS>   NIL </CLASSIFICATIONS>
<ABSTRACT>
At the early stages of design, it is necessary to obtain
an understanding of the design space characteristics for
the structural concepts under consideration. This
involves developing a representation of the structural
system's behavior to variations in the design variables
of interest. The effort of this research was to
efficiently obtain both qualitative and quantitative
structural design space mappings for use in preliminary
design studies. Recent advances in finite element based
structural optimization techniques provide the means to
address this concern, but these approaches typically
involve the determination of "points" in the
design space, rather than a mapping of the design space.
Neural networks, mathematical models of biologically
occurring neural systems, were employed to quantify the
design space representations. The neural networks form
the representation of the design space based on a set of
optimal designs obtained from math-programming and fully-
stressed design optimization programs. Feed-forward,
back-propagation neural networks were used to form the
design space representation. The neural network
representations were then used to ascertain trends in
the design space, and the neural networks were also
"searched" using various optimization
procedures to define those regions of the design space
that showed the most promising design characteristics.
Math-programming techniques and simulated annealing
procedures were employed to perform the searches of the
design spaces. Recursive learning was explored to
minimize the amount of training data necessary (training
data generation being the most computationally expensive
part of the neural network procedure). Continuous as
well as discrete design variables were examined. The
continuous design variable cases involved
configurational design, while the discrete design
variable cases involved material selection. Planar
trusses, a 3-D space truss, and three semi-monocoque
wings were used to describe the implementation of the
neural network procedure. The results obtained from
these models show that the design spaces are effectively
represented by the neural networks. The neural networks
also provide the means to determine significantly
improved designs, with reductions in objective function
values of over 10% noted for several cases. The neural
network approach to design space representation appears
to hold promise to a wide range of structural design
problems.
</ABSTRACT>
</THESIS>
<THESIS>
<NUMBER> 4508 </NUMBER>
<ORDER>   AAG9309583 </ORDER>
<TITLE>   THE VIRTUAL DESIGN TEAM: AN INFORMATION-PROCESSING MODEL OF DESIGN TEAM MANAGEMENT </TITLE>
<AUTHOR>   COHEN, GEOFFREY PATRICK </AUTHOR>
<YEAR>   1993 </YEAR>
<INSTITUTION>   STANFORD UNIVERSITY; 0212 </INSTITUTION>
<DESCRIPTORS>   BUSINESS ADMINISTRATION, MANAGEMENT; SOCIOLOGY, GENERAL </DESCRIPTORS>
<ADVISER>   RAYMOND E. LEVITT </ADVISER>
<CLASSIFICATIONS>   NIL </CLASSIFICATIONS>
<ABSTRACT>
Research to date on organizational theory in general--
and coordination theory in particular--has been hampered
by the difficulty of conducting controlled experiments
in real organizations to test and refine theories. The
Virtual Design Team (VDT) research is an information
processing model of managerial decision-making based
principally on organizational concepts derived from
(Thompson 1967), (Galbraith 1977) and (Mintzberg 1979),
(Simon 1981) and (March 1988a). Verification tests the
implication of parts of Galbraith's theory on the
coordination performance of an engineering design team.
A behavioral interpretation of organizational
information processing and decision-making is used
within a process perspective. This perspective regards
how information processing is carried out as more
important than what information is used. Managers and
design subteams (actors) are modeled performing
organizational roles--considered an insightful and
meaningful perspective from which to understand
organizational processes and their outcomes (March
1988a). Extensive observations of managerial behavior by
other researchers is complemented with my own field
observations.
The VDT model is an object-oriented, stochastic,
discrete event simulation of a multidisciplinary design
team using model-based reasoning derived from Artificial
Intelligence. Extensive verification and testing of the
model was carried out with an oil refinery design
project.
The design task is modeled as a network of activities
performed by actors. Actors pay attention to information
according to attention rules; process information in a
length of time determined by processing knowledge; and
direct information to others. Actors inherit behavioral
characteristics from professional, corporate, and team
hierarchies. They receive and direct information through
task, hierarchical control, and social relationships.
Actors' communication tools affect the richness, volume,
and timing of information passing among them. Within
this framework, we can model how alternative
organizational relationships and communication tools
affect the duration of design tasks.
Typical questions include "How will centralizing
decision-making affect project team performance?"
or "How will a new communication tool such as
electronic mail affect performance?"
Simulation models based on VDT ideas are expected to
provide computerized tools for researchers to develop,
validate and refine theories that describe how
collaborative knowledge-intensive tasks such as the
concurrent design of facilities are, or should be,
coordinated.
</ABSTRACT>
</THESIS>
<THESIS>
<NUMBER> 4509 </NUMBER>
<ORDER>   AAG9237309 </ORDER>
<TITLE>   FAST INCREMENTAL LEARNING, CLASSIFICATION, AND PREDICTION BY SELF-ORGANIZING NEURAL NETWORKS </TITLE>
<AUTHOR>   ROSEN, DAVID B. </AUTHOR>
<YEAR>   1993 </YEAR>
<INSTITUTION>   BOSTON UNIVERSITY; 0017 </INSTITUTION>
<DESCRIPTORS>   COMPUTER SCIENCE; BIOLOGY, NEUROSCIENCE; ENGINEERING, GENERAL; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER>   GAIL A. CARPENTER </ADVISER>
<CLASSIFICATIONS>   NIL </CLASSIFICATIONS>
<ABSTRACT>
New neural networks for supervised and unsupervised
classification and clustering are introduced. They can
operate at a high learning rate in on-line (incremental)
or off-line (batch) applications, without becoming
unstable. They emulate the brain's ability to rapidly
correct errors and assimilate new data using a highly
parallel architecture with local computations. Each of
many input attributes may be continuous-or discrete-
valued.
A new algorithm termed ART 2-A is introduced as an
efficient proxy for the unsupervised neural network ART
2. Both ART 2 and ART 2-A are studied to determine
appropriate learning rates and training regimes for
stable category formation with continuous-valued
(analog) input attributes.
The unsupervised neural network ART 1 operates on-line,
with stable category formation for any learning rate and
arbitrary binary input sequences. ARTMAP incorporates
ART 1 into a supervised learning system. Fuzzy ART and
Fuzzy ARTMAP, introduced herein, use operations of fuzzy
set theory to extend ART 1 and ARTMAP (respectively) to
allow inputs that represent continuous-valued attributes
as well as binary.
A normalization procedure called complement coding is
introduced to symmetrize the theory, avoid category
erosion, and ensure rapid error correction with fast
incremental learning in Fuzzy ARTMAP, without having to
store all the data.
Each "hidden node" of Fuzzy ARTMAP is shown to
represent a box in M-dimensional input space that
expands during learning. This geometric interpretation
allows the decomposition of a trained network into
interpretable rules, and enables specific comparison
with related algorithms.
Empirical studies demonstrate the effectiveness of Fuzzy
ARTMAP, for example completing a benchmark learning task
three orders of magnitude faster than typical multi-
layer perceptrons.
</ABSTRACT>
</THESIS>
<THESIS>
<NUMBER> 4510 </NUMBER>
<ORDER>   AAGNN89474 </ORDER>
<TITLE>   VLSI HARDWARE SYNTHESIS OF ARTIFICIAL NEURAL NETWORKS </TITLE>
<AUTHOR>   ACHYUTHAN, ARUN </AUTHOR>
<YEAR>   1993 </YEAR>
<INSTITUTION>   UNIVERSITY OF WATERLOO (CANADA); 1141 </INSTITUTION>
<DESCRIPTORS>   ENGINEERING, ELECTRONICS AND ELECTRICAL; COMPUTER SCIENCE; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER>   MOHAMMED ELMASRY </ADVISER>
<CLASSIFICATIONS>   NIL </CLASSIFICATIONS>
<ABSTRACT>
A design methodology for automated mapping of Artificial
Neural Network (ANN) systems to VLSI architectures is
presented. The synthesis is targeted for generalized
descriptions of popular ANN systems with diverse
learning procedures, connection structures and
performance requirements. The methodology takes into
account specific requirements for a targeted
application, such as hardware cost, speed of
performance, and accuracy and precision of the
computation of the algorithm. The ANN is input in the
form of a Data Flow Graph (DFG) with the functional
modules as the nodes of the graph. The output of the
synthesizer is a high-level interconnection description
of analog and digital building block circuits. Analog
circuit non-idealities are addressed by quantitatively
analyzing the ANN systems, generating specifications on
error due to these effects, modeling the non-ideal
behavior of building block circuits and selecting those
circuits whose behavior match the specifications. Analog
blocks are used wherever possible, and digital circuits
are employed only when the performance of analog
circuits fall short of the specifications. Synthesis of
mixed analog/digital hardware description is performed
after minimizing the interfaces between analog and
digital circuit sections, and by exploring a design
space for varying emphasis on hardware minimization and
execution speed. The overall approach is based on
techniques that are adopted for digital systems, but it
is capable of meeting the needs of analog operations.
The methodology fully utilizes the compactness of analog
circuits while striving to preserve concurrency of ANN
operations. When concurrency needs to be traded with
hardware cost, the synthesizer employs a selective
sequentialization approach to find an optimum balance
between resource utilization and performance throughput.
The utilities of the proposed methodology is
demonstrated with the help of design examples from three
different ANN systems.
</ABSTRACT>
</THESIS>
<THESIS>
<NUMBER> 4511 </NUMBER>
<ORDER>   AAGNN88987 </ORDER>
<TITLE>   DIAGNOSTIC TESTS FOR PROTOCOL IMPLEMENTATIONS MODELED BY FINITE STATE MACHINES </TITLE>
<AUTHOR>   GHEDAMSI, ABDERRAZAK BEN NACEUR </AUTHOR>
<YEAR>   1993 </YEAR>
<INSTITUTION>   UNIVERSITE DE MONTREAL (CANADA); 0992 </INSTITUTION>
<DESCRIPTORS>   COMPUTER SCIENCE </DESCRIPTORS>
<ADVISER>   G. V. BOCHMANN; R. DSSOULI </ADVISER>
<CLASSIFICATIONS>   NIL </CLASSIFICATIONS>
<ABSTRACT>
Systematic test sequence generation for communication
protocols in conformance testing has been an active
research area during the last decade. New test selection
methods have been developed to test the conformity of
protocol implementations against their specifications.
These methods are mainly based on finite state machine
models (FSMs). They produce test sequences destined to
detect faults in the transitions of an implementation
under test.
An approach for localization of detected faults is based
on the sequences of transitions executed in the
specification, once the initially given test suite is
applied. It deduces some fault hypotheses having the
ability of explaining the observed traces. The approach
allows the production of a sub-set of transitions
suspected of being faulty. In the case where the single
fault hypothesis is used, with the help of additional
test cases, it is possible to reduce such a sub-set to a
single transition and hence the localization of the
fault. It has to be noted that this approach does not
require that all specification transitions be covered by
the initially given test suite.
In order to develop diagnostic methods for distributed
systems and communication software, where the
specifications and the implementations are represented
by finite state machine models, we have studied existing
diagnostic methods in the domains of artificial
intelligence, integrated circuits and software
engineering. With the inspiration from these methods, we
were able to develop a new diagnostic approach for FSMs.
Under the single fault (output or transfer) hypothesis,
we developed a first method which provides the diagnosis
of deterministic finite state machines. We developed a
second diagnostic method for another type of systems
consisting of two communicating finite state machines.
The same fault model is used for this second type of
systems. Under the hypothesis of single transition
faults, we proposed a third method to diagnose non-
deterministic systems. A transition is faulty if it has
an output fault and/or a transfer fault.
We believe that our diagnostic methods are the first to
use the test result analysis technique to diagnose
different FSM models. They can be used to localize
faults into real implementations of communication
protocols. An ongoing project takes traces from the ISDN
LAP-D Protocol, executed on the IDACOM Protocol Tester,
and converts them to be analyzed by FSMDiags. The usage
of a fault detection technique, completed by one of our
diagnostic methods, will cost less (in terms of the
total number of test cases) than the usage of a
technique which has both fault detection and fault
localization powers, as for example the W method under
the single fault hypothesis. (Abstract shortened by
UMI.)
</ABSTRACT>
</THESIS>
<THESIS>
<NUMBER> 4512 </NUMBER>
<ORDER>   AAG9432991 </ORDER>
<TITLE>   OPTOELECTRONIC ARRAY PROCESSORS WITH APPLICATIONS IN MACHINE INTELLIGENCE AND DATABASE MANAGEMENT </TITLE>
<AUTHOR>   MARSDEN, GARY COLT </AUTHOR>
<YEAR>   1993 </YEAR>
<INSTITUTION>   UNIVERSITY OF CALIFORNIA, SAN DIEGO; 0033 </INSTITUTION>
<DESCRIPTORS>   ENGINEERING, ELECTRONICS AND ELECTRICAL; PHYSICS, OPTICS; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER>   SADIK C. ESENER; SING H. LEE </ADVISER>
<CLASSIFICATIONS>   NIL </CLASSIFICATIONS>
<ABSTRACT>
Many computational problems in machine intelligence and
database management can be solved using simple array
manipulations which are similar to those of linear
algebra. The regularity of these operations allows
efficient parallel algorithms to be executed on array
processors, thereby satisfying demands for increased
throughput. A progression of increasingly complex
parallel array architectures is presented. Algorithms
which exploit the properties of these architectures are
presented for various applications. Both conventional
and novel neural learning algorithms are mapped onto
these architectures. Mathematical reductions of fuzzy
inference mechanisms to simple vector operations are
presented which allow extremely efficient parallel
computations on array architectures. Algorithms which
use outer product operations are presented for
constraint satisfaction problems. Intelligent secondary
storage interfaces based on the array architectures are
shown to provide data reduction for relational database
applications by executing a portion of the database
query directly at the interface. Several optoelectronic
array processor designs are described which allow
efficient implementations of the array architectures. By
introducing optical interconnections, area and delay
penalties associated with very-large-scale-integration
(VLSI) electronic systems are diminished, since the
optoelectronic layout topologies are determined by
various optical interconnection strategies rather than
by planar wiring requirements. Several simple optical
systems are presented and experimentally demonstrated.
In particular, the optical transpose interconnection
system is shown to support several array architectures.
The advantages of optically interconnected array
processors are shown to be significant for large array
dimensions due to the fundamental incompatibility
between these arrays and the planar nature of VLSI
systems. Optoelectronic technologies which support
optically interconnected array processors are analyzed
according to their effects on system performance.
Optimal operational configurations of PLZT and multiple-
quantum-well modulators are derived. Multiple-quantum
well modulators are shown to have limited fan-out
capabilities due to saturation effects. Future research
directions for optical interconnections and
optoelectronic array processors are also postulated.
</ABSTRACT>
</THESIS>
<THESIS>
<NUMBER> 4513 </NUMBER>
<ORDER>   AAG9431531 </ORDER>
<TITLE>   A KNOWLEDGE-BASED APPROACH FOR PREDICTING THE INTERNAL STRUCTURE OF OBJECTS WITH TWO-LEVEL CASE-BASED REASONING </TITLE>
<AUTHOR>   LENG, BING </AUTHOR>
<YEAR>   1993 </YEAR>
<INSTITUTION>   UNIVERSITY OF PITTSBURGH; 0178 </INSTITUTION>
<DESCRIPTORS>   COMPUTER SCIENCE; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER>   NIL </ADVISER>
<CLASSIFICATIONS>   NIL </CLASSIFICATIONS>
<ABSTRACT>
For a class of real-world labeling problems, a complex
object to be identified is formed of units (its internal
structures) that are locally ambiguous--they can have
one of several possible labels. This causes difficulty
for both the Rule-Based Learning systems, due to
inadequate concept description languages resulting from
weak domain theories, and most of Case-Based Reasoning
systems, because they either treat an object as a single
case or treat units as independent cases. Protein
secondary structure prediction is one such problem and
is the example used in this work.
This thesis addresses the following question: can we
make use of context information expressed in the form of
neighboring units, in order to assign to each unit a
label such that the object as a whole is labeled
consistently or makes global sense?
A general Two-Level, Case-Based Reasoning framework is
proposed. In particular, a Two-Level, Case-Based
Reasoner is designed and implemented, which uses context
information, domain knowledge, and evidence-gathering
techniques to predict the internal structure of objects.
The method is evaluated along three dimensions:
predictive accuracy, computational efficiency, and error
tolerance. The evaluation results show that the program
performs better than previous techniques and is
efficient and robust. A detailed analysis reveals how
each part of the method contributes to its performance.
In addition, this thesis shows that machine learning can
contribute to the effectiveness of a Case-Based Reasoner
by using a training set of examples to initialize the
program.
The method has also been tested on an artificial domain
that captures the common characteristics of the problems
in the class defined above. The experimental results
provide evidence that the method is generalizable to the
whole class.
</ABSTRACT>
</THESIS>
<THESIS>
<NUMBER> 4514 </NUMBER>
<ORDER>   AAG9430899 </ORDER>
<TITLE>   CONCURRENT INFORMATION PROCESSING WITH PATTERN RECOGNITION APPLICATIONS </TITLE>
<AUTHOR>   HU, YALIN </AUTHOR>
<YEAR>   1993 </YEAR>
<INSTITUTION>   UNIVERSITY OF SOUTH CAROLINA; 0202 </INSTITUTION>
<DESCRIPTORS>   COMPUTER SCIENCE; ENGINEERING, ELECTRONICS AND ELECTRICAL </DESCRIPTORS>
<ADVISER>   ROBERT J. JANNARONE </ADVISER>
<CLASSIFICATIONS>   NEURAL NETWORKS </CLASSIFICATIONS>
<ABSTRACT>
Artificial Neural Networks (ANNs) represent a new
approach to artificial intelligence, but ANN training
algorithms create concurrent operation bottlenecks. Some
popular conventional training algorithms such as back-
propagation have been used in a wide variety of
applications, but they are criticized as being
biologically implausible, they also suffer from slow
convergence and lack of robustness, and they are not
suitable for on-line operation.
In this dissertation, a concurrent information
processing (CIP) model is provided as an alternative to
conventional neurocomputing. Contrasts between the CIP
approach and the conventional approach are discussed for
a pattern recognition problem in a concurrent learning
context. Results indicate that CIP learning per trial
can range from 10$sp3$ to 10$sp5$ times faster than
backpropagation learning per trial. The CIP model is
based on massively parallel implementation of a
multiplicative regression model for pattern completion,
with provisions for "easy Bayes" response and
learning. The CIP model can transform input measurement
values to linear or nonlinear feature values, use the
feature values to update parameter values, and impute
missing measurement values as quickly as incoming
measurements arrive.
The key feature of CIP systems is their ability to learn
computing relationships automatically and concurrently.
Other useful features include available sequential
software that can process incoming records at fairly
fast rates; available parallel functions that can
process records at very fast rates; provisions for
concurrent learning, missing value imputing, and
measurement deviance monitoring; and provisions for
occasional model refinement and interpretation.
Optimal model refinement is important because it
maximizes CIP speed and accuracy when memory
specifications are fixed, and it minimizes memory
requirements when speed and accuracy specifications are
fixed. CIP refinement must be fast as well as optimal,
because it must precede optimal CIP operation. Results
indicate that optimal models can be quickly identified
that produce comparable correct classification rates to
full-scale models for a pattern recognition problem, but
much more quickly and compactly. CIP fast model
refinement procedures include a feature joining method,
a feature pruning method, and a feature grafting method.
CIP joining methods can quickly cluster features that
are redundant, CIP pruning methods can quickly exclude
features that are not necessary, and CIP grafting
methods can introduce higher-order features that may
improve operational accuracy.
The CIP kernel (CIPK) algorithm involves several large
matrix and vector operations. A hypercube implementation
of the CIPK algorithm is also described in this
dissertation. The parallel CIPK algorithm reduces the
computing time for these operations and reduces host
computer memory requirement, allowing large problems to
be treated. Implementation details and a parallel CIPK
formulation are given; benchmarks for computing times
are provided indicating that the parallel CIPK algorithm
is highly efficient; and processing times are obtained
to indicate that CIP system performance improved if
optimal architecture can be implemented.
</ABSTRACT>
</THESIS>
<THESIS>
<NUMBER> 4515 </NUMBER>
<ORDER>   AAG9430653 </ORDER>
<TITLE>   EXPERT SYSTEMS APPROACH TO REGIONAL EVALUATION OF DEBRIS FLOW HAZARD </TITLE>
<AUTHOR>   ROGERS, CASSANDRA THEODORA </AUTHOR>
<YEAR>   1993 </YEAR>
<INSTITUTION>   UNIVERSITY OF CALIFORNIA, BERKELEY; 0028 </INSTITUTION>
<DESCRIPTORS>   ENGINEERING, CIVIL; GEOLOGY; GEOTECHNOLOGY; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER>   NICHOLAS SITAR; ALICE A. AGOGINO </ADVISER>
<CLASSIFICATIONS>   NIL </CLASSIFICATIONS>
<ABSTRACT>
Conventional methods for debris flow hazard assessment
typically utilize either subjective or objective
techniques to evaluate debris flows on a regional level.
In this research, a knowledge-based database management
system has been developed, which automates a regional
evaluation of debris flow hazard similar to that which
is performed by an experienced engineering geologist or
geotechnical engineer.
The program developed here automates a wide range of
sequential knowledge-based processing tasks, ranging
from data input, database creation and data reduction,
to statistical computations, plotting and map
generation. Two unique features of the system are (a)
its ability to include the user in the decision-making
process and (b) flexibility to perform selective
processing of data by user.
The approach presented here combines expert opinion with
empirical data. Expert opinion was acquired from the
literature and from experts in the form of a factor
model of debris flow occurrence, and ratings associating
the relative importance of individual factors and factor
classes. Independent of the expert-derived data,
statistical analyses of the sample data are conducted to
determine similar relative importance of factor classes,
based on the sample data, and in addition, sensitivity
analyses are used to identify the relative importance of
the model factors. These two distinct data sources are
then combined to derive a qualitative measure of debris
flow hazard.
The methodology was tested on a study area underlain by
granitic rocks, using 30-meter and 10-meter grids. The
relationships between debris flow occurrence and six
factors: slope gradient, slope aspect, slope plan
curvature, slope profile curvature, upstream drainage
area and colluvium thickness were analyzed. These
analyses indicate that, of the two grids, the 10-meter
data is required in order to identify the controlling
terrain characteristics. Based on the 10-meter data set,
the most susceptible sites have slope gradients ranging
between 22$spcirc$ and 39$spcirc$, are plan-
concave:profile-concave in configuration, occur at ridge-
hillslope transitions and are oriented northeast to
south southeast. Confident conclusions cannot be made as
to the relationship between colluvium thickness and
debris flow occurrence.
In addition, the data also indicate that some planar
slopes have debris flow likelihoods as high as
calculated for hollow locations, and highlight the
probable influence of non-topographic factors, such as
geologic structure, in controlling debris flow
occurrence. Of the seven factors examined, plan
curvature, upstream drainage area and slope gradient
were identified as the most critical, in that relative
order. These results agree well with our physical
understanding of debris flow occurrence. On this basis,
the methodology developed here appears to be suitable
for regional evaluation of debris flows.
</ABSTRACT>
</THESIS>
<THESIS>
<NUMBER> 4516 </NUMBER>
<ORDER>   AAGNN88447 </ORDER>
<TITLE>   FORMALIZED DECISION-SUPPORT FOR CARDIOVASCULAR INTENSIVE CARE </TITLE>
<AUTHOR>   LAU, FRANCIS YIN YEE </AUTHOR>
<YEAR>   1993 </YEAR>
<INSTITUTION>   UNIVERSITY OF ALBERTA (CANADA); 0351 </INSTITUTION>
<DESCRIPTORS>   HEALTH SCIENCES, MEDICINE AND SURGERY; ENGINEERING, SYSTEM SCIENCE; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER>   DON FENNA </ADVISER>
<CLASSIFICATIONS>   NIL </CLASSIFICATIONS>
<ABSTRACT>
Despite the plethora of electronic devices and
monitoring systems that exists today in the
Cardiovascular Intensive Care Unit (CVICU), most
hemodynamic management decisions are still intuitive and
manually driven. Unfortunately, the massive volume of
physiologic data from these post-operative cardiac
patients can create information overload, impairing
effective decision-making. At the same time, practice
variations among CVICU physicians have rendered it
difficult to assess the effectiveness of the therapeutic
interventions.
This dissertation describes the development and
validation of a decision-support system prototype that
can help manage hypotension associated with hypovolemia
in CVICU patients. The hypothesis was: expertise in
hemodynamic management can be formalized as computer-
based protocols that can provide therapeutic
recommendations significantly more consistent with
clinical management goals than occurs with current
practice. Limited resources constrained the research to
hypovolemic-hypotension, and to retrospective analysis
of historical cases, also to modeling rather than a real-
time system.
The prototype uses physiologic pattern-matching,
therapeutic protocols, computational drug-dosage
response modeling and expert reasoning heuristics in the
selection of intervention strategies and choices. The
protocols were formalized through consensus by four
expert CVICU physicians. Other knowledge sources were
textbooks and detailed critical review by two of the
physicians of 13 historical CVICU cases with 410
interventions. The prototype used a monitoring approach,
simulating real-time operation by processing the
historical physiologic and intervention data on a
patient sequentially, generating alerts on questionable
data, critiques of interventions instituted and
recommendations on preferred interventions. Bench-
testing used another 13 historical cases with 399
interventions, each case critically reviewed to identify
the preferred interventions reflective of clinical
management goals. The testing, applied equally to the
prototype's proposals and to the actual history, showed
the therapies for bleeding and fluid replacement
proposed by the prototype were significantly better (p
$<$ 0.0001) than those as instituted by the staff
(80% consistent versus 44%, respectively).
This study has demonstrated the feasibility of
formalizing hemodynamic management of CVICU patients in
a manner that may be implemented in a clinical setting.
The introduction of this type of computer-based decision-
support tool is timely, as there has been an increasing
effort from the medical community to establish standards
for the delivery and assessment of patient care to
improve its quality and outcome. Such effort can be
aided by this type of system, which can provide the
necessary patient data and practice guidelines to
conduct formal scientific evaluations in a systematic
fashion.
</ABSTRACT>
</THESIS>
<THESIS>
<NUMBER> 4517 </NUMBER>
<ORDER>   AAG9431913 </ORDER>
<TITLE>   ADAPTIVE, DISTRIBUTED DECISION SUPPORT USING GENETIC LEARNING: APPLICATION TO A PRODUCTION SCHEDULING ENVIRONMENT </TITLE>
<AUTHOR>   BHATTACHARYYA, SIDDHARTHA </AUTHOR>
<YEAR>   1993 </YEAR>
<INSTITUTION>   UNIVERSITY OF FLORIDA; 0070 </INSTITUTION>
<DESCRIPTORS>   BUSINESS ADMINISTRATION, GENERAL; COMPUTER SCIENCE; INFORMATION SCIENCE </DESCRIPTORS>
<ADVISER>   GARY J. KOEHLER </ADVISER>
<CLASSIFICATIONS>   GENETIC ALGORITHMS </CLASSIFICATIONS>
<ABSTRACT>
Scheduling is a crucial activity in a manufacturing
system. With traditional approaches, applications of
optimization techniques to a mathematical formulation of
the problem have proven to be intractable even for many
idealized situations; thus, a variety of Artificial
Intelligence (AI) approaches have been proposed for
effective production scheduling. These techniques too,
however, have felt the limitations imposed by the lack
of adequate means to acquire the requisite knowledge.
This knowledge acquisition bottleneck is further
aggravated by the complexity of the production
scheduling environment and the lack of reliable human
experts from whom to glean the required knowledge--
hence, the need for the development of machine learning
schemes to aid in production scheduling.
Genetic algorithms (GAs) provide a stochastic search
strategy based on principles of biological evolution and
are noted to be specially suited for application to
complex, poorly understood search spaces. A framework
for utilizing genetic algorithm based learning in
typical decentralized factory-floor decision making
environments is presented. A high level knowledge
representation scheme for modelling the production
environment is developed, with facilities for genetic
learning within this scheme. Experimental results from
job shop simulations considering initial stages of a
semiconductor manufacturing line demonstrate the
feasibility of the designed approach and provide
insights for future enhancements.
A second part of this research focusses on the
theoretical analysis of genetic algorithms. Most
theoretical studies on GAs consider binary encodings of
the search space, and the fundamental principle of
minimal alphabets suggests the optimality of binary over
higher cardinality representations for genetic
processing. A growing number of successful applications
using higher level representations, however, present a
potential conflict between theory and practice.
This research undertakes a generalization of a recent
model of binary GAs, providing a detailed
characterization of their search behavior, to higher
cardinality alphabets. Walsh functions have been widely
used in studying binary GAs, and a generalization of the
Walsh matrix terms to consider higher cardinality
representations is obtained. This, and other identities
derived in the analysis, provide useful results for
further studies of nonbinary GAs.
</ABSTRACT>
</THESIS>
<THESIS>
<NUMBER> 4518 </NUMBER>
<ORDER>   AAG9431909 </ORDER>
<TITLE>   A DECISION SUPPORT SYSTEM FOR DYNAMIC SCHEDULING: PRACTICE AND THEORY </TITLE>
<AUTHOR>   AYTUG, HALDUN </AUTHOR>
<YEAR>   1993 </YEAR>
<INSTITUTION>   UNIVERSITY OF FLORIDA; 0070 </INSTITUTION>
<DESCRIPTORS>   BUSINESS ADMINISTRATION, GENERAL; INFORMATION SCIENCE; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER>   GARY J. KOEHLER </ADVISER>
<CLASSIFICATIONS>   GENETIC ALGORITHMS </CLASSIFICATIONS>
<ABSTRACT>
Knowledge acquisition is a major bottleneck in
successfully implementing an Expert System in a
production environment. Moreover, it is very
questionable that a domain expert exists in this domain,
due to the dynamic and complex nature of the
environment. Knowledge base update is another problem
with the Expert System approaches for the scheduling
domain since some production environments are subject to
frequent changes making the existing knowledge base
obsolete. A remedy to the knowledge acquisition and
update problems is using "Machine Learning"
approaches. This reduces the dependence on a human
expert and automates the knowledge acquisition and
update processes.
In this research we motivate the need for using machine
learning techniques for artificial-intelligence-based
production scheduling systems and demonstrate how a
classifier system/genetic algorithm hybrid approach can
be used to generate an acceptable knowledge base. Due to
their continuous feedback control mechanisms, classifier
systems are very appropriate for updating knowledge
bases when the environment is changing. We have
developed a learning system that is integrated with a
simulation environment (developed in C++) which supports
inference. A rule language supportive of the genetic
search operators used by the system has been developed.
Two subsystems, the "learning subsystem" and
the "task subsystem" interact throughout the
"knowledge construction" process. The learning
subsystem evaluates the performance of the task
subsystem after every learning episode and generates an
expectedly better knowledge base for the task subsystem
to use in the next learning episode. This procedure
stops after a reasonable knowledge base is constructed.
The theoretical part of this research involves
developing a worst case bound on the number of learning
episodes the system has to perform before stopping with
a well performing knowledge base. This is equivalent to
developing a stopping criteria for genetic algorithms
since classifier systems use genetic algorithms to
search for new rules. To date there has been no series
attempt to develop a stopping criteria for Genetic
Algorithms. We have developed an upper bound on the
number of iterations a GA has to execute to assure
seeing an optimal solution with a specified confidence
level by using the concept of first passage times of a
Markov Chain. For a given string length, we have also
found the optimal number of iterations necessary before
stopping.
</ABSTRACT>
</THESIS>
<THESIS>
<NUMBER> 4519 </NUMBER>
<ORDER>   AAG9430725 </ORDER>
<TITLE>   THE STRUCTURE OF RUSSIAN CONVERSATION: LANGUE OR PAROLE? </TITLE>
<AUTHOR>   VAN DOREN, FREDERICK LITTLE </AUTHOR>
<YEAR>   1993 </YEAR>
<INSTITUTION>   UNIVERSITY OF CALIFORNIA, BERKELEY; 0028 </INSTITUTION>
<DESCRIPTORS>   LANGUAGE, LINGUISTICS; SPEECH COMMUNICATION </DESCRIPTORS>
<ADVISER>   BORIS M. GASPAROV </ADVISER>
<CLASSIFICATIONS>   COLLOQUIAL, DISCOURSE </CLASSIFICATIONS>
<ABSTRACT>
The goal of this work is to present a model of Russian
conversational discourse that will help explain some of
the systematic differences between Contemporary Standard
Russian (CSR) and Russian colloquial speech (RR). The
structure of Russian dialogue is examined through the
analysis of transcribed conversation, level by level,
using a variety of theoretical frameworks proposed for
English and artificial intelligence. The aim is to
determine how much systematicity prevails at each
structural level, how it is encoded and recognized, and
how it can account for certain features or colloquial
speech. For if a discourse model can account for the
communicative adequacy or forms and locutions
unacceptable in CSR through alternative, compensatory
sources of meaning, and if this compensation is
sufficiently regular, then the rules and tendencies that
shape utterances in dialogue can be considered part of
the system of the language, langue, while the non-
canonical output itself is parole. By expanding the
traditional boundaries of langue, much of the apparent
non-grammaticality of RR can be explained as loosely
predictable, contextually conditioned variation of CSR.
The body of the work is in three parts, each devoted to
a separate analytical level. Part I explores the
adjacency pair as a minimal unit of dialogic text
through a study of question-answer pairs, and presents a
hearer-based model of discourse processing that
integrates lexico-syntactic, pragmatic, interactive and
social knowledge.
Part II explores how cohesion marks linear and non-
linear connections in conversational text, and how it
can account for problems or reference, ellipsis and
substitution. The operation of anaphora, inexplicable by
grammatical rules alone, is shown to depend, in part, on
consituation, background knowledge and the norms of
conversational discourse.
Part III is devoted to the broader issue of textual
coherence, exemplified by cohesion, but defined by
semantic, propositional, pragmatic and dynamic macro-
structures that include topic, rhetoric and
interpersonal goals. The composite model is presented in
full and evaluated in the Conclusion to the work.
</ABSTRACT>
</THESIS>
<THESIS>
<NUMBER> 4520 </NUMBER>
<ORDER>   AAGMM87780 </ORDER>
<TITLE>   DEVELOPMENT AND EVALUATION OF AN EXPERT MONITORING SYSTEM FOR AN ICU </TITLE>
<AUTHOR>   LAM, ANDREW KIN FAI </AUTHOR>
<YEAR>   1993 </YEAR>
<INSTITUTION>   MCGILL UNIVERSITY (CANADA); 0781 </INSTITUTION>
<DESCRIPTORS>   ENGINEERING, ELECTRONICS AND ELECTRICAL; ENGINEERING, BIOMEDICAL; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER>   A. MALOWANY </ADVISER>
<CLASSIFICATIONS>   NIL </CLASSIFICATIONS>
<ABSTRACT>
This thesis presents the development and evaluation of a
real-time monitoring and warning expert system developed
for the patient data management system (PDMS) of the
Pediatric Intensive Care Unit of the Montreal Children's
Hospital. The principal objective of the Expert
Monitoring System (EMS) is to provide basic
physiological trend analysis and interpretation and
generate warnings in the event of critical patient
conditions.
The thesis begins with a literature survey of the impact
of patient data management systems, the attitudes of
medical professionals toward computerization, as well as
the needs, the difficulties and the methodologies of
evaluation. This is followed by an overview of the
system. The design and the implementation of the EMS are
described. An evaluation scheme for the EMS and some
results are presented. Future improvements of the EMS
are discussed before the conclusion.
</ABSTRACT>
</THESIS>
<THESIS>
<NUMBER> 4521 </NUMBER>
<ORDER>   AAGMM87758 </ORDER>
<TITLE>   A PROBABILISTIC MIN-MAX TREE </TITLE>
<AUTHOR>   KAMOUN, OLIVIER </AUTHOR>
<YEAR>   1993 </YEAR>
<INSTITUTION>   MCGILL UNIVERSITY (CANADA); 0781 </INSTITUTION>
<DESCRIPTORS>   COMPUTER SCIENCE; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER>   LUC DEVROYE </ADVISER>
<CLASSIFICATIONS>   NIL </CLASSIFICATIONS>
<ABSTRACT>
MIN-MAX trees have been studied for thirty years as
models of game trees in artificial intelligence. Judea
Pearl introduced a popular probabilistic model that
assigns random independent and identically distributed
values to the leaves. Among the dependent models,
incremental models assume that terminal values are
computed as sums of edge values on the path from the
root to a leaf. We study a special case called the scSUM
model where the edge values follow a Bernoulli
distribution with mean p. Let $Vsb{n}$ be the root's
value of a complete b-ary, n-level scSUM tree. We prove
the E$Vsb{n}$/n tends to a uniformly continuous function
${cal V}(p)$. Surprisingly, ${cal V}(p)$ is very
nonlinear and has some flat parts. More formally, for
all b, there exist $alpha,beta in$ (0, 1) such
that,$$cases{${rm if}
pinlbrack0,alpharbrack$&:E$Vsb{n}$ has a finite
limitcr ${rm if} pinlbrack1-alpha,1rbrack$&:$n-{rm
E}Vsb{n}$ has a finite limitcr ${rm if} pinlbrackbeta,1-
betarbrack$&:E$Vsb{n}/n$ tends to 1/2cr}$$Finally
$beta$ and $alpha$ tend to zero when b tends to
infinity.
</ABSTRACT>
</THESIS>
<THESIS>
<NUMBER> 4522 </NUMBER>
<ORDER>   AAGMM87376 </ORDER>
<TITLE>   IMPROVING EXPLANATION FACILITIES IN EXPERT SYSTEMS </TITLE>
<AUTHOR>   BUI, HIEN MY </AUTHOR>
<YEAR>   1993 </YEAR>
<INSTITUTION>   UNIVERSITY OF WINDSOR (CANADA); 0115 </INSTITUTION>
<DESCRIPTORS>   COMPUTER SCIENCE; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER>   J. MORRISSEY </ADVISER>
<CLASSIFICATIONS>   NIL </CLASSIFICATIONS>
<ABSTRACT>
One of the important features of expert systems is to
provide explanations suitable to the user's needs. Thus
it is desirable to construct an expert system which can
flexibly give explanations to different levels of users.
Many existing expert systems are only designed for one
type of user. In this work, using the Designer's
Assistant system as the platform, we build up the user
modelling and text retrieval components so that the
system can adapt to different levels of the user's
expertise. In the implementation, a model is built for
each user using the system based on his/her expertise,
goals, needs, etc. Text documentation is retrieved for a
particular user based on his/her model and is used as
explanations. The result is that different explanations
are provided for different users, depending on their
needs.
</ABSTRACT>
</THESIS>
<THESIS>
<NUMBER> 4523 </NUMBER>
<ORDER>   AAGMM87296 </ORDER>
<TITLE>   A MULTI-EXPERT SYSTEM FOR CLASSIFYING UNCONSTRAINED HANDWRITTEN NUMERALS </TITLE>
<AUTHOR>   ADEL, SAM </AUTHOR>
<YEAR>   1993 </YEAR>
<INSTITUTION>   CONCORDIA UNIVERSITY (CANADA); 0228 </INSTITUTION>
<DESCRIPTORS>   COMPUTER SCIENCE; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER>   C. Y. SUEN </ADVISER>
<CLASSIFICATIONS>   NIL </CLASSIFICATIONS>
<ABSTRACT>
There are infinite styles of handwriting and humans have
no problem reading and recognizing them. Until now,
computers using mathematical models have failed to match
human performance in classifying handwritten characters.
Classification of handwritten characters becomes
especially difficult when computers are faced with
confusing characters.
This thesis describes and analyses the design,
implementation and testing of a new character
recognition system for the recognition of unconstrained
handwritten numerals. The system models and uses
multiple human expertise in this field and focuses on
the recognition of confusing cases of handwritten
numerals.
Test results of this numeral recognition system indicate
that the system maintained low substitution rates with
different data sets and consistently improved on its
recognition rate by further training. Also that, in
spite of the limitations of its knowledge base (in terms
of scope and quality), its performance is comparable to
that of some complete recognition systems which do not
use human expertise. In the 'Conclusion' section of this
thesis there are suggestions for improving knowledge
acquisition and implementation of the system. The
suggested improvements should enhance the system
significantly so that its performance will approach that
of humans'.
This system differs from other recognition systems in
the way it handles and uses human knowledge in this
field and its original method of defining and grouping
subclasses of numerals. These alone or the system as a
whole might have an effect on the future direction in
this area.
</ABSTRACT>
</THESIS>
<THESIS>
<NUMBER> 4524 </NUMBER>
<ORDER>   AAGMM87288 </ORDER>
<TITLE>   A METHOD FOR SEGMENTATION OF TOUCHING HANDWRITTEN NUMERALS </TITLE>
<AUTHOR>   STRATHY, NICHOLAS W. </AUTHOR>
<YEAR>   1993 </YEAR>
<INSTITUTION>   CONCORDIA UNIVERSITY (CANADA); 0228 </INSTITUTION>
<DESCRIPTORS>   COMPUTER SCIENCE; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER>   NIL </ADVISER>
<CLASSIFICATIONS>   NIL </CLASSIFICATIONS>
<ABSTRACT>
A method of separating the leftmost numeral from a
string of touching unconstrained handwritten arabic
numerals is proposed. A binary image containing a string
of touching numerals is scanned to give contour chains.
The chains are analysed and subdivided into four kinds
of regions: valleys, mountains, holes, and open regions.
Individual points of interest in the outer contour are
then identified, e.g., points of high curvature, and
other points which have been shown to be significant for
performing perceptual grouping of objects in scenes. The
separating path is assumed to pass between some pair of
these significant contour points (SCPs). To find that
pair, 9 features of the SCPs are measured and are used
to sort the list of all possible pairings of SCPs. As
with other segmentation methods, the output of this
system is a short list of segmentation hypotheses sorted
in order of confidence. Test results show that the
correct cut is sorted within the first 3 choices in
89.5% of samples, and within the first 5 choices in
96.3% of samples. The total number of test images is 946
divided between 3 different sets. The system is
trainable, something not seen in any other digit
separation system in the literature. Training was done
on a completely different set of 212 images.
</ABSTRACT>
</THESIS>
<THESIS>
<NUMBER> 4525 </NUMBER>
<ORDER>   AAGC376136 </ORDER>
<TITLE>   THE APPLICATION OF NEURAL NETWORKS TO IMAGING AND SIGNAL PROCESSING IN ASTRONOMY AND MEDICINE </TITLE>
<AUTHOR>   MILLER, ADRIAN STEVENSON </AUTHOR>
<YEAR>   1993 </YEAR>
<INSTITUTION>   UNIVERSITY OF SOUTHAMPTON (UNITED KINGDOM); 5036 </INSTITUTION>
<DESCRIPTORS>   COMPUTER SCIENCE </DESCRIPTORS>
<ADVISER>   NIL </ADVISER>
<CLASSIFICATIONS>   NIL </CLASSIFICATIONS>
<ABSTRACT>
The growing use of computer technology throughout
astronomy and medicine, as well as other fields of
scientific research, has led to greatly increased rates
of data acquisition. The advent of the computer also
gave birth to the new research field of Artificial
Intelligence (AI). AI techniques may allow the
construction of intelligent filtering systems, to reduce
the amount of acquired data which must be stored, and
allow the vast quantities of scientific data already
stored on computer to be analysed without the need for
human intervention. The resurgence of neural networks
within AI research is driven in part by their ability to
solve image and signal recognition problems, two areas
where AI's rule-based systems have performed poorly.
Neural networks also have the ability to learn by
example and generalise, allowing them to be trained on a
representative set of examples for a given problem.
Neural nets have been applied to the problems of
star/galaxy classification of telescope survey plates.
Classification rates in excess of 90% for both stars and
galaxies have been obtained to a limiting B-magnitude of
20. Event selection on the INTEGRAL $gamma$-ray
satellite, using both neural networks and rule
generation systems, has shown that signal (photons which
passed through the mask) and background (photons which
did not) events cannot be separated using a statistical
classifier. Finally the use of neural networks for
electrical impedance tomographic image characterisation
is considered. The network is shown to be able to
characterise simulated images but this property does not
extend to real images. Further clinical validation is
required in order to improve the image data available
for training the network.
</ABSTRACT>
</THESIS>
<THESIS>
<NUMBER> 4526 </NUMBER>
<ORDER>   AAGC372819 </ORDER>
<TITLE>   COMPUTER AIDS FOR THE SAFE DESIGN AND OPERATION OF CHEMICAL PLANTS </TITLE>
<AUTHOR>   JOURNET, CHRISTOPHE EMILE </AUTHOR>
<YEAR>   1993 </YEAR>
<INSTITUTION>   UNIVERSITY OF BATH (UNITED KINGDOM); 0690 </INSTITUTION>
<DESCRIPTORS>   ENGINEERING, CHEMICAL BATH, AVON BA2 7AY, ENGLAND </DESCRIPTORS>
<ADVISER>   NIL </ADVISER>
<CLASSIFICATIONS>   NIL </CLASSIFICATIONS>
<ABSTRACT>
The traditional approach to safety in the process
industries has been mainly concerned with the detailed
process design and the operation. Hazards are
identified, methods are developed and equipment
installed to control these hazards, leading to
extrinsically safe plants. An alternative solution is to
consider safety as an integral part through all stages
of the life of a plant. In this project computer aids
for enhancing safety in the process industries have been
developed for two groups of personnel: process operators
and process engineers.
A computer-based training programme (CBT) has been
developed to promote the safe operation of processes by
operators. The aim of the CBT is to instruct operators
in fundamental safety matters. The CBT is a tutorial
with two main topics: (a) the safe practice during
maintenance and (b) fire and explosion. A series of
questions helps to assess and monitor the student's
understanding of the topics. The CBT has been
implemented on a small scale for validation, and the
trainees have found it useful and attractive.
A prototype knowledge-based system (KBS) has been
developed to assist process designers in eliminating or
reducing, as far as reasonably practicable, hazards at
the very initial stages of the design. This approach is
aimed at designing inherently safer chemical plants. A
multi-level hazard assessment has been defined to
identify and manage hazards at each stage of the design,
from the inception to detailed flowsheeting. This new
approach adapts and extends the traditional Preliminary
Hazard Analysis (PHA) to the early stages of the
synthesis. This hazard assessment has been implemented
using the capabilities of artificial intelligence. The
KBS makes use of a combination of object-orientated
programming to describe the chemical process (chemicals,
reactions and units), and rule-based programming to
embody the knowledge of the safety experts. The KBS has
been validated using examples of industrial accidents.
It has proved successful in finding hazards and in
directing the process design towards inherent safety.
</ABSTRACT>
</THESIS>
<THESIS>
<NUMBER> 4527 </NUMBER>
<ORDER>   AAGC370915 </ORDER>
<TITLE>   AN EXPERT SYSTEM FOR MMIC AMPLIFIER DESIGN </TITLE>
<AUTHOR>   PARKS, GILLIAN </AUTHOR>
<YEAR>   1993 </YEAR>
<INSTITUTION>   QUEEN'S UNIVERSITY OF BELFAST (NORTHERN IRELAND); 0725 </INSTITUTION>
<DESCRIPTORS>   ENGINEERING, ELECTRONICS AND ELECTRICAL </DESCRIPTORS>
<ADVISER>   NIL </ADVISER>
<CLASSIFICATIONS>   NIL </CLASSIFICATIONS>
<ABSTRACT>
Computed-Aided-Design (CAD) tools are playing an
increasingly important role in the design of microwave
circuits, with commercial software vendors such as
EEsof$rmsp{TM}$, Compact$rmsp{TM}$, and Hewlett-
Packard$rmsp{TM}$ addressing procedural design steps
such as circuit simulation and optimisation. While these
systems continue to develop and mature, current research
is now shifting away from this traditional numerical
computation towards the design of computer systems which
exhibit characteristics associated with intelligence in
human behaviour.
This work investigates the use of Artificial
Intelligence (AI) techniques to assist in the design of
Monolithic Microwave Integrated Circuits (MMICs). An
Intelligent-Knowledge-Based System (IKBS) has been
developed which assists in the initial stages of the
design of microwave amplifiers. This consultant-type
expert system combines established design techniques
with heuristics and rules of thumb to select an
appropriate topology and FET for the amplifier circuit.
Choice of circuit topology for the amplifier is made
from the reactive, lossy, feedback and distributed
circuits, and active devices manufactured under the GEC-
Marconi F20 Process are considered.
The thesis describes the key elements in the development
of the amplifier design assistant, focusing on
acquisition, representation and manipulation of the
domain knowledge. Operation of the design assistant is
illustrated through a number of design examples, and the
system recommendations are verified by circuit
simulation.
This development has demonstrated the potential of
knowledge based systems for the complex domain of
microwave circuit design, and has provided a framework
which could subsequently be extended for other areas
such as oscillator and filter design. An approach for
integrating this expert system with commercial microwave
design software is also discussed, the ultimate
objective being to create a unified environment for
automation of the complete MMIC design process.
</ABSTRACT>
</THESIS>
<THESIS>
<NUMBER> 4528 </NUMBER>
<ORDER>   AAGC370324 </ORDER>
<TITLE>   TEMPORAL REASONING AND DATA BASES </TITLE>
<AUTHOR>   ORCI, TERTTU </AUTHOR>
<YEAR>   1993 </YEAR>
<INSTITUTION>   KUNGLIGA TEKNISKA HOGSKOLAN (SWEDEN); 1022 </INSTITUTION>
<DESCRIPTORS>   COMPUTER SCIENCE SWEDEN </DESCRIPTORS>
<ADVISER>   NIL </ADVISER>
<CLASSIFICATIONS>   NIL </CLASSIFICATIONS>
<ABSTRACT>
Temporal reasoning is reasoning about time and
temporally-related phenomena, an everyday activity,
which anyone seems to handle with success. Nevertheless,
it is a question which has occupied philosophers since
ancient times.
In computer science, the primary goal of the study of
temporal reasoning is to find computationally efficient
methods, based on formal temporal logics. Temporal
reasoning is applicable to several areas of computer
science, e.g. artificial intelligence, programming
methodologies, and data bases.
This thesis consists of two parts, each concerning a
different kind of temporal reasoning: Part I is a study
of temporal reasoning from an automated theorem-proving
perspective without any particular application area in
mind, while Part II is a study of temporal reasoning in
a specific application area, temporal deductive data
bases.
In Part I, a proof procedure for propositional modal
logic Q is presented. Modal logics are more general than
temporal logics in that modal logics may be interpreted
in several ways, e.g., temporally, spatially, or
epistemically. The proof procedure is based on clause
graph resolution, which differs from the traditional set-
based resolution in that it has certain built-in,
computation saving properties.
In Part II, a temporal logic for temporal deductive data
bases is presented. Temporal deductive data bases
possess a deductive capability and contain data over
time. The temporal logic is the basis for a temporal
logic programming language called TLOG, which has
constructs for both absolute and relative time and
thereby extends most of the existing temporal logic
programming languages. Three different models for
temporal deductive data bases are presented, each making
use of different subsets of TLOG for query and
representation of the logical rules in the data base.
For each of the models, both declarative and procedural
semantics are defined, laying a basis for further work
in query evaluation strategies.
</ABSTRACT>
</THESIS>
<THESIS>
<NUMBER> 4529 </NUMBER>
<ORDER>   AAG9424467 </ORDER>
<TITLE>   ENTROPY-BASED EVALUATION OF ADAPTIVELY CONSTRUCTED NEURAL NETWORKS </TITLE>
<AUTHOR>   ADELSBERGER-MANGAN, DAWN MARIE </AUTHOR>
<YEAR>   1993 </YEAR>
<INSTITUTION>   UNIVERSITY OF VIRGINIA; 0246 </INSTITUTION>
<DESCRIPTORS>   ENGINEERING, BIOMEDICAL; ENGINEERING, ELECTRONICS AND ELECTRICAL; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER>   WILLIAM B. LEVY </ADVISER>
<CLASSIFICATIONS>   NIL </CLASSIFICATIONS>
<ABSTRACT>
This research explores the role of adaptive processes in
constructing networks which perform successful
transformations on their inputs. Successful
transformations are characterized by the minimization of
two information measures: the information loss incurred
with the transformation and the output statistical
dependence. However, because the networks are
computational models of the dentate gyrus region of the
hippocampus, they must reflect the anatomy and
physiology of the region. The networks are composed of
binary neurons, connected by excitatory, feed-forward
synapses. Synaptic strengths are adjusted using an
expression inspired by long-term potentiation and
depression.
The first simulations explored the interaction of firing
threshold, synaptic connectivity, and input environment
statistical dependence, on the ability of networks with
fixed connectivity to create successful transformations.
Additionally, the utility of two adaptive process in
facilitating successful network transformation was
explored. The first process, associative weight
modification, adjusted the weights of the synaptic
connections. The second process, firing threshold
adjustment, modified the firing threshold of the output
neurons. The results of these simulations illustrated
the importance of maintaining appropriate levels of
output firing in creating successful transformations.
The next simulations eliminated the difficulties
encountered with fixed synaptic connectivity, and
incorporated the success of networks where the output
neurons fired 50% of the time. In these simulations a
synaptic connectivity was built that insured that each
output neuron fired approximately 50% of the time. The
synaptic connectivity was constructed using two
processes: synaptogenesis, which created new synaptic
connections; and associative synaptive modification,
which adjusted the weight of existing synapses.
Synaptogenesis produced additional innervation for each
output neuron until it fired approximately 50% of the
time. Associative modification of synapses lent
robustness to network construction by adjusting
suboptimal choices of initial synaptic weight. Networks
constructed using these two mechanisms preserved the
information content of a variety of inputs over a range
of firing thresholds.
Next, two additional mechanisms were incorported into
network construction. The first process, input neuron
avidity, regulated the tendency of an input neuron to
participate in the construction of new synapses. The
second process, selective synapse removal, eliminated
synapses between neurons with uncorrelated firing. The
simulations demonstrated that incorporating selective
synapse removal, when combined with a mechanism which
limited the tendency of the input neurons to participate
in synaptogenesis, resulted in increased output
representational information and reduced output
statistical dependence as compared to networks where
synapses were not removed and the ability of the input
neurons to create new synapses was not limited.
This research details a robust, "hands-off",
methodology for constructing biologically plausible
network architectures which are able to successfully
transform inputs. Additionally, the networks are
constructed using only information that is present
locally at the neurons and synapses. (Abstract shortened
by UMI.)
</ABSTRACT>
</THESIS>
<THESIS>
<NUMBER> 4530 </NUMBER>
<ORDER>   AAG9426690 </ORDER>
<TITLE>   A MODEL FOR COLLABORATIVE EXPERT REPRESENTATION OF AN ORGANIZATIONALLY CONSTRAINED INFORMATION SYSTEMS PLANNING PROBLEM WITHIN A MANAGEMENT SCIENCE FRAMEWORK </TITLE>
<AUTHOR>   GILBERT, GARY REED </AUTHOR>
<YEAR>   1993 </YEAR>
<INSTITUTION>   UNIVERSITY OF PITTSBURGH; 0178 </INSTITUTION>
<DESCRIPTORS>   BUSINESS ADMINISTRATION, MANAGEMENT; COMPUTER SCIENCE; OPERATIONS RESEARCH; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER>   NIL </ADVISER>
<CLASSIFICATIONS>   EXPERT SYSTEMS </CLASSIFICATIONS>
<ABSTRACT>
Availability of an expert can enhance the practical
utility of management science decision models for
planning. Experts more appropriately represent problems
for the models than non-experts. If one also
incorporates external planning guidance into problem
representations, the decisions produced will adhere to
that guidance without significantly restricting
planners' prerogatives. As a typical management science
model, the Analytical Hierarchy Process (AHP) has been
used in this research as the decision model for which an
Army hospital information systems planning problem must
be represented. A significant amount of external
planning guidance must be incorporated into the plan at
the local level for the plan to be approved by the Army
Health Services Command (HSC). I have modeled the
collective knowledge and the collaborative problem
solving process employed by a model expert and a domain
expert to represent a particular hospital's information
system planning problem as AHP hierarchies that
incorporate Command guidance. This model could be
implemented as an expert system capable of producing
hierarchies that could be used by Army hospital managers
with the AHP to prioritize and select information
systems planning initiatives for their hospitals. This
research contributes a new and useful model of
collaborative expertise that can represent
organizationally constrained planning problems for use
in decision models.
</ABSTRACT>
</THESIS>
<THESIS>
<NUMBER> 4531 </NUMBER>
<ORDER>   AAG9426418 </ORDER>
<TITLE>   PERFORMANCE EVALUATION OF INDUSTRIAL DEVELOPMENT IN DEVELOPING COUNTRIES: AN EXPERT SYSTEMS APPROACH </TITLE>
<AUTHOR>   NAKHLA, ROUSHDY AZIZ </AUTHOR>
<YEAR>   1993 </YEAR>
<INSTITUTION>   WEST VIRGINIA UNIVERSITY; 0256 </INSTITUTION>
<DESCRIPTORS>   ECONOMICS, GENERAL; COMPUTER SCIENCE; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER>   WAFIK H. ISKANDER </ADVISER>
<CLASSIFICATIONS>   NIL </CLASSIFICATIONS>
<ABSTRACT>
Industrialization is a fundamental objective for most
developing countries in their efforts to achieve
economic growth. However, simple quantitative increases
in industrial output or in total national income cannot
accurately measure other changes in the development
process such as attainment of social objectives,
technological advances, efficiency considerations, etc.
Assessing such measures can help planners in developing
countries to better formulate industrial policies, and
stimulate improvements in performance. It can also help
aid donors and international lenders.
This study explores and applies a method of
classification, ranking, and comparison of countries
according to their level of industrial development. It
is based on a comprehensive analysis of the different
factors affecting, directly or indirectly, industrial
growth. These factors include criteria--both
quantitative and qualitative--related to effectiveness,
comparative performance, efficiency, impacts,
sustainability, and capabilities. Aggregation of these
elements results in a composite index of industrial
progress.
Based on this analysis, a generic prototype performance
evaluation system was developed. An expert systems
approach was attempted in building the prototype in view
of the heuristic nature of the problem. The system's
knowledge base was acquired from domain experts, as well
as from the literature. The system was tested using real
data from a sample of 20 countries. The prototype runs
on personal computers (IBM and compatibles) using an
expert systems shell (VP-Expert) interfacing with
database and spreadsheet files.
</ABSTRACT>
</THESIS>
<THESIS>
<NUMBER> 4532 </NUMBER>
<ORDER>   AAG1356820 </ORDER>
<TITLE>   A LEARNING AUTOMATON APPROACH TO TRAJECTORY LEARNING AND CONTROL SYSTEM DESIGN USING DYNAMIC RECURRENT NEURAL NETWORKS </TITLE>
<AUTHOR>   CONDARCURE, THOMAS A. </AUTHOR>
<YEAR>   1993 </YEAR>
<INSTITUTION>   THE UNIVERSITY OF ARIZONA; 0009 </INSTITUTION>
<DESCRIPTORS>   ENGINEERING, ELECTRONICS AND ELECTRICAL; ARTIFICIAL INTELLIGENCE; COMPUTER SCIENCE </DESCRIPTORS>
<ADVISER>   MALUR K. SUNDARESHAN </ADVISER>
<CLASSIFICATIONS>   NIL </CLASSIFICATIONS>
<ABSTRACT>
This thesis presents a method for the training of
dynamic, recurrent neural networks to generate
continuous-time trajectories. In the past, most methods
for this type of training were based on gradient descent
methods and were deterministic. The method presented
here is stochastic in nature. The problem of local
minima is addressed by adding the enhancement of
incremental learning to the learning automaton; i.e.,
small learning goals are used to train the neural
network from its initialized state to its final
parameters for the desired response. The method is
applied to the learning of a benchmark continuous-time
trajectory--the circle. Then the learning automaton
approach is applied to stabilization and tracking
problems for linear and nonlinear plant models, using
either state or output feedback as needed.
</ABSTRACT>
</THESIS>
<THESIS>
<NUMBER> 4533 </NUMBER>
<ORDER>   AAG1356800 </ORDER>
<TITLE>   THE GEOLOGY OF THE MINERAL HILL AREA, MISSION MINE, PIMA COUNTY, ARIZONA </TITLE>
<AUTHOR>   WILLIAMSON, ROBERT LINN, JR. </AUTHOR>
<YEAR>   1993 </YEAR>
<INSTITUTION>   THE UNIVERSITY OF ARIZONA; 0009 </INSTITUTION>
<DESCRIPTORS>   GEOLOGY; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER>   JOHN M. GUILBERT </ADVISER>
<CLASSIFICATIONS>   NIL </CLASSIFICATIONS>
<ABSTRACT>
The Mission Mine, 32 kilometers southwest of Tucson,
Arizona, is developed on a porphyry copper skarn with
ore hosted in the Permian Epitaph, Scherrer, and Concha
Formations and the Triassic Rodolfo Formation. The
western portion of the orebody, the Mineral Hill area,
has distinct geologic and structural differences from
the Mission pit sequence. Cross-sections constructed
from recent drill hole data revealed that three major
faults are responsible for the differing geology and
stratigraphy. Two of these cause carbonate rocks whose
formation identity was previously unknown to be emplaced
in the project area. Geochemical analysis of known
carbonate formations and of the unknown carbonates was
used to attempt classification of the unknowns by
determining normative mineral compositions, and by using
neutral networks, a computer algorithm previously
successful in classifying complex patterns. The
normative mineral compositions were too similar to be
useful, but neural networks were moderately successful
in correctly classifying unknowns whose formation name
could be deduced by stratigraphic means. Sections of the
Cambrian Abrigo, Devonian Martin, and Permian Rainvalley
Formations, previously unrecognized at Mission, were
identified by neural network and stratigraphic data.
</ABSTRACT>
</THESIS>
<THESIS>
<NUMBER> 4534 </NUMBER>
<ORDER>   AAG1356629 </ORDER>
<TITLE>   REAL-TIME NON-UNIFORMITY CORRECTION OF AN INFRARED FOCAL PLANE ARRAY USING NEURAL NETWORKS </TITLE>
<AUTHOR>   KUNZMAN, ADAM JOHN </AUTHOR>
<YEAR>   1993 </YEAR>
<INSTITUTION>   THE UNIVERSITY OF TEXAS AT ARLINGTON; 2502 </INSTITUTION>
<DESCRIPTORS>   COMPUTER SCIENCE; ENGINEERING, ELECTRONICS AND ELECTRICAL; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER>   FARHAD KAMANGAR </ADVISER>
<CLASSIFICATIONS>   NIL </CLASSIFICATIONS>
<ABSTRACT>
This paper discusses an artificial neural network
approach to correcting the output of staring Infrared
Focal Plane Array Detectors (IRFPA) with respect to
their spatial response non-uniformities. Variations
across the detector due to manufacturing variability and
non-uniformities in the associated electronics can cause
spatial noise in the image produced by the IRFPA. This
degrades the ability of computer vision systems or human
operators to recognize objects in the scene. To correct
for the non-uniformities, a neural network is trained to
compensate the detector response of known infrared
inputs. Using computer simulations, the response
characteristics of a real detector is modeled to expose
the neural network to simulated IRFPA images. These
images are used to evaluate the performance of the
neural network. A comparison to a conventional two-point
correction scheme is also discussed.
</ABSTRACT>
</THESIS>
<THESIS>
<NUMBER> 4535 </NUMBER>
<ORDER>   AAG1356608 </ORDER>
<TITLE>   APPLICATION OF A NEURAL NETWORK TO A DEDUCTIVE PROBLEM: MASTERMIND </TITLE>
<AUTHOR>   CHANG, CHENG-YAW </AUTHOR>
<YEAR>   1993 </YEAR>
<INSTITUTION>   THE UNIVERSITY OF TEXAS AT ARLINGTON; 2502 </INSTITUTION>
<DESCRIPTORS>   COMPUTER SCIENCE; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER>   BOB WEEMS </ADVISER>
<CLASSIFICATIONS>   NIL </CLASSIFICATIONS>
<ABSTRACT>
Game playing has gone through several transitions from
straight rule-based systems through to neural networks.
The underlying similarity in games like chess and
backgammon, is a definite set of rules and moves. Thus,
a search tree with a specified ply can be implemented to
solve the puzzle. In the same manner, there are numerous
methods to solve reasoning and deductive problems, such
as rule-based systems and inference nets which are often
very big and cumbersome. A neural network can be used to
replace the larger systems. This was shown in Tesaro's
work where he implemented the game backgammon using
neural networks, which produced a world-class backgammon
player. The network learned strategies that were
difficult to implement using conventional AI techniques.
In the same spirit, I will show that a Neural Network
can "learn" to solve problems that call for
some amount of deductive reasoning such as Mastermind.
</ABSTRACT>
</THESIS>
<THESIS>
<NUMBER> 4536 </NUMBER>
<ORDER>   AAGMM85987 </ORDER>
<TITLE>   AN EXPERT SYSTEM FOR THE FIRE PROTECTION REQUIREMENTS OF THE NATIONAL BUILDING CODE OF CANADA 1990 </TITLE>
<AUTHOR>   OLYNICK, DARRYL MICHAEL </AUTHOR>
<YEAR>   1993 </YEAR>
<INSTITUTION>   THE UNIVERSITY OF MANITOBA (CANADA); 0303 </INSTITUTION>
<DESCRIPTORS>   ENGINEERING, CIVIL; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER>   R. B. PINKNEY; M. J. FRYE </ADVISER>
<CLASSIFICATIONS>   NIL </CLASSIFICATIONS>
<ABSTRACT>
In Canada, the standard for fire safety for new
buildings, reconstruction of buildings including
alteration and additions, and buildings involving a
change in occupancy, is established in Part 3, Use and
Occupancy of the National Building Code of Canada 1990.
While the fire protection requirements contained in this
section of the Code are very explicit, inexperienced or
infrequent users of the Code often find it confusing and
overwhelming because of the number of requirements which
apply or seem to apply to a given building. An
experienced code user or expert understands what
information is relevant and will generally use a
systematic process to determine the fire protection
requirements that are applicable.
Because the human approach to fire protection analysis
is, in fact, systematic and logically sequential, and
because the knowledge contained in codes and standards
is largely in the form of rules, an expert system can be
developed to effectively simulate human competence in
fire protection design.
This thesis describes the development of a user-friendly
expert system that closely mimics the human approach
used in the fire protection analysis of those buildings
regulated by Part 3, Use and Occupancy of the National
Building Code of Canada 1990. The principal fire
protection requirements of the Code have been
incorporated into the expert system. The resulting
expert system will be useful to the experienced code
user as a code assistant, and to the inexperienced or
infrequent code user who requires code information when
no expert is available.
</ABSTRACT>
</THESIS>
<THESIS>
<NUMBER> 4537 </NUMBER>
<ORDER>   AAGMM85975 </ORDER>
<TITLE>   AN EVALUATION OF TECHNIQUES AND TOOLS FOR INTEGRATING KNOWLEDGE-BASED AND CONVENTIONAL-COMPUTING SYSTEMS </TITLE>
<AUTHOR>   BRZEZINSKI, ANDRZEJ </AUTHOR>
<YEAR>   1993 </YEAR>
<INSTITUTION>   THE UNIVERSITY OF MANITOBA (CANADA); 0303 </INSTITUTION>
<DESCRIPTORS>   COMPUTER SCIENCE; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER>   MARK EVANS </ADVISER>
<CLASSIFICATIONS>   NIL </CLASSIFICATIONS>
<ABSTRACT>
Even though Artificial Intelligence (AI) technology
became commercially available in 1980s, it was viewed
from the wrong perspective throughout most of the
decade. A large portion of AI research during this
period viewed AI systems as the central part of
computing environments. This AI-centric perspective led
to many limitations in commercially available tools.
Recently, AI researchers and developers have begun to
view their techniques as extensions to conventional
computing environments. This view dictates a need for
integration between AI tools and conventional tools.
This thesis examines various techniques and tools that
have been developed to integrate knowledge-based and
conventional computing environments. The topics to
examined include: expert systems and databases, calling
external programs from AI tools, embedding AI tools in
conventional systems, and techniques for using client-
server architectures to support knowledge-based systems.
Examples using various commercial tools will be used to
illustrate these techniques.
</ABSTRACT>
</THESIS>
<THESIS>
<NUMBER> 4538 </NUMBER>
<ORDER>   AAG9425130 </ORDER>
<TITLE>   IF..THEN..ELSE SYSTEMS </TITLE>
<AUTHOR>   SAVIGNY, MARC DE </AUTHOR>
<YEAR>   1993 </YEAR>
<INSTITUTION>   UNIVERSITY OF MARYLAND COLLEGE PARK; 0117 </INSTITUTION>
<DESCRIPTORS>   ENGINEERING, ELECTRONICS AND ELECTRICAL; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER>   ROBERT W. NEWCOMB </ADVISER>
<CLASSIFICATIONS>   IF..THEN..ELSE SYSTEMS, BOOLEAN GATES, FUZZY LOGIC, NEURAL NETWORKS </CLASSIFICATIONS>
<ABSTRACT>
This dissertation presents realizations of
IF..THEN..ELSE circuits and systems, developing a theory
for these and giving applications including Boolean
gates, fuzzy logic, neural networks.
An IF gate is introduced by providing its functional
description and its properties. A six-CMOS-transistor
circuit for it is proposed and simulated. We draw a VLSI
layout, from which a chip is built and tested.
Also, we present a least-number-of-IF-gates
implementation of the Boolean functions of two input
variables. It is shown that this IF-gate implementation
uses fewer gates than that with AND, OR, INV gates,
furthermore we prove that, in average, less CMOS
transistors are necessary to implement Boolean functions
than with other known methods. A generalization for more
inputs through a new recursive structure called the IF
chain is proposed. A theoretical analysis of the IF
chain and a method to simplify the computation of its
output's logic equation are given together with examples
for commonly used multi-input gates.
A block diagram for a four-bit microprocessor made with
IF gates is given, along with the IF gate realization of
its elements (memories, buffers, multiplexers, and
demultiplexers). A VLSI chip for that microprocessor is
designed. We tell how to write software for that
microprocessor and give three sample programs.
For error correction and detection with (n,k) linear
block codes, we describe an encoder and a syndrome
circuit realized with IF gates. Additionally, we select
various applications and show how to build them with IF
gates, these including an IF digital adder which is a
combinational logic function different from the two-
input Boolean functions already discussed and the
realization of a switching network with IF gates.
An extension of the IF gate is made to analog CONTINUOUS
IF gates for which we give and simulate practical CMOS
circuits. Also, we construct an artificial neuron with
CONTINUOUS IF gates that does not use multipliers, and
detail the case of the one-neuron network that computes
any of the fourteen linearly separable Boolean functions
of two input variables including simulations of the
network. The weights are set by applying analog voltages
on inputs of the CONTINUOUS IF gates. Finally, we model
a simple biological coastal snail with rules based on
the IF..THEN..ELSE structure.
</ABSTRACT>
</THESIS>
<THESIS>
<NUMBER> 4539 </NUMBER>
<ORDER>   AAG9425087 </ORDER>
<TITLE>   NOVEL SELF-ORGANIZING NEURAL ARCHITECTURES WITH APPLICATIONS TO IMAGE PROCESSING AND PATTERN RECOGNITION </TITLE>
<AUTHOR>   LIU, LURNG-KUO </AUTHOR>
<YEAR>   1993 </YEAR>
<INSTITUTION>   UNIVERSITY OF MARYLAND COLLEGE PARK; 0117 </INSTITUTION>
<DESCRIPTORS>   ENGINEERING, ELECTRONICS AND ELECTRICAL; COMPUTER SCIENCE; PSYCHOLOGY, BEHAVIORAL; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER>   PANOS A. LIGOMENIDES </ADVISER>
<CLASSIFICATIONS>   NIL </CLASSIFICATIONS>
<ABSTRACT>
This dissertation is primarily concerned with two
problems of learning in neural networks. In the first
case, the goal is to construct an efficient unsupervised
neural network for dimensionality reduction/feature
extraction such that subsequent learning may be done
more efficiently. When neural networks are applied to
pattern recognition problems with high-dimensional
patterns, the problem of dimensionality becomes the main
factor affecting system performance. The training time
depends strongly on the dimensionality of the inputs.
The problem of dimensionality can be significantly
alleviated by using a preprocessing stage for
dimensionality reduction and feature extraction. An
unsupervised orthogonalization neural network
architecture and learning algorithm are proposed, based
on Principal Component Analysis (PCA), for this purpose.
The use of mathematical analysis is emphasized to
provide a model for analyzing and predicting the
behavior of the learning procedure. A comparative study
of the related approaches and the application of
proposed model to image compression problem are
investigated. It turns out that the proposed model
offers a significant reduction in dimensionality with
minimum linear reconstruction error and provides great
convergence speed during the learning process.
The second problem of learning which has been
investigated, concerns improving the learning stability,
speed, and patterns representation in an unsupervised
competitive learning algorithm. Generally, competitive
learning always involves some sort of competition among
the responses of output units. Since Euclidean distance
has greater sensitivity to the vector lengths to be
compared, traditional approaches (which base competition
for activation on Euclidean distance alone) may have
problems of patterns representation and learning
instability. We are investigating the competition based
on extended measure of distance. A new combined
similarity measurement taking into account learning
tendency in addition to Euclidean distance, is
introduced and employed in our proposed self-organizing
learning algorithm. The proposed approach is shown to be
effective through computer simulations.
In addition, by restricting our attention to
preattentive applications and computational speed, a
further investigation is suggested for using and
extending the proposed orthogonalization neural network
as a tool to perform fast edge detection in image
processing.
</ABSTRACT>
</THESIS>
<THESIS>
<NUMBER> 4540 </NUMBER>
<ORDER>   AAG9425037 </ORDER>
<TITLE>   LEARNING ACTIVATION RULES RATHER THAN WEIGHTS IN CONNECTIONIST MODELS </TITLE>
<AUTHOR>   GRUNDSTROM, ERIC LOWELL </AUTHOR>
<YEAR>   1993 </YEAR>
<INSTITUTION>   UNIVERSITY OF MARYLAND COLLEGE PARK; 0117 </INSTITUTION>
<DESCRIPTORS>   MATHEMATICS; COMPUTER SCIENCE; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER>   JAMES A. REGGIA </ADVISER>
<CLASSIFICATIONS>   NIL </CLASSIFICATIONS>
<ABSTRACT>
Connectionist models usually learn by adjusting
connection weights. However, such learning algorithms do
not use the fact that adjusting activation rules can
also have a profound effect on the overall computation.
In fact, for networks with a local representation of
knowledge, connection weights are often known a priori,
and adjusting activation rules is the only way for the
network to learn. This dissertation derives a new
supervised learning rule based on gradient descent,
where connection weights are fixed and a network learns
by changing the activation rule. This learning rule
incorporates both traditional and competitive activation
mechanisms, the latter being an efficient method for
instilling competition in a network. The learning rule
has been implemented in C, and its effectiveness is
demonstrated in a number of applications. Specifically,
a simplified exclusive-or network shows the power of
complex activation rules, providing a novel solution to
a problem involving non-linear associations. In the
second application, the person-location-proposition
network demonstrates how connectionist models can learn
to have competitive, winner-takes-all behavior; also,
the network's performance is compared to that of human
subjects in a psychological study. The center-of-mass
network is an example of a network that learns to be non-
competitive; it also shows how the algorithm has the
ability to produce analog output. Finally, the print-to-
sound application demonstrates the algorithm's ability
to handle a large and complex network architecture; the
network learns to generalize well from a small training
set. The results of this testing demonstrate that
learning activation mechanisms is an effective new
approach to creating adaptive neural networks.
</ABSTRACT>
</THESIS>
<THESIS>
<NUMBER> 4541 </NUMBER>
<ORDER>   AAG9423532 </ORDER>
<TITLE>   AGENTSHEETS: A TOOL FOR BUILDING DOMAIN-ORIENTED DYNAMIC, VISUAL ENVIRONMENTS </TITLE>
<AUTHOR>   REPENNING, ALEXANDER </AUTHOR>
<YEAR>   1993 </YEAR>
<INSTITUTION>   UNIVERSITY OF COLORADO AT BOULDER; 0051 </INSTITUTION>
<DESCRIPTORS>   COMPUTER SCIENCE </DESCRIPTORS>
<ADVISER>   CLAYTON LEWIS </ADVISER>
<CLASSIFICATIONS>   PROGRAMMING </CLASSIFICATIONS>
<ABSTRACT>
Cultures deal with their environments by adapting to
them and simultaneously changing them. This is
particularly true for technological cultures, such as
the dynamic culture of computer users. To date, the
ability to change computing environments in non-trivial
ways has been dependent upon the skill of programming.
Because this skill has been hard to acquire, most
computer users must adapt to computing environments
created by a small number of programmers. In response to
the scarcity of programming ability, the computer
science community has concentrated on producing general-
purpose tools that cover wide spectrums of applications.
As a result, contemporary programming languages largely
ignore the intricacies arising from complex interactions
between different people solving concrete problems in
specific domains.
This dissertation describes Agentsheets, a substrate for
building domain-oriented, visual, dynamic programming
environments that do not require traditional programming
skills. It discusses how Agentsheets supports the
relationship among people, tools, and problems in the
context of four central themes: (1) Agentsheets features
a versatile construction paradigm to build dynamic,
visual environments for a wide range of problem domains
such as art, artificial life, distributed artificial
intelligence, education, environmental design, and
computer science theory. The construction paradigm
consists of a large number of autonomous, communicating
agents organized in a grid, called the agentsheet.
Agents utilize different communication modalities such
as animation, sound, and speech. (2) The construction
paradigm supports the perception of programming as
problem solving by incorporating mechanisms to
incrementally create and modify spatial and temporal
representations. (3) To interact with a large number of
autonomous entities Agentsheets postulates participatory
theater, a human-computer interaction scheme combining
the advantages of direct manipulation and delegation
into a continuous spectrum of control and effort. (4)
Metaphors serve as mediators between problem solving-
oriented construction paradigms and domain-oriented
applications. Metaphors are used to represent
application semantics by helping people to conceptualize
problems in terms of concrete notions. Furthermore,
metaphors can simplify the implementation of
applications. Application designers can explore and
reuse existing applications that include similar
metaphors.
</ABSTRACT>
</THESIS>
<THESIS>
<NUMBER> 4542 </NUMBER>
<ORDER>   AAGNN86753 </ORDER>
<TITLE>   UN MODELE DE RESEAU NEURONIQUE POUR LA PERCEPTION VISUELLE DE LA PROFONDEUR D'UNE SCENE A PARTIR DE LA STEREOSCOPIE ET DE L'OMBRAGE </TITLE>
<AUTHOR>   LEPAGE, RICHARD </AUTHOR>
<YEAR>   1993 </YEAR>
<INSTITUTION>   UNIVERSITE LAVAL (CANADA); 0726 </INSTITUTION>
<DESCRIPTORS>   ENGINEERING, ELECTRONICS AND ELECTRICAL; COMPUTER SCIENCE; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER>   DENIS POUSSART </ADVISER>
<CLASSIFICATIONS>   FRENCH TEXT, SHADING </CLASSIFICATIONS>
<ABSTRACT>
Les travaux de cette these portent sur un reseau
neuronique artificiel qui realise la fusion de la
stereoscopie et de l'analyse de l'ombrage pour
reconstituer la profondeur de la scene observee a partir
de deux images d'illuminance. Ces dernieres peuvent
provenir de deux cameras et la reconstitution de la
profondeur a partir d'images a deux dimensions est une
etape essentielle avant les traitements de haut niveau
que constituent la reconnaissance et la memorisation des
elements de la scene tridimensionnelle observee. Les
aretes contenues dans chacune des deux images sont
d'abord detectees. Les aretes identiques sur chacune des
images sont ensuite appariees par l'algorithme de
stereoscopie et les disparites mesurees indiquent la
profondeur de la scene observee aux differentes
positions d'aretes. Une analyse de l'ombrage sur l'une
des images produit un estime de la profondeur relative
pour des variations douces de la surface exterieure. Un
reseau de relaxation combine les deux analyses et permet
d'obtenir une grille dense de mesures de profondeur.
</ABSTRACT>
</THESIS>
<THESIS>
<NUMBER> 4543 </NUMBER>
<ORDER>   AAGNN86552 </ORDER>
<TITLE>   MODELES ET ALGORITHMES POUR LA LOGIQUE PROBABILISTE </TITLE>
<AUTHOR>   POGGI DE ARAGAO, MARCUS </AUTHOR>
<YEAR>   1993 </YEAR>
<INSTITUTION>   ECOLE POLYTECHNIQUE, MONTREAL (CANADA); 1105 </INSTITUTION>
<DESCRIPTORS>   MATHEMATICS </DESCRIPTORS>
<ADVISER>   BRIGITTE JAUMARD </ADVISER>
<CLASSIFICATIONS>   FRENCH TEXT </CLASSIFICATIONS>
<ABSTRACT>
Probabilistic logic became an active research topic in
the area of reasoning under uncertainty in Artificial
Intelligence. Indeed, many models have been proposed for
reasoning under certainty in expert systems specialized
in medical and/or failure diagnosis. A typical expert
system consists in a knowledge base and an inference
engine. Most of the models deal locally with the
uncertainty, that is considering one logical implication
at a time. On the contrary, probabilistic logic
considers globally the knowledge base. The work of this
thesis consists in the design of theoretical and
algorithmic methods to solve the consistency and
entailment problems in probabilistic logic.
The first study concerns the analytical solution of both
problems. Hailperin (1965) showed that they can be
expressed by linear programs. Completing some work of
Hailperin (1965), we showed that analytical solutions
can be obtained by enumerating the extreme points and
rays of the polyhedron of the dual of a given linear
program.
Next, we study algorithmic methods. The linear programs
turn out to have an exponential number of variables and
a number of constraints equal to the number of logical
implications. Consequently, column generation techniques
are needed to solve them. The subproblem to be solved at
each iteration, i.e. to find a column whose reduced cost
has a given sign, corresponds to an unconstrained
nonlinear 0-1 program. Since it is NP-hard and since it
is not required to find the column with the most
negative (or positive) reduced cost at each iteration,
we use a heuristic of tabu search type to solve the
subproblem. When such a heuristic fails to find a column
with the desired reduced cost sign, an exact algorithm
is used. We observe that in practice when an exact
algorithm is needed, most of the dual variables are
equal to zero and hence, the subproblem can be easily
solved despite of its theoretical complexity. We also
propose extensions of the model that consider
conditional probabilities and probability intervals.
Finally, we discuss how to restore consistency when
necessary by finding the minimum variation of the
probability intervals. A confidence factor can be
associated with each logical implication to assess the
belief of the truth probability of it. Then adjustments
of probability are made first on those with smaller
confidence factors.
Another way to restore consistency is to determine the
minimum number of logical implications to be removed in
order to regain consistency. Again, coefficients can be
associated with the implications to assess their
importance and then remove the minimum of them with
respect to their significance. This problem can be
mathematically expressed by a mixed-integer program,
again with an exponential number of variables. We
propose a new exact column generation method, based on
the primal simplex algorithm, to solve it.
In all the exact algorithms we experimented for the
solution of the models of probabilistic logic, we show
that heuristic methods play a crucial role. This gave us
motivation to start a quite fundamental study of the
topology of the local optima of combinatorial problems.
(Abstract shortened by UMI.)
</ABSTRACT>
</THESIS>
<THESIS>
<NUMBER> 4544 </NUMBER>
<ORDER>   AAG9424782 </ORDER>
<TITLE>   TOWARDS A NEW FRAMEWORK FOR ARTIFICIAL INTELLIGENCE RESEARCH </TITLE>
<AUTHOR>   STITTS, KARL BROCK </AUTHOR>
<YEAR>   1993 </YEAR>
<INSTITUTION>   THE FLORIDA STATE UNIVERSITY; 0071 </INSTITUTION>
<DESCRIPTORS>   PHILOSOPHY; COMPUTER SCIENCE </DESCRIPTORS>
<ADVISER>   EUGENE F. KAELIN </ADVISER>
<CLASSIFICATIONS>   EMBEDDED COMPUTATION </CLASSIFICATIONS>
<ABSTRACT>
This dissertation constitutes an attempt to reconcile
artificial intelligence research with the philosophical
movement of phenomenology. It is not an easy task, as
the initial work relating phenomenology and AI, done by
Hubert Dreyfus, involved harsh criticisms of AI.
After an introductory chapter, I examine Dreyfus's
arguments against AI. I conclude that these arguments,
though they point to difficulties which AI researchers
must face, do not provide compelling reasons for AI
workers to abandon their research. Furthermore, the
alternative theoretical assumptions which Dreyfus
advocates are not clear-cut enough to provide an
alternative paradigm for AI research.
In the next chapter, I examine another set of criticisms
of AI done by phenomenologists, that of Terry Winograd
and Fernando Flores. I draw similar conclusions with
these criticisms as I do with those of Dreyfus.
In the fourth chapter, I examine the emerging AI
paradigm of "embedded computation." Advocates
of this paradigm hold that AI should rely on an
"interactionist" theory of mind rather than
the "mentalistic" theories traditional AI
uses. Although I agree with much of the substance of
this paradigm, some of the claims made by its advocates
have not been sufficiently well argued.
Because so many of the criticisms of AI discussed in
Chapters Two through Four are inconclusive, in the fifth
chapter I attempt to strengthen the arguments involved.
I find some of the fundamental tenets of AI research,
such as the compositionality of semantics and the
language of thought hypothesis, to be untenable, but
conclude that one of Dreyfus's central arguments against
AI, the "background" argument, is not
effective. Nevertheless, I infer that the inadequacies
of GOFAI are large enough so that an alternative to
traditional AI research is needed. Building on the work
of Philip Agre, who I classify as an embedded
computation advocate, I develop my own alternative
framework for AI research, which uses a counterpart to
what Marvin Minsky has dubbed "frames."
</ABSTRACT>
</THESIS>
<THESIS>
<NUMBER> 4545 </NUMBER>
<ORDER>   AAGNN86726 </ORDER>
<TITLE>   DU SYSTEME EXPERT AU TUTEUR INTELLIGENT: APPLICATION D'UN MODELE D'APPRENTISSAGE AU DEVELOPPEMENT D'UN SYSTEME D'ENSEIGNEMENT DE L'ALGORITHMIQUE </TITLE>
<AUTHOR>   MALOUIN, JACQUES </AUTHOR>
<YEAR>   1993 </YEAR>
<INSTITUTION>   UNIVERSITE LAVAL (CANADA); 0726 </INSTITUTION>
<DESCRIPTORS>   EDUCATION, TECHNOLOGY; ARTIFICIAL INTELLIGENCE; EDUCATION, MATHEMATICS </DESCRIPTORS>
<ADVISER>   GUY PROVOST </ADVISER>
<CLASSIFICATIONS>   FRENCH TEXT </CLASSIFICATIONS>
<ABSTRACT>
Dans cette these, l'auteur presente la conception, le
developpment et une mise a l'essai d'un systeme tutoriel
intelligent, TIRPA (Tutoriel Intelligent de Resolution
de problemes d'Algorithmique), prototype de systeme
d'apprentissage de l'algorithmique. Le design du systeme
est base d'une part sur un systeme expert en
programmation capable de generer des programmes et de
suivre le cheminement d'un eleve, et d'autre part sur la
theorie d'apprentissage ACT$sp*$ d'Anderson. L'auteur se
refere aux tuteurs intelligents developpes par Anderson
et son equipe, principalement le LISP-TUTOR. Apres une
description detaillee des caracteristiques du systeme
TIRPA, l'auteur discute et justifie les divers choix de
son design. La methodologie d'une mise a l'essai du
systeme avec une quarantaine d'eleves du niveau
secondaire est presentee ainsi que les resultats de
cette mise a l'essai.
</ABSTRACT>
</THESIS>
<THESIS>
<NUMBER> 4546 </NUMBER>
<ORDER>   AAGC360258 </ORDER>
<TITLE>   AN INTELLIGENT KNOWLEDGE-BASED PROCESS PLANNING AND FIXTURING SYSTEM USING THE STEP STANDARD </TITLE>
<AUTHOR>   GULESIN, MAHMUT </AUTHOR>
<YEAR>   1993 </YEAR>
<INSTITUTION>   COUNCIL FOR NATIONAL ACADEMIC AWARDS (UNITED KINGDOM); 0935 </INSTITUTION>
<DESCRIPTORS>   ENGINEERING, SYSTEM SCIENCE </DESCRIPTORS>
<ADVISER>   NIL </ADVISER>
<CLASSIFICATIONS>   NIL </CLASSIFICATIONS>
<ABSTRACT>
This thesis outlines the problems associated with
automation of process planning and reviews established
available methods. It identifies the key problems
related to the integration of CAD/CAM. The major
requirement for such integration is to automate
manufacturing tasks which currently require human
reasoning and experience. Process planning plays an
important role in these activities. Expert system
techniques which provide efficient knowledge
representation and inferencing techniques from
Artificial Intelligence (AI) are believed to be
potential key factors towards achieving this goal of
integration.
This thesis explores the potential application of expert
system techniques to automate process planning
activities by capturing the planning logic and knowledge
within the expert Computer Aided Process Planning (CAPP)
system developed. This CAPP system is flexible,
automated, generative and uses 3-D prismatic part data
in STEP standard format as input. Three main parts of
the system are introduced, namely the expert system that
comprises an inference engine, user interface and
knowledge base, the machining decisions and fixturing.
The machining decisions include blank part design,
selection of reference surface and operation, sequencing
of operations, cutter and machine tool selection and
calculation of machining parameters. The techniques and
algorithms developed for machining decisions, fixturing
and establishing the expert system are described.
In order to examine the feasibility of the approach
employed, the experimental planning system was tested on
several components.
</ABSTRACT>
</THESIS>
<THESIS>
<NUMBER> 4547 </NUMBER>
<ORDER>   AAGC360155 </ORDER>
<TITLE>   BUDOWA ELEKTROENERGETYCZNYCH BAZ WIEDZY NA PRZYKLADZIE SYSTEMU EKSPERTOWEGO DO PROJEKTOWANIA PRZEMYLSLOWYCH STACJI ELEKTRO-ENERGETYCZNYCH; BUILDING ELECTRICAL POWER ENGINEERING KNOWLEDGE-BASES BASED ON AN EXAMPLE OF AN EXPERT SYSTEM FOR DESIGNING INDUSTRIAL MEDIUM-VOLTAGE SUBSTATIONS </TITLE>
<AUTHOR>   GLUSZEK, ARTUR FRANCISZEK </AUTHOR>
<YEAR>   1993 </YEAR>
<INSTITUTION>   POLITECHNIKA WROCLAWSKA (POLAND); 5999 </INSTITUTION>
<DESCRIPTORS>   ENGINEERING, ELECTRONICS AND ELECTRICAL </DESCRIPTORS>
<ADVISER>   NIL </ADVISER>
<CLASSIFICATIONS>   SUBSTATIONS </CLASSIFICATIONS>
<ABSTRACT>
The dissertation contains a description of studies which
concern the process of knowledge-bases design in some
fields of electrical power engineering. The design of
industrial medium voltage substations has been chosen as
an example of a suitable problem domain. The suitability
for such an application of knowledge-base technology
results from the main features of the problem such as:
decisions are made based largely on imprecise, uncertain
and incomplete information; the data are given mostly in
linguistic form; the quality of a solution is assessed
by several objectives, which are often uncountable and
without known priorities; there are almost no numerical
routines; a strong need for previous designer experience
exist. First, the general methodology of engineering
design according to designer intelligence is presented,
and a substation as an object of design is described.
The second chapter contains information about different
artificial intelligence techniques, among them an expert
system approach is presented with details as far as the
definition, structure and traits are concerned. Chapter
four describes knowledge acquisition techniques. Among
the latest are: interview, literature and case studies,
repertory grid, card-sorting, multidimensional scaling,
induction, and only the first two appear to be effective
enough. In the next chapter a way of knowledge
elicitation from experts, and then a conversion of the
knowledge into rules is described. Based on the
characteristic of the problems and gathered knowledge,
in chapter five the requirements for an expert system
concerning knowledge representation, inference mechanism
and so on, are formulated. In the same chapter a
description of a prototype expert system shell
implemented in PROLOG is presented. The combined
approach using certainty factors and simple triangle-
like fuzzy values of attributes is suggested.
Incompleteness is overcome by usage of default values
and dependant rules. The system can be fed with
information obtained from four sources: fact base, rule
base, calculation module base, and answers gained from
the user through question base. In chapter six three
different ways of building the rule base are presented.
The subtasks (selection of transformers, designing
schematic diagrams of medium and low voltage sides,
designing substation building structures) are chosen so
as to present domains in which different types of
knowledge representation, inference process, calculation
routines, model of preferences, should be used. The
results show that it is possible to get reasonable
solutions based on practical design data. (Abstract
shortened by UMI.)
</ABSTRACT>
</THESIS>
<THESIS>
<NUMBER> 4548 </NUMBER>
<ORDER>   AAGC360004 </ORDER>
<TITLE>   METHODOLOGY FOR MODELLING COMPLETE PRODUCT ASSEMBLIES </TITLE>
<AUTHOR>   GUI, JIN KANG </AUTHOR>
<YEAR>   1993 </YEAR>
<INSTITUTION>   HELSINGIN KAUPPAKORKEAKOULU (FINLAND); 0431 </INSTITUTION>
<DESCRIPTORS>   COMPUTER SCIENCE SF-00100 HELSINKI, FINLAND </DESCRIPTORS>
<ADVISER>   NIL </ADVISER>
<CLASSIFICATIONS>   PRODUCT ASSEMBLIES, ASSEMBLIES </CLASSIFICATIONS>
<ABSTRACT>
Mechanical assembly design plays a central role from
conceptual to detail design. Research into modelling
complete product assemblies in computers is, therefore,
of significance not only for product manufacturing and
maintenance, but also for conceptual design problem-
solving and interpretation. The thesis investigates a
new methodology for product modelling beyond geometric
and feature modelling by sharing findings in design
theory and artificial intelligence, including bond graph
theory and fuzzy logic. The focuses of the thesis are on
the representation of assemblies and prototype-based
design problem-solving in computers, in particular, on
qualitative modelling and approximate reasoning for
conceptual design support. The main contents include:
how an assembly can be represented in the terms of
function, behaviour and structure, how a design problem
can be solved on the basis of fuzzy logic, and, in
particular, how initial assembly design alternatives can
be generated by mechanical design prototype-based
reasoning. As an attempt to seek computerized modelling
techniques, a top-down assembly design system, $Delta$
(read "delta") is initially implemented by
using tools of object oriented programming in Smalltalk
environment. The thesis provides details for the system
realisation on the basis of the new concepts. Finally,
the thesis presents some application algorithms for
assembly sequence planning, and for product data
exchange of assembly information.
</ABSTRACT>
</THESIS>
<THESIS>
<NUMBER> 4549 </NUMBER>
<ORDER>   AAGC359417 </ORDER>
<TITLE>   ARTIFICIAL INTELLIGENCE IN EXTRUSION COOKING PROCESS MODELLING AND CONTROL </TITLE>
<AUTHOR>   EERIKAINEN, TERO HENRIK </AUTHOR>
<YEAR>   1993 </YEAR>
<INSTITUTION>   TEKNILLINEN KORKEAKOULU (HELSINKI) (FINLAND); 5766 </INSTITUTION>
<DESCRIPTORS>   ENGINEERING, CHEMICAL </DESCRIPTORS>
<ADVISER>   NIL </ADVISER>
<CLASSIFICATIONS>   NIL </CLASSIFICATIONS>
<ABSTRACT>
Artificial intelligence in its multiple forms of
manifestation has gained a lot of popularity in various
fields of engineering, as well as in appliances
belonging to the everyday life. Food technology is a
field that leans especially heavily on traditional
solutions, and food technologists seem to be sometimes
even reluctant to try any new methods. But the problems
in the food field are often difficult to define and
measure in engineering units, and the cognitive load in
control tasks may far exceed the capability of standard
control systems used e.g. in chemical processes. As an
example of a complicated food process, extrusion cooking
was investigated in the present work in artificial
intelligence frames. Fuzzy logic, expert systems and
neural networks were used for modelling and control of
various food extruders in on-line experiments and off-
line simulations. Fuzzy logic has been shown to be a
valuable tool in dealing with vague and incomplete
information, and in incorporating human expert knowledge
into process models. An expert system consisting of rule-
based knowledge networks was used in various control and
fault diagnosis tasks. Fuzzy sets were utilized also in
the expert system developed to describe linguistic
levels of various process variables. Neural network
programs capable of learning from past experience are
useful when little or no exact mathematical information
on the process under investigation is available. Dynamic
models are needed in identification and/or on-line
controlling of real-time, dynamic processes.
Difficulties caused by the multivariable nature of food
processes are also often mentioned. In the present work,
dynamic changes (including inversion) of various
extrusion variables were modelled (identified) using
feedforward type multi-layer artificial neural networks
(ANN), thus enabling dynamic control of the MIMO (Multi
Input Multi Output) process. Each one of the above AI-
approaches has its advantages and disadvantages, and
combining them into a hybrid system should result in the
most flexible control performance.
</ABSTRACT>
</THESIS>
<THESIS>
<NUMBER> 4550 </NUMBER>
<ORDER>   AAG9422229 </ORDER>
<TITLE>   A CONNECTIONIST EXPERT SYSTEM FOR LEARNING PROCESS DRIFT CONTROL IN OFFSET LITHOGRAPHIC PRINTING </TITLE>
<AUTHOR>   AL-MUTAWA, SOUHAILA </AUTHOR>
<YEAR>   1993 </YEAR>
<INSTITUTION>   SYRACUSE UNIVERSITY; 0659 </INSTITUTION>
<DESCRIPTORS>   ENGINEERING, MECHANICAL; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER>   YOUNG BAI MOON </ADVISER>
<CLASSIFICATIONS>   NIL </CLASSIFICATIONS>
<ABSTRACT>
Techniques from artificial intelligence research have
provided a foundation for the development of decision-
making systems for automation at the knowledge level. By
studying the role of the human operator in the on-line
control of process drift, this research investigates the
nature of the knowledge that is specific to the operator
and the machine. The primary objective is to develop a
representation that models the relationship between the
observable and adjustable variables of a process as
perceived by an experienced operator when compensating
for process drift. The phenomenon of process drift is
studied in the context of offset lithographic printing
where it is a prominent problem. The on-line adjustments
that a proficient press operator applies to compensate
for process drift are specific to a particular machine.
The nature of the operator's knowledge was found to
consist of articulated relationships between process
variables and an unarticulated conceptualization. An
integrated connectionist expert system was developed to
model the operator's machine-specific knowledge. The
articulated relationships were represented in the form
of production rules. Whereas, a connectionist system was
designed to learn from actual process data generated by
the operator during on-line control. It was found that
the relation between the subtractive primaries of the
ink colors and the additive primaries has been uncovered
by the connectionist representation. A weight-based
conflict resolution technique was developed to integrate
the connectionist representation with the expert system.
</ABSTRACT>
</THESIS>
<THESIS>
<NUMBER> 4551 </NUMBER>
<ORDER>   AAG9421739 </ORDER>
<TITLE>   CLOSED LOOP CONTROL OF GUIDED MISSILES USING NEURAL NETWORKS </TITLE>
<AUTHOR>   SADATI, SEYED HOSSEIN </AUTHOR>
<YEAR>   1993 </YEAR>
<INSTITUTION>   THE UNIVERSITY OF ARIZONA; 0009 </INSTITUTION>
<DESCRIPTORS>   ENGINEERING, AEROSPACE; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER>   THOMAS L. VINCENT </ADVISER>
<CLASSIFICATIONS>   NIL </CLASSIFICATIONS>
<ABSTRACT>
An optimal guidance law for a missile flight is one
which determines appropriate controls to produce a
flight path such that some mission objective will be
achieved in the most efficient manner. Optimal Control
Theory is often used to accomplish this task. One must
bear in mind, however, that the usefulness of optimal
control is sharply divided between two distinct classes
of dynamical systems, namely, linear systems and
nonlinear systems. For linear systems, the theory is
complete in the sense that given a quadratic cost, a
closed-loop feedback guidance law may be determined. For
nonlinear systems, generally the best one can do is to
determine an open-loop guidance law numerically using a
software package such as MISER (1). (Some notable
exceptions exist where a complete analytical synthesis
of the closed-loop control may be obtained for nonlinear
systems, e.g., in (2).)
Although open-loop optimal guidance laws for nonlinear
systems can now be computed quite efficiently with the
advances of sophisticated numerical techniques along
with high-speed digital computers, the highly-nonlinear
and complex dynamics of missiles precludes the
possibility of on-line implementation of open-loop
optimal control. It has always been realized that if
optimal closed-loop solutions could be obtained for
comprehensive nonlinear systems such as missiles, then
guidance laws based on such results would be superior to
any other guidance laws available today. This
superiority is due to, among other things, the
elimination of some of the restrictive, and in many
cases unrealistic assumptions made in the derivation of
most current guidance laws in use such as, for instance,
"tail-chase", unbounded control, simplified
dynamics and/or aerodynamics, and non-maneuvering
target, to name a few.
In this study, an optimal closed-loop control law is
obtained off-line by means of a Neural Network which is
then used as an on-line controller for a generic
missile. In the nonlinear case, the missile/target
scenario is set up as a mathematical model using
realistic dynamics. Then, given a Performance Index, the
open-loop control is obtained by solving the problem
using the optimal control software MISER for a number of
different initial configurations. These open-loop
solutions are then used to "teach" a neural
network via backpropagation. Through simulation, it is
then demonstrated how well the neural network performs
as a feedback controller. The miss distance as well as
the value of the Performance Index are used as measures
of performance to be compared under the original open-
loop control and the neural network closed-loop control.
This problem is further extended to include a time lag
in the missile dynamics. The effect of this time delay
in the overall performance of the optimal controller is
then examined.
</ABSTRACT>
</THESIS>
<THESIS>
<NUMBER> 4552 </NUMBER>
<ORDER>   AAG9421714 </ORDER>
<TITLE>   NEURAL NETWORK APPROACHES FOR PERFORMANCE MODELING OF PARALLEL APPLICATIONS </TITLE>
<AUTHOR>   LEE, HYUKJOON </AUTHOR>
<YEAR>   1993 </YEAR>
<INSTITUTION>   SYRACUSE UNIVERSITY; 0659 </INSTITUTION>
<DESCRIPTORS>   COMPUTER SCIENCE; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER>   NIL </ADVISER>
<CLASSIFICATIONS>   NIL </CLASSIFICATIONS>
<ABSTRACT>
In this dissertation, neural network methods are
developed for modeling performance of programs executing
on parallel computers: primitives are modeled, new
algorithms are developed for approximating the class of
functions arising in these problems, methods are
developed to identify the relevant inputs for
performance evaluation, and algorithms are developed to
select the best possible algorithm.
System primitive modeling. Communication primitives of a
hypercube multiprocessor are modeled using feedforward
neural networks. Traditional backpropagation learning is
shown to be inadequate for discontinuous function
approximation problems that arise in this context.
Discontinuous function approximation. Two algorithms are
developed for this problem. In the first, the error
backpropagation rule is modified, adding a smoothness
norm to the error term to be minimized using gradient
descent in weight space. In the second, an incremental
network construction algorithm is developed, which
focuses the performance of each module on a specific
window in the problem space that is dynamically
expanded, and automatically generates new modules as the
current performance deteriorates with window expansion.
This algorithm shows superior performance to all other
methods with which experimentation has been conducted.
Irrelevant input identification. In many problems, large
amounts of data are available, and the irrelevant inputs
need to be identified. Several algorithms are developed
and evaluated for this task, using neural network
models.
Algorithm selection. For a given task, different
algorithms perform the fastest depending on parameters
of the problem and the parallel computer used. Two
neural network methods are developed to identify regions
in parameter space in which each algorithm performs
best.
</ABSTRACT>
</THESIS>
<THESIS>
<NUMBER> 4553 </NUMBER>
<ORDER>   AAG9421681 </ORDER>
<TITLE>   APPLICATION OF FUZZY LOGIC FOR PERFORMANCE ENHANCEMENT OF DRIVES </TITLE>
<AUTHOR>   SOUSA, GILBERTO COSTA D. </AUTHOR>
<YEAR>   1993 </YEAR>
<INSTITUTION>   THE UNIVERSITY OF TENNESSEE; 0226 </INSTITUTION>
<DESCRIPTORS>   ENGINEERING, ELECTRONICS AND ELECTRICAL; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER>   BIMAL K. BOSE </ADVISER>
<CLASSIFICATIONS>   NIL </CLASSIFICATIONS>
<ABSTRACT>
Fuzzy logic application to DC and AC drives control is
the essence of this work.
Initially, a phase-controlled converter DC drive system
was considered. Fuzzy control was used to linearize the
transfer characteristics of the converter in
discontinuous conduction mode. It was then extended to
the current and speed loops, replacing the conventional
proportional-integral controllers. The control
algorithms were developed in detail, and verified by PC-
SIMNON digital simulation. Significant performance
improvement was achieved over conventional control
methods.
Efficiency optimization of an indirect vector controlled
induction motor drive was next considered. An accurate
loss model of the converter induction machine system was
first developed. Steady-state fundamental and harmonics
loss characteristics, besides the dynamics of the
machine are represented in the model, resulting in a new
synchronous frame dynamic D$sp{rm e}$-Q$sp{rm e}$
equivalent circuit. The converter system has been
modeled accurately for conduction and switching losses.
The lossy models were then used in the validation of the
fuzzy logic based on-line efficiency optimization
control. At steady-state, the fuzzy controller
adaptively changes the excitation current on the basis
of measured input power, until the maximum efficiency
point is reached. The pulsating torque, due to flux
reduction, has been compensated by an ingenious
feedforward scheme. During transients, rated flux is
established, to get the best transient response. After a
comprehensive simulation study, an experimental 5 hp
drive system was tested, with the proposed controller
implemented on a TMS320C25 digital signal processor, and
the theoretical development was fully validated.
Finally, fuzzy logic was applied in combination with
model-reference adaptive control (MRAC) technique to
slip gain tuning of an indirect vector controlled
induction motor drive. The MRAC methods based on
reactive power and D-axis voltage are combined through a
weighting factor, generated by a fuzzy controller, that
ensures the use of the best method for any point in the
torque-speed plane. A second fuzzy controller tunes the
slip gain based on combined detuning error and its
slope. The drive performance was extensively
investigated through simulations and experiments, and
found to be quite satisfactory.
</ABSTRACT>
</THESIS>
<THESIS>
<NUMBER> 4554 </NUMBER>
<ORDER>   AAG9421503 </ORDER>
<TITLE>   EVALUATION OF AN APPROACH TO INTELLIGENT COACHING WITH STUDENT MODELING </TITLE>
<AUTHOR>   SHAHIDI, ANOOSH KHATIB </AUTHOR>
<YEAR>   1993 </YEAR>
<INSTITUTION>   UNIVERSITY OF PITTSBURGH; 0178 </INSTITUTION>
<DESCRIPTORS>   COMPUTER SCIENCE; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER>   NIL </ADVISER>
<CLASSIFICATIONS>   COACHING </CLASSIFICATIONS>
<ABSTRACT>
Until recently, most of the research effort in ITS was
centered around investigating the implementational
issues involved in constructing components and systems.
The field has now reached a consensus on the different
types of ITS systems, and their respective components.
This research evaluates the effectiveness of the student
modeling component of an intelligent coaching system by
asking the following question: Do Students learn better
with on-line intelligent coaching systems driven by
student modeling than with intelligent coaching systems
without student modeling or passive on-line help
systems?
To examine this question, a coaching system with student
modeling, a coaching system without student modeling,
and an on-line help system was implemented. The domain
of these systems was spreadsheet formula entry. The
intelligent coach provided knowledgeable feedback using
the student model. This approach attempts to identify
missing knowledge and explicitly remediate
misconceptions. The coach without student modeling only
provided feedback regarding the correctness of
procedures. The two types of coaching systems were also
compared with traditional sources of information
available to the student in a software environment
(i.e., on-line help) in order to provide a point of
reference for this evaluation. Both coaching systems
were passive (i.e. the student must initiate a coaching
interaction). An experimental study compared the
effectiveness of these systems. Subjects who used the
intelligent coaching system with student modeling had a
significantly higher completion rate with fewer errors
during the post-test. Anaphoric references to the
student's past actions in the intelligent coach's
feedback was the factor that greatly enhanced learning.
These results have implications for the design and
development of instructional systems. Implementing the
intelligent coaching systems in this project was much
more demanding than the rudimentary coach. Additional
modeling, programming, and performance costs are the
norm in developing intelligent tutoring systems: the
cost of intelligence. By indicating that knowledgeable
coaching is preferable in this procedural domain and
showing that it can be provided by an intelligent
coaching system utilizing individual student modeling,
this research suggests that the investment is
worthwhile.
This study also extended Goldstein's (1982) genetic
graph formalism for designing learning models.
Goldstein's learning scheme implied a very strong
progression only from general concepts to specific
concepts. Current views of learning see learning take
place in both directions (i.e., initial learning can
also take place in terms of specifics, from which
generalizations are often incomplete). The student may
learn specific concepts well and may or may not abstract
more general concepts from specific ones. This study
expanded the genetic graph formalism to allow for both
kinds of learning to take place.
</ABSTRACT>
</THESIS>
<THESIS>
<NUMBER> 4555 </NUMBER>
<ORDER>   AAG9421228 </ORDER>
<TITLE>   TRANSPUTER-BASED MACHINE FAULT DIAGNOSTICS </TITLE>
<AUTHOR>   HUANG, HSIN-HAO </AUTHOR>
<YEAR>   1993 </YEAR>
<INSTITUTION>   THE UNIVERSITY OF IOWA; 0096 </INSTITUTION>
<DESCRIPTORS>   ENGINEERING, INDUSTRIAL; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER>   HSU-PIN WANG </ADVISER>
<CLASSIFICATIONS>   NEURAL NETWORKS, FUZZY LOGIC </CLASSIFICATIONS>
<ABSTRACT>
Nowadays, manufacturing companies are making every
effort to reduce costs and improve quality in order to
maintain their competitiveness in the global markets. It
is well recognized that true cost savings and
profitability can be achieved by higher equipment
reliability, availability, and maintainability. In order
to achieve this goal, it is necessary to implement an
effective equipment maintenance program. The primary
objective of this research is to develop a reliable
machine fault diagnostic system to help ensure effective
equipment maintenance.
Several different technologies were integrated to
increase the versatility and reliability of the fault
diagnostic system. The major technique used for fault
diagnostics is a fault diagnostic network (FDN) which is
based on a modified ARTMAP neural network architecture.
In-depth testings have been performed to validate the
performance of the FDN. The testing results show that
the network is able to identify machine faults
perfectly. In addition, the network demonstrated a
remarkable capability to unlearn patterns and fuse
different sensory inputs.
A hypothesis and test procedure based on fuzzy logic and
physical bearing models was developed to work with the
FDN for analyzing complex machine conditions. The
performance results indicate that this procedure is able
to provide accurate fault diagnosis for both one and
multiple-fault conditions.
Furthermore, the requirement of rapid processing in an
on-line system motivated the inclusion of the parallel
processing. Therefore, a transputer-based parallel
processing technique was investigated in this research.
The FDN was implemented on a network of four T800-25
transputers. It is found that a single transputer is
much slower than a 486-33 personal computer. However,
the performance is improved substantially when
transputers are implemented in parallel. The results
show a 12.6% and 37% improvement in network training and
hypothesis and test, respectively.
More and more manufacturing companies are adopting
predictive maintenance in their maintenance programs
today. The fault diagnostic system developed in this
research contributes significantly to the implementation
of an effective predictive maintenance program. With the
capability of performing robust and on-line fault
diagnostics, the system is able to reduce machine
downtime and costs dramatically.
</ABSTRACT>
</THESIS>
<THESIS>
<NUMBER> 4556 </NUMBER>
<ORDER>   AAG9421206 </ORDER>
<TITLE>   AUTOMATED IMAGE SEGMENTATION AND INTERPRETATION USING GENETIC ALGORITHMS AND SEMANTIC NETS </TITLE>
<AUTHOR>   TADIKONDA, SATISH KUMAR </AUTHOR>
<YEAR>   1993 </YEAR>
<INSTITUTION>   THE UNIVERSITY OF IOWA; 0096 </INSTITUTION>
<DESCRIPTORS>   ENGINEERING, ELECTRONICS AND ELECTRICAL; COMPUTER SCIENCE </DESCRIPTORS>
<ADVISER>   STEVE M. COLLINS </ADVISER>
<CLASSIFICATIONS>   NIL </CLASSIFICATIONS>
<ABSTRACT>
Image interpretation plays an important role in computer
vision and robotics. In this thesis, a new approach to
image interpretation is introduced, its feasibility
demonstrated and its accuracy examined using simulated
and real images. A novel feature of this approach is
that it integrates segmentation and interpretation steps
into a single feedback process that incorporates
contextual knowledge and uses a genetic algorithm to
produce an optimal image interpretation.
The general segmentation and object recognition strategy
is based on the "hypothesize and verify"
principle of artificial intelligence. The method begins
with the segmentation of the original image into a large
number of primary regions. A primary region adjacency
graph is constructed that describes the properties of
each primary region as well as its relationships to its
neighbors. A genetic algorithm technique is used to
generate a population of image interpretation
hypotheses, represented as linear strings. Each primary
region is associated with a position in the string of
symbols. The confidence that a particular hypothesis is
correct is evaluated by calculating an objective
function that compares the information contained in the
image data to a priori knowledge about image regions and
objects, their features and relationships. The genetic
algorithm serves to retain good hypotheses and eliminate
poor hypotheses so that over a series of steps the
process converges to the optimal image interpretation.
The genetic algorithm optimizes the objective function.
The method was tested on simulated images of geometrical
shapes and on real images of objects with complex shapes
(magnetic resonance images of the brain). Based on
achieved results, the semantic genetic interpretation
method produced correct object segmentation and labeling
in the tested images.
The presented method is a significant departure from
previous approaches and represents a very promising
image understanding strategy.
</ABSTRACT>
</THESIS>
<THESIS>
<NUMBER> 4557 </NUMBER>
<ORDER>   AAG9420876 </ORDER>
<TITLE>   OPTIMIZATION TECHNIQUES FOR IMAGE RESTORATION, NEURAL NETWORKS, AND HETEROGENEOUS SUPERCOMPUTER SYSTEM DESIGN </TITLE>
<AUTHOR>   MOHANDES, MOHAMED </AUTHOR>
<YEAR>   1993 </YEAR>
<INSTITUTION>   PURDUE UNIVERSITY; 0183 </INSTITUTION>
<DESCRIPTORS>   ENGINEERING, ELECTRONICS AND ELECTRICAL; COMPUTER SCIENCE; ARTIFICIAL INTELLIGENCE </DESCRIPTORS>
<ADVISER>   SAUL B. GELFAND </ADVISER>
<CLASSIFICATIONS>   ANNEALING </CLASSIFICATIONS>
<ABSTRACT>
Simulated annealing algorithms for optimization over
continuous spaces come in two varieties: Markov chain
annealing algorithm (MCAA) and gradient annealing
algorithm (GAA). There is a large amount of theoretical
analysis and practical methodology developed for MCAA.
The practical methodology is closely linked to heuristic
procedures developed in Monte Carlo simulation of
physical systems, from which the MCAA was originally
developed. It has been observed that MCAA is not a
viable approach to high-dimensional problems with smooth
cost function. Theoretical analysis has been developed
for the GAA but no practical methodology exists in the
literature. As GAA attempts to exploit smoothness by its
use of derivatives, an appropriate implementation should
outperform the MCAA for high-dimensional problems with
smooth cost functions. In this thesis we propose a
practical methodology for the GAA. This methodology is
tested and compared with other annealing algorithms on a
set of benchmark functions. Also, we use the GAA for the
restoration of gray-level images corrupted by
multiplicative noise, where we seek the maximum a
posteriori probability (MAP) estimate of the original
image given the degraded one.
In this thesis we show that existing stepsize rules for
gradient descent can skip over nearby minima,
particularly if the minima are deep and have small
regions of attraction. Skipping over nearby minima may
be undesirable when a local search is used as part of a
global optimization strategy. propose a conservative
stepsize rule and prove that it has a linear rate of
convergence. This stepsize rule depends on the maximum
eigenvalue of the Hessian matrix, which is usually hard
to compute. We propose two methods to estimate this
value from function and gradient values. Using these
methods we develop two adaptive stepsize rules which we
use in conjunction with the gradient annealing algorithm
and for training feedforward neural networks.
Distributed Heterogeneous Supercomputing Systems (DHSS)
have been suggested to achieve computational speedup for
complex applications comprising numerous tasks with
varying computational characteristics. DHSS are expected
to outperform homogeneous supercomputing systems, whose
performance can be degraded severely by an ill-matched
segment of code. In this thesis we propose and evaluate
a neural network approach for mapping tasks to a suite
of heterogeneous supercomputers.
</ABSTRACT>
</THESIS>
